第３９卷 第１０期 计 算 机 学 报 Ｖｏｌ．３９ Ｎｏ．１０
２０１６年１０月 ＣＨＩＮＥＳＥ ＪＯＵＲＮＡＬ ＯＦ ＣＯＭＰＵＴＥＲＳ Ｏｃｔ．２０１６
一种大规模网络中基于节点结构特征映射的
链接预测方法
李志宇 梁 循 周小平 张海燕 马跃峰
（中国人民大学信息学院计算机系 北京 １００８７２）
摘 要 网络链接预测能够获取网络中丢失链接的重要信息或进行网络的动态演变分析．现有的基于节点相似性
的网络链接预测方法往往针对简单的一（多）阶邻居信息或特定类型的小型网络，设计较为复杂的计算方法，其扩
展性和大规模网络中的可计算性都受到了严峻的挑战．文中基于深度学习在神经网络语言模型中应用的启发，提
出了一个ＬｓＮｅｔ２Ｖｅｃ（Ｌａｒｇｅ－ｓｃａｌｅ Ｎｅｔｗｏｒｋ ｔｏ Ｖｅｃｔｏｒ）模型．通过结合随机游走的网络数据集序列化方法，进行大
规模的无监督机器学习，从而将网络中节点的结构特征信息映射到一个连续的、固定维度的实数向量．然后，使用
学习到的节点结构特征向量，就可以迅速计算大规模网络中任意节点之间的相似度，以此来进行网络中的链接预
测．通过在１６个大规模真实数据集上和目前的多个基准的最优预测算法对比发现，ＬｓＮｅｔ２Ｖｅｃ模型所得到的预测
总体效果是最优的：在保证了大规模网络中链接预测计算可行性的同时，于多个数据集上相对已有方法呈现出较
大的ＡＵＣ值提升，最高达８．９％．
关键词 链接预测；大规模网络；节点特征向量；连续性表达；神经网络；机器学习
中图法分类号 ＴＰ３１１ ＤＯＩ号 １０．１１８９７／ＳＰ．Ｊ．１０１６．２０１６．０１９４７
Ａ Ｌｉｎｋ Ｐｒｅｄｉｃｔｉｏｎ Ｍｅｔｈｏｄ ｆｏｒ Ｌａｒｇｅ－Ｓｃａｌｅ Ｎｅｔｗｏｒｋｓ
ＬＩ Ｚｈｉ－Ｙｕ ＬＩＡＮＧ Ｘｕｎ ＺＨＯＵ Ｘｉａｏ－Ｐｉｎｇ ＺＨＡＮＧ Ｈａｉ－Ｙａｎ ＭＡ Ｙｕｅ－Ｆｅｎｇ
（Ｓｃｈｏｏｌ ｏｆ Ｉｎｆｏｒｍａｔｉｏｎ，Ｒｅｎｍｉｎ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｃｈｉｎａ，Ｂｅｉｊｉｎｇ １００８７２）
Ａｂｓｔｒａｃｔ Ｔｈｅ ｐｒｏｂｌｅｍ ｏｆ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｃａｎ ｂｅ ｃａｔｅｇｏｒｉｚｅｄ ｉｎｔｏ ｔｗｏ ｃｌａｓｓｅｓ，ｎａｍｅｌｙ，ｍｉｓｓｉｎｇ
ｌｉｎｋｓ ｐｒｅｄｉｃｔｉｏｎ ａｎｄ ｆｕｔｕｒｅ ｌｉｎｋｓ ｐｒｅｄｉｃｔｉｏｎ．Ｔｈｅ ｆｏｒｍｅｒ ｉｓ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ ｏｆ ｕｎｋｎｏｗｎ ｌｉｎｋｓ ｉｎ
ｓａｍｐｌｉｎｇ ｎｅｔｗｏｒｋｓ；ａｎｄ ｔｈｅ ｏｔｈｅｒ ｉｓ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ ｏｆ ｌｉｎｋｓ ｔｈａｔ ｍａｙ ｅｘｉｓｔ ｉｎ ｔｈｅ ｆｕｔｕｒｅ ｏｆ
ｅｖｏｌｖｉｎｇ ｃｏｍｐｌｅｘ ｎｅｔｗｏｒｋｓ．Ｕｎｔｉｌ ｎｏｗ，ｍｏｓｔ ｏｆ ｔｈｅ ｍｅｔｈｏｄｓ ｆｏｒ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ａｒｅ ｄｅｓｉｇｎｅｄ
ｂａｓｅｄ ｏｎ ｔｈｅ ａｓｓｕｍｐｔｉｏｎ ｏｆ ｎｏｄｅ ｓｉｍｉｌａｒｉｔｙ，ｗｈｉｃｈ ｄｅｆｉｎｅｄ ｂｙ ｕｓｉｎｇ ｔｈｅ ｅｓｓｅｎｔｉａｌ ｆｅａｔｕｒｅｓ ｏｆ
ｎｏｄｅｓ．Ｔｈｅ ｓｉｍｉｌａｒｉｔｙ ｅｖａｌｕａｔｉｏｎ ｏｆ ｔｗｏ ｎｏｄｅｓ ｍａｋｉｎｇ ｔｈｅ ｓｐａｒｓｉｔｙ ａｎｄ ｈｕｇｅ ｓｉｚｅ ｏｆ ｎｅｔｗｏｒｋｓ
ｂｅｃｏｍｅ ｔｗｏ ｏｆ ｔｈｅ ｍａｉｎ ｃｈａｌｌｅｎｇｅｓ ｒｅｍａｉｎ ｉｎ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｐｒｏｂｌｅｍｓ．Ｉｎ ｔｈｉｓ ｗｏｒｋ，ｗｅ ｐｒｅｓｅｎｔ ａ
ｎｅｗ ｍｏｄｅｌ，ｎａｍｅｄ ＬｓＮｅｔ２Ｖｅｃ，ｆｏｒ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｉｎ ｌａｒｇｅ－ｓｃａｌｅ ｎｅｔｗｏｒｋｓ ａｃｃｏｒｄｉｎｇ ｔｏ ｔｈｅ
ｕｎｓｕｐｅｒｖｉｓｅｄ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ．Ｔｈｅ ｍａｉｎ ｉｄｅａ ｏｆ ｏｕｒ ｍｅｔｈｏｄ ｉｓ ｅｍｂｅｄｄｉｎｇ ｔｈｅ ｆｅａｔｕｒｅｓ ｏｆ ｎｏｄｅｓ
ｉｎ ｌａｒｇｅ－ｓｃａｌｅ ｎｅｔｗｏｒｋｓ ｉｎｔｏ ａ ｌｏｗｅｒ ａｎｄ ｆｉｘｅｄ ｄｉｍｅｎｓｉｏｎ ｏｆ ｖｅｃｔｏｒ ｉｎ ｔｈｅ ｓｅｔ ｏｆ ｒｅａｌ ｎｕｍｂｅｒｓ．Ｗｅ
ｃｏｎｄｕｃｔ ｅｘｔｅｎｓｉｖｅ ｅｘｐｅｒｉｍｅｎｔａｌ ａｎａｌｙｓｉｓ ｏｎ ｓｉｘｔｅｅｎ ｆａｍｏｕｓ ｄａｔａｓｅｔｓ ａｎｄ ｐｒｅｓｅｎｔ ａ ｃｏｎｔｒｏｌｌｅｄ
ｃｏｍｐａｒｉｓｏｎ ｏｆ ｔｈｅ ＬｓＮｅｔ２Ｖｅｃ ｍｏｄｅｌ ａｇａｉｎｓｔ ｓｅｖｅｒａｌ ｓｔｒｏｎｇ ｂａｓｅｌｉｎｅｓ ｏｆ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｍｅｔｈｏｄｓ，
收稿日期：２０１５－０８－０６；在线出版日期：２０１６－０３－０７．本课题得到国家自然科学基金（７１２７１２１１，７１５３１０１２）、北京市自然科学基金
（４１３２０６７）、中国人民大学科学研究基金（１０ＸＮＩ０２９）、中国人民大学２０１５年度拔尖创新人才培育资助计划资助．李志宇，男，１９９１年生，
博士研究生，中国计算机学会（ＣＣＦ）会员，主要研究方向为社会计算、机器学习．Ｅ－ｍａｉｌ：ｚｈｉｙｕｌｅｅ＠ｒｕｃ．ｅｄｕ．ｃｎ．梁 循（通信作者），男，
１９６５年生，博士，教授，博士生导师，中国计算机学会（ＣＣＦ）会员，主要研究领域为神经网络、支持向量机、社会计算．Ｅ－ｍａｉｌ：ｘｌｉａｎｇ＠
ｒｕｃ．ｅｄｕ．ｃｎ．周小平，男，１９８５年生，博士研究生，中国计算机学会（ＣＣＦ）会员，主要研究方向为Ｗｅｂ挖掘、社会计算．张海燕，女，１９７５年
生，博士研究生，中国计算机学会（ＣＣＦ）会员，主要研究方向为复杂网络、社会计算、推荐系统．马跃峰，男，１９７６年生，博士研究生，中国
计算机学会（ＣＣＦ）会员，主要研究方向为数据挖掘、机器学习与模式识别． １９４８ 计 算 机 学 报 ２０１６年
ｗｉｔｈ ＡＵＣｔｅｓｔｉｎｇ．Ｒｅｓｕｌｔ ｓｈｏｗ ｔｈａｔ ｏｕｒ ｍｏｄｅｌ ｐｅｒｆｏｒｍｓ ｃｏｍｐａｒａｂｌｙ ｗｉｔｈ ｓｔａｔｅ－ｏｆ－ｔｈｅ－ａｒｔ ｍｅｔｈｏｄｓ，
ｓｕｃｈ ａｓ Ｋａｔｚ ｉｎｄｅｘ ａｎｄ ｒａｎｄｏｍ ｗａｌｋ ｒｅｓｔａｒｔ ｍｅｔｈｏｄ，ｉｎ ｖａｒｉｏｕｓ ｅｘｐｅｒｉｍｅｎｔ ｓｅｔｔｉｎｇｓ．
Ｋｅｙｗｏｒｄｓ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ；ｌａｒｇｅ－ｓｃａｌｅ ｎｅｔｗｏｒｋｓ；ｎｏｄｅ ｆｅａｔｕｒｅ ｖｅｃｔｏｒ；ｄｉｓｔｒｉｂｕｔｅｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ；
ｎｅｕｒａｌ ｎｅｔｗｏｒｋ；ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ
从网络节点的邻接矩阵Ａ转换到邻接矩阵Ｂ的可
１ 引 言 能性问题．
从链接预测采用的信息源来划分，链接预测方
网络链接预测（ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ）是指利用已知 法又主要可以分为基于网络拓扑结构的链接预测方
的网络信息对未知的链接（ｅｘｉｓｔｅｎｔ ｙｅｔ ｕｎｋｎｏｗｎ 法、基于网络内容属性的链接预测方法以及基于结
ｌｉｎｋｓ）或者未来时间的链接（ｆｕｔｕｒｅ ｌｉｎｋｓ）进行预 构－属性的混合链接预测方法．基于网络拓扑结
测［１］．如图１（Ａ）所示，图Ｇ为已知的节点及其链接 构［３，１０］的预测算法主要利用网络中节点的结构信
关系（实线），而Ｇ珚为Ｇ中不存在的链接关系（细虚 息，包括节点的Ｎ阶邻居关系、节点的出入度信息
线），则链接预测问题就是利用图Ｇ中的已知信息 等等，对节点之间的未知链接进行预测．基于网络内
给出图Ｇ珚中细虚线的形成概率．链接预测的相关研 容属性的链接预测［５］主要利用节点所包含的属性内
究在包括生物学领域、电子领域、信息领域等各类领 容和标签信息，结合机器学习以及自然语言处理等
域得到了广泛关注［２］．典型的链接预测应用包括分 工具，来对不同节点的相似性进行度量，从而预测节
子生物学的蛋白质交互关系预测［３－４］、合作关系预 点之间构建链接的可能性．最后，结构－属性的混合
测［５－６］、社会网络关系预测［７－８］以及推荐系统的推荐 链接预测则是上述二者的综合与权衡．
预测［９］等等． 一般而言，相对于现有的基于拓扑结构的预测
算法，基于内容属性的相关算法虽然能够有效地利
用节点的外部信息，使得在一定程度上提升算法的
效果，但通常由于节点的属性信息获取较为困难，以
及节点属性的信息的真实性无法得到保证，因此这
类方法的稳定性需要进一步的衡量［１１］．近年来，基
于拓扑结构的链接预测方法受到了越来越多的关
注［３，１０］．相比节点属性方法而言，节点的结构信息可
获取性较高，同时信息的真实性较强，因此能够具有
更好的通用性．
目前，基于网络拓扑结构的主流预测算法包括
基于节点Ｎ阶邻居信息的预测算法、基于最大似然
图１ 连接预测问题网络结构举例
估计的预测算法以及基于概率模型的预测算法．在
对于网络链接的预测问题，从预测方法上来说， 现有网络链接预测的研究中，有一个重要的应用思
可以分为基于马尔可夫链的分析方法和基于机器学 想和假设是：如果两个节点的相似性（结构相似性或
习的分析方法，其本质都是计算网络中两个节点存 者属性相似性）越高，则它们存在链接或者在未来形
在链接的概率问题，即在表达形式上，可以根据特定 成链接的可能性则更高．由此，在相似性假设的基础
的网络基本数据信息将链接关系转换为有向图链接 上产生了很多较为实用的链接预测方法．其中，代表
和无向图链接，图中的节点用以表示网络中的节点， 性的算法可分为３类［１２］：基于网络局部信息的相似
图中的边则表示链关系存在的可能性．同时，对于有 性算法［１］、基于网络节点路径相似性算法［１３－１４］以及
些特殊问题，图中的边还会赋予一定的权重用以表 基于网络随机游走的相似性算法［１５－１６］．对比之下，虽
示不同节点边的重要性差异．在存储数据上，通常将 然基于局部信息相似性的计算方法通常计算复杂度
网络结构信息以邻接矩阵的形式存储，矩阵中的值 较低，但是计算的准确度却不如基于网络路径的相
既有可能是离散的（０，１）结构，也有可能是连续的概 似性算法，而基于网络随机游走的相似性则是上述
率分布．然而，最终的链接预测问题都可以规范为： 二者的折中，同时考虑计算效率以及预测的准确率． １０期 李志宇等：一种大规模网络中基于节点结构特征映射的链接预测方法 １９４９
随着大数据时代的来临，各类网络规模都在迅 地提升了现有基于网络拓扑结构节点相似性用以大
速的增加，并且呈动态变化，动辄上百万甚至上千万 规模网络中链接预测问题方法的准确性．
的网络数据使得现有的网络分析与链接预测方法 （２）在计算效率方面：ＬｓＮｅｔ２Ｖｅｃ模型训练得
变得捉襟见肘．因此，在原始小型网络环境中设计 到的节点的分布式表达（节点向量）克服了在大规模
的相关链接预测算法在计算的可行性以及准确度 网络中利用网络拓扑结构进行链接预测所带来的高
上需要被重新设计．换而言之，需要针对现有大规 计算复杂度问题，使得在大规模网络中对任意节点
模的网络结构特点，设计新的链接预测算法：在首 之间的相似性计算变为可行同时高效．
先保证计算可行性的前提下，提高网络链接预测 （３）在应用拓展方面：ＬｓＮｅｔ２Ｖｅｃ模型所训练
的准确率． 得到的节点结构特征向量为复杂网络中以网络结构
近年来，在机器学习领域，深度学习是一个值得 特征基础的其他应用问题如社区发现、关键路径预
重点关注的研究方法．深度学习已经在包括计算机 测、跨平台用户检测等提供了一个可能的新思路和
视觉、音频处理以及自然语言处理等领域取得了巨 新方法．
大的成功［１７］．其中，在自然语言处理领域中，基于神 本文的第２节主要介绍链接预测问题的相关工
经网络的语义空间模型的文本分布式表达的相关模 作，同时指出当前链接预测问题存在的难点；第３节
型及其拓展得到了广泛的研究［１８－２２］，并且取得了较 对模型论述过程中涉及到的相关概念和符号进行详
大的进展．词语特征的分布式表达模型的核心思想 细的定义，同时给出链接预测以及模型评估问题的
是将词语的语法或者语义特征映射到一个固定维度 数学形式化表述；第４节对模型的主要框架以及模
的连续空间，以此解决原有方法中存在的词语矩阵 型优化涉及到的数学过程进行推导，同时给出参数
所包含的稀疏性问题以及计算的维数灾难［２３］．后续 修改的数学表达式以及最终算法的伪代码叙述；第
研究中，Ｍｉｋｏｌｏｖ等人［２４］在此基础上提出了ＣＢＯＷ ５节给出实验的基本设置以及数据集、基准对比方
模型以及Ｓｋｉｐ－ｇｒａｍ模型用以大规模的文本连续性 法和评价指标的选取，对实验取得的相关结果进
表达的学习，并在多个应用上取得了较好的结果． 行分析并讨论超参对于实验结果的影响；最后，我
本文的模型设计受到深度学习在自然语言中相 们在第６节给出相应的研究结论以及下一步的研
关应用的启发，结合了网络随机游走的序列化方法， 究展望．
通过将传统网络中节点的结构特征映射到连续的、
固定维度的向量空间，由此得到大规模网络中节点 ２ 相关工作
结构特征的分布式表达（节点向量），从而应用于网
络链接预测问题中．在链接预测问题中，本文采用的 较为系统的链接预测问题最早由Ｌｉｂｅｎ－Ｎｏｗｅｌｌ
假设同样是基于节点相似性预测，即通过计算不同 等人［２５］提出，此后便得到了学术界的广泛关注．在
节点结构特征向量的余弦相似性估计节点之间存在 文献［２５］中，作者基于节点的相似性假设，对科学合
链接的可能性． 作网络的链接预测问题进行了实证研究，同时作者
和以往研究不同的是，对于大规模网络中节点 提出了一些基本的节点相似性计算方法，这些方法
的结构特征的获取不再是进行人工的构建，而是利 也成为后续研究的对比基准．Ｌｉｂｅｎ－Ｎｏｗｅｌｌ等人提
用节点在网络中随机游走的方法，使用ＬｓＮｅｔ２Ｖｅｃ 出的基准方法包括节点共同邻居相似性（Ｃｏｍｍｏｎ
模型进行自动的无监督学习，从而有效避免了繁杂 Ｎｅｉｇｈｂｏｒ，ＣＮ）（局部信息）、Ａｄａｍｉｃ－Ａｄａｒ（ＡＡ）相
的手工网络特征构造工作，同时提高了算法在不同 似性（局部信息）、Ｊａｃｃａｒｄ系数相似性（局部信息）、
类型网络之间迁移的能力．实验证明，ＬｓＮｅｔ２Ｖｅｃ Ｋａｔｚ相似性（全局路径信息）、ＳｉｍＲａｎｋ相似性（随
模型拥有强大的数据扩展能力，能快速实现百万（笔 机游走）等．此后，国内外学者围绕基于节点相似性
记本电脑／数小时训练时间）甚至千万级别（笔记本 的链接预测问题提出了各种类型的改进模型和链接
电脑／数天训练时间）网络中节点结构特征的分布式 方法，不断的从预测的准确性上进行相应的改善，具
表达的学习问题． 有代表性研究包括：
本文的主要贡献包括３个方面： （１）基于局部信息．Ｚｈｏｕ等人［１］基于网络中资
（１）在准确性方面：通过在广泛和大规模的真 源分配（Ｒｅｓｏｕｒｃｅ Ａｌｌｏｃａｔｉｏｎ，ＲＡ）的角度提出了一
实数据集上的实证实验表明，ＬｓＮｅｔ２Ｖｅｃ模型较大 种新的节点相似性度量方法．其核心思想上假设网 １９５０ 计 算 机 学 报 ２０１６年
络中每个单元都有一个资源，对于原始网络中某两 的输入，来改进传统无监督预测算法的准确率．吴祖
个不存在链接的节点Ａ和Ｂ，其共同邻居为Ａ／Ｂ间 峰等人［３１］基于ＡｄａＢｏｏｓｔ算法对基于网络拓扑结构
资源传递的媒介，假设每个媒介都会均匀的把资源 的链接预测问题中存在的召回率低的问题进行了改
传给它的邻居，那么Ｂ接收到的资源数就被定义为 进．按照网络中节点之间是否存在链接关系，将链路
Ａ／Ｂ节点之间的相似度．ＲＡ方法虽然能够有效惩 预测问题定义为二分类问题，然后进一步遵循算法
罚大度节点，但是当网络节点的平均度较小时，ＲＡ 互补的原则选择若干具有代表性的链路预测算法作
算法和ＡＡ算法差别并不大．Ｌｉｕ等人［２６］基于社会 为弱分类器实现了链接预测．李玉华等人［３２］针对基
网络定义不同社区成员之间的距离关系问题，结合 于拓扑网络结构的链路预测方法中不存在时间属性
多维度的社会距离表示，利用 Ｈａｓｈ方法在多维度 的问题，结合科研合作网的特点，提出了一种基于链
的空间中进行节点相似度的计算，通过统计节点的 接重要性的动态链接预测方法．通过引入链接重要
局部结构特征，来对全局环境中的信息传递进行动 性的度量，对拓扑属性和语义相似度等属性进行修
态预测． 正，以此考虑动态性以反映时间因素对链接形成的
（２）基于路径信息．Ｌü等人［２７］提出了一种基于 影响，最后利用分类技术进行预测．
两个节点之间的局部路径（Ｌｏｃａｌ Ｐａｔｈ，ＬＰ）的相似 经过已有文献的实验表明［１１，３３－３５］，现有方法
性度量方法，该方法是在邻居节点的基础上进一步 中基于全局的节点信息的相似度计算方法，如Ｋａｔｚ
考虑了三阶邻居的贡献，从而挖掘节点之间的相似 方法、ＬＨＮ－ＩＩ方法，以及基于随机游走方法中，如
性．ＬＰ方法是ＣＮ方法的扩展，当进一步考虑Ｎ阶 ＡＣＴ方法、Ｃｏｓ＋方法、ＲＷＲ方法、ＳｉｍＲａｎｋ方法
扩展时，该方法则相当于Ｋａｔｚ方法，复杂性较高．同 等在大规模网络中的计算复杂度都很高，同时计算
时，Ｌｉｃｈｔｅｎｗａｌｔｅｒ等人［２８］提出了一种有监督的加权 效果的表现也不是很稳定．而目前，专门针对大规模
的节点相似性度量方法，该方法在构建训练集时需 网络（１０５个节点以上）的链接预测算法几乎很少，目
要大量可靠标签，因此对于不同的未标注网络扩展 前采用的做法是针对现有的链接预测算法设计并行
性较差． 的思路进行改进，例如Ｏｇａｔａ等人［３６］提出了一种基
（３）基于随机游走．这类方法是后续改进方法对 于乔里斯基分解（Ｃｈｏｌｅｓｋｙ ｄｅｃｏｍｐｏｓｉｔｉｏｎ）的矩阵
效果和效率同时进行权衡的一类方法，其中平均通勤 分解方法，来对链接的传播机制进行分析．然而，虽
时间（Ａｖｅｒａｇｅ Ｃｏｍｍｕｔｅ Ｔｉｍｅ，ＡＣＴ）、随机游走余 然这种方法能够相对于传统的方法在速度上有所提
弦相似性（Ｃｏｓ＋）、有重启的随机游走（Ｒａｎｄｏｍ 升，但是在准确度上却不如以前．还有一种做法就是
Ｗａｌｋ ｗｉｔｈ Ｒｅｓｔａｒｔ，ＲＷＲ）成为了基准的基于随机 基于分层或者社区标注的思想，进行预处理后在通
游走的相似性度量对照方法．此后Ｌｉｕ等人［１５］提出 过社区标签或者分层标签进行链接预测．例如Ｓｈｉｎ
了一种基于叠加的局部随机游走相似性度量方法 等人［３７］提出了一个基于树结构的，通过结合层次聚
（Ｓｕｐｅｒｐｏｓｅｄ Ｒａｎｄｏｍ Ｗａｌｋ，ＳＲＷ），它是在局部随 类的方式在多个数量级上进行链接预测．然而，由于
机游走的基础上对Ｔ步及其前序结果进行加和从 作者在模型中使用的是一个平衡层次树结构来对现
而得到ＳＲＷ相似度．该方法是对ＲＷＲ的方法的改 有的数据进行拟合，使得相对来说并不能够有效地
进，但只考虑了真实网络中的局域性特点（目的是为 切合很多实际数据集中所存在的情况．
了减少计算复杂度），忽视了网络的全局特征，精度 但是上述策略始终是无法针对性地解决大规模
有所下降． 网络所带来的数据稀疏性以及邻接矩阵的维数灾难
除上述网络节点相似度计算方法外，国内的其 问题．因此，本文针对现有研究存在的计算复杂度
他相关研究包括：黄立威等人［２９］针对异质信息网络 高，需要的内存开销大等问题提出了基于节点结构
的特征，使用元路径描述节点之间不同类型的关系， 特征的分布式表达模型ＬｓＮｅｔ２Ｖｅｃ．
从而提出了关于异质信息网络的链路预测模型，通
过组合不同元路径上对象之间的连接建立的概率来 ３ 符号及问题定义
进行链路预测，取得了不错的效果．刘冶等人［３０］提
出了一种基于低秩和稀疏矩阵分解的多源融合去噪 本节首先给出了模型中涉及到的基础符号定义
链接预测算法，通过将主数据源和附加数据源进行 （如表１），然后定义了模型中涉及到的重要概念，最
有效融合，然后作为传统无监督拓扑链接预测算法 后给出了链接预测问题求解思路的形式化表达． １０期 李志宇等：一种大规模网络中基于节点结构特征映射的链接预测方法 １９５１
表１ 基础符号定义
训练窗口中，其周边节点Ａｒｏｕｎｄ（Ｓ）是不同的，并
符号 定义
且Ａｒｏｕｎｄ（Ｓ）可以包含节点Ｓ最多任意预测窗口
Ｇ＝（Ｖ，Ｅ）图Ｇ包含节点集合Ｖ，以及边集合Ｅ Ｗｉｎｄｏｗ Ｎ大小阶数的邻居．Ａｒｏｕｎｄ（Ｓ）的形成方
Ｇ 图Ｇ中包含的节点数目
式为：
Ｇ珚 图Ｇ的补图
Ｘ∈Ｖ 正体Ｘ表示图Ｇ节点集合Ｖ中的节点Ｘ 对于节点Ｓ，首先随机向前选取ｓｔｅｐ个节点，然
ｍ 特征向量的维度数，正整数值，通常的０＜ｍ１０００
Ｍ 节点特征嵌入矩阵Ｍ，是一个｜Ｇ｜×ｍ实数值矩阵
后随机向后选取Ｎ－ｓｔｅｐ个节点构成，其中每次向前
ＳｘＭ ，ｅ ｙｔｈｏｄ 相识度计算方法Ｍｅｔｈｏｄ基于节点ｘ，ｙ的相似度得分 选取的随机值ｓｔｅｐ满足：０ｓｔｅｐＮ．
以图２中节点Ｇ为例，节点Ｇ出现在了前３条
定义１． 训练预测窗口Ｗｉｎｄｏｗ Ｎ． 训练集中，那么此时以Ｇ为预测目标的，即Ｗｉｎｄｏｗ
在ＬｓＮｅｔ２Ｖｅｃ模型中，预测窗口Ｗｉｎｄｏｗ Ｎ Ｎ＝４时的可能周边节点为
（Ｎ４）为一个实值正整数．其意义为限制每一个被 Ｇ在第１条训练集中的周边节点（ｓｔｅｐ＝３）：
预测节点Ｓ的周边节点Ａｒｏｕｎｄ（Ｓ）的覆盖幅度，数 Ａｒｏｕｎｄ（Ｇ）＝｛Ｆ，Ｄ，Ｂ，Ｈ｝→Ｇ；
值上等于Ａｒｏｕｎｄ（Ｓ）中节点的个数． Ｇ在第２条训练集中的周边节点（ｓｔｅｐ＝２）：
定义２． 节点Ｓ的周边节点Ａｒｏｕｎｄ（Ｓ）． Ａｒｏｕｎｄ（Ｇ）＝｛Ｃ，Ｈ，Ｂ，Ｆ｝→Ｇ；
和现有网络分析中关于邻居节点的定义不同的 Ｇ在第３条训练集中的周边节点（ｓｔｅｐ＝０）：
是，ＬｓＮｅｔ２Ｖｅｃ模型中的邻居节点是根据网络节点 Ａｒｏｕｎｄ（Ｇ）＝｛Ｂ，Ｃ，Ｅ，Ｈ｝→Ｇ．
序列化（４．２节）的结果动态变化的．因此，对于同一 其中，节点Ｄ，Ｂ，Ｈ，Ｅ为节点Ｇ的直接邻居（一阶
个节点，在不同的输出序列化训练集中，甚至不同的 邻居），节点Ｃ，Ｆ为节点Ｇ的间接邻居（二阶邻居）．
图２ ＭＡＸ＿ＬＥＮＧＴＨ＝７，ＷＡＬＫ＿ＴＩＭＥＳ＝４的随机游走网络节点序列化结果
定义３． 节点特征分布式表达嵌入矩阵Ｍ． 试集Ｅｔ中的信息看作已知信息，以此对测试集合
实质上，嵌入矩阵Ｍ可以看作一个关于网络中 Ｅｅ中存在的链接进行预测．
节点特征向量的“表”结构，每个节点对应嵌入矩阵
Ｍ的一行，每行的维度数即节点特征向量的维度数 ４ ＬｓＮｅｔ２Ｖｅｃ模型
ｍ，每次获取特定节点特征向量的过程即为一次查
表过程． ４．１ 模型架构概述
问题１．网络链接预测． 如图３所示，ＬｓＮｅｔ２Ｖｅｃ模型为３层架构，分别
给定一个无向图Ｇ＝（Ｖ，Ｅ），得到Ｇ珚，如图１（Ａ） 包括输入层、投影层以及输出层，本节将分别对每层
所示．则对于既定的链路预测方法，得出补图Ｇ珚中每 架构的基本功能进行阐述．
两个节点（每条边）之间的分值（或概率）Ｓｉｍ（ｘ，ｙ）， ４．１．１ 输入层
然后对所有分值进行排序，得到最可能的边分布情 输入层的主要功能是对原始网络进行序列化
况．即链接预测问题的目标是给出补图Ｇ珚中边的形 （即图３中Ｋ１）处理．序列化指的是按照一定的规则
成概率． 对网络中的节点进行遍历，然后按照序列化的格式
问题２．网络链接预测的评估方法． 进行输出，进而重构训练集．目的是利用目标节点的
为了评估链接预测算法的准确性，通常，对于 周围环境特征来对目标节点进行预测，即通过节点
已知图Ｇ＝（Ｖ，Ｅ）中的链接集合Ｅ，将其拆分为训 环境结构特征的学习来预测节点自身．训练集的重
练集Ｅｔ和测试集合Ｅｅ，其中，拆分需要满足：Ｅ＝ 构是网络节点结构特征向量化的关键步骤之一，也
Ｅｔ∪Ｅｅ，同时Ｅｔ∩Ｅｅ＝，如图１（Ｂ）所示．即将测 是涉及节点结构特征提取好坏的重要预处理步骤． １９５２ 计 算 机 学 报 ２０１６年
图３ ＬｓＮｅｔ２Ｖｅｃ模型架构
即对于网络中的某个节点Ｓ，模型的基本目标是在 ４．１．２ 投影层
已知节点Ｓ的周边节点Ａｒｏｕｎｄ（Ｓ）的前提下，对节 投影层的主要功能是将序列化的训练集按照给
点Ｓ进行预测，如式（１）所示： 定训练窗口大小α在嵌入矩阵Ｍ（即图３中Ｋ２）中
进行查找，然后将查找得到的向量集合作为参数传
Ｔｒａｉｎｉｎｇ ｓｅｔ＝｛（Ｓ，Ａｒｏｕｎｄ（Ｓ））｝，Ｓ∈Ｖ （１）
则对所有预测目标的预测概率对数似然后，最
递给聚合函数ｆ（·）进行处理，如图４所示．向量维
度数ｍ为超参，通常由具体应用结合原始网络的大
终目标函数为
小以及训练精度和时间等要求动态设计，该超参对
Ｏ＝ａｒｇ ｍａｘ∑ｌｏｇｐ（Ｓ，Ａｒｏｕｎｄ（Ｓ）） （２）
结节点特征提取用于链接预测问题的好坏影响将在
Ｓ∈Ｖ
式（２）中，Ｖ为重构后的训练集，ｐ（·）为概率函数． 第５．５．１节进行实验讨论．
图４ 投影层结构关系
４．１．３ 输出层 ＷＡＬＫ＿ＴＩＭＥＳ．通过实验发现，上述参数和输入
如图５所示，输出层的构成是一棵 Ｈｕｆｆｍａｎ 网络的节点数量和边数存在相应的数量关系．一般
树，选用 Ｈｕｆｆｍａｎ树对网络节点进行重构存储能 来说，对于较大规模的网络，如果式（３）取值过小，则
够有效地降低计算的复杂度．ＬｓＮｅｔ２Ｖｅｃ模型中 会导致网络结构初步提取不充分，从而使得训练得
Ｈｕｆｆｍａｎ树的编码原则是基于输入图中节点的度 到的节点向量无法充分学习得到网络的结构特征．
的大小进行编码存储．Ｈｕｆｆｍａｎ树中共包含 Ｇ 个 ＭＡＸ＿ＬＥＮＧＴＨ×ＷＡＬＫ＿ＴＩＭＥＳ （３）
叶子节点．树中的每个节点可以看作一个分类器，对 反之，如果式（３）取值过大则会增加模型的训练
输入的信息进行分类预测，其详细功能在４．３节进 时间和复杂度，甚至降低预测效率．
行详细分析． 以图２为例，假设ＭＡＸ＿ＬＥＮＧＴＨ＝７，ＷＡＬＫ＿
４．２ 网络节点的序列化 ＴＩＭＥＳ＝４，对原始输出网络进行一轮序列化．其基
网络节点的序列化是对原始网络节点的结构特 本步骤为：每次游走时随机从网络中选取一个初始
征进行初步提取的基本步骤．在 ＬｓＮｅｔ２Ｖｅｃ模型 出发节点，然后在网络中进行随机游走，游走的步长
中，我们采用随机游走的方法获取序列化的节点信 为ＭＡＸ＿ＬＥＮＧＴＨ－１，将走过的节点按顺序输出，
息．该步骤主要包含两个参数：每次游走的最大长度 作为一个训练序列，重复该步骤ＷＡＬＫ＿ＴＩＭＥＳ
ＭＡＸ＿ＬＥＮＧＴＨ 和重构数据集的随机游走次数 次．对于参数ＭＡＸ＿ＬＥＮＧＴＨ的分析在５．５．２节 １０期 李志宇等：一种大规模网络中基于节点结构特征映射的链接预测方法 １９５３
是节点Ｃ的直接邻居，也有可能是其间接邻居，如
社会网络中，朋友的朋友关系．
现考虑，以输入序列｛Ａ，Ｈ，Ｉ，Ｂ，Ｆ｝→Ｃ进行
的一次训练和参数调整的过程：
对于输入序列｛Ａ，Ｈ，Ｉ，Ｂ，Ｆ｝，一次模型的训练
目标是通过Ｈｕｆｆｍａｎ树的分类，以最大的概率到达
Ｃ所在的叶子节点．对于叶子节点Ｃ，其 Ｈｕｆｆｍａｎ
编码为式（４）：
｛ＨＣ，ＨＣ，ＨＣ｝＝｛１，０，１｝ （４）
１ ２ ３
此时该编码路径上所包含的非叶子节点的参数
向量集合为式（５）：
｛θＣ，θＣ，θＣ｝ （５）
０ １ ２
由图５中投影层可知，对于输入序列｛Ａ，Ｈ，Ｉ，
Ｂ，Ｆ｝在节点嵌入矩阵Ｍ中进行查找，可以得到序
列节点的分布式表达：
｛Ａ，Ｈ，Ｉ，Ｂ，Ｆ｝→｛ｖ（Ａ），ｖ（Ｅ），ｖ（Ｉ），ｖ（Ｂ），ｖ（Ｆ）｝（６）
然后对式（６）通过聚合函数ｆ（·）进行聚合，得
到结构特征环境向量ｖ ，本模型中我们选用基本
Ａ（Ｃ）
的叠加函数进行计算，如式（７）所示．
ｖ ＝Ａｒｏｕｎｄ（ｖ）＝ ∑ ｖ （７）
Ａ（Ｃ） Ｃ ｉ
图５ 以叶子节点Ｃ为目标的一次训练过程 ｉ∈Ａｒｏｕｎｄ（Ｃ）
其中，Ａｒｏｕｎｄ（Ｃ）为训练窗口，在本例子中窗口
进行了详细的讨论． 大小为５，即选取以预测目标Ｃ为中心的前后，窗口
４．３ 模型推导与参数训练 大小为５的邻居节点作为Ｃ的周边结构特点的描
本节中，将结合一个具体的例子，对模型参数的 述．此时预测问题转换为：以向量ｖ 根节点的输
Ａ（Ｃ）
训练过程进行详细推导．首先，给出了模型训练中的 入，如何计算到达叶子节点Ｃ的概率．
重要符号及其定义；然后，以一次训练过程为例，给 如４．１．３节所述，将 Ｈｕｆｆｍａｎ树中的每个节点
出了分层的ｓｏｆｔｍａｘ方法；接着，结合目标函数，采 看作一个分类器，我们选取经典的ｓｉｇｍｏｉｄ函数作
用随机梯度上升的方法对参数进行寻优，并给出了 为的激活函数结合逻辑回归，那么对于输入向量Ｘ，
节点向量，参数的具体更新过程． 其输出为正例的概率为式（８）：
４．３．１ 目标函数推导 １
σ（ＸＴθ）＝ （８）
如图５中输出层所示．考虑 Ｈｕｆｆｍａｎ树中某个 １＋ｅ－ＸＴθ
叶子节点对应图Ｇ节点集合中的某个节点Ｃ，定义 输出为负例的概率为１－σ（ＸＴθ）．
符号如下所示： 那么，对于叶子节点Ｃ而言，其 Ｈｕｆｆｍａｎ编码
（１）ｐＣ＝｛ｐＣ ０，ｐＣ １，…，ｐ ｎＣ｝：从根节点出发到达 ｛１，０，１｝对应的分类过程为式（９）：
叶子节点Ｃ的所包含的路径，其中ｐＣ ０为 Ｈｕｆｆｍａｎ 烄１→ｐ（１ ｖ ＡＴ （Ｃ），θＣ ０）＝σ（ｖ ＡＴ （Ｃ）θＣ ０）
树的根节点，ｐ ｎＣ为对应的叶子节点Ｃ，｜ｐＣ｜为路径 烅０→ｐ（０ｖ ＡＴ （Ｃ），θＣ １）＝１－σ（ｖ ＡＴ （Ｃ）θＣ １） （９）
中包含的节点个数； 烆１→ｐ（１ ｖ ＡＴ （Ｃ），θＣ ２）＝σ（ｖ ＡＴ （Ｃ）θＣ ２）
（２）｛ＨＣ，ＨＣ，…，ＨＣ｝：叶子节点Ｃ对应的 因此，基于邻居节点的向量的输入成功到达叶
１ ２ ｎ
Ｈｕｆｆｍａｎ编码； 子节点Ｃ的最终联合概率为式（１０）：
（３）｛θＣ，θＣ，…，θＣ ｝：到达叶子节点Ｃ路径中
３
０ １ ｎ－１
所包含非叶子节点的参数向量集合；
ｐ（Ｃ Ａｒｏｕｎｄ（Ｃ））＝∏ｐ（Ｈ ｉＣｖＴ （Ｃ），θ ｉＣ －１）（１０）
ｉ＝１
在ＬｓＮｅｔ２Ｖｅｃ模型中，对于节点Ｃ的预测同样 将上述推导过程一般化，得到任意某个叶子节
基于 Ｍａｒｋｏｖ假设，即对于一个节点Ｃ，其出现的概 点Ｓ，其输入邻居聚合向量为ｖ ，则从根节点到叶
Ａ（Ｓ）
率只与其周边的ｎ个邻居相关，这些邻居既有可能 子节点，正确分类的条件概率为式（１１）： １９５４ 计 算 机 学 报 ２０１６年
｜ｐＳ｜ 由于ｖ Ａ（Ｓ）为节点Ｓ的邻居节点通过加法聚合
ｐ（Ｓ Ａｒｏｕｎｄ（Ｓ））＝∏ｐ（Ｈ ｊＳｖ ＡＴ （Ｓ），θ ｊＳ －１）（１１）
而成，因此关于ｖ 的梯度更新可以直接反馈到其
ｊ＝１ Ａ（Ｓ）
其中： 邻居节点向量的分布式表达上去，因此，对于ｉ∈
ｐ（Ｈ 联ｊＳ 合ｖ ＡＴ
式（Ｓ）
（１，θ ２ｊＳ
）－ 、１
（１） １＝ ）烅烄
烆
代σ
１
入（ －ｖ
σ
目ＡＴ （Ｓ
（ｖ
标）θ ＡＴｊＳ 似（Ｓ－ ）θ１ 然）
ｊＳ
函，
－１
数），
式Ｈ
Ｈ
（ｊｊ ２ＳＳ＝
＝
）中１
０
得（１２ 到） Ａｒｏｕｎｄ（Ｓ）的 ｖ每 ｉ个
·
·＝节
ｖ
ｉ点 ＋η向
ｊ｜
∑量
ｐ ＝Ｓ
１ｖ
｜
ｉ Ｏ， 其
ｖ（Ｓ
Ａ更
（Ｓ，ｊ
）新 ）梯度为式（１ （８ １８）：
）
即节点特征向量的更新梯度为式（１９）：
｜ｐＳ｜
Ｏ＝ａｒｇ ｍａｘ∑ｌｏｇ∏ｐ（Ｈ ｊＳｖ ＡＴ （Ｓ），θ ｊＳ －１） ｜ｐＳ｜
Ｓ∈Ｖ ｊ＝１ ｖ ｉ· ·＝ｖ ｉ＋η∑［Ｈ ｊＳ－σ（ｖ ＡＴ （Ｓ）θ ｊＳ －１）］·θ ｊＳ
－１
（１９）
｜ｐＳ｜ ｊ＝１
＝ａｒｇｍａｘ∑ｌｏｇ∏｛［σ（ｖ ＡＴ （Ｓ）θ ｊＳ －１）］Ｈ ｊＳ · ４．３．３ 模型小结
Ｓ∈Ｖ ｊ＝１ 通过将模型在重构的网络节点关系集上进行遍
［１－σ（ｖＴ θＳ ）］（１－Ｈ ｊＳ）｝
Ａ（Ｓ）ｊ－１ 历，对模型中的各个参数以及节点向量进行调整，
＝ａｒｇｍａｘ∑｜ ∑ｐＳ｜
｛ＨＳ·ｌｏｇ［σ（ｖＴ θＳ ）］＋
算法１给出ＬｓＮｅｔ２Ｖｅｃ模型的基本流程．
ｊ Ａ（Ｓ）ｊ－１
Ｓ∈Ｖｊ＝１ 算法１． ＬｓＮｅｔ２Ｖｅｃ模型的训练与节点向量
（１－Ｈ ｊＳ）·ｌｏｇ［１－σ（ｖ ＡＴ （Ｓ）θ ｊＳ －１）］｝ （１３） 构建．
即式（１３）为需要优化的目标函数．
输入：网络节点关系（边序列）
４．３．２ 参数估计 输出：每个节点的连续性向量表达ｖ
ｉ
由式（１３）可知，记 ＢＥＧＩＮ
Ｏ（Ｓ，ｊ）＝ＨＳ·ｌｏｇ［σ（ｖＴ θＳ ）］＋ ｔｒａｉｎｉｎｇ ｓｅｔｓ ｒｅｃｏｎｓｔｒｕｃｔｉｏｎ：Ｒａｎｄｏｍ ｗａｌｋ ｗｉｔｈ
ｊ Ａ（Ｓ）ｊ－１
（１－ＨＳ）·ｌｏｇ［１－σ（ｖＴ θＳ ）］（１４） Ｗｉｎｄｏｗ ｓｉｚｅ Ｎｉｎ ｅｄｇｅ ｌｉｓｔ，ｇｅｎｅｒａｔｅ ｔｒａｉｎｉｎｇ ｐａｉｒｓ：
ｊ Ａ（Ｓ）ｊ－１
（Ｓ，Ａｒｏｕｎｄ（Ｓ））
与文献［２４］所提出的连续词袋模型相似，针对
ｐａｒａｍｅｔｅｒｓ ｉｎｉｔｉａｌｉｚａｔｉｏｎ：Ｐａｒａｍｅｔｅｒｓθｉｎ Ｈｕｆｆｍａｎ
上述目标函数同样采用随机梯度上升进行优化，即
ｔｒｅｅ ａｎｄ ｖ ｉｉｎ Ｍａｔｒｉｘ Ｍ
每次选取一个序列化后的窗口样本（Ｓ，Ａｒｏｕｎｄ（Ｓ）），
ＦＯＲＥＡＣＨ（Ｓ，Ａｏｕｒｎｄ（Ｓ））ｉｎ ｔｒａｉｎｉｎｇ ｓｅｔｓ ＤＯ
就对目标函数的参数进行一次更新．那么，针对目标
Ｉｎｉｔｉａｌｉｚａｔｉｏｎ：ｑ＝０，ｖ（Ｓ）＝ ∑ ｖ
ｉ
函数式（１４）中存在的参数：ｖ Ａ（Ｓ）和θ ｊＳ －１做出更新 ｉ∈Ａｒｏｕｎｄ（Ｓ）
ＦＯＲＥＡＣＨ ｎｏｎ－ｌｅａｆ ｎｏｄｅ ｉｎ Ｐａｔｈ ＤＯ
即可．
Ｕｐｄａｔｅ：
因此分别对上述参数关于目标函数求偏导数，
ｑ··＝ｑ＋η［Ｈ ｊＳ－σ（ｖ ＡＴ （Ｓ）θ ｊＳ －１）］·θ ｊＳ
－１
得出参数的更新梯度：
Ｕｐｄａｔｅ：
（１）参数θ ｊＳ －１更新如式（１５）所示： θ ｊＳ －１＝θ ｊＳ －１＋η［Ｈ ｊＳ－σ（ｖ ＡＴ （Ｓ）θ ｊＳ －１）］·ｖ ＡＴ （Ｓ）
Ｏ（Ｓ，ｊ） ＥＮＤ
＝｛ＨＳ·［１－σ（ｖＴ θＳ ）］－
θ ｊＳ －１ ｊ Ａ（Ｓ）ｊ－１ ＦＯＲＥＡＣＨ ｎｏｄｅ ｉｎ Ａｒｏｕｎｄ（Ｓ）ＤＯ
（１－Ｈ ｊＳ）［σ（ｖ ＡＴ （Ｓ）θ ｊＳ －１）］｝·ｖ ＡＴ
（Ｓ）
Ｕｐｄａｔｅ：ｖ ｉ··＝ｖ ｉ＋ｑ
＝｛ＨＳ－ＨＳσ（ｖＴ θＳ ）－σ（ｖＴ θＳ ）＋ ＥＮＤ
ｊ ｊ Ａ（Ｓ）ｊ－１ Ａ（Ｓ）ｊ－１
ＥＮＤ
ＨＳσ（ｖＴ θＳ ）｝·ｖＴ
ｊ Ａ（Ｓ）ｊ－１ Ａ（Ｓ） ＥＮＤ
＝［Ｈ ｊＳ－σ（ｖ ＡＴ （Ｓ）θ ｊＳ －１）］·ｖ ＡＴ （Ｓ） （１５） ＬｓＮｅｔ２Ｖｅｃ模型采用随机梯度上升对参数进
因此，参数θ ｊＳ －１的更新梯度如式（１６）所示：
行优化，模型收敛与训练集重构的方式相关联．在
θ ｊＳ －１· ·＝θ ｊＳ －１＋η［Ｈ ｊＳ－σ（ｖ ＡＴ （Ｓ）θ ｊＳ －１）］·ｖ ＡＴ （Ｓ）（１６） ＬｓＮｅｔ２Ｖｅｃ模型中，我们通过随机初始化参数后，
式（１６）中， η用以控制学习速率． 在重构的训练集中用随机无放回选取训练对 （Ｓ，
（１）参数ｖ Ａ（Ｓ）的更新如式（１７）所示： Ａｒｏｕｎｄ（Ｓ））的方式进行参数训练，直到训练集中所
Ｏ（Ｓ，ｊ）
＝｛ＨＳ·［１－σ（ｖＴ θＳ ）］－
有训练对被随机遍历完毕后停止训练．在我们的实
ｖ ｊ Ａ（Ｓ）ｊ－１
Ａ（Ｓ） 际实验过程中，我们将ＬｓＮｅｔ２Ｖｅｃ模型的迭代隐含
（１－Ｈ ｊＳ）［σ（ｖ ＡＴ （Ｓ）θ ｊＳ －１）］｝·θ ｊＳ －１ 到训练集的重构中，即可以通过增大随机游走的次
＝｛Ｈ ｊＳ－Ｈ ｊＳσ（ｖ ＡＴ （Ｓ）θ ｊＳ －１）－σ（ｖ ＡＴ （Ｓ）θ ｊＳ －１）＋ 数或者随机游走的步长来构建更多的训练样例，以
Ｈ ｊＳσ（ｖ ＡＴ （Ｓ）θ ｊＳ －１）｝·θ ｊＳ
－１
达到模型迭代的目的．在实际实验过程中，我们对学
＝［ＨＳ－σ（ｖＴ θＳ ）］·θＳ （１７） 习速率采用的是线性降低的方式，随着数据集遍历
ｊ Ａ（Ｓ）ｊ－１ ｊ－１ １０期 李志宇等：一种大规模网络中基于节点结构特征映射的链接预测方法 １９５５
的进行，学习速率逐步降低，最后训练结束时学习速 模型的复杂度同样是较低的．
率降为０． ４．５．２ 空间复杂度分析
４．４ 节点向量与链接预测 不同于以往的链接预测的存储或计算策略，
训练得到节点结构特征的分布式表达ｖ之后， ＬｓＮｅｔ２Ｖｅｃ模型是基于内存友好的方式构建的．首
ｉ
就可以将原有网络节点拓扑结构的相似性转换为向 先，ＬｓＮｅｔ２Ｖｅｃ模型只需要存储节点的特征向量矩
量相似度计算问题了．为了降低计算复杂度，增强模 阵，即空间开销为 Ｇ ×ｍ；而对于传统的计算方
型在大规模网络中的拓展和计算能力，我们选取被 法，在计算过程中通常依赖于邻接矩阵和相似度矩
广泛采用的余弦相似度来计算不同节点之间的相似 阵的计算方式，其内存开销至少是 Ｇ × Ｇ ．对于
性，即 大规模的网络，ＬｓＮｅｔ２Ｖｅｃ模型的节点特征向量维
ｖ·ｖ 度通常设置为ｍ∈［１００，１０００］ Ｇ ，因此在训练
ＳＮ２Ｖ＝ｃｏｓ（ｖ，ｖ）＝ ｘ ｙ （２０）
ｘ，ｙ ｘ ｙ ｖ ·ｖ 时模型的空间开销远远低于以往的邻接矩阵式计算
ｘ ｙ
因此，通过训练一次得到的节点结构特征向量 方法．
后，就可以重复查询使用，结合式（２０）快速计算得到 其次，ＬｓＮｅｔ２Ｖｅｃ模型采用的是在线学习的策
大规模网络里面任意两个节点之间的结构相似度． 略，对于新增加的节点，通过在节点附近按照一定方
４．５ 算法复杂度分析与对比 法进行重新采样，可以在原有模型的基础上继续训
４．５．１ 时间复杂度分析 练，从而能够有效地适应动态的，快速增长的网络节
ＬｓＮｅｔ２Ｖｅｃ模型训练节点特征向量的复杂度 点特征学习的问题．
如式（２１）所示：
Ｔ ＝Ｎ×ｍ＋ｍ×ｌｏｇ（Ｇ ） （２１） ５ 实验与分析
Ｎ２Ｖ ２
式（２１）中，｜Ｇ｜为图中节点的数量，ｍ为节点特
征向量的维度，Ｎ为随机采样节点窗口的大小．因 ５．１ 数据集
此，在模型向量的训练阶段，ＬｓＮｅｔ２Ｖｅｃ模型训练 我们选取了公路网络、合作网络、购买共现网
的复杂度为Ｏ（ｌｏｇ（｜Ｇ｜）），相对于Ｓｈｉｎ等人［３７］提 络、社会网络、邮件通信网络、维基百科网络以及蛋
２
出的 ＭＳＬＰ算法的Ｏ（Ｇ ）时间开销要低． 白质互作用网络６个大类，共１６个数据集，其拓扑
同时，如果需要计算整个网络中所有节点之间 汇总信息如表２所示．这些数据集都属于较大规模
的相似度，则 ＬｓＮｅｔ２Ｖｅｃ模型的复杂度为Ｔ ＋ 的网络数据集，如公路网络（２７６万条边）、Ｙｏｕｔｕｂｅ
Ｎ２Ｖ
Ｏ（｜Ｇ｜２），即Ｏ（｜Ｇ｜２），因此从计算复杂度上来讲，模 社交网络（２９８万条边）等．数据主要来源于斯坦福
型的复杂度和最近邻类方法中最简单的ＣＮ算法是 大学网络分析项目组（Ｓｔａｎｆｏｒｄ Ｎｅｔｗｏｒｋ Ａｎａｌｙｓｉｓ
相同的，因此相对其他的基于路径或者全局的计算方 Ｐｒｏｊｅｃｔ，ＳＮＡＰ）①的公开网络项目，下面分别对这些
法而言，如ＲＷＲ的Ｏ（｜Ｇ｜３）的复杂度，ＬｓＮｅｔ２Ｖｅｃ 数据集的构成意义以及拓扑特性进行简要介绍．
表２ 对比数据集基本拓扑信息
类型 数据集（缩写） 点数 边数 密度 平均度 平均集聚度
Ｐｅｎｎｓｙｌｖａｎｉａ ＰＲＮ １．０９Ｅ＋０６ １．５４Ｅ＋０６ ２．６０Ｅ－０６ ２．８３４ ０．０４７
公路网络 Ｔｅｘａｓ ＴＲＮ １．３８Ｅ＋０６ １．９２Ｅ＋０６ ２．０２Ｅ－０６ ２．７８５ ０．０４７
Ｃａｌｉｆｏｒｎｉａ ＣＲＮ １．９７Ｅ＋０６ ２．７７Ｅ＋０６ １．４３Ｅ－０６ ２．８１５ ０．０４６
Ａｓｔｒｏ ＡＣＮ １．８８Ｅ＋０４ １．９８Ｅ＋０５ １．１２Ｅ－０３ ２１．１０６ ０．６３０
Ｈｉｇｈ－Ｅｎｅｒｇｙ ＨＣＮ １．２０Ｅ＋０４ １．１９Ｅ＋０５ １．６４Ｅ－０３ １９．７４０ ０．６１１
合作网络
Ｃｏｎｄｅｎｓｅ ＣＣＮ ２．３１Ｅ＋０４ １．８７Ｅ＋０５ ３．４９Ｅ－０４ ８．０８３ ０．６３３
ＤＢＬＰ ＤＣＮ ３．１７Ｅ＋０５ １．０５Ｅ＋０６ ２．０８Ｅ－０５ ６．６２２ ０．６３２
Ａｍａｚｏｎ ＡＰＮ１ ３．３５Ｅ＋０５ ９．２６Ｅ＋０５ １．６５Ｅ－０５ ５．５２９ ０．３９６
购买网络
Ａｍａｚｏｎ ＡＰＮ２ ４．０１Ｅ＋０５ ３．２０Ｅ＋０６ ２．９２Ｅ－０５ １１．７２８ ０．４０２
Ｙｏｕｔｕｂｅ ＹＳＮ １．１３Ｅ＋０６ ２．９９Ｅ＋０６ ４．６４Ｅ－０６ ５．２６５ ０．０８１
社交网络 Ｅｐｉｎｉｏｎｓ ＥＳＮ ７．５９Ｅ＋０４ ５．０９Ｅ＋０５ １．４１Ｅ－０４ １０．６９４ ０．１３７
Ｓｌａｓｈｄｏ ＳＳＮ ７．７４Ｅ＋０４ ９．０５Ｅ＋０５ １．８２Ｅ－０４ １４．１２８ ０．０５５
Ｅｎｒｏｎ ＥＥＮ ３．６７Ｅ＋０４ １．８４Ｅ＋０５ ２．７３Ｅ－０４ １０．０２０ ０．４９７
通信网络
ＥＵ ＵＥＮ ２．６５Ｅ＋０５ ４．２０Ｅ＋０５ １．０４Ｅ－０５ ２．７５７ ０．０６７
Ｔａｌｋ ｎｅｔｗｏｒｋ ＷＴＮ ２．３９Ｅ＋０６ ５．０２Ｅ＋０６ １．６３Ｅ－０６ ３．８９２ ０．０５３
维基百科
Ｖｏｔｅ ｎｅｔｗｏｒｋ ＷＶＮ ７．１２Ｅ＋０３ １．０４Ｅ＋０５ ３．９８Ｅ－０３ ２８．３２３ ０．１４１
① ｈｔｔｐ：／／ｓｎａｐ．ｓｔａｎｆｏｒｄ．ｅｄｕ １９５６ 计 算 机 学 报 ２０１６年
５．１．１ 公路网络 １８个月期间的邮件账号的来往信息，其平均集聚系
公路网络数据集主要包含３个子数据集：分别 数为０．０６７１．
是Ｐｅｎｎｓｙｌｖａｎｉａ、Ｔｅｘａｓ和Ｃａｌｉｆｏｒｎｉａ，为无向图．其 ５．１．６ 维基百科网络
中，节点代表路的交叉点或者终点，同时这些终点或 维基百科网络包含了 Ｗｉｋｉ Ｔａｌｋ和 Ｗｉｋｉ Ｖｏｔｅ
者交叉点又被不同的路所连接．在这３个数据集中， 两个数据集．Ｗｉｋｉ Ｔａｌｋ包含了约５００万条边，每条
最大的数据集为Ｃａｌｉｆｏｒｎｉａ，包含了１９６万个节点和 边表示该用户节点和其他的用户至少存在存在一次
２７６万条边，同时，３个数据集的平均集聚系数①都 沟通和交流，其平均集聚系数为０．０５２６．Ｗｉｋｉ Ｖｏｔｅ
是相似的，约为０．０４６５． 为关于维基百科中管理员选举投票的数据集，每条
５．１．２ 作者合作网络 边表示用户之间存在投票的行为，其平均集聚系数
作者合作网络主要包含３个子数据集：Ａｒｘｉｖ 为０．１４０９．
Ａｓｔｒｏ、Ｈｉｇｈ Ｅｎｅｒｇｙ、Ｃｏｎｄｅｎｓｅ Ｍａｔｔｅｒ Ｐｈｙｓｉｃｓ合作 ５．２ 度量指标
网络与ＤＢＬＰ合作网络，为无向图．这些数据集都 常用的链接预测准确度的评价指标包括ＡＵＣ
是以作者为节点，以作者之间的论文共现为边的形 （Ａｒｅａ Ｕｎｄｅｒ ｔｈｅ Ｒｅｃｅｉｖｅｒ Ｏｐｅｒａｔｉｎｇ Ｃｈａｒａｃｔｅｒｉｓｔｉｃ
成条件，即如果两个作者共同出现在一篇论文中，则 Ｃｕｒｖｅ）和Ｐｒｅｃｉｓｉｏｎ两类．其中，ＡＵＣ主要侧重在整
节点之间形成一条边，如果ｋ个作者同时出现在一 体上衡量算法的准确度，而Ｐｒｅｃｉｓｉｏｎ主要侧重在
篇论文中，则形成一个完全图，即每个节点之间两两 只评价部分链接（排序前Ｎ位）预测的准确率．和文
相连．通过统计发现，作者合作网络的平均集聚系数 献［２９，３８－３９］等模型采用的评价方法一致，我们同
都较高，约为０．６２７． 样使用ＡＵＣ作为模型的度量指标．
５．１．３ 购买共现网络 一般而言，ＡＵＣ评价指标可以理解为一个概率
购买共现网络包含两个数据集，都来自亚马逊 值，其值表示在测试集Ｅｅ中节点链接的得分比一个
网站上的商品信息，为无向图．它是根据亚马逊网站 随机选择实际上不存在的链接得分高的概率，一次
上关于“Ｃｕｓｔｏｍｅｒｓ Ｗｈｏ Ｂｏｕｇｈｔ Ｔｈｉｓ Ｉｔｅｍ Ａｌｓｏ 测试Ｔｅｓｔ的具体计算方法如下：
ｉ
Ｂｏｕｇｈｔ”的推荐信息来进行抓取的．类似的，以商品 （１）在测试集Ｅｅ中随机选出一个链接Ｅｅ，同时
ｘ
为节点，如果两个商品同时出现在一次推荐信息中， 在已知图Ｇ＝（Ｖ，Ｅ）的补图Ｇ珚中随机选择一个不存
则节点之间形成一条边．购买共现网络的平均集聚 在的链接Ｅ珚 ．
ｙ
系数相对合作者网络而言稍低，约为０．３９５．
（２）利用训练集得到的数据分别计算两条链接
５．１．４ 社会网络 的形成概率：ｐ（Ｅｅ），ｐ（Ｅ珚 ）．
ｘ ｙ
社会网络数据集包含３个子数据集：Ｙｏｕｔｕｂｅ、
（３）如果ｐ（Ｅｅ）＞ｐ（Ｅ珚），Ｔｅｓｔ＝１；或者ｐ（Ｅｅ）＝
ｘ ｙ ｉ ｘ
Ｓｌａｓｈｄｏ和Ｅｐｉｎｉｏｎｓ．Ｙｏｕｔｕｂｅ是国外的著名视频分
ｐ（Ｅ珚 ），Ｔｅｓｔ＝０．５，否则Ｔｅｓｔ＝０
ｙ ｉ ｉ
享社交网站，用户之间可以互相形成朋友关系，或者
因此，经过ｎ次上述实验后，最终ＡＵＣ的计算
构建自己的圈子，其平均集聚度系数为０．０８０８，该
方法为式（２２）：
数据包含了２９８万条边，为一个较大型的社会网络．
ｎ
Ｓｌａｓｈｄｏ是一个技术行业新闻社交网络，它允许用户 ∑Ｔｅｓｔ
ｉ
之间建立朋友或者敌人的关系，以此形成不同的社
ＡＵＣ＝ｉ＝１
ｎ
（２２）
区，其平均集聚系数为０．０５４９．Ｅｐｉｎｉｏｎｓ是一个在线 使用ＡＵＣ评价指标来衡量链接预测准确率
点评网站，它允许用户之间建立互相信任的关系，即 时，ＡＵＣ越接近于１，则算法预测效果越好．通常而
“ｗｈｏ－ｔｒｕｓｔ－ｗｈｏｍ”，其平均集聚系数为０．１２７９． 言，如果某个算法的ＡＵＣ值小于０．５，则说明该算
５．１．５ 邮件通信网络 法的效果非常差，甚至比随机的链接预测方法都差．
邮件通信网络包含了Ｅｎｒｏｎ和ＥＵ两个较为著 ５．３ 基准方法
名的数据集．Ｅｎｒｏｎ数据集包含了３万多个节点之 基准对比方法主要涉及三大类，分别是局部基
间的互相通信关系．网络中每个节点代表一个账号， 准方法（ＣＮ／ＲＡ／ＡＡ），路径基准方法（Ｋａｔｚ／ＬＰ）以
不同账号之间如果存在超过一次的邮件联系，则形 及随机游走基准方法（ＡＣＴ／ＲＷＲ）．上述方法的选
成一条边，网络的平均集聚系数为０．４９７０．ＥＵ数据
集则是由 Ｅｕｒｏｐｅａｎ ｒｅｓｅａｒｃｈ ｉｎｓｔｉｔｕｔｉｏｎ提供的在 ① ｈｔｔｐｓ：／／ｅｎ．ｗｉｋｉｐｅｄｉａ．ｏｒｇ／ｗｉｋｉ／Ｃｌｕｓｔｅｒｉｎｇ＿ｃｏｅｆｆｉｃｉｅｎｔ １０期 李志宇等：一种大规模网络中基于节点结构特征映射的链接预测方法 １９５７
取主要考虑到两个方面：（１）权威性．上述方法无论是 其中，α为可调参数，用以控制三阶邻居的贡献强
在大规模的链接预测研究，还是小规模的链接研究中 度，Ａ为网络的邻接矩阵，（Ａｎ） ｘ，ｙ为节点（ｘ，ｙ）之间
都被公认为较好的参照方法；（２）有效性．上述方法在 路径长度为ｎ的路径数．
已有文献的众多对比实验中都能够在特定的数据集 ５．３．６ 基于平均通勤时间的相似度计算（ＡＣＴ）
上取得最佳ＡＵＣ值，因此适合作为模型可扩展性检 平均通勤时间（Ａｖｅｒａｇｅ Ｃｏｍｍｕｔｅ Ｔｉｍｅ，ＡＣＴ）
验的标准参照方法．下面，将对上述方法作简单阐述． 指的是一个随机粒子从节点ｘ到达节点ｙ平均需
５．３．１ 基于共同邻居的相似度计算（ＣＮ） 要走的步数ｍ（ｘ，ｙ），此时，节点ｘ和节点ｙ的平均
在网络分析算法中，节点共同邻居的相似度计 通勤时间定义为式（２８）：
算方法是最简单的基于局部信息的相似性定义方 ｎ（ｘ，ｙ）＝ｍ（ｘ，ｙ）＋ｍ（ｙ，ｘ） （２８）
法［４０］．该算法基于的假设是两个节点的公共节点数 其数值求解可以参考文献［１１］．
越多，则它们之间的稳定性越强，由此相似性也就越 ５．３．７ 基于重启随机游走的相似度计算（ＲＷＲ）
高．因此在链接预测的问题中，两个节点共同邻居节 基于重启随机游走（Ｒａｎｄｏｍ ｗａｌｋ ｒｅｓｔａｒｔ）的相
点数越多，则两者之间存在相互链接的可能性越大． 似度计算方法是目前连接预测的较好方法之一，在
ＣＮ算法中，节点的相似性计算方法如式（２３）所示： 一些常见的网络数据集中都取得了最佳的ＡＵＣ
ＳＣＮ＝ Ｎ（ｘ）∩Ｎ（ｙ） （２３） 值［１１］，该方法可看作是ＰａｇｅＲａｎｋ算法的拓展，被广
ｘ，ｙ
５．３．２ 基于资源分配算法的相似度计算（ＲＡ） 泛的用于信息检索的各个领域［３５］．其假设是：在网
如相关工作一节所述，资源分配的相似度计算 络中进行随机游走时，粒子每走一步都会以一定的
方法主要是以资源的重新分配为基本思路．ＲＡ算
概率返回初始位置［４２］．假设粒子的返回概率为
法对于每个媒介的传递资源以１／Ｋ的形式递减．其
１－ｐ，Ｐ为网络的马尔可夫概率转移矩阵，其元素
相似度的计算方法如式（２４）所示： Ｐ ｘ，ｙ＝ａ ｘ，ｙ／ｋ ｘ表示节点ｘ处的粒子下一步走到节点
１
ｙ的概率．在网络中如果ｘ和ｙ相连，则ａ ｘ，ｙ＝１；否
ＳＲＡ＝ ∑ （２４）
ｘ，ｙ ｋ（Ｚ） 则ａ ＝０，而ｋ则为节点ｘ的度 Ｅ（ｘ）．
Ｚ∈Ｎ（ｘ）∩Ｎ（ｙ） ｘ，ｙ ｘ
５．３．３ 基于Ａｄａｍｉｃ－Ａｄａｒ算法的相似度计算（ＡＡ） 如果某一初始时刻粒子在节点ｘ处，则ｔ＋１时
ＡＡ算法［４１］同时考虑了两个共同节点度的信 刻粒子到达网络中各个节点的概率向量为
息，核心思想是提高度小的共同邻居节点的贡献值． ｑ（ｔ＋１）＝ｃＰＴｑ（ｔ）＋（１－ｃ）ｅ （２９）
ｘ ｘ ｘ
例如在商品共现问题中，两个共同用户同时购买了 式（２９）中，ｅ为初始状态，由此可得稳定解为
ｘ
冷门商品的相似性往往比同时购买热门商品的用户 式（３０）：
更相似．ＡＡ算法通过共同邻居节点的度为每个节 ｑ＝（１－ｃ）（Ｉ－ｃＰＴ）－１ｅ （３０）
ｘ ｘ
点赋予一个权重值，该权重值等于节点度的对数分 因此，元素ｑ ｘ，ｙ表示从节点ｘ出发的粒子最终
之一，其计算定义为式（２５）： 以多少的概率走到节点ｙ，由此得到ＲＷＲ的相似
１
性计算方法如式（３１）所示：
ＳＡＡ＝ ∑ （２５）
ｘ，ｙ Ｚ∈Ｎ（ｘ）∩Ｎ（ｙ）ｌｏｇｋ（Ｚ） Ｓ ｘＲ ，Ｗ ｙＲ＝ｑ ｘ，ｙ＋ｑ
ｙ，ｘ
（３１）
５．３．４ 基于Ｋａｔｚ方法的相似度计算（ＫＡ） ５．４ 有效性验证
Ｋａｔｚ方法考虑节点（ｘ，ｙ）之间所有的路径数， ５．４．１ 实验环境
且对于较短的路径赋予叫大的权重，而较长的路径 实验系统平台为Ｍａｃ ＯＳ Ｘ Ｙｏｓｅｍｉｔｅ １０．１０．５，
赋予较小的权重，它的计算方法如式（２６）所示： 同时，为了提高对比的基准链路预测算法的矩阵计
Ｓ ｘＫａ ，ｙｔｚ＝βＡ＋β２ Ａ２＋β３ Ａ３…＝（Ｉ－βＡ）－１－Ｉ（２６） 算效率，这部分程序采用 Ｍａｔｌａｂ ２０１４ｂ实现，而
其中， β为权重衰减因子，通常为了保证数列的收敛性， ＬｓＮｅｔ２Ｖｅｃ模型则采用Ｐｙｔｈｏｎ ２．７实现，同时启用
β的取值必须小于邻接矩阵Ａ最大特征值的倒数． ＧＰＵ并行计算．实验仪器的硬件性能为 ２．５ＧＨｚ
５．３．５ 基于局部路径的相似性计算（ＬＰ） Ｉｎｔｅｌ ｉ７四核八线程处理器，内存为１６ＧＢ，ＧＰＵ为
局部路径（Ｌｏｃａｌ Ｐａｔｈ）计算是在ＣＮ方法的基础
ＮＶｉｄｉａ ＧｅＦｏｒｃｅ ＧＴ７５０ ２ＧＢ．
上进一步考虑三阶邻居的贡献，其计算方法如式（２７） ５．４．２ ＡＵＣ对比
所示： 我们将ＬｓＮｅｔ２Ｖｅｃ模型在各个数据集上进行了
Ｓ ｘＬＰ ，ｙ＝Ａ２＋αＡ３ （２７） ５０次的随机重复实验，通过ＡＵＣ值，验证ＬｓＮｅｔ２Ｖｅｃ １９５８ 计 算 机 学 报 ２０１６年
模型用以大规模网络链接预测问题的有效性．如 取得的平均值，其中ＬｓＮｅｔ２Ｖｅｃ的ＡＵＣ值为在不
表３所示，为各个算法在所有数据集上重复实验所 同超参选择下的对应平均最优值．
表３ 各方法在各个数据集上的ＡＵＣ值对比
Ｄａｔａｓｅｔ Ｎ２Ｖ ＣＮ ＡＡ ＲＡ ＫＡ．０１ ＬＰ．０００１ ＡＣＴ ＲＷＲ
ＷＶＮ ０．９５２３ ０．９４０６ ０．９４２４ ０．９６１２ ０．３８０２ ０．９７６１ ０．８９７７ ０．９６７１

ＨＣＮ ０．９８５２ ０．９８２３ ０．９８３２ ０．９８４１ ０．４７８６ ０．９８５０ ０．９６６０ ０．９８８０

ＡＣＮ ０．９９０８ ０．９３３５ ０．９３４９ ０．９３５９ ０．９７４１ ０．９７２８ ０．９４０９ ０．９７５９

ＣＣＮ ０．９８８０ ０．９２１８ ０．９２２９ ０．９２２８ ０．９６９９ ０．９５５６ ０．９２４１ ０．９５８３

ＥＥＮ ０．９７９４ ０．８９７７ ０．９０５５ ０．９０４７ ０．９５７８ ０．９５４１ ０．９４２１ ０．９５６１

ＥＳＮ ０．９２２０ ０．６７７５ ０．６９９４ ０．６９７４ ０．９２５４ ０．８９３６ ０．９０４０ ０．９１５０

ＳＳＮ ０．９０３３ ０．５７００ ０．５７４４ ０．５７５２ ０．８９９３ ０．８９６９ ０．９００４ ０．９４４１

ＵＥＮ ０．９７８５ ０．５７６５ ０．５７６４ ０．５７８４ ０．８８９５ ０．６９７３ ０．８２６５ ０．８２５８

ＤＣＮ ０．９８４７ ０．８１６０ ０．８１８７ ０．８１７８ ０．９６９６ ０．９５２７ ０．９５８６ ０．９５４３

ＡＰＮ１ ０．９７２４ ０．８３４１ ０．８３４８ ０．８３５０ ０．９１８２ ０．９０７９ ０．９０５２ ０．９００３

ＡＰＮ２ ０．９９４５ ０．７２３６ ０．７４５９ ０．７４５９ ０．８４４４ ０．８５６１ ０．９２３０ ０．９１４１

ＰＲＮ ０．９５５４ ０．５６２０ ０．５６１７ ０．５６１７ ０．９１３０ ０．７０９７ ０．９０７２ ０．９００３

ＹＳＮ ０．８７１７ ０．６２５４ ０．７０３５ ０．７０２１ ０．７５０９ ０．８００１ ０．８５５９ ０．８４８４

ＴＲＮ ０．９４９８ ０．５６５３ ０．５６５４ ０．５６５３ ０．９０１７ ０．６８９９ ０．９０１６ ０．８９０２

ＣＲＮ ０．９６３５ ０．５７３９ ０．５７３６ ０．５７３７ ０．９１２２ ０．７０１６ ０．８９９８ ０．９０１８

ＷＴＮ ０．８２５９ ０．５１６０ ０．４９４８ ０．５３８４ ０．７９８５ ０．８０１３ ０．８１２５ ０．８２４６

注：加粗波浪下划线为最大值，直下划线为次大．
值得注意的是，通过我们的初步实验，在大规模 ＲＡ算法的计算过程能够从根本上解释资源传递和
的真实数据集上，无论是对物理内存的需求还是算 节点之间的非线性关系，这种计算方式在节点的平
法的时间开销，现有基准对照方法根本无法直接在 均度较高的网络中效果更为明显，如ＡＣＮ和 ＷＶＮ
我们现有的实验硬件条件下进行相似性计算用以链 网络．
接预测．因此，除了ＬｓＮｅｔ２Ｖｅｃ模型是直接在上述 在基于路径信息的相似性计算方法中 （６／７
大规模网络数据集的全集上进行进行训练和计算 列），ＫＡ（０．０１）算法的表现最为突出，其在多个数据
外，其他对照方法都只能采用社区抽样来完成评估． 集上取得了次优于ＬｓＮｅｔ２Ｖｅｃ模型的结果，甚至在
为了有效和科学地获取现有基准方法在各个数据集 数据集ＥＳＮ上取得了最优．相对于ＣＮ类算法而
上的表现，我们通过在每个大规模网络中分别按深 言，ＫＡ和ＬＰ算法由于引入了高阶邻居的贡献，使
度优先和广度优先各进行１００次社团随机抽样，从 得原来很多在低阶环境下无法被区分的相似节点在
而得到随机选取的若干小型社团（每个社团１０ ０００ 高阶环境中变得可分，因此相对于直接的近邻算法
个左右的节点）；然后，在每个抽样得到的社团上进行 （ＣＮ类）而言其相似性的匹配性能普遍要好．虽然，
１０次重复实验；最后，计算每个算法在２×１００×１０ 用过引入高阶邻居的贡献能够在一定程度上提升算
次实验上取均值，作为该方法在数据集上的表现． 法的预测效果，但同时这也带来了一个重要的负面
由表３中的（３／４／５列）实验结果可以发现，在 影响，即ＫＡ算法的计算复杂度以及时间开销都是
以节点邻居的局部信息为参照的计算方法中，共同 非常大的，而ＬＰ算法次之，因此从本质上来讲，这
邻居类的相似性计算方法（ＣＮ／ＡＡ／ＲＡ）对于网络 类算法并不适用于大规模网络中的链接预测或节点
结构的密度或者平均集聚度系数特征要求较高，这三 的相似度计算等问题．
类算法的预测效果随着网络的密度或平均集聚系数 在随机游走类的算法中（８／９列），基于重启随
的下降而变得非常不理想，例如 ＡＡ算法在 ＷＴＮ 机游走的相似性计算方法ＲＷＲ表现最为突出，甚
数据集中０．４９４８的ＡＵＣ值甚至还不如以０．５０００ 至在ＨＣＮ和ＳＳＮ数据集上取得了最优的成绩，同
为基准的随机猜测方法好．然而，还应该注意到的 时取得了３个第二的预测效果．此外，ＡＣＴ算法也
是：在高密度的网络，如 ＣＣＮ、ＡＣＮ、ＨＣＮ 以及 取得了３个第二的对比效果．但在实验中我们发现，
ＷＶＮ网络中，ＣＮ、ＡＡ和ＲＡ算法也同样也获得了 虽然通过对数据集进行了社团采样，将数据量降为
非常高的ＡＵＣ值，这与文献［３４］等结论一致．同 原来的０．０１倍甚至０．００１倍，ＲＷＲ和 ＡＣＴ算法
时，对于ＣＮ、ＡＡ以及ＲＡ的对比而言，资源分配算 相对于其他算法而言仍然较为耗时．由于ＲＷＲ和
法（ＲＡ）相对于其他两种算法而言更好，原因在于 ＡＣＴ算法的计算复杂度都是Ｏ（ｎ３），因此在大规模 １０期 李志宇等：一种大规模网络中基于节点结构特征映射的链接预测方法 １９５９
的数据集中，其计算效率已变得十分低下． 大大降低后续应用的计算复杂度，例如计算节点
通过对比发现，ＬｓＮｅｔ２Ｖｅｃ虽然在ＤＣＮ、ＹＳＮ 相似度时，只用计算任意两个节点向量的余弦相似
和 ＷＴＮ数据集上并没有十分明显的ＡＵＣ提升，但 性即可．同时，在ＬｓＮｅｔ２Ｖｅｃ模型的训练过程中，我
由于现有的计算方法在这些数据集上的计算开销十 们在每个节点上选取了较为简单的二分类，结合
分庞大．从而使得从根本上来看，现有的方法在这些 Ｈｕｆｆｍａｎ树进行存储后，利用随机梯度上升算法进
数据集上是无法进行不同节点之间的相似性计算 行寻优，有效降低了计算的复杂度．最后由于使用了
的，因此在大规模网络结构中，现有的计算方法具有 在线的随机梯度上升算法，因此可以增量式地处理
很大的局限性．通过进一步分析发现：ＬｓＮｅｔ２Ｖｅｃ 新增的节点数据，而不必重新训练，大大地节约了模
模型在ＵＥＮ、ＡＰＮ１、ＡＰＮ２、ＰＲＮ、ＴＲＮ和ＣＲＮ数 型的训练时间．
据集上相对现有算法而言有较大的性能提升，分别 ５．５ 超参讨论
高于次优方法８．９％、５．４２％、７．１５％、４．２４％、４．８１％ ＬｓＮｅｔ２Ｖｅｃ模型中包含了节点向量维度Ｖ－Ｓｉｚｅ、
和５．１３％．但是在ＥＳＮ，ＳＳＮ两个社会网络类的数 随机游走步长 ＭＡＸ＿ＬＥＮＧＴＨ、随机游走次数
据集以及两个小型数据集ＷＶＮ，ＨＣＮ中，ＬｓＮｅｔ２Ｖｅｃ ＷＡＬＫ＿ＴＩＭＥＳ以及预测窗口Ｗｉｎｄｏｗ－Ｓｉｚｅ Ｎ这
模型取得的效果并不十分理想．特别是在ＳＳＮ网络 ４个超参．本节将通过实验，探讨上述超参的选取
中，低于现有方法４．０８％，其原因是在 ＷＶＮ，ＨＣＮ 对于ＬｓＮｅｔ２Ｖｅｃ模型用以链接预测问题性能好坏
数据集中，不同节点之间的关系非常的紧密，网络的 的影响方式，并给出ＬｓＮｅｔ２Ｖｅｃ模型在该问题中超
稀疏性不高，同时节点的平均度却非常高，使得基于 参选取的建议．在下文超参讨论中，我们采用控制
多阶共现的ＬｓＮｅｔ２Ｖｅｃ模型并不能有效地识别不 变量的方法，取基准超参为ＭＡＸ＿ＬＥＮＧＴＨ＝５０；
同节点之间的相似性与差异性．而在ＥＳＮ，ＳＳＮ这 ＷＡＬＫ＿ＴＩＭＥＳ＝１．０×Ｎｏｄｅ＿ｎｕｍｂｅｒ；Ｖ－Ｓｉｚｅ＝
样的社会关系网络数据集中，由于节点之间的不同 １００；Ｗｉｎｄｏｗ－Ｓｉｚｅ＝６；当讨论某一个超参时，其他
阶影响差异较大，但是在ＬｓＮｅｔ２Ｖｅｃ模型中却被平 超参以上述基准超参为准，不进行变更．
等看待，因此效果稍弱．但总的来说，相比于现有的 ５．５．１ 节点特征向量维度
链接预测方法，ＬｓＮｅｔ２Ｖｅｃ模型在众多种类的数据 选取在初始探索性实验中ＡＵＣ值因向量维度
集中都取得了不错的结果． 变动幅度较大的数据集进行进一步的对比实验．将
５．４．３ ＬｓＮｅｔ２Ｖｅｃ性能解释 特征向量维度变更范围设置为［５０，３００］，同时每次
本节主要对ＬｓＮｅｔ２Ｖｅｃ模型取得相应效果的 增加２５维进行一次ＡＵＣ评测实验，实验结果如
原因进行分析．主要包括两个方面： 图６所示．
（１）预测效果较好的原因．如模型推理部分所
述，ＬｓＮｅｔ２Ｖｅｃ模型主要基于被预测节点的邻居节
点的结构特征综合来表达自身的结构特征．通过在
网络中进行随机游走获得重构的序列化数据集后，
针对特定窗口Ｎ大小的序列进行采样训练，因此对
于一个节点而言，其结构特征理论上由其Ｎ阶邻居
共同确定，这一点和 ＫＡ方法以及ＬＰ方法有一定
的相似性．换句话说，一个节点的特征向量既由自身
Ｎ阶邻居节点来估计，也被用于其Ｎ阶邻居节点特
征向量的估计中．
（２）计算复杂度相对较低的原因．从本质上说：
ＬｓＮｅｔ２Ｖｅｃ模型可以看作是对原始网络节点结构
特征的一种降维算法．在特征的存储结构上，
图６ 节点特征向量维度与ＡＵＣ关系
ＬｓＮｅｔ２Ｖｅｃ模型和现有的网络计算中基于邻接矩阵
通过对比实验发现，向量维度对网络链接预测
的存储方式不同，ＬｓＮｅｔ２Ｖｅｃ模型对节点的结构特
的影响方式可以分为两种：对于网络密度较大的数
征采用固定维度的向量进行存储，通常只有２０～
１０００维．通过训练得到节点结构特征向量后，能够
据集，随着节点特征向量维度的增加，ＡＵＣ值逐步 １９６０ 计 算 机 学 报 ２０１６年
下降，并且在同等变化区域内，密度越大，ＡＵＣ值下
降越快．对于网络密度较小的数据集，随着节点特征
向量维度的增加，ＡＵＣ值逐步上升，同时，在同等变
化区域内，网络密度越小，ＡＵＣ值上升越快．
因此，节点特征向量维度参数的选取需要和网
络拓扑结构相适应．对于密度较小的网络（一般这类
网络通常也具备较大的节点数），其节点的结构特征
分布较为分散，需要用更多的向量维度去获取不同
分散特征（节点）之间的相似性与差异性．而对于密
度较大的网络，节点相对集中，如果采用过多的向量
维度去衡量节点结构特征的相似性，那么则会减少
具有重要区分度的特征权重，从而给链接预测带来
不准确性．
５．５．２ 序列化随机游走步长与随机游走次数
随机游走步长 ＭＡＸ＿ＬＥＮＧＴＨ 和预测窗口
Ｗｉｎｄｏｗ－Ｓｉｚｅ Ｎ之间存在一个基本范围限制，通常
需要满足
ＭＡＸ＿ＬＥＮＧＴＨＷｉｎｄｏｗ－Ｓｉｚｅ，
否则，在进行序列采样训练时，无法满足采样要求．因
此我们选取ＭＡＸ＿ＬＥＮＧＴＨ变化区间为［２０，１００］，
以１０为步长进行递增，重复实验得到稳定结果后如
图７所示．
从图７（ａ）中可以发现，ＭＡＸ＿ＬＥＮＧＴＨ的变
更对数据集链接预测ＡＵＣ值的影响幅度（极差）是
随着网络节点平均度／网络密度的降低而增加：当网
络较为稀疏时，通过增加随机游走的步长能够有效地
提升系统的预测性能．当网络相对密集时，通过增加
随机游走步长，并不能十分明显的提升预测效率．同
时，我们发现，对于固定的预测窗口Ｗｉｎｄｏｗ－Ｓｉｚｅ＝
Ｎ的参数而言，通过变更随机游走步长，ＡＵＣ极差
的跳跃点发生在平均度约为Ｎ／２的数据集处．如
图７（ｂ）所示，当数据集的平均度小于Ｎ／２＝３的时
候，通过在区间［２０，１００］变更步长所产生的极差首
先迅速下降，然后趋于平稳．同样，网络密度对极差
的影响也是相似的，如图７（ｃ）所示．
因此，随机游走的步长选取应结合网络的平均
图７ 随机游走步长与ＡＵＣ关系
度（Ａｖｅ＿ｄｅｇｒｅｅ）以及预测窗口Ｗｉｎｄｏｗ－Ｓｉｚｅ＝Ｎ
整并不会对ＡＵＣ值造成太大的提升，如果再进行
来进行设定：
大范围的实验，会增加计算开销与复杂度．
当Ａｖｅ＿ｄｅｇｒｅｅ≈Ｎ／２时，可以通过大范围的实
随机游走次数ＷＡＬＫ＿ＴＩＭＥＳ主要影响模型
验来调整随机游走步长来获取较大的ＡＵＣ变更
训练的充分性以及时间开销．从本质来说，ＷＡＬＫ＿
信息．
当Ａｖｅ＿ｄｅｇｒｅｅＮ／２或Ａｖｅ＿ｄｅｇｒｅｅＮ／２
ＴＩＭＥＳ和ＭＡＸ＿ＬＥＮＧＴＨ 存在一个均衡关系，
时，建议选取和网络直径相似的随机游走步长来进
当ＭＡＸ＿ＬＥＮＧＴＨ 增加时，可以通过适当减少
行小范围的调整实验，因为此时随机游走步长的调
ＷＡＬＫ＿ＴＩＭＥＳ来保证ＡＵＣ不变的同时减少训练 １０期 李志宇等：一种大规模网络中基于节点结构特征映射的链接预测方法 １９６１
的复杂度．同样，当ＭＡＸ＿ＬＥＮＧＴＨ固定时，可以 的热点问题之一．现有的链接预测方法主要针对特
通过增加ＷＡＬＫ＿ＴＩＭＥＳ来提升一定的ＡＵＣ值， 定的网络结构进行详细的分析和设计，从而使得预
一般的：当ＷＡＬＫ＿ＴＩＭＥＳ大于网络中的边数时， 测方法变得较为复杂，因此难以适应越来越庞大的
这种提升并不明显，限于篇幅，关于ＷＡＬＫ＿ＴＩＭＥＳ 网络结构．本文针对大规模网络链接预测问题中存
的影响不再详细讨论． 在的网络特征稀疏性和计算复杂度高的情况，提出
５．５．３ 预测窗口（Ｗｉｎｄｏｗ－Ｓｉｚｅ Ｎ） 了基于网络结构特征降维的ＬｓＮｅｔ２Ｖｅｃ模型．
预测窗口反映了被预测节点的结构环境信息， 首先，通过对网络中节点特征的概率拟合，以节
当预测窗口为Ｎ时，其环境邻居最多可达Ｎ阶．通 点的环境特征为输入，节点自身特征为输出，无监督
过将预测窗口控制在［４，１１］，按照步长１进行重复 学习得到了网络中节点特征的分布式表达．然后，通
实验，得到如图８所示关系．图中实验数据集几乎都
过学习得到的固定低维度特征向量就可以直接而
是先上升后下降，同时出现了相应的极值点．
又快速地计算出大规模网络中任意节点之间的相
似度．最后，基于大规模真实数据集的实验表明，
ＬｓＮｅｔ２Ｖｅｃ模型在大规模网络上具备可计算性以及
相对较优的预测性能，并在多个数据集上对以往的
链接预测方法有了很大的提升．
当然，ＬｓＮｅｔ２Ｖｅｃ模型也存在一定的不足，主
要表现在以下两点：（１）ＬｓＮｅｔ２Ｖｅｃ模型在节点环
境向量的构建过程中并没有考虑不同阶邻居所带来
的不同影响，而是将它们统一看待，削弱了近邻的影
响；（２）ＬｓＮｅｔ２Ｖｅｃ模型对于特殊网络（例如，高密
度或集聚度网络）的适应性不足，如在 ＷＴＮ网络中
预测的ＡＵＣ值只有８２．５６％．
图８ 预测窗口与ＡＵＣ关系
后续的可能研究思路主要包括研究节点特征环
对于ＬｓＮｅｔ２Ｖｅｃ模型而言，扩大环境窗口并不
境的不同构造方法，如增加权重衰减等；研究不同类
会增加太多的计算量（固定维度的向量加减运算）．
型网络的节点结构（或边结构）特征的分布式表达问
因此，理论上利用的全局信息越多，越有利于模型的
题，例如带权网络节点／边结构特征的分布式表达，
预测．但在本文ＬｓＮｅｔ２Ｖｅｃ模型中，我们采用的是
多重网络的节点结构特征的分布式表达等；研究不
对窗口范围内的环境向量直接加和的形式（式（７））
同网络（异质网络）结构特征的统一表达问题，以此
获得环境特征向量，即不存在相对位置差异，也不存
探索跨平台网络中不同节点结构特征的相似性匹配
在权重的变化，从而导致一阶邻居和二阶邻居和Ｎ
问题．
阶邻居的贡献相同．当窗口较小时，这些邻居的结构
贡献对于预测节点是相似的，增加到二阶，三阶等将
参 考 文 献
有利于提供更多的信息．但当预测窗口超出一定范
围，就会使得本来的一阶邻居和Ｎ阶邻居的贡献大
［１］ Ｚｈｏｕ Ｔ，Ｌｕ Ｌ，Ｚｈａｎｇ Ｙ－Ｃ．Ｐｒｅｄｉｃｔｉｎｇ ｍｉｓｓｉｎｇ ｌｉｎｋｓ ｖｉａ ｌｏｃａｌ
不相同的情况在ＬｓＮｅｔ２Ｖｅｃ模型中成为相似的（这
ｉｎｆｏｒｍａｔｉｏｎ．Ｔｈｅ Ｅｕｒｏｐｅａｎ Ｐｈｙｓｉｃａｌ Ｊｏｕｒｎａｌ Ｂ，２００９，７１（４）：
是不合理的），因此反而使得ＬｓＮｅｔ２Ｖｅｃ模型的预
６２３－６３０
测准确性下降．针对这个问题，我们将在后续的研究
［２］ Ｎａｒａｎｇ Ｋ，Ｌｅｒｍａｎ Ｋ，Ｋｕｍａｒａｇｕｒｕ Ｐ．Ｎｅｔｗｏｒｋ ｆｌｏｗｓ ａｎｄ
中进一步改进：通过引入环境向量的贡献衰减函数， ｔｈｅ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｐｒｏｂｌｅｍ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ７ｔｈ Ｗｏｒｋｓｈｏｐ
针对不阶的邻居给予不同的结构贡献权重，进一步 ｏｎ Ｓｏｃｉａｌ Ｎｅｔｗｏｒｋ Ｍｉｎｉｎｇ ａｎｄ Ａｎａｌｙｓｉｓ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，
优化预测模型． ２０１３：１－８
［３］ Ｌｅｉ Ｃ，Ｒｕａｎ Ｊ．Ａ ｎｏｖｅｌ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ａｌｇｏｒｉｔｈｍ ｆｏｒ ｒｅｃｏｎ－
６ 结论与下一步研究
ｓｔｒｕｃｔｉｎｇ ｐｒｏｔｅｉｎ－ｐｒｏｔｅｉｎ ｉｎｔｅｒａｃｔｉｏｎ ｎｅｔｗｏｒｋｓ ｂｙ ｔｏｐｏｌｏｇｉｃａｌ
ｓｉｍｉｌａｒｉｔｙ．Ｂｉｏｉｎｆｏｒｍａｔｉｃｓ，２０１３，２９（３）：３５５－３６４
［４］ Ｄｕ Ｎ，Ｇａｏ Ｊ，Ｚｈａｎｇ Ａ，ｅｔ ａｌ．Ｄｅ－ｎｏｉｓｅ ｂｉｏｌｏｇｉｃａｌ ｎｅｔｗｏｒｋ
网络链接预测是复杂网络分析和数据挖掘领域 ｆｒｏｍ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｓｏｕｒｃｅｓ ｖｉａ ｌｉｎｋ ｐｒｏｐａｇａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ １９６２ 计 算 机 学 报 ２０１６年
ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｂｉｏｉｎｆｏｒｍａｔｉｃｓ ａｎｄ ［１８］ Ｂｅｎｇｉｏ Ｙ，Ｄｕｃｈａｒｍｅ Ｒ，Ｖｉｎｃｅｎｔ Ｐ，ｅｔ ａｌ．Ａ ｎｅｕｒａｌ ｐｒｏｂａｂｉｌｉｓｔｉｃ
Ｂｉｏｍｅｄｉｃｉｎｅ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１２：１－６ ｌａｎｇｕａｇｅ ｍｏｄｅｌ．Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，
［５］ Ｂｒａｎｄｏ Ｍ Ａ，Ｍｏｒｏ Ｍ Ｍ，Ｌｏｐｅｓ Ｇ Ｒ，ｅｔ ａｌ．Ｕｓｉｎｇ ｌｉｎｋ ２００３，３：１１３７－１１５５
ｓｅｍａｎｔｉｃｓ ｔｏ ｒｅｃｏｍｍｅｎｄ ｃｏｌｌａｂｏｒａｔｉｏｎｓ ｉｎ ａｃａｄｅｍｉｃ ｓｏｃｉａｌ ［１９］ Ｍｉｋｏｌｏｖ Ｔ，Ｚｗｅｉｇ Ｇ．Ｃｏｎｔｅｘｔ ｄｅｐｅｎｄｅｎｔ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ
ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２２ｎｄ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｎｅｔｗｏｒｋ ｌａｎｇｕａｇｅ ｍｏｄｅｌ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｗｏｒｋｓｈｏｐ
ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｒｉｏ ｄｅ ｊａｎｅｉｒｏ，Ｂｒａｚｉｌ，２０１３：８３３－８４０ ｏｎ Ｓｐｏｋｅｎ Ｌａｎｇｕａｇｅ Ｔｅｃｈｎｏｌｏｇｉｅｓ．Ｍｉａｍｉ，ＵＳＡ，２０１２：
［６］ Ｙｕ Ｑ，Ｌｏｎｇ Ｃ，Ｌｖ Ｙ，ｅｔ ａｌ．Ｐｒｅｄｉｃｔｉｎｇ ｃｏ－ａｕｔｈｏｒ ｒｅｌａｔｉｏｎ－ ２３４－２３９
ｓｈｉｐ ｉｎ ｍｅｄｉｃａｌ ｃｏ－ａｕｔｈｏｒｓｈｉｐ ｎｅｔｗｏｒｋｓ．ＰＬｏＳ ＯＮＥ，２０１４， ［２０］ Ｈｕａｎｇ Ｅ Ｈ，Ｓｏｃｈｅｒ Ｒ，Ｍａｎｎｉｎｇ Ｃ Ｄ，ｅｔ ａｌ．Ｉｍｐｒｏｖｉｎｇ ｗｏｒｄ
９（７）：ｅ１０１２１４ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｖｉａ ｇｌｏｂａｌ ｃｏｎｔｅｘｔ ａｎｄ ｍｕｌｔｉｐｌｅ ｗｏｒｄ ｐｒｏｔｏｔｙｐｅｓ
［７］ Ｌｉｂｅｎ－Ｎｏｗｅｌｌ Ｄ，Ｋｌｅｉｎｂｅｒｇ Ｊ Ｍ．Ｔｈｅ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｐｒｏｂｌｅｍ ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ５０ｔｈ Ａｎｎｕａｌ Ｍｅｅｔｉｎｇ ｏｆ ｔｈｅ Ａｓｓｏｃｉａｔｉｏｎ
ｆｏｒ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ．Ｊｏｕｒｎａｌ ｏｆ ｔｈｅ Ａｍｅｒｉｃａｎ Ｓｏｃｉｅｔｙ ｆｏｒ ｆｏｒ Ｃｏｍｐｕｔａｔｉｏｎａｌ Ｌｉｎｇｕｉｓｔｉｃｓ．Ｐｉｔｔｓｂｕｒｇｈ，ＵＳＡ，２０１２：８７３－
Ｉｎｆｏｒｍａｔｉｏｎ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，２００７，５８（７）：１０１９－１０３１ ８８２
［８］ Ｔｙｌｅｎｄａ Ｔ，Ａｎｇｅｌｏｖａ Ｒ，Ｂｅｄａｔｈｕｒ Ｓ．Ｔｏｗａｒｄｓ ｔｉｍｅ－ａｗａｒｅ ［２１］ Ｓｏｃｈｅｒ Ｒ，Ｐｅｒｅｌｙｇｉｎ Ａ，Ｗｕ Ｊ Ｙ，ｅｔ ａｌ．Ｒｅｃｕｒｓｉｖｅ ｄｅｅｐ ｍｏｄ－
ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｉｎ ｅｖｏｌｖｉｎｇ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｅｌｓ ｆｏｒ ｓｅｍａｎｔｉｃ ｃｏｍｐｏｓｉｔｉｏｎａｌｉｔｙ ｏｖｅｒ ａ ｓｅｎｔｉｍｅｎｔ ｔｒｅｅｂａｎｋ／／
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｅｍｐｉｒｉｃａｌ Ｍｅｔｈｏｄｓ ｉｎ Ｎａｔｕｒａｌ
ｔｈｅ ３ｒｄ Ｗｏｒｋｓｈｏｐ ｏｎ Ｓｏｃｉａｌ Ｎｅｔｗｏｒｋ Ｍｉｎｉｎｇ ａｎｄ Ａｎａｌｙｓｉｓ．
Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２００９：１－１０ Ｌａｎｇｕａｇｅ Ｐｒｏｃｅｓｓｉｎｇ．Ｓｅａｔｔｌｅ，ＵＳＡ，２０１３：１６３１－１６４２
［２２］ Ｒｏｔｈ Ｍ，Ｗｏｏｄｓｅｎｄ Ｋ．Ｃｏｍｐｏｓｉｔｉｏｎ ｏｆ ｗｏｒｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ
［９］ Ｇｕｎｓ Ｒ，Ｒｏｕｓｓｅａｕ Ｒ．Ｒｅｃｏｍｍｅｎｄｉｎｇ ｒｅｓｅａｒｃｈ ｃｏｌｌａｂｏｒａｔｉｏｎｓ
ｉｍｐｒｏｖｅｓ ｓｅｍａｎｔｉｃ ｒｏｌｅ ｌａｂｅｌｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｃｏｎｆｅｒｅｎｃｅ
ｕｓｉｎｇ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ａｎｄ ｒａｎｄｏｍ ｆｏｒｅｓｔ ｃｌａｓｓｉｆｉｅｒｓ．Ｓｃｉｅｎｔｏ－
ｏｎ Ｅｍｐｉｒｉｃａｌ Ｍｅｔｈｏｄｓ ｉｎ Ｎａｔｕｒａｌ Ｌａｎｇｕａｇｅ Ｐｒｏｃｅｓｓｉｎｇ．Ｄｏｈａ，
ｍｅｔｒｉｃｓ，２０１４，１０１（２）：１４６１－１４７３
Ｑａｔａｒ，２０１４：４０７－４１３
［１０］ Ｆｉｒｅ Ｍ，Ｔｅｎｅｎｂｏｉｍ Ｌ，Ｌｅｓｓｅｒ Ｏ，ｅｔ ａｌ．Ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｉｎ
［２３］ Ｂｅｎｇｉｏ Ｙ，Ｓｃｈｗｅｎｋ Ｈ，Ｓｅｎéｃａｌ Ｊ－Ｓ，ｅｔ ａｌ．Ｎｅｕｒａｌ ｐｒｏｂａｂｉｌｉｓｔｉｃ
ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ ｕｓｉｎｇ ｃｏｍｐｕｔａｔｉｏｎａｌｌｙ ｅｆｆｉｃｉｅｎｔ ｔｏｐｏｌｏｇｉｃａｌ
ｌａｎｇｕａｇｅ ｍｏｄｅｌｓ／／Ｈｏｌｍｅｓ Ｄ Ｅ，Ｊａｉｎ Ｌ Ｃ ｅｄｓ．Ｉｎｎｏｖａｔｉｏｎｓ ｉｎ
ｆｅａｔｕｒｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｔｈｉｒｄ Ｉｎｔｅｒｎａｔｉｏｎａｌ
Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｓｐｒｉｎｇｅｒ Ｂｅｒｌｉｎ Ｈｅｉｄｅｌｂｅｒｇ，２００６：１３７－
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｓｏｃｉａｌ Ｃｏｍｐｕｔｉｎｇ ａｎｄ ２０１１ＩＥＥＥ Ｔｈｉｒｄ
１８６
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｐｒｉｖａｃｙ，Ｓｅｃｕｒｉｔｙ，Ｒｉｓｋ ａｎｄ
［２４］ Ｍｉｋｏｌｏｖ Ｔ，Ｃｈｅｎ Ｋ，Ｃｏｒｒａｄｏ Ｇ，ｅｔ ａｌ．Ｅｆｆｉｃｉｅｎｔ Ｅｓｔｉｍａｔｉｏｎ
Ｔｒｕｓｔ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１１：７３－８０
ｏｆ Ｗｏｒｄ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｉｎ Ｖｅｃｔｏｒ Ｓｐａｃｅ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ，
［１１］ ＬüＬｉｎ－Ｙｕａｎ．Ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｏｎ ｃｏｍｐｌｅｘ ｎｅｔｗｏｒｋｓ．Ｊｏｕｒｎａｌ
２０１３，ｃｓ．ＣＬ：１－１２
ｏｆ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｅｌｅｃｔｒｏｎｉｃ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ ｏｆ Ｃｈｉｎａ，
［２５］ Ｌｉｂｅｎ－Ｎｏｗｅｌｌ Ｄ，Ｋｌｅｉｎｂｅｒｇ Ｊ Ｍ．Ｔｈｅ ｌｉｎｋ－ｐｒｅｄｉｃｔｉｏｎ ｐｒｏｂｌｅｍ
２０１０，３９（５）：６５４－６６１（ｉｎ Ｃｈｉｎｅｓｅ）
ｆｏｒ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ．Ｊｏｕｒｎａｌ ｏｆ ｔｈｅ Ａｍｅｒｉｃａｎ Ｓｏｃｉｅｔｙ ｆｏｒ
（吕琳媛．复杂网络链路预测．电子科技大学学报，２０１０，
Ｉｎｆｏｒｍａｔｉｏｎ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，２００７，５８（７）：１０１９－１０３１
３９（５）：６５４－６６１）
［２６］ Ｌｉｕ Ｄ，Ｗａｎｇ Ｙ，Ｊｉａ Ｙ，ｅｔ ａｌ．ＬＳＤＨ：Ａ ｈａｓｈｉｎｇ ａｐｐｒｏａｃｈ
［１２］ ＬüＬ，Ｚｈｏｕ Ｔ．Ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｉｎ ｃｏｍｐｌｅｘ ｎｅｔｗｏｒｋｓ：Ａ ｓｕｒｖｅｙ．
ｆｏｒ ｌａｒｇｅ－ｓｃａｌｅ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｉｎ ｍｉｃｒｏｂｌｏｇｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
Ｐｈｙｓｉｃａ Ａ：Ｓｔａｔｉｓｔｉｃａｌ Ｍｅｃｈａｎｉｃｓ ａｎｄ Ｉｔｓ Ａｐｐｌｉｃａｔｉｏｎｓ，２０１１，
ｔｈｅ ２８ｔｈ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．
３９０（６）：１１５０－１１７０
Ｑｕéｂｅｃ，Ｃａｎａｄａ，２０１４：３１２０－３１２１
［１３］ Ｚｈａｎｇ Ｊ，Ｙｕ Ｐ Ｓ，Ｚｈｏｕ Ｚ－Ｈ．Ｍｅｔａ－ｐａｔｈ ｂａｓｅｄ ｍｕｌｔｉ－ｎｅｔｗｏｒｋ ［２７］ ＬüＬ，Ｊｉｎ Ｃ－Ｈ，Ｚｈｏｕ Ｔ．Ｓｉｍｉｌａｒｉｔｙ ｉｎｄｅｘ ｂａｓｅｄ ｏｎ ｌｏｃａｌ
ｃｏｌｌｅｃｔｉｖｅ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０ｔｈ Ｉｎｔｅｒｎａ－
ｐａｔｈｓ ｆｏｒ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｏｆ ｃｏｍｐｌｅｘ ｎｅｔｗｏｒｋｓ．Ｐｈｙｓｉｃａｌ
ｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ． Ｒｅｖｉｅｗ Ｅ，２００９，８０（４）：０４６１２２
Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１４：１２８６－１２９５ ［２８］ Ｌｉｃｈｔｅｎｗａｌｔｅｒ Ｒ Ｎ，Ｌｕｓｓｉｅｒ Ｊ Ｔ，Ｃｈａｗｌａ Ｎ Ｖ．Ｎｅｗ ｐｅｒｓｐｅｃ－
［１４］ Ｔｈｉ Ｄ Ｂ，Ｉｃｈｉｓｅ Ｒ，Ｌｅ Ｂ．Ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｉｎ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ ｔｉｖｅｓ ａｎｄ ｍｅｔｈｏｄｓ ｉｎ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １６ｔｈ
ｂａｓｅｄ ｏｎ ｌｏｃａｌ ｗｅｉｇｈｔｅｄ ｐａｔｈｓ／／Ｄａｎｇ Ｔ Ｋ，Ｗａｇｎｅｒ Ｒ，
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ
Ｎｅｕｈｏｌｄ Ｅ ｅｔ ａｌ，ｅｄｓ．Ｆｕｔｕｒｅ Ｄａｔａ ａｎｄ Ｓｅｃｕｒｉｔｙ Ｅｎｇｉｎｅｅｒｉｎｇ． Ｍｉｎｉｎｇ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１０：２４３－２５２
Ｓｗｉｔｚｅｒｌａｎｄ：Ｓｐｒｉｎｇｅｒ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｐｕｂｌｉｓｈｉｎｇ，２０１４：１５１－ ［２９］ Ｈｕａｎｇ Ｌｉ－Ｗｅｉ，Ｌｉ Ｄｅ－Ｙｉ，Ｍａ Ｙｕ－Ｔａｏ，ｅｔ ａｌ．Ａ ｍｅｔａ ｐａｔｈ－
１６３
ｂａｓｅｄ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｍｏｄｅｌ ｆｏｒ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｉｎｆｏｒｍａｔｉｏｎ
［１５］ Ｌｉｕ Ｗ，ＬüＬ．Ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｂａｓｅｄ ｏｎ ｌｏｃａｌ ｒａｎｄｏｍ ｗａｌｋ． ｎｅｔｗｏｒｋｓ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１４，３７（４）：８４８－
Ｅｕｒｏｐｈｙｓｉｃｓ Ｌｅｔｔｅｒｓ，２０１０，８９（５）：５８００７ ８５８（ｉｎ Ｃｈｉｎｅｓｅ）
［１６］Ｊｉｎ Ｔ，Ｘｕ Ｔ，Ｃｈｅｎ Ｅ，ｅｔ ａｌ．Ｒａｎｄｏｍ ｗａｌｋ ｗｉｔｈ ｐｒｅ－ｆｉｌｔｅｒｉｎｇ （黄立威，李德毅，马于涛等．一种基于元路径的异质信息网
ｆｏｒ ｓｏｃｉａｌ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ９ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ 络链路预测模型．计算机学报，２０１４，３７（４）：８４８－８５８）
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔａｔｉｏｎａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ ａｎｄ Ｓｅｃｕｒｉｔｙ． ［３０］ Ｌｉｕ Ｙｅ，Ｚｈｕ Ｗｅｉ－Ｈｅｎｇ，Ｐａｎ Ｙａｎ，ｅｔ ａｌ．Ｍｕｌｔｉｐｌｅ ｓｏｕｒｃｅｓ
Ｌｅｓｈａｎ，Ｃｈｉｎａ，２０１３：１３９－１４３ ｆｕｓｉｏｎ ｆｏｒ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｖｉａ ｌｏｗ－ｒａｎｋ ａｎｄ ｓｐａｒｓｅ ｍａｔｒｉｘ ｄｅｃｏｍ－
［１７］ ＬｅＣｕｎ Ｙ，Ｂｅｎｇｉｏ Ｙ，Ｈｉｎｔｏｎ Ｇ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ．Ｎａｔｕｒｅ， ｐｏｓｉｔｉｏｎ．Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ，
２０１５，５２１（７５５３）：４３６－４４４ ２０１５，５２（２）：４２３－４３６（ｉｎ Ｃｈｉｎｅｓｅ） １０期 李志宇等：一种大规模网络中基于节点结构特征映射的链接预测方法 １９６３
（刘冶，朱蔚恒，潘炎等．基于低秩和稀疏矩阵分解的多源融 ｐｒｅｄｉｃｔｉｏｎ ｆｏｒ ｌａｒｇｅ ｓｃａｌｅ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
合链接预测算法．计算机研究与发展，２０１５，５２（２）：４２３－４３６） ２３ｒｄ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｓｅｏｕｌ，
［３１］ Ｗｕ Ｚｕ－Ｆｅｎｇ，Ｌｉａｎｇ Ｑｉ，Ｌｉｕ Ｑｉａｏ，ｅｔ ａｌ．Ｍｏｄｉｆｉｅｄ ｌｉｎｋ Ｋｏｒｅａ，２０１４：１３２７－１３３２
ｐｒｅｄｉｃｔｉｏｎ ａｌｇｏｒｉｔｈｍ ｂａｓｅｄ ｏｎ ＡｄａＢｏｏｓｔ．Ｊｏｕｒｎａｌ ｏｎ Ｃｏｍｍｕ－ ［３７］ Ｓｈｉｎ Ｄ，Ｓｉ Ｓ，Ｄｈｉｌｌｏｎ Ｉ Ｓ．Ｍｕｌｔｉ－ｓｃａｌｅ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ／／
ｎｉｃａｔｉｏｎｓ，２０１４，３５（３）：１１６－１２３（ｉｎ Ｃｈｉｎｅｓｅ） Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２１ｓｔ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
（吴祖峰，梁棋，刘峤等．基于ＡｄａＢｏｏｓｔ的链路预测优化算 Ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ Ｋｎｏｗｌｅｄｇｅ Ｍａｎａｇｅｍｅｎｔ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，
法．通信学报，２０１４，３５（３）：１１６－１２３） ２０１２：２１５－２２４
［３２］ Ｌｉ Ｙｕ－Ｈｕａ，Ｘｉａｏ Ｈａｉ－Ｌｉｎｇ，Ｌｉ Ｄｏｎｇ－Ｃａｉ，ｅｔ ａｌ．Ｒｅｓｅａｒｃｈ ｏｆ ［３８］ Ｒｉｃｈａｒｄ Ｅ，Ｇａｉｆｆａｓ Ｓ，Ｖａｙａｔｉｓ Ｎ．Ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｉｎ ｇｒａｐｈｓ
ｄｙｎａｍｉｃ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｍｅｔｈｏｄ ｂａｓｅｄ ｏｎ ｌｉｎｋ ｉｍｐｏｒｔａｎｃｅ． ｗｉｔｈ ａｕｔｏｒｅｇｒｅｓｓｉｖｅ ｆｅａｔｕｒｅｓ．Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ
Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ，２０１１，４８（Ｓ３）： Ｒｅｓｅａｒｃｈ，２０１４，１５（１）：５６５－５９３
４０－４６（ｉｎ Ｃｈｉｎｅｓｅ） ［３９］ Ｃｈｅｎ Ｚ，Ｃｈｅｎ Ｍ，Ｗｅｉｎｂｅｒｇｅｒ Ｋ Ｑ，ｅｔ ａｌ．Ｍａｒｇｉｎａｌｉｚｅｄ
（李玉华，肖海岭，李栋才等．基于链接重要性的动态链接预 ｄｅ－ｎｏｉｓｉｎｇ ｆｏｒ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ａｎｄ ｍｕｌｔｉ－ｌａｂｅｌ ｌｅａｒｎｉｎｇ／／
测方法研究．计算机研究与发展，２０１１，４８（Ｓ３）：４０－４６） Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２９ｔｈ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ
［３３］ Ｐｕｊａｒｉ Ｍ，Ｋａｎａｗａｔｉ Ｒ．Ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｉｎ ｍｕｌｔｉｐｌｅｘ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ａｕｓｔｉｎ，ＵＳＡ，２０１５：１７０７－１７１３
ｎｅｔｗｏｒｋｓ．Ｎｅｔｗｏｒｋｓ ａｎｄ Ｈｅｔｅｒｏｇｅｎｅｏｕｓ Ｍｅｄｉａ，２０１５，１０（１）： ［４０］ Ｌｏｒｒａｉｎ Ｆ，Ｗｈｉｔｅ Ｈ Ｃ．Ｓｔｒｕｃｔｕｒａｌ ｅｑｕｉｖａｌｅｎｃｅ ｏｆ ｉｎｄｉｖｉｄｕａｌｓ
１７－３５ ｉｎ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ．Ｔｈｅ Ｊｏｕｒｎａｌ ｏｆ Ｍａｔｈｅｍａｔｉｃａｌ Ｓｏｃｉｏｌｏｇｙ，
［３４］ Ｈｅ Ｙ Ｌ，Ｌｉｕ Ｊ Ｎ Ｋ，Ｈｕ Ｙ Ｘ，ｅｔ ａｌ．ＯＷＡ ｏｐｅｒａｔｏｒ ｂａｓｅｄ １９７１，１（１）：４９－８０
ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｅｎｓｅｍｂｌｅ ｆｏｒ ｓｏｃｉａｌ ｎｅｔｗｏｒｋ．Ｅｘｐｅｒｔ Ｓｙｓｔｅｍｓ ［４１］ Ａｄａｍｉｃ Ｌ Ａ，Ａｄａｒ Ｅ．Ｆｒｉｅｎｄｓ ａｎｄ ｎｅｉｇｈｂｏｒｓ ｏｎ ｔｈｅ Ｗｅｂ．
ｗｉｔｈ Ａｐｐｌｉｃａｔｉｏｎｓ，２０１５，４２（１）：２１－５０ Ｓｏｃｉａｌ Ｎｅｔｗｏｒｋｓ，２００３，２５（３）：２１１－２３０
［３５］ Ｌｖ Ｂ，Ｙｕ Ｗ，Ｗａｎｇ Ｌ，ｅｔ ａｌ．Ｅｆｆｉｃｉｅｎｔ ｐｒｏｃｅｓｓｉｎｇ ｎｏｄｅ ［４２］ Ｆｏｕｓｓ Ｆ，Ｐｉｒｏｔｔｅ Ａ，Ｒｅｎｄｅｒｓ Ｊ－Ｍ，ｅｔ ａｌ．Ｒａｎｄｏｍ－ｗａｌｋ
ｐｒｏｘｉｍｉｔｙ ｖｉａ ｒａｎｄｏｍ ｗａｌｋ ｗｉｔｈ ｒｅｓｔａｒｔ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ｃｏｍｐｕｔａｔｉｏｎ ｏｆ ｓｉｍｉｌａｒｉｔｉｅｓ ｂｅｔｗｅｅｎ ｎｏｄｅｓ ｏｆ ａ ｇｒａｐｈ ｗｉｔｈ
１６ｔｈ Ａｓｉａ－Ｐａｃｉｆｉｃ Ｗｅｂ Ｃｏｎｆｅｒｅｎｃｅ．Ｃｈａｎｇｓｈａ，Ｃｈｉｎａ，２０１４： ａｐｐｌｉｃａｔｉｏｎ ｔｏ ｃｏｌｌａｂｏｒａｔｉｖｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．ＩＥＥＥ Ｔｒａｎｓａｃ－
５４２－５４９ ｔｉｏｎｓ ｏｎ Ｋｎｏｗｌｅｄｇｅ ａｎｄ Ｄａｔａ Ｅｎｇｉｎｅｅｒｉｎｇ，２００７，１９（３）：
［３６］ Ｏｇａｔａ Ｈ，Ｓｕｚｕｍｕｒａ Ｔ．Ｔｏｗａｒｄｓ ｓｃａｌａｂｌｅ Ｘ１０ｂａｓｅｄ ｌｉｎｋ ３５５－３６９
ＬＩ Ｚｈｉ－Ｙｕ，ｂｏｒｎ ｉｎ １９９１，Ｐｈ．Ｄ． ｓｕｐｐｏｒｔ ｖｅｃｔｏｒ ｍａｃｈｉｎｅ ａｎｄ ｓｏｃｉａｌ ｃｏｍｐｕｔｉｎｇ．
ｃａｎｄｉｄａｔｅ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ＺＨＯＵ Ｘｉａｏ－Ｐｉｎｇ，ｂｏｒｎ ｉｎ １９８５，Ｐｈ．Ｄ．ｃａｎｄｉｄａｔｅ．Ｈｉｓ
ｓｏｃｉａｌ ｃｏｍｐｕｔｉｎｇ，ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ． ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ Ｗｅｂ ｄａｔａ ｍｉｎｉｎｇ ａｎｄ ｓｏｃｉａｌ ｃｏｍｐｕｔｉｎｇ．
ＺＨＡＮＧ Ｈａｉ－Ｙａｎ，ｂｏｒｎ ｉｎ １９７５，Ｐｈ．Ｄ．ｃａｎｄｉｄａｔｅ．Ｈｅｒ
ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｃｏｍｐｌｅｘ ｎｅｔｗｏｒｋｓ，ｓｏｃｉａｌ ｃｏｍｐｕｔｉｎｇ
ａｎｄ ｒｅｃｏｍｍｅｎｄ ｓｙｓｔｅｍｓ．
ＭＡ Ｙｕｅ－Ｆｅｎｇ，ｂｏｒｎ ｉｎ １９７６，Ｐｈ．Ｄ．ｃａｎｄｉｄａｔｅ．Ｈｉｓ ｒｅｓｅａｒｃｈ
ＬＩＡＮＧ Ｘｕｎ，ｂｏｒｎ ｉｎ １９６５，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ，Ｐｈ．Ｄ． ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｄａｔａ ｍｉｎｉｎｇ，ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ａｎｄ ｐａｔｔｅｒｎ
ｓｕｐｅｒｖｉｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ， ｒｅｃｏｇｎｉｔｉｏｎ．
Ｂａｃｋｇｒｏｕｎｄ
Ｓｉｎｃｅ ｃｏｍｐｌｅｘ ｎｅｔｗｏｒｋｓ ａｒｅ ｌｉｋｅｌｙ ｔｏ ｐｌａｙ ａｎ ｅｓｓｅｎｔｉａｌ ｄｅｓｉｇｎｅｄ ｂａｓｅｄ ｏｎ ｔｈｅ ａｓｓｕｍｐｔｉｏｎ ｏｆ ｎｏｄｅ ｓｉｍｉｌａｒｉｔｙ，ｗｈｉｃｈ
ｒｏｌｅ ｉｎ ｄａｔａ ｍｉｎｉｎｇ ｒｅｓｅａｒｃｈ ａｒｅａｓ，ｗｈｉｃｈ ｍａｋｅ ｔｈｅ ｐｒｏｂｌｅｍ ｄｅｆｉｎｅｄ ｂｙ ｕｓｉｎｇ ｔｈｅ ｅｓｓｅｎｔｉａｌ ｆｅａｔｕｒｅｓ ｏｆ ｎｏｄｅｓ．Ｔｈｏｓｅ
ｏｆ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｉｎ ｃｏｍｐｌｅｘ ｎｅｔｗｏｒｋｓ ａｌｓｏ ａｔｔｒａｃｔｅｄ ｍｕｃｈ ｆｅａｔｕｒｅｓ ｃａｎ ｂｅ ｓｔｒｕｃｔｕｒａｌ ｏｒ ｃｏｎｔｅｘｔｕａｌ，ｗｈｉｃｈ ｍｅａｎｓ ｔｈａｔ
ａｔｔｅｎｔｉｏｎ ｒｅｃｅｎｔｌｙ．Ｔｈｅ ｐｒｏｂｌｅｍ ｏｆ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｃａｎ ｂｅ ｔｗｏ ｎｏｄｅｓ ａｒｅ ｃｏｎｓｉｄｅｒｅｄ ｔｏ ｂｅ ｓｉｍｉｌａｒ ｉｆ ｔｈｅｙ ｈａｖｅ ｍａｎｙ
ｃａｔｅｇｏｒｉｚｅｄ ｉｎｔｏ ｔｗｏ ｃｌａｓｓｅｓ，ｎａｍｅｌｙ，ｍｉｓｓｉｎｇ ｌｉｎｋｓ ｐｒｅｄｉｃｔｉｏｎ ｃｏｍｍｏｎ ｆｅａｔｕｒｅｓ．
ａｎｄ ｆｕｔｕｒｅ ｌｉｎｋｓ ｐｒｅｄｉｃｔｉｏｎ．Ｍｉｓｓｉｎｇ ｌｉｎｋｓ ｐｒｅｄｉｃｔｉｏｎ ｉｓ ｔｈｅ Ｔｈｅ ｏｂｊｅｃｔｉｖｅ ｏｆ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｉｓ ｔｏ ｅｓｔｉｍａｔｅ ｔｈｅ ｌｉｋｅｌｉ－
ｐｒｅｄｉｃｔｉｏｎ ｏｆ ｕｎｋｎｏｗｎ ｌｉｎｋｓ ｉｎ ｓａｍｐｌｉｎｇ ｎｅｔｗｏｒｋｓ；ａｎｄ ｔｈｅ ｈｏｏｄ ｔｈａｔ ａ ｌｉｎｋ ｅｘｉｓｔｓ ｂｅｔｗｅｅｎ ｔｗｏ ｎｏｄｅｓ，ｍａｋｉｎｇ ｔｈｅ
ｏｔｈｅｒ ｉｓ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ ｏｆ ｌｉｎｋｓ ｔｈａｔ ｍａｙ ｅｘｉｓｔ ｉｎ ｔｈｅ ｆｕｔｕｒｅ ｏｆ ｓｐａｒｓｉｔｙ ａｎｄ ｈｕｇｅ ｓｉｚｅ ｏｆ ｎｅｔｗｏｒｋｓ ｂｅｃｏｍｅ ｔｗｏ ｏｆ ｔｈｅ ｍａｉｎ
ｅｖｏｌｖｉｎｇ ｃｏｍｐｌｅｘ ｎｅｔｗｏｒｋｓ．Ｂｏｔｈ ｍｉｓｓｉｎｇ ａｎｄ ｆｕｔｕｒｅ ｌｉｎｋｓ ｃｈａｌｌｅｎｇｅｓ ｒｅｍａｉｎ ｉｎ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｐｒｏｂｌｅｍｓ．Ａｌｔｈｏｕｇｈ
ｐｒｅｄｉｃｔｉｏｎ ａｒｅ ｃｏｎｓｉｄｅｒｅｄ ｉｍｐｏｒｔａｎｔ ｓｕｂｔａｓｋｓ ｉｎ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ． ｔｈｅｒｅ ａｒｅ ｍａｎｙ ｓｉｍｉｌａｒｉｔｙ－ｂａｓｅｄ ａｌｇｏｒｉｔｈｍｓ，ｓｕｃｈ ａｓ Ｃｏｍｍｏｎ
Ｕｎｔｉｌ ｎｏｗ，ｍｏｓｔ ｏｆ ｔｈｅ ｍｅｔｈｏｄｓ ｆｏｒ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ａｒｅ Ｎｅｉｇｈｂｏｒ（ＣＮ）ａｌｇｏｒｉｔｈｍ，Ｋａｔｚ ａｌｇｏｒｉｔｈｍ，Ｌｏｃａｌ Ｐａｔｈ（ＬＰ） １９６４ 计 算 机 学 报 ２０１６年
ａｌｇｏｒｉｔｈｍ，Ｒａｎｄｏｍ Ｗａｌｋ Ｒｅｓｔａｒｔ（ＲＷＲ）ａｌｇｏｒｉｔｈｍ ｅｔｃ．， Ｐｒｏｊｅｃｔ．Ｔｈｅｎ，ｗｅ ｐｒｅｓｅｎｔ ａ ｃｏｎｔｒｏｌｌｅｄ ｃｏｍｐａｒｉｓｏｎ ｏｆ ｔｈｅ
ｗｈｉｃｈ ｈａｖｅ ｂｅｅｎ ｐｒｏｐｏｓｅｄ ｔｏ ｈａｎｄｌｅ ｔｈｉｓ ｅｓｓｅｎｔｉａｌ ｐｒｏｂｌｅｍ ｉｎ ＬｓＮｅｔ２Ｖｅｃ ｍｏｄｅｌ ａｇａｉｎｓｔ ｓｅｖｅｒａｌ ｓｔｒｏｎｇ ｂａｓｅｌｉｎｅ ｌｉｎｋ
ｔｈｅ ｓｍａｌｌ ｃｏｍｐｌｅｘ ｎｅｔｗｏｒｋｓ，ｔｈｅ ｅｍｐｉｒｉｃａｌ ｏｂｓｅｒｖａｔｉｏｎｓ ｓｈｏｗ ｐｒｅｄｉｃｔｉｏｎ ｍｅｔｈｏｄｓ ｏｎ ａ ｆｉｘｅｄ ｄａｔａｓｅｔ，ｗｉｔｈ ＡＵＣ ｔｅｓｔｉｎｇ．
ｔｈａｔ ｔｈｅ ｓｔａｂｉｌｉｔｙ ａｎｄ ｕｓａｂｉｌｉｔｙ ｉｎ ｌａｒｇｅ－ｓｃａｌｅ ｎｅｔｗｏｒｋｓ ｏｆ Ｒｅｓｕｌｔ ｓｈｏｗｅｄ ｔｈａｔ ｔｈｅ ＬｓＮｅｔ２Ｖｅｃ ｍｏｄｅｌ ｐｅｒｆｏｒｍｓ ｃｏｍｐａｒａｂｌｙ
ｅｘｉｓｔｉｎｇ ａｌｇｏｒｉｔｈｍｓ ｉｓ ｕｓｕａｌｌｙ ｖｅｒｙ ｌｏｗ，ｗｈｉｃｈ ｍｅａｎｓ，ｆｏｒ ａ ｗｉｔｈ ｓｔａｔｅ－ｏｆ－ｔｈｅ－ａｒｔ ｍｅｔｈｏｄｓ，ａｎｄ ｃｏｎｓｉｓｔｅｎｔｌｙ ｏｕｔｐｅｒｆｏｒｍｓ
ｌａｒｇｅ ｎｅｔｗｏｒｋ ｗｉｔｈ ｍｉｌｌｉｏｎｓ ｏｆ ｎｏｄｅｓ，ｔｈｉｓ ｎｕｍｂｅｒ ｃａｎ ｅａｓｉｌｙ ｍｏｄｅｌｓ，ｓｕｃｈ ａｓ Ｋａｔｚ ａｎｄ ＲＷＲ ｅｔｃ．，ｉｎ ｖａｒｉｏｕｓ ｅｘｐｅｒｉｍｅｎｔ
ｄｏｕｂｌｅ ｏｒ ｔｒｉｐｌｅ，ｍａｋｉｎｇ ｌｅａｒｎｉｎｇ ａｎｄ ｐｒｅｄｉｃｔｉｎｇ ｏｆ ｕｎｋｎｏｗｎ ｓｅｔｔｉｎｇｓ．
ｌｉｎｋｓ ｖｅｒｙ ｅｘｐｅｎｓｉｖｅ． Ｔｈｉｓ ｗｏｒｋ ｉｓ ｐａｒｔｌｙ ｓｕｐｐｏｒｔｅｄ ｂｙ ｔｈｅ Ｎａｔｉｏｎａｌ Ｎａｔｕｒａｌ
Ｉｎ ｔｈｉｓ ｗｏｒｋ，ｗｅ ｄｅｓｃｒｉｂｅ ｈｅｒｅ ａ ｎｅｗ ａｐｐｒｏａｃｈ ｔｏ ｐｒｅｄｉｃｔ Ｓｃｉｅｎｃｅ Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｃｈｉｎａ （Ｇｒａｎｔ Ｎｏｓ．７１２７１２１１ａｎｄ
ｕｎｋｎｏｗｎ ｌｉｎｋｓ ｉｎ ｌａｒｇｅ－ｓｃａｌｅ ｎｅｔｗｏｒｋｓ ａｃｃｏｒｄｉｎｇ ｔｏ ｔｈｅ ７１５３１０１２），ｔｈｅ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｂｅｉｊｉｎｇ（Ｇｒａｎｔ
ｕｎｓｕｐｅｒｖｉｓｅｄ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ．Ｔｈｅ ｍａｉｎ ｉｄｅａ ｏｆ ｏｕｒ ｍｅｔｈｏｄ Ｎｏ．４１３２０６７），ｔｈｅ Ｆｕｎｄａｍｅｎｔａｌ Ｒｅｓｅａｒｃｈ Ｆｕｎｄｓ ｆｏｒ ｔｈｅ
ｉｓ ｍａｐｐｉｎｇ ｔｈｅ ｆｅａｔｕｒｅｓ ｏｆ ｎｏｄｅ ｉｎ ｌａｒｇｅ－ｓｃａｌｅ ｎｅｔｗｏｒｋｓ ｉｎｔｏ ａ Ｃｅｎｔｒａｌ Ｕｎｉｖｅｒｓｉｔｉｅｓ（ｔｈｅ Ｒｅｓｅａｒｃｈ Ｆｕｎｄｓ ｏｆ Ｒｅｎｍｉｎ Ｕｎｉｖｅｒｓｉｔｙ
ｌｏｗｅｒ ａｎｄ ｆｉｘｅｄ ｄｉｍｅｎｓｉｏｎ ｏｆ ｖｅｃｔｏｒ ｉｎ ｔｈｅ ｓｅｔ ｏｆ ｒｅａｌ ｎｕｍｂｅｒｓ． ｏｆ Ｃｈｉｎａ，Ｇｒａｎｔ Ｎｏ．１０ＸＮＩ０２９），ｔｈｅ Ｏｕｔｓｔａｎｄｉｎｇ Ｉｎｎｏｖａｔｉｖｅ
Ｗｅ ｃｏｎｄｕｃｔ ｅｘｔｅｎｓｉｖｅ ｅｘｐｅｒｉｍｅｎｔａｌ ａｎａｌｙｓｉｓ ｏｎ ｓｉｘｔｅｅｎ Ｔａｌｅｎｔｓ Ｃｕｌｔｉｖａｔｉｏｎ Ｆｕｎｄｅｄ Ｐｒｏｇｒａｍｓ ２０１５ ｏｆ Ｒｅｎｍｉｎ
ｆａｍｏｕｓ ｄａｔａｓｅｔｓ，ｗｈｉｃｈ ｐｒｏｖｉｄｅｄ Ｓｔａｎｆｏｒｄ Ｎｅｔｗｏｒｋ Ａｎａｌｙｓｉｓ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｃｈｉｎａ． --------------------------------------------------------------------------------- 第33卷第3期 计 算 机 应 用 研 究 Vol.33 No.3
2016年3月 Application Ｒesearch of Computers Mar． 2016
*
一种用于微博谣言检测的半监督学习算法
路同强1，2，石 冰1，闫中敏1，周 珮1
(1．山东大学 计算机科学与技术学院，济南250101; 2．中国人民解放军61516部队，北京100094)
摘 要: 在微博谣言检测中，对微博谣言进行正确标注需要耗费大量的人力和时间，同时数据类别的不平衡也
影响了微博谣言的正确识别。为了解决该问题，提出一种基于Co-Forest算法针对不平衡数据集的改进方法，利
用SMOTE算法和分层抽样平衡数据分布，并通过代价敏感的加权投票法来提高对未标记样本预测的正确率。
该方法只需要对少量训练数据实例进行谣言类别标注即可有效检测谣言。10 组UCI测试数据和2 组微博谣言
的实证实验证明了算法有效性。
关键词: 微博; 谣言检测; 不平衡数据; 半监督学习; Co-Forest算法; SMOTE; 代价敏感
中图分类号: TP181; TP301.6 文献标志码: A 文章编号: 1001-3695(2016)03-0744-05
doi:10．3969/j．issn．1001-3695．2016．03．024
Semi-supervised learning algorithm applied to microblog rumors detection
Lu Tongqiang1，2，Shi Bing1，Yan Zhongmin1，Zhou Pei1
(1．SchoolofComputerScience＆Technology，ShandongUniversity，Jinan250101，China; 2．Troop61516，PLA，Beijing100094，China)
Abstract: In microblog rumor detection，labeling microblog rumors correctly requires a huge amount of manpower and time．
At the same time，imbalanced data category also affects the correct recognition of microblog rumors． To resolve thisproblem，
this paper proposed an improved method based on Co-Forest algorithm，which could be used for imbalanced dataset． This
method used SMOTE algorithm and stratified sampling tobalancethedata'sdistribution． Besides，itimprovedthecorrectrate
of unlabeled sample through the cost-sensitive weighted voting method． This method required only a small amount of training
data instances which labeled a rumor category，and could be used to detect rumors effectively． Experiment results on10 UCI
data sets and2 microblog rumors prove that the algorithm is effective．
Key words: microblog; rumor detection; imbalanced data; semi-supervised learning; Co-Forest algorithm; SMOTE; cost
sensitive
练样本集的成本。
0 引言
半监督学习是利用未标记示例的主流学习技术之一，可大
谣言检测属于互联网信息可信度［1］研究范畴，是互联网
大减小数据标注的高昂代价。Li等人［13］在Co-training基础上
信息可信度研究的新方向。国外学者对社交网络和微博尤其
提出一种不需要充分冗余属性子集的半监督学习算法Co-For-
是Twitter可信度作了大量的研究［2～9］。其研究工作首先从 est，能使用大量的未标注数据迭代优化在标注数据上学得的
Twitter上抓取数据，去除与特定事件话题无关的tweets作为样 假设，在实际应用( 计算机辅助诊断) 中取得了良好效果。微
本数据;接着选取tweets文本内容包含的元素统计特征( 如标 博中谣言的数量远少于非谣言，同时准确识别谣言比识别非谣
签个数、链接个数等)或者浅层的内容信息( 如情感词个数、名 言价值更高，因此本文认为微博谣言检测是一个不平衡数据的
词个数等)作为特征，辅以用户信息和传播特征等，运用分类 二分类问题。但由于Co-Forest算法采用传统的随机森林( ran-
(如nave Bayes、support vector machine、decision tree等)［2～6］或 dom forest)算法来保证各分类器之间的差异性，使得Co-Forest
排序［7，8］的方法对微博信息可信度进行评估。国内学 算法在不平衡数据集上不能较好地识别少数类，不能直接应用
者［10～12］对微博谣言检测的研究与国外学者基本相似。这些 到微博谣言检测中。
研究基本上采用基于监督学习的方法，均需要训练数据被正 本文综合考虑上述几方面的问题，提出一种基于Co-Forest
确地标注; 同时，为了提高分类的精度，需要训练样本足够 算法针对不平衡数据集的改进方法———ImCo-Forest 算法
大，需要耗费大量的人力和时间。然而在微博平台中存在着 (semi-supervised learning algorithm from imbalanced data based
海量数据，并且每天都会产生大量的数据。以目前国内最广 on Co-Forest)，利用SMOTE算法和分层抽样平衡数据分布，并
泛使用的新浪微博为例，其每天发布的内容就超过了1 亿 通过引入代价因子来提高对未标记样本预测的正确率。实验
条，对这些海量数据进行内容真伪的判别并正确地标注是一 表明，该方法在处理类别不平衡分类问题时较 Co-Forest算法
项艰巨的任务，需要耗费大量的人力和时间，这也增加了训 优越，能有效提升少数类样本的识别准确率。最后，本文还将
收稿日期: 2014-12-15; 修回日期: 2015-01-28 基金项目: 国家自然科学基金资助项目(61303005)
作者简介:路同强(1986-)，男，助理工程师，硕士，主要研究方向为机器学习、数据挖掘(lutongq@163．com);石冰(1957-)，男，教授，硕士，主要
研究方向为数据库、数据挖掘、机器学习;闫中敏(1977-)，女，副教授，博士，主要研究方向为Web数据集成、数据库;周珮(1990-)，女，硕士，主要
研究方向为数据挖掘． 第3期 路同强，等:一种用于微博谣言检测的半监督学习算法 ·745·
该算法应用到微博谣言检测中，进一步验证算法的有效性和可 更少或者没有，从而加剧数据集的不平衡性，使得基于此数据
行性。 集训练出来的决策树的规则不能很好地体现少数类的特点。
1 相关基础 2 基于Co-Forest的改进算法
1．1 不平衡数据分类 本文基于 Co-Forest 算法，提出了新的半监督学习算法
ImCo-Forest。该算法旨在通过改善训练集中少数类的分布来
目前，解决不平衡数据分类问题主要有数据层和算法层两
提高基分类器对少数类的识别能力，从而使得集成后的分类
种策略［14］。数据层的方法又称为重抽样，它通过对正( 少数)
器对少数类有效识别。设L={( x ，y ) ，…，( x，y ) }表示已
类数据重复采样或随机地从多数( 负) 类中删除元组，使得结 1 1 l c
标记样本，y∈{1，…，c}，U={( x ，y ) ，…，( x，y ) }表示未
果训练集包含相同个数的正元组和负元组，以此改变训练集中 i 1 u j u
标记样本，并且l＜＜j。算法的目的是预测未标记样本的类标
的元组分布。算法层的方法主要对分类模型结构进行改变，即
签y 。
修改已有的分类算法，通过调节不同类样本之间的成本函数、 u
2．1 代价引入及终止条件
改变概率密度、调整分类边界、调整分类决策等措施使其更有
利于少数类的分类。 在对未标注数据进行标注时，为了提高少数类识别的准确
在数据层面，Chawla等人［15］提出的SMOTE算法是一种简 率，引入代价敏感的思想。给定代价矩阵Cost(i，j)，如表1 所
单有效的过采样方法。其主要思想是在近邻少数类样本之间 示，其中Cost(i，j)表示将类j错误分类为i的代价。
进行线性差值，通过人工合成新的少数类样本来降低类别的不 表1 代价矩阵
平衡。具体做法是:首先为每个少类样本x随机选出其k个最 预测正类 预测负类
邻近少数类样本x( i=1，…，k);然后根据给定的向上采样倍 实际正类 Cost(1，1) =0 Cost(0，1)
i
率K，随机选择K个样本，记为y ，y ，…，y ;接下来在x与y之 实际负类 Cost(1，0) Cost(0，0) =0
1 2 K
间使用式(1)构造新的少数类样本x new;重复以上步骤，直至所 对实例x进行类别预测时，H
i
中每棵决策树首先得出训
有少数类样本均处理完为止。该方法使分类器的分类平面向 练集中类别j的概率估计P(j|x)，通过最小化式(2) 给出属于
多数类的空间伸展，同时可有效地避免随机向上采样的过学习 类别j的预测，并对最终类别采用多数投票决定。
问题。 H(x) =argmin(∑P(j|x)C(i，j)) (2)
i
x =x+random(0，1) ×(x －x) (1)
new i 其中:P(j|x)是把实例x分类为类别j的后验概率。
其中:i=1，2，…，k;random(0，1)表示产生一个0～1的随机数。
文献［13］指出，过大的自动标注数据可能影响所学假设
在算法层面，一种比较有效的方法是对学习算法进行一定
的性能。为保证元分类器的多样性，只需要对部分数据进行标
的修改，使其转变为代价敏感学习方法( cost sensitive learning，
注。与Co-Forest算法相同，ImCo-Forest算法中元分类器h 在
i
CSL)［16］，即考虑不平衡类数据中正确识别少数类比多数类具
m 大小的初始已标记数据集L和新标记m 大小的新标记数
0 i，t
有更大价值的事实，在传统分类算法中引入代价因子，对少数
据集L' 的集合上优化自己。定义 H 在 L' 上的错误率为
i，t i i，t
类样本赋予较高的代价，多数类样本赋予较小的代价，迫使最
e ，错误率通过袋外(out of bag，OOB) 数据估计。H 在L' 被
i，t i i，t
终分类器对正类样本有更高的识别率。Ting［17］将代价敏感学
误分的实例加权为e W ，其中W =∑mi，tω ，ω 为H 在
i，t i，t i，t j=0 i，t，j i，t，j i
习引入随机决策树的训练中，提出了代价敏感的决策树算法，
L' 对实例x 的预测置信度。迭代更新终止条件通过式(3)
i，t j
能有效提升不平衡数据中少数类的识别精度。Chen等人［18］
判断:
利用代价敏感思想，在构建决策树的属性分裂过程中引入权重
e W
0＜ i，t ＜ i，t－1 ＜1 (3)
因素，并通过ＲOC反馈调整权重因子来获得最优权值，构造出 e W
i，t－1 i，t
权重随机森林算法(WＲF)。
2．2 算法步骤
1．2 Co-Forest算法 输入标记数据集L，未标记数据集U，ImCo-Forest算法按
Co-Forest算法是基于半监督学习算法中协同训练算法的 照以下步骤执行:
改进算法。其基本思想是用N个分类器来代替协同训练算法 a)初始化
中的两个分类器。当为分类器集合中的一个组件h( i=1，…， (a)用SMOTE方法对 L 样本集中的少数类样本使用式
i
N)确定最确定的标记实例时，使用不包含分类器h 的集成学 (1)进行采样，使不平衡数据趋于平衡，新的样本集为L。
i s
习分类器组合H 来计算未标记实例的置信度。如果置信度超 (b)对平衡后数据L 进行自助抽样，产生 N个训练子集
i s
过预先设置的阈值θ，将其标记并加入到新的标记数据集合L' 分别作为训练集，构造包含N个随机决策树的随机森林。
i
中。再用这个标记数据集和原有的标记数据集对分类器 h 进 b)未标记样本预测过程
i
行优化。通过使用这种方法，Co-Forest首先在已标记数据集上 第t轮迭代，对于分类器h:
i
训练一个分类器集合，然后使用伴随分类器选取的未标记数据 (a)若本轮错误率小于上一轮，对未标记样本集U进行抽
优化每个元分类器。 样产生样本数量大小小于e W /e 的抽样子集U' 。
i，t－1 i，t－1 i，t i，t
Co-Forest算法采用随机森林来保证各分类器之间的差异 (b)对任意给定的未标记数据，采用H ( i=1，…，N) 按照
i
性。然而由于随机森林在构建过程中使用装袋( bagging) 随机 代价敏感的加权投票法进行标记。选择满足条件L i ={x|x∈
选取训练集，如果训练集中的少数类数据量较少，就会使得N U，H j(x) =H k(x)}且置信度大于给定阈值θ的样本生成新的
个随机选取的训练集中含有的少数类的数量比原有的数据集 标记样本L' i，t。 ·746· 计 算 机 应 用 研 究 第33卷
c)迭代优化过程 20%的标记率可以分为一组20个已标记实例和一组80 个未
对分类器h，若本轮错误率小于上一轮且满足式(3) 中所 标记实例的训练集。为了模拟不同量的未标记的数据，这里考
i
示条件，利用基于正负类的分层抽样方法抽样从 L∪L' 中抽 察三种不同的已标记率，如10%、20%、40%。注意到 L 和 U
i，t
取训练子集，更新分类器h，具体地: 中类分布与原始数据集相同。
i
(a)统计L∪L' 中少数类样本数量n ; 实验基于 WEKA( http: //www． cs． waikato． ca． nz/ml/we-
i，t i，t
(b)根据n 大小从L∪L' 中抽取相同数量的多数类，并 ka/)平台进行，实验中参照文献［13］的参数设置，将 Ｒandom
i，t i，t
与少数类样本组合形成子集Lsub∪L'sub; Forest个数N设为6，置信度阈值设为0．75，其他参数为WE-
i，t
(c)使用Lsub∪L'sub优化。 KA默认参数。算法中 SMOTE 采样倍率 K =round( IL) －1。
i，t
d)采用多数投票H* =arg max ∑ 1决定类别。
其中:round(IL)表示对IL四舍五入得到的数值，IL指不平衡
y∈label i:hi(x)=y 度，最近邻k=5。多数类误分代价固定为Cost(1，0) =1．0，少
2．3 ImCo-Forest算法分析
数类误分代价固定为Cost(0，1) =2．0。为便于对样本进行分
与Co-Forest算法相比，改进的算法ImCo-Forest有两方面 类，首先对特征集合中特征向量采用线性归一化方法进行处
不同之处:a)在初始已标注数据集和加入新标注数据的数据 理，使每个特征处于同一量纲之下。
集上分别使用SMOTE算法和分层抽样平衡数据;b) 在未标注 3．2 评价指标
数据置信度预测时，引入代价因子，对少数类样本赋予较高的
在不平衡数据分类任务中，衡量分类器的性能指标也与平
代价，多数类样本赋予较小的代价。ImCo-Forest算法一方面通
时有所差异，常用评价标准有 F-measure 以及 G-mean 等。在
过SMOTE算法和分层抽样人为地将少数类的数量加大，平衡
两类别情形下，将训练样例少但具有高识别重要性的少数类视
了数据分布，使得随机森林算法更稳定地发挥其优越性;另一
为正类，多数类视为负类。经过分类过程后，训练样例可以分
方面通过加大少数类的误分类代价，使得分类器更加关注少
为表3所示混淆矩阵中所表示的四种情况。
数类。
表3 二分类问题混淆矩阵
具体地:
类别 预测正类 预测负类
a)对已标注数据集L采用SMOTE算法进行类别平衡，使
实际正类 TP FP
得在计算未标记数据可信度时避免了决策树学习假设的偏斜;
实际负类 FP TN
b)基于代价敏感的加权投票法计算未标记数据集合 U中
F-measure 指标是一种综合考虑查全率和查准率的分类评
的每一个未标记数据的标记可信度，提高了少数类识别的准
价指标。其定义为
确率;
(1+β2) ×recall×precision
F-measure= (4)
c)对加入新标记数据的数据集L∪L' ，采用基于正负类的 β2 ×recall+precision
i
分层抽样方法抽样，进一步保证了类别平衡，避免了因样本选 TP
对于少数类来说，查全率recall= ，查准率precision=
TP+FN
取不当而造成分类性能恶化的问题。
TP
。实验中β 取值为1，即当查全率和查准率都比较大
3 实验与讨论 TP+FP
时，F-measure才可取得较大的值。
3．1 实验设置 G-mean表示的是少数类分类精度和多数类分类精度的几
采用UCI数据集进行算法验证是机器学习研究常用的办 何平均值。只有在多数类和少数类的分类精度同时都高的情
法，本文实验所用的测试数据集是在研究不平衡数据分类时常 况下，G-mean 的值才最大。
用的10个公开数据集，它们都是从 UCI( http: //archive． ics． G-mean= 槡sensitivity×specificity (5)
uci．edu/ml/)的机器学习数据库中获得的。其中，yeast、page- TP TN
其中: sensitivity= ，specificity= 。
TP+FN FP+TN
blocks等数据集为多类数据集，本文将其中最少类作为少数
同时，为了与改进前算法作比较，采用机器学习中最常用
类，其他类合并为多数类。具体信息见表2。
的指标分类正确率Accuracy来衡量总体正确率。
表2 UCI测试数据集
TP+TN
数据集 属性数 总样本 正例 负例 目标类 不平衡度
Accuracy= TP+FP+TN+FN×100% (6)
cleveland 13 303 139 164 1 1．18
3．3 结果与分析
pima 8 768 268 500 1 1．87
iris0 4 150 50 100 1 2．0 图1～3分别显示了在不同已标注率下，改进后的 ImCo-
haberman 3 306 81 225 2 2．78 Forest与Co-Forest算法的性能对比。
vehicle3 18 846 212 634 3 2．99
cmc 9 1473 333 1140 2 3．42
yeast3 8 1949 163 1321 4 8．10
page-blocks0 10 5472 559 4913 2，3，4，5 8．79
page-blocks1 10 472 28 444 1，4 15．86
yeast4 8 1484 244 1240 3 28．10
对于每一个数据集，用十折交叉验证来评价。对每一折，
训练数据根据给定的已标记率μ随机地分成已标记数据集合
L和未标注集U。例如，如果一个训练集包含100个实例，根据 图1 10%已标注比例算法对比 第3期 路同强，等:一种用于微博谣言检测的半监督学习算法 ·747·
从新浪微博抓取了两个热点事件相关的微博作为语料，以新浪
微博官方的辟谣信息为依据，选取共5 894条微博进行人工标
注。为了保证标注精度，对抓取的微博语料，采用两个组员分
别独立地对语料进行人工标注，并通过计算Kappa系数来保证
微博数据标注的一致性。实验采用文献［11，12］提出的微博
文本内容特征、用户属性信息和微博传播特征三类基本特征中
16个特征作为分类属性，这些特征已经被证实能有效检测微
图2 20%已标注比例算法对比 博谣言。检测数据集描述如表5所示。
表5 微博语料数据集
谣言事件 属性数 总样本 谣言数 非谣言数 不平衡率
蓟县大火 16 2909 849 2060 2．42
少女遭毁容 16 2985 312 2673 8．57
通过UCI数据集上算法性能对比，可以看出 ImCo-Forest
算法主要通过未标记数据来提升性能。同时，本文的主要目的
是减少人工数据标注的代价，因此，只考虑在少量已标注数据
图3 40%已标注比例算法对比
的情况下算法对微博谣言的检测性能。为了与其他已有工作
从图中可以看出，对于10 个不平衡数据集，与 Co-Forest
比较，本文在L∪U上，当μ=0%情况下的数据集上训练SVM、
算法相比，除10%已标注比例下haberman数据集上本文算法
Bayes及J48分类器和已标注比例10%的情况下对 Co-Forest
的平均G-mean有所下降以外，本文算法的平均G-mean、平均
和ImCo-Forest算法性能进行了比较。实验采用本文2．2节中
F-measure均有所显著提升，表明本文算法能较好地处理不平
评价指标。实验结果如表6所示。
衡数据。
表6 算法性能比较
表4显示了不同已标注数据比例下算法的分类正确率。
可以看出，在20%已标记数据比例下，算法结果整体指标最 性能
好;在40%已标注数据比例下，不管是Co-Forest算法还是改进 算法 蓟县大火 少女遭毁容
后的ImCo-Forest算法，其性能均有所下降，这是因为这两种算 Acc PrecisionG-meanF-measure Acc PrecisionG-meanF-measure
法性能的提升主要得益于未标记数据，当未标注训练集较小 SVM 74．67 0．705 0．259 0．124 90．03 0．501 0．130 0．500
时，通过自主抽样获得的初始多样性很有限，结果学习过程中
Bayes 61．93 0．327 0．538 0．367 86．01 0．250 0．422 0．216
的多样性快速下降，集成器的性能也相应下降，这也与文献
J48 72．61 0．452 0．409 0．259 89．23 0．143 0．109 0．023
［13］的实验结果相符。同时，从表4中可以看出，改进后的算
Co-Forest 65．05 0．388 0．530 0．378 89．05 0．330 0．345 0．179
法只有在少数数据集上分类正确率较Co-Forest算法有所小幅
ImCo-Forest 70．21 0．694 0．601 0．633 87．90 0．620 0．650 0．874
度下降，说明本文算法在提升少数类识别率的同时并没有降低
对多数类的识别精度。 注:加粗表示性能表现最好。
表4 不同已标注比例下算法Acc比较 /% 从表6中可以看出，ImCo-Forest算法在两个语料数据集上
G-mean和F-measure指标均最好，说明其在处理非平衡数据问
Co-Forest ImCo-Forest
数据集 题时较其他算法有优势。值得注意的是，SVM 算法虽然在总
10 20 40 10 20 40
体正确率上比较高，甚至在语料2上达到了90．23%的高正确
cleveland 69．64 77．59 71．34 72．60 78．81 72．61
率，但是G-mean和F-value都较低，说明对少数类的识别性能
pima 70．31 72．52 70．05 72．00 75．12 72．15
iris0 94．00 98．90 89．33 96．67 98．90 89．50
较差，表明其并不能准确识别谣言。
haberman 72．23 71．55 73．13 72．22* 70．25* 73．25 同时，实验对选取的三种监督学习算法的训练数据是全部
vehicle3 69．15 74．58 66．56 82．35 77．21 77．21 标注的理想数据集，其结果仅SVM和J48 算法在总体正确率
cmc 76．10 75．49 73．18 75．67* 76．41 75．45 指标上优于 ImCo-Forest，表明要达到较高的正确率，需要比
yeast3 93．67 94．07 91．55 95．97 97．10 91．10* ImCo-Forest算法更多的标注数据，这无疑中减弱了其在实际
page-blocks0 95．98 96．44 95．56 96．71 96．55 96．10 应用中的可行性。
page-blocks1 94．49 94．28 94．28 93．75* 94．28 95．12 以上实验结果表明，本文算法能在少量标注数据下较好地
yeast4 86．05 86．92 89．19 84．56* 84．92* 89．19 检测谣言，可在微博谣言识别中大大减小数据标注的代价。
注:加* 表示相同标注比例时性能下降。
5 结束语
以上实验结果表明，本文所提算法在处理类别不平衡分类
问题时较Co-Forest算法优越，能有效提升少数类样本的识别
本文算法是在Co-Forest算法基础上改进的，继承了半监
准确率。
督学习算法的优点，利用少量的已标记样本和大量的未标记样
本进行分类。同时考虑了数据分布不平衡的问题，增强算法对
4 微博谣言检测验证
少数类的识别性能，使得能在微博谣言检测中应用。对于下一
本文以新浪微博为例进行谣言检测实证实验。实验首先 步工作，将考虑对算法的抽样阶段进行改进，以避免由于样本 ·748· 计 算 机 应 用 研 究 第33卷
复制而导致的算法复杂度的提升，以期达到更好的效果。另 impactevents［C］//Procofthe1stWorkshoponPrivacyandSecurity
外，对于不同的错分代价如何影响算法性能的研究，也是下一 inOnlineSocialMedia． NewYork:ACMPress，2012．
步将要做的工作。 ［9］ GuptaM，ZhaoPeixiang，HanJiawei． Evaluatingeventcredibilityon
twitter［C］//ProcofSIAMInternationalConferenceon DataMining．
参考文献:
2012:153-164．
［1］ Metzger M J． Making sense of credibility on the Web: models for ［10］程亮，邱云飞，孙鲁． 微博谣言检测方法研究［J］． 计算机应用与
evaluatingonlineinformationandrecommendationsforfutureresearch 软件，2013，30(2): 226-228．
［J］． Journal of the American Society for Information Science ［11］YangFan，YuXiaohui，LiuYang，etal． Automaticdetectionofrumor
andTechnology，2007，58(13): 2078-2091． onSinaWeibo［C］//ProcofACMSIGKDDWorkshoponMiningDa-
［2］ WangAH． Don'tfollowme: spamdetection in twitter［C］//Procof
taSemantics． NewYork: ACMPress，2012:1-7．
International Conference on Security and Cryptography．［S． l．］:
［12］贺刚，吕学强，李卓，等． 微博谣言识别研究［J］． 图书情报工作，
IEEEPress，2010:142-151．
2013，57(23): 114-120．
［3］ QazvinianV，ＲosengrenE，ＲadevDＲ，etal． Ｒumorhasit: identif-
［13］Li Ming，Zhou Zhihua． Improve computer-aided diagnosis with ma-
yingmisinformationinmicroblogs［C］//ProcofConferenceonEmpiri-
chine learning techniques using undiagnosed samples［J］． IEEE
cal Methods in Natural Language Processing．［S． l．］: ACL，2011:
Trans on Systems，Man and Cybernetics，Part A: Systems
1589-1599．
andHumans，2007，37(6): 1088-1098．
［4］ CastilloC，MendozaM，PobleteB． Information credibilityon twitter
［14］叶志飞，文益民，吕宝粮． 不平衡分类问题研究综述［J］． 智能
［C］// Proc of the 20th International Conference on World Wide
系统学报，2009，4(2): 148-156．
Web． NewYork:ACMPress，2011:675-684．
［15］ChawlaNV，BowyerKW，HallLO，etal． SMOTE: syntheticmi-
［5］ SuzukiY． Acredibilityassessmentformessagestreamsonmicroblogs
norityover-samplingtechnique［J］． JournalofArtificialIntelligence
［C］//Proc of International Conference on P2P，Parallel，Grid，
Ｒesearch，2002，16(1): 321-357．
CloudandInternetComputing．［S．l．］: IEEEPress，2010:527-530．
［16］ElkanC． Thefoundationsofcost-sensitivelearning［C］//Procofthe
［6］ MendozaM，PobleteB，CastilloC． Twitterundercrisis: canwetrust
17thInternational Joint Conference on Artificial Intelligence． 2001:
whatweＲT? ［C］//Procofthe1stWorkshop on SocialMediaAna-
lytics． NewYork: ACMPress，2010:71-79． 973-978．
［7］ CaniniKＲ，SuhB，PirolliPL． Findingcredibleinformationsources ［17］TingKaiming． An instance-weightingmethod to induce cost-sensitive
insocialnetworksbasedoncontentandsocialstructure［C］//Procof trees［J］． IEEE Trans on Knowledge and Data Engineering，
the3rdIEEE International Conference on Social Computing．Boston， 2002，14(3): 659-665．
MA: IEEEPress，2011:1-8． ［18］ChenChao，LiawA，BreimanL． Usingrandomforesttolearnimbal-
［8］ Gupta A，Kumaraguru P． Credibility ranking of tweets during high anceddata［Ｒ］． Berkeley:UniversityofCalifornia，2004:1-12．
(上接第743页)目标相距较近时依然可以分辨目标的数目并实 2014，8(1): 131-141．
现定位;但当多个目标相距太近时，多目标位置信息场定位法 ［2］ ShenJunyang，MolischA，SalmiJ． Accuratepassivelocationestima-
也可能无法分辨目标，将多个目标判为一个目标，出现漏警 tion usingTOAmeasurements［J］． IEEETransonWirelessCom-
munications，2012，11(6): 2182-2192．
现象。
［3］ 袁罡，陈鲸． 三站时差定位模糊问题解决方法［J］． 中国电子科
5 结束语 学研究院学报，2014，9(1): 89-92．
［4］ PicardJS，WeissAJ． Timedifferencelocalizationinthepresenceof
本文从最大似然估计定位法出发，分析了在单目标定位过
outliers［J］． SignalProcessing，2012，92(10): 2432-2443．
程中存在测量误差较大或错误参数时最大似然估计定位法性 ［5］ WangZhi，Luo Ji’an，Zhang Xiaoping． A novel location-penalized
能急剧下降的问题，引出了目标位置信息场定位法，通过加入 maximumlikelihoodestimatorforbearing-onlytargetlocalization［J］．
代价函数使得该方法能够剔除错误数据，降低了误差大的数据 IEEETransonSignalProcessing，2012，60(12): 6166-6181．
对定位结果估计的影响，性能稳定。在对不可区分的多目标进 ［6］ 白晶，王国宏，王娜，等． 测向交叉定位系统中的最优交会角研究
行定位时，最大似然估计定位法只能得到一个多目标平均位置 ［J］． 航空学报，2009，30(2): 298-304．
的估计，而目标位置信息场定位法可以同时得到目标的数目和 ［7］ 蔡晶晶，鲍丹，李鹏，等． 强约束优化降维MUSIC二维DOA估计
位置。在后续的处理中，可以此目标数目和位置为基础，对测 ［J］． 电子与信息学报，2014，36(5): 1113-1118．
量参数按目标区分，转换为单目标定位问题用经典方法处理。 ［8］ Chen Chen，Zhang Xiaofei． A ＲD-ESPＲIT algorithm for coherent
DOAestimationinmonostaticMIMOradarusingasinglepulse［J］．
然而文中对多目标位置信息场定位法的研究还不够深入，如多
InternationalJournalofElectronics，2014，101(8): 1074-1085．
于两个目标的定位问题、关于各个目标测量参数信息不均衡条
［9］ 张敏，郭福成，周一宇，等． 时变长基线2维干涉仪测向方法［J］．
件下定位问题、定位的漏警虚警问题等，都将有待进一步研究，
电子与信息学报，2013，35(12): 2882-2888．
以便算法在工程中实际使用。
［10］韩月涛，潘伟萍，吴嗣亮，等．干涉仪解模糊异常值检测及纠错方
参考文献:
法［J］． 北京理工大学学报，2012，34(8): 849-854．
［1］ LeeJY，HudsonＲE，YaoK． AcousticDOAestimation: anapproxi- ［11］马贤同，罗景青，张奎．面向DOA测量的多目标位置信息场定位
mate maximum likelihood approach［J］． IEEE Systems Journal， 法［J］． 信号处理，2013，29(1): 121-126． --------------------------------------------------------------------------------- 第 卷 第 期 电子设计工程 年 月
26 9 2018 5
Vol.26 No.9 ElectronicDesignEngineering May.2018
一种融合协同过滤和用户属性过滤的混合推荐算法
曹俊豪，李泽河，江 龙，张德刚
（云南电网有限责任公司 教育培训评价中心，云南 昆明 ）
650000
摘要：传统的推荐算法向用户进行推荐时一般以用户评分矩阵作为基础，向用户推荐相应的内容，
但评分矩阵数据不充分时，该推荐算法准确性难以得到保障。本文中所述的融合协同过滤和用户
属性过滤的混合推荐算法，提出时间热度的计算方法并对 相关系数进行改进，建立用户属
Pearson
性相似度模型，对邻居用户进行过滤，由最终票选得到的可信邻居用户向当前匹配用户推荐。经
过的系列实验的结果表明，本文中提出的融合协同过滤和用户属性过滤的混合推荐算法较之前经
典的系统过滤算法有更好的效果。
关键词：协同过滤；用户属性相似度；数据稀疏；推荐算法
中图分类号： 文献标识码： 文章编号： （ ）
TP311 A 1674-6236 2018 09-0060-04
A hybrid recommendation algorithm based on collaborative filtering and user
attribute filtering
， ， ，
CAOJun⁃hao LIZe⁃he JIANGLong ZHANGDe⁃gang
（YunnanPowerGridCo.，Ltd.，Kunming ，China）
650000
Abstract: （ ）
The traditional Collaborative Filtering CF recommendation algorithm is based on the user
scoring matrix to recommend to the user. There is a problem that the recommendation information is
inaccurate due to sparse data. Accordingly we propose a hybrid recommendation algorithm which
，
combines cooperative filtering and user attribute filtering. In this paper we first propose the method of
calculating the time heat and improve the Pearson correlation coefficient algorithm. And then establish
，
the user attribute similarity model. Filtering the neighbor user and recommending by trusted neighbors
user finally obtained to the current user. The experimental results show that the hybrid recommendation
algorithm proposedinthispaperhasbettereffectthanthetraditionalsystem filteringalgorithm.
Keywords: ； ； ；
CollaborativeFiltering userattributesimilarity sparsedata recommendationalgorithm
DOI:10.14022/j.cnki.dzsjgc.2018.09.014
目前，云南电网年培训人次达 万，具有规模
6 1 混合推荐算法
大、内容覆盖面广、专业多、专业性强等特点，如何根
据每个用户行为数据对用户推送其感兴趣的项目 1.1 协同过滤下邻居用户的寻找
（如设备知识点）成为培训中一个难题。于此，本次 当前，信息推荐领域算法种类繁多，一般常见的
研究中提出了一种融合协同过滤和用户属性过滤的 是协同过滤算法。协同过滤算法是通过分析所有用
混合推荐算法，即移动端通过用户行为收集用户习 户对物品的偏好，发现与当前用户爱好相似的邻居
惯行为信息，利用该算法对用户的基本行为习惯进 用户群，根据发现的相似用户群对当前的匹配用户
行分析整合，结合用户的兴趣为其推荐对应的项目 进行信息推荐；另一种类型是基于项目的协同过滤
服务。在平台“基于数字编码的移动学习管理平台” 算法，这种算法是在分析物品与物品之间相似度后，
中的实验及实际应用中表明，本文算法在对比其他 根据当前用户爱好为其推荐相似的物品[13-14]。本文
中混合算法是一种基于用户的算法，通过对不同用
推荐算法具有较优的信息推荐效果[1-2]。
户之间的相似度进行匹配，推荐给用户相似邻居的
收稿日期： 稿件编号：
2017-09-01 201709006
作者简介：曹俊豪（ —），男，河南新野人，硕士研究生，工程师。研究方向：教育培训。
1985
- 60 - 曹俊豪，等 一种融合协同过滤和用户属性过滤的混合推荐算法
个性化推荐内容。本文考虑到用户的兴趣会随时间 ） 相关系数的优化
3 Pearson
不断发生变化，提出了时间热度这一概念，并对相似 计算用户相似度的方法有很多，最常见的一般
度计算进行优化。 是 相关系数。用户集U、项目集P以及给定
Pearson
）用户评分矩阵 的用户所对项目的评分矩阵R（如表），r 表示了匹
1 a， p
系统中需要在得到匹配用户对项目的兴趣评分 配用户a对兴趣项目p的评分，r 表示匹配用户u对
` u
的基础上，利用评分值反映用户对项目的兴趣值。 兴趣项目 评分的平均值，则用户a和用户b的相似
P
评分值范围一般在 ，为概似值范畴，相对的评分 度表示如下：
1~5
- -
值越高，即表示当前匹配用户对项目的兴趣度越大[15]。 r r r r
a b ∑p ∈P( a ,p- a)( b ,p- b) （）
设 、 、 、 为系统的项目， 、 、 、 为系统 sim( , )= - - 2
的用I1 户I2 ，将... 用IM 户对项目的评分填U1 入U 对2 应... 的U 矩N
阵单元
∑p ∈P(r a ,p-r a)2 ∑p ∈P(r b ,p-r b)2
在传统的算法中，当其在对当前用户兴趣进行
中，即可得到用户 项目评分矩阵，如表 所示。
- 1 分析时，往往会将时间这一影响因素考虑在外，而在
表1 用户-项目评分矩阵
文中通过 系数[17]对算法进行了改善，从而能
Pearson
… 够为用户推荐更加具有价值的内容，改善的公式内
I1 I2 I3 IM
…
U1 5 - 1 - 容为：
… - -
U2 - - 2 4 WT a p r r WT b p r r
U3 3 4 -
…
-
sim *(a ,b
)
∑p ∈P( ( , )× a ,p -- a)( ( , )× b ,p- b)
-
… … … … … … WT a p r r 2 WT bp r r 2
∑p ∈P( ( , )× a ,p- a)∑p ∈P( ( , )× b ,p- b)
…
UN 5 - - - （）
3
）时间热度
从公式（）中可以看出，引入时间热度之后，在
2
3
对于传统的算法，其在当前用户的邻居寻找时，
计算a和b的相似度时，用户历史中近期的兴趣将会
对时间方面并无涉及，但时间概念对用户的兴趣具
反映更加充分。利用优化后的公式（）可计算出当
3
有较大的影响，若将这一因素忽略往往导致推荐的
前用户与其余用户的相似度，在得到似度的基础上
内容同用户需求之间产生较大的变化。为了寻找对
可以用 原则票选出当前匹配用户的N位邻居
Top-N
推荐结果更有价值的相似用户，考虑用户近期访问
用户。
的项目比早期访问过的项目更能反映用户兴趣，本
但是通过本文提出的改进的用户相似度计算公
文在相似度计算公式里面加入了时间热度因素，避
式（公式（））计算得出的相似用户集合，其集合中也
3
免了在相似度计算时忽视了时间概念对用户兴趣的
有可能会存在与目标用户兴趣差异很大的相似用
影响，增加寻找相似用户的可信度。
户，所以在一般情况下并不能对用户群中匹配的所
时间热度是指用户访问项目的时间新鲜度，访
有的相似用户都可以有很好的信息推荐效果。由这
问时间离当前时间越近则新鲜度越高，时间热度就
样的相似用户产生的推荐准确率是比较低的。之所
越高，反之亦然。设 表示用户u访问项目i的时
以会存在这种现象，主要是由于评分矩阵比较稀疏
Dui
间与用户u最早访问系统任一项目的时间间隔（在
的缘故导致的，接下来要做的就是要再次过滤掉这
数据库中有相应的时间记录），定义时间热度函数
类相似度比较低的用户。
（u，i），它是一个和 相关的函数值。在本文研 1.2 用户属性过滤下相似度低的邻居用户滤除
WT Dui
究中，为了能够对访问项目的重要性进行重点突出，
要求在用户属性过滤下对计算出的相似度比较
其通过设计一种关于 的递减函数来对其进行表
低的邻居用户进行滤除，需要得到对应用户的特征
Dui
示[16]，即对于 ，有 （u，i） （u，j）。时间
矩阵。而计算对应特征值则需要对用户的一系列属
Dui>Duj WT ≥WT
热度函数计算公式如下：
性进行特征提取，提取方法广泛，在得到了对应用户
u，i a a （）
WT( )=(1- )+ 1 的特征矩阵后，即可计算出相应用户与用户之间的
上述公式为线性函数，其中 指的是用户 在
Lu u 相似度。
进行推荐系统使用时的时间跨度，也就是该用户最
）建立用户的特征矩阵
1
早访问的项目同当前需要访问项目之间的时间间
一个用户可有多种属性，本文提取其中较能反
隔，a（ ，）称为权重增长指数。
∈ 0 1
- 61 - 《电子设计工程》 年第 期
2018 9
应用户特征的 种属性来构建用户特征矩阵，分别 ）在得到预测的基础上，由 方法票选出
7 5 Top-N
是：工种、学历、工龄、归属部门、性别、岗位、技能等 最终能代表当前匹配用户最佳信息推荐项目的项目
级。特征矩阵如表 所示。 集合。
2
表2 用户特征矩阵
2 实验以及结果分析
用户 工种 技能等级 岗位 归属部门 …
用户 工种 等级 岗位 部门 … 2.1 实验数据与度量
1 1 1 1 1
用户 工种 等级 岗位 部门 … 数据稀疏度是指不包含数据的单元与总单元的
2 2 1 2 2
用户 工种 等级 岗位 部门 … 相对百分比，其计算公式如下：
3 3 1 1 1
… … … … … A
... R （）
）计算用户之间的相似度 =1- P 6
2
式（）中： 表示已包含数据的单元数，表示总
用户特征属性包括工种、学历、工龄、归属部门、 6 A P
单元数。本文采用自《基于数字编码的移动学习管
性别、岗位、技能等级，则用户ｕ的特征属性可以用
理平台》产生的数据集，包含 个用户对 个项
向量 （a ，a ，a ，a ，a ，a ，a ）来表示。其 897 122
UAttru= u1 u2 u3 u4 u5 u6 u7
目的 条兴趣评分，评分的值为 到 ，根据公式
中，从u 到u 分表代表以上用户特征属性。对于数 8 600 1 5
1 7
（）可计算出数据稀疏度为 。在数据集中随
值属性，如工龄，根据实际经验本文规定若二者工龄 6 0.921 4
机性抽取其中百分之八十作为训练集，另外百分之
相差超过 ，则认为二者不同；对于分类属性，例如工
3
二十作为测试集。利用所抽取的百分之八十的训练
种、学历、归属部门、性别、岗位、技能等级则采用原
集中的数据和本文所属的算法来算出测试集中所有
始值。若用户u和用户v的第i个属性相同，我们令
单元的预测评分，对比测试集中的实际评分可对算
（u，v，i） ，否则 （u，v，i） 。用户u
USimUAttr =1 USimUAttr =0
法的推荐质量进行分析。
和v的相似度可以用下面的公式来计算[18]。
在实验中的评价指标采用平均绝对误差
USimattru v ωi Usim u v （）
( , )=∑ , UAt tr( , ) 4
（MAE）。实验中计算得出的测试度量集合中的测试
式中：为第i个属性的权重，所有属性的权重值
用户对项目的预测评分一般与实际的用户评分有一
相加为 。
1 定的偏差，而MAE可以通过这种偏差对度量结果的
1.3 推荐步骤的描述
准确性进行度量，一般而言，MAE测试度量值越大，
融合协同过滤和用户属性过滤的混合推荐算法
推荐质量越低；越小，推荐质量越高，也即推荐可信
其具体实现流程有以下几个步骤：
度越高。具体的 MAE计算公式为：
）由用户访问项目的具体时间，根据公式（）计
1 1 N p q
算时间热度。 MAE ∑i =1| i- i| （）
= N 7
）对于待推荐用户，利用前文中改进过的相似
2 预测的用户评分集p为 P，P， P ，对应实际
度计算公式（），得到当前匹配用户与其他用户的相 i { 1 2 ⋯ N}
3 的用户评分集q为 q，q， ，q ，
似度，结合 原则票选出由N位匹配用户所组 i { 1 2 ⋯ N}
Top-N 2.2 结果分析
成的相似邻居用户集。
为了验证文中混合推荐算法的有效性，分别对
）依据本文前面介绍特征矩阵建立方法建立对
3 传统的协同过滤算法（ ）和本文混合推荐算法
应用户的特征矩阵，并且可以通过公式（）得到的N UserCF
4 （ ， ）进行了对比
位邻居用户逐一与当前匹配用户的相似度比较分 Hybrid Recommendation Method HRM
实验，实验的结果如图 所示。图横坐标为K值
析，根据相似度大小由小到大对匹配用户N位邻居 1~2
（用户数），纵坐标为评价指标 值。
用户整理，经过排序分析，以票选方式选择出最终的 MAE
）从两个图可得出，基于协同过滤算法的
对应M位可信邻居（M N）。 1 MAE
< 值在整个k值区间都要大于本文混合推荐算法的
）匹配用户a对项目p的预测评分r 的计算公
4 a，p 值， 越小，表示推荐质量越高，由此可说明
式如下： MAE MAE
本文所述的混合推荐算法在整体推荐精准度上优于
-
- a b r r
r r ∑b ∈Msim*( , )×( b ,p- b) （） 传统的协同过滤算法。
a ,p= a+ a b 5
∑b ∈Msim*( , ) 2）从两个图可得出，当k >60后，随着k值的增
- 62 - 曹俊豪，等 一种融合协同过滤和用户属性过滤的混合推荐算法
王雪 协同过滤推荐算法的改进研究 鞍山：辽
[3] . [D].
宁科技大学，
2016.
一种适应于 环境的复杂推荐算法
[4] e-Learning [J].
环球信息， ， （）： ）
2014 17 2 271-284
温梅个性化推荐中基于贝叶斯网络的用户兴趣
[5] .
模型研究 武汉：华中师范大学，
[D]. 2013.
李克潮，蓝冬梅 一种属性和评分的协同过滤混
[6] .
合推荐算法 计算机技术与发展， ，（）：
[J]. 2013 23 7
图 基于协同过滤算法的 值
1 MAE ，
116-119 123.
郝丽燕，王靖 基于填充和相似性信任因子的协
[7] .
同过滤推荐算法 计算机应用， ， （）：
[J]. 2013 33 3
834-837.
陈彦萍，王赛基于用户 项目的混合协同过滤算法
[8] . -
计算机技术与发展， ，（ ）： ，
[J]. 2014 24 12 88-91 95.
许智宏，王宝莹基于项目综合相似度的协同过滤
[9] .
算法 计算机应用研究， ，（）：
[J]. 2014 31 2 398-400.
图 基于本文混合推荐算法的 值 李克潮，梁正友 适应用户兴趣变化的指数遗忘
2 MAE [10] .
加，两种算法的 值都有所增加，但是基于协同过 协同过滤算法 计算机工程与应用， ，
MAE [J]. 2011 37
滤算法的 值的增长速率明显高于基于本文混合 （）：
MAE 6 226-243.
推荐算法的 值的增长速率， 值增长速率越 杨秀萍融合用户评分和属性相似度的协同过滤推
MAE MAE [11] .
低，则表示推荐稳定性越好，由此可说明本文所述的 荐算法 计算机与现代化， ，（）：
[J]. 2017 33 7 16-19.
推荐算法在稳定性上要优于传统的协同过滤算法。 刘欣面向社会化媒体的内容推荐若干关键技术
[12] .
研究 北京：北京邮电大学，
3 结束语 [D]. 2015.
王三虎，王丰锦 融合用户评分和属性相似度的
[13] .
相关参数关系分析和信息推荐方法对比实验表 协同过滤推荐算法 计算机应用与软件， ，
[J]. 2017
明，本文所支持的融合协同过滤和用户属性过滤混 （）： ，
34 4 305-308 321.
合推荐算法在一定程度上是行之有效的算法，相对 ， 稀疏数据下的动态个性
[14] Xiangyu Tang Jie Zhou.
于传统经典的协同过滤算法一定呈上缓解了数据稀 化推荐 知识与数据工程汇刊， ，
[J]. IEEE 2013 25
疏矩阵所造成的用户相似度不高的问题，其推荐范 （ ）：
12 2895-2899.
围更广，推荐可信度也更高，推荐效果更优。但是本 李梁，张海宁，李宗博，等 融合用户属性的协同
[15] .
文提出的算法还存在一些其他问题，例如在用户属 过滤推荐算法在政府采购中的应用 重庆理工
[J].
性过滤下比较对应匹配用户与用户之间相似度值 大学学报：自然科学， ，（）：
2015 31 1 76-81.
时，对匹配用户的不同属性特征在计算模型中的权 纪科融合上下文信息的混合协同过滤推荐算法
[16] .
重如何分配等问题还有待进一步的深入研究。 研究 北京：北京交通大学，
[D]. 2016.
参考文献： 邹永贵，望靖，刘兆宏，夏英 基于项目之间相似
[17] .
刘庆鹏，陈明锐 优化稀疏数据集提高协同过滤 性的兴趣点推荐方法 计算机应用研究， ，
[1] . [J] 2012
推荐系统质量的方法 计算机应用， ， （）： ，
[J]. 2014 24 29 1 116-118 126.
（ ）： ， 陈庚午混合推荐算法在云计算平台的研究与应
12 88-91 95. [18] .
张亮基于协同过滤与划分聚类的推荐算法研究 用 沈阳：中国科学院研究生院（沈阳计算技
[2] . [D].
长春：吉林大学， 术研究所），
[D]. 2014. 2016.
- 63 - --------------------------------------------------------------------------------- ｈｔｔｐ：／／ｗｗｗ．ｊｓｊｋｘ．ｃｏｍ
ＤＯＩ：１０．１１８９６／ｊｓｊｋｘ．２００２００１１４
个性化推荐系统技术进展
刘君良 李晓光
辽宁大学信息学院 沈阳１１００３６
（１４０３４３２３２７＠ｑｑ．ｃｏｍ）
摘 要 推荐系统通过获取用户的历史行为数据，如网页的浏览数据、购买记录、社交网络信息、用户地理位置等，来推断用户
偏好。随着计算机技术的发展，推荐系统所采用的推荐技术由早期的基于用户－项的数据矩阵分解技术为主，逐渐向与数据挖
掘、机器学习、人工智能等技术相融合的方向发展，从而深度挖掘用户行为的潜在偏好，以构建更加精准的用户偏好模型。推荐
过程也从静态预测发展到实时推荐，通过与用户实时交互来使推荐结果更加丰富。文中重点回顾了推荐系统在不同时期所采
用的关键技术，主要包括基于内容过滤的推荐技术、基于协同过滤的推荐技术、基于深度学习的推荐技术、基于强化学习的推荐
技术和基于异构网络的推荐技术等。最后对比和分析了关键技术的优缺点，并对推荐系统的未来发展进行展望。
关键词：推荐算法；矩阵分解；神经网络；强化学习；异构信息网络
中图法分类号 ＴＰ３１１．５
Ｔｅｃｈｎｉｑｕｅｓ ｆｏｒ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ Ｓｙｓｔｅｍ：Ａ Ｓｕｒｖｅｙ
ＬＩＵ Ｊｕｎ－ｌｉａｎｇ ａｎｄ ＬＩ Ｘｉａｏ－ｇｕａｎｇ
Ｃｏｌｌｅｇｅ ｏｆ ｉｎｆｏｒｍａｔｉｏｎ，Ｌｉａｏｎｉｎｇ Ｕｎｉｖｅｒｓｉｔｙ，Ｓｈｅｎｙａｎｇ １１００３６，Ｃｈｉｎａ
Ａｂｓｔｒａｃｔ Ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ ｏｂｔａｉｎｓ ｕｓｅｒｓ’ｈｉｓｔｏｒｉｃａｌ ｂｅｈａｖｉｏｒ ｄａｔａ ｔｏ ｐｒｅｄｉｃｔ ｔｈｅｉｒ ｐｒｅｆｅｒｅｎｃｅｓ，ｓｕｃｈ ａｓ ｗｅｂ ｂｒｏｗｓｉｎｇ
ｄａｔａ，ｐｕｒｃｈａｓｅ ｒｅｃｏｒｄｓ，ｓｏｃｉａｌ ｎｅｔｗｏｒｋ ｉｎｆｏｒｍａｔｉｏｎ，ｕｓｅｒｓ’ｇｅｏｇｒａｐｈｉｃａｌ ｌｏｃａｔｉｏｎ ａｎｄ ｓｏ ｏｎ．Ｗｉｔｈ ｔｈｅ ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ ｃｏｍｐｕｔｅｒ
ｔｅｃｈｎｏｌｏｇｙ，ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｔｅｃｈｎｏｌｏｇｙ ｉｓ ｍａｉｎｌｙ ｂａｓｅｄ ｏｎ ｕｓｅｒ－ｉｔｅｍ ｄａｔａ ｍａｔｒｉｘ ｄｅｃｏｍｐｏｓｉｔｉｏｎ ｔｅｃｈｎｏｌｏｇｙ ｉｎ ｔｈｅ ｅａｒｌｙ ｓｔａｇｅ．
Ａｆｔｅｒｗａｒｄｓ，ｉｔ ｉｓ ｇｒａｄｕａｌｌｙ ｉｎｔｅｇｒａｔｅｄ ｗｉｔｈ ｄａｔａ ｍｉｎｉｎｇ，ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ，ａｒｔｉｆｉｃｉａｌ ｉｎｔｅｌｌｉｇｅｎｃｅ ａｎｄ ｏｔｈｅｒ ｔｅｃｈｎｏｌｏｇｉｅｓ，ｓｏ ａｓ ｔｏ
ｄｅｅｐｌｙ ｍｉｎｅ ｔｈｅ ｐｏｔｅｎｔｉａｌ ｐｒｅｆｅｒｅｎｃｅｓ ｏｆ ｕｓｅｒ ｂｅｈａｖｉｏｒ ａｎｄ ｂｕｉｌｄ ａ ｍｏｒｅ ａｃｃｕｒａｔｅ ｕｓｅｒ ｐｒｅｆｅｒｅｎｃｅ ｍｏｄｅｌ．Ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ
ｐｒｏｃｅｓｓ ａｌｓｏ ｍｏｖｅｓ ｆｒｏｍ ｓｔａｔｉｃ ｐｒｅｄｉｃｔｉｏｎ ｔｏ ｒｅａｌ－ｔｉｍｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ，ｅｎｒｉｃｈｉｎｇ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｒｅｓｕｌｔｓ ｔｈｒｏｕｇｈ ｒｅａｌ－ｔｉｍｅ
ｉｎｔｅｒａｃｔｉｏｎ ｗｉｔｈ ｕｓｅｒｓ．Ｔｈｉｓ ｐａｐｅｒ ｍａｉｎｌｙ ｒｅｖｉｅｗｓ ｔｈｅ ｋｅｙ ｔｅｃｈｎｏｌｏｇｉｅｓ ａｄｏｐｔｅｄ ｂｙ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ ｉｎ ｄｉｆｆｅｒｅｎｔ ｐｅｒｉ－
ｏｄｓ，ｉｎｃｌｕｄｉｎｇ ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｆｉｌｔｅｒｉｎｇ ｔｅｃｈｎｏｌｏｇｙ，ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｔｅｃｈｎｏｌｏｇｙ，ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｔｅｃｈｎｏｌｏｇｙ ｂａｓｅｄ ｏｎ ｄｅｅｐ
ｌｅａｒｎｉｎｇ，ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｔｅｃｈｎｏｌｏｇｙ ｂａｓｅｄ ｏｎ ｒｅｉｎｆｏｒｃｅｍｅｎｔ ｌｅａｒｎｉｎｇ，ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｔｅｃｈｎｏｌｏｇｙ ｂａｓｅｄ ｏｎ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｉｎｆｏｒ－
ｍａｔｉｏｎ ｎｅｔｗｏｒｋ．Ｆｉｎａｌｌｙ，ｔｈｉｓ ｐａｐｅｒ ａｎａｌｙｚｅｓ ｔｈｅ ａｄｖａｎｔａｇｅｓ ａｎｄ ｄｉｓａｄｖａｎｔａｇｅｓ ｏｆ ｋｅｙ ｔｅｃｈｎｏｌｏｇｉｅｓ，ａｎｄ ｔｈｅｎ ｌｏｏｋｓ ｆｏｒｗａｒｄ ｔｏ ｔｈｅ
ｆｕｔｕｒｅ ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ．
Ｋｅｙｗｏｒｄｓ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｌｇｏｒｉｔｈｍｓ，Ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ，Ｎｅｕｒａｌ ｎｅｔｗｏｒｋ，Ｒｅｉｎｆｏｒｃｅｍｅｎｔ ｌｅａｒｎｉｎｇ，Ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｉｎｆｏｒｍａ－
ｔｉｏｎ ｎｅｔｗｏｒｋ
于电子商务、搜索引擎、智慧教育等领域。
１ 引言
随着概率统计、机器学习、人工智能、数据挖掘技术的不
随着互联网、物联网和云计算技术的迅猛发展，现代社会 断发展，推荐系统所采用的技术也从传统的矩阵分解、概率矩
是一个信息化、数字化的社会，数据充斥着整个世界。面对大 阵分解等推荐技术，向基于现代人工智能技术的推荐技术演
量的数据，用户对信息的利用率反而降低了，即产生了信息超 进。传统的推荐系统主要可以分为两类：基于内容过滤（Ｃｏｎ－
载（Ｉｎｆｏｒｍａｔｉｏｎ ｏｖｅｒｌｏａｄ）问题。推荐系统是有效解决信息超 ｔｅｎｔ Ｆｉｌｔｅｒｉｎｇ）的推荐系统与基于协同过滤（Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｆｉｌ－
载难题的关键技术之一，其根据用户需求为用户推荐其感兴 ｔｅｒｉｎｇ）的推荐系统等。基于内容过滤的推荐系统主要是通过
趣的信息。经过二十余年的发展，推荐系统现已被大量应用 项特征与用户特征的匹配或相关程度来筛选或排序推荐项。
到稿日期：２０２０－０２－２５ 返修日期：２０２０－０５－０８ 本文已加入开放科学计划（ＯＳＩＤ），请扫描上方二维码获取补充信息。
基金项目：国家自然科学基金联合基金项目（Ｕ１８１１２６１）；辽宁省教育厅服务地方项目（ＬＦＷ２０１７０５）
Ｔｈｉｓ ｗｏｒｋ ｗａｓ ｓｕｐｐｏｒｔｅｄ ｂｙ ｔｈｅ Ｎａｔｉｏｎａｌ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｃｈｉｎａ（Ｕ１８１１２６１）ａｎｄ Ｌｉａｏｎｉｎｇ Ｅｄｕｃａｔｉｏｎ Ｄｅｐａｒｔｍｅｎｔ Ｓｅｒｖｉｃｅ Ｌｏｃａｌ
Ｐｒｏｊｅｃｔｓ（ＬＦＷ２０１７０５）．
通信作者：李晓光（ｘｇｌｉ＠ｌｎｕ．ｅｄｕ．ｃｎ） ４８ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ 计算机科学 Ｖｏｌ．４７，Ｎｏ．７，Ｊｕｌｙ ２０２０
基于内容过滤的推荐系统根据推荐项类别采用不同的特征抽 本、图像类的非结构化数据等，其特征描述依然制约着该方法
取与描述技术，如文本类的项采用了大量自然语言理解、信息 的应用效果；高维数据的相似性度量的稀疏性也极大地影响
检索等领域的相关技术，图像与视频类的项采用了数字图像 了推荐效果。基于内容的过滤还会忽略项目的多样性和流行
处理领域的相关技术。基于协同过滤的推荐系统则是利用相 度偏见，导致推荐的物品可能是重复的。
近兴趣或具有共同经验的群体喜好来推荐个体感兴趣的信 ２．２ 基于协同过滤的推荐技术
息。基于协同过滤的推荐系统主要采用矩阵分解或概率矩阵 协同过滤使用用户－项（Ｕｓｅｒ－Ｉｔｅｍ）二维评价矩阵来寻找
分解技术，其基本思想是构造用户－项目的评分矩阵，通过分 相似的用户。该类技术侧重于从数据中寻找某些隐含的模
解评分矩阵来获取未知项评分。传统的推荐技术在许多实际 式，并将用户和项的表达映射到隐含模式上。协同过滤主要
推荐系统中取得了良好的效果，但也存在许多需要解决的问 分为基于邻域的协同过滤和基于模型的协同过滤两大类。
题，如冷启动问题和数据稀疏问题。近年来，随着深度神经网 ２．２．１ 基于邻域的协同过滤技术
络、强化学习、图神经网络等技术的发展，基于机器学习技术 基于邻域的协同过滤主要通过已有评分来直接预测新的
的推荐系统得到了越来越多的关注。特别是大数据技术的出 评分，其中基于邻域的协同过滤分为基于用户的协同过滤与
现，使得推荐系统应用场景所积累的历史数据也有所增大。 基于项的协同过滤。
系统与系统之间也不再相互独立，系统可以获得大量相关的 基于用户的协同过滤方法应用时间较早，例如 Ｄａｖｉｄ
关联数据，使得机器学习技术获得了大量的可用数据。利用 等［６］首次提出基于用户的协同过滤并将其用于垃圾邮件过
大数据、机器学习技术可以捕捉到复杂的用户偏好信息。利 滤；Ｐａｕｌ等［７］于１９９４年利用该技术构建新闻过滤系统Ｇｒｏｕｐ－
用多系统的异构数据，推荐系统可以有效地解决传统推荐技 Ｌｅｎｓ。基于项的协同过滤方法适用于拥有大量数据基础的系
术中存在的冷启动和数据稀疏等问题，并且增加了推荐项目 统，例如Ｂａｄｒｕｌ等［８］提出了基于项的协同过滤方法，Ｇｒｅｇ
的多样性和准确性。 等［９］于２００３年将系统应用Ａｍａｚｏｎ商品系统。基于项的协
本文在介绍传统推荐技术的基础上，重点阐述了当前基
同过滤技术都曾广泛应用在Ｎｅｔｆｌｉｘ，Ｈｕｌｕ以及ＹｏｕＴｕｂｅ上。
于机器学习技术的推荐技术的进展。本文第２节简述了传统
基于用户的协同过滤方法可以发现用户的潜在偏好，但
推荐技术；第３节讨论了以深度学习为主的推荐技术；第４节
是存在冷启动问题且运算量较大。基于项的协同过滤方法基
介绍了基于强化学习与其他技术的推荐模型；第５节给出了
本不存在冷启动问题，而且在推荐时具有实时性，但是仅仅在
相关技术的分析比较；最后，回顾了整个推荐技术的发展，并
项的数量远少于用户数量的情况下，该方法才适用。这两种
展望推荐系统的未来发展方向。
方法在大规模环境下的推荐效率较低，只适用于小规模的场
２ 传统推荐技术
景。因此，基于邻域的协同过滤算法常见于早期的推荐系统
中，或用于数据量较小的情况。
推荐系统在最早期主要应用于电商类应用。系统通常被
２．２．２ 基于模型的协同过滤技术
设计为根据用户的购买历史或项目评级向用户推荐项目。早
基于模型的协同过滤通常对用户－项的关系建立某种关
期的推荐系统主要分为基于内容过滤的推荐系统、基于协同
联模型，通过最优化模型参数来获得项的最佳预测。典型的
过滤的推荐系统和混合推荐系统３类。
方法有基于矩阵因子分解的协同过滤方法和基于贝叶斯概率
２．１ 基于内容过滤的推荐技术
语言生成模型的协同过滤方法。基于矩阵因子分解的协同过
基于内容的推荐技术主要是利用推荐项的特征相似度进
滤方法主要采用矩阵分解技术将用户－项空间映射到低秩空
行推荐。该类方法通常提取项的特征来表示物品，利用用户
间，通过降低维度来更好地捕捉用户和项目的偏好特征表达。
历史评价数据（如喜欢／不喜欢的项特征数据）来学习该用户
该类方法采用的矩阵分解技术主要有ＳＶＤ［１０］，ＮＭＦ［１１］，
的偏好特征。最后通过比较用户的偏好特征与潜在的物品特
ＷＭＦ［１２］等。
征，来为用户推荐相关项。目前，常见的计算相似度的方法有
概率矩阵分解［１３］（Ｐｒｏｂａｂｉｌｉｓｔｉｃ Ｍａｔｒｉｘ Ｆａｃｔｏｒｉｚａｔｉｏｎ）由
余弦距离、相关性系数、ＫＬ距离等，以及项的特征描述技术，
于其丰富的语义表达能力，是处理基于模型的协同过滤问题
如ＴＦＩＤＦ，ｎ－ｇｒａｍ等。
的重要方法。首先，概率矩阵分解将矩阵中的元素Ｒ 看作用
基于内容的推荐技术的应用范围广泛，其可以处理文本
ｉｊ
户潜在偏好向量Ｕ和项潜在属性向量Ｖ的内积，并且服从均
类数据，例如Ｙａｈｙａ等［１］提出了 Ｗｅｂ挖掘的网页推荐系统， ｉ ｊ
Ｍａｎｊｕｌａ等［２］通过计算文本内容的相似度来推荐期刊，Ｓｕｎ
值为Ｕ ｉＴＶ ｊ、方差为σ的一个正态分布。那么，评分矩阵Ｒ的
条件概率如下：
等［３］提出了基于内容的个性化知识服务推荐算法ＣＲＯＡ等。
Ｎ Ｍ
推荐项也可以是非文本类数据，例如Ｙａｎｉｒ等［４］从文本的写 ｐ（Ｒ｜Ｕ，Ｖ，σ２）～∏ ∏Ｎ（Ｕ ＩＴＶ ｊ，σ２）Ｉｉｊ （１）
ｉ＝１ｊ＝１
作风格中推测情感的强烈级别，Ａｍｉｔ等［５］提出了基于图像的 然后，假设Ｕ和Ｖ相互独立，那么根据贝叶斯公式可得
内容推荐模型等。 出潜变量Ｕ，Ｖ的后验分布：
基于内容的推荐技术的优点是易于实现、具有良好的解 ｐ（Ｕ，Ｖ，Ｒ，σ２，σ２，σ２）
释性、不存在冷启动等问题。但是，该方法在提取特征以及度
ｐ（Ｕ，Ｖ｜Ｒ，σ２，σＶ２，σ Ｕ２）＝
ｐ（Ｒ，σ２，σ
Ｖ２，σＶ Ｕ２）Ｕ
量高维特征数据的相似性方面存在一定挑战。例如，对于文 ～ｐ（Ｒ｜Ｕ，Ｖ，σ２）ｐ（Ｕ｜σ２）ｐ（Ｖ｜σ２）
Ｕ Ｖ 刘君良，等：个性化推荐系统技术进展 ４９
＝ｐ（Ｒ｜Ｕ，Ｖ，σ２）×ｐ（Ｕ｜σ Ｕ２）×ｐ（Ｖ｜σ Ｖ２） （２） 表示两者关系的强度。Ｕ ｉ和Ｓ ｋ分别表示用户特定的特征向量
最终，将Ｒ，Ｕ，Ｖ的联合分布对数化，并为了限制评分的 和社会因素的特征向量。观察到的社交网络关系的条件分布
范围，将高斯函数的均值加入ｌｏｇｉｓｔｉｃ函数ｇ（ｘ）。最后能量 可以显示为：
的函数为： ｐ（Ｑ｜Ｕ，Ｓ，σ２ Ｑ）＝∏ｍ ∏ｍ Ｎ（ｑｉｊ｜ｇ（Ｕ ｉＴＳ ｋ），σ２ Ｑ）ＩｉＱ ｊ （４）
Ｅ（Ｕ，Ｖ）＝１ ２∑ ｉｊＩ ｉｊ（Ｒ ｉｊ－ｇ（Ｕ ｉＴＶ ｊ））２＋λ ２Ｕ∑ ｉＵ ｉＴＵ ｉ２＋ 通过贝叶斯定理ｉ 进＝１ｋ 行＝１ 推导，结合ＬＤＡ和ＳＭＦ得出：
λ
ｐ（Ｕ，Ｖ，Ｓ｜Ｑ，Ｒ，σ２ Ｑ，σ２ Ｒ，σ Ｕ２，σ Ｖ２，σ Ｓ２）∝ｐ（Ｒ｜Ｕ，Ｖ，σ２ Ｒ）ｐ（Ｑ｜
２Ｖ∑ ｉＶ ｉＴＶ ｉ２ （３）
Ｕ，Ｖ，σ２ Ｑ）×ｐ（Ｕ｜σＵ２）ｐ（Ｖ｜σＵ２）ｐ（Ｓ｜σＵ２） （５）
然后，使用梯度下降法求解Ｕ ｉ和Ｖ ｊ中的每一个元素。 学习完最佳参数后求解该模型。
传统的矩阵分解方法在矩阵数据过多或过于稀疏时效果 该模型的主要优点是可以自动推断有用的潜在主题和社
不佳，而概率矩阵分解缓解了这些问题。但是，概率矩阵分解 交信息，并且该模型的表现始终优于ＣＴＲ模型。因为该模型
技术也有需要改进的地方：１）可以用其他算法优化求解过程。 使用社交网络信息来更好地模拟用户潜在空间，即更好地模
例如最小二乘法、随机梯度下降法、最大期望法和马尔可夫链 拟来自类似朋友的用户偏好。但是，该模型建模所需的时间
蒙特卡罗算法等；２）没有考虑到评分过程中用户的个人偏好， 复杂度高于ＣＴＲ模型。
可以加入偏置，例如贝叶斯概率矩阵分解等；３）ＰＭＦ算法假 协同过滤技术有很多优点。第一，对于物品或用户不需
设所有用户都是独立的并且分布均匀，但这种假设在现实生 要建立复杂的模型，其可应用在很多领域并能在大部分场景
活中是不存在的。因此，在评分矩阵之外添加辅助信息是一 中产生较好的推荐结果。第二，协同过滤所推荐的物品不局
种解决方法。例如，Ｍａ等［１４］提出添加了社交邻域信息的概 限于类似物品，可以推荐内容上不相似的新颖物品。协同过
率矩阵推荐算法，通过使用用户的社交网络信息来处理数据 滤技术也存在很多缺点。第一，由于协同过滤技术是基于历
稀疏性问题；Ｗｕ等［１５］提出添加了物品自身含义的协同过滤 史数据来预测新的项，因此新用户会存在冷启动问题。ＰＭＦ
方法，使用知识图谱将语义数据嵌入一个低维的语义空间中。 和ＣＴＲ算法都是基于矩阵的算法，只是预测矩阵中“空白”位
这些手段都提升了推荐结果的准确性。此外，社交因素、浏览 置数据的方法不同。新的用户、物品在矩阵中没有评分数据，
记录、发表过的图片和评论都可以作为辅助数据来丰富矩阵。 因此无法对用户或者项进行推荐。第二，协同过滤技术如原
如今大部分基于模型的协同过滤算法都是从ＰＭＦ算法改进 始的矩阵分解技术等，普遍存在数据稀疏性问题，但ＰＭＦ算
而来的。 法及其改进算法有效地缓解了这个问题。第三，协同过滤推
基于贝叶斯概率语言生成模型的协同过滤是将潜在 荐的效果依赖于用户历史偏好数据的准确性，这一点是以
Ｄｉｒｉｃｈｌｅｔ分配［１６］和ＰＭＦ算法相结合，是一类对文字隐含主 ＰＭＦ技术为主的协作过滤推荐模型都存在的问题，只能在求
题进行建模的模型。Ｃｈｅｎ等［１７］提出了ＴＲＣＦ模型，以解决 解过程中加入一些约束条件来缓解。第四，协同过滤技术存
非常用评分项的数据稀疏问题等。Ｗａｎｇ等［１８］提出了一种模 在不够灵活和难于提供解释性等缺点。
型对内容信息进行充分的表示学习，以解决辅助信息稀疏时 ２．３ 混合推荐
的问题。这些模型都是在ＣＴＲ（Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｔｏｐｉｃ Ｒｅｇｒｅｓ－ 混合推荐（Ｈｙｂｒｉｄ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ）通过组合不同推荐
ｓｉｏｎ）模型的基础之上修改的。ＣＴＲ模型由于出众的性能被 系统来弥补各自推荐技术的弱点，从而达到更好的推荐效果。
广泛应用于其他语言生成模型。 其通常是将基于内容的推荐技术和协同过滤技术融合到一个
Ｗａｎｇ等［１９］提出了协作主题回归模型（ＣＴＲ）来推荐论文 模型中。例如，Ａｙｓｕｎ等［２１］提出了一种基于协同过滤和基于
和科学文章，协作主题回归模型假设项目潜在因素取决于文 内容过滤的混合推荐模型进行天气推荐；Ｖｉｐｕｌ等［２２］提出了
本的潜在主题分布，并在建模评级时添加潜在变量以抵消项 ＷｅｂＢｏｔ模型，将协作过滤和基于内容的过滤技术相混合来
目的主题分布。该算法可以同时发现根据相似用户来推荐的 推荐餐馆。
旧文章和反映用户偏好的新文章。最后，该算法还具有很好 在现实应用中，混合算法被大量应用于大型成熟网站、各
的解释性。 种手机软件等。混合推荐方法具有很多优势：１）通过集成学
协作主题回归模型将反馈矩阵和项目内容无缝集成到同 习来融合多种模型，以实现更高的准确性；２）混合模型没有冷
一模型中，解决了矩阵分解技术的难题。通过结合 Ｍａｔｒｉｘ 启动问题；３）能利用附加的信息，如推荐中可能会获取到除评
Ｆａｃｔｏｒｉｚａｔｉｏｎ技术（ＭＦ）和潜在Ｄｉｒｉｃｈｌｅｔ分配，ＣＴＲ实现了比 分以外的用户信息（如上下文信息、评论信息等），可以使推荐
基于ＭＦ的协同过滤更好的预测性能，并且其能够为用户建 结果更加丰富。但是混合推荐方法需要通过大量的调试工作
立标签，具有更好的可解释结果。此外，利用项目内容信息， 才能使模型平衡，需要耗费大量的时间和人力。
ＣＴＲ可以预测对于矩阵外项目的反馈。
３ 基于深度学习的推荐技术
Ｃｈｅｎ等［２０］提出了ＣＴＲ－ＳＭＦ模型，其将基于社会因素的
矩阵分解和ＣＴＲ模型进行结合以解决推荐问题。已知一个 随着深度学习的兴起，神经网络已经应用于各种推荐问
社交网络图Ｇ、顶点集Ｖ和矩阵Ｑ，Ｑ为社交网络图Ｇ的社交 题。例如，Ｃｈｅｎ等［２３］通过神经网络捕捉用户动态偏好的改
网络矩阵。Ｖ ｉ和Ｖ ｋ是一对顶点，ｑｉｋ表示用户ｉ与ｋ的关系，ｄ
ｉｋ
变来实时推荐项目；Ｎｉｕ等［２４］提出了ＮＰＲ模型用于提高社 ５０ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ 计算机科学 Ｖｏｌ．４７，Ｎｏ．７，Ｊｕｌｙ ２０２０
交网络中图像推荐的质量等。基于深度学习的推荐系统通过 能属于下一篮子的一组物品，即实际上不处理项目序列，而是
学习数据的潜在特征来捕捉用户深层次的偏好，与传统的协 处理篮子序列。例如，用户购买了一篮子物品，ＲＩＢ模型会推
作过滤相比可处理各类复杂的用户数据。常用于推荐系统中 荐这个篮子中的下一个物品，而Ｂｅａｃｏｎ模型会根据当前篮子
的深度学习模型有递归神经网络、卷积神经网络、生成式对抗 中的物品去推测下一次购物时用户购买的一篮子物品是什
网络等。 么。基于递归神经网络的推荐技术与基于相似度和基于矩阵
３．１ 基于递归神经网络的推荐技术 分解的方法相比有许多优点：１）基于递归神经网络的推荐技
基于递归神经网络（Ｒｅｃｕｒｓｉｖｅ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ）的推荐 术可以避免数据稀疏问题，并且加入了“时间”这个影响因素；
技术可以通过建模用户的历史序列行为来预测用户的下一个 ２）基于递归神经网络的推荐技术对推荐和短期预测的效果较
动作。递归神经网络及其变体长短期记忆网络（Ｌｏｎｇ Ｓｈｏｒｔ 好，但是递归神经网络在训练时会出现梯度膨胀或梯度消失
Ｔｅｒｍ Ｍｅｍｏｒｙ ｎｅｔｗｏｒｋｓ，ＬＳＴＭ）和门控循环单元（Ｇａｔｅｄ 问题，而且问题会随着网络层数的增加变得越来越明显，出现
Ｒｅｃｕｒｒｅｎｔ Ｕｎｉｔ，ＧＲＵ）也已被广泛应用于顺序推荐中。例如， 这种问题的原因是网络层数量太多，网络权值更新不稳定，可
Ｂａｌａｚｓ等［２５］利用ＧＲＵ提出基于会话的推荐模型；Ｙｕ等［２６］ 以使用不同的激活函数来缓解此问题。
提出了基于ＲＮＮ的动态递归篮模型，在学习用户的动态表 ３．２ 基于卷积神经网络的推荐技术
示的同时捕获篮子之间的全局顺序特性等。 卷积神经网络（Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ）是一类包
Ｚｈｏｕ等［２７］提出ＲＩＢ框架，其通过捕捉微观行为和顺序 含卷积计算且具有深度结构的前馈神经网络。基于卷积神经
建模用户信息来预测用户将要购买的物品。该框架考虑到用 网络的推荐系统主要是从数据中提取潜在因素和特征，如提
户浏览商品时的微观行为，将浏览的产品、用户的活动以及停 取图像、音频等非结构化数据的特征。例如，Ｗａｎｇ等［２９］提出
留时间作为模型的输入序列。该框架由５层组成：输入层的 了一种自动的ＣＮＮ图像分类推荐系统；Ｚｈｅｎｇ等［３０］利用两
输入是用户ｕ的ｎ个微观行为序列，定义为序列Ｓｕ＝｛ｘ， 个并行的ＣＮＮ从评论中提取语义信息，以获取用户和商品
１
ｘ，…，ｘ｝，其中每个ｘ 是一个元组；在嵌入层中将序列ｘ变 的潜在特征。
２ ｎ ｉ ｉ
成一个低维稠密向量ｅ ｔ，以解决数据稀疏和数据高维的问题； 在卷积神经网络及其变体方面，感知卷积网络（Ａ－ＣＮＮ）
在ＲＮＮ层捕捉序列的微观行为；在注意力层为每个隐藏单 和ＶＧＧＮｅｔ１６也被大量应用于各种模型。Ｍａ等［３１］提出
元分配适当的重量，有助于在输出层获得更平衡的输出。 ＣｏＡ－ＣＡＭＮ模型，即交叉注意记忆模型，通过ＶＧＧ－Ｎｅｔ１６提
ＲＩＢ框架有两个创新之处，首先是模拟了用户宏观动作 取出图片的内容并与推文结合，以捕获用户偏好。该模型分
中的顺序信息，其次是有效地捕捉了各种微观行为。但在捕 为３个部分，第１部分使用预先训练的ＶＧＧ－Ｎｅｔ１６来提取模
获模拟微观行为时有３个缺点：１）用户是一系列元组，因此用 型中图像的表示，包括给定推文和帖子历史的图像；第２部分
户表示或输入数据非常稀疏且高维；２）序列中的微观行为是 使用推文编码器来表示推文，在ＬＳＴＭ上使用共同注意机
相关的，无法对微观行为的序列信息进行建模；３）捕捉微观行 制，来提取文本信息的重要部分和推文的视觉信息；第３部分
为的难点在于处理用户的停留时间，停留时间的长短并不能 编码了用户的历史兴趣和候选用户的历史兴趣，借助新颖的
完全反馈出用户的喜好。 交叉注意机制来捕捉高质量的后期历史兴趣信息。
Ｄｕｃ－Ｔ等［２８］使用ＬＳＴＭ处理顺序信息并提出Ｂｅａｃｏｎ模 传统的基于ＣＮＮ的推荐模型只是简单地结合了文本特
型。该模型将用户的历史信息划分为组，即一个组为一个“篮 征向量和图像特征，但是正确的实体或有意义的内容通常仅
子”，篮子往往包含支持特定需求的相关项目组。模型通过收 与图像或文本的一小部分内容相关，因此使用矢量表示图像
集历史信息来预测下一篮子中的所有项目，主要由３个部分 或文本会产生不正确的预测。ＣｏＡ－ＣＡＭＮ结合了一种注意
组成：相关敏感篮子编码器、篮子序列编码器和相关敏感预测 机制来处理推文的文本信息和视觉信息，此模型可以关注推
器。首先，将篮子序列和相关矩阵作为输入，序列Ｓ表示篮 文的视觉和文本信息的重要部分，这几乎可以获取多模式推
子的时间顺序列表，Ｃ表示相关矩阵。然后，篮子编码器捕获 文的完整含义，可以将图像内容视为辅助信息来充分利用视
篮内物品相关性并将篮子编码器转换成二进制矢量。最后， 觉信息。
篮子表示的序列被进一步馈送到序列编码器中，以捕获篮间 Ｔａｎｇ等［３２］提出了Ｃａｓｅｒ的卷积序列嵌入模型，该方法提
的顺序关联。序列编码器的输出与相关矩阵一起被预测器用 供了一个统一的网络结构，结合卷积神经网络ＣＮＮ来学习
于产生下一个篮子。 顺序特征，并使用潜在因子模型ＬＦＭ来学习用户特定特征。
基于递归神经网络的推荐技术常被用于购物网站，递归 Ｃａｓｅｒ模型由３个部分组成：嵌入查找层、卷积层和完全连接
神经网络因其特性可以对时序信息进行建模。而在电子商务 层。嵌入查找层通过提取用户序列中的多个连续项，并将其
系统中，用户的浏览历史和用户动作序列的顺序会影响其购 嵌入到神经网络中来捕获潜在空间中的序列特征。卷积层将
买行为，因此推荐系统常使用ＲＮＮ获取用户的浏览历史和 顺序模式视为此局部特征的“图片”。连接层连接两个卷积层
顺序。ＲＩＢ模型和Ｂｅａｃｏｎ模型都利用了物品的序列关系进 的输出，并将它们反馈到一个完全连接的神经网络层，使用卷
行推荐，但两个模型的推荐思路不同。ＲＩＢ模型通过序列中 积过滤器将最近的行为建模为时间、潜在维度与学习顺序模
前几个物品的关系来预测序列中的下一个项目。而Ｂｅａｃｏｎ 式之间的“图片”。Ｃａｓｅｒ模型既可以进行跨平台的知识转移，
模型是将用户采用的一系列“篮子”作为输入，目标是预测可 又可以捕获用户－用户之间和用户－项目之间的相关性，是一 刘君良，等：个性化推荐系统技术进展 ５１
种较新的Ｔｏｐ－Ｎ推荐解决方案。 对抗来不断训练数据。
Ｌｉ等［３３］提出了一种基于神经序列的推荐模型———ＲＮＳ ＩＲＧＡＮ模型有以下两个优点：１）在判别式模型中引入文
模型，其利用用户评论进行预测。ＲＮＳ模型使用Ａ－ＣＮＮ来 本外的特征，例如行为特征等，丰富了数据来源；２）在生成式
提取用户评论的潜在因素、用户的内在偏好以及个人的时间 模型中，根据生成式模型的学习进度来控制生成样本的多样
偏好。首先利用评论分别形成用户文档和项目文档，将每个 性程度。因此，该模型的推荐效果良好。ＩＲＧＡＮ模型也存在
单词嵌入到序列中；然后采用分层关注注意机制捕获用户序 缺点，首先，生成式检索模型认为检索和文档之间存在潜在的
列模式，利用类似于彩色图像的多通道卷积操作进行特征提 生成过程，其缺点在于很难利用其他相关的信息，如点击文档
取；最后，该模型在获得该编码的时间顺序信息之后，将用户 的次数、文档和文档之间的内在联系等；其次，判别式检索模
的长期偏好和短期时间偏好相结合，以获得混合表示并提出 型同时将检索和文档作为特征，预测它们之间的相关性，其缺
更准确的下一项推荐。 点在于缺乏获取有用特征的方法。
使用深度学习技术来增强顺序推荐是一类常见的模型， Ｗｕ等［３５］使用ＧＡＮ构建了一个新的推荐模型———ＰＤ－
此类模型可以在不同的时间步骤对历史项目赋予不同的权 ＧＡＮ，以增加推荐结果的多样性，它由生成网络（生成器）和
重，以达到推荐的目的。ＲＮＳ模型的创新之处在于进行顺序 判别网络（鉴别器）相互竞争组成。如果在系统中有多个用
推荐的同时还考虑了用户的语义信息。该模型通过考虑一般 户、多个项目和多个项目类别，则该模型从每个用户的历史数
偏好和物品之间的顺序关系来动态地近似用户当前的偏好， 据中分别抽取不同类别下的项目。ＰＤ－ＧＡＮ的目的是生成
并且利用了用户评论信息。该模型是在顺序推荐领域中首个 前ｋ个既多样化又相互相关的推荐项。模型的生成器首先通
利用文本评论来获取语义的模型。 过矩阵分解评估所有项目的相关性，然后将相关性分数与预
基于卷积神经网络的推荐技术常用于社交媒体或含有图 先学习的ＤＰＰ模型相结合。ＰＤ－ＧＡＮ的鉴别器试图区分生
片信息的网站中。ＣＮＮ可以处理高清、内容丰富的图片信 成器生成的前ｋ项，通过对抗性学习，生成器能够生成一组不
息，因此使用该技术的推荐系统可以挖掘用户大量的背景信 同却相关的项目。ＰＤ－ＧＡＮ的生成器采用了ＤＰＰ模型来学
息，例如图片信息等，以进行更全面的推荐。除了提取非结构 习不同项目的一般共现情况，并结合用户的个性化偏好生成
性数据等丰富数据来源，基于卷积神经网络的推荐技术会考 既多样化又相关的推荐。
虑数据的顺序模式。顺序模式在推荐中是一个很重要的因 与ＩＲＧＡＮ模型相比，ＰＤ－ＧＡＮ模型的推荐结果更具多
素，序列中最近的交互物品对下一个物品的推荐有重要的影 样性。ＰＤ－ＧＡＮ模型同时考虑了两个方面，个人对个体项目
响。Ｃａｓｅｒ模型和ＲＮＳ模型都考虑了这一点。Ｃａｓｅｒ模型的 的偏好，以及个人对一组项目的喜好，在保持推荐结果相关性
主要思想是在时间和潜在空间上将最近一系列物品嵌入到一 的同时又保证了推荐的多样性。ＰＤ－ＧＡＮ模型在帮助网站
个图像中，然后用卷积过滤器学习顺序模式。ＲＮＳ模型也同 服务商探索用户的潜在利益方面发挥了重要作用。基于生成
样利用了用户行为中的行为顺序，但是并没有学习顺序模式， 式对抗网络的推荐技术是一种新兴的技术，由于生成式对抗
而是将用户历史购买物品的序列和用户的固有偏好融合进行 网络具有运行时间短、可以产生更好的样本、运算便捷等优
推荐。但是，基于卷积神经网络的推荐系统也存在一些缺点： 点，提高了推荐结果的精准性和多样性。并且，推荐结果的多
１）在建模时需要调参并且需要大量样本，因为当网络层数太 样化可以在扩大用户视野和帮助在线服务提供商探索用户的
多时，采用反向传播算法时修改参数会使靠近输入层的参数 潜在利益方面发挥重要作用，但是其同样存在不收敛、推荐结
改动较慢，而采用梯度下降算法时存在训练结果收敛于局部 果过于自由化等缺点。目前，生成式对抗网络还只是初步应
最小值的问题；２）ＲＮＮ在推荐系统中提取的数据特征是抽象 用在推荐系统中，随着对ＧＡＮ的深度研究，会有越来越多的
的，其物理含义不能得到很好的解释。 相关模型出现。
３．３ 基于生成式对抗网络的推荐技术
４ 其他推荐技术
生成式对抗网络（Ｇｅｎｅｒａｔｉｖｅ Ａｄｖｅｒｓａｒｉａｌ Ｎｅｔｗｏｒｋｓ）是一
种深度学习模型，该网络包括两个模块：基于生成式的网络学 ４．１ 基于强化学习的推荐技术
习模型以及基于判别式的网络学习模型。基于生成式对抗网 强化学习（Ｒｅｉｎｆｏｒｃｅｍｅｎｔ Ｌｅａｒｎｉｎｇ）是智能体（ａｇｅｎｔ）在
络的推荐系统通过两个模型的互相博弈来学习用户的历史数 与外界的交互过程中不断学习并成为最优策略的过程。基于
据，排列出前ｋ个用户感兴趣的项；基于生成式的模型算法有 强化学习的推荐系统可进行动态的推荐，即通过实时交互来
Ｄｅｅｐｗａｌｋ，Ｎｏｄｅ２ｖｅｃ，Ｍｅｔａｐａ－ｔｈ２ｖｅｃ等；基于判别式的模型算 调整推荐策略。例如 Ｗａｎｇ等［３６］提出了基于回归神经网络
法有ＤＮＧＲ，ＳＤＮＥ，Ｐｐｎｅ等。 的监督强化学习模型ＳＲＬ－ＲＮＮ，来进行个性化药物推荐；
Ｗａｎｇ等［３４］提出了ＩＲＧＡＮ模型，用于信息检索。该模 Ｚｈａｏ等［３７］提出了一种基于多智能体强化学习的深度链方
型借鉴了ＧＡＮ中生成器和判别器相互对抗的思想，将生成 法，能够捕获不同场景之间的顺序相关性，从而进行综合
检索模型和判别检索模型统一到一个框架中，并利用强化学 推荐。
习来训练生成器。ＩＲＧＡＮ模型首先选取相关的文档构成数 Ｚｈａｏ等［３８］提出了ＤＥＥＲＳ模型并利用强化学习找出学
据对并将其送入生成器中，然后根据生成的数据来训练判别 习的最优策略。该模型认为用户的浏览状态不仅应包含用户
器并最小化判别能力，从而完成一次对抗。该模型通过多次 单击或订购的正项，还应包含负（跳过）项。正状态ｓ＋表示用 ５２ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ 计算机科学 Ｖｏｌ．４７，Ｎｏ．７，Ｊｕｌｙ ２０２０
户之前点击或购买过的物品序列，负状态ｓ－表示之前略过的 术。最近，基于异构信息网络的推荐模型由于对复杂信息建
物品序列。其根据用户点击或跳过的行将推荐物品ａ为加入 模具有优势而备受关注。例如Ｓｈｉ等［４０］提出一种挖掘多个
到两个物品序列中，并使用ＧＲＵ处理两个序列中的物品，最 用户之间潜在结构的特征嵌入推荐模型 ＨＥＲｅｃ；Ｙｕ等［４１］提
后通过ＤＱＮ模型计算出Ｑ值。 出了通过 ＨＩＮ获取用户隐式偏好进行推荐的推荐系统；
传统的推荐模型将推荐过程视为静态过程，并只推荐当 Ｗａｎｇ等［４２］提出了基于 ＨＩＮ的音乐推荐系统（ＨＩＮ－ＭＲＳ）；
下收益最大的项。而该模型将推荐过程视为用户和ａｇｅｎｔ之 Ｗｕ等［４３］根据风险投资的特点提出了ＶＣ－Ｒｅｃｏｍ模型，以帮
间的顺序交互，并通过最大化用户的预期长期累积奖励来得 助投资企业找到合适的创业项目等。
出最佳推荐策略。除此之外，该模型还从用户的行动中捕获 Ｈｕ等［４４］基于上下文的元路径来建立一个三通道模型
正／负反馈，来调整推荐的策略。该模型将点击动作视为正反 ＭＣＲｅｃ。该模型用〈ｕｓｅｒ，ｍｅｔａ－ｐａｔｈ，ｉｔｅｍ〉三元组来将元路径
馈，将跳过行为视为负反馈，以帮助模型更好地理解用户偏 明确地合并到交互模型中，并通过 ＭＬＰ多层感知机来对项
好。但是，模型中用户跳过项目的原因有多种，并不能确定用 目进行打分，最后实现Ｔｏｐ－Ｎ推荐。这种方法能够从基于元
户的真实喜好，因此可以加入停留时间等其他因素来完善该 路径的上下文中有效地挖掘和提取有用信息，以提高推荐性
框架。 能。给定用户和项目之间的交互，我们可以得到用户、项目和
Ｚｏｕ等［３９］提出了ＦｅｅｄＲｅｃ模型，通过追踪马尔可夫过程 元路径连接的嵌入。通过这种方式，基于元路径上下文的表
来跟踪用户的兴趣转变，进行精准的推荐。该模型由两个网 征将更灵活，以适应不同的交互场景，从而为推荐结果提供良
络组成，即Ｑ网络和Ｓ网络，Ｑ网络负责建模复杂的用户行 好的可解释性，这使得基于ＨＩＮ的模型在一定程度上实现了
为，Ｓ网络用来模拟环境，协助Ｑ网络并消除策略中收敛的不 性能提升。该模型的新颖之处在于明确地表征基于元路径的
稳定性问题。生成过程如下：首先在Ｑ网络中获取用户的长 上下文，以改进交互的建模。此外，使用共同注意机制改进的
期历史行为信息，并将其顺序地输入原始行为嵌入层中；然后 交互嵌入算法，可使不同用户对原路径有不同的偏好。
经过ＬＳＴＭ处理送入Ｑ值层进行学习；最后将数据库中的数 Ｗａｎｇ等［４５］提出了基于 ＨＩＮ的单一嵌入模型 ＨｕｅＲｅｃ
据输入到Ｓ网络中，让其学习真正客户的反应，从而生成用户 用于推荐。该模型首先将用户和项目嵌入到一个统一的潜在
数据。Ｓ网络解决了Ｑ学习中出现的不稳定和分歧的问题。 空间中，然后设计了一个端到端的训练模型来提取信息和推
ＦｅｅｄＲｅｃ模型解决了如何收集长期用户行为特征的问 荐，以避免丢失信息，最后用注意机制来权衡用户对元路径的
题，传统的推荐系统需要大量的环境交互来模拟长期行为并 偏好。该模型认为用户或项目在不同元路径下存在一些共同
有效地训练ａｇｅｎｔ。而该模型通过ＬＳＴＭ建模一个用户行为 特征，因此模型使用元路径之间的相互关系来缓解一个元路
链，例如点击、跳过、浏览、排序、停留等动作，并可以模拟用户 径上的数据稀疏性和噪声问题。大多数基于 ＨＩＮ的推荐模
的长期行为来进行精准推荐，而不是仅考虑当下行为之后做 型总是对元路径下的用户和项目进行单独建模，这可能导致
出推荐。 信息提取错误并且丢失信息。而ＨｕｅＲｅｃ模型利用元路径之
对于以强化学习为主要技术的推荐模型，如何随着用户 间的相互关系来缓解单个元路径上的数据稀疏性和噪声问
行为和时间的动态变化来捕获最符合用户的偏好是最主要的 题，并且提高个性化推荐的效果。
挑战，本节中的两个模型，即ＤＥＥＲＳ模型和ＦｅｅｄＲｅｃ模型， ＭＣＲｅｃ模型使用元路径对用户和项进行建模。但是，该
分别从不同角度来解决该问题。ＤＥＥＲＳ模型通过用户的正 模型总是在每个元路径下对用户和项目进行单独建模，并没
负反馈来捕获用户的实时偏好，而ＦｅｅｄＲｅｃ模型则直接为用 有考虑到元路径之间的关系，这可能导致信息提取错误。而
户建模，记录用户的长期喜好，为用户推荐物品。从长期收益 ＨｕｅＲｅｃ模型考虑到每个用户或项在不同元路径下存在某些
的角度来看，ＦｅｅｄＲｅｃ模型的推荐效果更好。基于强化学习 共同特征，并使用来自所有元路径的数据来学习单一用户和
的推荐系统与传统的推荐系统相比有很多优点。传统的推荐 项目的表示，因此 ＨｕｅＲｅｃ模型的推荐效果优于 ＭＣＲｅｃ模
系统将推荐的过程视为静态的并根据已有的条件来进行推 型。基于异构信息网络的推荐系统与传统的推荐系统相比具
荐，只能推荐针对当下利益最大的项。而基于强化学习的推 有许多优点，因为其加入了更多的用户背景信息，并以元路径
荐系统能够在交互过程中不断更新策略，可以进行多轮推荐 的概念，使得基于异构信息网络的推荐系统在推荐效果、可解
直到系统收敛到最佳策略为止，因此可以生成最符合用户偏 释性、多样性上的表现都很好。但是，基于 ＨＩＮ的方法也有
好的动态推荐。并且，用户的行为特征反馈很好地解决了传 很多缺点：１）没有在推荐方法中学习路径或元路径的显式表
统推荐模型中数据稀疏的问题等。但是基于强化学习的推荐 示；２）很少考虑交互中元路径和涉及的用户－项对之间的相互
系统在真实环境上的表现并不出色，并且大部分模型都可以 影响。
看作是监督学习，因此强化学习在推荐系统上的应用还有很 ４．３ 基于其他框架的推荐技术
多问题需要解决。 Ｙａｎｇ等［４６］提出一个基于Ｐｙｔｈｏｎ的开放模块化框架
４．２ 基于异构网络的推荐技术 ＯｐｅｎＲｅｃ，以改善推荐系统的可扩展性和适应性问题。该模
异构信息网络（Ｈｅｔｅｒｏｇｅｎｅｏｕｓ Ｉｎｆｏｒｍａｔｉｏｎ Ｎｅｔｗｏｒｋ）可 型由３个部分抽象组成：模块、推荐器以及一组效用函数。模
以通过融合不同类型的数据，将用户不同类型的偏好集成到 块为每类算法组件提供标准输入／输出接口，推荐器提供了从
同一框架中，因此是解决推荐系统数据稀疏的另一种重要技 模块构建端到端系统的机制。该模型将每种推荐算法视为一 刘君良，等：个性化推荐系统技术进展 ５３
个模块，并通过一组接口组合在一起。 Ｚｈａｎｇ等［４８］提出了基于哈希码的深度学习框架 ＤＤＬ。
ＯｐｅｎＲｅｃ混合模型相比传统的推荐算法具有良好的适应 该模型是一种基于散列的混合推荐框架，由协作过滤和深度
性和扩展性。ＯｐｅｎＲｅｃ模型的适应性体现在没有场景的限 置信网络组成。通过联合优化基于ＤＢＮ的目标和基于ＣＦ
制，因此可以广泛用于各种推荐技术和场景，例如交互式、会 的目标来获得有效的哈希码，并计算用户和项目的哈希码之
话式和群组推荐。该模型的可扩展性体现在可以在现有模块 间的汉明距离来估计用户的偏好，从而进行建模。
的基础上开发新算法，因此该模型可以适用于大部分场景。 该框架的创新点在于使用了散列技术，该技术是将用户
与传统的推荐模型不同，该模型更像是一组标准，各种推荐算 和项编码为汉明空间中的二进制代码，通过计算汉明距离来
法可以融合到一起，为推荐算法提供了一种新的思路。 取代计算用户的偏好，可较好地解决推荐系统效率低下的问
Ｙｉ等［４７］提出了一个多指针共同注意网络模型 ＭＰＣＮ。 题。该技术有两个优点：１）使用在汉明空间内查找最近的邻
该模型从用户对项的评论中提取特征，首先将用户和项的文 居项技术来代替传统的按照预测偏好排序的技术，减小了时
字信息转化为序列，然后分别从每个用户和项目的输入序列 间复杂度；２）汉明空间存储二进制代码时只需要一位，节省了
中选择最具信息性的序列，并将其压缩为一个单独嵌入项，最 空间复杂度。
后使用多个指针，使最具信息性的评论能够用于预测并能实 随着用户个性化越来越被重视，推荐系统逐渐被大家研
现更深层次的单词级交互。该模型通过提取文本中的词来匹 究，因此除了主流的推荐技术外，还有许多其他技术被移植到
配需要推荐的物品。 推荐领域中，如文献［４７］与文献［４８］将指针技术和哈希码应
文献［４７］主要通过提取评论中的关键信息来获取用户的 用在了推荐系统中。并且，随着研究人员对推荐系统不同角
偏好，这种思路并不新颖，并且随着深度学习的兴起，各种利 度的理解，会有越来越多的技术应用在推荐系统中，这些技术
用评论推荐的创新模型逐渐被推出。但是，与传统模型不同， 的加入会推动推荐系统的发展。
该模型从评论中提取关键信息的技术有所提升。例如，该模 个性化推荐系统最早是为电子商务网站而制定的，根据
型对每个类别的评论都独立建模，并且每类评论的权重不同。 用户的喜好向用户推荐其感兴趣的商品。随着推荐系统的发
其利用了一种新颖的基于指针的学习方案，这不仅减少了噪 展，大量不同类型的推荐系统被应用在多个领域内，其中，运
音，还实现了用户和项目之间的深层词级交互。最重要的是， 用相似度技术、概率矩阵分解技术、神经网络、强化学习和异
用户和项目评论并没有以常见的压缩矢量来表示，而是以单词 构网络这５种技术的推荐系统的推荐效果最具有代表性。对
级别进行交互，这大大提升了从评论中提取有用信息的概率。 推荐系统不同时期的这５种技术进行对比总结，如表１所列。
表１ 推荐技术的比较
Ｔａｂｌｅ １ Ｃｏｍｐａｒｉｓｏｎ ｏｆ ｒｅｃｏｍｍｅｎｄｅｄ ｔｅｃｈｎｉｑｕｅｓ
技术 稀疏性 冷启动 可解释性 推荐效果
相似度 存在 存在 易于解释 只能推荐用户历史使用过的相关物品
从概率的角度解释
概率因子分解 存在 存在 无法处理较大的数据集，但在小数据集上表现较好
矩阵分解
对用户和项提取特征时效果较好，推荐结果丰富，
神经网络 部分存在 存在 存在解释问题
无扩展性
可以动态地推荐项目，需平衡未来最大收益与即时
强化学习 不存在 存在 易于解释
推荐项的关系
异构网络 不存在 可较好处理 存在解释 将不同类型的历史数据融合在一起，推荐结果丰富
结束语 推荐系统旨在帮助用户发现其可能感兴趣的 需要处理的难点。
项，已成为现代网站和各类软件必备的功能之一。目前，推荐 （３）新的基于神经网络模型的推荐系统。每个基于神经
系统获得了广泛的关注，并且有许多模型和算法被提出。虽 网络的推荐系统有单独的应用背景，因此单一模型不可能适
然目前的研究已取得了一定的成果，但仍然存在一些需要探 用于所有背景，需要根据不同的用处建立基于神经网络的模
索的问题，以下３点可能会成为主流的研究方向。 型，如商品推荐、影片推荐、视频推荐、场所推荐等。因此，基
（１）知识跨域迁移与异构网络。知识跨域迁移与异构网 于神经网络模型的推荐系统会被广泛应用。
络的结合可以在不同领域学习用户的历史数据。此类推荐系
参 考 文 献
统通过分析大量不同种类的历史数据来推荐新的项给用户。
与传统推荐系统相比，其推荐的效率更高，推荐的结果更具多 ［１］ ＹＡＨＹＡ Ａ Ｍ，ＭＤ Ｎ Ｓ，ＮＯＲＷＡＴＩ Ｍ，ｅｔ ａｌ．Ｉｍｐｒｏｖｅｄ ｗｅｂ
样性。但是，对于大量数据的处理，迁移与提取用户偏好将是 ｐａｇｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ ｂａｓｅｄ ｏｎ ｗｅｂ ｕｓａｇｅ ｍｉｎｉｎｇ［Ｃ］∥
该方向的几个难点。
Ｔｈｅ ３ｒｄ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｉｎｇ ａｎｄ Ｉｎｆｏｒｍａｔｉｃｓ
（２）基于强化学习的实时推荐。推荐过程是一个动态过 （ＩＣＯＣＩ）．２０１１：８－９．
程，基于强化学习的实时推荐系统可以在获取用户的实时反 ［２］ ＭＡＮＪＵＬＡ Ｗ，ＶＩＶＩＥＮ Ｐ，ＮＡＯＭＡＬ Ｄ，ｅｔ ａｌ．Ｓｅｌｅｃｔｉｎｇ ａ ｔｅｘｔ
馈后立即调整推荐目标，以提高推荐效果。对于此类推荐系 ｓｉｍｉｌａｒｉｔｙ ｍｅａｓｕｒｅ ｆｏｒ ａ ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ
统，即时捕获用户兴趣的改变，调整即将推荐项目的优先级是 ［Ｊ］．Ｔｈｅ Ｅｌｅｃｔｒｏｎｉｃ Ｌｉｂｒａｒｙ，２０１９，３７（３）：５０６－５２７． ５４ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ 计算机科学 Ｖｏｌ．４７，Ｎｏ．７，Ｊｕｌｙ ２０２０
［３］ ＳＵＮ Ｘ，ＸＵ Ｘ Ｌ，ｅｔ ａｌ．ＣＲＯＡ：Ａ Ｃｏｎｔｅｎｔ－Ｂａｓｅｄ Ｒｅｃｏｍｍｅｎｄａ－ ａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．２０１５：
ｔｉｏｎ Ｏｐｔｉｍｉｚａｔｉｏｎ Ａｌｇｏｒｉｔｈｍ ｆｏｒ Ｐｅｒｓｏｎａｌｉｚｅｄ Ｋｎｏｗｌｅｄｇｅ Ｓｅｒｖｉ－ １２３５－１２４４．
ｃｅｓ［Ｃ］∥２１ｓｔ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｈｉｇｈ Ｐｅｒｆｏｒｍａｎｃｅ ［１９］ＷＡＮＧ Ｃ，ＤＡＶＩＤ Ｍ Ｂ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｔｏｐｉｃ ｍｏｄｅｌｉｎｇ ｆｏｒ ｒｅｃｏｍ－
Ｃｏｍｐｕｔｉｎｇ ａｎｄ Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ．２０１９：８０４－８１０． ｍｅｎｄｉｎｇ ｓｃｉｅｎｔｉｆｉｃ ａｒｔｉｃｌｅｓ［Ｃ］∥ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｐａｔｔｅｒｎ
［４］ ＹＡＮＩＲ Ｓ，ＩＮＧＲＩＤ Ｚ，ＦＡＢＩＡＮ Ｂ，ｅｔ ａｌ．Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｉｎｆｅｒｅｎｃｅ Ａｎａｌｙｓｉｓ Ａｎｄｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ．２０１１：４４８－４５６．
ｏｆ Ｓｅｎｔｉｍｅｎｔｓ ｆｒｏｍ Ｔｅｘｔｓ［Ｃ］∥Ｔｈｅ １８ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅ－ ［２０］ＳＡＮＪＡＹ Ｐ，ＬＩＵ Ｙ．Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｔｏｐｉｃ Ｒｅｇｒｅｓｓｉｏｎ ｗｉｔｈ Ｓｏｃｉａｌ
ｒｅｎｃｅ．２０１０：１９５－２０６． Ｍａｔｒｉｘ Ｆａｃｔｏｒｉｚａｔｉｏｎ ｆｏｒ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ Ｓｙｓｔｅｍｓ［Ｃ］∥Ｔｈｅ
［５］ ＡＭＩＴ Ｋ Ｊ，ＬＩＵ Ｈ Ｍ，Ｉｎｇｏ Ｆ，ｅｔ ａｌ．Ｉｎｆｏｒｍａｔｉｏｎ Ｆｏｒａｇｉｎｇ ｆｏｒ ２９ｔｈＩｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．２０１２：１－８．
Ｅｎｈａｎｃｉｎｇ Ｉｍｐｌｉｃｉｔ Ｆｅｅｄｂａｃｋ ｉｎ Ｃｏｎｔｅｎｔ－ｂａｓｅｄ Ｉｍａｇｅ Ｒｅｃｏｍ－ ［２１］ＡＹＳＵＮ Ｂ，ＢＩＲＧＵＬ Ｋ．ＨｙｂＲｅｃＳｙｓ：Ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｃｏｎｔｅｘｔｕａｌ
ｍｅｎｄａｔｉｏｎ［Ｃ］∥ｔｈｅ １１ｔｈ Ｆｏｒｕｍ ｆｏｒ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ Ｅｖａ－ ｈｙｂｒｉｄ ｖｅｎｕｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ［Ｊ］．Ｊｏｕｒｎａｌ ｏｆ Ｉｎｆｏｒｍａｔｉｏｎ
ｌｕａｔｉｏｎ．２０１９：６５－６９． Ｓｃｉｅｎｃｅ，２０１９，４５（２）：２１２－２２６．
［６］ ＤＡＶＩＤ Ｇ，ＤＡＶＩＤ Ａ Ｎ，ＢＲＩＡＮ Ｍ Ｏ，ｅｔ ａｌ．Ｕｓｉｎｇ ｃｏｌｌ－ ［２２］ＶＩＰＵＬ Ｖ，ＫＵＬＫＡＲＮＩ Ｇ Ｒ．Ｈｙｂｒｉｄ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ：
ａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｔｏ ｗｅａｖｅ ａｎ ｉｎｆｏｒｍａｔｉｏｎ ｔａｐｅｓｔｒｙ［Ｃ］∥Ｃｏｍ－ Ｓｕｒｖｅｙ ａｎｄ Ｅｘｐｅｒｉｍｅｎｔｓ［Ｃ］∥ Ｔｈｅ ２０１２Ｄｉｇｉｔａｌ Ｉｎｆｏｒｍａｔｉｏｎ
ｍｕｎｉｃａｔｉｏｎｓ ｏｆ ｔｈｅ ＡＣＭ．１９９２：６１－７０． ａｎｄ Ｃｏｍｍｕｎｉｃａｔｉｏｎ Ｔｅｃｈｎｏｌｏｇｙ ａｎｄ ｉｔ’ｓ Ａｐｐｌｉｃａｔｉｏｎｓ（ＤＩＣＴ－
［７］ ＰＡＵＬ Ｒ，ＮＥＯＰＨＹＴＯＳ Ｌ，ＭＩＴＥＳＨ Ｓ，ｅｔ ａｌ．ＧｒｏｕｐＬｅｎｓ：ａｎ ＡＰ）．２０１２：４６９－４７３．
ｏｐｅｎ ａｒｃｈｉｔｅｃｔｕｒｅ ｆｏｒ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｏｆ ｎｅｔｎｅｗｓ［Ｃ］∥
［２３］ＣＨＥＮ Ｘ，ＸＵ Ｈ Ｔ，ＺＨＡＮＧ Ｙ Ｆ，ｅｔ ａｌ．Ｓｅｑｕｅｎｔｉａｌ ｒｅｃｏｍｍｅｎｄａ－
ＡＣＭ １９９４ Ｃｏｎｆｅｒｅｎｃｅ ｏｎＣｏｍｐｕｔｅｒ Ｓｕｐｐｏｒｔｅｄ Ｃｏｏｐｅｒａｔｉｖｅ
ｔｉｏｎ ｗｉｔｈ ｕｓｅｒ ｍｅｍｏｒｙ ｎｅｔｗｏｒｋｓ［Ｃ］∥Ｔｈｅ １１ｔｈ ＡＣＭ Ｉｎｔｅｒｎａ－
Ｗｏｒｋ．１９９４：１７５－１８６．
ｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．２０１８：１０８－
［８］ ＢＡＤＲＵＬ Ｍ，ＧＥＯＲＧＥ Ｋ，ＪＯＳＥＰＨ Ａ，ｅｔ ａｌ．Ｉｔｅｍ－ｂａｓｅｄ ｃｏｌｌａｂ－
１１６．
ｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｌｇｏｒｉｔｈｍｓ［Ｃ］∥Ｔｈｅ １０ｔｈ Ｉｎ－
［２４］ＮＩＵ Ｗ，ＪＡＭＥＳ Ｃ，ＬＵ Ｈ Ｋ，ｅｔ ａｌ．Ｎｅｕｒａｌ Ｐｅｒｓｏｎａｌｉｚｅｄ Ｒａｎｋｉｎｇ
ｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．２０１１：２８５－２９５．
ｆｏｒ Ｉｍａｇｅ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｃ］∥ｔｈｅ １１ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ
［９］ ＧＲＥＧ Ｌ，ＢＲＥＮＴ Ｓ，ＪＥＲＥＭＹ Ｙ，ｅｔ ａｌ．Ａｍａｚｏｎ．ｃｏｍ Ｒｅｃｏｍ－
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．２０１８：４２３－４３１．
ｍｅｎｄａｔｉｏｎｓ：Ｉｔｅｍ－ｔｏ－Ｉｔｅｍ Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｆｉｌｔｅｒｉｎｇ［Ｊ］．ＩＥＥＥ Ｉｎ－
［２５］ＢＡＬＡＺＳ Ｈ，ＡＬＥＸＡＮＤＲＯＳ Ｋ，ＬＩＮＡＳ Ｂ，ｅｔ ａｌ．Ｓｅｓｓｉｏｎ－ｂａｓｅｄ
ｔｅｒｎｅｔ Ｃｏｍｐｕｔｉｎｇ，２００３，７（１）：７６－８０．
ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ ｗｉｔｈ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ［Ｃ］∥Ｉｎｔｅｒｎａ－
［１０］ＹＥＨＵＤＡ Ｋ Ａ．Ｆａｃｔｏｒｉｚａｔｉｏｎ ｍｅｅｔｓ ｔｈｅｎ ｅｉｇｈｂｏｒｈｏｏｄ：ａ ｍｕｌｔｉ－
ｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅｏｎ Ｌｅａｒｎｉｎｇ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ．２０１６：１０－１５．
ｆａｃｅｔｅｄ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｍｏｄｅｌ［Ｃ］∥Ｔｈｅ １４ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ
［２６］ＹＵ Ｆ，ＬＩＵ Ｑ，ＷＵ Ｓ，ｅｔ ａｌ．Ａ ｄｙｎａｍｉｃ ｒｅｃｕｒｒｅｎｔ ｍｏｄｅｌ ｆｏｒ ｎｅｘｔ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．２００８：
ｂａｓｋｅｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｃ］∥Ｔｈｅ ３９ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩ－
４２６－４３４．
ＧＩＲ ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ
［１１］ＤＡＮＬＥＬ Ｄ Ｌ，ＳＥＢＡＳＴＩＡＮ Ｓ．Ｌｅａｒｎｉｎｇ ｔｈｅ ｐａｒｔｓ ｏｆ ｏｂｊｅｃｔｓ ｂｙ
Ｒｅｔｒｉｅｖａｌ．２０１６：７２９－７３２．
ｎｏｎ－ｎｅｇａｔｉｖｅ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ［Ｃ］∥Ｎａｔｕｒｅ．１９９９：７８８－７９１．
［２７］ＺＨＯＵ Ｍ Ｚ，ＤＩＮＧ Ｚ Ｙ，ＴＡＮＧ Ｊ Ｌ，ｅｔ ａｌ．Ｍｉｃｒｏ Ｂｅｈａｖｉｏｒｓ：Ａ
［１２］ＰＡＮＲ，ＺＨＯＵ Ｙ Ｈ，ＣＡＯ Ｂ，ｅｔ ａｌ．Ｏｎｅ－ｃｌａｓｓ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅ－
Ｎｅｗ Ｐｅｒｓｐｅｃｔｉｖｅｉｎ Ｅｃｏｍｍｅｒｃｅ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ［Ｃ］∥
ｒｉｎｇ［Ｃ］∥Ｔｈｅ ２００８ ８ｔｈ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｄａｔａ
Ｔｈｅ １１ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａ－
Ｍｉｎｉｎｇ．２００８：１－２５．
ｔａ Ｍｉｎｉｎｇ．２０１８：７２７－７３５．
［１３］ＲＵＳＬＡＮ Ｓ，ＡＮＤＲＩＹ Ｍ，ｅｔ ａｌ．Ｐｒｏｂａｂｉｌｉｓｔｉｃ Ｍａｔｒｉｘ Ｆａｃｔｏｒｉｚａ－
［２８］ＤＵＣ Ｔ Ｌ，ＨＡＤＹ Ｗ Ｌ，ＦＡＮＧ Ｙ．Ｃｏｒｒｅｌａｔｉｏｎ－Ｓｅｎｓｉｔｉｖｅ Ｎｅｘｔ－
ｔｉｏｎ［Ｃ］∥Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ
Ｂａｓｋｅｔ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｃ］∥Ｔｈｅ ２８ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ
２０．２００７：１－８．
［１４］ＭＡ Ｈ，ＩＲＷＩＮ Ｋ，ＭＩＣＨＡＥＬ Ｒ Ｌ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ ｔｏ Ｒｅｃｏｍ－
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．２０１９：２８０８－２８１４．
ｍｅｎｄ ｗｉｔｈ Ｓｏｃｉａｌ Ｔｒｕｓｔ Ｅｎｓｅｍｂｌｅ［Ｃ］∥Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ［２９］ＷＡＮＧ Ｓ，ＳＵＮ Ｌ，ＦＡＮ Ｗ，ｅｔ ａｌ．Ａｎ ａｕｔｏｍａｔｅｄ ＣＮＮ ｒｅｃｏｍ－
ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．２００９： ｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ ｆｏｒ ｉｍａｇｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｔａｓｋｓ［Ｃ］∥２０１７
２０３－２１０．
ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍｕｌｔｉｍｅｄｉａ ａｎｄ Ｅｘｐｏ．２０１７：
［１５］ＷＵ Ｘ Ｙ，ＣＨＥＮ Ｑ Ｍ，ＬＩＵ Ｈ，ｅｔ ａｌ．Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｆｉｌｔｅｒｉｎｇ ２８３－２８８．
Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ Ａｌｇｏｒｉｔｈｍ Ｂａｓｅｄ ｏｎ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ Ｌｅａｒｎｉｎｇ ［３０］ＺＨＥＮＧ Ｌ，ＶＡＨＩＤ Ｎ，ＰＨＩＬＩＰ Ｓ Ｙ，ｅｔ ａｌ．Ｊｏｉｎｔ ｄｅｅｐ ｍｏｄｅｌｉｎｇ
ｏｆ Ｋｎｏｗｌｅｄｇｅ Ｇｒａｐｈ［Ｊ］．Ｃｏｍｐｕｔｅｒ Ｅｎｇｉｎｅｅｒｉｎｇ，２０１８，４４（２）： ｏｆ ｕｓｅｒｓ ａｎｄ ｉｔｅｍｓ ｕｓｉｎｇ ｒｅｖｉｅｗｓ ｆｏｒ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｃ］∥Ｔｈｅ
２２６－２３２，２６３． １１ｔｈＡＣＭＩｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ
［１６］ＤＡＶＩＤ Ｍ Ｂ，ＡＮＤＲＥＷ Ｙ，ｅｔ ａｌ．Ｌａｔｅｎｔ Ｄｉｒｉｃｈｌｅｔ Ａｌｌｏｃａｔｉｏｎ Ｍｉｎｉｎｇ．２０１７：４２５－４３４．
［Ｃ］∥Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ．２００３：９９３－１０２２． ［３１］ＭＡ Ｒ Ｆ，ＺＨＡＮＧ Ｑ，ＷＡＮＧ Ｊ Ｗ，ｅｔ ａｌ．Ｍｅｎｔｉｏｎ Ｒｅｃｏｍｍｅｎｄａ－
［１７］ＣＨＥＮ Ｃ Ｃ，ＺＨＥＮＧ Ｘ Ｌ，ＷＡＮＧ Ｙ，ｅｔ ａｌ．Ｃａｐｔｕｒｉｎｇ Ｓｅｍａｎｔｉｃ ｔｉｏｎ ｆｏｒ Ｍｕｌｔｉｍｏｄａｌ Ｍｉｃｒｏｂｌｏｇ ｗｉｔｈ Ｃｒｏｓｓ－ａｔｔｅｎｔｉｏｎ Ｍｅｍｏｒｙ
Ｃｏｒｒｅｌａｔｉｏｎ ｆｏｒ Ｉｔｅｍ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｉｎ Ｔａｇｇｉｎｇ Ｓｙｓｔｅｍｓ Ｎｅｔｗｏｒｋ［Ｃ］∥Ｔｈｅ ４１ｓｔ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ
［Ｃ］∥Ｔｈｅ １３ｔｈ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ． ｏｎ Ｒｅｓｅａｒｃｈ ＆ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．２０１８：
２０１６：１０８－１１４． １９５－２０４．
［１８］ＷＡＮＧ Ｈ，ＷＡＮＧ Ｎ Ｙ．Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｄｅｅｐ Ｌｅａｒｎｉｎｇ ｆｏｒ Ｒｅｃ－ ［３２］ＴＡＮＧ Ｊ Ｘ，ＷＡＮＧ Ｋ．Ｐｅｒｓｏｎａｌｉｚｅｄ Ｔｏｐ－Ｎ Ｓｅｑｕｅｎｔｉａｌ Ｒｅｃｏｍ－
ｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ［Ｃ］∥Ｔｈｅ ２１ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎ－ ｍｅｎｄａｔｉｏｎ ｖｉａ ＣｏｎｖｏｌｕｔｉｏｎａｌＳｅｑｕｅｎｃｅ Ｅｍｂｅｄｄｉｎｇ［Ｃ］∥１１ｔｈ 刘君良，等：个性化推荐系统技术进展 ５５
ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎ－ ［４２］ＷＡＮＧ Ｒ Ｒ，ＭＡ Ｘ，ＪＩＡＮＧ Ｃ，ｅｔ ａｌ．Ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｉｎｆｏｒｍａｔｉｏｎ
ｉｎｇ．２０１８：５６５－５７３． ｎｅｔｗｏｒｋ－ｂａｓｅｄ ｍｕｓｉｃ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ ｉｎ ｍｏｂｉｌｅ ｎｅｔ－
［３３］ＬＩ Ｃ Ｌ，ＮＩＵ Ｘ Ｃ，ＬＵＯ Ｘ Ｙ，ｅｔ ａｌ．Ａ Ｒｅｖｉｅｗ－Ｄｒｉｖｅｎ Ｎｅｕｒａｌ ｗｏｒｋｓ［Ｊ］．Ｃｏｍｐｕｔｅｒ Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ，２０２０，１５０（１）：４２９－４３７．
Ｍｏｄｅｌ ｆｏｒ Ｓｅｑｕｅｎｔｉａｌ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｃ］∥Ｔｈｅ ２８ｔｈ Ｉｎｔｅｒｎａ－ ［４３］ＷＵ Ｓ，ＬＩ Ｈ Ｆ，ＬＩＵ Ｌ，ｅｔ ａｌ．Ａ Ｖｅｎｔｕｒｅ Ｃａｐｉｔａｌ Ｒｅｃｏｍｍｅｎｄａ－
ｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ Ｍａｉｎ Ｔｒａｃｋ． ｔｉｏｎ Ａｌｇｏｒｉｔｈｍ ｂａｓｅｄ ｏｎ Ｈｅｔｅｒｏｇｅｎｅｏｕｓ Ｉｎｆｏｒｍａｔｉｏｎ Ｎｅｔｗｏｒｋ
２０１９：２８６６－２８７２． ［Ｊ］．Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ ＆
［３４］ＷＡＮＧ Ｊ，ＹＵ Ｌ Ｔ，ＺＨＡＮＧ Ｗ Ｎ，ｅｔ ａｌ．ＩＲＧＡＨ：Ａ Ｍｉｎｉｍａｘ Ｃｏｎｔｒｏｌ，２０２０，１５（１）：１－８．
Ｇａｍｅ ｆｏｒ Ｕｎｉｆｙｉｎｇ Ｇｅｎｅｒａｔｉｖｅ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ Ｍｏｄｅｌｓ ［４４］ＨＵ Ｂ Ｂ，ＳＨＩ Ｃ．Ｌｅｖｅｒａｇｉｎｇ Ｍｅｔａ－ｐａｔｈｂａｓｅｄ Ｃｏｎｔｅｘｔ ｆｏｒ Ｔｏｐ－Ｎ
［Ｃ］∥Ｔｈｅ ４０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅ－ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｗｉｔｈ ＡＮｅｕｒａｌ Ｃｏ－Ａｔｔｅｎｔｉｏｎ Ｍｏｄｅｌ［Ｃ］∥Ｔｈｅ
ｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ．２０１７：５１５－５２４． ２４ｔｈ ＡＣＭＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓ－
［３５］ＷＵ Ｑ，ＬＩＵ Ｙ，ＭＩＡＯ Ｃ Ｙ，ｅｔ ａｌ．ＰＤ－ＧＡＮ：Ａｄｖｅｒｓａｒｉａｌ Ｌｅａｒｎ－ ｃｏｖｅｒｙ ＆Ｄａｔａ Ｍｉｎｉｎｇ．２０１８：１５３１－１５４０．
ｉｎｇ ｆｏｒ Ｐｅｒｓｏｎａｌｉｚｅｄ Ｄｉｖｅｒｓｉｔｙ－Ｐｒｏｍｏｔｉｎｇ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ［４５］ＷＡＮＧ Ｚ Ｋ，ＬＩＵ Ｈ Ｚ，ＤＵ Ｙ Ｐ，ｅｔ ａｌ．Ｕｎｉｆｉｅｄ Ｅｍｂｅｄｄｉｎｇ Ｍｏｄｅｌ
［Ｃ］∥Ｔｈｅ ２８ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎ－ ｏｖｅｒ Ｈｅｔｅｒｏｇｅｎｅｏｕｓ Ｉｎｆｏｒｍａｔｉｏｎ Ｎｅｔｗｏｒｋ ｆｏｒ Ｐｅｒｓｏｎａｌｉｚｅｄ Ｒｅｃ－
ｔｅｌｌｉｇｅｎｃｅ Ｍａｉｎ ｔｒａｃｋ．２０１９：３８７０－３８７６． ｏｍｍｅｎｄａｔｉｏｎ［Ｃ］∥Ｔｈｅ ２８ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．２０１９：３８１３－３８１９．
［３６］ＷＡＮＧ Ｌ，ＺＨＡＮＧ Ｗ，ＨＥ Ｘ Ｆ，ｅｔ ａｌ．Ｓｕｐｅｒｖｉｓｅｄ Ｒｅｉｎｆｏｒｃｅｍｅｎｔ
［４６］ＹＡＮＧ Ｌ Ｑ，ＥＵＧＥＮＥ Ｂ，ＪＯＳＨＵＡ Ｇ，ｅｔ ａｌ．ＯｐｅｎＲｅｃ：Ａ Ｍｏｄｕ－
Ｌｅａｒｎｉｎｇ ｗｉｔｈ Ｒｅｃｕｒｒｅｎｔ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ ｆｏｒ Ｄｙｎａｍｉｃ Ｔｒｅａｔ－
ｌａｒ Ｆｒａｍｅｗｏｒｋ ｆｏｒ Ｅｘｔｅｎｓｉｂｌｅ ａｎｄ Ａｄａｐｔａｂｌｅ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ
ｍｅｎｔ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｃ］∥２４ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ
Ａｌｇｏｒｉｔｈｍｓ［Ｃ］∥Ｔｈｅ １１ｔｈ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ＆ Ｄａｔａ Ｍｉｎｉｎｇ．２０１９：
ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．２０１８：６６４－６７２．
２４４７－２４５６．
［４７］ＹＩ Ｔ，ＡＮＨ Ｔ Ｌ．Ｍｕｌｔｉ－Ｐｏｉｎｔｅｒ Ｃｏ－Ａｔｔｅｎｔｉｏｎ Ｎｅｔｗｏｒｋｓ ｆｏｒ Ｒｅｃ－
［３７］ＺＨＡＯ Ｘ Ｙ，ＸＩＡ Ｌ，ＹＩＮ Ｄ Ｗ，ｅｔ ａｌ．Ｍｏｄｅｌ－Ｂａｓｅｄ Ｒｅｉｎｆｏｒｃｅ－
ｏｍｍｅｎｄａｔｉｏｎ［Ｃ］∥Ｔｈｅ ２４ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎ－
ｍｅｎｔ Ｌｅａｒｎｉｎｇ ｆｏｒ Ｗｈｏｌｅ－Ｃｈａｉｎ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ［Ｃ］∥Ｔｈｅ
ｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ＆ Ｄａｔａ Ｍｉｎｉｎｇ．２０１８：２３０９－
１３ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ
２３１８．
Ｍｉｎｉｎｇ．２０１９：４－８．
［４８］ＺＨＡＮＧ Ｙ，ＹＩＮ Ｈ Ｚ，ＨＵＡＮＧ Ｚ，ｅｔ ａｌ．Ｄｉｓｃｒｅｔｅ Ｄｅｅｐ Ｌｅａｒｎｉｎｇ
［３８］ＺＨＡＯ Ｘ Ｙ，ＺＨＡＮＧ Ｌ，ＤＩＮＧ Ｚ Ｙ，ｅｔ ａｌ．Ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ ｆｏｒ Ｆａｓｔ Ｃｏｎｔｅｎｔ－Ａｗａｒｅ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｃ］∥Ｔｈｅ １１ｔｈ ＡＣＭ
ｗｉｔｈ Ｎｅｇａｔｉｖｅ Ｆｅｅｄｂａｃｋ ｖｉａ Ｐａｉｒｗｉｓｅ Ｄｅｅｐ Ｒｅｉｎｆｏｒｃｅｍｅｎｔ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．２０１８：
Ｌｅａｒｎｉｎｇ［Ｃ］∥Ｔｈｅ ２４ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒ－ ７１７－７２６．
ｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ＆Ｄａｔａ Ｍｉｎｉｎｇ．２０１８：１０４０－１０４８．
［３９］ＺＯＵ Ｌ Ｘ，ＸＩＡ Ｌ，ＤＩＮＧ Ｚ Ｙ，ｅｔ ａｌ．Ｒｅｉｎｆｏｒｃｅｍｅｎｔ Ｌｅａｒｎｉｎｇ ｔｏ ＬＩＵ Ｊｕｎ－ｌｉａｎｇ，ｂｏｒｎ ｉｎ １９９６，ｐｏｓｔｇｒａ－
Ｏｐｔｉｍｉｚｅ Ｌｏｎｇ－ｔｅｒｍ Ｕｓｅｒ Ｅｎｇａｇｅｍｅｎｔ ｉｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓ－ ｄｕａｔｅ．Ｈｉｓ ｍａｉｎ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎ－
ｔｅｍｓ［Ｃ］∥Ｔｈｅ ２５ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｃｌｕｄｅ ｒｅｃｏｍｍｅｎｄｅｄ ａｌｇｏｒｉｔｈｍ ａｎｄ ｒｅｉｎ－
ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ＆Ｄａｔａ Ｍｉｎｉｎｇ．２０１９：２８１０－２８１８． ｆｏｒｃｅｍｅｎｔ ｌｅａｒｎｉｎｇ．
［４０］ＳＨＩ Ｃ，ＬＩＵ Ｊ，ＺＨＵＡＮＧ Ｆ Ｚ，ｅｔ ａｌ．Ｉｎｔｅｇｒａｔｉｎｇ ｈｅｔｅｒｏｇｅｎｅｏｕｓ
ｉｎｆｏｒｍａｔｉｏｎ ｖｉａｅｘｉｂｌｅ ｒｅｇｕｌａｒｉｚａｔｉｏｎ ｆｒａｍｅｗｏｒｋ ｆｏｒ ｒｅｃｏｍｍｅｎ－
ｄａｔｉｏｎ［Ｍ］．Ｋｎｏｗｌｅｄｇｅａｎｄ Ｉｎｆｏｒｍａｔｉｏｎ Ｓｙｓｔｅｍｓ，２０１６：８３５－ ＬＩ Ｘｉａｏ－ｇｕａｎｇ，ｂｏｒｎ ｉｎ １９７３，Ｐｈ．Ｄ，ｐｒｏ－
８５９． ｆｅｓｓｏｒ，ｉｓ ａ ｍｅｍｂｅｒ ｏｆ Ｃｈｉｎａ Ｃｏｍｐｕｔｅｒ
［４１］ＹＵ Ｘ，ＲＥＮ Ｘ，ＳＵＮ Ｙ Ｚ，ｅｔ ａｌ．Ｐｅｒｓｏｎａｌｉｚｅｄ ｅｎｔｉｔｙ ｒｅｃｏｍｍｅｎ－ Ｆｅｄｅｒａｔｉｏｎ．Ｈｉｓ ｍａｉｎ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓ－
ｄａｔｉｏｎ：Ａ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋ ａｐｐｒｏａｃｈ［Ｃ］∥ ｔｉｎｇｓ ｉｎｃｌｕｄｅ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ａｎｄ ｄａｔａ
Ｔｈｅ ７ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ ｍｉｎｉｎｇ．
Ｍｉｎｉｎｇ．２０１４：２８３－２９２． ---------------------------------------------------------------------------------          一    ，             一 面                 
   用司     如 ，，      ，    ，                 卜        二刀   ‘      
                       以玲            欧    一  石       
   加 如    如办栩陀，     加         恻  灸                   
互联网推荐系统比较研究’
许海玲’ ， 吴 潇’， 李晓东’， 阎保平’ 
仗中国科学院 计算机网络信息中心       实验室，北京        
  中国科学院 计算技术研究所 智能信息处理重点实验室，北京        
  中国科学院 计算机网络信息中心，北京        
                                              
     一      ，        ，       一     ，       一     · 
  加加  。叮       ，          幻胃 浅     ”           ，仆。          “              ，             ，      
         橄。口   。肠 一            ‘   卜        ，             帅        加。一。盯，几     。阴  “              ，       
      ，伪    
，           。即 浅                ’ 仆         恤           ，       一     ，      
十   ， 即碱                回               
    ，    ，    ，                一                                       “蒯   及幼加 ， ，
    声          ‘       刀      “    留     一             
  一                           传                                                  而               
             山                                                           ，                                
山 阴  ，                    ，                                                                       
                      ，                                                                         ，    
               比                                                                               
                       
心     一                                        ”                                                     
摘 要  全面地总结推荐系统的研究现状，旨在介绍网络推荐的算法思想、 帮助读者了解这个研究领城 首先阐述
了推荐系统研究的工业常求、主要研究机构和成果发表的期刊会议 在讨论了推荐问题的形式化和非形式化定义之
后，对主流算法进行了分类和对比 最后总结了常用数据集和评测指标，领城的重难点问题和未来可能的研究热点 
关扭词  推荐系统 杜会网络 信息过载 协同过滤 个性化
中圈法分类号       文献标识码  
·       比                 旧         朋                                  ，        ，         国家自然科学基
金  阮                 盯                  时                   一   国家重点基础研究发展计划                  
    ·介                               叨                        国家高技术研究发展计划          红       
 朋  如。 卜，滋口  ‘ 伪访“  人耐             助                  夕     中国科学院知识创新工程青年人才领域前
沿项目             洲                姗          盯                             北京市科技新星计划 
             刁 一        时     一  一  许海玲 等 互联网推荐系统比较研究    
互联网规模和覆盖面的迅速增长带来了信息超载                      的问题 过量信息同时呈现使得用
户无法从中获取对自己有用的部分，信息使用效率反而降低 现有的很多网络应用，比如门户网站、 搜索引擎和
专业数据索引本质上都是帮助用户过滤信息的手段 然而这些工具只满足主流需求，没有个性化的考虑，仍然无
法很好地解决信息超载的问题 推荐系统                  作为一种信息过滤的重要手段，是当前解决信息
超载问题的非常有潜力的方法 推荐系统与以搜索引擎为代表的信息检索                       系统最大的区
别在于   搜索注重结果 如网页 之间的关系和排序，推荐还研究用户模型              和用户的喜好，基于社
会网络                进行个性化的计算                     搜索的进行由用户主导，包括输入查询词和选择
结果，结果不好用户会修改查询再次搜索 而推荐是由系统主导用户的浏览顺序，引导用户发现需要的结果 高
质量的推荐系统会使用户对该系统产生依赖 因此，推荐系统不仅能够为用户提供个性化的服务，而且能够与用
户建立长期稳定的关系，提高用户忠诚度，防止用户流失 
推荐系统最典型的应用是在     电子商务领域，具有良好的发展和应用前景，商家根据用户的兴趣、 爱好
推荐顾客可能感兴趣或满意的商品 如书籍、 音像等  顾客的需求通常是不明确的、 模糊的，如果商家能够把满
足用户模糊需求的商品推荐给用户，就可以把用户的潜在需求转化为现实需求，从而达到提高产品销售量的目
的 目前，几乎所有的大型电子商务系统，如       ，     等，都不同程度地使用了各种形式的推荐系统 其中
      研究电子商务的推荐系统长达   年时间 各种提供个性化服务的   站点，如电影、 音乐网站，也需要
推荐系统的大力支持 表  中按照应用领域分类列举了一些典型的商用推荐系统 
介          能              坛                   
表   主流的商用推荐系统一览表
产     
   刃。 代 以 邵       刀刀               
 一  刃 扣  代   国    叨 ，    ，     ，   一          
           ，      ‘  宜   ，      ，        ，           ，    ，         ，   ，        ，     月 
 助        ，      形   ，     · 比  ·   
         五   伪 入     仙      ，         ，        
    
在学术界，自  世纪  年代中期出现第一批关于协同过滤的文章 ’一  以来，推荐系统在电子商务、 网络经
济学和人类社会学等领域一直保持很高的研究热度并逐渐成为一门独立的学科 各种推荐算法涵盖包括认知
科学、 近似性理论、 信息检索 ’ 、 管理科学   、 市场营销建模   等在内的众多研究领域 ，  近几年来，国际学术
界针对计算机网络信息整合的推荐相关的研究大量出现        设立推荐系统年会               
            计算机领域的人机交互、 数据挖掘和机器学习顶级会议       ，   ，     ，    等 中，推荐算
法的文章逐年增加   国际数据分析领域的高阶期刊 如                                           ，   
                          等 刊载数篇推荐系统方面的文章 信息领域做推荐系统领先的研究单位 学者 包
括 纽约大学                   、 明尼苏达州立大学的   叩    研究小组        ，       ，         等 、
美国密歇根大学             、 卡内基梅隆大学             、 微软研究院              等 其中，美国密歇
根大学在    年开授了由           主讲的推荐系统的课程 推荐系统，结合社会网络和语义网络的研究，面
向互联网发展中出现的新问题和新技术需求，具有广泛的研究和应用前景
本研究调研了推荐系统在计算机网络和信息领域的主流研究与应用进展 本文第  节中给出推荐系统的
形式化定义 第  节根据推荐算法的类别分类陈述最新的学术进展 第  节讨论使用的数据集以及实验评测方
法，对当前推荐系统的研究难点进行归纳并对比各种推荐方法的优、 缺点 第   节对推荐系统有待深入的研究
点和发展趋势进行初步预测 
推荐系统概念和形式化定义
目前被广泛引用的推荐系统的非形式化概念是        和        在      年   给出的 “它是利用电子商务
网站向客户提供商品信息和建议，希助用户决定应该购买什么产品，模拟销售人员帮助客户完成购买过程” 推       “、       伽口   软件学报      ，     ，      脚  以为
荐有 个组成要素 推荐候选对象、 用户、 推荐方法 通用的推荐系统模型流程如图  所示 用户可以向推荐系
统主动提供个人偏好信息或推荐请求，或者用户不提供，而是推荐系统主动采集 推荐系统可以使用不同的推荐
策略进行推荐，如将采集到的个性化信息和对象数据进行计算得到推荐结果，或者直接基于已建模的知识数据
库进行推荐 推荐系统将推荐结果返回给用户使用 
                                      
图  推荐系统通用模型
此外，文献【  给出了推荐系统的形式化定义 设 是所有用户      的集合， 是所有可以推荐给用户的对象
 喇    的集合 实际中， 和  集合的规模通常很大，如上百万的顾客以及上亿种歌曲等 设效用函数    可以计
算对象，对用户。 的推荐度 如提供商的可靠性                 刃和产品的可得性恤                  等 ，即“ 
。 心砷况尹是一定范围内的全序的非负实数，推荐要研究的问题就是找到推荐度 最大的那些对象，’加式    
  “  ， ’     臀   ，      
用户和对象的度 与采样可以使用不同的属性和特征，这根据实际面对的问题不同而不同 推荐算法研究
的中心问题是效用度“ 的计算，并非遥历整个  占的整个空间，而是分布到一个流形子空间          上 对于某
个数据集而言，必须先对 “ 进行外推               ，也就是说，对象必须具备用户以前作的评分        ，未评定
  到      的对象的评分必须先根据已标注的对象进行标注外推后才可以使用 各类推荐算法在外推和评分预测
                  上采用了不同的策略，设计了不同的效用函数，这些将在下一节中分类介绍 
  现有的推荐算法
推荐算法是整个推荐系统中最核心和关键的部分，在很大程度上决定了推荐系统类型和性能的优劣 目前，
对推荐系统的分类并没有统一的标准，很多学者从不同角度对推荐方法进行了不同的划分【 一，’  但主流的推荐
方法荃本包括以下几种 墓于内容推荐、 协同过滤推荐、 基于知识推荐和组合推荐 本节我们将分类讨论推荐
算法的研究成果，下一节我们将讨论这几类推荐算法各自的优、 缺点和推荐系统研究的重点、 难点问题 
    谷干内容的推荐
基于内容的推荐        一加洲 化          是指根据用户选择的对象，推荐其他类似属性的对象作为
推荐，属于       划分中    的    · ，      。二      方法 这类算法源于一般的信息检索方法    不需要依据
用户对对象的评价愈见 对象使用通过特征提取方法得到的对象内容特征来表示，系统基于用户所评价对象的 许海玲 等 互联网推荐系统比较研究    
特征，学习用户的兴趣，从而考察用户资料与待预测项目相匹配的程度 
对象内容特征            的选取在目前的研究中以对象的文字描述为主，比如信息检索中最经典的文本
特征是词频一倒排文档频率              卜访                      ，简称  一        另一方面，用户的资料模
型             代卯     取决于所用机器学习方法，常用的有决策树、 贝叶斯分类算法【” ，” 〕、 神经网络、 基于
向量的表示方法等，数据挖掘领域的众多算法都可以应用 结合对象内容特征和用户资料模型，最终的效用函数
可以定义为   
   ，                      叮厂     ，               
      的计算有不同的方法，比如使用最简单的向量夹角余弦的距离计算方法 
   ， ，一。   、 ，、 卜联，、 ，      愿庵万了欧琦万 
，    
最后得到的 数值用于排序对象，将最靠前的若干个对象作为推荐 
基于内容推荐的其他研究还包括自适应过滤   ，  】和闭值设定【’ ，” 〕等，前者关注如何通过不断到来的对象
增量地计算              那卢     ，使其更加准确 后者研究用户查询文字和对象特征的匹配方法，从而更精确
地计算      叹   
    协同过滤推荐
协同过滤推荐                         。          技术是推荐系统中最为成功的技术之一，它于  世纪
  年代开始研究并促进了整个推荐系统研究的繁荣 大量论文和研究都属于这个类别 
协同过滤的基本思想是 找到与当前用户  ，相似 比如兴趣和口味相似 的其他用户   ，计算对象 对于用
户的效用值    司，利用效用值对所有 进行排序或者加权等操作，找到最适合 ，的对象 ’ 其基本思想非常易
于理解，在日常生活中，我们往往会利用好朋友的推荐来进行一些选择 协同过滤正是把这一思想运用到推荐系
统中来，即基于其他用户对某一内容的评价向目标用户进行推荐 
基于协同过滤的推荐系统可以说是从用户的角度进行推荐的，并且是自动的，也就是说，用户所获得的推荐
是系统从用户购买或浏览等行为中隐式获得的，不需要用户主动去查找适合自己兴趣的推荐信息，如填写一些
调查表格等 其另外一个优点是对推荐对象没有特殊的要求 而基于内容的推荐需要对推荐对象进行特征分
析 ，能够处理非结构化的复杂对象，如音乐、 电影等 同时，研究用户之间的关系需要大量的用户访问行为的历史
数据，与社会网络研究有交叉点，有丰富的研究基础和广阔的前景 对协同过滤最早的研究有   ’           日  ，
后来的研究成果包括几      盯      ，  ，   叩     ， 〕，      ‘ ，              ‘ ，             ，， 等 总体而言，
此类推荐算法可以分为两类    启发式   而    七    。     理一      方法和基于模型     一      的方法 
   启发式方法
启发式方法   ，  〕的基本思想是使用与新用户 。 相似的用户 。，对一个对象，的评价来预测 ，对新用户 。 的
效用，进而判断是否推荐 给  显然，启发式方法的研究主要包括两点     计算用户之间的相似度     对所有与
用户 相似的用户 ’对对象，的评分进行聚合计算，以得到 对新用户 的效用的统计预测方法 
在用户相似度     ， 今这个研究点上，主流的思路是根据用户对同一对象的评分的差异来判断用户兴趣的
相似性 评分属于用户的浏览历史行为，可以是打分、 观看次数、 停留时间等 最基本的两种计算     ， ’  的方法
是基于关联的            一      和基于余弦距离的       一      方法 基于关联的方法研究用户   和  ’ 共同评
分过的所有对象的评分相似度来计算关联  ，   而基于余弦距离的方法直接把评分作为向量来计算余弦距离，进
而得到用户相似度   泌  
统计预测方法的计算公式可以形式化地表示如下    
  ，  叱落 ‘ ，  ’ 任      
之前的研究设计了很多计算 目梦的启发式函数，几个比较典型的例子是 
      青     
，            蒯   甸伽聪 软件学报      ，     ，              
  、      加  ， 今   ·，，     
   ，  元    如  ， 勺    、 一元· 
这 类 目歹函数都是利用以前用户的评价和用户之间的相似度来启发式地计算效用值 其中，式   是最简
单的形式 式   简单地引入用户相似度加权，是应用最广的方法 考虑到不同的用户在不同情况下作的评分可能
有不同的尺度，式   提出进行平均归一化的操作以消除这种尺度影响 
除了这两个研究点之外，近年来一些学者同时也发展了其他启发式方法，以提高启发式推荐的性能，如缺省
投票               、 用户倒排评分    。     加       、 实例扩展    。 。呷一             和主流加权预测
      喇·         耐           等 
   基于模型的方法
这类方法利用用户 对众多对象的评分来学习一个 的模型              气然后使用概率方法对新的对象，
的推荐效用进行预测 文献【  对这种方法的形式化描述如式   所示 
   ，     ，， 二 ‘” 州   ，      ，’， ’        
这样，墓于模型的方法把一个用户归类到一种模型下或者一个类型中 其他的算法还包括利用机器学习方
法    和统计棋型   】、 贝叶斯模型    、 概率相关模型    、 线性回归模型    和最大消模型   〕       在文献    
中还把推荐选择看作序列决策问翅 ”                           ，使用马尔可夫决策过程方法                
          加以解决 图模型方法，包括概率隐形语义分析      比 一      一             。            ‘ 和           
       以             ， ，也应用于协同过滤推荐算法的研究 
    ‘ 于知识的推荐
基于知识的推荐 如。      一     二             ’ 〕在某种程度上可以看成是一种推理           技术 
它不是建立在用户播要和偏好基础上推荐的，而是利用针对特定领域制定规则      来进行基于规则和实例的
推理     七‘姆 传  。咖   例如，文献【   中利用饭店的菜式方面的效用知识，推荐饭店给顾客 效用知识
 丘口                 是一种关于一个对象如何满足某一特定用户的知识，因而能够解释需求和推荐的关系，用
于推荐系统 效用知识在推荐系统中必须以机器可读的方式存在          本体知识库 ，例如       帅    
                  使用关于学术论文主题的。        本体知识库向读者作推荐 
    组合推称
组合推荐伪     概。          的一个最重要原则就是通过组合后应能避免或弥补各自推荐技术的弱
点 见第    节  研究和应用最多的是内容推荐和协同过滤推荐的组合           尽管从理论上有很多种推荐组合
方法，但不同的组合思路适用于不同的应用场景 我们将研究人员提出的组合思路大致分为如下  类 
   后融合 融合两种或两种以上的推荐方法各自产生的推荐结果 如使用基于内容的方法和协同过滤方法
分别得到推荐列表，融合列表的结果决定最后推荐的对象 
   中融合 以一种推荐方法为框架，融合另一种推荐方法 如以基于内容的方法为框架，融合协同过滤的方
法，或者以协同过滤的方法为框架，融合基于内容的方法，
   前融合 直接触合各种推荐方法 如将基于内容和协同过滤的方法整合到一个统一的框架模型下 
      后融合组合推荐
在后融合组合推荐中，最简单的做法就是分别用基于内容的方法和协同过滤推荐方法去产生一个推荐预
刹结果，然后用某种方法组合其结果 文献   】使用了评分结果的线性组合，而文献    使用了投票机制来组合
这些推荐结果 除此之外，也可以分别考察两个推荐列表，判断使用其中的哪个推荐结果 比如，             
  幽  ” 】计算推荐结果的可信度，然后选择一个列表的结果 这种结果层次上的融合我们称为后融合组合推荐  许海玲 等 互联网推荐系统比较研究    
      中融合组合推荐
目前，中融合的组合推荐主要有两种，以基于内容的方法为框架，融合协同过滤的方法和以协同过滤的方法
为框架，融合基于内容的方法 前者利用降维技术把基于内容的对象特征进行精简化 例如，文献【   使用了
                            算法，在基于内容的框架中使用精化的用户特征向量 后者为了克服协同过滤的稀
疏问题 详见第   节 ，把用户当作对象，使用基于内容的特征提取方法把用户本身的特征 如年龄、 工作情况等
人口统计学特征                       使用到相似度计算中，而不是仅仅依赖用户的点击行为     等人在文
献【  』中引入多种不同的用户描述符来归类用户，挖掘用户的内在联系，从而得到更好的推荐效果 文献    使
用独立的基于内容的特征来补偿用户提供的简单的      ，也属于此类方法 
      前融合组合推荐
近年来，这类推荐方法最受学者的关注 在文献〔   中，研究者把用户的年龄和电影的类型放到一个统一的
分类器中训练学习 另外一种方法   〕使用了贝叶斯混合效果回归模型，并通过马尔可夫蒙特卡洛方法得到这个
模型的参数 文献    将用户和对象的特征都放到一个统计模型下来计算效用函数，研究者使用用户属性  、 对
象属性 及其交互关系 如选择关系卜来计算效用  对象 对于用户  的效用值勺计算式可以表示为
份 凡群  ，    ，凡 ‘ ，  二马一   ，『， ，凡一    ，， ， 乙一   ，      
这其中的 种正态分布的变量分别用于描述数据的噪声、 用户属性的异质性和对象属性的异质性 式   表述效
用值是由这几个因素共同决定的 这  种分布的 个参数由马尔可夫蒙特卡洛方法估算得到 
近年来，一些方法比较的工作  ，  ，   讨论并实验了各种方法与组合策略，得出结论 组合策略能够取得比纯
基于内容或协同过滤方法更好的效果 这种在方法层次上融合的方法我们称为前融合组合推荐 
  推荐系统的孟点、 难点问题和主流算法对比
   推荐系统的评测标准数据集
推荐系统学术研究常用的数据集包括 
               
          数据集中，用户对自己看过的电影进行评分，分值为 卜           包括两个不同大小的库，
适用于不同规模的算法 小规模的库是    个独立用户对      部电影作的       次评分的数据 大规
模的库是    个独立用户对     部电影作的大约    万次评分 
               
         的    研究中心曾经在网上架设           电影推荐系统对公众开放 之后，这个推荐系
统关闭了一段时间，其数据作为研究用途对外公布，          的部分数据就是来自于这个数据集的 这
个数据集有     个用户对      部电影进行的        次评分 早期大量的协同过滤的研究工作都
是基于这个数据集的      年  重新开放          ，这个数据集就不提供公开下载了 
                  
这个数据集是网上的    ·  些     图书社区的        个用户对       本书进行的评分，包括显式
和隐式的评分 这些用户的年龄等人口统计学属性                     都以匿名的形式保存并供分析 
这个数据集是由   书             使用爬虫程序在     年从     一        图书社区上采集的 
                
           是一个网上推荐和分享笑话的网站 这个数据集有       个用户对     个笑话作的    万
次评分 评分范围是一 小   的连续实数 这些数据是由加州大学伯克利分校的            公布的 
             
这个数据集来自于电影租赁网址         的数据库         于     年底公布此数据集并设立百万美元
的奖金     认  血   刀 ，征集能够使其推荐系统性能上升    的推荐算法和架构 这个数据集包含了        阴    两伽聪 软件学报       ，     ，      田了     
       个匿名用户对大约       部电影作的大约   亿次评分 
            脚即     
这个数据集包括  个新闻组的用户浏览数据 最新的应用是在       上的论文     新闻组的内容和
讨论的话题包括计算机技术、 摩托车、 篮球、 政治等 用户们对这些话题进行评价和反馈 
     知识库 ，  
   知识库是     等人在      年开放的一个用于机器学习和评测的数据库，其中存储大量用于模型
训练的标注样本，在文献【   中被用于推荐系统的性能测试数据 
    推称系统的性能评测方法
推荐系统的性能指标一般有推荐的效果 精确度               和推荐的效率            ，使用的指标有
          血  行 叹    ，                        和            由于不同的研究工作针对不同的问题，
使用不同的数据集，所以具体评侧方法变化很大 比较普遍的评测方法来自于机器学习等领域的一般方法，比如
数据集被分割为训练集印   。 肠  和测试集           推荐算法的模型在训练集上进行学习和参数调整，然后在
测试集合上计算精确度和运行效率，从而达到评测目的 文献    使用两种评测方法来比较几种协同过滤的算
法性能，第 种评测得到每次推荐绝对误差的平均值，第 种评测计算整个推荐列表的推荐精度 
    推称系统的，点、 难点问皿
随着近年来对推荐系统研究的开展，很多研究中的重点、 难点问题得到研究者的关注和共识   ，主要包括 
  特征提取问题
虽然在信息检索中，文本等对象特征的提取技术已经很成熟，但是推荐系统的对象不一定具有文本特征
或者文本不足以作为描述川，此时特征的选择出现了问题 尤其是网络上广泛存在的多媒体数据如音
乐、 视频、 图像等，自动化的特征提取方法需要结合多媒体内容分析领域的相关技术 另一个问题是特
征的区分性问应，大规模数据情况下不同对象的特征错配会影响系统性能 
   模型过拟合问班 可扩展性问题 
推荐系统中推荐算法无法完全掌握用户每个方面的兴趣和需求，因为用户之前没有对足够多类别的对
象进行评价 过拟合现象是指系统推荐给用户的对象与用户刚刚看过的不是太相似，就是太不相关 模
型过拟合 过学习 的问题本质上来自于数据的不完备性，这在实际应用中是无法完全避免的 在信息检
索领城这类问且广泛存在，解决的主要方法是引入随机性，使算法收敛到全局最优或者逼近全局最优 
随机方法包括遗传算法   】等             相关的文献 巧，   针对这个问题考察了被推荐的对象的相
关性恤       和冗余性            ，认为被推荐的对象首先不能与用户看过的对象重复 冗余 ，其次必
须有相关性以相互联系 推荐的多样性是必不可缺的 
   新用户问题
系统没有存储或者存储很少新用户的信息，包括查看对象的历史记录和新用户对对象的评分，基于模型
的方法无法获得训练数据而基于规则的方法难以进行推理 近期一些研究特别针对这个问题提出了解
决方法 文献   ，”  利用对象摘伽廿叩  、 受欢迎程度印叩        、 用户个性属性等来改进效果，
   新对象问瓜
新用户和新对象问题都属于冷启动问题 在推荐系统尤其是协同过滤系统中，新对象加入数据库后必须
等待一段时间才有用户查看并进行评价 点击、 打分、 评论等都是评价的手段  在评价达到一定数量之
前无法对此对象进行分析和推荐 不同于新用户问题，这类问题一般考虑使用组合推荐的方法来应对 
   稀疏问题
在任何大型的推荐系统中，对于一个用户，总有大量的对象没有经过用户的评价或者查看，而且这类数
据常常比已经有此用户评价的数据 更大    用户之间由于选择的差异性非常大造成稀疏情况，即任意
两个用户的评分差别都非常大 文献【  】提出初步的解决方法，将用户的年龄、 国籍、 性别等个人信息 许海玲 等 互联网推荐系统比较研究    
增加作为用户相似度计算的根据，称为基于人口统计学的过滤方法                        文献〔  ，   
使用主分量分析     降维方法尝试把稀疏的关系矩阵降维到低维，以得到用户之间潜在的关系 
    各类推荐方法的对比
各类推荐方法都有其各自的优、 缺点，针对不同的数据集，效果也有所不同 每种方法因为算法本身的特征
可能不适合在所有数据集上作推荐 如在基于内容的推荐方法中，自动化的特征提取方法很难应用于多媒体数
据，即使在容易提取特征的文本数据的情况下，也无法仅仅通过词频统计的方式区分文档质量    除此之外，为用
户推荐的内容仅限于与该用户曾经选择的对象相似的对象，结果多样性差 而对于没有选择过任何对象的新用
户，推荐尤其困难 协同过滤的方法从某种程度上克服了基于内容方法自动化程度低、 推荐结果不丰富等弊端 
但是，协同过滤是基于大量历史数据集的，因而存在稀疏问题和冷启动问题 在冷启动方面，由于协同过滤是依
靠人与人之间选择内容的相似度进行推荐的，因此，与基于内容的方法相比，不但存在新用户问题    ，而且还存
在新对象问题，即刚刚加入的对象如果没有被任何人选择过，就很难被推荐    基于知识的推荐是一种静态的推
荐方法，不存在冷启动和稀疏问题，但知识很难建模 组合推荐策略由于组合方式不同，其性能特点差异很大，故
不在此讨论范围内 几种推荐方法的优、 缺点具体比较见表  
                              们仙                   
表  典型推荐算法对比
       ”刀  山                                   
    只            
          韶     又      加                                                                                     
                  ，  沈                                  
                                                                                      
     叩           吐   叮         爪                                           ，，
           幼     叮           介                                      
                   刀 宜口钾。们            肠         卿 吐曲                        
                                            
玖玖玖            ，                                                                 
              。刀 认业                      只      ，     ，       、                
                    叩     ，喂                                                  
                                                          
  推荐系统研究发展的热点方向
推荐系统的研究发展多年，曾经一度进入低潮期 近年来，机器学习、 大规模网络应用需求和高性能计算的
发展推动了这个研究领域的新进展河以深入并可能取得成果的方向很多，主要包括 
  引入更精确适用的用户和对象特征                          ， 
针对特定问题适用的用户和对象特征通常可以作为模型训练的样本 典型的协同过滤方法【’一  并没有
使用用户和对象特征，而是利用用户的评分 文献【  ，   只是使用简单的特征，如对象描述的关键词和
用户的人口统计学特征等 而结合数据挖掘的高层特征一般是基于网络上下文的分析的【   ，比如发现
用户浏览网页和对象的时序模式 这类方法需要精准的用户浏览历史数据和先进的数据挖掘算法，尚未
在基于内容和协同过滤的研究中广泛采用 
   推荐的多维度研究   
当前的大部分研究都是基于对象一用户的二维度量空间的，未考虑相关信息                         然
而，用户对对象的评价和选择常常由很多环境因素来决定，比如某个对象在特定时段很流行，用户在某
个地方浏览对象的时候偏向于选择某类对象等 环境因素是无法从用户和对象的自有特征得到的，正如
文献   ，   所指出的，推荐使用的特征维度有必要根据具体问题来增加 文献    提出在多维度量空间
上来定义效用函数 城  以电影推荐为例 除了看电影的人的特性和电影本身的固有描述特征以外，还有
环境因素 来决定如何计算效用函数    ， 包括    是一个人看电影还是和其他人一起看    是去电影     为“阴口才   沪  陀 软件学报      ，    ，              
院看还是在网上看等    看电影的时间段 基于这种多维特征的思想，文献【   提出使用贝叶斯模型的
方法进一步扩展了这个思路 问题在于，维度的扩展与应用场景相关，其可扩展性还有待进一步改进 
   推荐系统安全问压
协同过滩类别的推荐算法必须使用用户的行为历史记录，但用户出于保护隐私的考虑常常无法提交完
整而正确的信息给推荐系统 文献【  ，   认为良好的隐私保护机制是推荐系统获取优质数据和忠实用
户的关健之一，并提出了相应的算法 同时，用户的信用度            也是推荐算法的重要参考数据 文
献〔   提出两种信用计算模型并用于提高推荐精度 另外，熟悉推荐算法的攻击者恶意利用捏造的评分
和对象属性等数据欺编推荐系统，达到被频繁推荐的目的 文献   ，   中定义这类行为为用户欺诈
         比加  ，并设计算法监控评分的时序模式，去除不正常的对象与用户 
   相关反恢研究 旧           朗  与侵袭性问题
一般的推荐系统大多需要用户依据自身对推荐对象的喜好程度，提供适当的评比反饮信息，这种评比方
式称为相关反谈 传肠 。 介。       相关反馈可以分为显性反馈                  和隐性反馈
         介        目前部分推荐系统主要使用显性反馈的方式，即需要用户每次查看对象都进行评分
或者其他操作一些研究    ” 月 中使用的用户反馈的方法也属于显性反馈 使用这种方式来取得评价的
方法对于用户不是很友好，具有很大的侵袭性 隐性反馈使用无须用户评价的用户数据采集方法 在文
献    的研究中列举了  种用户在网络上的浏览行为，    和‘   闷延伸了文献    的研究，进一步将
这些行为分为  类，并增加了一种新的行为类型 文献    针对隐性反馈的可靠性进行了实验，结果显示
“使用者的阅览时间”和“使用者是否喜欢该文章”有正向潜在关系 解决侵袭性问题的另一个研究方向
是研究用户能够接受的评价方式是什么，比如能够有耐心进行几次评分          系统    利用固定负
担模型这种最简单的算法来计 用户评价的负担，将侵袭性问题转化为最优化问题来研究 
  推荐算法的评价准则   
有效性和时间消耗作为推荐系统的重要指标，其评价准则的设计一直是一个热点，但是没有统一的结
论 文献〔” ，  一  】都研究过评侧推荐系统性能的准则，包括查全率          和查准率       的评
侧 另外，信息检索领城使用的         和           叩                      指标也可以用于评测 
第    节给出了部分研究工作中使用过的推荐效果度量方法 然而这些基于用户评分的数据和评测的
方法存在固有的缺陷，比如用户的评分常常是针对他喜欢的对象，而其他对象被访问的概率则很小 评
价准则必须考虑到人类行为的特点 同时，如果召集若干志愿者来做实时的实验，不仅样本量小，而且耗
费的时间、 人力也很昂贵 这是一个很有研究意义的方向 
   荃于复杂网络理论及图方法的推荐系统
近年来，机器学习、 理论物理和复杂网络系统的研究者从图和动态复杂网络                   
加      的视角，开始关注推荐系统中的大规模网络智能挖掘 文献【川将网络视频推荐问题转化为热
 散播平衡态网络上的谱图分割       ’                    问题，通过设计长尾发现          
            的推荐策略引导用户发现潜在的感兴趣的网络视频 
   社会分化和推荐逻辑空间的巴尔干化现象伽】 朋     叨  
以    秘 为代表的信息和通信技术消除了地理壁垒，即传统的地理空间巴尔干 即局域性限制  然而却
不可避免地生成了逻辑空间巴尔干     在推荐系统中根据个体兴趣、 学科专业、 社会地位以及观点进
行推荐时尤其容易导致这种局域性限制和社会分化的出现 本质上，个体偏好关系是导致生成逻辑空间
巴尔干的原因 推荐和个性化技术所产生的一系列社会学问题，也是很重要的一个研究方向 网络推荐
中体现的其他社会学问屁还包括从众心理和行为研究，推荐与主流兴趣形成的相互作用等 
  结 论
在互联网的迅猛发展下，随着信息过载问题的逐年升温，互联网用户对信息需求的日益膨胀，推荐系统在各 许海玲 等 互联网推荐系统比较研究    
个领域的数字化进程中扮演着越来越重要的角色 在过去的数十年中，推荐系统在学术研究、 工业界各种应用
上取得了长足的进步 然而，现有的推荐算法仍然存在特征提取、 冷启动、 过拟合、 稀疏问题，需要不断完善和
解决 同时，多维度推荐、 相关反馈、 评价准则、 安全性以及推荐社会学等仍然是当前进行深入研究和扩展的
热点方向 伴随着这些问题的逐渐解决，推荐系统将在互联网领域为用户提供更加便捷、 有效的用户信息获取
体验 
           
【              ，                                                        “           ，，                         
                                          ，       华    
         ，      ，           ，                                                                                   
                                                      ，         一    
            ，        ，       ，          ，形                                                                       
                                                               ，         一    
         ·      ，拓比   一                                              一                   ，     
             ，                                                                            即    皿  ，     ，       
    一     
           ，      川                                                          抑   川                叮                
            
                ， 山山                                                                     一      一               
                       肠                         ，    ，         一    
            ，    助       切                                      ，    ，        一   
                ，                   一     ，             比                                     ，    ，             
              ，        ，侧      助                   一                                                        
                ，         一    
             ，                                                                      ，            脚          ·
               一                  ，       一   
             ，           ，                                                                                       
    ，       ，                                                           ，       一  ·
             ，          肠       助                                                                             ，     ，
         一    
            ，                                                                ’  卿                                      ，
                        昭，              
           ，       ，              助                        叩                                        ，         
                    ，        一   
                 卜  北     币      盯   刀                    叩                                  ，    ，   ·      一    
           ，                 议    以对                                                             ，               
                ，              
                           忱汀  勺，                   ，    ，        一   ·
              ，        ，     ，   了                                                         ’                     。
   ，    ，         一   
              ，        ，      ，           ，        ，                                                            
                             ，        一   
   」        ，     ，       ，         ，                                                                    
   ，    ，             
【          飞  ，       ， 即恤 ，                                                                                       ，
    ，        一            ” 旧   甸伽脾 软件学报      ，     ，      田，     
    ‘︸护 ，‘‘， 飞口 ，月，                     助  ，          帅       胡                                                                      ，
   ·  ·  一    司比               公  ，     
  】 目。  ，  址     姻。口·  曰 脚 沙加            耐    加         功           功       功                  ，  
                    娜皿                                        ，     
口   工   凡‘，‘  口矛工 ，          盯 ，                  形司      ·                           爬   口   叫                                 ’ 
        挑              ，        一    
         ， 边     肠 旧                                价                ，                                       
    朋鱿渡 丘 口。 内   比 口    ，           
    ，盛甘           曲到                       ，                                                                        
        助  晰卜。川 叱       
  几田          公沁   帕行  州。      “                   比          助  ”                   小   ，            ￡
                ，         一    
       ‘月 ，‘  碑                             幽          五                                                                                  
卜的          她                   ，        一   
             份          州  哪                          州                                                   ·
      肚  人人人】     ，        一    
    ‘弓 压        ，                                   代                               ，                                 
    颐    二 皿 几口  柳     助 汤 丘山   ，     
       ，  助          口    。叩                             州           ，  扔 ，    一                      
             山人朋        的   ，      团口    卜                      
    几  自  ‘曰︸ 飞甘月，， 弓︸，  ， 工 ，        即  ，      朗  ，                   ·                                                              ，
     ，      一     
                  ”        ””            助                           团旧           ，    ，          一    
            ，  目      ， 血   眠                                                                             
 钾恤比 ，    ，             
护   ‘‘︸  内 ，夕矛自            ，     ，           ””                                            ·                                     
       山 人人  ，            人                  一    
   们阵旧     比目  ，   助    ，          ，      ，                          一                                   
      此    户       “     奴          ，      比                   协                                     
人   传  ，     
  ‘   ‘ ︸自 ， 跳︸﹄一  电       ‘。 目    台                       ，      一     ，                  比                               ，    ，    一   
   一   
     璐     乙“口      “ 口叼          叩                                     一                  ，      ，    一   
   一    
                ，                            助   盈                                               ，                应     
  肠川                  加认    叩        ”         币       比   ，       一   
     ，         ，  朋      ，          ，       ，           ，                                                  
明即                 ”即山         街“ ，                                                                 ，     
   叫和场 
   ，白， ，月          ，    叮  ， 昭盯司           一    比                           帅         扣 扣                             
                           仍       二       惫 人口                                          ，         一    
   州    阴                 恤      口月                                            ，              一    
                   ，  翻   ，     画   ， 侧目                     目                       哪               
傲。 ””         姻    卜     奴   ，                        让                       ，        一    
      厄        助‘         】   比                                                                    
          刀研门切即 卜”                许海玲 等 互联网推荐系统比较研究    
︸   工   一       ， 己声矛， ， ﹄              刀明八               
     刀                  
     ，     ，    ，                                        ，                                                    
                                                             众                                      
        ，        一    
   」    州 肚                田  
                             即                                                             仁                        
                         一    
             ，               ，       ，     ，                                一                                            
                           ，    ，             
助      ，       ，       ，     ，       ，         ，                                                    
                           ，       ，                   ，                                                      
         一    
︸   ﹄   、﹄‘ ﹃ 尸，﹄﹄              ，        ，        ，形                                           托                一                   
                            
      幻，             一                                                                                ，  
                                                                ，         一    
      ︸曰、、﹃﹃ ，            ，                       ，       ，                                                                   ，      
                  ’                                    ·      ，        一    
            ，                                                                                               ， 
                                      ，               ·      ，        卜    
   ‘护  ‘︸ 尸、    ︸                   ， 肚止 门口 旧       ，     ，                                                                        
                     鹅                               ，    ，         一    
                        如                                                       ’                             
                                                  ，        一    
 ‘﹄   ‘    矛 ︸，               ，       州粗   巧  州                                                                                      
   ，              川                                 ，        一    
 ，        ，                                                      ’                                          
        ，        一    
护  ‘     乙矛‘，今 ， ﹄   胜           ，      ， 别     卜                                                                               ’ 
                  刀                                      ，       一   
      ，  目“       ，     ，                                                                              
   ，        肠         “沁                                  ，        一    
       ‘  护﹃一、月﹃  一      吧   即  ，    ，旧    ，        ，       ，      ，                                 昭                            
          优，    ，      一   
                      七  叨 五                                                                               
               ，       一  
      ‘  ‘ 工              ，幻                           〔。                         ，                                        
                   】 传  ，       一   
       ，          】刘阮 办而曲                                                        州                         
         ，                   助                                                               ·      ，      
   一    
                ，       】  拍 戏么 口  ，侧                                                                               
              ，     白助峨                                                                           ，      
   一         勿脚勃时   义如明 软件学报      。，     ，      曰甲     
， ‘   夕           几，  。朋 目   ，   ，侧，   ， 见司                    耐       州                                 二   
  加  比加 钾   ， 加 夕      一   
      公  场   知       目皿石加          盯                           叮         石              衅     一     
叼甲 鹅  】创的回    “   ”     叹口叫附       陷瓦     ，        一    
︸  ‘   ‘，，尹 几‘， 工           ，劝    ，     ，          山                                                         ’       
   幼口侧山 二       加止     即·    朴茂  ，      
  ” 加运   印曲           伪勿‘                         ，     
许海玲  ，  一 ，女，天津人，硕士，主要研 李晓东  ，  一 ，男，博士，副研究员，主要
究翻城为互联网寻址系统，计算机网络 研究领城为计算机网络与通信 
应用 
且资     一 ，男，博士生 主要研究领城为 阅保平  ，  一 ，女，博士，研究员，博士生
网络多橄体盆据挖翻，计算机视觉，机器 导师，   高级会员，主要研究领域为计算
学习  机网络，信息系统工程，大型数据库技术  --------------------------------------------------------------------------------- 市场营销
信息过载对在线消费者购物决策的影响
齐莉丽 教授 赵 蕊（天津职业技术师范大学经管学院 天津 300222）
基金项目：天津市艺术规划重点项目“京津冀现代信息服务业区域发展模式研究”
（项目编号：B14012）；天津市科技发展战略研究计划项目“京津冀科技型小微企业
协同创新平台及其生态系统构建”（项目编号：16ZLZXZF00490）
中图分类号：F026 文献标识码：A
内容摘要：随着电子商务的快速发展，消费者凭借互联网与智能设备享受着不断更新的、丰富的购物信息带来的
极大便利，同时也不得不遭受着过度的信息轰炸、信息膨胀和信息绑架等信息过载问题的困扰。信息过载给网络
消费者带来了选择过剩的问题，对消费者的生理、心理等都可能产生负面影响。通过问卷调研网络环境下的信息
过载对消费者购物决策的影响，分析数据得出以下主要结论：网络购物平台信息过载问题在一定程度上对消费者
造成了消极的影响。在此基础上，本文从网购平台、商家、消费者不同角度给出建议，以期减少网购信息过载对
消费者决策产生的不良影响。
关键词：电子商务 信息过载 选择过剩 购物决策
前言 识不断增长，信息技术得到广泛的应用，信息资源就会以
随着互联网的飞速发展，人们接收的信息越来越多， 指数级的速度迅速地增长。大量丰富的信息源源不断的出
身边的各类信息呈爆炸式增长，过多的信息包围着这个时 现并且不断地快速扩散将会引发信息的过载、资料品质的
代的所有人，信息过载的现象也由此产生。在电子商务领 下降和搜寻信息的负荷加重等问题。当人们所接收的信息
域，我国电子商务的蓬勃发展促进了网络购物的普及，据 量超过了大脑的负载时就会直接导致大脑对所接收信息的
国家统计局统计，2016年我国网上零售额51556亿元，比 处理效率低下，如果大脑经过长时间信息过载的困扰则会
2015年增长了26.2%，我国网购人数占我国总人口数的 使消费者出现头痛、注意力难以集中和记忆力下滑等症状，
36%，是全世界网购者数量最多的国家。不断增长的网络 对心理和生理都将造成一定负担。信息的极大丰富不但没
消费者数量和其不断增多的需求，使得长尾市场延长，网 有使人们的生活更加便捷高效，过量信息、信息平庸化和
店数量不断增加，据《浙江省网络零售业发展报告》统计， 噪音化反而阻碍了人们对所需信息的处理，成为人们信息
仅淘宝网这一购物网站的网店数量在2015年就已达到147 生活中的一大困扰。
万家，商品的种类、规格（属性）、数量极丰富。在线消 很多学者也对信息过载问题进行了研究，如Schick
费者在做购物决策之前，会首先通过网络平台进行查询、 （1990）认为信息过载是指信息超过个人接受和处理的能
比较和筛选，然而电子商务购物平台提供的大量相关商品 力，从而导致人们厌烦和焦虑的现象。Chi-Lun liu（2014）
信息，无论是商品的数量、介绍信息、规格信息、促销信 认为信息过载是接受大量信息而无法在一定时间内得到恰
息还是细节信息，都远超过消费者所能接受的范围，海量 当的处理;Soucek和Moser（2010）则认为信息过载是接受
的商品信息反而让网络消费者难以决策，同时过多的商品 大量超过个人信息加工容量的过程。周玲（2001）认为信
信息会促使消费者焦虑、纠结等负面情绪的产生，也即信 息过载是指人们在工作或学习过程中，如果接收到的具有
息过载对网络环境下消费者的购买决策产生了重要影响。 潜在价值信息的数量过多，就会造成信息使用效率降低的
如何识别网络环境下信息过载对消费者购物决策的影响并 现象;曾晓牧（2004）认为信息过载是海量信息与有限的
寻求有效的解决方法，是电子商务发展中改进消费者体验、 信息处理能力之间的矛盾所造成的，不能有效地对信息进
提升购物效率的热点问题。 行整合和利用的情况;杨涛（2016）认为信息过载是指在
信息时代消费者网购时，所需要加工的产品信息超过了消
信息过载及其产生的原因 费者信息处理、加工能力的一种现象。
（一）信息过载定义 （二）信息过载的原因
关于信息过载，托夫勒早在1970年《未来的冲击》 网络环境下信息过载产生的原因非常复杂，比如：信
一书中就提出，随着时代的发展，技术得到提升，新的知 息的大范围充分开发扩张和信息的总量不断增长；电子商
40 商业经济研究 2018年10期 Marketing Management
务快速发展，越来越多网购平台的出现，吸引了数量巨大 （二）信息过载对消费者购物的影响
的用户开设了网络店铺；电子信息资源容易编辑、更改、 信息过载对消费者购物的具体影响，可归纳为以下几
复制和传播，因此同一类商品的基本描述店铺间差异不大； 个方面。
现代人对信息科技的崇拜，导致很多人认为信息的数量越 信息过载对网络消费者购物决策效率的影响。一般情
多越好，认为更多的信息能够帮助他们更好地决策，盲目 况下，信息过载会影响工作者的专心程度、交换和处理信
追求数量从而忽略了信息的质量；消费者处理信息能力有 息的速度，对工作效率和质量产生一定的负面影响。网络
限等。另外一些购物网站推出了个性化推荐系统，但系统 环境下信息过载将会影响消费者的购物决策效率，一次简
推荐很难做到精确的个性化推送，消费者在使用时会接收 单的网购却需要花费过多的时间来了解众多商品的性能、
很多无关的信息，推荐信息不能迎合其兴趣，导致信息过 属性等信息及在线评论的好坏，花费精力了解网店商家之
载问题出现。这些原因都使得信息过载对网络消费者造成 间的区别，最后做出相应的购买决策。简单的一个关键词
了各方面的影响。 搜索可以搜出上千种甚至上万种的商品，上百家网店，难
以短时间内了解完，严重影响了消费者的决策效率。
信息过载对网络消费者购买意愿的影响 信息过载对网络消费者生理心理健康的影响。人们生
（一）信息过载环境下的选择过剩和选择成本 活在信息过载的环境中，被过多难以消化的信息包围，产
供选择的商品信息过载往往会导致网络购物者产生诸 生压力的同时会对生理、心理带来负面的影响。Wurman
如失望、后悔等负面的购物情绪，这一现象被学者们定义 （1989）提出的“信息焦虑”描述的是当人们面对海量的
为“选择过剩”。《选择的悖论》（2004）这部经典作品 信息却无法理解和消化、难以从其中寻找到自己所需的信
的作者Barry Schwartz认为更多的选择使人们的生活更加 息时所产生的焦虑、不安等负面情绪。这些负面情绪会使
不快乐和不幸福，他举出了几个消费领域内选择过剩现象 人们作出拙劣的抉择、记忆力减退、对工作越来越不满意
的事例。 甚至沮丧无助。网络消费者在网购时原本只想购买一件商
让有意愿购买果酱的消费者从30种果酱中做出购买 品，却因信息过载而被成千上万的商品和商品信息所包围，
决策的几率远低于让他们从6种果酱中做决策。选择过多 大多商家还会给消费者推送一些相关商品，而他们处理这
会让消费者容易去想象，如果选了别的可能结果会更好， 些信息的能力有限，在反复比较得不到希望的结果后难以
而这个幻想出来的另一个“更好”的选择让消费者对自己 避免出现心理上的负面情绪。
做出的决定感到后悔，即使消费者做了一个很好的选择， 信息过载对网络消费者生活和人际关系的影响。信息
这种懊悔依然会让这个决策的满意度大打折扣。即选择越 过载使人们在所作决策上花费大量的时间和精力，产生焦
多，人们越容易在自己做出的选择上进行挑剔，然后感到 虑，这种影响将不仅仅是停留在生理层面上，还会导致心
后悔。 理上的挫败，以至于影响日常的决策行为，让网络消费者
以前电话只是一个通讯设备，主要且唯一的功能就是 开始逃避和拒绝一些信息，造成物质和精神上的极大损失，
打电话，要购买电话也很简单。而如今买一个手机却要烦 同时增加了获取有效信息的成本。
恼于买带哪些附加功能的手机。追求最好选择的完美主义 信息过载情况下的网络消费者从选择到购买是个复杂
者——“效用最大化消费者”在购买时将比“满意即可消 而漫长的决策过程，消费者在决策时由于自身信息处理能
费者”花费更多的时间和精力用于商品的比较和选择，却 力有限，可能不能及时获取全部与购物决策相关的信息，
更难于做出购买决策，购买后的满意度也低于后者。 更不能处理这些过度的信息，当他们意识到这个问题时很
以前去买牛仔裤的时候，只有一种款式，消费者理想 可能产生负面的情绪，甚至拒绝作出决策。
值很低；但当有100种款式的时候，消费者将所得到的与
所期望的进行比较，结果是所得到的远不如所期望的。为 信息过载对消费者影响的调查分析
人们的生活增添选项不可避免的后果就是人们对这些选项 为了更好验证网络消费者的购物决策受信息过载环境
的期望值大大增加，这会让结果变得更加扫兴，即使结果 的影响，本文通过问卷调查法，对网络消费者偏好、购买
是好的。 决策受信息过载问题影响情况等进行较深入研究。本次调
消费者的每一次决策都会有相对应的决策成本和决策 查共发放问卷196份，收回有效问卷176份，占总发放数
质量，然而往往一些令人满意的决策背后都是花费了较高 的89.8%。从被调查者的购物频率来看，几乎所有人都有
的选择成本。商品信息越多，消费者所付出的时间、精力 网购经历，而且过半的被调查者偶尔网购，接近一半的被
等选择成本会越高。 调查者经常网购。
《中文核心期刊要目总览》贸易经济类核心期刊 41 市场营销
（一）关于商品信息过载问题的分析 全不能按自己的喜好快速地完成购买。这说明大多数网络
关于可供选择商品数量与最终购买商品质量关系的问 消费者已形成了在线购买前会反复比较商品信息的决策习
题。是否可供选择商品数量越多，消费者越能选出更好的 惯。而当消费者接收的信息远多于他们能够消化的范围，
商品呢？对此问题，调查中约73.9%的被调查者认为如果 就会导致信息过载，在某种程度浪费了网购消费者的时间
有更多供选择的商品，最终决策所购买的商品质量会相对 精力等，交易成本也随之变高。
更好，其中22%的被调查者非常确定如果购物网站提供 66%的被调查者认为要网购到满意的商品将需要花费
更多的商品供选择将会对自己有益；24%的消费者不能确 自己较多时间和精力等交易成本。当消费者花费了较高的
定；也有持相反看法的被调查者占了2%。 交易成本依旧有可能买不到满意的商品时（由于信息过多，
传统理性选择理论描述的是更多的产品选择能有效地 消费者的认知受到一定的限制，难以在有效时间内做出有
刺激消费者的购买。表面上看，越多的商品似乎给了消费 效的决策），就会导致购买风险增大，消费者负面情绪随
者越多的选择空间，消费者所选出来的商品也一定是在各 之产生，则很可能放弃选择甚至对将来的网购也产生了负
方面相对满意的商品，但实际上，本文后面的调查则显示， 面影响。
对于大部分非特殊商品，超过了一定限度的信息提供，越 关于消费者的机会成本获得问题。消费者在网购时，
多的商品信息只会给消费者认知带来越多的负担，造成更 除付出交易成本外，还会存在因购买某商品而失去选择其
多的选择障碍，成为消费者的负担而非利益。 他可能更好商品的机会，可称之为机会成本。由于信息
关于网购平台店铺过多及商品种类过多的问题。关于 超载的出现，备选商品数量、种类繁多，使得机会成本的
商品种类过多的问题，被调查者中62%的人在大多数网 变数增大，消费者无论购买备选商品中的哪一个，都会产
购情况下购买某种商品的时候，由于供选择的商品数量过 生怀疑的想法，决策的不确定性因素也由此增加。在本次
多而难以做出购买的决策；只有约38%的被访者不确定 调查中，被调查者中61%有过怀疑自己最后买到的商品
或不认为在网络购物时存在信息过载。关于网络平台提供 不是最好选择的经历，约有9%的被调查者非常确定，自
的店铺过多问题的调查中，有65.3%的被调查者认为在大 己曾在做了某个购买决策的同时失去了选择其他商品的机
多数情况下，网购某一商品时不同卖家之间的区别不大， 会，并为此感到沮丧；只有12%的被调查者认为自己在
因此难以做出购物决策；不确定的调查者占16.7%；只有 购物后完全不会再考虑机会成本的问题，另外选择不能确
约18%的被调查者认为不存在店铺过多难以选择的问题。 定的有18%。
这不难看出，目前网络购物平台商家数量庞大，他们售卖 信息过载对不同性别消费者产生的影响。不同性别对
的同类产品基本信息大致相同，卖家之间的区别不是特别 于信息过载环境下决策的影响有一定的差异。比如，对于
大，消费者将一些明显优势不足的商品筛选出去后，剩余 网购中常常纠结于几个备选商品难做决策的问题，对所调
的几个备选商品基本上相同，细小的地方有所不同各有优 查的女性消费者影响较大，有超过70%的女性消费者表
缺，消费者纠结于细节、需要仔细比较商家之间令人眼花 示有这种情况，而男性相对少占56%；对因购买了某一商
缭乱的各种促销信息，才能做出购物决策。 品而失去选择别的备选商品机会，在被调查者中，有过半
过多的选择反而让消费者难以吸收消化所有商家信息 的男性网络消费者会感到沮丧，有这种情况的女性仅占女
以及商品信息从而难以做出抉择，这即是选择过剩导致的 性消费者的38%；男性消费者中有64%会怀疑自己最后
问题。这说明现如今网络购物平台的部分商品种类已经多 买到的商品不是最好的，女性消费者则为54%；男性消费
到让过半的消费者出现了一定程度上的认知负担，从而难 者中68%以上能按自己决策快速购买，而女性则不到一
以做出购买决策。 半；男性消费者60%以上购买前就对预购买商品有所了
关于网络消费者花费交易成本问题。消费者进行网络 解，而女性仅50%左右。由此可见男性在网络购物时相
购物，虽节省了交通费用等成本，但事实上，因为需要在 对女性能提前对自己要购买的商品有所了解并且有一定的
网络上进行信息搜索、比较、咨询等，依然需要付出包括 偏好，受商品信息过载的困扰也会相对少一些，所花费的
时间、精力等在内的交易成本。调查中25%的被调查者 交易成本相对少。但男性消费者对于过多的选择没有足够
在网购前就清楚了解自己所要购买商品的所有特征。但在 的认知，一般不会将所有商品信息进行比对选择，但购买
我们的调查中，只有5%的消费者习惯于按自己喜好快速 后会怀疑自己所选择的商品不是最好的。
决策和购买而不需要详细比较商品信息；74%的网络消费 信息过载对不同收入消费者产生的影响。调查显示在
者大多数情况下都有将多个商品比较后才做决策以尽量买 进行网络购物决策时，低收入者相对于中高收入者更容易
到自己最满意商品的习惯；21%的被调查者基本甚至完 受到信息过载的负面影响。网购低收入者中，有68%以
42 商业经济研究 2018年10期 Marketing Management
上都表示有过网购时商品过多难以抉择的困扰，这种经历 的同时在一定范围内控制信息过载的问题。在消费者偏好
在中高层收入人群中相对少一些，为不足50%。由此可见， 研究的基础上实现个性化推荐，尽量提供更有针对性、更
较低收入的消费者相对于中高收入者在线购买商品时，因 符合消费者需求的信息。
信息过载产生的选择过剩现象所带来的问题和烦恼要多一 对于网店，应注重商品信息质量，优化商品信息（商
些。为了能购买最好的商品，收入较低的被调查者常纠结 品图片、介绍、规格等）使得产品信息精简有力，尽量突
于几个备选品并相信能从中做出最合适的决策。对于总能 出商品最大的特点，尽量避免与其他网店的商品信息相同
按自己喜好快速购买的消费者占比中，中高收入者比较低 或过于相似。选择商品品类时尽量避开普通常见商品，选
收入者多出16%，而喜欢将多个备选商品对比后购买的较 择一些新颖的、有创意的商品，或者是选择有特点的消耗
低收入者为76%，中高收入者中则为66%；69%以上的较 品，缩小推荐商品种类和范围。打造店铺特色，确定店铺
低收入者认为购买到合适商品将花费较多时间精力，而有 的核心产品和特色产品，在设置商品关键词时尽量设置个
这种想法的中高层收入者仅占40%左右。较低收入的网 性搜索优化关键词，避免大范围、普通的关键词，将一些
络消费者相对中高收入者在网购时不仅遭受的信息过载负 冗余的商品和搜索关键词排名靠后的商品下架。
面影响要大，且相对花费的交易成本要更高些。 对于信息过载对不同消费者人群所产生的影响，网店
（二）调查结果综合分析 店主可以通过优良的客户关系管理，在不侵犯客户隐私的
通过以上分析，本文得出以下结论：电子商务发展至 前提下尽力掌握客户信息，对客户进行细分和分级管理。
今，大多主流电子商务平台已存在较为严重的信息过载问 如按照网络消费者性别偏好对商品信息进行相应的调整，
题。这些问题产生的主要原因是商品数量和规模的庞大、 比如由于大部分男性消费者在进行网购前就对所购买商品
商品种类和属性的多样化、商品信息过多且平庸化、网上 有一定的了解和偏好，且选择时间较为短暂，又容易受同
店铺的数量多以及店铺间差异不大、缺少创新等；网络购 一商品在不同店家区别不大的信息过载问题困扰，网店店
物平台的信息过载给消费者的购物决策带来了一定程度的 主可将店内男性消费品商品信息精简且专业化，注重描述
负面影响。过多的商品和店铺信息让消费者选择过剩，难 商品特殊性能和特色，对于男性消费者购买后更容易怀疑
以认知和处理庞大的信息量，对消费者的身心造成负面的 自己所购买商品不是最好的问题，则可以做好售前售后处
影响。选择的增加使得未被选择商品的优点强化，对被选 理，缓解其因信息过载而产生的不适。
商品的满意度降低，同时机会成本让选择变得更加复杂， 对于消费者，在大数据时代，消费者必须增强信息处
对消费者的心情造成负面的影响；商品信息过载让消费者 理能力，学会合理选择有用的信息，保持一个良好心态提
的交易成本增高，他们需要花费过多的时间和精力去了解 高自身信息素养。在购买时将精力集中在最重要的选择上，
各个备选商品、权衡各个商品的优缺点后再通过自己的喜 不要太在意机会成本，就能够减少在购买时的沮丧。控制
好进行抉择；不同的消费人群对于网络环境信息过载的影 自己的期望值，过高的期望将会花费过多的选择成本且不
响存在一定的差异，如女性明显比男性更容易受过多信息 易感到满足，增加负面情绪。由于较低收入者更容易受信
的负面影响；低收入人群比其他人群更容易遭受信息过载 息过载问题的困扰，这类消费者需要学会在网购前确定自
环境下网购商品选择过剩难以抉择的烦恼。 己的偏好，确定有效的信息范围并选择启发式的策略，比
如选择一个有知名度的品牌，然后根据销量这一线索快速
对网络购物信息过载问题的建议 剔除一些低销量商品。在购物中将选择的限制看作是解放
信息过载是个多层面的问题，受多方面的影响，比如 而非自由，能有效减少信息过载带来的负面影响。
消费者处理信息的不同方式、系统的辅助方式、组织方式
和管理机制等。在信息过载环境下，必须将诸多的繁复信 参考文献：
1.曾晓牧，孙平.信息超载与图书馆的应对方案[J].
息经过各方面的过滤和萃取，使得有效的信息到达信息接
图书情报工作，2004，48（6）
收者手中，才能有效避免信息过载对消费者造成的一系列
2.杨涛.信息过载对网络消费者过程满意度和购买意
负面影响，节省其获取有效信息的代价和时间。本文从不 向影响的研究[D].陕西师范大学硕士论文，2016
3.菌丰奇，刘益.网络化信息环境中信息过载问题研
同角度给出具体建议。
究综述[J]. 情报资料工作，2007（3）
对于网络购物平台，应适当控制网络店铺数量和商品 4.王娜，田晓蒙.大众分类法对信息过载的影响及优
数量，做到少而精，以质取胜而非量取胜。可通过运用信 化策略研究——以豆瓣网为例[J].现代情报，2016，36（9）
5.王娜，陈会敏.泛在网络中信息过载危害及原因的
息筛选的管理机制将平台上一些相对没有用的商品信息、
调查分析[J].情报理论与实践，2014（11）
重复的和冗余的信息在消费者接收前过滤，减少信息数量
《中文核心期刊要目总览》贸易经济类核心期刊 43 --------------------------------------------------------------------------------- 理论述评
SummeryinTheory
DOI:10.19634/j.cnki.11-1403/c.2022.01.024
信息过载影响消费者决策研究的知识图谱分析
魏 娟 李 敏
□
(南京信息工程大学 管理工程学院,江苏 南京 )
210044
[摘要]以 数据库中收录的 篇相关论文为研究对象 本文使用 可视化分析工具绘制关键词图谱 结
CNKI 553 , CiteSpace 。
果显示 国内对信息过载和消费者决策研究以应对策略为主 分为以消费者为中心的策略 以信息处理为中心的策略和
: , 、
以技术为中心的策略
。
[关键词]信息过载 消费者决策 知识图谱 主题演变
; ; ;
[中图分类号]G203;C934 [文献标识码]A [文章编号]1003-1154(2022)01-0156-06
信息时代 互联网信息量呈指数级增长 消费者 境下消费者决策研究进行系统梳理 探讨该领域的研
, , ,
进入信息完全的环境 丰富的信息有利于消费者决 究现状及发展趋势 洞察消费者行为模式及其改变
。 , ,
策 但当信息量过多时 消费者无法在有限的时间内 为改善消费者决策质量 提高决策效率提供依据
, , 、 。
处理过多的信息 易造成决策困惑 决策延迟 决策绩
, 、 、
效下降 ,甚至不做决策[1] 。互联网是增长最快的零售 一、方法和数据
渠道 年全国网上零售额达到 亿元 比
,2020 117601 ,
年增长 在互联网环境下 由于信息的 (一)研究方法
2019 10.9%。 ,
易得性和传播的快捷性 消费者加工海量信息需要消 文献计量是运用数学和统计学方法对各种出版
,
耗更多的注意资源 社交媒体和智能手机能自动吸 物进行的定量分析 有助于研究者更好地理解某个主
。 ,
引用户注意 导致消费者认知控制能力下降 难以准 题领域内的知识结构和知识脉络 通过文献计量可
, , 。
确执行方案评估和购买决策[2]
。
以分析关键词 、作者 、研究机构 、国家 、文献来源 、参考
早在 年 就探讨了信息负荷对消费 文献等 了解该领域的研究热点和发展趋势 随着信
1974 ,Jacoby , 。
者决策的影响 通过改变选择集中的备选项数和属性 息技术的发展 通过文献计量可以生成知识图谱 展
, , ,
数量来改变提供给消费者的信息量 研究发现 信息 示更多的可视化信息 可以分析主题 作
。 , 。CiteSpace 、
数量和决策质量之间呈倒 U型曲线关系[3] 。随后许 者和关键词的共现网络 ,结合时区图和突变词探测
,
多学者对信息负载和消费者决策之间的关系进行了 呈现出主题的研究热点及演变趋势 目前 文献计量
。 ,
研究 但研究结果存在分歧 决策质量并不一定随着 分析方法已被广泛地应用于各个领域 如信息科学
, , , 、
信息量增加而降低 收集购房者在 社会科学 生命科学 管理科学等
。Malhotra(1982) 、 、 。
面临不同数量的房屋选项和房屋属性信息时的心理 (二)数据来源
状态数据 当选择集中的备选项或者属性数量从 个 本研究数据来源于 中国知网数据库 检
, 5 CNKI 。
增加到 个时 购房者会感到困惑 决策准确性降 索条件为 在专业检索中输入字符 消费者
25 , , : TKA=‘ ’
低 ,表示无法做出最佳的选择[4]
。
AND(TKA=‘信息超载 ’ORTKA=‘信息过载
’OR
以往研究通过提供给消费者备选项和属性数量 选择超载 选择过载
TKA=‘ ’ORTKA=‘ ’ORTKA
来衡量信息量多少 而没有包括信息的其他维度 如 认知过载 海量信息 超
, , =‘ ’ORTKA=‘ ’ORTKA=‘
信息格式 复杂性 可读性 可信度等 互联网环境 量信息 海量数据 检索范围为学术期
、 、 、 。 ’ORTKA=‘ ’),
下 海量信息呈现多样性 高维度等特点 这种情境 刊和学位论文 检索年限不限 检索时间为 年
, 、 , , , 2021 3
下 消费者的心理状况会发生哪些变化 如何解释消 月 日 共检索出相关研究成果 篇 其中存在
, ? 28 , 1062 ,
费者决策 海量信息对消费者行为和决策过程带来 大量非学术研究 如拥抱大数据 不能止于技术的膜
? , 、
哪些影响 本研究采用文献计量方法 对信息过载环 拜等文献 通过手工筛选 最终保留消费者决策领域
? , , ,
[基金项目]教育部人文社会科学研究青年基金项目( );江苏省高校哲学社会科学研究基金项目( )。
17YJC630168 2016SJB630017
156 管理现代化 理论述评
SummeryinTheory
中与信息过载的前因 后果及应对策略相关的学术研 同聚类包含的术语和关键词 关键词节点越大 表明
、 。 ,
究文献 共 篇 该节点是网络中的关键节点 节点间连线的粗细程度
, 553 。 ,
反映共现强度
。
二、文献计量分析
(一)时间分布
从检索结果可知 年开始出现了采用数据仓
,2002
库 数据挖掘和联机分析处理等技术分析海量信息环
、
境下消费者决策的文献 截止检索日期 年只有
。 ,2021
篇相关文献 故删除 年之前有关信息过载
1 , 。2007 、
海量信息的论文数量较少 年开始 互联网环境
。2008 ,
发生变化 社交媒体成为热点话题 论坛 微博 博客
, , 、 、 、
社交网站 微信等社交媒体工具和平台逐步发展 发
、 ,
文量开始小幅增长 年 月 麦肯锡公司发表了
。2011 5 ,
题为
《Bigdata:Thenextfrontierforinnovation,
的研究报告 年
competition,andproductivity》 ,2012
智能手机开始规模化应用 移动互联网进入高速发展
,
时期 由于研究成果发表具有一定的滞后性 因此 从
, , ,
年开始 与大数据 信息过载 消费者有关的研究
2013 , 、 、
成果快速增长 年达到了 篇 很明显大数据时
,2018 84 , 图1 关键词聚类知识图谱
代消费者决策研究倍受关注 主要分布在计算机技术
, 由图 可知 商品属性 信息过载 在线评论 数
与应用 企业管理 旅游管理 图书情报档案等学科 1 , 、 、 、
、 、 、 。 据挖掘 数据处理 推荐系统 大数据时代这七个术语
以后 研究热度有所减缓 趋于平稳 、 、 、
2019 , , 。 是该领域在 年间研究的热点 进一步对
(二)作者合作分析 2002—2020 ,
聚类结果进行归纳和统计分析 信息过载和消费者决
设置时间切片为 年 运行得到节 ,
1 ,TOPN=50, 策领域研究主要集中在两个方面 一是信息过载给消
点数为 连线数为 的主要发文作者合作图谱 图 :
16、 5 , 费者带来的影响 二是应对信息过载的策略 可以分
谱中显示高产作者发文分布及合作情况 发文最多 , ,
。 为以人为中心的策略 以信息处理为中心的策略和以
的是以李爱梅为核心的学术团队 发表相关研究成果 、
, 技术为中心的策略 将 归为一大类 即大
篇 主要围绕信息超载对决策 组织员工和消费者行 。 #1#4#6 ,
4 , 、 数据时代信息过载对消费者决策带来的影响
为的影响展开 从注意资源 工作记忆资源和时间压 ;#0#5
。 、 归为一大类 通过构建消费者画像 实现个性化推
力方面解释信息超载影响决策的内在机制 信息超 #7 , ,
。 荐和精准营销 从而缓解消费者感知过载 单独归
载会降低员工的工作效率 决策质量和工作幸福感 , ;#2
、 , 为一类 探讨消费者如何借助信息线索应对过载效
对员工的工作状态和行为产生消极影响[2,5,6] ;选择超
应
,
单独列为一类 主要研究个性化推荐过程中的
载作为信息过载的一种表现形式 当商品数量超过一 ;#3 ,
, 关键技术 研究热点主题划分结果如表 所示
定的阈值 消费者会感知到过载效应 如选择困难 选 。 1 。
, , 、 表1 研究热点主题划分
择延迟等 但选择过载效应是否会发生 除了受消费
, ,
主题分类主题名称 包含的关键词及其频次
者认知因素和情绪因素的影响 还受选择集特征和消
,
大数据 信息过载 消费者 购买意
费者个体差异两类边界条件的影响[7] 。 过载 过载 愿 ( 选55 择), 过剩 ( 海20 量), 数据 (15 社), 交媒体
作者合作图谱中以点型模式为主 标示着独立研 影响 效应 (8), (7), (6),
, 消费者困惑
究成果数量较多 这也可能是由于样本文献中包含较 (5), (5)
, 电子商务 推荐系统 个性化推荐
(101), (54),
多学位论文的原因 总之 科研合作是影响高质量成 消费者 精准营销 遗传算法 机器学习
。 , (40), (16), (7),
果产出的因素之一 通过团队协作可以建立高效的研 画像 推荐算法 购买决策 协同过滤
, (6), (6), (6), (5),
究网络 ,更有利于新学科和新领域的研究探索
。
应对 用户偏好 (5),兴趣度 (5)
(三)高频关键词分布 策略
在线评论
在线评论 (35),有用性 (27),网络口碑 (10),影响
因素 文本挖掘 信息采纳
通过分析高频关键词的频次和分布 可以了解某 (8), (7), (5)
,
数据挖掘 关联规则
个领域的研究热点 、研究内容和发展趋势 。图 1给出 关键技术 矩阵分解(39), (1 聚5 类), 分Ma 析pReduce(9),
了关键词共现聚类图谱 其中 块不规则图形显示不 (6),Hadoop(5), (5)
, 8
2022年第1期 157 理论述评
SummeryinTheory
信息过载对消费者决策的影响 者的感知风险 降低其感知价值 最终造成决策延迟
1. , , ,
当消费者无法在有限的时间内处理大量的 模糊 且消费者涉入度对影响过程起到调节作用 高涉入度
、 ,
的 复杂的信息时 消费者会感到不知所措 引起心理 消费者比低涉入度消费者有更高的感知风险和更低
、 , ,
不适的负面情绪 ,造成决策困难 。总的来看 ,信息过 的感知价值[11] 。比较和权衡的过程增加了决策难度
,
载对消费者造成的影响主要体现在心理反应和行为 再加上偏好的不确定性和决策策略的差异性 导致消
,
反应两大方面 费者倾向于延迟选择
。 。
心理反应 信息过载产生决策规避 信息过载环境下 消费
(1) 。 ,
为了充分了解信息过载的影响 从 者不太可能做出明智的选择 通常会遇到负面的结
,Jacoby(1974) ,
消费者对自身行为的满意度 不确定性 困惑及后悔 果 如延迟决策 决策疲劳 决策失误 消费者为了缓
、 、 、 , 、 、 。
额外信息的需求等方面设计了主观状态量表 用来测 解信息过载引起的负面影响 一般采用购买回避 明
, , 、
量信息过载对消费者心理状态带来的影响[3] 。除此 晰目标 、搜寻额外信息 、分享购买或缩小选择集来减
之外 信息过载可能还会引起抑郁 焦虑等负面心理 少决策失误 其中 购买回避指消费者在搜寻信息 处
, 、 , , 、
反应 调查显示 的消费者怀疑自己购买的商品 理和评估信息之后 做出的一种消极反应 在线评论
。 ,61% , 。
不是最优选择 的消费者因选择过剩或产品相似 是消费者决策的重要参考依据 同时也会引起一些负
;62% ,
难以选到满意的产品[8]
。
面效应 ,如浏览成千上万 、甚至几十万条观点不一 、内
信息过载降低决策满意度 杨涛 设定购 容模糊的在线评论时 消费者会产生犹豫 选择购买
。 (2016) , ,
买情境 信息量和选择集依次分为三组 不足组 最佳 回避 在健康管理领域 信息消费者在搜寻 阅读 理
、 : 、 。 , 、 、
组和过载组 相应的信息量设为 条 条和 条 解大量难辨真伪的疫情信息时 会加剧疫情带来的恐
, 3 、10 30 , ,
选择集设为 项 项和 项 当信息量超过 条或 惧 担心等消极情绪 通过感知健康威胁对信息产生
3 、5 30 , 10 、 ,
者选择集超过 5项时 ,消费者心理不适感随之增加
,
防御式的规避行为[12]
。
决策满意度开始下降 其影响过程受消费者认知需求 信息过载引发负面口碑传播 产品复杂性 相似
, 。 、
水平的调节 因信息处理策略和认知努力程度不同 性和大量模糊的信息会增加消费决策难度 造成消费
, , ,
低认知需求的消费者更容易产生过载效应[9] 。当信 者认知负担 ,导致消费者产生困惑 。消费者困惑指消
息量增加时 消费者处理信息需要付出更多的时间成 费者在信息处理过程中 无法正确理解产品或服务信
, ,
本和认知成本 造成消费者感知成本增加 决策满意 息而引发的不知所措的心理状态 是一个三维构念
, , , ,
度下降 包括 相似困惑 超载困惑和模糊困惑 其中 超载困
。 : 、 , ,
信息过载易引起负面情绪 网络环境下 无序信 惑指消费者面对丰富的信息环境 无法在有限的时间
。 , ,
息使消费者难辨真伪 矛盾信息使消费者难以提取到 内处理信息而导致信息内容理解不足 使消费者对购
、 ,
有用的信息 当信息数量超过消费者的信息处理能力 买决策缺乏信心 可能导致购买错误品牌或传播负面
, ,
且面临时间压力时 消费者在选择过载中容易产生焦 口碑等行为 在线旅游产品充斥着大量相似 模棱两
, 。 、
虑情绪 当消费者面对数以百计千计的相似商品时 可的信息 消费者选择旅游产品时难以准确筛选出满
。 , ,
替代品的优点会被强化 机会成本使选择过程变得更 足自身需求的产品 消费者困惑通过负面情绪影响
, 。
加复杂 ,造成消费者体验负面情绪[8]
。
负面口碑传播 ,且产品涉入度越高 ,二者之间的关系
(2)行为反应 越强[13]
。
丰富的网络信息为消费者提供多样化选择和足 应对信息过载的策略
2.
够的信息量 一方面满足消费者多元化需求 另一方 信息过载不仅造成消费者决策质量下降 决策低
, , 、
面 消费者需要花更多的时间和认知努力去筛选 比 效 决策延迟甚至放弃决策 还会造成消费者困惑 焦
, 、 、 , 、
较和评估相关信息 进而降低购买意愿或延迟决策 虑等负面心理反应 因此 缓解信息过载 可以在恰
, , 。 , ,
发生决策规避 甚至进行负面口碑传播 当的时间提供给消费者合适的信息 帮助消费者做出
, 。 ,
信息过载降低消费者购买意愿 信息过载环境 正确的决策 消费者研究领域应对信息过载的策略
。 。
下 从众多相似的商品中选择满足自己需求的商品 可以分为三类 以消费者为中心的策略 以信息处理
, , : 、
消费者需要花费更多的时间和精力 即产生了选择复 为中心的策略和以技术为中心的策略
, 。
杂性 为了做出明智的选择 消费者会主动搜寻额外 以消费者为中心的策略
。 , (1)
信息 此过程导致消费者感知成本增加 进而购买意 以消费者为中心的策略即构建消费者画像 考虑
, , ,
愿降低[10]
。
消费者个人特征属性 、点击流 、社交信息和购买记录
信息过载导致决策延迟 过多的信息量需要消 等数据 构建可以描述消费者需求 行为习惯和个人
。 , 、
费者付出更多的努力和认知资源来应对 会增加消费 偏好的模型 即将海量的消费者数据抽象成标签 从
, , ,
158 管理现代化 理论述评
SummeryinTheory
而将消费者形象具体化 为消费提供个性化服务 实 选择偏差效应的影响 从而使决策稳定性变差 决策
, , , 、
施精准营销 大数据时代 消费者的各种行为数据呈 质量下降 评论摘要能够提供细粒度 多维度的评论
。 , 。 、
爆炸式增长 ,用户画像是实施个性化服务或精准营销 信息[19] ,对于搜索型商品 ,将在线评论依据产品属性
的有力工具 能够挖掘消费者的偏好和需求 帮助消 或用户感受生成分类标签 能够提高消费者感知有用
, , ,
费者过滤掉与自己需求不相关的干扰信息 冗余信 性 缓解信息过载和自我选择偏见对消费者决策的影
、 ,
息 ,降低信息过载带来的影响 ,为其提供个性化的商 响[20] 。不管图片评论还是文本评论 ,评论的客观性
、
品或服务 从而降低信息过载带来的决策低效问题 真实性是评论质量的重要因素之一 激励在某种程度
, 。 ,
消费者画像首先明确数据维度 也就是从哪些方 上能够促进消费者认真书写评论 有用的评论包括
, 。
面收集消费者数据 。一般来说 ,消费者画像的数据维 产品或服务的客观评价以及消费者的主观体验[16] ,高
度包括个人属性 如性别 年龄 教育程度 职业 信用 质量的在线评论是消费者提高决策质量的前提
( 、 、 、 、 。
等 点击流数据 购买记录 用户生成内容 社交信息 以技术为中心的策略
)、 、 、 、 (3)
等方面 其次 使用用户标签提取技术 如统计分析 以技术为中心的策略倾向于为信息超载问题寻
; , ( 、
协同过滤 主题模型 贝叶斯网络 机器学习 深度学 找技术解决方案 大数据环境下 信息过载问题愈发
、 、 、 、 。 ,
习等 从海量数据中挖掘消费者需求 行为习惯 兴 严重 给消费者决策增加困扰 个性化推荐能够有效
), 、 、 , ,
趣偏好等 生成用户标签 然后 利用统计图 词云图 缓解这一难题 从信息过滤角度来看 推荐系统通常
, ; , 、 。 ,
等可视化技术直观地呈现消费者特征 最后 在消费 被分为协同过滤系统 内容推荐系统和混合式推荐系
; , 、
者画像分析基础上 实施个性化推荐和精准营销 从 统 大数据推荐系统有效地解决了传统推荐系统在
, , 。
而能够更智能化 、准确地匹配其需求[14]
。
时间效率 、空间效率和推荐准确度方面的瓶颈问题
。
以信息处理为中心的策略 大数据推荐系统需要强有力的技术支持 如大数
(2) ,
以信息处理为中心的策略旨在帮助消费者解决 据挖掘技术 优化的推荐算法等 因此 信息过载环
、 。 ,
信息的复杂性和海量问题 如改变信息呈现方式 降 境下 消费者决策研究领域同样关注个性化推荐的关
, , ,
低信息复杂度 生成评论标签摘要 减少信息量 提供 键技术 即从单一数据源到多平台交叉融合数据分
; , ; ,
激励措施 ,提高信息质量等 。以消费者为中心的策略 析 、从传统推荐算法到自适应优化推荐算法[21]
。
强调以信息过滤和个性化推荐为主要手段来缓解信 的核心思想是分而治之 将海量数据分发
MapReduce ,
息过载对消费者决策的影响 但还不能让消费者完全 给不同的服务器 实现大量非结构化数据的并行处
, ,
忽略过载感知的存在 因此 消费者必须依靠主动学 理 基于 的分布式框架 能够为
。 , 。 Hadoop , MapReduce
习 如观察学习和社会学习 来减轻遭受的过载效应 提供运行载体 考虑用户历史行为数据 构建用户兴
( ) 。 。 ,
网络环境下 消费者产生购买决策后 出于利己或利 趣分布矩阵 结合历史数据和兴趣偏好的个性化推荐
, , ,
他目的 ,通常会选择分享自己的消费体验 ,即撰写在 策略[22] ,实现多源数据整合 ,运用关联规则和聚类分
线评论 导致在线平台的用户评论急剧增长 多则几 析的融合算法 使用多维评分效用表示消费者对项目
, , ,
十万条 因此 在线评论也会引起消费者感知过载 的偏好 该模型考虑多种上下文信息 对用户评论进
, , 。 , ,
近年来 信息过载环境下消费者研究的一个重要方向 行情感分析 融合用户评分 情感倾向和推荐商品内
, , 、
是在线评论和消费者决策 消费者受浏览时间和移 容信息的混合式推荐算法 解决了历史数据不足和评
。 ,
动工具小屏幕的限制 ,不可能阅读所有相关的评论
,
分数据稀疏问题[23]
。
帮助消费者从大规模评论集中找出有用评论 是解决 个性化推荐关键技术的完善有利于多角度分析
,
在线评论过载 提高消费者决策质量和决策效率的有 消费者行为 使推荐内容质量更高 推荐结果更及时
、 , 、 、
效途径 推荐信息更多样化 并且能够考虑到消费者历史行为
。 ,
实证研究表明 影响在线评论有用性的因素包 信息 动态信息需求和兴趣演变 提高消费者满意度
, 、 , 。
括 情感倾向 句子长度 评论客观性 评论呈现方式
: 、 、 、 、
信息质量等[15-17] 。评论呈现方式有星级 、文本 、图片和 三、研究主题演化分析
视频等 对于感官型产品 如触感评价衣服质量 视
。 , 、
觉推断衣服匹配度等 一图胜千言 图片评论正向影 关键词时区图表示研究主题随着时间推移发生
, ,
响消费者购买意愿[18] ,图片降低阅读文本评论的时间 的变化情况 ,侧重于从时间维度反映研究主题的演
和复杂性 当处理过多评论时 消费者倾向于采用启 变 图 给出了信息过载环境下消费者决策研究领
。 , 。 2
发式规则 如差评 平均星级 星级分布等 来降低阅 域关键词时序变化情况 总的来说 可以分为三个
( 、 、 ) , ,
读的评论数量 启发式规则更多地依赖于直觉 虽然 阶段
。 , :
加工速度快且占用较少的认知资源 但容易受到自我 第一阶段 年 消费模式悄然变化
, (2002—2008 ): 。
2022年第1期 159 理论述评
SummeryinTheory
模式相对缺乏 研究者相互交流和合作 能
。 ,
够助推该领域的研究效率和成果质量 科研
,
合作是影响高质量成果产出的因素之一
。
从关键词图谱来看 研究主要集中在两
3. ,
个方面 信息过载给消费者决策带来的影响
:
和应对信息过载的策略 且应对策略的关注
,
度更高 信息过载不仅容易引起消费者负面
。
情绪 满意度下降等心理反应 还会造成决策
、 ,
延迟 决策规避 负面口碑传播等行为反应
、 、 。
国内研究者提出的应对策略主要包括以消费
者为中心的策略 以信息处理为中心的策略
、
图2 研究主题演化图谱 和以技术为中心的策略 比较侧重客户精准
,
营销 网络口碑 个性化推荐关键技术等
主流消费从传统模式逐渐向网络消费模式转变 淘 、 、
, 内容
宝 京东商城等电子商务平台逐步企稳 此阶段信息 。
、 , (二)展望
过载不是消费者遭受的普遍现象 研究成果相对较
,
国内研究者主要关注信息过载对消费者心理和
少 高强度的突变词有消费者和电子商务
, 。
行为造成的影响 但缺乏完整的理论研究框架 且对
第二阶段 年 信息过载效应渐显 , ,
(2008—2013 ): 。
影响机制和个体差异缺乏深层次的分析 只有充分
互联网迅速发展 京东商城 天猫 淘宝等综合性电子 。
, 、 、
了解信息过载成因 症状表现 才能提出高效的应对
商务平台为消费者选择提供便捷 如京东商城探索增 、 ,
,
策略
值服务 开启上门取件 移动客户端相继上线 进军在 。
, 、 、
理论研究框架 世纪 年代 伴随品牌数
线医药和奢侈品领域 启动酒店预订和电子书刊业务 1. 。20 70 ,
、
量的激增 消费者研究领域的信息过载问题已经引起
等 在线消费成为消费者较好的选择 因此 消费者 ,
, 。 ,
了学者们的关注 诸多学者对 的研究结论进行
行为信息激增 ,信息过载给消费者决策带来心理和行 , Jacoby
激烈的争辩 争辩焦点是品牌数量及其属性信息是否
为方面的负面影响 ,
。
会影响消费者对产品的选择 以实验法 访谈法和问
第三阶段 年 信息过载应对阶段 , 、
(2013—2020 ): 。
卷调查为主 基于有限认知资源理论 探讨不同情境
随着大数据 移动互联网 社交媒体等技术的发展 信 , ,
、 、 ,
下信息过载对消费者决策质量 决策时间和信息处理
息过载现象频繁出现 此阶段研究者主要关注信息过 、
,
方式的影响 少有研究构建一个完整的概念框架 对
载的各种解决方案 来帮助消费者缓解过载效应 主 。 ,
, 。
信息过载和消费者决策之间的关系进行系统的理论
要的爆发词有 协同过滤 大数据 文本挖
: 、 、Hadoop、
阐述 郭佳等 发展了 和 的研
掘 。推荐系统和精准营销可以减少消费者选择集数 。 (2018) Eppler Mengis
量 ,大数据技术 、深度学习 、文本挖掘等技术能够优化 究成果 ,指出网络环境下信息过载研究的理论包括 :
个性化推荐效果 改善推荐质量 用户生成内容作为 信息加工理论 认知负荷理论 压力与应对模式 使用
、 , 、 、 、
外在信息线索 能够降低消费者决策的复杂性 满足理论和期望失验理论等多种理论 研究情境可以
, 。 ,
划分为信息检索和分析过程 决策过程和传播过
、
四、结论与展望 程[24] 。消费者决策是一个复杂的过程 ,可以分为五个
阶段 需求确认 信息搜索 评价与选择 购买决策和
: 、 、 、
(一)结论 购后行为 每个阶段消费者的关注点和目标不同 信
。 ,
本研究采用文献计量学方法 对国内信息过载和 息过载成因 症状表现和应对策略也存在差异 比如
, 、 , ,
消费者决策领域相关文献进行系统梳理 绘制了知识 信息搜索阶段 由于信息特征 页面设计 个体特征和
, , 、 、
图谱 研究结果显示 动机强度等因素对消费者搜索行为产生影响 导致消
。 : ,
从发文时间看 随着大数据概念的提出和移动 费者难以获取有用或准确的信息 造成搜索效率下
1. , ,
互联网的高速发展 信息过载环境下消费者决策研究 降 从技术层面 如信息过滤和推荐技术 能够有效
, 。 ( )
倍受国内学者关注 研究成果快速增长 年之 缓解消费者的感知过载 因此 构建一个概念框架
, 。2008 。 , ,
前 网络消费非主流模式 信息过载不是消费者遭遇 明晰信息过载对消费者决策过程的影响 能够提出有
, , ,
的普遍现象 针对性的解决方案
。 。
从发文作者来看 国内该领域研究者的合作关 影响机制研究 并不是所有年龄段的消费者都
2. , 2. 。
系较弱 点型研究模式更为普遍 线型和星型等合作 会遭受过载效应 青年人和成年人相似 容易受到过
, , , ,
160 管理现代化 理论述评
SummeryinTheory
度选择效应的负面影响 但儿童和老年人遭受的负面 费者购买意愿的形成研究[] 价格理论与实践,
, J .
影响较少[25] 。成年人中出现选择过载效应 ,主要归因 2013,( 04)
.
于认知因素和情绪因素 而儿童与老人的认知能力相 [ ]李亮,黄赞 网上信息特征对于消费者延迟选择
, 11 .
对较低 过载效应是否会真正发生 还受到信息复杂 的影响研究[]情报科学, , ( )
。 , J. 2016 3402 .
性 决策任务难度 偏好不确定性 决策目标等调节变 [ ]陈琼,宋士杰,赵宇翔 突发公共卫生事件中信
、 、 、 12 .
量的影响 面对复杂问题决策时 不同消费者的信息 息过载对用户信息规避行为的影响:基于 信
。 , covid-19
处理方式存在差异 消费者通常依赖启发式信息来 息疫情的实证研究[] 情报资料工作, ,
。 J . 2020 41
简化决策过程 通过启发式信息减少选择的数量 例 ( )
, , 03 .
如消费者倾向于考虑知名品牌的商品 好品牌意味着 [ ]涂红伟,伍世代 在线旅游消费者困惑对负面口
, 13 .
高质量 当大量选择与品牌关联时 青少年的过载效 碑的影响———基于情绪聚焦应对的视角[] 旅游学
, , J .
应就会消失 没有表现出满意度下降 决策困难和遗 刊, , ( )
, 、 2019 3407 .
憾[26] 。因此 ,考虑到消费者个体差异 、偏好不确定性
、
[ 14]徐芳,应洁茹 .国内外用户画像研究综述[ J] .图
决策情境差异等因素 消费者面对海量信息时的决策 书馆学研究, ,( )
, 2020 12 .
又会发生什么变化 导致消费者感知过载的影响因 [ ]郝媛媛,叶强,李一军 基于影评数据的在线评
? 15 .
素 中介变量和调节变量等边界条件又有哪些 这些 论有用性影响因素研究[]管理科学学报, ,
、 ? J. 2010 13
问题值得研究者进一步探讨 ( )
。□ 08 .
[ ]李琪,阮燕雅 在线评论认真书写的激励机
16 .
[参考文献] 制———以优惠券为例[] 系统管理学报, ,
J . 2016 25
[] ( )
1 Roetzel P G.Information Overload in the 03 .
: [ ]江晓东 什么样的产品评论最有用? ———在线
InformationAge AReviewoftheLiteraturefrom 17 .
, , 评论数量特征和文本特征对其有用性的影响研究[]
BusinessAdministration BusinessPsychology and J.
外国经济与管理, , ( )
RelatedDisciplineswithaBibliometricApproachand 2015 3704 .
[ ] , [ ]林爽,吕兴洋,宋慧林 一图胜千言? 图片与文
Framework Development J .Business Research 18 .
, ( ): 字在线评论对消费者购买意向的影响研究[] 商业
2019 1202 479-522. J .
[]李爱梅,车敬上,刘楠,等 海量信息如何影响跨 经济与管理, ,( )
2 . 2017 08 .
期决策? 基于注意资源的理论视角[] 心理科学进 [ ]章成志,童甜甜,周清清 基于细粒度评论挖掘
J . 19 .
展, , ( ) 的书评自动摘要研究[]情报学报, , ( )
2021 2909 . J. 2021 4002 .
[] [ ]刘景方,李嘉,张朋柱,等 用户评论标签摘要系统
3 JacobyJ.BrandChoiceBehaviorasaFunctionof 20 .
[ ] 的有效性研究[]系统管理学报, , ( )
Information Load J .Journal of Marketing J. 2016 2504.
, , ( ): [ ]李翠平,蓝梦微,邹本友,等 大数据与推荐系
Research 1974 1101 63-69. 21 .
[] 统[]大数据, , ( )
4 MalhotraNK.InformationLoadandConsumer J. 2015 103 .
[] , [ ]王娜,何晓明,刘志强,等 一种基于用户播放
DecisionMakingJ.JournalofConsumerResearch 22 .
, ( ): 行为序列的个性化视频推荐策略[] 计算机学报,
1982 804 419-430. J .
[]车敬上,孙海龙,肖晨洁,等 为什么信息超载损 , ( )
5 . 2020 4301 .
害决策? 基于有限认知资源的解释[] 心理科学进 [ ]张宜浩,朱小飞,徐传运,等 基于用户评论的
J . 23 .
展, , ( ) 深度情感分析和多视图协同融合的混合推荐方法[]
2019 2710 . J.
[]李爱梅,李利平,车敬上 互联网环境下的信息 计算机学报, , ( )
6 . 2019 4206 .
超载及其对组织员工的影响[]商学研究, , [ ]郭佳,黄程松 国外网络环境中信息过载研究进
J. 2019 26 24 .
( ) 展[]情报科学, , ( )
04 . J. 2018 3607 .
[]刘楠,李爱梅,丁浩,等 “多多益善”还是“过犹 [ ] , ,
7 . 25 MisuracaR Teuscher U FaraciP.Is More
不及”? ———选择超载与消费者决策行为研究[]外 ?
J. Choice Always Worse Age Differencesin the
国经济与管理, , ( ) [ ]
2017 3909 . Overchoice Effect J .Journal of Cognitive
[]齐莉丽,赵蕊 信息过载对在线消费者购物决策 , , ( ):
8 . Psychology 2015 2802 242-255.
的影响[]商业经济研究, ,( ) [ ] , , ,
J. 2018 10 . 26 MisuracaR CeresiaF Nixon A E etal.
[]杨涛 信息过载对网络消费者过程满意度和购买 ?
9 . WhenIsMoreReallyMore TheEffectofBrandson
意向影响的研究[]陕西师范大学, [ ]
D . 2016. Choice Overloadin Adolescents J .Journalof
[ ]何仲,张念照,吕廷杰 信息过载环境下网络消 , , ( ):
10 . ConsumerMarketing 2021 3802 168-177.
2022年第1期 161 --------------------------------------------------------------------------------- DOI:10.19851/j.cnki.cn11-1010/f.2013.04.046
市场篇
何 仲 张念照 吕廷杰
信息过载环境下网络消费者购买意愿的形成研究
内容提要：电子商务中丰富的商品信息已造成信息过载现象，这
之间的相似程度。
2.感知效用。商品效用的大小是消费者购买决策
将对消费者购买决策产生重要影响。本文首先对信息过载环境下网络
的出发点。消费者感知效用受商品质量、价格、包装、
消费者购买意愿的形成进行理论研究，然后，构建相应结构方程模型，
运用问卷调查获取数据并对有效样本进行实证分析。最后，对电子商
服务、购物安全等各种有形与无形因素的影响。信息
务平台企业提出相应的经营建议。
过载的首要表现是丰富的商品选择。丰富的商品选
关键词：信息过载 选择过剩 购买意愿 择能够满足消费者多元化需求，提升选择自由度，降
低搜索成本。同时，满足消费者追求多样化和创新性
电子商务是网络化的新型商务贸易活动，其应用随着互
的愿望，以及增加消费者最终购买商品的信心。因此，在充分
联网的迅速发展而日渐深入。由于其在转变经济增长方式、促
掌握商品信息情况下，商品类别包含商品数量越多，消费者感
进产业结构升级、增加就业、形成新的消费习惯等方面具有重
知的效用越大。
要作用，因此越来越受到各国政府和企业界的重视。近几年，
3.感知成本。在信息过载环境下，消费者将会面临极大丰
电子商务在我国也获得了突飞猛进的发展，越来越多的消费
富的商品信息，在对备选商品进行对比和权衡时，需要花费更
者选择网上购物，同时，网络交易规模也逐年扩大。据中国互
多的时间和精力考察每一可供选择的商品。但是，由于消费者
联网络信息中心统计，截止2012年12月底，我国网民规模达
到5.64亿，其中网络购物用户规模达到2.42亿人，网络购
信息处理能力的有限性，会感受到认知负担。同时，为了做出
物使用率提升至42.9%。据中国电子商务研究中心发布的报 更明智的决策，消费者往往需要搜寻更多的信息来做支撑，此
告显示，2012年我国电子商务交易规模达7.85万亿元，其中 时，消费者往往面临较高的搜寻成本。此外，选定了某一商品
网络零售交易规模达1.32万亿元，成为仅次于美国的第二大 则意味着必须放弃对其他众多商品的购买，网络上提供的商
网购市场。 品越多，消费者的机会成本也就越高。
伴随电子商务市场蓬勃发展，网络商品信息极大丰富，巨 4.消费者特征。在面对选择复杂性时，不同类型的消费者
量的商品信息已经超过了消费者个人承受能力，导致信息过 反应是不同的。不同偏好的消费者往往对相同商品的评价不
载现象的产生。在已有的对网络消费者购买意愿的研究中，学 同，进而影响商品的网购意愿。此外，消费者自身的个性特征
者多从信任、感知风险、感知价值、服务质量等角度考察购买 以及消费者对某一商品所在行业的认知程度不同，也会对商
意愿和行为，尚没有学者研究信息过载对购买意愿的影响。本 品的网购意愿产生较大影响。
研究在已有文献的基础上，构建了信息过载环境下网络消费者 综上可知，信息过载环境下网络消费者购买意愿形成的
购买意愿形成过程的理论模型，并通过实证研究予以验证。 影响因素主要包括消费者选择商品的复杂性、感知效用、感知
成本以及消费者特征等。
一、信息过载环境下网络消费者购买意愿
形成的因素分析 二、信息过载环境下网络消费者购买意愿
在信息过载环境下，种类繁多的商品为消费者提供了更 形成的实证分析
多的选择余地。同时，长尾效应的存在也满足了更多消费者的 （一）变量的选择和度量
个性需求。然而，信息过载容易导致选择复杂性问题，消费者 综合上述理论研究，本文从选择复杂性、感知效用、感知
需要花费更多的时间和精力对比不同商品，做出购买决策。然 成本三个因素出发，构建了信息过载环境下网络消费者购买
而，这个过程容易导致消费者产生负面情绪，从而降低对商品 意愿形成过程的研究模型，如图1所示，并选择消费者预先
的购买意愿。因此，本文将从选择复杂性、感知效用、感知成本 偏好、个性特征、认知程度作为评价消费者特征的调节变
和消费者特征等几个方面来研究信息过载环境下网络消费者 量。同时，本文选择结构方程模型（SEM）和层次回归分析方法
购买意愿的形成过程。 作为样本数据的分析工具，并设计了24个测量问题项来观察
1.选择复杂性。在信息过载环境下，消费者将会面临数量 度量模型中的各个潜变量。每个测量项采用Likert七级分值
众多的备选商品，且各商品之间具有较高的相似度。此时，消 进行评分。
费者往往需要花费更多的时间和精力来思考和评估备选商 （二）数据的收集和统计
品，以做出合理的购买决策，即产生了选择复杂性。因此，可以 1.数据收集和统计。本次问卷调查以具有网络购物经历
说，选择复杂性主要来自于两个方面：备选商品数量和各商品 的互联网用户为调查对象，共调查了521名国内网民，有效样
本栏目由国核示范电站有限责任公司支持。 95 2013年第4期·总第346期 ·营销论坛·
本数为476份。其中，男性样本数为174份，女性样本数为 本和购买意愿。女性消费者的感知效用高于男性，但在选择复
302份；年龄在18至45周岁之间的样本数为474份；大部分 杂性、感知成本、购买意愿等方面不存在显著差异。年龄在18
调查用户的月收入都在1500-7000元之间。 至30岁的消费者感知到的选择复杂性显著高于其他年龄的
2.信度和效度检验。本文采用Cronbach’s alpha系数考 人群，并且消费者的购买意愿随着年龄的增加越来越高。随着
察该量表的信度，其中选择复杂性、感知效用、感知成本的 收入的提高，消费者感知到的选择复杂性越来越低，感知效用
Cronbach’s alpha系数分别为0.910、0.824、0.670，均大于 越来越高，购买意愿也越来越高。
0.6，说明该量表的可靠性或稳定性较高。
为了检验该量表的构建效度，本文对通过问卷调查获得 三、信息过载环境下电子商务平台企业的经营策略
的数据进行了KMO检验，并对研究模型中各个潜变量的测量 通过实证分析可以看出，随着互联网的普及和电子商务
项做了验证性因子分析，结果显示KMO值为0.864，球形度检 的发展，信息过载现象以及由此导致的选择复杂性现象将会
验近似卡方值为3509.771，相伴概率为0.000，适合做因子分 越来越普遍，并影响到消费者的购买意愿。因此，电子商务平
析。各题项在相应变量上的载荷均大于0.5，且方差累积贡献 台企业可以从以下几个方面入手解决信息过载问题：
率达到60.368%，说明各潜变量的结构效度良好。
1.严格遵守“少而精”的商家准入原则，打造品牌化和差
（三）模型拟合 异化商品。要解决选择复杂性带来的问题，应从商品数量的
本文的研究模型是结构方程模型，运用Amos17.0对模型
优化和商品质量的差异化入手，在商品数量方面求精不求
适配度进行检验，具体指标值如表1所示，各个检测指标项的
多，严格控制商家准入资格，引入知名品牌商，提高商品的
值均在接受范围内，说明该模型的适配度良好。
品牌化和差异化程度。随着移动互联网的发展，移动端的
表1 模型适配度检验 电子商务也成为新趋势。与传统电子商务相比较，移动
电子商务呈现时间碎片化、交易情景化、界面局限化等
特点，这些都使得消费者在购买之前考虑的商品数量相
比于在传统电子商务购物中所考虑的商品数量要少，这进一
信息过载环境下网络消费者购买意愿形成过程研究模型
步体现了引入高质量商家或品牌商的必要性。
拟合结果如图1所示。除了感知效用对感知成本影响不显著
2.优化商品展示，降低消费者感知成本。商品选择复杂性
之外，其余变量之间的影响系数均为显著。除此之外，本文还
带来的感知成本会削弱消费者的购买意愿，而认知成本和
采用层次回归分析方法检验了各调节变量的影响。
搜寻成本是感知成本的重要组成部分，因而应以消费者最
图1 信息过载环境下网络消费者购买意愿形成过程研究模型
易接受和理解的方式进行商品展示，降低其认知成本。同
时，提高商品搜索匹配度和提供个性化的商品推荐，降低消
费者的搜寻成本。
3.以垂直化电子商务平台为切入点，满足不同细分市场
需求。相对于综合性电子商务平台而言，垂直化电子商务平台
在商品数量信息、商品细节信息、消费者认知程度方面具有一
定的优势，可以在一定程度上降低消费者的选择复杂性，增加
注：*表示显著性水平为0.05，**表示显著性水平为0.01，***表示显著性水平为
消费者的感知效用，提升消费者的购买意愿。因此，当前应着
0.001，n.s.表示不显著。 力发展垂直化电子商务交易平台。
（四）实证结果分析
4.优化配套服务体系，提升消费者服务质量感知。研
通过实证分析，可以得出以下结论：
究表明，在信息过载环境下消费者往往对其购买的商品具
1.信息过载影响消费者选择。在消费者面临的选择复杂 有较低的满意度，而影响其下一次的购买意愿。电子商务
性的调查中，选择复杂性综合得分均值达到了5.27（满分为7 企业应积极提升物流服务、客户服务等方面的质量，提升
分），说明当前的电子商务企业提供了较多的商品选择，导致 购物全过程的用户体验，提高消费者的满意度。
消费者出现选择困难的现象。 参考文献：
2.选择复杂性直接影响购买决策。选择复杂性能够通过 [1]蔺丰奇,刘益.信息过载问题研究述评[J].情报资料工作,2007（5）.
影响消费者感知效用而正向影响购买意愿，通过影响消费者 [2]Barbara Fasolo, Ralph Hertwig, Michael Huber, Mark Ludwig.
Size,entropy,anddensity:whatisthedifferencethatmakesthedifference
感知成本而负向影响购买意愿。同时，选择复杂性导致的选择
between small and large real-world assortments? [J]. Psychology &
过剩也会直接负向影响网络消费者的购买意愿。
Marketing,2009（3）.
3.消费者自身特征影响购买意愿。在面对大量的商品选
[3]吴明隆.结构方程模型———AMOS的操作与应用[M].重庆：重
择时，具有预先偏好的消费者的购买意愿高于不具有预先偏
庆大学出版社,2009
好的消费者的购买意愿；对商品认知程度较高的消费者的购
[4]潘煜,张星,高丽.网络零售中影响消费者购买意愿因素研究———
买意愿高于对商品不熟悉的消费者的购买意愿；追求效用最
基于信任与感知风险的分析[J].中国工业经济,2010（7）.
大化的消费者的购买意愿高于追求满意即可的消费者的购买
[5]荆林波.技术变革与电子商务在中国的发展[J].价格理论与实
意愿。
践,2013(3).
4.不同消费者具有不同的选择复杂性、感知效用、感知成 （作者单位：北京邮电大学）
96 --------------------------------------------------------------------------------- 第３９卷 第１期 计 算 机 学 报 Ｖｏｌ．３９ Ｎｏ．１
２０１６年１月 ＣＨＩＮＥＳＥ ＪＯＵＲＮＡＬ ＯＦ ＣＯＭＰＵＴＥＲＳ Ｊａｎ．２０１６
利用社交关系的实值条件
受限玻尔兹曼机协同过滤推荐算法
何洁月 马 贝
（东南大学计算机科学与工程学院 南京 ２１００９６）
（东南大学计算机网络和信息集成教育部重点实验室 南京 ２１００９６）
摘 要 利用受限玻尔兹曼机（Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ Ｍａｃｈｉｎｅ，ＲＢＭ）解决推荐问题已成为一个很有意义的研究方
向．目前用于推荐的ＲＢＭ模型中使用的仅仅是用户评分数据，但用户评分数据存在着严重的数据稀疏性问题．随
着互联网对人们生活的不断渗透，社交网络已经成为人们生活中不可缺少的一部分，利用社交网络中的好友信任
关系，有助于缓解评分数据的稀疏性问题，提高推荐系统的性能．因此，该文首先提出基于实值的状态玻尔兹曼机
（Ｒｅａｌ－Ｖａｌｕｅｄ Ｃｏｎｄｉｔｉｏｎａｌ Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ Ｍａｃｈｉｎｅ，Ｒ＿ＣＲＢＭ）模型，此模型不需要将评分数据转化为一个Ｋ
维的０－１向量，并且Ｒ＿ＣＲＢＭ模型在训练过程中使用了训练数据中潜在的评分／未评分信息；同时该文将最近信任
好友关系应用到Ｒ＿ＣＲＢＭ模型推荐过程中．在百度数据集和Ｅｐｉｎｉｏｎｓ数据集上的实验结果表明Ｒ＿ＣＲＢＭ模型和
引入的最近信任好友关系均有助于提高推荐系统的预测精度；最后，针对大数据环境下，普通平台很难完成
Ｒ＿ＣＲＢＭ模型训练的问题，该文提出基于Ｓｐａｒｋ的并行化方案，较好地解决了该问题．
关键词 受限玻尔兹曼机；数据稀疏性；Ｒ＿ＣＲＢＭ；社交网络；信任关系；大数据
中图法分类号 ＴＰ３９３ ＤＯＩ号 １０．１１８９７／ＳＰ．Ｊ．１０１６．２０１６．００１８３
Ｂａｓｅｄ ｏｎ Ｒｅａｌ－Ｖａｌｕｅｄ Ｃｏｎｄｉｔｉｏｎａｌ Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ Ｍａｃｈｉｎｅ ａｎｄ
Ｓｏｃｉａｌ Ｎｅｔｗｏｒｋ ｆｏｒ Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｆｉｌｔｅｒｉｎｇ
ＨＥ Ｊｉｅ－Ｙｕｅ ＭＡ Ｂｅｉ
（Ｓｃｈｏｏｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ ａｎｄ Ｅｎｇｉｎｅｅｒｉｎｇ，Ｓｏｕｔｈｅａｓｔ Ｕｎｉｖｅｒｓｉｔｙ，Ｎａｎｊｉｎｇ ２１００９６）
（ＭＯＥ Ｋｅｙ Ｌａｂｏｒａｔｏｒｙ ｏｆ Ｃｏｍｐｕｔｅｒ Ｎｅｔｗｏｒｋ ａｎｄ Ｉｎｆｏｒｍａｔｉｏｎ Ｉｎｔｅｇｒａｔｉｏｎ，Ｓｏｕｔｈｅａｓｔ Ｕｎｉｖｅｒｓｉｔｙ，Ｎａｎｊｉｎｇ ２１００９６）
Ａｂｓｔｒａｃｔ Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ Ｍａｃｈｉｎｅ（ＲＢＭ）ｆｏｒ Ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｈａｓ ｂｅｃｏｍｅ ｏｎｅ ｏｆ
ｔｈｅ ｓｉｇｎｉｆｉｃａｎｔ ｒｅｓｅａｒｃｈｅｓ．Ｃｕｒｒｅｎｔｌｙ，ＲＢＭ ｍｏｄｅｌ ｆｏｒ Ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｏｎｌｙ ｕｓｅ ｕｓｅｒｓ ｒａｔｉｎｇ
ｄａｔａ．Ｈｏｗｅｖｅｒ，ｔｈｅｒｅ ａｒｅ ｓｅｒｉｏｕｓ ｄａｔａ ｓｐａｒｓｉｔｙ ｉｎ ｕｓｅｒｓ ｒａｔｉｎｇ ｄａｔａ．Ａｓ ｔｈｅ Ｉｎｔｅｒｎｅｔ ｃｏｎｔｉｎｕｅｓ ｔｏ
ｐｅｎｅｔｒａｔｅ ｏｎ ｐｅｏｐｌｅ’ｓ ｌｉｖｅｓ，ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ ｈａｖｅ ｂｅｃｏｍｅ ａｎ ｉｎｄｉｓｐｅｎｓａｂｌｅ ｐａｒｔ ｏｆ ｌｉｆｅ．Ｆｒｉｅｎｄｓ
ｔｒｕｓｔ ｒｅｌａｔｉｏｎｓｈｉｐｓ ｉｎ ｓｏｃｉａｌ ｎｅｔｗｏｒｋ ｃａｎ ｈｅｌｐ ａｌｌｅｖｉａｔｅ ｔｈｅ ｐｒｏｂｌｅｍ ｏｆ ｓｐａｒｓｅ ｒａｔｉｎｇ ｄａｔａ ａｎｄ
ｉｍｐｒｏｖｅ ｔｈｅ ｐｅｒｆｏｒｍａｎｃｅ ｏｆ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ．Ｔｈｅｒｅｆｏｒｅ，ａ Ｒｅａｌ－Ｖａｌｕｅｄ Ｃｏｎｄｉｔｉｏｎａｌ
Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ Ｍａｃｈｉｎｅ（Ｒ＿ＣＲＢＭ）ｍｏｄｅｌ ｉｓ ｐｒｏｐｏｓｅｄ ｉｎ ｔｈｉｓ ｐａｐｅｒ．Ｉｎ ｔｈｅ Ｒ＿ＣＲＢＭ
ｍｏｄｅｌ，ｒａｔｉｎｇ ｄａｔａ ｄｏｅｓ ｎｏｔ ｎｅｅｄ ｔｏ ｂｅ ｃｏｎｖｅｒｔｅｄ ｔｏ ａ Ｋｄｉｍｅｎｓｉｏｎａｌ ０－１ｖｅｃｔｏｒ ｕｎｉｔ．Ｍｅａｎｗｈｉｌｅ，
ｔｈｅ ｔｒａｉｎｉｎｇ ｐｒｏｃｅｓｓ ｏｆ Ｒ＿ＣＲＢＭ ｍｏｄｅｌ ａｌｓｏ ｕｓｅｓ ｒａｔｅｄ／ｕｎｒａｔｅｄ ｉｎｆｏｒｍａｔｉｏｎ．Ｍｏｒｅｏｖｅｒ，ｔｈｅ
ｎｅａｒｅｓｔ ｔｒｕｓｔｅｄ ｒｅｌａｔｉｏｎｓｈｉｐｓ ａｒｅ ａｐｐｌｉｅｄ ｔｏ ｔｈｅ Ｒ＿ＣＲＢＭ ｍｏｄｅｌ ｉｎ ｔｈｅ ｒｅｃｏｍｍｅｎｄｅｄ ｐｒｏｃｅｓｓ．Ｔｈｅ
ｅｘｐｅｒｉｍｅｎｔａｌ ｒｅｓｕｌｔｓ ｆｒｏｍ Ｂａｉｄｕ ａｎｄ Ｅｐｉｎｉｏｎｓ ｄａｔａｓｅｔｓ ｓｈｏｗ ｔｈａｔ ｔｈｅ Ｒ＿ＣＲＢＭ ｍｏｄｅｌ ａｎｄ ｔｈｅ
ｎｅａｒｅｓｔ ｔｒｕｓｔｅｄ ｒｅｌａｔｉｏｎｓｈｉｐｓ ｈｅｌｐ ｔｏ ｉｍｐｒｏｖｅ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ ａｃｃｕｒａｃｙ ｏｆ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ．
Ｆｉｎａｌｌｙ，ｄｕｅ ｔｏ ａ ｃｏｍｍｏｎ ｐｌａｔｆｏｒｍ ｉｓ ｖｅｒｙ ｄｉｆｆｉｃｕｌｔ ｔｏ ｔｒａｉｎ Ｒ＿ＣＲＢＭ ｍｏｄｅｌ ｉｎ ｂｉｇ ｄａｔａ．Ｔｈｅｒｅｆｏｒｅ，
ａｐａｒａｌｌｅｌｉｚａｔｉｏｎ ｓｃｈｅｍｅ ｂａｓｅｄ ｏｎ Ｓｐａｒｋ ｉｓ ａｌｓｏ ｐｒｏｐｏｓｅｄ ｉｎ ｔｈｉｓ ｐａｐｅｒ．Ｔｈｅ ｅｘｐｅｒｉｍｅｎｔａｌ ｒｅｓｕｌｔ
ｓｈｏｗｓ ｔｈａｔ ｔｈｅ ｐａｒａｌｌｅｌｉｚａｔｉｏｎ ｍｅｔｈｏｄ ｆｏｒ Ｒ＿ＣＲＢＭ ｉｓ ａ ｇｏｏｄ ｓｏｌｕｔｉｏｎ ｆｏｒ ｔｈｉｓ ｐｒｏｂｌｅｍ．
Ｋｅｙｗｏｒｄｓ ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅ；ｄａｔａ ｓｐａｒｓｉｔｙ；ｒｅａｌ－ｖａｌｕｅｄ ｃｏｎｄｉｔｉｏｎａｌ ｒｅｓｔｒｉｃｔｅｄ
Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅ；ｓｏｃｉａｌ ｎｅｔｗｏｒｋ；ｔｒｕｓｔ ｒｅｌａｔｉｏｎｓｈｉｐｓ；ｂｉｇ ｄａｔａ
收稿日期：２０１５－０１－１８；在线出版日期：２０１５－０５－１１．本课题得到江苏省自然科学基金（ＢＫ２０１２７４２）和软件新技术与产业化协同创新中心
部分资助．何洁月，女，１９６４年生，博士，教授，中国计算机学会（ＣＣＦ）会员，主要研究领域为数据密集型计算、生物信息学、数据挖掘和机
器学习等．Ｅ－ｍａｉｌ：ｊｉｅｙｕｅｈｅ＠ｓｅｕ．ｅｄｕ．ｃｎ．马 贝，男，１９９０年生，硕士，主要研究方向为深度学习、协同过滤推荐． １８４ 计 算 机 学 报 ２０１６年
权重和偏置是共享的，所以如果两个用户对同一项
１ 引 言 目进行了评分，那么将会使用同一个权重．作者同时
提出了条件受限玻尔兹曼机 （Ｃｏｎｄｉｔｉｏｎａｌ ＲＢＭ，
随着互联网和信息技术的快速发展，微博、即时 ＣＲＢＭ）模型，ＣＲＢＭ训练过程中利用潜藏在评分数
通讯、搜索引擎、电子商务、网络游戏等网络业务越 据中的评分／未评分数息，更加突出评分数据的作用．
来越普及，网络信息服务已经渗透到人们生活的各 但是Ｓａｌａｋｈｕｔｄｉｎｏｖ等人［２］所提模型的缺陷是：需要
个方面，导致互联网用户的数量急剧增长．急剧增加 将实值的评分数据转化为一个Ｋ维的０－１向量，可
的不仅仅是互联网用户的数量，还包括各种繁多的 见层与隐藏层之间的连接权重变为Ｍ×Ｋ×Ｓ维，
交易数据． 维数变为了原来的Ｋ倍，从而导致参数过多、训练
面对互联网上如此海量的商品，用户不得不浪 过程复杂、模型训练时间较长；而且该模型只能将整
费大量的时间来选择自己感兴趣的商品．基于此，推 型的评分数据转化为一个Ｋ维的０－１向量，如果训
荐系统应运而生，出现了很多商用推荐系统，比如为 练数据中的评分是Ｄｏｕｂｌｅ型的就无法转化．２０１３年
用户推荐图书和其它商品的 Ａｍａｚｏｎ，中国最大的 Ｇｅｏｒｇｉｅｖ等人［４］提出了可直接处理实值评分数据的
电子商务平台淘宝网，电影推荐系统 ＭｏｖｉｅＬｅｎｓ，文 ＲＢＭ模型并且改进了模型的训练过程，使ＲＢＭ 的
章推荐系统ＧｒｏｕｐＬｅｎｓ等． 可见单元可以直接表示实值，模型的训练和预测过
协同过滤推荐系统的应用最为广泛和成功．协 程得到了简化，但是模型只利用评分数据，未能解决
同过滤算法分成两类［１］：基于内存的协同过滤 数据的稀疏性问题；此外，虽然作者改进了ＲＢＭ的
（Ｍｅｍｏｒｙ－ｂａｓｅｄ ＣＦ）、基于模型的协同过滤（Ｍｏｄｅｌ－ 训练过程，提高了模型的推荐效果，但是此模型使
ｂａｓｅｄ ＣＦ）．基于内存的协同过滤，首先是计算用户 所有用户对同一项目的预测评分都相同，缺乏可解
（或项目）之间的相似度，然后是聚合最相似的若干 释性．
用户（或项目）的评分进行预测．推荐过程中主要根 近年来，随着社交网络的流行，利用社交网络中
据评分矩阵来进行，评分矩阵就好像是在内存中一 的社交关系来提供推荐服务受到了越来越多学者的
样．基于模型的协同过滤是从已有的评分矩阵中学 关注和研究．相对于传统的推荐系统，基于社交网络
习出一个紧凑的模型，后续推荐中用这个模型进行 的推荐系统具有可靠性高、转化潜在需求为实际购
预测．建立用户模型是该方法的核心，目前常用的模 买力强等特点．由于人们在社交网络中表达了很多
型包括回归模型、贝叶斯模型、聚类模型、马尔可夫 隐含的兴趣、爱好等社会媒体信息，因此基于社交网
模型、隐语义模型、奇异值分解模型、受限玻尔兹曼 络的推荐系统可以充分利用这些隐含的社会媒体信
机（Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ Ｍａｃｈｉｎｅ，ＲＢＭ）模型［２］ 息．目前基于社交网络的推荐系统中一种常用的社
等．其中ＲＢＭ模型因其准确度较高近年来受到较 会媒体信息是社会信任网络．
大关注． Ｇｏｌｂｅｃｋ［５］假设用户精确提供了对社交网络中
ＲＢＭ（图３（ａ））可以被视为一个无向图模型，它 其他用户的信任评分，使用信任值取代相似性的查
由两层二进制单元组成：一个可见层，表示数据；一 找，解决数据稀疏性问题．但用户提供对社交网络中
个隐层，可视为特征提取器增加学习能力［３］，并且层 所有用户的信任评分是不可能的，于是作者提出了
内无连接．ＲＢＭ模型已经被实验证明是一种有效的 一种ＴｉｄａｌＴｒｕｓｔ［６］推测机制：以广度优先搜索方式
解决推荐问题的方法［２，４］． 推测与其他用户之间的间接信任值．Ｍａｓｓａ等人［７－８］
２００７年Ｓａｌａｋｈｕｔｄｉｎｏｖ等人［２］首次将ＲＢＭ 模 使用类似于Ｇｏｌｂｅｃｋ［５］的方法，但其推导间接用户
型应用于解决推荐问题，作者对传统的ＲＢＭ 做了 间之间的信任值的主要思想是：考虑预先设定的距
两点改变：首先，可见层用一个长度为Ｋ的０－１向量 离范围内的所有用户，对所有到达用户的路径上的
单元表示评分数据；其次，用户可能只对若干个项目 信任值进行加权和，该方法被称为 ＭｏｌｅＴｒｕｓｔ［７－８］
进行评分，对没有评分的项目使用一种特殊的 算法．
（Ｍｉｓｓｉｎｇ）单元表示，这种单元不与任何隐层的单元 Ｍａ等人［９－１０］提出了一种基于概率矩阵分解的
连接．每一个用户都有一个单独的 ＲＢＭ，这些 因子分析方法，该方法利用用户的评分信息和社交
ＲＢＭｓ对应一个共同的隐层．所有的ＲＢＭｓ之间的 网络信息，可以很好的解决推荐系统数据稀疏性和 １期 何洁月等：利用社交关系的实值条件受限玻尔兹曼机协同过滤推荐算法 １８５
预测精度低的问题．Ｈｕａｎｇ等人［１１］研究了口碑推荐
的后影响，发现口碑推荐可以提高用户对项目的后
评价．这些方法均很好地利用了社交网络信息，提高
了推荐系统的预测效果．
本文借鉴Ｇｅｏｒｇｉｅｖ等人［４］提出的实值ＲＢＭ的
思想，对Ｓａｌａｋｈｕｔｄｉｎｏｖ等人［２］提出的ＣＲＢＭ 模型
进行了改进，提出了Ｒ＿ＣＲＢＭ 模型．此模型不需要 图１ Ｒｅａｌ－Ｖａｌｕｅｄ Ｃｏｎｄｉｔｉｏｎａｌ ＲＢＭ
（二进制向量ｒ表示评分／未评分信息）
将评分数据转化为一个Ｋ维的０－１向量，而且对训
练数据的类型没有要求，降低了模型的训练难度，训 ｂ表示隐单元的偏置．在给定可见单元状态（输入数
练过程中使用了潜藏的评分／未评分信息，以提高模 据）以及评分／未评分信息时，各隐单元的激活状态
型的推荐效果；其次，本文创新性地将最近信任好友 条件独立；反之，在给定隐单元状态时，可见层单元
的概念加入Ｒ＿ＣＲＢＭ模型，提出了基于 ＭｏｌｅＴｒｕｓｔ 的激活状态亦条件独立，并且可通过Ｇｉｂｂｓ采样有
推理的最近信任好友Ｒ＿ＣＲＢＭ 算法．在百度数据 效得到服从Ｒ＿ＣＲＢＭ所表示分布的随机样本．
集和Ｅｐｉｎｉｏｎｓ数据集上的实验结果表明Ｒ＿ＣＲＢＭ Ｒ＿ＣＲＢＭ考虑了评分／未评分这种潜藏信息，
模型以及基于 ＭｏｌｅＴｒｕｓｔ推理的最近信任好友 用ｒ∈｛０，１｝Ｍ表示评分／未评分信息，其中Ｍ表示
Ｒ＿ＣＲＢＭ算法，均提高了推荐系统的推荐效果． 数据集中总的项目数，０表示未对项目评分，１表示
本文第２节论述Ｒ＿ＣＲＢＭ 模型和基于 Ｍｏｌｅ－ 已评过分．由于将评分／未评分信息纳入考虑，因此
Ｔｒｕｓｔ推理的最近信任好友Ｒ＿ＣＲＢＭ 算法；第３节 向量ｒ也将影响隐单元的状态（见图１）．
给出了本模型和算法的实验结果及其分析；最后总 Ｒ＿ＣＲＢＭ将潜藏在评分数据中的评分／未评分
结本文的工作并提出下一步的研究方向． 数据信息应用到模型的训练过程中，更加突出评分
数据的作用．Ｒ＿ＣＲＢＭ 的原理是：从隐单元的偏置
２ 算法描述 中减去一部分权重放到权重矩阵Ｄ中，因为权重Ｄ
是ｒ层和隐单元之间的连接权重（见图１）而ｒ表示
本节首先论述本文提出的Ｒ＿ＣＲＢＭ 模型的原 评分／未评分信息，因此若用户对项目评分，那么从
理以及模型中各参数的训练方法；然后论述了基于 隐单元的偏置中减去的放到Ｄ中的权重将加回隐
ＭｏｌｅＴｒｕｓｔ推理的最近信任好友Ｒ＿ＣＲＢＭ算法． 单元的偏置中（见式（１）），所以若用户对项目评分，
条件受限玻尔兹曼机（ＣＲＢＭ［２］）模型，虽然能 那么从隐单元的偏置中减去的放到Ｄ中的权重不
利用潜藏在评分数据中的评分／未评分数据信息，但 会对隐单元或可见单元产生任何影响．但是如果评
实值的评分数据需转化为一个Ｋ维的０－１向量， 分缺失，那么从隐单元的偏置中减去的放到Ｄ中的
参数过多、训练过程复杂、模型训练时间较长．为此， 权重将不会加到隐单元的偏置中，因此缺失评分将
我们借鉴文献［３］的思想，提出直接利用实值的 影响隐单元的特征提取．
Ｒ＿ＣＲＢＭ模型，同时在模型中加入最近好友关系以 根据Ｒ＿ＣＲＢＭ 层间全连接、层内无连接的特
进一步强化推荐的有效性．２．１节和２．２节将分别 殊结构可知：可见层和隐层之间是相互独立的．当给
介绍Ｒ＿ＣＲＢＭ模型和基于 ＭｏｌｅＴｒｕｓｔ推理的最近 定可见单元状态时（包括评分／未评分信息），第ｊ个
信任好友Ｒ＿ＣＲＢＭ算法． 隐单元的激活概率为
２．１ Ｒｅａｌ－Ｖａｌｕｅｄ Ｃｏｎｄｉｔｉｏｎａｌ ＲＢＭ（Ｒ＿ＣＲＢＭ）模型 Ｐ（ｈ＝１｜ｖ，ｒ）＝σ（ｂ＋∑ｖＷ ＋∑ｒＤ ）（１）
ｊ ｊ ｉ ｉｊ ｉ ｉｊ
在此，我们基于文献［４］的思想提出Ｒ＿ＣＲＢＭ ｉ ｉ
其中，σ（ｘ）＝１／１＋ｅｘｐ（－ｘ）．
模型，如图１所示．此模型中可见单元可直接表示实
当给定隐单元的状态时，第ｉ个可见单元的值
值的评分数据．
为［１２］
Ｒ＿ＣＲＢＭ可以被视为一个无向图模型，ｖ为可
Ｐ（ｖ｜ｈ）＝Ν（ｃ＋∑ｈＷ ，１） （２）
见层，表示数据；ｈ为隐层，可视为特征提取器；Ｗ ｉ ｉ ｊ ｉｊ
ｊ
为可见层与隐层之间的连接权重矩阵；Ｄ为ｒ层和 ２００２年，Ｗｅｌｌｉｎｇ和 Ｈｉｎｔｏｎ［１３］提出了ＲＢＭ 的
隐层之间的连接权重矩阵；ｃ表示可见单元的偏置； 快速学习算法，即对比散度（Ｃｏｎｔｒａｓｔｉｖｅ Ｄｉｖｅｒｇｅｎｃｅ， １８６ 计 算 机 学 报 ２０１６年
ＣＤ）算法．Ｒ＿ＣＲＢＭ 也采用该算法，Ｒ＿ＣＲＢＭ 模型 第２种方法是可见单元的值等于该单元和所有隐单
中的参数更新准则为 元的连接权重的和再加上该可见单元的偏置．
ΔＷ ＝ε（〈ｖｈ〉 －〈ｖｈ〉 ）ｖ ＞０ （３） 第５行：Ｕｐｄａｔｅ Ｐｈａｓｅ阶段，该阶段更新模型
ｉｊ ｉｊ ｄａｔａ ｉｊ ｒｅｃｏｎ ｉ
Δｃ＝ε（〈ｖ〉 －〈ｖ〉 ）ｖ ＞０ （４） 的所有参数．值得注意的是计算ΔＷ 和Δｃ时训练
ｉ ｉ ｄａｔａ ｉｒｅｃｏｎ ｉ
Δｂ＝ε（〈ｈ〉 －〈ｈ〉 ） （５） 数据中该可见单元的值应大于０（即用户对该项目
ｉ ｊ ｄａｔａ ｊ ｒｅｃｏｎ
ΔＤ ＝ε（〈ｈ〉 －〈ｈ〉 ）ｒ （６）
评分）．
ｉｊ ｊ ｄａｔａ ｊ ｒｅｃｏｎ ｉ
其中：〈·〉表示数学期望；〈·〉 表示可见单元已知 ２．２ 基于推理的最近信任好友Ｒ＿ＣＲＢＭ算法
ｄａｔａ
的情况下，隐层的概率分布；〈·〉 表示用ＣＤ算法 ２．２．１ 直接信任度计算
ｒｅｃｏｎ
用户之间的直接信任关系可以用直接信任网络
重构后模型定义的分布；ε是学习率；ｒ∈｛０，１｝Ｍ是
来表示．直接信任网络可以用一个有向图Ｇ＝（Ｕ，Ｅ）
一个长度等于评分矩阵中项目数的０－１向量，用于
表示，Ｕ是图中节点集合，每个节点代表一个用户，
指示项目是否被用户评分，即评分／未评分信息．训
Ｅ是网络中边的集合，每条边上的值表示朋友间的
练Ｒ＿ＣＲＢＭ模型的伪代码见算法１．
信任值，如图２所示．
算法１． 基于Ｒ＿ＣＲＢＭ模型的协同过滤推荐
算法（其中ＣＤ的步长为１）的伪代码．
输入：训练数据集，评分／未评分数据
输出：训练好的Ｒ＿ＣＲＢＭ模型
１．ＦＯＲｔ＝１：ＮｕｍｂｅｒＥｐｏｃｈｓ ＤＯ：
２． ＦＯＲｎ＝１：ＮｕｍｂｅｒＤａｔａＳａｍｐｌｅｓ ＤＯ：
３． Ｐｏｓｉｔｉｖｅ Ｐｈａｓｅ：
Ｐ（ｈ ｊ＝１｜ｖ，ｒ）＝σ（ｂ ｊ＋∑ｖ ｉＷ ｉｊ＋∑ｒ ｉＤ ｉｊ）
ｉ ｉ
４． Ｎｅｇａｔｉｖｅ Ｐｈａｓｅ：
①： Ｐ（ｖ ｉ｜ｈ）＝Ν（ｃ ｉ＋∑ｈ ｊＷ ｉｊ，１）
ｊ
或者②：可见单元的值等于该单元和所有隐单元的连
接权重的和再加上该可见单元的偏置
５． Ｕｐｄａｔｅ Ｐｈａｓｅ：
ΔＷ ｉｊ＝ε（〈ｖ ｉｈ ｊ〉 ｄａｔａ－〈ｖ ｉｈ ｊ〉 ｒｅｃｏｎ）ｖ ｉ＞０
图２ ６个用户组成的直接信任网络
Δｃ ｉ＝ε（〈ｖ ｉ〉 ｄａｔａ－〈ｖ ｉ〉 ｒｅｃｏｎ）ｖ ｉ＞０
Δｂ ｉ＝ε（〈ｈ ｊ〉 ｄａｔａ－〈ｈ ｊ〉 ｒｅｃｏｎ） 直接信任网络中的信任值一般可以表示成
ΔＤ ｉｊ＝ε（〈ｈ ｊ〉 ｄａｔａ－〈ｈ ｊ〉 ｒｅｃｏｎ）ｒ
ｉ
［０，１］之间的实数，表达信任的程度，０代表完全不
６． ＥＮＤ ＦＯＲ 信任，１代表完全信任．然而，社交网络只是一个二
７．ＥＮＤ ＦＯＲ 值网络，０代表不是好友，１代表是好友．社交网络中
Ｒ＿ＣＲＢＭ模型的训练过程主要分为３个阶段： 好友关系大量存在，但是好友之间的信任值却无法
即Ｐｏｓｉｔｉｖｅ Ｐｈａｓｅ、Ｎｅｇａｔｉｖｅ Ｐｈａｓｅ和Ｕｐｄａｔｅ Ｐｈａｓｅ． 获得．
第１行：ＮｕｍｂｅｒＥｐｏｃｈｓ为训练数据集参与训练 本文的算法中使用Ｐｅａｒｓｏｎ系数计算社交网络
的次数； 中好友之间的直接信任值．Ｐｅａｒｓｏｎ相关系数表示
第２行：ＮｕｍｂｅｒＤａｔａＳａｍｐｌｅｓ表示训练数据集 两个变量之间的关联性．用户ｕ和用户ｖ的Ｐｅａｒｓｏｎ
的行数（或者列数），即将训练数据集中的每行数据 相关系数，如式（７）所示．
（或者每列数据）依次输入模型参与模型的训练； ∑ （Ｒ －Ｒ－ ）（Ｒ －Ｒ－ ）
ｕ，ｃ ｕ ｖ，ｃ ｖ
第３行：Ｐｏｓｉｔｉｖｅ Ｐｈａｓｅ阶段，已知可见单元状 ｓｉｍ（ｕ，ｖ）＝ ｃ∈Ｉｕ，ｖ
态时（包括评分／未评分信息），求隐单元的激活概率； ∑ （Ｒ －Ｒ－ ）２×∑ （Ｒ －Ｒ－ ）２
槡 ｕ，ｃ ｕ ｖ，ｃ ｖ
第４行：Ｎｅｇａｔｉｖｅ Ｐｈａｓｅ阶段，已知隐单元的状 ｃ∈Ｉｕ，ｖ ｃ∈Ｉｕ，ｖ
（７）
态时，求可见单元的值．在该阶段求可见单元的值有
其中：Ｉ 表示用户ｕ和ｖ共同评分的项目集合；Ｒ
ｕ，ｖ ｕ，ｃ
两种方法：第１种是Ｐ（ｖ ｉ｜ｈ）＝Ν（ｃ ｉ＋∑ｈ ｊＷ ｉｊ，１）； 表示用户ｕ对项目ｃ的评分；Ｒ － 和Ｒ－ 分别表示训
ｕ ｖ
ｊ １期 何洁月等：利用社交关系的实值条件受限玻尔兹曼机协同过滤推荐算法 １８７
练集中用户ｕ和ｖ对项目的平均评分．利用Ｐｅａｒｓｏｎ 最近信任好友．Ｒ＿ＣＲＢＭ模型训练好以后就可以利
系数计算社交网络中好友之间的直接信任值，基本 用用户ｕ对第２个项目的预测评分来改善用户１对
思想是：首先用训练数据训练一个Ｒ＿ＣＲＢＭ 模型， 第２个项目的评分．
模型训练好以后若两个用户是好友关系，那么对这两 利用 ＭｏｌｅＴｒｕｓｔ算法得到的信任网络，在信任
个用户的所有项目进行预测评分，然后使用Ｐｅａｒｓｏｎ 网络中寻找最近信任好友，从而利用最近信任好友的
系数计算两个用户的相似性，从而就获得了两个直 预测评分来改善预测效果．基于此我们提出了基于
接好友之间的信任值． ＭｏｌｅＴｒｕｓｔ推理的最近信任好友（Ｎｅａｒｅｓｔ Ｔｒｕｓｔｅｄ
２．２．２ 间接信任度计算 Ｆｒｉｅｎｄｓ Ｂａｓｅｄ ｏｎ ＭｏｌｅＴｒｕｓｔ，ＮＴＦＭＴ）Ｒ＿ＣＲＢＭ
间接信任表示间接好友间的信任程度．在社交 算法，称其为Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法．该算法在预
网络中，用户对其他所有用户提供信任评分是不可 测评分过程中考虑了均值因素的影响，因为即使两
能的．ＭｏｌｅＴｒｕｓｔ提供了一种推测机制，用好友之间 个用户的平均评分不同，但是利用Ｐｅａｒｓｏｎ系数求
的直接信任值推测间接好友的信任值，其主要思想 得的相似性也可能很高．Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法
是：考虑预先设定的距离范围内的所有用户，对所有 中用户ｕ对项目ｉ的预测评分如式（８）所示．
到达用户的路径上的信任值进行加权和． Ｆ
∑（ｆｒｉｅｎｄｓ－ｍｅａｎ ）×ｔｒｕｓｔｖ＿ａｌｕｅ
２．２．３ 基于ＭｏｌｅＴｒｕｓｔ推理的最近信任好友Ｒ＿ＣＲＢＭ ｋｉ ｋｉ ｕｋ
＾ ｋ＝１
Ｒ ＝ｍｅａｎ ＋
算法 ｕ，ｉ ｕｉ Ｆ
∑ｔｒｕｓｔ＿ｖａｌｕｅ
ｕｋ
所谓最近信任好友关系是指和用户是好友关 ｋ＝１ （８）
系，同时两人之间的信任值大于阈值０．６［６］，并且该 其中
好友对用户要预测的项目已评分过，我们将这种 ｍｅａｎ ＝ｕｓｅｒ＿ｍｅａｎ ｕ＋ｉｔｅｍ＿ｍｅａｎ ｉ （９）
ｕｉ
２
好友关系称为最近信任好友关系（Ｎｅａｒｅｓｔ Ｔｒｕｓｔｅｄ
Ｆｒｉｅｎｄｓ，ＮＴＦ）． ｍｅａｎ
＝ｕｓｅｒ＿ｍｅａｎ ｋ＋ｉｔｅｍ＿ｍｅａｎ
ｉ （１０）
ｋｉ
２
如图３所示，在图３（ａ）表示标准的ＲＢＭ 的模
其中：ｕｓｅｒ＿ｍｅａｎ表示训练集中用户ｕ的平均评
型图，图３（ｂ）表示我们提出的Ｒ＿ＣＲＢＭ 模型的结 ｕ
分；ｉｔｅｍ＿ｍｅａｎ为训练集中项目ｉ的平均评分；
构图．在利用Ｒ＿ＣＲＢＭ 模型进行推荐时，每一个用 ｉ
户都有一个单独的Ｒ＿ＣＲＢＭ，这些Ｒ＿ＣＲＢＭｓ对应 ｍｅａｎ ｕｉ表示用户ｕ的平均评分和项目ｉ的平均评分
一个共同的隐层，所有的Ｒ＿ＣＲＢＭｓ之间的权重和
的平均，综合考虑用户平均评分和项目平均评分
偏置是共享的，所以如果两个用户对同一项目进行 的影响；ｍｅａｎ ｋｉ表示用户ｋ的平均评分和项目ｉ的
了评分，那么将会使用同一个权重．
平均评分的平均；Ｆ为最近信任好友的数目；
ｆｒｉｅｎｄｓ表示最近信任好友ｋ的Ｒ＿ＣＲＢＭ 模型对
ｋｉ
项目ｉ的预测评分；ｔｒｕｓｔ＿ｖａｌｕｅ 表示用户ｕ和ｋ之
ｕｋ
间的信任值（大于阈值０．６［７］）．
Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法的基本思想是：首先
用训练数据训练一个Ｒ＿ＣＲＢＭ 模型，然后在用户
的信任网络中寻找最近信任好友关系，最后利用
最近信任好友的预测评分来改善用户对项目的预
图３ 模型结构图 测评分．其伪代码如算法２和算法３所示．
Ｚｉｅｇｌｅｒ和 Ｇｏｌｂｅｃｋ［１４］研究了用户兴趣相似性 算法２的Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法的输入是训
与用户间信任的联系，结果表明两者之间存在着正 练数据集、评分／未评分数据、好友社交关系网络和距
相关性，即用户之间的信任度较高，则他们兴趣相似 离参数Ｄｉｓｔａｎｃｅ的值，输出是预测评分．而算法３的
性也相对较高．如图３（ｂ），假设要预测用户１对第２ ＣｏｎｓｔｒｕｃｔＴｒｕｓｔＮｅｔ函数的功能是用好友社交关系
个项目的评分，用户ｕ是用户１的好友那么他们的 网络构建信任网络，其输入为训练好的 Ｒ＿ＣＲＢＭ
兴趣也必然比较相似，恰好此时用户ｕ对第２项目 模型、好友社交关系网络以及距离Ｄｉｓｔａｎｃｅ的值，
已评分过，因此，用户ｕ是用户１关于第２个项目的 输出是信任网络Ｔｒｕｓｔ＿ｎｅｔ． １８８ 计 算 机 学 报 ２０１６年
算法２． Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法的伪代码． 第１行～第５行：若（ｕ，ｕ）是社交网络中的好
１ ２
输入：训练数据集、评分／未评分数据、好友社交关系网 友关系，用训练好的Ｒ＿ＣＲＢＭ 模型预测ｕ，ｕ对所
１ ２
络和距离参数Ｄｉｓｔａｎｃｅ的值 有项目的评分；然后用Ｐｅａｒｓｏｎ系数计算ｕ，ｕ的信
１ ２
输出：预测评分
任值，从而构建了好友之间的直接信任网络；
／／Ｔｒｕｓｔ＿ｎｅｔ表示信任网络
第６行～结尾：用直接信任网络，通过 Ｍｏｌｅ－
／／Ｆ是用户ｕ关于项目ｉ的最近信任好友的数目
Ｔｒｕｓｔ算法推理得到用户之间的信任网络．
１．训练一个Ｒ＿ＣＲＢＭ模型
２．调用ＣｏｎｓｔｒｕｃｔＴｒｕｓｔＮｅｔ函数构建Ｔｒｕｓｔ＿ｎｅｔ
３．ＦＯＲ ａｌｌ ｒａｔｉｎｇｓ ｗｈｉｃｈ ｎｅｅｄ ｔｏ ｂｅ ｐｒｅｄｉｃｔｅｄ ＤＯ： ３ 实验结果及分析
４． 寻找用户ｕ关于项目ｉ的所有最近信任好友；
５． ｍｅａｎ ｕｉ＝ｕｓｅｒ＿ｍｅａｎ ｕ＋ ２ｉｔｅｍ＿ｍｅａｎ ｉ 本节通过实验验证我们所提算法的性能，实验
数据采用百度推荐大赛数据集和Ｅｐｉｎｉｏｎｓ数据集，
ｕｓｅｒ＿ｍｅａｎ＋ｉｔｅｍ＿ｍｅａｎ
６． ｍｅａｎ ｋｉ＝ ｋ
２
ｉ 其中８０％的数据作为训练数据，２０％的数据作为测试
＾
数据，ＭｏｌｅＴｒｕｓｔ算法和ＲＢＭ［４］模型（包括文献［４］
７． Ｒ ｕ，ｉ＝ｍｅａｎ ｕｉ＋
改进的训练过程）作为对比结果．文献［４］改进了标
Ｆ
∑（ｆｒｉｅｎｄｓ ｋｉ－ｍｅａｎ ｋｉ）×ｔｒｕｓｔ＿ｖａｌｕｅ ｕｋ 准ＣＤ算法的训练过程，改进思想是：可见单元的值
ｋ＝１
Ｆ 等于对应隐单元连接权重的和（ｓｕｍ ｗｅｉｇｈｔ）再加上
∑ｔｒｕｓｔ＿ｖａｌｕｅ
ｕｋ
ｋ＝１ 偏置，我们将此时的ＲＢＭ模型我们称其为Ｓ＿ＲＢＭ．
８．ＥＮＤ ＦＯＲ
３．１ 数据集
算法３． ＣｏｎｓｔｒｕｃｔＴｒｕｓｔＮｅｔ函数的伪代码．
百度推荐大赛的数据集，可从ｈｔｔｐ：／／ｗｗｗ．
输入：Ｒ＿ＣＲＢＭ模型、好友社交关系网络和距离参数
ｄａｔａｔａｎｇ．ｃｏｍ／ｄａｔａ／４４２６８下载．首先对数据集进行
Ｄｉｓｔａｎｃｅ的值
输出：Ｔｒｕｓｔ＿ｎｅｔ
了预处理，将评分数据中没有好友关系的用户的数
／／Ｔｒｕｓｔ＿ｎｅｔ表示信任网络 据剔除，得到一个３１９３个用户对７８８９部电影的评
／／Ｔｒｕｓｔ＿ｎｅｔ＿ｄｉｒｅｃｔ表示直接信任网络 分数据，包括其好友关系网络．
１．ＦＯＲ ａｌｌ ｆｒｉｅｎｄｓｈｉｐ（ｕ １，ｕ ２）ｉｎ Ｓｏｃｉａｌ＿ｎｅｔｗｏｒｋ ＤＯ： Ｅｐｉｎｉｏｎｓ数据集由Ｍａｓｓａ等人［１５］从Ｅｐｉｎｉｏｎｓ．ｃｏｍ
２． 使用Ｒ＿ＣＲＢＭ模型预测用户ｕ １，ｕ ２对所有项目
网站上收集得到，包含４０ １６３个用户对１３９ ５２９个
的评分；
项目的评分．我们从该数据集中抽取了一个１９６３名
３． 使用Ｐｅａｒｓｏｎ相关系数计算ｕ １和ｕ ２之间的信任值；
用户对２４３６个项目的评分数据集作为实验数据，包
４． 将ｕ １和ｕ ２之间的信任值加入Ｔｒｕｓｔ＿ｎｅｔ＿ｄｉｒｅｃｔ
括其好友关系．
５．ＥＮＤ ＦＯＲ
／／使用Ｔｒｕｓｔ＿ｎｅｔ＿ｄｉｒｅｃｔ构建Ｔｒｕｓｔ＿ｎｅｔ ３．２ 评价指标
６．使用ＭｏｌｅＴｒｕｓｔ算法推理得到Ｔｒｕｓｔ＿ｎｅｔ 目前，绝大多数的推荐系统都使用预测准确度
７．ＥＮＤ 来评价推荐算法的性能，预测准确度是比较推荐算
从算法２可看出Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法实现
法的预测评分与用户实际评分的相似程度．预测准
推荐的过程主要可划分为３步：
确度的常用度量方法有平均绝对误差（ＭＡＥ［１６－１７］）、
第１行：用训练数据训练一个Ｒ＿ＣＲＢＭ模型；
根均方误差（ＲＭＳＥ［１８］）．
第２行：调用ＣｏｎｓｔｒｕｃｔＴｒｕｓｔＮｅｔ函数，获得信
平均绝对误差计算预测评分与用户实际评分之
任网络；
间的平均绝对误差值．它的计算公式如式（１１）所示．
第３行～结尾：首先，在信任网络中寻找用户ｕ
＾
关于项目ｉ的最近信任好友；然后，根据式（８）～
ＭＡＥ＝（ｕ，ｉ∑ ）∈Ｒｔｅｓｔ｜Ｒ ｕ，ｉ－Ｒ ｕ，ｉ｜
（１１）
（１０）计算Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法对相应预测项目 ｜Ｒ ｔｅｓｔ｜
的预测评分，即用最近信任好友的预测评分来改善 其中：Ｒ ｔｅｓｔ表示测试集数据；Ｒ ｕ，ｉ表示用户ｕ对项目ｉ
用户对项目的预测评分． 的实际评分；Ｒ＾ ｕ，ｉ是用户ｕ对项目ｉ的预测评分；
算法３是ＣｏｎｓｔｒｕｃｔＴｒｕｓｔＮｅｔ函数的伪代码，该 Ｒ 是测试集中数据的个数．推荐算法的准确度
ｔｅｓｔ
函数的功能是用好友社交关系网络构建信任网络， 是所有用户预测评分与用户实际评分之差的平均．
主要可划分为两步： 根均方误差计算用户实际评分与预测评分之间 １期 何洁月等：利用社交关系的实值条件受限玻尔兹曼机协同过滤推荐算法 １８９
的根均方误差．它的计算公式如式（１２）所示． 值．从两张图中可明显看出当Ｄｉｓｔａｎｃｅ达到６以
∑ （Ｒ ｕ，ｉ－Ｒ＾ ｕ，ｉ）２
后，ＭＡＥ和ＲＭＳＥ基本就不再减少．因此在下面的
ＲＭＳＥ＝槡（ｕ，ｉ）∈Ｒｔｅｓｔ
（１２）
实验中我们使用 ＭｏｌｅＴｒｕｓｔ算法中Ｄｉｓｔａｎｃｅ为６
Ｒ 所对应的信任网络，并且将Ｄｉｓｔａｎｃｅ为６所对应
ｔｅｓｔ
其中：Ｒ ｔｅｓｔ表示测试集数据；Ｒ ｕ，ｉ表示用户ｕ对项目ｉ ＭｏｌｅＴｒｕｓｔ算法的预测结果作为一个对比结果．
的实际评分；Ｒ＾ 是用户ｕ对项目ｉ的预测评分； ３．３．２ ＲＢＭ模型中隐单元数目的确定
ｕ，ｉ
Ｒ 是测试集中数据的个数．根均方误差在求和 本实验的目的是考察ＲＢＭ［４］模型中隐单元数
ｔｅｓｔ
之前对系统预测评分与用户实际评分的误差进行平 目对推荐结果的影响，确定隐单元的数目使 ＲＢＭ
方，因此评分之间的误差越大，其对根均方误差的影 模型的推荐结果最优，实验是基于训练次数Ｅｐｏｃｈｓ
响会比平均绝对误差更大． 为１０进行的，实验结果如图６和图７所示．
３．３ 百度数据集实验结果及分析
３．３．１ ＭｏｌｅＴｒｕｓｔ算法中参数Ｄｉｓｔａｎｃｅ值的确定
ＭｏｌｅＴｒｕｓｔ算法考虑预先设定的距离（Ｄｉｓｔａｎｃｅ）
范围内的所有用户．为了计算用户ｕ对用户ｖ的信
任值，前节点用户的信任值以信任边为权值进行加权
和，即构建了一个以用户ｕ为核心的距离Ｄｉｓｔａｎｃｅ
范围内的信任网络．图４和图５验证 ＭｏｌｅＴｒｕｓｔ算
法中距离Ｄｉｓｔａｎｃｅ对预测结果的影响．
图６ ＲＢＭ模型中隐单元数目对ＭＡＥ值的影响
图４ ＭｏｌｅＴｒｕｓｔ算法中参数Ｄｉｓｔａｎｃｅ值对ＭＡＥ值的影响
图７ ＲＢＭ模型中隐单元数目对ＲＭＳＥ值的影响
图６坐标系中，横坐标表示ＲＢＭ 模型中隐单
元数目，纵坐标为评价指标ＭＡＥ的值．图７坐标系
中，横坐标表示ＲＢＭ模型中隐单元数目，纵坐标为
ＲＭＳＥ的值．从图６和图７可发现随着隐单元数目
的增加，ＭＡＥ与ＲＭＳＥ值先降后升，说明模型的效
图５ ＭｏｌｅＴｒｕｓｔ算法中参数Ｄｉｓｔａｎｃｅ值对ＲＭＳＥ值的影响
果呈现了先变好后变差的趋势．隐单元用于提取数
图４坐标系中，横坐标表示最大距离Ｄｉｓｔａｎｃｅ的
据的特征，当模型提取的特征较少时这些特征不足
值，纵坐标为评价指标ＭＡＥ的值．图５坐标系中，
以表达数据的特征，此时增加提取的特征数，模型的
横坐标表示距离Ｄｉｓｔａｎｃｅ的值，纵坐标为ＲＭＳＥ的
效果会逐渐变好，但是当模型提取的特征达到一定 １９０ 计 算 机 学 报 ２０１６年
程度后，此时增加提取的特征会导致特征过多反而 其缺点是使所有用户对同一项目的预测评分均相
影响模型的效果．从图６中可发现隐单元数为８０时 同，这缺乏可解释性．从两图中可看出我们提出的
对应的ＭＡＥ值最小，图７中隐单元数为９０时对应 Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法预测性能优于所有的算
的ＲＭＳＥ值最小，综合考虑隐单元为８０和９０时的 法，而且是一种比较稳定的算法，其ＭＡＥ和ＲＭＳＥ
ＭＡＥ、ＲＭＳＥ值，隐单元数为８０时效果更好，因此 基本是稳定的，受Ｅｐｏｃｈｓ的影响不大，达到了较好
下面的实验中ＲＢＭ、Ｓ＿ＲＢＭ 和Ｒ＿ＣＲＢＭ 模型的 的预测效果．
隐单元数目都为８０． ３．３．４ 数据稀疏性实验
３．３．３ 训练数据参与训练次数Ｅｐｏｃｈｓ对推荐结 本实验通过改变训练数据集和测试数据集占评
果的影响 分数据的比例，观测数据在不同稀疏性的情况下对实
本实验中使用 ＭｏｌｅＴｒｕｓｔ算法中Ｄｉｓｔａｎｃｅ为６ 验结果的影响．本实验分别将评分数据中的２０％、
所对应的信任网络，ＲＢＭ、Ｓ＿ＲＢＭ和Ｒ＿ＣＲＢＭ模型 ４０％、６０％、８０％作为训练数据集，相应地测试数据
的隐单元数目均为８０．实验结果如图８和图９所示． 集占评分数据的比例分别为８０％、６０％、４０％、２０％．
实验结果如图１０和图１１所示．
图８ 百度数据集上各方法的ＭＡＥ值 图１０ 数据稀疏性比较＿ＭＡＥ值
图１１ 数据稀疏性比较＿ＲＭＳＥ值
图９ 百度数据集上各方法的ＲＭＳＥ值
图１０中，横坐标表示不同稀疏度的训练数据
图８坐标系中，横坐标表示训练集参与训练的
集，纵坐标为评价指标ＭＡＥ的值；图１１坐标系中，
次数Ｅｐｏｃｈｓ的值，纵坐标为评价指标ＭＡＥ的值；
横坐标表示不同稀疏度的训练数据集，纵坐标为评
图９坐标系中，横坐标表示训练集参与训练的次数
价指标ＲＭＳＥ的值．从两图中可发现随着训练数据
Ｅｐｏｃｈｓ的值，纵坐标为评价指标ＲＭＳＥ的值．两图
集占整个数据集比例的提高，也就是说随着数据稀
中ＭｏｌｅＴｒｕｓｔ表示 ＭｏｌｅＴｒｕｓｔ算法中Ｄｉｓｔａｎｃｅ为６
疏性的减少，几种算法的ＭＡＥ值和ＲＭＳＥ值均减
所对应的预测结果．从两图中可发现Ｒ＿ＣＲＢＭ 模
小，也就是推荐效果不断变好．两图中Ｒ＿ＣＲＢＭ 模
型的实验结果均略优于ＲＢＭ 模型，说明潜藏的评
型的推荐效果均优于ＲＢＭ 模型的结果，表明评分／
分／未评分信息可以改善预测效果．Ｓ＿ＲＢＭ 模型
未评分信息确实有利于提高推荐结果，在一定程度
推荐效果比ＲＢＭ 模型有了一定程度的提高，但是
上解决了数据稀疏性问题；Ｓ＿ＲＢＭ 模型的效果较 １期 何洁月等：利用社交关系的实值条件受限玻尔兹曼机协同过滤推荐算法 １９１
ＲＢＭ模型也有了一定程度的提高；我们提出的
Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法的推荐结果远远优于ＲＢＭ
和Ｓ＿ＲＢＭ 模型，表明我们利用的最近信任好友关
系确实有利于提高推荐效果，而且数据越稀疏预测
效果比ＲＢＭ 和Ｓ＿ＲＢＭ 模型提高的越多．当训练
数据占２０％时，我们的 Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法，
ＭＡＥ比ＲＢＭ和Ｓ＿ＲＢＭ 模型分别提高６．９２％和
４．２５％，ＲＭＳＥ比ＲＢＭ 和Ｓ＿ＲＢＭ 模型分别提高
１０．７０％和８．５５％；当训练数据占８０％时，我们的
Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法，ＭＡＥ比ＲＢＭ 和Ｓ＿ＲＢＭ
图１３ Ｅｐｉｎｉｏｎｓ数据集上各方法的ＲＭＳＥ值
模型分别提高３．０６％和２．２７％，ＲＭＳＥ比ＲＢＭ和
Ｓ＿ＲＢＭ模型分别提高４．７６％和４．０３％．
型．我们提出的Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法取得了最
３．４ Ｅｐｉｎｉｏｎｓ数据集实验结果及分析 好的预测效果．
参数Ｄｉｓｔａｎｃｅ和隐单元数目的确定与百度数据 ３．４．２ 数据稀疏性实验
集类似，这里不再展示．实验中使用 ＭｏｌｅＴｒｕｓｔ算法
本实验将评分数据中的２０％、４０％、６０％、８０％
中Ｄｉｓｔａｎｃｅ为３所对应的信任网络，并且将Ｄｉｓｔａｎｃｅ
作为训练数据集，相应地测试数据集占评分数据的
比例分别为８０％、６０％、４０％、２０％．实验结果如
为３所对应ＭｏｌｅＴｒｕｓｔ算法的预测结果作为一个对
比结果，ＲＢＭ、Ｓ＿ＲＢＭ 和Ｒ＿ＣＲＢＭ 模型的隐单元
图１４和图１５所示．
数目均为８０．
３．４．１ 训练数据参与训练次数Ｅｐｏｃｈｓ对推荐结
果的影响
本实验主要考查随着训练数据集参与训练次数
Ｅｐｏｃｈｓ的增加，各算法的推荐结果的变化情况．实
验结果如图１２和图１３所示．
图１２坐标系中，横坐标表示训练集参与训练的
次数Ｅｐｏｃｈｓ的值，纵坐标为评价指标ＭＡＥ的值；
图１３坐标系中，横坐标表示训练集参与训练的次数
图１４ 数据稀疏性比较＿ＭＡＥ值
Ｅｐｏｃｈｓ的值，纵坐标为评价指标ＲＭＳＥ的值．两图
中ＭｏｌｅＴｒｕｓｔ表示ＭｏｌｅＴｒｕｓｔ算法中Ｄｉｓｔａｎｃｅ为３所
对应的预测结果，可发现ＭｏｌｅＴｒｕｓｔ算法在Ｅｐｉｎｉｏｎｓ
数据集上取得了较好的推荐效果．Ｓ＿ＲＢＭ、Ｒ＿ＣＲＢＭ
模型在此数据集上的实验结果仍然优于ＲＢＭ模
图１５ 数据稀疏性比较＿ＲＭＳＥ值
图１４中，横坐标表示不同稀疏度的训练数据
集，纵坐标为评价指标ＭＡＥ的值；图１５坐标系中，
横坐标表示不同稀疏度的训练数据集，纵坐标为评
价指标ＲＭＳＥ的值．从两图中可发现随着训练数据
集占整个数据集比例的提高，几种算法推荐效果均
图１２ Ｅｐｉｎｉｏｎｓ数据集上各方法的ＭＡＥ值
不断变好．两图中Ｒ＿ＣＲＢＭ和Ｓ＿ＲＢＭ模型的效果 １９２ 计 算 机 学 报 ２０１６年
较为接近，Ｒ＿ＣＲＢＭ 和Ｓ＿ＲＢＭ 模型的推荐结果均 ３．５ 基于Ｓｐａｒｋ的大数据环境下的并行化实验
优于ＲＢＭ模型的结果，表明评分／未评分信息确实 在大数据环境下，由于数据量巨大，普通平台无
有利于提高推荐结果，在一定程度上解决了数据稀 法处理大数据问题并且此时Ｒ＿ＣＲＢＭ 模型的参数
疏性问题；我们提出的Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法的 数量将变得极其巨大，Ｒ＿ＣＲＢＭ模型的训练将面临
推荐结果远远优于ＲＢＭ和Ｓ＿ＲＢＭ模型，表明我们 巨大的挑战，因此，针对大数据下的 Ｒ＿ＣＲＢＭ 模
利用的最近信任好友关系确实有利于提高推荐效 型，本文提出了基于Ｓｐａｒｋ的并行化方案．
果，而且数据越稀疏预测效果比ＲＢＭ和Ｓ＿ＲＢＭ模 本实验的数据集采用完整的Ｅｐｉｎｉｏｎｓ数据集，
型提高的越多，充分说明我们的算法能有效缓解 包含４０ １６３个用户对１３９ ５２９个项目的评分以及用
数据稀疏性问题．当训练数据占２０％时，我们的 户之间的关系数据．
Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法，ＭＡＥ比ＲＢＭ和Ｓ＿ＲＢＭ 本实验使用ＩＢＭ 高性能计算平台，使用其中
模型分别提高１５．１１％和６．２３％，ＲＭＳＥ比 ＲＢＭ １０个计算节点，每个节点８ＧＢ内存．
和Ｓ＿ＲＢＭ模型分别提高１７．４５％和１３．１４％；当训 ３．５．１ 基于Ｓｐａｒｋ的Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法
练数据占８０％时，我们的Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法， Ｓｐａｒｋ是一个基于内存计算的开源集群计算系
ＭＡＥ比ＲＢＭ和Ｓ＿ＲＢＭ 模型分别提高５．８９％和 统，其目的是更快速地进行数据分析．Ｓｐａｒｋ创新地
２．２０％，ＲＭＳＥ比ＲＢＭ 和Ｓ＿ＲＢＭ 模型分别提高 提出了“弹性分布式数据集”（Ｒｅｓｉｌｉｅｎｔ Ｄｉｓｔｒｉｂｕｔｅｄ
５．０６％和２．９５％． Ｄａｔａｓｅｔｓ，ＲＤＤ）的概念，ＲＤＤ是一种内存分布式数
综合对比两个数据集上的实验结果，可发现 据集，它可以将中间结果缓存在内存中从而省去不
Ｒ＿ＣＲＢＭ模型比 ＲＢＭ 模型取得了更好的推荐效 必要的磁盘读写，提高运行速度．
果，说明Ｒ＿ＣＲＢＭ 模型中利用的潜在的评分／未评 图１６为Ｒ＿ＣＲＢＭ 模型的并行化方案．图中参
分信息有助于提高推荐精度；我们提出的Ｒ＿ＣＲＢＭ＿ 数θ＝｛Ｗ，ｂ，ｃ，Ｄ｝．在并行化分解样本阶段将训练
ＮＴＦＭＴ算法取得了最好的推荐效果，推荐效果比 数据集切分到各个分片上；并行化阶段针对每个分
ＲＢＭ、Ｒ＿ＣＲＢＭ和Ｓ＿ＲＢＭ模型均有了较大程度地 片上的训练数据进行参数学习，得到各参数的更新
提高，说明我们算法中使用的最近信任好友关系是 值，即为式（３）～（６）；汇总阶段汇总每个分片上的参
值得信赖的．至此我们得出结论：我们的Ｒ＿ＣＲＢＭ 数得到平均后的参数．本文的Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ
模型和Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法中使用的评分／未 算法在Ｒ＿ＣＲＢＭ模型训练好以后有一个寻找最近
评分信息和社交关系信息均有助于提高推荐效果， 邻居的过程，其基本思想与Ｒ＿ＣＲＢＭ 模型的并行
有效地解决了数据稀疏性问题． 化方案类似．
图１６ Ｒ＿ＣＲＢＭ模型并行化
３．５．２ 可扩展性实验结果 示Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法的运行时间，时间单位
本实验中，Ｒ＿ＣＲＢＭ模型的隐单元数量为１８０， 为分钟；图１８中横坐标表示集群的节点数，总坐标
训练次数Ｅｐｏｃｈｓ为１０，实验结果如图１７和图１８ 表示加速比．从两图中可发现随着集群节点数的增
所示． 加，算法的运行时间越来越少，说明基于Ｓｐａｒｋ的并
图１７中，横坐标表示集群的节点数，纵坐标表 行化方案是有效的；当集群从１个节点增加到４个 １期 何洁月等：利用社交关系的实值条件受限玻尔兹曼机协同过滤推荐算法 １９３
并将Ｒ＿ＣＲＢＭ模型和用户的社交关系相结合提出
了Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法．实验结果表明我们的
方法很好地解决了数据稀疏性问题，并且在数据越
稀疏的情况下我们的Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法的预
测效果比ＲＢＭ和Ｓ＿ＲＢＭ 模型提高的越多．最后，
针对大数据环境下算法面临的挑战，本文提出了基
于Ｓｐａｒｋ的Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ算法并行化方案，
取得了一些初步的有效结果，未来将进一步优化其
性能以适应在大数据下的推荐预测．
图１７ 随集群节点变化算法运行时间变化
本论文中采用了文献［４］中的训练方法（包括其
所作的改进），本质上都是ＣＤ算法，但在深度学习
领域，一些研究者在ＣＤ算法的基础上，已经对其作
了一系列的改进，例如，Ｔｉｅｌｅｍａｎ［１９］提出了持续对
比散度（Ｐｅｒｓｉｓｔｅｎｔ Ｃｏｎｔｒａｓｔｉｖｅ Ｄｉｖｅｒｇｅｎｃｅ，ＰＣＤ）算
法；Ｔｉｅｌｅｍａｎ和 Ｈｉｎｔｏｎ［２０］进一步改进了ＰＣＤ算
法，引入一组辅助参数以加快马氏链的混合率，提出
了快速持续对比散度（Ｆａｓｔ Ｐｅｒｓｉｓｔｅｎｔ Ｃｏｎｔｒａｓｔｉｖｅ
Ｄｉｖｅｒｇｅｎｃｅ，ＦＰＣＤ）算法；Ｄｅｓｊａｒｄｉｎｓ等人［２１］提出了
Ｐａｒａｌｌｅｌ Ｔｅｍｐｅｒｉｎｇ（ＰＴ）算法，通过交换相邻两个分
布的状态，可以将低温下的状态传递到高温状态中，
这样便可以从局部最优值中跳出，有更大的概率转移
图１８ 随集群节点变化算法加速比
到距离较远的峰值中去；Ｊｉ等人［２２］提出了Ｐａｒａｌｌｅｌ
节点时算法加速非常明显，加速比是２．６４，但是随 Ｔｅｍｐｅｒｉｎｇ ｗｉｔｈ Ｅｑｕｉ－Ｅｎｅｒｇｙ（ＰＴＥＥ）算法，用于解
着集群数量的继续增加，算法的加速情况变得较为 决ＰＴ算法中当相邻两个状态的能量差距很大时交
缓慢，此时节点之间的通讯开销逐渐占据主导．
换概率低的问题等等，但是这些方法的应用领域都
本实验中使用到３个数据（训练数据、测试数
是传统的０－１数据，因此如何改进这些方法使其适
用于像推荐这种数据是实值并且数据大量缺失的应
据、社交数据），３个数据总的数据量约为２３ＧＢ，使
用领域，将是我们未来的研究工作．
用Ｓｐａｒｋ读取这３个数据仅需２０ｓ左右，很好地解
决了普通环境无法处理大数据的问题．同时１０个节
参 考 文 献
点时基于Ｓｐａｒｋ的并行化方案实现了２．８４倍左右
的加速，较好地解决了大数据环境下Ｒ＿ＣＲＢＭ 模
［１］ Ｂｒｅｅｓｅ Ｊ Ｓ，Ｈｅｃｋｅｒｍａｎ Ｄ，Ｋａｄｉｅ Ｃ．Ｅｍｐｉｒｉｃａｌ ａｎａｌｙｓｉｓ ｏｆ
型的训练问题． ｐｒｅｄｉｃｔｉｖｅ ａｌｇｏｒｉｔｈｍｓ ｆｏｒ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｏｆ ｔｈｅ １４ｔｈ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｕｎｃｅｒｔａｉｎｔｙ ｉｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．
４ 总结及展望 Ｍａｄｉｓｏｎ，ＵＳＡ，１９９８：４３－５２
［２］ Ｓａｌａｋｈｕｔｄｉｎｏｖ Ｒ，Ｍｎｉｈ Ａ，Ｈｉｎｔｏｎ Ｇ．Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ
ｍａｃｈｉｎｅｓ ｆｏｒ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ
当前，以ＲＢＭ 为基本模块的深度置信网模型
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｃｏｒｖａｌｌｉｓ，
被认为是最有效的深度学习算法，也使其在深度学 ＵＳＡ，２００７：７９１－７９８
习领域中占据着核心位置，ＲＢＭ目前已被应用于多 ［３］ Ｚｈａｎｇ Ｃｈｕｎ－Ｘｉａ，Ｊｉ Ｎａｎ－Ｎａｎ，Ｗａｎｇ Ｇｕａｎ－Ｗｅｉ．Ｉｎｔｒｏｄｕｃｔｉｏｎ
ｏｆ ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ．Ｃｈｉｎａ Ｓｃｉｅｎｃｅ Ｐａｐｅｒ Ｏｎｌｉｎｅ，
种机器学习问题，协同过滤便是其中之一．目前的研
２０１３（ｉｎ Ｃｈｉｎｅｓｅ）
究中ＲＢＭ使用的还仅仅是用户的评分数据，众所 （张春霞，姬楠楠，王冠伟．受限波尔兹曼机简介．中国科技
周知推荐领域中存在严重的数据稀疏性问题，以我 论文在线，２０１３）
［４］ Ｇｅｏｒｇｉｅｖ Ｋ，Ｎａｋｏｖ Ｐ．Ａ ｎｏｎ－ＩＩＤ ｆｒａｍｅｗｏｒｋ ｆｏｒ ｃｏｌｌａｂｏｒａｔｉｖｅ
们实验所采用的百度推荐大赛的数据集为例，其超
ｆｉｌｔｅｒｉｎｇ ｗｉｔｈ ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
过９７．４％的数据是缺失的，这将大大影响ＲＢＭ 模
ｔｈｅ ３０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．
型的训练效果．基于此，本文提出了Ｒ＿ＣＲＢＭ 模型 Ａｔｌａｎｔａ，ＵＳＡ，２０１３：１１４８－１１５６ １９４ 计 算 机 学 报 ２０１６年
［５］ Ｇｏｌｂｅｃｋ Ｊ．Ｇｅｎｅｒａｔｉｎｇ Ｐｒｅｄｉｃｔｉｖｅ Ｍｏｖｉｅ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ ｔｏｇｅｔｈｅｒ．Ｄｅｃｉｓｉｏｎ Ｓｕｐｐｏｒｔ Ｓｙｓｔｅｍｓ，２００５，２００５，４３（２）：
ｆｒｏｍ Ｔｒｕｓｔ ｉｎ Ｓｏｃｉａｌ Ｎｅｔｗｏｒｋｓ．Ｂｅｒｌｉｎ Ｈｅｉｄｅｌｂｅｒｇ：Ｓｐｒｉｎｇｅｒ， １－３４
２００６ ［１５］ Ｍａｓｓａ Ｐ，Ａｖｅｓａｎｉ Ｐ．Ｔｒｕｓｔ－ａｗａｒｅ ｂｏｏｔｓｔｒａｐｐｉｎｇ ｏｆ ｒｅｃｏｍ－
［６］ Ｇｏｌｂｅｃｋ Ｊ，Ｈｅｎｄｌｅｒ Ｊ．ＦｉｌｍＴｒｕｓｔ：Ｍｏｖｉｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ ｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＥＣＡＩ Ｗｏｒｋｓｈｏｐ ｏｎ
ｕｓｉｎｇ ｔｒｕｓｔ ｉｎ ｗｅｂ－ｂａｓｅｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｒｉｖａ ｄｅｌ Ｇａｒｄａ，Ｉｔａｌｙ，２００６：２９－３３
ＩＥＥＥ Ｃｏｎｓｕｍｅｒ Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ ａｎｄ Ｎｅｔｗｏｒｋｉｎｇ Ｃｏｎｆｅｒｅｎｃｅ． ［１６］ Ｂｒｅｅｓｅ Ｊ Ｓ，Ｈｅｃｋｅｒｍａｎ Ｄ，Ｋａｄｉｅ Ｃ．Ｅｍｐｉｒｉｃａｌ ａｎａｌｙｓｉｓ ｏｆ
Ｌａｓ Ｖｅｇａｓ，ＵＳＡ，２００６：２８２－２８６ ｐｒｅｄｉｃｔｉｖｅ ａｌｇｏｒｉｔｈｍｓ ｆｏｒ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ
［７］ Ｍａｓｓａ Ｐ，Ａｖｅｓａｎｉ Ｐ．Ｃｏｎｔｒｏｖｅｒｓｉａｌ ｕｓｅｒｓ ｄｅｍａｎｄ ｌｏｃａｌ ｔｒｕｓｔ ｏｆ ｔｈｅ １４ｔｈ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｕｎｃｅｒｔａｉｎｔｙ ｉｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．
ｍｅｔｒｉｃｓ：Ａｎ ｅｘｐｅｒｉｍｅｎｔａｌ ｓｔｕｄｙ ｏｎ ｅｐｉｎｉｏｎｓ．ｃｏｍ ｃｏｍｍｕｎｉｔｙ Ｍａｄｉｓｏｎ，ＵＳＡ，１９９８：４３－５２
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０ｔｈ Ｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ ［１７］ Ｈｅｒｌｏｃｋｅｒ Ｊ Ｌ，Ｋｏｎｓｔａｎ Ｊ Ａ，Ｂｏｒｃｈｅｒｓ Ａ，ｅｔ ａｌ．Ａｎ ａｌｇｏｒｉｔｈｍｉｃ
Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｍｅｎｌｏ Ｐａｒｋ，ＵＳＡ，２００５：１２１－１２６ ｆｒａｍｅｗｏｒｋ ｆｏｒ ｐｅｒｆｏｒｍｉｎｇ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ
［８］ Ｍａｓｓａ Ｐ，Ａｖｅｓａｎｉ Ｐ．Ｔｒｕｓｔ ｍｅｔｒｉｃｓ ｏｎ ｃｏｎｔｒｏｖｅｒｓｉａｌ ｕｓｅｒｓ： ｏｆ ｔｈｅ ２２ｎｄ Ａｎｎｕａｌ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
Ｂａｌａｎｃｉｎｇ ｂｅｔｗｅｅｎ ｔｙｒａｎｎｙ ｏｆ ｔｈｅ ｍａｊｏｒｉｔｙ．Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ｂｅｒｋｅｌｅｙ，
Ｊｏｕｒｎａｌ ｏｎ Ｓｅｍａｎｔｉｃ Ｗｅｂ ａｎｄ Ｉｎｆｏｒｍａｔｉｏｎ Ｓｙｓｔｅｍｓ，２００７， ＵＳＡ，１９９９：２３０－２３７
３（１）：３９－６４ ［１８］ Ｓｈａｒｄａｎａｎｄ Ｕ，Ｍａｅｓ Ｐ．Ｓｏｃｉａｌ ｉｎｆｏｒｍａｔｉｏｎ ｆｉｌｔｅｒｉｎｇ：Ａｌｇｏｒｉｔｈｍｓ
［９］ Ｍａ Ｈａｏ，ｅｔ ａｌ．ＳｏＲｅｃ：Ｓｏｃｉａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｕｓｉｎｇ ｐｒｏｂａ－ ｆｏｒ ａｕｔｏｍａｔｉｎｇ“ｗｏｒｄ ｏｆ ｍｏｕｔｈ”／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＳＩＧＣＨＩ
ｂｉｌｉｓｔｉｃ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １７ｔｈ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｈｕｍａｎ Ｆａｃｔｏｒｓ ｉｎ Ｃｏｍｐｕｔｉｎｇ Ｓｙｓｔｅｍｓ．Ｄｅｎｖｅｒ，
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ Ｋｎｏｗｌｅｄｇｅ Ｍａｎａｇｅｍｅｎｔ． ＵＳＡ，１９９５：２１０－２１７
Ｎａｐａ Ｖａｌｌｅｙ，ＵＳＡ，２００８：９３１－９４０ ［１９］ Ｔｉｅｌｅｍａｎ Ｔ．Ｔｒａｉｎｉｎｇ ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ ｕｓｉｎｇ
［１０］ Ｍａ Ｈａｏ，ｅｔ ａｌ．Ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｗｉｔｈ ｓｏｃｉａｌ ｒｅｇｕｌａｒｉｚａｔｉｏｎ ａｐｐｒｏｘｉｍａｔｉｏｎｓ ｔｏ ｔｈｅ ｌｉｋｅｌｉｈｏｏｄ ｇｒａｄｉｅｎｔ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ４ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ２５ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｈｅｌｓｉｎｋｉ，
Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｈｏｎｇ Ｋｏｎｇ，Ｃｈｉｎａ，２０１１： Ｆｉｎｌａｎｄ，２００８：１０６４－１０７１
２８７－２９６ ［２０］ Ｔｉｅｌｅｍａｎ Ｔ，Ｈｉｎｔｏｎ Ｇ．Ｕｓｉｎｇ ｆａｓｔ ｗｅｉｇｈｔｓ ｔｏ ｉｍｐｒｏｖｅ
［１１］ Ｈｕａｎｇ Ｊｕｎ－Ｍｉｎｇ，ｅｔ ａｌ．Ｅｘｐｌｏｒｉｎｇ ｓｏｃｉａｌ ｉｎｆｌｕｅｎｃｅ ｖｉａ ｐｏｓｔｅｒｉｏｒ ｐｅｒｓｉｓｔｅｎｔ ｃｏｎｔｒａｓｔｉｖｅ ｄｉｖｅｒｇｅｎｃｅ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２６ｔｈ
ｅｆｆｅｃｔ ｏｆ ｗｏｒｄ－ｏｆ－ｍｏｕｔｈ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ Ａｎｎｕａｌ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．
ｔｈｅ ５ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，２００９：１０３３－１０４０
Ｄａｔａ Ｍｉｎｉｎｇ．Ｓｅａｔｔｌｅ，ＵＳＡ，２０１２：５７３－５８２ ［２１］ Ｄｅｓｊａｒｄｉｎｓ Ｇ，Ｃｏｕｒｖｉｌｌｅ Ａ Ｃ，Ｂｅｎｇｉｏ Ｙ，ｅｔ ａｌ．Ｔｅｍｐｅｒｅｄ
［１２］Ｊｉ Ｎ，Ｚｈａｎｇ Ｊ，Ｚｈａｎｇ Ｃ，ｅｔ ａｌ．Ｅｎｈａｎｃｉｎｇ ｐｅｒｆｏｒｍａｎｃｅ ｏｆ Ｍａｒｋｏｖ ｃｈａｉｎ Ｍｏｎｔｅ Ｃａｒｌｏ ｆｏｒ ｔｒａｉｎｉｎｇ ｏｆ ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ
ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ ｖｉａ ｌｏｇ－ｓｕｍ ｒｅｇｕｌａｒｉｚａｔｉｏｎ． ｍａｃｈｉｎｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
Ｋｎｏｗｌｅｄｇｅ－Ｂａｓｅｄ Ｓｙｓｔｅｍｓ，２０１４，６３（３）：８２－９６ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ ａｎｄ Ｓｔａｔｉｓｔｉｃｓ．Ｃｈｉａ Ｌａｇｕｎａ Ｒｅｓｏｒｔ，
［１３］ Ｗｅｌｌｉｎｇ Ｍ，Ｈｉｎｔｏｎ Ｇ Ｅ．Ａ ｎｅｗ ｌｅａｒｎｉｎｇ ａｌｇｏｒｉｔｈｍ ｆｏｒ ｍｅａｎ Ｓａｒｄｉｎｉａ，Ｉｔａｌｙ，２０１０：１４５－１５２
ｆｉｅｌｄ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ ［２２］Ｊｉ Ｎ，Ｚｈａｎｇ Ｊ．Ｐａｒａｌｌｅｌ ｔｅｍｐｅｒｉｎｇ ｗｉｔｈ ｅｑｕｉ－ｅｎｅｒｇｙ ｍｏｖｅｓ ｆｏｒ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ（ＩＣＡＮＮ ２００２）． ｔｒａｉｎｉｎｇ ｏｆ ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
Ｍａｄｒｉｄ，Ｓｐａｉｎ，２００２：３５１－３５７ ｔｈｅ ２０１４Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ．
［１４］ Ｚｉｅｇｌｅｒ Ｃ Ｎ，Ｇｏｌｂｅｃｋ Ｊ．Ｉｎｖｅｓｔｉｇａｔｉｎｇ ｃｏｒｒｅｌａｔｉｏｎｓ ｏｆ ｔｒｕｓｔ Ｂｅｉｊｉｎｇ，Ｃｈｉｎａ，２０１４：１２０－１２７
ａｎｄ ｉｎｔｅｒｅｓｔ ｓｉｍｉｌａｒｉｔｙ—Ｄｏ ｂｉｒｄｓ ｏｆ ａ ｆｅａｔｈｅｒ ｒｅａｌｌｙ ｆｌｏｃｋ
ＨＥ Ｊｉｅ－Ｙｕｅ，ｂｏｒｎ ｉｎ １９６４，Ｐｈ．Ｄ．， ＭＡ Ｂｅｉ，ｂｏｒｎ ｉｎ １９９０，Ｍ．Ｓ．Ｈｉｓ ｃｕｒｒｅｎｔ ｒｅｓｅａｒｃｈ
ｐｒｏｆｅｓｓｏｒ．Ｈｅｒ ｃｕｒｒｅｎｔ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｄｅｅｐ ｌｅａｒｎｉｎｇ ａｎｄ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ．
ｉｎｃｌｕｄｅ ｄａｔａ ｉｎｔｅｎｓｉｖｅ ｃｏｍｐｕｔｉｎｇ，
ｂｉｏｉｎｆｏｒｍａｔｉｃｓ，ｄａｔａ ｍｉｎｉｎｇ，ｍａｃｈｉｎｅ
ｌｅａｒｎｉｎｇ．
Ｂａｃｋｇｒｏｕｎｄ
Ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｈａｓ ｂｅｃｏｍｅ ｏｎｅ ｏｆ ｔｈｅ ｍｏｓｔ ｕｓｅｄ ｆｉｌｔｅｒｉｎｇ ａｌｇｏｒｉｔｈｍ ｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ．Ｄａｔａ ｓｐａｒｓｉｔｙ
ａｐｐｒｏａｃｈｅｓ ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ．Ｈｏｗｅｖｅｒ，ｄａｔａ ｓｐａｒｓｉｔｙ ｗｉｌｌ ｌｅａｄ ｔｏ ｔｈｅ ｌｏｗ ｐｒｅｄｉｃｔｉｏｎ ａｃｃｕｒａｃｙ ｏｆ ｃｏｌｌａｂｏｒａｔｉｖｅ
ｉｓ ｏｎｅ ｏｆ ｔｈｅ ｍｏｓｔ ｃｒｕｃｉａｌ ｃｈａｌｌｅｎｇｅｓ ｆｏｒ ｔｈｅ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ａｌｇｏｒｉｔｈｍｓ，ｗｈｉｃｈ ｗｉｌｌ ｓｅｒｉｏｕｓｌｙ ｒｅｄｕｃｅ ｔｈｅ ｕｓｅｒ １期 何洁月等：利用社交关系的实值条件受限玻尔兹曼机协同过滤推荐算法 １９５
ｅｘｐｅｒｉｅｎｃｅ．Ｉｎ ｒｅｃｅｎｔ ｙｅａｒｓ，ｗｉｔｈ ｔｈｅ ｐｏｐｕｌａｒｉｔｙ ｏｆ ｓｏｃｉａｌ ｗｉｔｈ Ｎｅａｒｅｓｔ Ｔｒｕｓｔｅｄ Ｆｒｉｅｎｄｓ Ｂａｓｅｄ ｏｎ ＭｏｌｅＴｒｕｓｔ ｉｎ ｓｏｃｉａｌ
ｎｅｔｗｏｒｋ，ｓｏｃｉａｌ ｎｅｔｗｏｒｋ ｒｅｌａｔｉｏｎｓｈｉｐ ｉｓ ｂｅｃｏｍｉｎｇ ｍｏｒｅ ａｎｄ ｎｅｔｗｏｒｋ ｉｎｆｏｒｍａｔｉｏｎ．Ｔｈｅ ｅｘｐｅｒｉｍｅｎｔａｌ ｒｅｓｕｌｔｓ ｏｎ Ｂａｉｄｕ ａｎｄ
ｍｏｒｅ ｉｍｐｏｒｔａｎｔ ｉｎ ｐｅｏｐｌｅ’ｓ ｄａｉｌｙ ｌｉｆｅ．Ｆｒｉｅｎｄｓ’ｏｐｉｎｉｏｎ ｏｒ Ｅｐｉｎｉｏｎｓ ｄａｔａｓｅｔｓ ｓｈｏｗ ｔｈａｔ ｔｈｅ Ｒ＿ＣＲＢＭ ｍｏｄｅｌ ａｎｄ
ｖｉｅｗ ｉｎ ｓｏｃｉａｌ ｎｅｔｗｏｒｋ ｔｅｎｄｓ ｔｏ ｉｎｆｌｕｅｎｃｅ ｏｕｒ ｄｅｃｉｓｉｏｎ． Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ ａｌｇｏｒｉｔｈｍ ｈｅｌｐ ｔｏ ｉｍｐｒｏｖｅ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ
Ｔｈｅｒｅｆｏｒｅ，ｔｈｅ ｕｓｅ ｏｆ ｓｏｃｉａｌ ｒｅｌａｔｉｏｎｓｈｉｐ ｉｎ ｓｏｃｉａｌ ｎｅｔｗｏｒｋ ｃａｎ ａｃｃｕｒａｃｙ ｏｆ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ，ｔｈｅ Ｒ＿ＣＲＢＭ ｍｏｄｅｌ
ｓｏｌｖｅ ｔｈｅ ｐｒｏｂｌｅｍ ｏｆ ｄａｔａ ｓｐａｒｓｉｔｙ． ａｎｄ Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ ａｌｇｏｒｉｔｈｍ ａｒｅ ｇｏｏｄ ｓｏｌｕｔｉｏｎｓ ｔｏ ｓｏｌｖｅ
Ｎｏｗａｄａｙｓ，ｄｅｅｐ ｌｅａｒｎｉｎｇ ｈａｓ ｍａｄｅ ｓｉｇｎｉｆｉｃａｎｔ ｂｒｅａｋ－ ｔｈｅ ｐｒｏｂｌｅｍ ｏｆ ｄａｔａ ｓｐａｒｓｉｔｙ．Ｍｏｒｅｏｖｅｒ，ｔｈｅ ｅｘｐｅｒｉｍｅｎｔａｌ
ｔｈｒｏｕｇｈ ｉｎ ｍａｎｙ ｆｉｅｌｄｓ．Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅ ｍｏｄｅｌ ｒｅｓｕｌｔｓ ｓｈｏｗ ｔｈａｔ ｔｈｅ ｔｒａｉｎ ｄａｔａ ｍｏｒｅ ｓｐａｒｓｅ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ
ｏｃｃｕｐｉｅｓ ａ ｃｅｎｔｒａｌ ｐｏｓｉｔｉｏｎ ｉｎ ｔｈｅ ｆｉｅｌｄ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ，ｗｈｉｃｈ ａｃｃｕｒａｃｙ ｏｆ Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ ａｌｇｏｒｉｔｈｍ ｉｓ ｍｕｃｈ ｂｅｔｔｅｒ
ｃａｎ ｂｅ ｕｓｅｄ ｔｏ ｓｏｌｖｅ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｐｒｏｂｌｅｍ．Ｉｎ ｃｕｒｒｅｎｔ ｔｈａｎ ＲＢＭ ａｎｄ Ｓ＿ＲＢＭ ｍｏｄｅｌ．Ｆｉｎａｌｌｙ，ｄｕｅ ｔｏ ａ ｃｏｍｍｏｎ
ｒｅｓｅａｒｃｈ，Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅ ｍｏｄｅｌ ｆｏｒ Ｃｏｌｌａｂｏｒａ－ ｐｌａｔｆｏｒｍ ｉｓ ｖｅｒｙ ｄｉｆｆｉｃｕｌｔ ｔｏ ｔｒａｉｎ Ｒ＿ＣＲＢＭ ｍｏｄｅｌ ｉｎ ｂｉｇ ｄａｔａ．
ｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｏｎｌｙ ｕｓｅｓ ｕｓｅｒｓ ｒａｔｉｎｇ ｄａｔａ．Ｈｏｗｅｖｅｒ，ｔｈｅｒｅ ａｒｅ Ｔｈｅｒｅｆｏｒｅ，ａ ｐａｒａｌｌｅｌｉｚａｔｉｏｎ ｓｃｈｅｍｅ ｂａｓｅｄ ｏｎ Ｓｐａｒｋ ｉｓ
ｓｅｒｉｏｕｓ ｄａｔａ ｓｐａｒｓｅｎｅｓｓ ｐｒｏｂｌｅｍ ｉｎ ｕｓｅｒ ｒａｔｉｎｇ ｄａｔａ． ｐｒｏｐｏｓｅｄ ｉｎ ｔｈｉｓ ｐａｐｅｒ，ｔｈｅ ｅｘｐｅｒｉｍｅｎｔａｌ ｒｅｓｕｌｔ ｓｈｏｗ ｔｈａｔ ｔｈｅ
Ｔｈｅｒｅｆｏｒｅ，ａ Ｒｅａｌ－Ｖａｌｕｅｄ Ｃｏｎｄｉｔｉｏｎａｌ Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ｐａｒａｌｌｅｌｉｚａｔｉｏｎ ｍｅｔｈｏｄ ｆｏｒ Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ ａｌｇｏｒｉｔｈｍ ｈａｓ
Ｍａｃｈｉｎｅ ｍｏｄｅｌ（Ｒ＿ＣＲＢＭ）ｉｓ ｐｒｏｐｏｓｅｄ ｉｎ ｔｈｉｓ ｐａｐｅｒ．Ｉｎ ｇｏｏｄ ｓｃａｌａｂｉｌｉｔｙ．
Ｒ＿ＣＲＢＭ ｍｏｄｅｌ ｒａｔｉｎｇ ｄａｔａ ｄｏｅｓ ｎｏｔ ｎｅｅｄ ｔｏ ｂｅ ｃｏｎｖｅｒｔｅｄ ｔｏ Ｔｈｉｓ ｗｏｒｋ ｗａｓ ｓｕｐｐｏｒｔｅｄ ｉｎ ｐａｒｔ ｂｙ ｔｈｅ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ
ａＫｄｉｍｅｎｓｉｏｎａｌ ０－１ｖｅｃｔｏｒ ｕｎｉｔ．Ｍｅａｎｗｈｉｌｅ，ｔｈｅ ｍｏｄｅｌ ｔｒａｉｎｉｎｇ Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｊｉａｎｇｓｕ Ｐｒｏｖｉｎｃｅ ｕｎｄｅｒ Ｇｒａｎｔ Ｎｏ．ＢＫ２０１２７４２
ｐｒｏｃｅｓｓ ｕｓｅｓ ｒａｔｅｄ／ｕｎｒａｔｅｄ ｉｎｆｏｒｍａｔｉｏｎ．Ｍｏｒｅｏｖｅｒ，ｗｅ ａｌｓｏ ａｎｄ Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｉｎｎｏｖａｔｉｏｎ Ｃｅｎｔｅｒ ｆｏｒ Ｎｏｖｅｌ Ｓｏｆｔｗａｒｅ
ｐｒｏｐｏｓｅｄ ａ ｍｅｔｈｏｄ Ｒ＿ＣＲＢＭ＿ＮＴＦＭＴ ｗｈｉｃｈ ｃｏｍｂｉｎｅｓ Ｔｅｃｈｎｏｌｏｇｙ ａｎｄ Ｉｎｄｕｓｔｒｙ ｏｆ Ｊｉａｎｇｓｕ Ｐｒｏｖｉｎｃｅ，Ｎａｎｊｉｎｇ，
Ｒｅａｌ－Ｖａｌｕｅｄ Ｃｏｎｄｉｔｉｏｎａｌ Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ Ｍａｃｈｉｎｅ ｍｏｄｅｌ ２１００４６． --------------------------------------------------------------------------------- 第４０卷 第６期 计 算 机 学 报 Ｖｏｌ．４０ Ｎｏ．６
２０１７年６月 ＣＨＩＮＥＳＥ ＪＯＵＲＮＡＬ ＯＦ ＣＯＭＰＵＴＥＲＳ Ｊｕｎｅ ２０１７
卷积神经网络研究综述
周飞燕１），２） 金林鹏１），２） 董 军１）
１）（中国科学院苏州纳米技术与纳米仿生研究所 江苏 苏州 ２１５１２３）
２）（中国科学院大学 北京 １０００４９）
摘 要 作为一个十余年来快速发展的崭新领域，深度学习受到了越来越多研究者的关注，它在特征提取和建模
上都有着相较于浅层模型显然的优势．深度学习善于从原始输入数据中挖掘越来越抽象的特征表示，而这些表示
具有良好的泛化能力．它克服了过去人工智能中被认为难以解决的一些问题．且随着训练数据集数量的显著增长
以及芯片处理能力的剧增，它在目标检测和计算机视觉、自然语言处理、语音识别和语义分析等领域成效卓然，因
此也促进了人工智能的发展．深度学习是包含多级非线性变换的层级机器学习方法，深层神经网络是目前的主要
形式，其神经元间的连接模式受启发于动物视觉皮层组织，而卷积神经网络则是其中一种经典而广泛应用的结构．
卷积神经网络的局部连接、权值共享及池化操作等特性使之可以有效地降低网络的复杂度，减少训练参数的数目，
使模型对平移、扭曲、缩放具有一定程度的不变性，并具有强鲁棒性和容错能力，且也易于训练和优化．基于这些优
越的特性，它在各种信号和信息处理任务中的性能优于标准的全连接神经网络．该文首先概述了卷积神经网络的
发展历史，然后分别描述了神经元模型、多层感知器的结构．接着，详细分析了卷积神经网络的结构，包括卷积层、
池化层、全连接层，它们发挥着不同的作用．然后，讨论了网中网模型、空间变换网络等改进的卷积神经网络．同时，
还分别介绍了卷积神经网络的监督学习、无监督学习训练方法以及一些常用的开源工具．此外，该文以图像分类、
人脸识别、音频检索、心电图分类及目标检测等为例，对卷积神经网络的应用作了归纳．卷积神经网络与递归神经
网络的集成是一个途径．为了给读者以尽可能多的借鉴，该文还设计并试验了不同参数及不同深度的卷积神经网
络来分析各参数间的相互关系及不同参数设置对结果的影响．最后，给出了卷积神经网络及其应用中待解决的若
干问题．
关键词 卷积神经网络；深度学习；网络结构；训练方法；领域数据
中图法分类号 ＴＰ１８ ＤＯＩ号 １０．１１８９７／ＳＰ．Ｊ．１０１６．２０１７．０１２２９
Ｒｅｖｉｅｗ ｏｆ Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ
ＺＨＯＵ Ｆｅｉ－Ｙａｎ１），２） ＪＩＮ Ｌｉｎ－Ｐｅｎｇ１），２） ＤＯＮＧ Ｊｕｎ１）
１）（Ｓｕｚｈｏｕ Ｉｎｓｔｉｔｕｔｅ ｏｆ Ｎａｎｏ－Ｔｅｃｈ ａｎｄ Ｎａｎｏ－Ｂｉｏｎｉｃｓ，Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ，Ｓｕｚｈｏｕ，Ｊｉａｎｇｓｕ ２１５１２３）
２）（Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ，Ｂｅｉｊｉｎｇ １０００４９）
Ａｂｓｔｒａｃｔ Ａｓ ａ ｎｅｗ ａｎｄ ｒａｐｉｄｌｙ ｇｒｏｗｉｎｇ ｆｉｅｌｄ ｆｏｒ ｍｏｒｅ ｔｈａｎ ｔｅｎ ｙｅａｒｓ，ｄｅｅｐ ｌｅａｒｎｉｎｇ ｈａｓ ｇａｉｎｅｄ
ｍｏｒｅ ａｎｄ ｍｏｒｅ ａｔｔｅｎｔｉｏｎ ｆｒｏｍ ｄｉｆｆｅｒｅｎｔ ｒｅｓｅａｒｃｈｅｒｓ．Ｃｏｍｐａｒｅｄ ｗｉｔｈ ｓｈａｌｌｏｗ ａｒｃｈｉｔｅｃｔｕｒｅｓ，ｉｔ ｈａｓ
ｇｒｅａｔ ａｄｖａｎｔａｇｅｓ ｉｎ ｂｏｔｈ ｆｅａｔｕｒｅ ｅｘｔｒａｃｔｉｎｇ ａｎｄ ｍｏｄｅｌ ｆｉｔｔｉｎｇ．Ａｎｄ ｉｔ ｉｓ ｖｅｒｙ ｇｏｏｄ ａｔ ｄｉｓｃｏｖｅｒｉｎｇ
ｉｎｃｒｅａｓｉｎｇｌｙ ａｂｓｔｒａｃｔ ｆｅａｔｕｒｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｗｈｏｓｅ ｇｅｎｅｒａｌｉｚａｔｉｏｎ ａｂｉｌｉｔｙ ｉｓ ｓｔｒｏｎｇ ｆｒｏｍ ｔｈｅ ｒａｗ
ｉｎｐｕｔ ｄａｔａ．Ｉｔ ａｌｓｏ ｈａｓ ｓｕｃｃｅｓｓｆｕｌｌｙ ｓｏｌｖｅｄ ｓｏｍｅ ｐｒｏｂｌｅｍｓ ｗｈｉｃｈ ｗｅｒｅ ｃｏｎｓｉｄｅｒｅｄ ｄｉｆｆｉｃｕｌｔ ｔｏ ｓｏｌｖｅ
ｉｎ ａｒｔｉｆｉｃｉａｌ ｉｎｔｅｌｌｉｇｅｎｃｅ ｉｎ ｔｈｅ ｐａｓｔ．Ｆｕｒｔｈｅｒｍｏｒｅ，ｗｉｔｈ ｔｈｅ ｏｕｔｓｔａｎｄｉｎｇｌｙ ｉｎｃｒｅａｓｅｄ ｓｉｚｅ ｏｆ ｄａｔａ
ｕｓｅｄ ｆｏｒ ｔｒａｉｎｉｎｇ ａｎｄ ｔｈｅ ｄｒａｓｔｉｃ ｉｎｃｒｅａｓｅｓ ｉｎ ｃｈｉｐ ｐｒｏｃｅｓｓｉｎｇ ｃａｐａｂｉｌｉｔｉｅｓ，ｉｔ ｈａｓ ｒｅｓｕｌｔｅｄ ｉｎ ｓｉｇｎｉｆｉ－
ｃａｎｔ ｐｒｏｇｒｅｓｓ ａｎｄ ｂｅｅｎ ｕｓｅｄ ｉｎ ａ ｂｒｏａｄ ａｒｅａ ｏｆ ａｐｐｌｉｃａｔｉｏｎｓ ｓｕｃｈ ａｓ ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ，ｃｏｍｐｕｔｅｒ
ｖｉｓｉｏｎ，ｎａｔｕｒａｌ ｌａｎｇｕａｇｅ ｐｒｏｃｅｓｓｉｎｇ，ｓｐｅｅｃｈ ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｓｅｍａｎｔｉｃ ｐａｒｓｉｎｇ ａｎｄ ｓｏ ｏｎ，ｔｈｕｓ ａｌｓｏ
收稿日期：２０１６－０７－２７；在线出版日期：２０１７－０１－１８．周飞燕，女，１９８６年生，博士研究生，主要研究方向为计算机辅助心血管疾病诊断．
Ｅ－ｍａｉｌ：ｚｈｆｙｙｆ１５＠１２６．ｃｏｍ．金林鹏，男，１９８４年生，博士，主要研究方向为机器学习．董 军（通信作者），男，１９６４年生，博士，研究员，博
士生导师，主要研究领域为人工智能及其在健康监护、传统文化中的应用．Ｅ－ｍａｉｌ：ｊｄｏｎｇ２０１０＠ｓｉｎａｎｏ．ａｃ．ｃｎ．
书书书 １２３０ 计 算 机 学 报 ２０１７年
ｐｒｏｍｏｔｉｎｇ ｔｈｅ ａｄｖａｎｃｅｍｅｎｔ ｏｆ ａｒｔｉｆｉｃｉａｌ ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ｗｈｉｃｈ ｃｏｎｓｉｓｔｓ ｏｆ ｍｕｌｔｉｐｌｅ
ｌｅｖｅｌｓ ｏｆ ｎｏｎ－ｌｉｎｅａｒ ｔｒａｎｓｆｏｒｍａｔｉｏｎｓ ｉｓ ａ ｈｉｅｒａｒｃｈｉｃａｌ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ｍｅｔｈｏｄ．Ａｎｄ ｄｅｅｐ ｎｅｕｒａｌ
ｎｅｔｗｏｒｋ ｉｓ ｔｈｅ ｍａｉｎ ｆｏｒｍ ｏｆ ｔｈｅ ｐｒｅｓｅｎｔ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｍｅｔｈｏｄ ｉｎ ｗｈｉｃｈ ｔｈｅ ｃｏｎｎｅｃｔｉｖｉｔｙ ｐａｔｔｅｒｎ
ｂｅｔｗｅｅｎ ｉｔｓ ｎｅｕｒｏｎｓ ｉｓ ｉｎｓｐｉｒｅｄ ｂｙ ｔｈｅ ｏｒｇａｎｉｚａｔｉｏｎ ｏｆ ｔｈｅ ａｎｉｍａｌ ｖｉｓｕａｌ ｃｏｒｔｅｘ．Ｃｏｎｖｏｌｕｔｉｏｎａｌ
ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｔｈａｔ ｈａｓ ｂｅｅｎ ｗｉｄｅｌｙ ｕｓｅｄ ｉｓ ａ ｃｌａｓｓｉｃ ｋｉｎｄ ｏｆ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ．Ｔｈｅｒｅ ａｒｅ ｓｅｖｅｒａｌ
ｃｈａｒａｃｔｅｒｉｓｔｉｃｓ ｓｕｃｈ ａｓ ｌｏｃａｌ ｃｏｎｎｅｃｔｉｏｎｓ，ｓｈａｒｅｄ ｗｅｉｇｈｔｓ，ｐｏｏｌｉｎｇ ｅｔｃ．Ｔｈｅｓｅ ｆｅａｔｕｒｅｓ ｃａｎ ｒｅｄｕｃｅ
ｔｈｅ ｃｏｍｐｌｅｘｉｔｙ ｏｆ ｔｈｅ ｎｅｔｗｏｒｋ ａｎｄ ｔｈｅ ｎｕｍｂｅｒ ｏｆ ｔｒａｉｎｉｎｇ ｐａｒａｍｅｔｅｒｓ，ａｎｄ ｔｈｅｙ ａｌｓｏ ｃａｎ ｍａｋｅ ｔｈｅ
ｍｏｄｅｌ ｃｒｅａｔｉｎｇ ｓｏｍｅ ｄｅｇｒｅｅ ｏｆ ｉｎｖａｒｉａｎｃｅ ｔｏ ｓｈｉｆｔ，ｄｉｓｔｏｒｔｉｏｎ ａｎｄ ｓｃａｌｅ ａｎｄ ｈａｖｉｎｇ ｓｔｒｏｎｇ ｒｏｂｕｓｔｎｅｓｓ
ａｎｄ ｆａｕｌｔ ｔｏｌｅｒａｎｃｅ．Ｓｏ ｉｔ ｉｓ ｅａｓｙ ｔｏ ｔｒａｉｎ ａｎｄ ｏｐｔｉｍｉｚｅ ｉｔｓ ｎｅｔｗｏｒｋ ｓｔｒｕｃｔｕｒｅ．Ｂａｓｅｄ ｏｎ ｔｈｅｓｅ
ｐｒｅｄｏｍｉｎａｎｔ ｃｈａｒａｃｔｅｒｉｓｔｉｃｓ，ｉｔ ｈａｓ ｂｅｅｎ ｓｈｏｗｎ ｔｏ ｏｕｔｐｅｒｆｏｒｍ ｔｈｅ ｓｔａｎｄａｒｄ ｆｕｌｌｙ ｃｏｎｎｅｃｔｅｄ ｎｅｕｒａｌ
ｎｅｔｗｏｒｋｓ ｉｎ ａ ｖａｒｉｅｔｙ ｏｆ ｓｉｇｎａｌ ａｎｄ ｉｎｆｏｒｍａｔｉｏｎ ｐｒｏｃｅｓｓｉｎｇ ｔａｓｋｓ．Ｉｎ ｔｈｉｓ ｐａｐｅｒ，ｆｉｒｓｔ ｏｆ ａｌｌ，ｔｈｅ
ｈｉｓｔｏｒｉｃａｌ ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｉｓ ｓｕｍｍａｒｉｚｅｄ．Ａｆｔｅｒ ｔｈａｔ，ｔｈｅ ｓｔｒｕｃｔｕｒｅｓ
ｏｆ ａ ｎｅｕｒｏｎ ｍｏｄｅｌ ａｎｄ ｍｕｌｔｉｌａｙｅｒ ｐｅｒｃｅｐｔｉｏｎ ａｒｅ ｓｈｏｗｎ．Ｌａｔｅｒ ｏｎ，ａ ｄｅｔａｉｌｅｄ ａｎａｌｙｓｉｓ ｏｆ ｔｈｅ
ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｒｃｈｉｔｅｃｔｕｒｅ ｗｈｉｃｈ ｉｓ ｃｏｍｐｒｉｓｅｄ ｏｆ ａ ｎｕｍｂｅｒ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｌａｙｅｒｓ
ａｎｄ ｐｏｏｌｉｎｇ ｌａｙｅｒｓ ｆｏｌｌｏｗｅｄ ｂｙ ｆｕｌｌｙ ｃｏｎｎｅｃｔｅｄ ｌａｙｅｒｓ ｉｓ ｇｉｖｅｎ．Ｄｉｆｆｅｒｅｎｔ ｋｉｎｄｓ ｏｆ ｌａｙｅｒｓ ｉｎ ｃｏｎｖｏ－
ｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｒｃｈｉｔｅｃｔｕｒｅ ｐｌａｙ ｄｉｆｆｅｒｅｎｔ ｒｏｌｅｓ．Ｔｈｅｎ，ａ ｆｅｗ ｉｍｐｒｏｖｅｄ ａｌｇｏｒｉｔｈｍｓ ｓｕｃｈ
ａｓ Ｎｅｔｗｏｒｋ ｉｎ Ｎｅｔｗｏｒｋ ａｎｄ ｓｐａｔｉａｌ ｔｒａｎｓｆｏｒｍｅｒ ｎｅｔｗｏｒｋｓ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｒｅ
ｄｅｓｃｒｉｂｅｄ．Ｍｅａｎｗｈｉｌｅ，ｔｈｅ ｓｕｐｅｒｖｉｓｅｄ ｌｅａｒｎｉｎｇ ａｎｄ ｕｎｓｕｐｅｒｖｉｓｅｄ ｌｅａｒｎｉｎｇ ｍｅｔｈｏｄ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ
ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｎｄ ｓｏｍｅ ｗｉｄｅｌｙ ｕｓｅｄ ｏｐｅｎ ｓｏｕｒｃｅ ｔｏｏｌｓ ａｒｅ ｉｎｔｒｏｄｕｃｅｄ，ｒｅｓｐｅｃｔｉｖｅｌｙ．Ｉｎ ａｄｄｉｔｉｏｎ，ｔｈｅ
ａｐｐｌｉｃａｔｉｏｎ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｏｎ ｉｍａｇｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ，ｆａｃｅ ｒｅｃｏｇｎｉｔｉｏｎ，ａｕｄｉｏ ｒｅｔｒｉｅｖｅ，
ｅｌｅｃｔｒｏｃａｒｄｉｏｇｒａｍ ｃｌａｓｓｉｆｉｃａｔｉｏｎ，ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ，ａｎｄ ｓｏ ｏｎ ｉｓ ａｎａｌｙｚｅｄ．Ｉｎｔｅｇｒａｔｉｎｇ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ
ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｎｄ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｔｏ ｔｒａｉｎ ｉｎｐｕｔｔｅｄ ｄａｔａ ｃｏｕｌｄ ｂｅ ａｎ ａｌｔｅｒｎａｔｉｖｅ
ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ａｐｐｒｏａｃｈ．Ｆｉｎａｌｌｙ，ｄｉｆｆｅｒｅｎｔ ｃｏｎｖｏｌｕｔｉｏｎ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｓｔｒｕｃｔｕｒｅｓ ｗｉｔｈ ｄｉｆｆｅｒｅｎｔ
ｐａｒａｍｅｔｅｒｓ ａｎｄ ｄｉｆｆｅｒｅｎｔ ｄｅｐｔｈｓ ａｒｅ ｔｅｓｔｅｄ．Ｔｈｒｏｕｇｈ ａ ｓｅｒｉｅｓ ｏｆ ｅｘｐｅｒｉｍｅｎｔｓ，ｔｈｅ ｒｅｌａｔｉｏｎｓ
ｂｅｔｗｅｅｎ ｔｈｅｓｅ ｐａｒａｍｅｔｅｒｓ ｉｎ ｔｈｅｓｅ ｍｏｄｅｌｓ ａｎｄ ｔｈｅ ｉｎｆｌｕｅｎｃｅ ｏｆ ｄｉｆｆｅｒｅｎｔ ｐａｒａｍｅｔｅｒ ｓｅｔｔｉｎｇｓ ａｒｅ
ｐｒｅｌｉｍｉｎａｒｙ ｇｒａｓｐｅｄ．Ｓｏｍｅ ａｄｖａｎｔａｇｅｓ ａｎｄ ｒｅｍａｉｎｅｄ ｉｓｓｕｅｓ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｎｄ
ｉｔｓ ａｐｐｌｉｃａｔｉｏｎｓ ａｒｅ ｃｏｎｃｌｕｄｅｄ．
Ｋｅｙｗｏｒｄｓ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ；ｄｅｅｐ ｌｅａｒｎｉｎｇ；ｎｅｔｗｏｒｋ ｓｔｒｕｃｔｕｒｅ；ｔｒａｉｎｉｎｇ ｍｅｔｈｏｄ；
ｄｏｍａｉｎ ｄａｔａ
等人［４］提出了一种按误差逆传播算法训练的多层前
１ 引 言 馈网络—反向传播网络（Ｂａｃｋ Ｐｒｏｐａｇａｔｉｏｎ Ｎｅｔｗｏｒｋ，
ＢＰ网络），解决了原来一些单层感知器所不能解决
人工神经元网络（Ａｒｔｉｆｉｃｉａｌ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ， 的问题．由于在２０世纪９０年代，各种浅层机器学习
ＡＮＮ）是对生物神经网络的一种模拟和近似，是由 模型相继被提出，较经典的如支持向量机［５］，而且当
大量神经元通过相互连接而构成的自适应非线性动 增加神经网络的层数时传统的ＢＰ网络会遇到局部
态网络系统．１９４３年，心理学家 ＭｃＣｕｌｌｏｃｈ和数理逻 最优、过拟合及梯度扩散等问题，这些使得深度模型
辑学家Ｐｉｔｔｓ提出了神经元的第１个数学模型——— 的研究被搁置．
ＭＰ模型［１］．ＭＰ模型具有开创意义，为后来的研究 ２００６年，Ｈｉｎｔｏｎ等人［６］在《Ｓｃｉｅｎｃｅ》上发文，其
工作提供了依据．到了２０世纪５０年代末至６０年代 主要观点有：（１）多隐层的人工神经网络具有优异
初，Ｒｏｓｅｎｂｌａｔｔ在 ＭＰ模型的基础之上增加了学习 的特征学习能力；（２）可通过“逐层预训练”（ｌａｙｅｒ－
功能，提出了单层感知器模型，第一次把神经网络的 ｗｉｓｅ ｐｒｅ－ｔｒａｉｎｉｎｇ）来有效克服深层神经网络在训练
研究付诸实践［２，３］．但是单层感知器网络模型不能 上的困难，从此引出了深度学习（Ｄｅｅｐ Ｌｅａｒｎｉｎｇ）的
够处理线性不可分问题．直至１９８６年，Ｒｕｍｅｌｈａｒｔ 研究，同时也掀起了人工神经网络的又一热潮［７］．在 ６期 周飞燕等：卷积神经网络研究综述 １２３１
深度学习的逐层预训练算法中首先将无监督学习应 其中：ｘ表示输入信号；ｎ个输入信号同时输入神经
ｉ
用于网络每一层的预训练，每次只无监督训练一层， 元ｊ．ｗ 表示输入信号ｘ与神经元ｊ连接的权重值，
ｉｊ ｉ
并将该层的训练结果作为其下一层的输入，然后再 ｂ表示神经元的内部状态即偏置值，ｙ为神经元的
ｊ ｊ
用有监督学习（ＢＰ算法）微调预训练好的网络［８－１０］． 输出．输入与输出之间的对应关系可用下式表示：
这种深度学习预训练方法在手写体数字识别或者行 ｎ
人检测中，特别是当标注样本数量有限时能使识别
ｙ ｊ＝ｆ （ｂ ｊ＋∑（ｘ ｉ×ｗ ｉｊ）） （１）
ｉ＝１
效果或者检测效果得到显著提升［１１］．Ｂｅｎｇｉｏ［１２］系统 ｆ（·）为激励函数，其可以有很多种选择，可以是线
地介绍了深度学习所包含的网络结构和学习方法． 性 纠正函数（Ｒｅｃｔｉｆｉｅｄ Ｌｉｎｅａｒ Ｕｎｉｔ，ＲｅＬＵ）［２５］，
目前，常用的深度学习模型有深度置信网络（Ｄｅｅｐ ｓｉｇｍｏｉｄ函数、ｔａｎｈ（ｘ）函数、径向基函数等［２６］．
Ｂｅｌｉｅｆ Ｎｅｔｗｏｒｋ，ＤＢＮ）［１３－１６］、层叠自动去噪编码机 ２．２ 多层感知器
（Ｓｔａｃｋｅｄ Ｄｅｏｉｓｉｎｇ Ａｕｔｏｅｎｃｏｄｅｒｓ，ＳＤＡ）［１７，１８］、卷积神 多层感知器（Ｍｕｌｔｉｌａｙｅｒ Ｐｅｒｃｅｐｔｒｏｎ，ＭＬＰ）是
经网络（Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ，ＣＮＮ）［１９，２０］ 由输入层、隐含层（一层或者多层）及输出层构成的
等．２０１６年１月２８日，英国《Ｎａｔｕｒｅ》杂志以封面文章 神经网络模型，它可以解决单层感知器不能解决的
形式报道：谷歌旗下人工智能公司深灵（ＤｅｅｐＭｉｎｄ） 线性不可分问题．图２是含有２个隐含层的多层感
开发的ＡｌｐｈａＧｏ以５∶０战胜了卫冕欧洲冠军——— 知器网络拓扑结构图．
本以为大概１０年后人工智能才能做到［２１］．ＡｌｐｈａＧｏ
主要采用价值网络（ｖａｌｕｅ ｎｅｔｗｏｒｋｓ）来评估棋盘的
位置，用策略网络（ｐｏｌｉｃｙ ｎｅｔｗｏｒｋｓ）来选择下棋步
法，这两种网络都是深层神经网络模型，ＡｌｐｈａＧｏ
所取得的成果是深度学习带来的人工智能的又一次
突破，这也说明了深度学习具有强大的潜力．
事实上，早在２００６年以前就已有人提出一种学
习效率很高的深度学习模型———ＣＮＮ．在２０世纪
８０年代和９０年代，一些研究者发表了ＣＮＮ的相关
研究工作，且在几个模式识别领域尤其是手写数字识
别中取得了良好的识别效果［２２，２３］．然而此时的ＣＮＮ
只适合做小图片的识别，对于大规模数据，识别效
果不佳［７］．直至２０１２年，Ｋｒｉｚｈｅｖｓｋｙ等人［２４］使用扩
展了深度的ＣＮＮ在ＩｍａｇｅＮｅｔ大规模视觉识别挑
战竞赛（ＩｍａｇｅＮｅｔ Ｌａｒｇｅ Ｓｃａｌｅ Ｖｉｓｕａｌ Ｒｅｃｏｇｎｉｔｉｏｎ
Ｃｈａｌｌｅｎｇｅ，ＬＳＶＲＣ）中取得了当时最佳的分类效果，
使得ＣＮＮ越来越受研究者们的重视．
图２ 多层感知器结构图
２ ＣＮＮ概述
输入层神经元接收输入信号，隐含层和输出层
的每一个神经元与之相邻层的所有神经元连接，即
２．１ 神经元
全连接，同一层的神经元间不相连．图２中，有箭头
神经元是人工神经网络的基本处理单元，一般
的线段表示神经元间的连接和信号传输的方向，且
是多输入单输出的单元，其结构模型如图１所示．
每个连接都有一个连接权值．隐含层和输出层中每
一个神经元的输入为前一层所有神经元输出值的加
权和．假设ｘｌ是 ＭＬＰ中第ｌ层第ｍ个神经元的输
ｍ
入值，ｙｌ和ｂｌ分别为该神经元输出值和偏置值，
ｍ ｍ
ｗｌ－１为该神经元与第ｌ－１层第ｉ个神经元的连接
ｉｍ
权值，则有：
图１ 神经元模型 １２３２ 计 算 机 学 报 ２０１７年
ｋ 敏感性．尽管在神经认知机中没有像 ＢＰ算法那样
ｘｌ ＝ｂｌ ＋∑ｗｌ－１×ｙｌ－１ （２）
ｍ ｍ ｉｍ ｉ 的全局监督学习过程可利用，但它仍可认为是ＣＮＮ
ｉ＝１
ｙｌ ＝ｆ（ｘｌ） （３） 的第一个工程实现网络，卷积和池化（也称作下采
ｍ ｍ
当多层感知器用于分类时，其输入神经元个数 样）分别受启发于 Ｈｕｂｅｌ－Ｗｉｅｓｅｌ概念的简单细胞和
为输入信号的维数，输出神经元个数为类别数，隐含 复杂细胞，它能够准确识别具有位移和轻微形变的
层个数及隐层神经元个数视具体情况而定．但在实 输入模式［２９，３０］．随后，ＬｅＣｕｎ等人基于Ｆｕｋｕｓｈｉｍａ
际应用中，由于受到参数学习效率影响，一般使用不 的研究工作使用ＢＰ算法设计并训练了ＣＮＮ（该模
超过３层的浅层模型．ＢＰ算法可分为两个阶段：前 型称为ＬｅＮｅｔ－５），ＬｅＮｅｔ－５是经典的ＣＮＮ结构，后
向传播和后向传播，其后向传播始于 ＭＬＰ的输出 续有许多工作基于此进行改进，它在一些模式识别
层．以图２为例，则损失函数为［２７］ 领域中取得了良好的分类效果［１９］．
ｈ ＣＮＮ的基本结构由输入层、卷积层（ｃｏｎｖｏｌｕ－
Ｅ＝Ｅ（ｙｌ，…，ｙｌ）＝ ∑（ｙｌ－ｔ）２ （４）
１ ｈ ｊ ｊ ｔｉｏｎａｌ ｌａｙｅｒ）、池化层（ｐｏｏｌｉｎｇ ｌａｙｅｒ，也称为取样
ｊ
其中第ｌ层为输出层，ｔ为输出层第ｊ个神经元的期 层）、全连接层及输出层构成．卷积层和池化层一般会
ｊ
望输出，对损失函数求一阶偏导，则网络权值更新公 取若干个，采用卷积层和池化层交替设置，即一个卷
式为 积层连接一个池化层，池化层后再连接一个卷积层，
Ｅ 依此类推．由于卷积层中输出特征面的每个神经元与
ｗ ｉｌ ｍ－１ ＝ｗ ｉｌ ｍ－１－η×
ｗｌ ｉｍ－１
（５）
其输入进行局部连接，并通过对应的连接权值与局部
其中， η为学习率． 输入进行加权求和再加上偏置值，得到该神经元输入
２．３ ＣＮＮ 值，该过程等同于卷积过程，ＣＮＮ也由此而得名［１９］．
１９６２年，生物学家 Ｈｕｂｅｌ和 Ｗｉｅｓｅｌ［２８］通过对 ２．３．１ 卷积层
猫脑视觉皮层的研究，发现在视觉皮层中存在一系 卷积层由多个特征面（Ｆｅａｔｕｒｅ Ｍａｐ）组成，每个
列复杂构造的细胞，这些细胞对视觉输入空间的局 特征面由多个神经元组成，它的每一个神经元通过
部区域很敏感，它们被称为“感受野”．感受野以某种
卷积核与上一层特征面的局部区域相连．卷积核是
方式覆盖整个视觉域，它在输入空间中起局部作用， 一个权值矩阵（如对于二维图像而言可为３×３或
因而能够更好地挖掘出存在于自然图像中强烈的局 ５×５矩阵）［１９，３１］．ＣＮＮ的卷积层通过卷积操作提取
部空间相关性．文献［２８］将这些被称为感受野的细 输入的不同特征，第１层卷积层提取低级特征如边
胞分为简单细胞和复杂细胞两种类型．根据 Ｈｕｂｅｌ－ 缘、线条、角落，更高层的卷积层提取更高级的特征①．
Ｗｉｅｓｅｌ的层级模型，在视觉皮层中的神经网络有一 为了能够更好地理解ＣＮＮ，下面以一维ＣＮＮ（１Ｄ
个层级结构：外侧膝状体→简单细胞→复杂细胞→ ＣＮＮ）为例，二维和三维 ＣＮＮ 可依此进行拓展．
低阶超复杂细胞→高阶超复杂细胞［２９］．低阶超复杂
图３所示为一维ＣＮＮ的卷积层和池化层结构示意
细胞与高阶超复杂细胞之间的神经网络结构类似于 图，最顶层为池化层，中间层为卷积层，最底层为卷
简单细胞和复杂细胞间的神经网络结构．在该层级 积层的输入层．
结构中，处于较高阶段的细胞通常会有这样一个倾 由图３可看出卷积层的神经元被组织到各个特
向：选择性地响应刺激模式更复杂的特征；同时还具 征面中，每个神经元通过一组权值被连接到上一层
有一个更大的感受野，对刺激模式位置的变化更加 特征面的局部区域，即卷积层中的神经元与其输入
不敏感［２９］．１９８０年，Ｆｕｋｕｓｈｉｍａ根据Ｈｕｂｌｅ和 Ｗｉｅｓｅｌ 层中的特征面进行局部连接［１１］．然后将该局部加权
的层级模型提出了结构与之类似的神经认知机 和传递给一个非线性函数如 ＲｅＬＵ函数即可获得
（Ｎｅｏｃｏｇｎｉｔｒｏｎ）［２９］．神经认知机采用简单细胞层 卷积层中每个神经元的输出值．在同一个输入特征
（Ｓ－ｌａｙｅｒ，Ｓ层）和复杂细胞层（Ｃ－ｌａｙｅｒ，Ｃ层）交替组 面和同一个输出特征面中，ＣＮＮ 的权值共享，如
成，其中Ｓ层与Ｈｕｂｌｅ－Ｗｉｅｓｅｌ层级模型中的简单细 图３所示，权值共享发生在同一种颜色当中，不同颜色
胞层或者低阶超复杂细胞层相对应，Ｃ层对应于复 权值不共享．通过权值共享可以减小模型复杂度，使
杂细胞层或者高阶超复杂细胞层．Ｓ层能够最大程度
地响应感受野内的特定边缘刺激，提取其输入层的 ① Ｈｉｊａｚｉ Ｓ，Ｋｕｍａｒ Ｒ，Ｒｏｗｅｎ Ｃ，ｅｔ ａｌ．Ｕｓｉｎｇ ｃｏｎｖｏｌｕｔｉｏｎａｌ
ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ．ｈｔｔｐ：／／ｉｐ．ｃａｄｅｎｃｅ．
局部特征，Ｃ层对来自确切位置的刺激具有局部不 ｃｏｍ／ｕｐｌｏａｄｓ／９０１／ｃｎｎ＿ｗｐ－ｐｄｆ，２０１６，９，２２ ６期 周飞燕等：卷积神经网络研究综述 １２３３
图３ 卷积层与池化层结构示意图
得网络更易于训练．以图３中卷积层的输出特征 ｓｉｇｍｏｉｄ函数、ｔａｎｈ函数等．相比较于饱和非线性函
面１和其输入层的输入特征面１为例，ｗ １（１）１（１）＝ 数，不饱和非线性函数（ｎｏｎ－ｓａｔｕｒａｔｉｎｇ ｎｏｎｌｉｎｅａｒｉｔｙ）
ｗ １（２）１（２）＝ｗ １（３）１（３）＝ｗ １（４）１（４），而ｗ １（１）１（１）≠ｗ １（２）１（１）≠ 能够解决梯度爆炸／梯度消失问题，同时也能够加快
ｗ ，其中ｗ 表示输入特征面ｍ第ｉ个神经 收敛速度［３３］．Ｊａｒｒｅｔｔ等人［３４］探讨了卷积网络中不
１（３）１（１） ｍ（ｉ）ｎ（ｊ）
元与输出特征面ｎ第ｊ个神经元的连接权值．此外 同的纠正非线性函数（ｒｅｃｔｉｆｉｅｄ ｎｏｎｌｉｎｅａｒｉｔｙ，包括
卷积核的滑动步长即卷积核每一次平移的距离也是 ｍａｘ（０，ｘ）非线性函数），通过实验发现它们能够显
卷积层中一个重要的参数．在图３中，设置卷积核在 著提升卷积网络的性能，Ｎａｉｒ等人［２５］也验证了这一
上一层的滑动步长为１，卷积核大小为１×３．ＣＮＮ 结论．因此在目前的ＣＮＮ结构中常用不饱和非线性
中每一个卷积层的每个输出特征面的大小（即神经 函数作为卷积层的激励函数如ＲｅＬＵ函数．ＲｅＬＵ函
元的个数）ｏＭａｐＮ满足如下关系［３２］ 数的计算公式如下所示［２４，２５］
ｏＭａｐＮ＝（（ｉＭａｐＮ－ＣＷｉｎｄｏｗ） ＋１） （６） ｆ ｃｏｖ（ｘ）＝ｍａｘ（０，ｘ） （９）
ＣＩｎｔｅｒｖａｌ 图４中实线为ＲｅＬＵ曲线，虚线为ｔａｎｈ曲线．
其中：ｉＭａｐＮ 表示每一个输入特征面的大小；
对于ＲｅＬＵ而言，如果输入大于０，则输出与输入相
ＣＷｉｎｄｏｗ为卷积核的大小；ＣＩｎｔｅｒｖａｌ表示卷积核
等，否则输出为０．从图４可以看出，使用ＲｅＬＵ函
在其上一层的滑动步长．通常情况下，要保证式（６）
数，输出不会随着输入的逐渐增加而趋于饱和．
能够整除，否则需对ＣＮＮ网络结构作额外处理．每
Ｃｈｅｎ在其报告中分析了影响ＣＮＮ性能的３个因
个卷积层可训练参数数目ＣＰａｒａｍｓ满足式（７）［３２］
素：层数、特征面的数目及网络组织①．该报告使用
ＣＰａｒａｍｓ＝（ｉＭａｐ×ＣＷｉｎｄｏｗ＋１）×ｏＭａｐ ９种结构的ＣＮＮ进行中文手写体识别实验，通过统
（７）
计测试结果得到具有较小卷积核的ＣＮＮ结构的一
其中：ｏＭａｐ为每个卷积层输出特征面的个数； 些结论：（１）增加网络的深度能够提升准确率 ；
ｉＭａｐ为输入特征面个数．１表示偏置，在同一个输 （２）增加特征面的数目也可以提升准确率；（３）增加
出特征面中偏置也共享．假设卷积层中输出特征面 一个卷积层比增加一个全连接层更能获得一个更高
ｎ第ｋ个神经元的输出值为ｘ ｎｏ ｋｕｔ，而ｘｉ ｍｎ ｈ表示其输入 的准确率．Ｂｅｎｇｉｏ等人［３５］指出深度网络结构具有两
特征面ｍ 第ｈ个神经元的输出值，以图３为例， 个优点：（１）可以促进特征的重复利用；（２）能够获取
则［３２］
高层表达中更抽象的特征，由于更抽象的概念可根
ｘ ｎｏ ｋｕｔ＝ｆ ｃｏｖ（ｘｉ １ｎ ｈ×ｗ １（ｈ）ｎ（ｋ）＋ｘｉ １ｎ （ｈ＋１）×ｗ １（ｈ＋１）ｎ（ｋ）＋ 据抽象性更弱的概念来构造，因此深度结构能够获
ｘｉ １ｎ （ｈ＋２）×ｗ １（ｈ＋２）ｎ（ｋ）＋…＋ｂ ｎ） （８） 取更抽象的表达，例如在ＣＮＮ中通过池化操作来
式（８）中，ｂ为输出特征面ｎ的偏置值．ｆ （·）为非
ｎ ｃｏｖ
线性激励函数．在传统的ＣＮＮ 中，激励函数一般 ① Ｘｕ Ｃｈｅｎ．Ｃｏｎｖｏｌｕｔｉｏｎ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ Ｃｈｉｎｅｓｅ ｈａｎｄ－
ｗｒｉｔｉｎｇ ｒｅｃｏｇｎｉｔｉｏｎ．ｈｔｔｐ：／／ｃｓ２３１ｎ．ｓｔａｎｆｏｒｄ．ｅｄｕ／ｒｅｐｏｒｔｓ２０１６／
使用饱和非线性函数（ｓａｔｕｒａｔｉｎｇ ｎｏｎｌｉｎｅａｒｉｔｙ）如 ４２８＿Ｒｅｐｏｒｔ．ｐｄｆ，２０１６，９，２２ １２３４ 计 算 机 学 报 ２０１７年
建立这种抽象，更抽象的概念通常对输入的大部分 获得具有空间不变性的特征［３７］．池化层起到二次提
局部变化具有不变性．Ｈｅ等人［３６］探讨了在限定计 取特征的作用，它的每个神经元对局部接受域进行
算复杂度和时间上如何平衡ＣＮＮ 网络结构中深 池化操作．常用的池化方法有最大池化即取局部接
度、特征面数目、卷积核大小等因素的问题．该文献 受域中值最大的点、均值池化即对局部接受域中的
首先研究了深度（Ｄｅｐｔｈ）与卷积核大小间的关系， 所有值求均值、随机池化［３８，３９］．Ｂｏｕｒｅａｕ等人［４０］给
采用较小的卷积核替代较大的卷积核，同时增加网 出了关于最大池化和均值池化详细的理论分析，通
络深度来增加复杂度，通过实验结果表明网络深度 过分析得出以下一些预测：（１）最大池化特别适用
比卷积核大小更重要；当时间复杂度大致相同时，具 于分离非常稀疏的特征；（２）使用局部区域内所有的
有更小卷积核且深度更深的ＣＮＮ结构比具有更大 采样点去执行池化操作也许不是最优的，例如均值池
卷积核同时深度更浅的ＣＮＮ结构能够获得更好的 化就利用了局部接受域内的所有采样点．Ｂｏｕｒｅａｕ等
实验结果．其次，该文献也研究了网络深度和特征面 人［４１］比较了最大池化和均值池化两种方法，通过实
数目间的关系，ＣＮＮ网络结构设置为：在增加网络 验发现：当分类层采用线性分类器如线性ＳＶＭ 时，
深度时适当减少特征面的数目，同时卷积核的大小 最大池化方法比均值池化能够获得一个更好的分类
保持不变，实验结果表明，深度越深，网络的性能越 性能．随机池化方法是对局部接受域采样点按照其
好；然而随着深度的增加，网络性能也逐渐达到饱 值大小赋予概率值，再根据概率值大小随机选择，该
和．此外，该文献还通过固定网络深度研究了特征面 池化方法确保了特征面中不是最大激励的神经元也
数目和卷积核大小间的关系，通过实验对比，发现特 能够被利用到［３７］．随机池化具有最大池化的优点，
征面数目和卷积核大小的优先级差不多，其发挥的 同时由于随机性它能够避免过拟合．此外，还有混合
作用均没有网络深度大． 池化、空间金字塔池化、频谱池化等池化方法［３７］．在
通常所采用的池化方法中，池化层的同一个特征面
不同神经元与上一层的局部接受域不重叠，然而也
可以采用重叠池化的方法．所谓重叠池化方法就是
相邻的池化窗口间有重叠区域．Ｋｒｉｚｈｅｖｓｋｙ等人［２４］
采用重叠池化框架使ｔｏｐ－１和ｔｏｐ－５的错误率分别
降低了０．４％和０．３％，与无重叠池化框架相比，其
泛化能力更强，更不易产生过拟合．设池化层中第ｎ
个输出特征面第ｌ个神经元的输出值为ｔ ｏｕｔ，同样以
ｎｌ
图４ ＲｅＬＵ与ｔａｎｈ函数曲线图
图３为例，则有［３２］：
在ＣＮＮ结构中，深度越深、特征面数目越多， ｔ ｎｏ ｌｕｔ＝ｆ ｓｕｂ（ｔｉ ｎｎ ｑ，ｔｉ ｎｎ （ｑ＋１）） （１０）
则网络能够表示的特征空间也就越大、网络学习能 其中：ｔｉｎ表示池化层的第ｎ个输入特征面第ｑ个神
ｎｑ
力也越强，然而也会使网络的计算更复杂，极易出现 经元的输出值；ｆ （·）可为取最大值函数、取均值
ｓｕｂ
过拟合的现象．因而，在实际应用中应适当选取网络
函数等．
深度、特征面数目、卷积核的大小及卷积时滑动的步
池化层在上一层滑动的窗口也称为池化核．事
长，以使在训练能够获得一个好的模型的同时还能 实上，ＣＮＮ 中的卷积核与池化核相当于 Ｈｕｂｅｌ－
减少训练时间． Ｗｉｅｓｅｌ模型［２８］中感受野在工程上的实现，卷积层用
２．３．２ 池化层 来模拟Ｈｕｂｅｌ－Ｗｉｅｓｅｌ理论的简单细胞，池化层模拟
池化层紧跟在卷积层之后，同样由多个特征面
该理论的复杂细胞．ＣＮＮ中每个池化层的每一个输
组成，它的每一个特征面唯一对应于其上一层的一 出特征面的大小（神经元个数）ＤｏＭａｐＮ为［３２］
个特征面，不会改变特征面的个数．如图３，卷积层
（ｏＭａｐＮ ）
ＤｏＭａｐＮ＝ （１１）
是池化层的输入层，卷积层的一个特征面与池化层 ＤＷｉｎｄｏｗ
中的一个特征面唯一对应，且池化层的神经元也与 其中，池化核的大小为ＤＷｉｎｄｏｗ，在图３中ＤＷｉｎｄｏｗ＝
其输入层的局部接受域相连，不同神经元局部接受 ２．池化层通过减少卷积层间的连接数量 ，即通
域不重叠．池化层旨在通过降低特征面的分辨率来 过池化操作使神经元数量减少，降低了网络模型 ６期 周飞燕等：卷积神经网络研究综述 １２３５
的计算量． 少，可能会使一些有利于网络学习的特征被忽略掉，
２．３．３ 全连接层 从而不利于网络的学习；但是如果特征面个数过多，
在ＣＮＮ结构中，经多个卷积层和池化层后，连 可训练参数个数及网络训练时间也会增加，这同样
接着１个或１个以上的全连接层．与 ＭＬＰ类似，全 不利于学习网络模型．Ｃｈｕｏ等人［４６］提出了一种理
连接层中的每个神经元与其前一层的所有神经元进 论方法用于确定最佳的特征面数目，然而该方法仅
行全连接．全连接层可以整合卷积层或者池化层中 对极小的接受域有效，它不能够推广到任意大小的
具有类别区分性的局部信息［４２］．为了提升ＣＮＮ网 接受域．该文献通过实验发现：与每层特征面数目均
络性能，全连接层每个神经元的激励函数一般采用 相同的ＣＮＮ结构相比，金字塔架构（该网络结构的
ＲｅＬＵ函数［４３］．最后一层全连接层的输出值被传递 特征面数目按倍数增加）更能有效利用计算资源．目
给一个输出层，可以采用ｓｏｆｔｍａｘ逻辑回归（ｓｏｆｔｍａｘ 前，对于ＣＮＮ网络特征面数目的设定通常采用的
ｒｅｇｒｅｓｓｉｏｎ）进行分类，该层也可称为ｓｏｆｔｍａｘ层 是人工设置方法，然后进行实验并观察所得训练模
（ｓｏｆｔｍａｘ ｌａｙｅｒ）．对于一个具体的分类任务，选择一 型的分类性能，最终根据网络训练时间和分类性能
个合适的损失函数是十分重要的，Ｇｕ等人［３７］介绍 来选取特征面数目．
了ＣＮＮ几种常用的损失函数并分析了它们各自的 ２．３．５ ＣＮＮ结构的进一步说明
特点．通常，ＣＮＮ 的全连接层与 ＭＬＰ结构一样， ＣＮＮ的实现过程实际上已经包含了特征提取
ＣＮＮ的训练算法也多采用ＢＰ算法． 过程，以图５、图６为例直观地显示ＣＮＮ提取的特
当一个大的前馈神经网络训练一个小的数据集 征．Ｃａｏ等人［４７］采用 ＣＮＮ 进行指纹方向场评估，
时，由于它的高容量，它在留存测试数据（ｈｅｌｄ－ｏｕｔ 图５为其模型结构．图５共有３个卷积层（Ｃ１，Ｃ３，
ｔｅｓｔ ｄａｔａ，也可称为校验集）上通常表现不佳［３０］．为 Ｃ５）、２个池化层（Ｍ２，Ｍ４）、１个全连接层（Ｆ６）和
了避免训练过拟合，常在全连接层中采用正则化方 １个输出层（Ｏ７）．输入的大小为１６０×１６０，Ｃ１中９６×
法———丢失数据（ｄｒｏｐｏｕｔ）技术，即使隐层神经元的 １１×１１×１（４）表示Ｃ１层有９６个大小为１１×１１的
输出值以０．５的概率变为０，通过该技术部分隐层 卷积核，１为它的输入特征面个数，４是卷积核在其
节点失效，这些节点不参加ＣＮＮ的前向传播过程， 输入特征面上的滑动步长，３８×３８为每个输出特征
也不会参加后向传播过程［２４，３０］．对于每次输入到网 面的大小．卷积层通过卷积操作提取其前一层的各
络中的样本，由于ｄｒｏｐｏｕｔ技术的随机性，它对应的 种不同的局部特征，由图５可看出，Ｃ１层提取输入
网络结构不相同，但是所有的这些结构共享权 图像的边缘、轮廓特征，可看成是边缘检测器．池化
值［２４］．由于一个神经元不能依赖于其它特定神经元 层的作用是在语义上把相似的特征合并起来，池化
而存在，所以这种技术降低了神经元间相互适应的 层通过池化操作使得特征对噪声和变形具有鲁棒
复杂性，使神经元学习能够得到更鲁棒的特征［２４］． 性［１１］．从图上可看出，各层所提取的特征以增强的
目前，关于ＣＮＮ的研究大都采用ＲｅＬＵ＋ｄｒｏｐｏｕｔ 方式从不同角度表现原始图像，并且随着层数的增
技术，并取得了很好的分类性能［２４，４４，４５］． 加，其表现形式越来越抽象［４８］．全连接层Ｆ６中的每
２．３．４ 特征面 个神经元与其前一层进行全连接，该层将前期所提
特征面数目作为ＣＮＮ的一个重要参数，它通 取的各种局部特征综合起来，最后通过输出层得到
常是根据实际应用进行设置的，如果特征面个数过 每个类别的后验概率．从模式分类角度来说，满足
图５ 指纹经过ＣＮＮ的中间层输出特征［４７］ １２３６ 计 算 机 学 报 ２０１７年
Ｆｉｓｈｅｒ判别准则的特征最有利于分类，通过正则化 来替换传统ＣＮＮ的全连接层，它可以增强神经网
方法（ｄｒｏｐｏｕｔ方法），网络参数得到有效调整，从而 络的表示能力．微神经网络主要是采用 ＭＬＰ模型，
使全连接层提取的特征尽量满足Ｆｉｓｈｅｒ判别准则， 如图７所示．
最终有利于分类［４８］．图６给出了ＣＮＮ提取心电图
（ｅｌｅｃｔｒｏｃａｒｄｉｏｇｒａｍ，ＥＣＧ）特征的过程，首先通过卷
积单元 Ａ１、Ｂ１、Ｃ１（其中每个卷积单元包括一个卷
积层和一个池化层）提取特征，最后由全连接层汇总
所有局部特征．由图中也可以看出，层数越高，特征
的表现形式也越抽象．显然，这些特征并没有临床诊
断的物理意义，仅仅是数理值［４８］． 图７ 线性卷积层与ＭＬＰ卷积层对比［５０］
图７中，图７（ａ）是传统ＣＮＮ的线性卷积层，
图７（ｂ）是ＮＩＮ模型的非线性卷积层，用 ＭＬＰ来取
代原来的ＧＬＭ．ＮＩＮ通过在输入中滑动微型神经
网络得到卷积层的特征面．与卷积的权值共享类似，
ＭＬＰ对同一个特征面的所有局部感受野也共享，即
对于同一个特征面 ＭＬＰ相同．文献［５０］之所以选
择 ＭＬＰ，考虑到 ＭＬＰ采用ＢＰ算法进行训练，能与
ＣＮＮ结构融合，同时 ＭＬＰ也是一种深度模型，具
图６ ＥＣＧ经过ＣＮＮ的中间层［４８］ 有特征重用的思想．ＭＬＰ卷积层能够处理更复杂的
２．３．６ 与传统的模式识别算法相比
非线性问题，提取更加抽象的特征．在传统的ＣＮＮ
结构中全连接层的参数过多，易于过拟合，因此它严
ＣＮＮ的本质就是每一个卷积层包含一定数量
的特征面或者卷积核［４６］．与传统 ＭＬＰ相比，ＣＮＮ 重依赖于ｄｒｏｐｏｕｔ正则化技术．ＮＩＮ模型采用全局
平均池化代替原来的全连接层，使模型的参数大大
中卷积层的权值共享使网络中可训练的参数变少，
减少．它通过全局平均池化方法对最后一个 ＭＬＰ
降低了网络模型复杂度，减少过拟合，从而获得了一
卷积层的每个特征面求取均值，再将这些数值连接
个更好的泛化能力［４９］．同时，在ＣＮＮ结构中使用池
成向量，最后输入到ｓｏｆｔｍａｘ分类层中．全局平均池
化操作使模型中的神经元个数大大减少，对输入空
化可看成是一个结构性的正则化算子（ｓｔｒｕｃｔｕｒａｌ
间的平移不变性也更具有鲁棒性［４９］．而且ＣＮＮ结
ｒｅｇｕｌａｒｉｚｅｒ），它可以增强特征面与类别的一致性．
构的可拓展性很强，它可以采用很深的层数．深度模
在全局平均池化层中没有需要优化的参数，因此能
型具有更强的表达能力，它能够处理更复杂的分类
够避免过拟合．此外，全局平均池化层对空间信息进
问题．总的来说，ＣＮＮ的局部连接、权值共享和池化
行求和，因此对输入的空间变化具有更强的鲁棒性．
操作使其比传统 ＭＬＰ具有更少的连接和参数，从
Ｌｉｎ等人［５０］将该算法应用于 ＭＮＩＳＴ及ＳＶＨＮ 等
而更易于训练．
数据集中，验证了该算法的有效性．Ｘｕ等人［５１］结合
ＮＩＮ模型提出了 ＭＬ－ＤＮＮ模型，使用与文献［５０］
３ ＣＮＮ的一些改进算法
相同的数据库，将其与稀疏编码等方法比较，表明了
该模型的优越性．
３．１ 网中网结构
３．２ 空间变换网络
ＣＮＮ中的卷积滤波器是一种广义线性模型
尽管ＣＮＮ已经是一个能力强大的分类模型，
（Ｇｅｎｅｒａｌｉｚｅｄ Ｌｉｎｅａｒ Ｍｏｄｅｌ，ＧＬＭ），ＧＬＭ的抽象水
但是它仍然会受到数据在空间上多样性的影响．
平比较低，但通过抽象却可以得到对同一概念的不
Ｊａｄｅｒｂｅｒｇ等人［５２］采用一种新的可学习模块—空间
同变体保持不变的特征［５０］．Ｌｉｎ等人［５０］提出了一种
变换网络（Ｓｐａｔｉａｌ Ｔｒａｎｓｆｏｒｍｅｒ Ｎｅｔｗｏｒｋｓ，ＳＴＮｓ）
网中网（Ｎｅｔｗｏｒｋ ｉｎ Ｎｅｔｗｏｒｋ，ＮＩＮ）模型，该模型使 来解决此问题，该模块由３个部分组成：本地化网络
用微型神经网络（ｍｉｃｒｏ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ）代替传 （ｌｏｃａｌｉｓａｔｉｏｎ ｎｅｔｗｏｒｋ）、网格生成器（ｇｒｉｄ ｇｅｎｅｒａｔｏｒ）
统ＣＮＮ的卷积过程，同时还采用全局平均池化层 及采样器（ｓａｍｐｌｅｒ）．ＳＴＮｓ可用于输入层，也可 ６期 周飞燕等：卷积神经网络研究综述 １２３７
插入到卷积层或者其它层的后面，不需要改变原 于与视频相关的任务［５５］．
ＣＮＮ模型的内部结构．ＳＴＮｓ能够自适应地对数据
进行空间变换和对齐，使得ＣＮＮ 模型对平移、缩 ４ 训练方法及开源工具
放、旋转或者其它变换等保持不变性．此外，ＳＴＮｓ
的计算速度很快，几乎不会影响原有ＣＮＮ模型的 ４．１ 训练方法
训练速度． 虽然通常都认为如果没有无监督预训练，对深
３．３ 反卷积 度神经网络进行有监督训练是非常困难的，但ＣＮＮ
由Ｚｅｉｌｅｒ等人［５３］提出的反卷积网络（Ｄｅｃｏｎ－ 却是一个特例，它可直接执行有监督学习训练［１２］．
ｖｏｌｕｔｉｏｎａｌ Ｎｅｔｗｏｒｋｓ）模型与ＣＮＮ的思想类似，只 ＣＮＮ通过ＢＰ算法进行有监督训练，也需经过信息
是在运算上有所不同．ＣＮＮ是一种自底而上的方 的正向传播和误差的反向传播两个阶段［１９］．ＣＮＮ
法，其输入信号经过多层的卷积、非线性变换和下采 开始训练之前，需要采用一些不同的小随机数对网
样处理．而反卷积网络中的每层信息是自顶而下的， 络中所有的权值和偏置值进行随机初始化．使用“小
它对由已学习的滤波器组与特征面进行卷积后得到 随机数”以保证网络不会因为权过大而进入饱和状
的特征求和就能重构输入信号．随后，Ｚｅｉｌｅｒ［５４］采用 态，从而导致训练失败；“不同”用来保证网络可正常
反卷积网络可视化ＣＮＮ中各网络层学习得到的特 地学习训练，如果使用相同的数值初始化权矩阵，那
征，从而有利于分析并改进它的网络结构．反卷积网 么网络将没有学习的能力［５６］．随机初始化的权值和
络也可看成是一个卷积模型，它同样需要进行卷积和 偏置值的范围可为［－０．５，０．５］或者［－１，１］（或者
池化过程，不同之处在于与ＣＮＮ是一个逆过程．文献 是其它合适的区间）［５７］．在实际应用中，无标注的数
［５４］模型中的每一个卷积层都加上一个反卷积层．在 据远多于有标注的数据，同时对数据进行人工标注
卷积、非线性函数、最大池化后，不仅将输出的特征 也需要耗费较大的人力．但是为了使有监督ＣＮＮ
作为下一层的输入，也将它送给对应的反卷积层．反 得到充分的训练并获得较好的泛化能力，又需要大
卷积层需要依次进行ｕｎｐｏｏｌｉｎｇ（采用一种近似的方 量有标注的训练样本，这一定程度上制约了ＣＮＮ
法求最大池化的逆过程）、矫正（使用非线性函数来 在实际中的应用．这也是有监督学习的一个缺欠．
保证所有输出均为非负数）及反卷积操作（利用卷积 事实上，ＣＮＮ也可以进行无监督训练．现存的
过程中卷积核的转置作为核，与矫正后的特征作卷 一些无监督学习算法一般都需要调整很多超参数
积运算），然后形成重构特征．通过反卷积技术可视 （ｈｙｐｅｒｐａｒａｍｅｔｅｒ），这使得它们难以被利用，对此
化ＣＮＮ各网络层学习到的特征，Ｚｅｉｌｅｒ［５４］还得出以 Ｎｇｉａｍ等人［５８］提出了一种只需调整一个超参数的
下结论：ＣＮＮ学习到的特征对于平移和缩放具有不 无监督学习算法—稀疏滤波（ｓｐａｒｓｅ ｆｉｌｔｅｒｉｎｇ）．稀疏
变性，但是对于旋转操作一般不具有该特性，除非被 滤波只优化一个简单的代价函数———Ｌ２范数稀疏
识别对象具有很强的对称性．Ｚｈａｏ等人［５５］提出了 约束特征，从而得到好的特征表示．在稀疏滤波中，
一个新的称为ＳＷＷＡＥ（Ｓｔａｃｋｅｄ Ｗｈａｔ－Ｗｈｅｒｅ Ａｕｔｏ－ 其特征分布矩阵具有如下特点：样本分布稀疏性
Ｅｎｃｏｄｅｒｓ）的结构，ＳＷＷＡＥ模型由卷积结构及反 （ｐｏｐｕｌａｔｉｏｎ ｓｐａｒｓｉｔｙ）、高分散性（ｈｉｇｈ ｄｉｓｐｅｒｓａｌ）、
卷积结构组成，采用卷积结构对输入进行编码，而反 存在稀疏（ｌｉｆｅｔｉｍｅ ｓｐａｒｓｉｔｙ）．文中指出可将稀疏滤
卷积结构用来进行重构．ＳＷＷＡＥ的每一个阶段是 波用于深度网络模型中，先用稀疏滤波训练得到一
一个“内容－位置”（ｗｈａｔ－ｗｈｅｒｅ）自动编码机，编码机 个单层的归一化特征，然后将它们作为第２层的输
由一个卷积层及紧随其后的一个最大池化层组成， 入来训练第２层，依此类推．通过实验，发现使用稀
通过最大池化层产生两个变量集：最大池化的输出 疏滤波贪心算法逐层训练，可学习到一些很有意义
记为ｗｈａｔ变量，它作为下一层的输入；将最大池化的 的特征表示．Ｄｏｎｇ等人［５９］将稀疏滤波应用于ＣＮＮ
位置信息记为ｗｈｅｒｅ变量，ｗｈｅｒｅ变量要横向传递 的无监督学习，同时使用该ＣＮＮ模型识别交通工
到反卷积结构中．ＳＷＷＡＥ的损失函数包含３个部 具类型．在文献［５９］中，采用稀疏滤波作为预训练，
分（判别损失、重构损失及中间重构损失）．ＳＷＷＡＥ 并将ＣＮＮ学习到的高级全局特征和低级局部特征
在各种半监督和有监督任务中取得了很高的准 输入到ｓｏｆｔｍａｘ层中进行分类．随后，Ｄｏｎｇ等人［６０］
确率，它特别适用于具有大量无标注类别而有标注 又采用一种半监督学习ＣＮＮ用于交通工具类型识
类别相对少的数据集的情况，该模型也可能适用 别中．文中采用大量无标注的数据无监督训练卷积 １２３８ 计 算 机 学 报 ２０１７年
层的卷积核，该无监督算法为稀疏拉普拉斯滤波器， 许多优秀的开源深度学习仿真工具．目前常用的深度
再用一定量的有标注数据有监督训练ＣＮＮ输出层 学习仿真工具有Ｃａｆｆｅ［６２］①、Ｔｏｒｃｈ②③ 及Ｔｈｅａｎｏ［６３］④
的参数，最后通过ＢＩＴ－Ｖｅｈｉｃｌｅ数据库验证该ＣＮＮ 等．Ｃａｆｆｅ是一个基于Ｃ＋＋语言且关于ＣＮＮ相关
模型的可行性．如果数据集中只有少量的标注数据， 算法的架构．Ｃａｆｆｅ可以在ＣＰＵ及ＧＰＵ上运行，它支
同时还需要训练一个大的ＣＮＮ网络，传统的做法 持ＭＡＴＬＡＢ和Ｐｙｔｈｏｎ接口．Ｃａｆｆｅ提供了一个完
是首先进行无监督预训练，然后再采用有监督学习 整的工具包，用于训练、测试、微调及部署模型．Ｃａｆｆｅ
（如ＢＰ算法）进行微调（ｆｉｎｅ－ｔｕｎｉｎｇ）． 允许用户对新数据格式、网络层和损失函数进行拓
显性训练是传统的神经网络训练方法，其最大 展；它的运行速度也很快，在单个 Ｋ４０或者 Ｔｉｔａｎ
特点是训练过程中有一部分样本不参与ＣＮＮ的误 ＧＰＵ上一天可以训练超过４千万幅图像；用户还可
差反向传播过程，将该部分样本称为校验集．在显性 以通过Ｃａｆｆｅ社区参与开发与讨论．但是Ｃａｆｆｅ的灵
训练过程中，为了防止发生过拟合现象，每隔一定时
活性较差．
间就用当前分类模型测试校验样本，这也表明了校
Ｔｏｒｃｈ是一个支持机器学习算法的科学计算框
验集中样本选取的好坏会影响最终分类模型的性 架．它是采用Ｌｕａ脚本语言和Ｃ语言编写的．Ｔｏｒｃｈ
能．在ＣＮＮ分类模型中，为了增加训练样本数，可
为设计和训练机器学习模型提供了一个灵活的环
采用“平移起始点”和“加躁”这两种技术［６１］．不妨以
境，它还可支持ｉＯＳ、Ａｎｄｒｏｉｄ等嵌入式平台．最新
一个采样点数为１×１９００的一维信号为例，设置起
版本Ｔｏｒｃｈ７使ＣＮＮ的训练速度得到大幅度提升．
始点的范围为［１，２００］．训练过程中，每个样本随机
对于Ｔｏｒｃｈ的时域卷积，其输入长度可变，这非常
选定一个起始点，截取其后连续的１７００个点作为网
有助于自然语言任务．但Ｔｏｒｃｈ没有Ｐｙｔｈｏｎ接口．
络的输入参与ＢＰ训练过程，则ＣＮＮ的输入维数为
Ｔｈｅａｎｏ是一个允许用户定义、优化并评价数学
１×１７００，显然起始点不同，截取所得的子段也不同．
表达式的ｐｙｔｈｏｎ库．Ｔｈｅａｎｏ提供了 ＮｕｍＰｙ的大
在文献［４８］的校验集中，每幅ＥＣＧ的起始点均为
部分功能，可在ＧＰＵ上运行．此外，Ｔｈｅａｎｏ能够自
１，实际上起始点也可以不一样，但是在ＣＮＮ的整
动求微分，它尤其适用于基于梯度的方法．Ｔｈｅａｎｏ
个训练过程中，必须保持该校验集不变，同时校验集
能够很容易且高效地实现递归神经网络（Ｒｅｃｕｒｒｅｎｔ
和训练集完全没有交集，其样本为来自不同病人的
Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ，ＲＮＮ）．然而Ｔｈｅａｎｏ的编译过程
不同记录．此外，只要对类别的最终判断没有影响，
很慢，导入Ｔｈｅａｎｏ也需要消耗时间．
也可通过加躁处理或者对原始数据做某种扭曲变换
Ｂａｈｒａｍｐｏｕｒ等人［６４］从可拓展性、硬件利用率及
从而达到增加训练样本的目的．
速度方面对Ｃａｆｆｅ、Ｔｏｒｃｈ、Ｔｈｅａｎｏ、Ｎｅｏｎ⑤ 及Ｔｅｎｓｏｒ－
在某些应用领域如计算机辅助ＥＣＧ分析中，不
Ｆｌｏｗ⑥ 等５个深度学习软件架构作了比较．其中
同的ＥＣＧ记录（一维信号）也可能存在一些表现相
Ｃａｆｆｅ、Ｔｏｒｃｈ及Ｔｈｅａｎｏ是目前最广泛使用的软件
似的ＥＣＧ记录．如果校验样本不典型，即该校验集
架构．这５个软件架构均可在ＣＰＵ或者ＧＰＵ上运
没有包含全部有差异的个体，则训练所得的分类模
行，但是Ｎｅｏｎ不能使用多线程ＣＰＵ，Ｃａｆｆｅ需要在
型就会存在偏差．由于受到一些现实条件的影响，人
安装的时候确定好 ＣＰＵ 的线程数，ＴｅｎｓｏｒＦｌｏｗ、
工挑选校验样本也并非易事．因此在ＣＮＮ的分类
Ｔｏｒｃｈ及 Ｔｈｅａｎｏ则可以灵活地选择 ＣＰＵ 线程
过程中，还可以采用隐性训练方法．与显性训练相
数［６４］．Ｂａｈｒａｍｐｏｕｒ等人［６４］通过实验发现：Ｔｏｒｃｈ与
比，隐性训练方法主要的区别是怎样检验当前的分
Ｔｈｅａｎｏ是两个最具有拓展性的架构，不仅支持各种
类模型．隐性训练方法从整个训练集中取出一小部
深度结构，还支持各种库；在ＣＰＵ 上，对于任一深
分样本用于校验：用于校验的这部分样本不做加躁
处理，并且对于每一个样本都截取起始点固定的子
① Ｃａｆｆｅ［Ｏｎｌｉｎｅ］．ｈｔｔｐ／／ｃａｆｆｅ．ｂｅｒｋｅｌｅｙｖｉｓｉｏｎ．ｏｒｇ／，２０１６，
段．在实际应用中，这两种训练方法各有优势．通过 ９，２２
② Ｔｏｒｃｈ［Ｏｎｌｉｎｅ］．ｈｔｔｐ：／／ｔｏｒｃｈ．ｃｈ／，２０１６，９，２２
实验表明，这种平移起始点和加躁技术对分类性能
③ Ｔｏｒｃｈ７［Ｏｎｌｉｎｅ］．ｈｔｔｐｓ：／／ｇｉｔｈｕｂ．ｃｏｍ／ｔｏｒｃｈ／ｔｏｒｃｈ７，２０１６，
的提升有很大的帮助，尤其是对于数据不平衡的分
９，２２
④ Ｔｈｅａｎｏ［Ｏｎｌｉｎｅ］．ｈｔｔｐｓ：／／ｇｉｔｈｕｂ．ｃｏｍ／Ｔｈｅａｎｏ／Ｔｈｅａｎｏ，
类问题［６１］． ２０１６，９，２２
⑤ Ｎｅｏｎ［Ｏｎｌｉｎｅ］．ｈｔｔｐｓ：／／ｇｉｔｈｕｂ．ｃｏｍ／ｙｅｌｉｔｅ／ｎｅｏｎ，２０１６，
４．２ 开源工具 ９，２２
⑥ ＴｅｎｓｏｒＦｌｏｗ［Ｏｎｌｉｎｅ］．ｈｔｔｐｓ：／／ｗｗｗ．ｔｅｎｓｏｒｆｌｏｗ．ｏｒｇ／，
深度学习能够广泛应用于众多研究领域，离不开 ２０１６，９，２２ ６期 周飞燕等：卷积神经网络研究综述 １２３９
度网络结构的训练和部署，Ｔｏｒｃｈ表现最优，其次是 最易于评价标准深度结构的性能；与Ｔｈｅａｎｏ类似，
Ｔｈｅａｎｏ，Ｎｅｏｎ的性能最差；在ＧＰＵ上训练卷积和 ＴｅｎｓｏｒＦｌｏｗ也是非常灵活的架构，但是它在单个
全连接网络，对于小网络模型Ｔｈｅａｎｏ的训练速度 ＧＰＵ上的性能不如其它几个架构．表１总结了Ｃａｆｆｅ、
最快，对于较大的网络模型则是 Ｔｏｒｃｈ最快，而对 Ｔｏｒｃｈ及 Ｔｈｅａｎｏ所具有的一些特点①．Ｔｈｅａｎｏ没
于大的卷积网络Ｎｅｏｎ也非常有竞争力；在ＧＰＵ上 有预训练的ＣＮＮ模型，所以在Ｔｈｅａｎｏ上不能直接
训练和部署ＲＮＮ模型，Ｔｈｅａｎｏ的性能最好；Ｃａｆｆｅ 进行ＣＮＮ无监督预训练．
表１ 不同软件包的一些特点
架构 编写语言 开源 接口 硬件 平台 适合模型 预训练ＣＮＮ模型
Ｃａｆｆｅ Ｃ＋＋，Ｐｙｔｈｏｎ 是 命令行 Ｍａ， ｔＰ ｌａｙ ｂｔｈｏｎ， ＣＰＵ，ＧＰＵ Ｌ Ｕｉｎ ｂｕ ｕｘ ｎｔ， ｕＯ ，Ｓ
Ａ
Ｘ Ｗ， ＳＷ ，ｉ Ａｎ ｎｄ ｄｏ ｒｗ ｏｉｓ ｄ， ＣＮＮ 有
Ｌｉｎｕｘ，Ａｎｄｒｉｏｄ，Ｍａｃ ＯＳ Ｘ，
Ｔｏｒｃｈ Ｌｕａ，Ｃ 是 Ｌｕａ，Ｃ ＣＰＵ，ＧＰＵ，ＦＰＧＡ ＣＮＮ，ＲＮＮ，ＤＢＮ 有
ｉＯＳ，Ｗｉｎｄｏｗｓ
Ｔｈｅａｎｏ Ｐｙｔｈｏｎ 是 Ｐｙｔｈｏｎ ＣＰＵ，ＧＰＵ 可跨平台 ＣＮＮ，ＲＮＮ，ＤＢＮ 无
换方式减少了参数的数量，而且也能够使决策函数
５ 实际应用 更具有判别性．ＶＧＧ模型在ＬＳＶＲＣ－１４竞赛中，得
到了图像分类“指定数据”组的第２名，证明了深度在
５．１ 图像分类 视觉表示中的重要性．但是由于ＶＧＧ与ＧｏｏｇＬｅＮｅｔ
近年来，ＣＮＮ已被广泛应用于图像处理领域中． 的深度都比较深，所以网络结构比较复杂，训练时间
Ｋｒｉｚｈｅｖｓｋｙ等人［２４］第１次将ＣＮＮ用于ＬＳＶＲＣ－１２ 长，而且ＶＧＧ还需要多次微调网络的参数．
竞赛中，通过加深ＣＮＮ模型的深度并采用ＲｅＬＵ＋ ＡｌｅｘＮｅｔ模型、ＧｏｏｇＬｅＮｅｔ模型与 ＶＧＧ模型
ｄｒｏｐｏｕｔ技术，取得了当时最好的分类结果（该网络 都在ＩｍａｇｅＮｅｔ竞赛中取得了很好的结果，然而它
结构也被称为ＡｌｅｘＮｅｔ）．ＡｌｅｘＮｅｔ模型包含５个卷 们只能接受固定大小的输入．事实上，ＣＮＮ的卷积
积层和２个全连接层．与传统ＣＮＮ相比：在 Ａｌｅｘ－ 层不需要固定大小的输入，它可以产生任意大小的
Ｎｅｔ中采用ＲｅＬＵ代替饱和非线性函数ｔａｎｈ函数， 特征面，但是它的全连接层需要固定长度的输入，因
降低了模型的计算复杂度，模型的训练速度也提升 此ＣＮＮ的输入大小需保持一致的限制源于它的全
了几倍；通过ｄｒｏｐｏｕｔ技术在训练过程中将中间层的 连接层［６７］．为了获得固定大小的输入，需要对输入
一些神经元随机置为０，使模型更具有鲁棒性，也减 图像进行裁剪或者缩放，但是这样的变换会破坏输
少了全连接层的过拟合；而且还通过图像平移、图像 入图像的纵横比及完整的信息等，从而影响识别的
水平镜像变换、改变图像灰度等方式来增加训练样 准确率．Ｈｅ等人［６７］提出一种ＳＰＰ－ｎｅｔ模型，该模型
本，从而减少过拟合．相比于 ＡｌｅｘＮｅｔ，Ｓｚｅｇｅｄｙ等
是在ＣＮＮ的最后一个卷积层与第１个全连接层
人［６５］大大增加了ＣＮＮ的深度，提出了一个超过２０层
中间加入一个空间金字塔池化 （Ｓｐａｔｉａｌ Ｐｙｒａｍｉｄ
的 ＣＮＮ 结构（称为 ＧｏｏｇＬｅＮｅｔ）．在 ＧｏｏｇＬｅＮｅｔ Ｐｏｏｌｉｎｇ，ＳＰＰ）层．ＳＰＰ层能够使ＣＮＮ不同大小的
结构中采用了３种类型的卷积操作（１×１，３×３， 输入却产生大小相同的输出，打破了以往ＣＮＮ模
５×５），该结构的主要特点是提升了计算资源的利用
型的输入均为固定大小的局限，且该改进的ＣＮＮ
率，它的参数比文献［２４］少了１２倍，而且ＧｏｏｇＬｅＮｅｔ
模型训练速度较快，在ＬＳＶＲＣ－１４的图像分类比赛
的准确率更高，在 ＬＳＶＲＣ－１４中获得了图像分类
中获得第３名．
“指定数据”组的第１名．Ｓｉｍｏｎｙａｎ等人［６６］在其发
在层级很深的深度网络模型中，除了存在梯度
表的文章中探讨了“深度”对于ＣＮＮ 网络的重要 扩散问题外，还存在着退化问题．批规范化（Ｂａｔｃｈ
性．该文通过在现有的网络结构中不断增加具有
Ｎｏｒｍａｌｉｚａｔｉｏｎ，ＢＮ）是解决梯度扩散问题的一种有
３×３卷积核的卷积层来增加网络的深度，实验表明，
效方法［６８］．所谓退化问题就是：随着深度的增加，网
当权值层数达到１６～１９时，模型的性能能够得到有
络精度达到饱和，然后迅速下降．且该性能的下降不
效提升（文中的模型也称为ＶＧＧ模型）．ＶＧＧ模型
是由过拟合引起的，而是增加网络的深度使得它的
用具有小卷积核的多个卷积层替换一个具有较大卷
积核的卷积层（如用大小均为３×３卷积核的３层卷 ① Ｃｏｍｐａｓｉｏｎ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｓｏｆｔｗａｒｅ［Ｏｎｌｉｎｅ］．ｈｔｔｐｓ：／／ｅｎ．
ｗｉｋｉｐｅｄｉａ．ｏｒｇ／ｗｉｋｉ／Ｃｏｍｐａｒｉｓｏｎ＿ｏｆ＿ｄｅｅｐ＿ｌｅａｒｎｉｎｇ＿ｓｏｆｔ－
积层代替一层具有７×７卷积核的卷积层），这种替 ｗａｒｅ，２０１６，９，２２ １２４０ 计 算 机 学 报 ２０１７年
训练误差也随之增加［６９］．文献［６９］采用残差网络 不能增加输入图像的大小，那么可以减小其后
（Ｒｅｓｉｄｕａｌ Ｎｅｔｗｏｒｋｓ，ＲｅｓＮｅｔ）来解决退化问题． 卷积层中的滑动步长，这样也能够得到大致相同
ＲｅｓＮｅｔ的主要特点是跨层连接，它通过引入捷径连 的结果．
接技术（ｓｈｏｒｔｃｕｔ ｃｏｎｎｅｃｔｉｏｎｓ）将输入跨层传递并与 ５．２ 人脸识别
卷积的结果相加．在ＲｅｓＮｅｔ中只有一个池化层，它 在人脸识别中，传统的识别路线包括４个步骤：
连接在最后一个卷积层后面．ＲｅｓＮｅｔ使得底层的网 检测－对齐－人脸表示－分类．ＤｅｅｐＦａｃｅ［７２］也遵循这一
络能够得到充分训练，准确率也随着深度的加深 技术路线，但是对人脸对齐和人脸表示阶段进行了
而得到显著提升．将深度为１５２层的ＲｅｓＮｅｔ用于 改进．在 ＤｅｅｐＦａｃｅ中首先对图像进行３Ｄ人脸对
ＬＳＶＲＣ－１５的图像分类比赛中，它获得了第１名的成 齐，再输入到深度神经网络中．ＤｅｅｐＦａｃｅ的前３层
绩．在该文献中，还尝试将ＲｅｓＮｅｔ的深度设置为１０００， （２个卷积层及１个池化层）用于提取低级特征（如
并在ＣＩＦＡＲ－１０图像处理数据集中验证该模型． 边缘及纹理信息）．池化层能够使得网络对微小偏移
ＡｌｅｘＮｅｔ与 ＶＧＧ模型的网络结构为直线型， 更具有鲁棒性，但是为了减少信息的丢失，Ｄｅｅｐ－
它们的输入都是从第１个卷积层按单个路径直接传 Ｆａｃｅ的池化层只有１层，其紧跟在第１个卷积层后
递到最后一层．在ＢＰ训练中预测误差是由最顶层传 面．ＤｅｅｐＦａｃｅ的第２个卷积层后紧连着３个局部连
递到底层的，对于很深的网络模型传递至底层的误差 接层（这３个局部连接层卷积核不共享），由于在对
很小，难以优化底层参数［７０］．因此，对于ＡｌｅｘＮｅｔ与 齐的人脸图像中不同的区域有不同的局部统计特
ＶＧＧ模型，如果它们的深度很深，则将难以优化它 征，采用不共享的卷积核可减少信息的丢失．Ｄｅｅｐ－
们的结构．为了使网络结构能够得到有效训练， Ｆａｃｅ具有２个全连接层，全连接层可用来捕获人脸
ＧｏｏｇＬｅＮｅｔ在多个中间层中加入监督信号．ＲｅｓＮｅｔ 图像不同位置的特征之间（如人眼的位置与形状、嘴
则通过捷径连接技术使得输入可以通过多个路径流 巴的位置与形状）的相关性．将该模型应用于户外人
入最顶层，它大幅度降低了更深层模型的训练难度． 脸检测数据库（Ｌａｂｅｌｅｄ Ｆａｃｅｓ ｉｎ ｔｈｅ Ｗｉｌｄ，ＬＦＷ）中，
如何有效地训练层级很深的深度网络模型仍旧是一 ＤｅｅｅｐＦａｃｅ［７２］取得的人脸识别准确率为９７．３５％，接
个有待研究的问题．尽管图像分类任务能够受益于 近人眼辨识准确率９７．５３％，其所用方法克服了以
层级较深的卷积网络，但一些方法还是不能很好地 往方法的缺点和局限性．然而ＤｅｅｐＦａｃｅ的参数个数
处理遮挡或者运动模糊等问题． 多于１．２亿，其中９５％参数来自３个局部连接层及
Ｍｉｓｈｋｉｎ等人［７１］系统地比较了近年来在ＩｍａｇｅＮｅｔ ２个全连接层，因此ＤｅｅｐＦａｃｅ对有标注样本的数量
竞赛 的 大 数 据 中 不 同 ＣＮＮ 结 构 （包 括 ＶＧＧ、 要求较高，它需要一个大的有标注数据集．
ＧｏｏｇＬｅＮｅｔ）的性能及不同参数选取对ＣＮＮ结构的 在ＤｅｅｐＩＤ［７３］、ＤｅｅｐＩＤ２［７４］之后，Ｓｕｎ等人［７５］又
影响．文中通过实验得到以下一些建议：（１）对于激 相继提出了ＤｅｅｐＩＤ２＋、ＤｅｅｐＩＤ３［７６］．ＤｅｅｐＩＤ２＋继
励函数，可选取没有ＢＮ的指数线性单元（Ｅｘｐｏｎｅｎ－ 承了ＤｅｅｐＩＤ２的结构，它也包含４个卷积层，且每
ｔｉａｌ Ｌｉｎｅａｒ Ｕｎｉｔ，ＥＬＵ）［３７，７１］或者有ＢＮ的ＲｅＬＵ非 个卷积层后均紧随着一个池化层，并作了３个方面
线性函数；（２）在池化层中采用平均池化及最大值 的改进：（１）加大网络结构，每个卷积层的特征面个
池化之和比随机池化、单独的平均池化或者最大池 数增加到了１２８个，最终的特征表示也增加到了
化等方法要好；（３）相比较于平方根学习率衰减方 ５１２维；（２）增加了训练数据；（３）一个具有５１２维的
法（ｓｑｕａｒｅ ｒｏｏｔ）、平方学习率衰减方法（ｓｑｕａｒｅ）或 全连接层均与每一个池化层进行全连接，且每一池
者阶跃学习率衰减方法（ｓｔｅｐ），使用线性学习率衰 化层都添加监督信号（由人脸辨识信号和人脸确认
减方法（ｌｉｎｅａｒ）更好；（４）最小批量尺寸（ｍｉｎｉ－ｂａｔｃｈ 信号组成），使用监督信号既能够增加类间变化又能
ｓｉｚｅ）可取１２８或者２５６，如果这对于所用ＧＰＵ而言 够减少类内变化．ＤｅｅｐＩＤ２＋在ＬＦＷ 上的准确率达
还是太大，那么可按批量尺寸成比例减少学习率； 到了９９．４７％．ＤｅｅｐＩＤ２＋具有３个重要的属性：
（５）目前深度学习的性能高度依赖于数据集的大 （１）它的顶层神经元响应是中度稀疏的，即使将神
小．如果训练集大小小于它的最小值，那么模型性能 经元二值化后，仍能获得较好的识别结果，该性质能
会迅速降低．因此当增加训练集大小时，需要检查 够最大化网络的辨识能力及图像间的距离；（２）高
数据量是否已达到模型所需的最小值；（６）如果 层的神经元对人脸身份以及人脸属性具有很高的选 ６期 周飞燕等：卷积神经网络研究综述 １２４１
择性；（３）高层神经元对局部遮挡具有良好的鲁棒 高，但是ＣＮＮ在人脸识别中仍然有许多具有挑战
性．以往的许多研究工作为了获得这些引人注目的 性的问题，如面部特征点定位、人脸、姿态等对人脸
属性，通常需要对模型加入一些显性的约束，但是 识别效果的影响，都是需要深入研究的问题［７９］．
ＤｅｅｐＩＤ２＋通过数据训练深度模型就能够自动地得 ５．３ 音频检索
到这些属性［７５］．ＤｅｅｐＩＤ２＋的提出不仅能够显著提 Ａｂｄｅｌ－Ｈａｍｉｄ等人［８０，８１］结合隐马尔科夫建立了
升人脸识别的性能，还能够帮助人们理解深度模型 ＣＮＮ用于识别语音的模型，并在标准ＴＩＭＩＴ 语音
及其网络连接，且对稀疏表示、属性学习和遮挡处理 数据库上进行实验，实验结果显示该模型的错误率
等研究也起一定的指导作用［７５］．Ｓｕｎ等人［７６］分别重 相对于具有相同隐含层数和权值的常规神经网络模
建了ＶＧＧ网络和ＧｏｏｇＬｅＮｅｔ网络，得到ＤｅｅｐＩＤ３ 型低了１０％，表明ＣＮＮ模型能够提升语音的识别
ｎｅｔ１网络和ＤｅｅｐＩＤ３ｎｅｔ２网络（将它们称为Ｄｅｅｐ－ 准确率．在文献［８０，８１］中，ＣＮＮ模型的卷积层均采
ＩＤ３）．ＤｅｅｐＩＤ３继承了ＤｅｅｐＩＤ２＋的一些特点，在最 用了受限权值共享（Ｌｉｍｉｔｅｄ Ｗｅｉｇｈｔ Ｓｈａｒｉｎｇ，ＬＷＳ）
后几个特征提取层中它们的权值也不共享，并且为 技术，该技术能够更好地处理语音特征，然而这种
了使网络能够更好地学习中级特征及更易于训练， ＬＷＳ方法仅限于单个卷积层，不像大部分的ＣＮＮ
在网络的一些中间层中也要加入人脸辨识－人脸确 研究可以使用多个卷积层．ＩＢＭ 和微软公司近年来
认监督信号．然而ＤｅｅｐＩＤ３的深度更深，且它的非 在ＣＮＮ用于识别语音方面也做了大量的研究工
线性特征提取层可达１０～１５层．通过结合ＤｅｅｐＩＤ３ 作，并发表了一些相关的论文［８２－８４］．
ｎｅｔ１网络和ＤｅｅｐＩＤ３ｎｅｔ２网络，在ＬＦＷ 上Ｄｅｅｐ－ ５．４ ＥＣＧ分析
ＩＤ３的人脸识别准确率为９９．５３％．尽管 ＤｅｅｐＩＤ３ ＥＣＧ是目前极为有用的一种心血管系统疾病
的深度要比ＤｅｅｐＩＤ２＋深，但是它要比 ＶＧＧ或者 的临床诊断体征．远程医疗诊断服务系统的产生使
ＧｏｏｇＬｅＮｅｔ深度浅得多．然而当更正了ＬＦＷ上一些 得更多的人获得医疗专家的诊断服务，许多研究者
错误标注的数据后，它的准确率与ＤｅｅｐＩＤ２＋一样， 包括本课题组多年来一直致力于研究计算机辅
还需在更大的训练集上进一步研究很深的深度模型 助ＥＣＧ分析［８５］．Ｋａｄｉ等人［８６］综述了从２０００年到
的有效性． ２０１５年将数据挖掘技术应用于计算机辅助心血管
ＦａｃｅＮｅｔ［７７］是由 Ｇｏｏｇｌｅ公司提出的一种人脸 疾病分析的文章．他们根据数据挖掘技术及其性能
识别模型，它直接学习从人脸图像到紧致欧式空间 选出１４９篇文献并进行分析，通过研究发现：从
的一个映射，使欧式距离直接关联着人脸相似度的 ２０００年到２０１５年，关于使用数据挖掘技术辅助分
一个度量．ＦａｃｅＮｅｔ是一个端对端的学习方法，它通 析心血管疾病的研究数量呈增长趋势；研究人员常
过引入三元组损失函数进行人脸验证、识别和聚类． 将挖掘技术用于分类和预测；相比较于其它数据挖
ＦａｃｅＮｅｔ直接优化与任务相关的三元组损失函数， 掘技术，神经网络和支持向量机能够获得更高的准
在训练过程中该损失不仅仅用在最后一层，它也用 确率．该文献的分析结果也说明了神经网络技术在
于多个层中．然而如果选择不合适的三元组损失函 计算机辅助心血管疾病分析中的有效性．然而由于
数，那么将会影响模型的性能，同时也会使收敛速度 实际应用中ＥＣＧ数据形态复杂多变，将传统的神经
变慢，因此三元组损失函数的选取对于 ＦａｃｅＮｅｔ性 网络技术应用于大数据的ＥＣＧ分析中，取得的结果
能的提升很重要．经ＬＦＷ 数据库和ＹｏｕＴｕｂｅ人脸 并不是很理想．
数据库测试，ＦａｃｅＮｅｔ得到的识别准确率分别为 临床实际应用中，ＥＣＧ多数为多导联信号，与
９９．６３％和９５．１２％． 二维图像相似．本课题组成员朱洪海［８７］针对多导联
相比较于 ＤｅｅｐＦａｃｅ、ＤｅｅｐＩＤ，ＦａｃｅＮｅｔ不需要 ＥＣＧ数据，同时考虑到ＣＮＮ的优越特性，提出了一
进行复杂的３Ｄ对齐，ＤｅｅｐＩＤ则需要一个简单的２Ｄ 种ＥＣＧ－ＣＮＮ模型，从目前公开发表的文献可知，该
仿射对齐．Ｐａｒｋｈｉ等人［７８］在其文章中也研究了在不 ＥＣＧ－ＣＮＮ模型也是ＣＮＮ首次应用于ＥＣＧ分类
同ＣＮＮ结构中人脸对齐对人脸识别准确性的影 中．ＥＣＧ－ＣＮＮ模型采用具有３个卷积层和３个池
响．他们通过实验发现对齐后 ＦａｃｅＮｅｔ的识别准确 化层的ＣＮＮ结构，其输入数据维数为８×１８００（对
率比原模型的高［７８］．在 ＬＦＷ 数据库，ＤｅｅｐＦａｃｅ、 应８个基本导联ＥＣＧ采样点数）．ＥＣＧ－ＣＮＮ的第１
ＤｅｅｐＩＤ系列及ＦａｃｅＮｅｔ的人脸识别准确率都比较 个卷积核的大小为８×２３，它包含了全部的行，这与 １２４２ 计 算 机 学 报 ２０１７年
ＬｅＮｅｔ－５网络结构在图像中的卷积核大小为５×５ ＣＮＮ模型的分类性能优于对照文献的分类性能．
不一样，图像中的卷积核一般不会包含全部的行．通 Ｈａｋａｃｏｖａ等人［９１］２０１２年统计了市场上一些心电图
过采用ＥＣＧ－ＣＮＮ模型对国际公认的心律失常数 机的自动诊断结果，总共统计了５７６例ＥＣＧ，发现
据库———ＭＩＴ－ＢＩＨ数据库①（该数据库共４８条记 Ｐｈｉｌｉｐｓ ｍｅｄｉｃａｌ自动诊断准确率只有８０％，Ｄｒａｅｇｅｒ
录）中的４０条ＥＣＧ记录进行病人内心拍分类，得到 ｍｅｄｉｃａｌ ｓｙｓｔｅｍｓ的准确率为７５％，而３名普通医生
的准确率为９９．２％．同时在该文献中还采用ＥＣＧ－ 的ＥＣＧ 判读准确率为８５％，对比该统计结果及
ＣＮＮ模型对本课题组为了面向临床应用而建立的 ＥＣＧ－ＣＮＮ模型所得结果，验证了ＣＮＮ在ＥＣＧ分
中国心血管疾病数据库［８８］（Ｃｈｉｎｅｓｅ Ｃａｒｄｉｏｖａｓｃｕｌａｒ 类中的有效性．
Ｄｉｓｅａｓｅ Ｄａｔａｂａｓｅ，ＣＣＤＤ，ｈｔｔｐ：／／５８．２１０．５６．１６４： 文献［８７］的ＥＣＧ－ＣＮＮ模型其实也是一种二
８８／ｃｃｄｄ／）的前２５１条记录进行心拍正异常分类，得 维ＣＮＮ，但是ＥＣＧ的导联间数据相关性与导联内
到的准确率为９７．８９％．文中将文献［８９］和文献 数据的相关性不一样，导联内数据具有时间相关性，
［９０］作为对照文献，相同数据集上，文献［８９］和［９０］ 导联间的数据却是独立的，因此不宜将二维图像的
得到的心拍正异常分类准确率分别为 ９８．５１％和 ＣＮＮ结构应用于ＥＣＧ分类中［４８］．据此，金林鹏和
９４．９７％．此外文献［８７］还采用该算法对ＣＣＤＤ数 董军［４８］在ＥＣＧ－ＣＮＮ模型上做了改进，提出了导联
据库的Ｓｅｔ ＩＶ数据集共１１ ７６０条记录进行按记录 卷积神经网络（Ｌｅａｄ Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ，
的病人间正异常分类，最终准确率为８３．４９％，文 ＬＣＮＮ）模型．图８所示为基于记录分类的ＬＣＮＮ
献［８９］和［９０］在该数据集中得到的准确率分别为 结构．
７０．１５％和７２．１４％．从上述对比结果可知，ＥＣＧ－
图８ 基于记录分类的ＬＣＮＮ结构［４８］
在图８中，每个卷积单元ＣＵ均包含一个卷积 ＥＣＧ记录的周期特性，对ＥＣＧ记录进行起始点平
层和一个池化层，例如ＣＵ－Ａ１、ＣＵ－Ｂ１及ＣＵ－Ｃ１均 移操作，将一条ＥＣＧ记录所有可能的情况都包含进
包含一个卷积层和一个池化层，１Ｄ－Ｃｏｃ表示一维卷 去［４８］．在ＬＣＮＮ的训练过程中，采用惯性量和变步
积运算．对于８个导联，每一个导联均有３个卷积单 长的反向ＢＰ算法［９２］．同样在ＣＣＤＤ上进行模型验
元，而且不同导联间的卷积单元是相互独立的．每个 证，经测试，ＬＣＮＮ取得了８３．６６％的ＥＣＧ病人间
导联的数据依次通过３个卷积单元，如其中一个导 正异常分类准确率，该结果也说明了ＬＣＮＮ在实际
联依次通过卷积单元ＣＵ－Ａ１、ＣＵ－Ｂ１、ＣＵ－Ｃ１，然后 应用中的有效性．王丽苹［９３］构建了一个包含个体内
将每个导联的第３个池化层都连接到同一个全连接
时间序列及统计分类的混合分类模型（简称ＥＣＧ－
层进行信息汇总，最终在逻辑回归层上进行分类．与
ＭＴＨＣ），该模型包含ＲＲ间期正异常分析、ＱＲＳ波
文献［８７］相比，ＥＣＧ－ＣＮＮ模型只有３个卷积单元， 群相似度分析、基于数值和形态特征的ＳＶＭ 分类
而图８中的ＬＣＮＮ结构有２４个卷积单元．文献［８７］ 模型及ＥＣＧ典型特征分析４个分类模块．金等将
中对于连接输入层的卷积层，其卷积核大小为
ＥＣＧ－ＭＴＨＣ模型同样对ＣＣＤＤ中的ＥＣＧ记录进
８×２３，图８中每一个导联的第１个卷积层的卷积核
行测试，但是由于有１万多条ＥＣＧ记录的中间特征
大小均为１×１８．为了增加训练样本从而降低不同
① ＭＩＴ－ＢＩＨ Ａｒｒｈｙｔｈｍｉａ Ｄａｔａｂａｓｅ［Ｏｎｌｉｎｅ］．ｈｔｔｐ：／／ｗｗｗ．
类别 ＥＣＧ 数据的不平衡性，ＬＣＮＮ 充分利用了 ｐｈｙｓｉｏｎｅｔ．ｏｒｇ／ｐｈｙｓｉｏｂａｎｋ／ｄａｔａｂａｓｅ／ｍｉｔｄｂ／，２０１６，９，２８ ６期 周飞燕等：卷积神经网络研究综述 １２４３
提取出错而无法给出诊断结论，因此ＥＣＧ－ＭＴＨＣ 出一种基于一维ＣＮＮ的病人内ＥＣＧ分类，该ＣＮＮ
模型只给出了１４多万条 ＥＣＧ 的自动诊断结果， 结构包含３个ＣＮＮ层和２个 ＭＬＰ层，将 ＭＩＴ－ＢＩＨ
其判断准确率为７２．４９％，而 ＬＣＮＮ 在该测试数 数据库中的４４条记录作为实验数据，得到室性异位
据上的分类结果为８３．７２％［４８］．与文献［９３］相比： 心拍（ＶＥＢ）和室上性异位心拍（ＳＶＥＢ）的分类准确
（１）ＬＣＮＮ实际上也是一个端对端的学习方法，将 率分别为９９％和９７．６％．然而这些研究工作仅利用
中间的卷积层和池化层提取得到的特征输入到全连 了标准数据库中的部分数据，不能够充分体现模型
接层中，最后由ｓｏｆｔｍａｘ层进行分类；（２）对于较大 在实际应用中的整体分类性能．
规模的数据集，ＬＣＮＮ比ＥＣＧ－ＭＴＨＣ更易于训练； 由于不同的时间序列可能需要不同时间尺度上
（３）由于ＬＣＮＮ的深度架构及复杂的网络结构，使它 的不同特征表示，但是现有的许多算法没有考虑到
具有很强的非线性拟合能力，克服了ＥＣＧ－ＭＴＨＣ 这些因素，而且由于高频干扰及随机噪声的影响，在
中ＳＶＭ非线性拟合能力有限的缺点．最终，ＬＣＮＮ 实时时间序列数据中具有判别性的模式通常也会变
的分类准确率高于ＥＣＧ－ＭＴＨＣ的准确率．周飞燕 形．为了克服这些问题，Ｃｕｉ等人［９７］提出了一种基于
等人［９４］将ＬＣＮＮ作为基分类器提出了一种基于集成 多尺度ＣＮＮ的时间序列分类模型（称为 ＭＣＮＮ模
学习的室性早博识别方法，采用该方法对 ＭＩＴ－ＢＩＨ 型）．ＭＣＮＮ模型包含３个阶段：变换阶段、局部卷
中的４８条记录进行室性早搏心拍分类得到的准确 积阶段、全卷积阶段．变换阶段：首先对输入数据分
率为９９．９１％；同时该文还注重模拟医生诊断ＥＣＧ 别采用不同的变换（包含时域中的恒等映射、下采样
的思维过程，采用ＬＣＮＮ与室性早搏诊断规则相结 变换以及频域中的光谱变换），假设原始输入数据分
合的方法对ＣＣＤＤ进行按记录的室性早搏分类，得 别经过上述３种变换，则得到３种变换数据．局部卷
到的测试准确率为９７．８７％．在与文献［４８］相同的
积阶段：将３种变换数据作为３个并联卷积层的输
数据集上，Ｊｉｎ等人①还分别采用显性训练方法及隐
入（一种变换数据输入到一个卷积层中，这与文献
性训练方法独立训练两个ＬＣＮＮ模型并进行正异 ［４８］的ＬＣＮＮ模型类似），每个卷积层后紧随着一
常分类，然后采用集成学习中的融合规则方法融合这
个池化层．全卷积阶段：局部卷积阶段的３个池化层
两个分类器的判别结果，最后再采用规则推理分别对
连接到同一个卷积层中进行信息汇总，在该阶段中可
ＬＣＮＮ融合后判断出来的正异常类作再次判断，最
以采用多个卷积层和多个池化层进行交替设置，最后
终得到的准确率为８６．２２％，所得分类结果优于文
跟随着一个全连接层及ｓｏｆｔｍａｘ层．与文献［４８］相
献［４８］．实验结果表明，利用ＣＮＮ与其它方法相结
比：ＭＣＮＮ在卷积层中将多通道的数据进行整合，
合是提升整体分类性能的一种有效途径．
文献［４８］则在全连接层中进行信息汇总，ＭＣＮＮ对
然而在文献［４８，８７，９４］的ＣＮＮ结构中，它们
卷积核大小及池化核大小的设置也不一样．ＭＣＮＮ
的全连接层只能接受固定长度的输入，因此在网络
可以处理多元时间序列，它通过将原始数据下采样
训练之前需要将ＥＣＧ记录截取到固定长度．但是在
到不同的时间尺度使其不仅能够提取不同尺度的低
实际应用中，ＥＣＧ 记录的长度通常不一致，如在
级特征还能够提取更高级的特征．ＣＮＮ除了用于时
ＣＣＤＤ中ＥＣＧ记录的长度为１０ｓ～３０ｓ，而且有的
间序列分类外，还可以用于时间序列度量学习［９８］．
疾病（如早搏）可以发生在一条记录的前几秒，它
５．５ 其它应用
也可发生在记录中的中间几秒或者最后几秒，这
Ｒｅｄｍｏｎ等人［９９］将目标检测看成是一个回归问
种截取到固定长度的方式可能会使信息丢失比较
题，采用一个具有２４个卷积层和２个全连接层的
严重．
ＣＮＮ结构（也称为ＹＯＬＯ，Ｙｏｕ Ｏｎｌｙ Ｌｏｏｋ Ｏｎｃｅ）进
Ｚｈｅｎｇ等人［９５，９６］将一种多通道的深层ＣＮＮ模型
行目标检测．在ＹＯＬＯ中，输入整幅图像，并将图像
（Ｍｕｌｔｉ－Ｃｈａｎｎｅｌｓ Ｄｅｅｐ Ｃｏｎｖｏｌｕｔｉｏｎ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ，
划分为７×７个网格，通过ＣＮＮ预测每个网格的多
ＭＣ－ＤＣＮＮ）应用于时间序列分类中，每一通道的数
个包围盒（ｂｏｕｎｄｉｎｇ ｂｏｘｅｓ，用来包裹场景中目标的
据都首先经过一个独立的ＣＮＮ结构，其中每一通
几何体）及这些包围盒的类别概率．ＹＯＬＯ将整幅
道的输入是一个时间序列，然后将每一个ＣＮＮ结
构的最后一层卷积层全连接到 ＭＬＰ中进行分类，
① Ｊｉｎ Ｌｉｎ－Ｐｅｎｇ，Ｄｏｎｇ Ｊｕｎ．Ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｏｆ ｎｏｒｍａｌ ａｎｄ ａｂｎｏｒｍａｌ
在ＢＩＤＭＣ充血性心力衰竭数据集上的检测准确率 ＥＣＧ ｒｅｃｏｒｄｓ ｕｓｉｎｇ ｌｅａｄ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｎｄ
ｒｕｌｅ ｉｎｆｅｒｅｎｃｅ［Ｊ］．Ｓｃｉｅｎｃｅｓ Ｃｈｉｎａ Ｉｎｆｏｒｍａｔｉｏｎ Ｓｃｉｅｎｃｅ，
为９４．６５％，优于其他一些算法．Ｋｉｒａｎｙａｚ等人［２７］提 ２０１７．ｄｏｉ：１０．１００７／ｓ１１４３２－０１６－９０４７－６） １２４４ 计 算 机 学 报 ２０１７年
图像作为下文信息，使得背景误差比较小．ＹＯＬＯ 构，并将不同网络结构的ＣＮＮ 模型应用于 ＭＩＴ－
的检测速度也非常快，在Ｔｉｔａｎ Ｘ的ＧＰＵ上每秒钟 ＢＩＨ 数据库中的室性早搏心拍分类中．根据各个实
可以处理４５幅图像．然而ＹＯＬＯ也有存在一些不 验结果，分析了ＣＮＮ各参数间的相互关系及不同
足：（１）因为每个网格只预测两个包围盒且只有一 参数设置对分类结果的影响．将 ＭＩＴ－ＢＩＨ 数据库
个类别，因此它具有很强的空间约束性，这种约束限 中４８条记录的１１０ １０９个心拍划分为ＣＮＮ模型的
制了模型对邻近目标的预测，同时如果小目标数量 训练集和测试集，其中随机选取２４ １００个心拍作为
过多也会影响模型的检测能力；（２）对于不包含在 训练集，其余心拍为测试集，同时采用ＢＰ算法进行
训练集中的目标或者有异常比例的目标，它的泛化 有监督训练（用开源工具Ｔｈｅａｎｏ实现）．每个ＣＮＮ
能力不是很好；（３）模型主要的误差仍然因为是不
结构的训练集和测试集都一样．心拍截取方式与文
能精准定位而引起的误差．由于ＹＯＬＯ不能精准定 献［９４］一致．本文采用ＡＵＣ［４８］即ＲＯＣ曲线下的面
位，这也使得它的检测精度小于Ｆａｓｔｅｒ Ｒ－ＣＮＮ［１００］，
积来衡量每个ＣＮＮ结构的室性早搏分类性能．一
但是ＹＯＬＯ的速度更快．Ｆａｓｔｅｒ Ｒ－ＣＮＮ是候选框
般来说，ＡＵＣ值越大，算法分类性能越好．
网络 （Ｒｅｇｉｏｎ Ｐｒｏｐｏｓａｌ Ｎｅｔｗｏｒｋ，ＲＰＮ）［１００］与Ｆａｓｔ
本文所采用的网络结构深度共有４种：深度为
Ｒ－ＣＮＮ［１０１］结合并共享卷积层特征的网络，它也是
５（含输入层、输出层、全连接层、１个卷积层及１个
基于分类器的方法［７９］．由于 ＹＯＬＯ检测精度不是
池化层）、７（含输入层、输出层、全连接层、２个卷积
很高，因此 Ｌｉｕ等人［１０２］基于 ＹＯＬＯ 提出了ＳＳＤ
层及２个池化层）、９（含输入层、输出层、全连接层、
（Ｓｉｎｇｌｅ Ｓｈｏｔ Ｄｅｔｅｃｔｏｒ）模型．ＳＳＤ利用了ＹＯＬＯ的
３个卷积层及３个池化层）及１１（含输入层、输出层、
回归思想，同时还借鉴了Ｆａｓｔｅｒ Ｒ－ＣＮＮ的锚点机
全连接层、４个卷积层及４个池化层）．首先讨论卷
制（ａｎｃｈｏｒ机制）．它与ＹＯＬＯ一样通过回归获取目
积核大小对分类性能的影响．实验过程：分别对每一
标位置和类别，不同的是：ＳＳＤ预测某个位置采用
种深度设置５个不同的ＣＮＮ模型，这５个不同的
的是该位置周围的特征．最终，ＳＳＤ获得的检测精
ＣＮＮ模型除卷积核大小外，其它参数如特征面数
度与Ｆａｓｔｅｒ Ｒ－ＣＮＮ 的差不多，但是ＳＳＤ 保持了
目、池化核大小、全连接层神经元个数均相同．如
ＹＯＬＯ快速检测的特性．此外，ＣＮＮ还可用于短文
表２所示．
本聚类［１０３］、视觉追踪［１０４］、图像融合［１０５］等领域中．
表２列出了每个卷积层和池化层对应卷积核的
５．６ ＣＮＮ的优势
大小及池化核的大小．每一行参数构成一个ＣＮＮ
ＣＮＮ具有４个特点：局部连接、权值共享、池化
模型，表中特征面数目为每个卷积层所采用的特征
操作及多层结构［１１］．ＣＮＮ能够通过多层非线性变
面个数，由于卷积层与池化层特征面唯一对应，所以
换，从数据中自动学习特征，从而代替手工设计的特
卷积层特征面个数确定后，紧跟其后的池化层特征
征，且深层的结构使它具有很强的表达能力和学习能
力［７０］．许多研究实验已经表明了ＣＮＮ结构中深度的
面个数也唯一确定．表２的这５个ＣＮＮ模型只有
卷积核大小不同．从表２的分类结果可看出，对于网
重要性．例如从结构来看，ＡｌｅｘＮｅｔ、ＶＧＧ、ＧｏｏｌｅＮｅｔ
络深度为１１的模型，随着卷积核变大，ＡＵＣ先增加
及ＲｅｓＮｅｔ的一个典型的发展趋势是它们的深度越
来越深［３７］．在ＣＮＮ中，通过增加深度从而增加网络
后减小．对于另外３组实验：在深度为５和７的模型
的非线性来使它能够更好地拟合目标函数，获得更
中，随着卷积核的增大，ＡＵＣ先减小后增加再减小；
好的分布式特征［１１］． 深度为９的模型，随着卷积核增大，ＡＵＣ先较小后
趋于平稳再减小．图９所示为深度是５的ＣＮＮ结
６ 关于ＣＮＮ参数设置的一些探讨 构（含１个卷积层和１个池化层）随着卷积核的改
变，其分类性能的变化曲线图．通过实验发现，在某
６．１ ＥＣＧ实验分析 一个范围内我们能够找到一个比较合适的卷积核的
ＣＮＮ在计算机辅助ＥＣＧ分析领域中的研究已 大小，卷积核过大或者过小均不利于模型的学习．在
初见端倪．本文就ＣＮＮ在计算机辅助ＥＣＧ分析应 本实验中，卷积核的大小取值范围在［１０，１６］时，其
用中，设计了不同参数及不同深度的 ＣＮＮ网络结 模型能够获得一个更好的分类结果． ６期 周飞燕等：卷积神经网络研究综述 １２４５
表２ 深度为１１的５个不同网络结构的ＣＮＮ分类结果
Ｓｔａｇｅ１ Ｓｔａｇｅ２ Ｓｔａｇｅ３ Ｓｔａｇｅ４
特征面数目 深度 ＡＵＣ
卷积层 池化层 卷积层 池化层 卷积层 池化层 卷积层 池化层
１×３ １×２ １×４ １×２ １×４ １×２ １×４ １×２ （８，８，８，８） １１ ０．９９７９
１×７ １×２ １×６ １×２ １×６ １×２ １×６ １×２ （８，８，８，８） １１ ０．９９８０
Ｄｅｐ＿１１Ａ １×１１ １×２ １×１０ １×２ １×１１ １×２ １×１０ １×２ （８，８，８，８） １１ ０．９９８７
１×１５ １×２ １×１４ １×２ １×１４ １×２ １×１５ １×２ （８，８，８，８） １１ ０．９９６７
１×１９ １×２ １×１８ １×２ １×１９ １×２ １×１９ １×２ （８，８，８，８） １１ ０．９９６７
来看，随着模型深度的增加，其分类结果也越来越
好．在本实验中，模型通常在池化核大小为２或者３
时取得相对较好的分类结果．表３列出了深度为９
的３个不同网络结构的ＣＮＮ室性早搏分类结果．
为了探讨特征面数目对分类性能的影响，这里
我们也对每一种深度分别设置５个不同的ＣＮＮ模
型．其中，这５个ＣＮＮ模型除特征面数目外，其它
参数设置一样．通过实验发现，如果特征面数目过
小，其分类性能较差．这是由于特征面数目过少，使
图９ 卷积核大小与分类性能的影响 得一些有利于网络学习的特征被忽略掉，因而不利
为了讨论池化核大小对分类性能的影响，我们
于模型的学习．然而，当特征面数目大于４０时，模型
同样对每一种深度分别设置３个不同的ＣＮＮ 模
的训练时间大大增加，这同样不利于模型的学习．通
型．类似地，这３个ＣＮＮ模型，除了池化核大小外，
过实验可知，本实验中，比较好的特征面数目选取范
其他参数设置均相同．由于池化核大小要使式（１１） 围为［１０，３５］．表４列出了深度为１１的５个不同网
能够整除，因此对于某一深度的网络，池化核大小不 络结构的ＣＮＮ分类结果，在这５个ＣＮＮ结构中，
能够随意取值．从几组实验的结果来看，一般来说随 只有特征面数目不同，且随着特征面数目的增加，
着池化核大小的增加，ＡＵＣ先增加后减小．从总体 ＡＵＣ先增加再减小后增加．
表３ 深度为９的３个不同网络结构的ＣＮＮ分类结果
Ｓｔａｇｅ１ Ｓｔａｇｅ２ Ｓｔａｇｅ３
特征面数目 深度 ＡＵＣ
卷积层 池化层 卷积层 池化层 卷积层 池化层
１×５ １×１ １×５ １×１ １×５ １×１ （１６，１６，１６） ９ ０．９９７０
Ｄｅｐ＿９ １×５ １×２ １×５ １×２ １×５ １×２ （１６，１６，１６） ９ ０．９９８０
１×５ １×４ １×５ １×５ １×５ １×５ （１６，１６，１６） ９ ０．９９７８
表４ 深度为１１的５个不同网络结构的ＣＮＮ分类结果
Ｓｔａｇｅ１ Ｓｔａｇｅ２ Ｓｔａｇｅ３ Ｓｔａｇｅ４
特征面数目 深度 ＡＵＣ
卷积层 池化层 卷积层 池化层 卷积层 池化层 卷积层 池化层
１×５ １×２ １×５ １×４ １×５ １×４ １×５ １×４ （３，３，３，３） １１ ０．９８４６
１×５ １×２ １×５ １×４ １×５ １×４ １×５ １×４ （６，６，６，６） １１ ０．９９１０
Ｄｅｐ＿１１Ｂ １×５ １×２ １×５ １×４ １×５ １×４ １×５ １×４ （１２，１２，１２，１２） １１ ０．９９７１
１×５ １×２ １×５ １×４ １×５ １×４ １×５ １×４ （２４，２４，２４，２４） １１ ０．９９５６
１×５ １×２ １×５ １×４ １×５ １×４ １×５ １×４ （４８，４８，４８，４８） １１ ０．９９７２
表５所示为４个不同深度的ＣＮＮ模型及其室 表５ 不同深度的ＣＮＮ分类结果
性早搏分类结果．在每一个Ｓｔａｇｅ：（１×５）＋（１×２） Ｍｏｄｅｌ 具体结构 特征面数目 深度 ＡＵＣ
Ｍｏｄｅｌ＿Ａ Ｓｔａｇｅ１：（１×５）＋（１×２） １５ ５ ０．９９７１
中，１×５表示卷积层中卷积核大小，１×２表示紧跟
Ｍｏｄｅｌ＿Ｂ
Ｓｔａｇｅ１：（１×５）＋（１×２）；
（１５，１５） ７ ０．９９７５
Ｓｔａｇｅ２：（１×５）＋（１×２）
其后的池化层的池化核大小．实验结果表明，随着深
Ｓｔａｇｅ１：（１×５）＋（１×２）；
度的加深，网络性能也越来越好． Ｍｏｄｅｌ＿Ｃ Ｓｔａｇｅ２：（１×５）＋（１×２）； （１５，１５，１５） ９ ０．９９８１
Ｓｔａｇｅ３：（１×５）＋（１×２）
为了探讨ＣＮＮ的深度、卷积核大小、池化核大
Ｓｔａｇｅ１：（１×５）＋（１×２）；
小及特征面数目之间的关系，我们采用不同的深度、 Ｍｏｄｅｌ＿Ｄ Ｓ Ｓｔ ｔａ ａｇ ｇｅ ｅ２ ３： ：（ （１ １× ×５ ５） ）＋ ＋（ （１ １× ×２ ２） ）； ；（１５，１５，１５，１５）１１ ０．９９８５
卷积核大小、池化核大小及特征面数目设计了３５０ Ｓｔａｇｅ４：（１×５）＋（１×２） １２４６ 计 算 机 学 报 ２０１７年
多个不同的ＣＮＮ模型．这些不同的ＣＮＮ模型均利 ＭＩＴ－ＢＩＨ数据库进行的；（２）深度比卷积核大小及
用与上述相同的训练集和测试集进行实验．通过实 池化核大小更重要；（３）随着网络深度的加深，模型
验发现：（１）对于同一深度，特征面数目比卷积核大 分类性能来越越好；（４）对于同一个深度的模型，特
小更重要，具有更小卷积核及更大特征面数目的 征面数目越大，分类性能越好．
ＣＮＮ模型比具有更大卷积核且更小特征面数目的 ６．２ 脉搏波实验分析
ＣＮＮ模型获得更好的分类结果，这与文献［３６］中特 胡晓娟［１０６］采用两种不同深度的ＣＮＮ结构分
征面数目与卷积核大小所发挥的作用相当不一样， 别在健康／亚健康数据集及动脉硬化／肺动脉硬化数
同时也说明了对于不同的数据库，ＣＮＮ的分类性能 据集进行分类实验．表６为不同ＣＮＮ模型分别在
会有些不一样的表现，本小结的实验分析是基于 两个数据集上的测试结果．
表６ 不同深度的ＣＮＮ在脉搏波上的分类结果
健康／亚健康 动脉硬化／非动脉硬化
Ｍｏｄｅｌ
特异性／％ 灵敏度／％ 准确率／％ 特异性／％ 灵敏度／％ 准确率／％
ＣＮＮ（７Ｌ） ７０．８７ ６４．１４ ６７．５０ ９６．６２ ８９．０９ ９４．７８
ＣＮＮ（９Ｌ） ７５．６４ ６８．９９ ７２．３１ ９６．６４ ９５．５３ ９６．３３
表６中ＣＮＮ（７Ｌ）表示该ＣＮＮ的深度为７层， （２）对于一个具体的任务，仍很难确定使用哪
而ＣＮＮ（９Ｌ）模型的深度为９层．从上述结果也可看 种网络结构，使用多少层，每一层使用多少个神经元
出，在两个数据集上ＣＮＮ（９Ｌ）模型所得各指标均 等才是合适的．仍然需要详细的知识来选择合理的
高于ＣＮＮ（７Ｌ）模型，同时也说明了增加网络的层 值如学习率、正则化的强度等［１０７］．
数可以挖掘脉搏波更深层的特征，深度越深，模型的 （３）如果训练数据集与测试数据集的分布不一
性能越好． 样，则ＣＮＮ也很难获得一个好的识别结果，特别是
对于复杂的数据例如临床ＥＣＧ数据．因此，需要引
７ 总 结 入ＣＮＮ模型的自适应技术，可考虑将自适应抽样
等应用于ＣＮＮ模型中［１６］．
近年来，ＣＮＮ的局部连接、权值共享、池化操作 （４）尽管依赖于计算机的ＣＮＮ模型是否与灵
及多层结构等优良特性使其受到了许多研究者的关 长类视觉系统相似仍待确定，但是通过模仿和纳入
注．ＣＮＮ通过权值共享减少了需要训练的权值个 灵长类视觉系统也能使ＣＮＮ模型具有进一步提高
数、降低了网络的计算复杂度，同时通过池化操作使 性能的潜力［１０７］．
得网络对输入的局部变换具有一定的不变性如平移 （５）目前，ＣＮＮ在计算机辅助ＥＣＧ分析领域
不变性、缩放不变性等，提升了网络的泛化能力． 中，其输入维数需保持一致．为了使输入维数保持一
ＣＮＮ将原始数据直接输入到网络中，然后隐性地从 致，需要将原始数据截取到固定长度，然而ＲＮＮ可
训练数据中进行网络学习，避免了手工提取特征、从 以处理长度不等的数据，因此需考虑如何将ＣＮＮ
而导致误差累积的缺点，其整个分类过程是自动的． 与ＲＮＮ相结合，并应用于ＥＣＧ记录分类中．
虽然ＣＮＮ所具有的这些特点使其已被广泛应用于 （６）在隐性训练中，如何将整个训练过程中的
各种领域中，但其优势并不意味着可以解决或改善 最佳分类模型保存下来也是一个值得探讨的问题．
以往各种问题．比如，由对金融数据的初步分析结果 在文献［４８］的隐性训练中，当所有的训练样本在一
可知，ＣＮＮ并未获得预期性能，可能原因是金融数 个训练周期内都参与ＢＰ反向传播过程后，才输出
据本身缺乏规律、易受干扰以及预测结果反过来会 整个训练中的测试结果，如果此时其准确率是目前
影响走势等特点所致．ＣＮＮ仍有许多工作需要进一 为止最高的，则保存当前分类模型．事实上，我们
步去做： 还可以对它做进一步的改进，例如当部分样本进
（１）目前所使用的ＣＮＮ模型是 Ｈｕｂｅｌ－Ｗｉｅｓｅｌ 行ＢＰ训练后，就可采用校验样本测试当前的模
模型［２８］简化的版本，有待进一步借鉴 Ｈｕｂｅｌ－Ｗｉｅｓｅｌ 型，然后判断该模型是否为迄今为止性能最佳的分
模型，对它进行深入研究并发现结构特点及一些规 类模型．
律，同时还需引入其它理论使 ＣＮＮ能够充分发挥 总之，ＣＮＮ虽然还有许多有待解决的问题，但
其潜在的优势． 是这并不影响今后它在模式识别与人工智能等领域 ６期 周飞燕等：卷积神经网络研究综述 １２４７
中的发展与应用，它在未来很长的一段时间内仍然 ［１５］ Ｓａｌａｋｈｕｔｄｉｎｏｖ Ｒ，Ｈｉｎｔｏｎ Ｇ．Ａｎ ｅｆｆｉｃｉｅｎｔ ｌｅａｒｎｉｎｇ ｐｒｏｃｅｄｕｒｅ
会是人们研究的一个热点． ｆｏｒ ｄｅｅｐ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ．Ｎｅｕｒａｌ Ｃｏｍｐｕｔａｔｉｏｎ，２０１２，
２４（８）：１９６７－２００６
［１６］ Ｌｉｕ Ｊｉａｎ－Ｗｅｉ，Ｌｉｕ Ｙｕａｎ，Ｌｕｏ Ｘｉｏｎｇ－Ｌｉｎ．Ｒｅｓｅａｒｃｈ ａｎｄ
致 谢 感谢朱洪海博士关于金融数据的尝试！
ｄｅｖｅｌｏｐｍｅｎｔ ｏｎ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅ．Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ
Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ，２０１４，５１（１）：１－１６（ｉｎ Ｃｈｉｎｅｓｅ）
参 考 文 献 （刘建伟，刘媛，罗雄麟．波尔兹曼机研究进展．计算机研究
与发展，２０１４，５１（１）：１－１６）
［１］ ＭｃＣｕｌｌｏｃｈ Ｗ Ｓ，Ｐｉｔｔｓ Ｗ．Ａ ｌｏｇｉｃａｌ ｃａｌｃｕｌｕｓ ｏｆ ｔｈｅ ｉｄｅａｓ ［１７］ Ｖｉｎｃｅｎｔ Ｐ，Ｌａｒｏｃｈｅｌｌｅ Ｈ，Ｂｅｎｇｉｏ Ｙ，ｅｔ ａｌ．Ｅｘｔｒａｃｔｉｎｇ ａｎｄ
ｉｍｍａｎｅｎｔ ｉｎ ｎｅｒｖｏｕｓ ａｃｔｉｖｉｔｙ．Ｂｕｌｌｅｔｉｎ ｏｆ Ｍａｔｈｅｍａｔｉｃａｌ
ｃｏｍｐｏｓｉｎｇ ｒｏｂｕｓｔ ｆｅａｔｕｒｅｓ ｗｉｔｈ ｄｅｎｏｉｓｉｎｇ ａｕｔｏｅｎｃｏｄｅｒｓ／／
Ｂｉｏｐｈｙｓｉｃｓ，１９４３，５（４）：１１５－１３３ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２５ｔｈ ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ
Ｌｅａｒｎｉｎｇ．Ｈｅｌｓｉｎｋｉ，Ｆｉｎｌａｎｄ，２００８：１０９６－１１０３
［２］ Ｒｏｓｅｎｂｌａｔｔ Ｆ．Ｔｈｅ ｐｅｒｃｅｐｔｒｏｎ：Ａ ｐｒｏｂａｂｉｌｉｓｔｉｃ ｍｏｄｅｌ ｆｏｒ
［１８］ Ｖｉｎｃｅｎｔ Ｐ，Ｌａｒｏｃｈｅｌｌｅ Ｈ，Ｂｅｎｇｉｏ Ｙ，ｅｔ ａｌ．Ｓｔａｃｋｅｄ ｄｅｎｏｉｓｉｎｇ
ｉｎｆｏｒｍａｔｉｏｎ ｓｔｏｒａｇｅ ａｎｄ ｏｒｇａｎｉｚａｔｉｏｎ ｉｎ ｔｈｅ ｂｒａｉｎ．Ｐｓｙｃｈｏｌｏｇｉｃａｌ
Ｒｅｖｉｅｗ，１９５８，６５（６）：３８６－４０８
ａｕｔｏｅｎｃｏｄｅｒｓ：Ｌｅａｒｎｉｎｇ ｕｓｅｆｕｌ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｉｎ ａ ｄｅｅｐ
ｎｅｔｗｏｒｋ ｗｉｔｈ ａ ｌｏｃａｌ ｄｅｎｏｉｓｉｎｇ ｃｒｉｔｅｒｉｏｎ．Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ
［３］ Ｒｏｓｅｎｂｌａｔｔ Ｆ．Ｐｒｉｎｃｉｐｌｅｓ ｏｆ Ｎｅｕｒｏｄｉｎａｍｉｃｓ：Ｐｒｅｃｅｐｔｒｏｎ ａｎｄ
Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，２０１０，１１（１２）：３３７１－３４０８
Ｔｈｅｏｒｙ ｏｆ Ｂｒａｉｎ Ｍｅｃｈａｎｉｓｍｓ．Ｗａｓｈｉｎｇｔｏｎ，ＵＳＡ：Ｓｐａｒｔａｎ
Ｂｏｏｋｓ，１９６２ ［１９］ ＬｅＣｕｎ Ｙ，Ｂｏｔｔｏｕ Ｌ，Ｂｅｎｇｉｏ Ｙ，ｅｔ ａｌ．Ｇｒａｄｉｅｎｔ－ｂａｓｅｄ ｌｅａｒｎｉｎｇ
ａｐｐｌｉｅｄ ｔｏ ｄｏｃｕｍｅｎｔ ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ，
［４］ Ｒｕｍｅｌｈａｒｔ Ｄ Ｅ，Ｈｉｎｔｏｎ Ｇ，Ｗｉｌｌｉａｍｓ Ｒ Ｊ．Ｌｅａｒｎｉｎｇ ｒｅｐｒｅｓｅｎ－
１９９８，８６（１１）：２２７８－２３２４
ｔａｔｉｏｎｓ ｂｙ ｂａｃｋ－ｐｒｏｐａｇａｔｉｎｇ ｅｒｒｏｒｓ．Ｎａｔｕｒｅ，１９８６，３２３
（６０８８）：５３３－５３６ ［２０］ ＬｅＣｕｎ Ｙ，Ｂｏｓｅｒ Ｂ，Ｄｅｎｋｅｒ Ｊ Ｓ，ｅｔ ａｌ．Ｂａｃｋｐｒｏｐａｇａｔｉｏｎ
［５］ Ｃｏｒｔｅｓ Ｃ，Ｖａｐｎｉｋ Ｖ．Ｓｕｐｐｏｒｔ ｖｅｃｔｏｒ ｎｅｔｗｏｒｋｓ．Ｍａｃｈｉｎｅ ａｐｐｌｉｅｄ ｔｏ ｈａｎｄｗｒｉｔｔｅｎ ｚｉｐ ｃｏｄｅ ｒｅｃｏｇｎｉｔｉｏｎ．Ｎｅｕｒａｌ Ｃｏｍｐｕｔａｔｉｏｎ，
Ｌｅａｒｎｉｎｇ，１９９５，２０（３）：２７３－２９７
１９８９，１１（４）：５４１－５５１
［６］ Ｈｉｎｔｏｎ Ｇ，Ｓａｌａｋｈｕｔｄｉｎｏｖ Ｒ Ｒ．Ｒｅｄｕｃｉｎｇ ｔｈｅ ｄｉｍｅｎｓｉｏｎａｌｉｔｙ ［２１］ Ｄａｖｉｄ Ｓ，Ｈｕａｎｇ Ａ，Ｍａｄｄｉｄｏｎ Ｃ Ｊ．Ｍａｓｔｅｒｉｎｇ ｔｈｅ ｇａｍｅ ｏｆ
ｏｆ ｄａｔａ ｗｉｔｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．Ｓｃｉｅｎｃｅ，２００６，３１３（５７８６）： Ｇｏ ｗｉｔｈ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ａｎｄ ｔｒｅｅ ｓｅａｒｃｈ．Ｎａｔｕｒｅ，
２０１６，５２９（７５８７）：４８４－４８９
５０４－５０７
［７］ Ｙｕ Ｋａｉ，Ｊｉａ Ｌｅｉ，Ｃｈｅｎ Ｙｕ－Ｑｉａｎｇ，ｅｔ ａｌ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ： ［２２］ Ｌａｗｒｅｎｃｅ Ｓ，Ｇｉｌｅｓ Ｃ Ｌ，Ｔｓｏｉ Ａ Ｃ，ｅｔ ａｌ．Ｆａｃｅ ｒｅｃｏｇｎｉｔｉｏｎ：Ａ
Ｙｅｓｔｅｒｄａｙ，ｔｏｄａｙ，ａｎｄ ｔｏｍｏｒｒｏｗ．Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｒｅｓｅａｒｃｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ－ｎｅｔｗｏｒｋ ａｐｐｒｏａｃｈ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ
ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ，２０１３，５０（９）：１７９９－１８０４（ｉｎ Ｃｈｉｎｅｓｅ） ｏｎ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ，１９９７，８（１）：９８－１１３
（于凯，贾磊，陈宇强等．深度学习的昨天、今天和明天．计 ［２３］ Ｎｅｕｂａｕｅｒ Ｃ．Ｅｖａｌｕａｔｉｏｎ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ
算机研究与发展，２０１３，５０（９）：１７９９－１８０４） ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ，
［８］ Ｂｅｎｇｉｏ Ｙ，Ｌａｍｂｌｉｎ Ｐ，Ｐｏｐｏｖｉｃｉ Ｄ，ｅｔ ａｌ．Ｇｒｅｅｄｙ ｌａｙｅｒ－ｗｉｓｅ １９９８，９（４）：６８５－６９６
ｔｒａｉｎｉｎｇ ｏｆ ｄｅｅｐ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２００７Ａｄｖａｎｃｅｓ ［２４］ Ｋｒｉｚｈｅｖｓｋｙ Ａ，Ｓｕｔｓｋｅｖｅｒ ＩＩ，Ｈｉｎｔｏｎ Ｇ．Ｉｍａｇｅｎｅｔ ｃｌａｓｓｉｆｉｃａｔｉｏｎ
ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｖａｎｃｏｕｖｅｒ，Ｃａｎａｄａ， ｗｉｔｈ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
２００７：１５３－１６０ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｌａｋｅ
［９］ Ｒａｎｚａｔｏ Ｍ Ａ，Ｐｏｕｌｔｎｅｙ Ｃ，Ｃｈｏｐｒａ Ｓ，ｅｔ ａｌ．Ｅｆｆｉｃｉｅｎｔ ｌｅａｒｎｉｎｇ Ｔａｈｏｅ，ＵＳＡ，２０１２：１０９７－１１０５
ｏｆ ｓｐａｒｓｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｗｉｔｈ ａｎ ｅｎｅｒｇｙ－ｂａｓｅｄ ｍｏｄｅｌ／／ ［２５］ Ｎａｉｒ Ｖ，Ｈｉｎｔｏｎ Ｇ Ｅ，Ｆａｒａｂｅｔ Ｃ．Ｒｅｃｔｉｆｉｅｄ ｌｉｎｅａｒ ｕｎｉｔｓ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２００７Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ ｉｍｐｒｏｖｅ ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｖａｎｃｏｕｖｅｒ，Ｃａｎａｄａ，２００７：１１３７－１１４４ ２７ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｈａｉｆａ，
［１０］ Ｅｒｈａｎ Ｄ，Ｂｅｎｇｉｏ Ｙ，Ｃｏｕｒｖｉｌｌｅ Ａ，ｅｔ ａｌ．Ｗｈｙ ｄｏｅｓ ｕｎｓｕｐｅｒ－ Ｉｓｒａｅｌ，２０１０：８０７－８１４
ｖｉｓｅｄ ｐｒｅ－ｔｒａｉｎｉｎｇ ｈｅｌｐ ｄｅｅｐ ｌｅａｒｎｉｎｇ？Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ ［２６］ Ｈａｇａｎ Ｍ Ｔ，Ｄｅｍｕｔｈ Ｈ Ｂ，Ｂｅａｌｅ Ｍ Ｈ．Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ
Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，２０１０，１１（３）：６２５－６６０ Ｄｅｓｉｇｎ．Ｔｒａｎｓｌａｔｅｄ ｂｙ Ｄａｉ Ｋｕｉ，Ｂｅｉｊｉｎｇ：Ｃｈｉｎａ Ｍａｃｈｉｎｅ
［１１］ Ｌｅｃｕｎ Ｙ，Ｂｅｎｇｉｏ Ｙ，Ｈｉｎｔｏｎ Ｇ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ．Ｎａｔｕｒｅ， Ｐｒｅｓｓ，２００２（ｉｎ Ｃｈｉｎｅｓｅ）
２０１５，５２１（７５５３）：４３６－４４４ （Ｈａｇａｎ Ｍ Ｔ，Ｄｅｍｕｔｈ Ｈ Ｂ，Ｂｅａｌｅ Ｍ Ｈ．神经网络设计．戴
［１２］ Ｂｅｎｇｉｏ Ｙ．Ｌｅａｒｎｉｎｇ ｄｅｅｐ ａｒｃｈｉｔｅｃｔｕｒｅｓ ｆｏｒ ＡＩ．Ｆｏｕｎｄａｔｉｏｎｓ 葵，译．北京：机械工业出版社，２００２）
ａｎｄ Ｔｒｅｎｄｓ ｉｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ，２００９，２（１）：１－１２７ ［２７］ Ｋｉｒａｎｙａｚ Ｓ，Ｉｎｃｅ Ｔ，Ｇａｂｂｏｕｊ Ｍ．Ｒｅａｌ－ｔｉｍｅ ｐａｔｉｅｎｔ－ｓｐｅｃｉｆｉｃ
［１３］ Ｈｉｎｔｏｎ Ｇ，Ｏｓｉｎｄｅｒｏ Ｓ，Ｔｅｈ Ｙ－Ｗ．Ａ ｆａｓｔ ｌｅａｒｎｉｎｇ ａｌｇｏｒｉｔｈｍ ＥＣＧ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｂｙ １Ｄｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．
ｆｏｒ ｄｅｅｐ ｂｅｌｉｅｆ ｎｅｔｓ．Ｎｅｕｒａｌ Ｃｏｍｐｕｔａｔｉｏｎ，２００６，１８（７）： ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｂｉｏｍｅｄｉｃａｌ Ｅｎｇｉｎｅｅｒｉｎｇ，２０１６，６３（３）：
１５２７－１５５４ ６６４－６７５
［１４］ Ｓａｌａｋｈｕｔｄｉｎｏｖ Ｒ，Ｈｉｎｔｏｎ Ｇ．Ｄｅｅｐ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ． ［２８］ Ｈｕｂｅｌ Ｄ Ｈ，Ｗｉｅｓｅｌ Ｔ Ｎ．Ｒｅｃｅｐｔｉｖｅ ｆｉｅｌｄｓ ｂｉｎｏｃｕｌａｒ ｉｎｔｅｒａｃｔｉｏｎ，
Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ－Ｐｒｏｃｅｅｄｉｎｇｓ Ｔｒａｃｋ， ａｎｄ ｆｕｎｃｔｉｏｎａｌ ａｒｃｈｉｔｅｃｔｕｒｅ ｉｎ ｔｈｅ ｃａｔ’ｓ ｖｉｓｕａｌ ｃｏｒｔｅｘ．Ｊｏｕｒｎａｌ
２００９，９（１）：４４８－４５５ ｏｆ Ｐｈｙｓｉｏｌｏｇｙ，１９６２，１６０（１）：１０６－１５４ １２４８ 计 算 机 学 报 ２０１７年
［２９］ Ｆｕｋｕｓｈｉｍａ Ｋ．Ｎｅｏｃｏｇｎｉｔｒｏｎ：Ａ ｓｅｌｆ－ｏｒｇａｎｉｚｉｎｇ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ［４４］ Ｓｒｉｖａｓｔａｖａ Ｎ，Ｈｉｎｔｏｎ Ｇ，Ｋｒｉｚｈｅｖｓｋｙ Ａ，ｅｔ ａｌ．Ｄｒｏｐｏｕｔ：Ａ
ｍｏｄｅｌ ｆｏｒ ａ ｍｅｃｈａｎｉｓｍ ｏｆ ｐａｔｔｅｒｎ ｒｅｃｏｇｎｉｔｉｏｎ ｕｎａｆｆｅｃｔｅｄ ｂｙ ｓｉｍｐｌｅ ｗａｙ ｔｏ ｐｒｅｖｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｒｏｍ ｏｖｅｒｆｉｔｔｉｎｇ．
ｓｈｉｆｔ ｉｎ ｐｏｓｉｔｉｏｎ．Ｂｉｏｌｏｇｉｃａｌ Ｃｙｂｅｒｎｅｔｉｃｓ，１９８０，３６（４）：１９３－ Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，２０１４，１５（６）：１９２９－
２０２ １９５８
［３０］ Ｙｏｏ Ｈ－Ｊ．Ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｉｎ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ： ［４５］ Ｓａｉｎａｔｈａ Ｔ Ｎ，Ｋｉｎｇｓｂｕｒｙａ Ｂ，Ｓａｏｎａ Ｇ，ｅｔ ａｌ．Ｄｅｅｐ ｃｏｎｖｏｌｕ－
Ａ ｒｅｖｉｅｗ．ＩＥＩＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｓｍａｒｔ Ｐｒｏｃｅｓｓｉｎｇ ａｎｄ ｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｌａｒｇｅ－ｓｃａｌｅ ｓｐｅｅｃｈ ｔａｓｋｓ．Ｎｅｕｒａｌ
Ｃｏｍｐｕｔｉｎｇ，２０１５，４（１）：３５－４３ Ｎｅｔｗｏｒｋｓ，２０１５，６４（Ｓｐｅｃｉａｌ Ｉｓｓｕｅ）：３９－４８
［３１］ Ｇａｏ Ｌｉ－Ｇａｎｇ，Ｃｈｅｎ Ｐａｉ－Ｙｕ，Ｙｕ Ｓｈｉ－Ｍｅｎｇ．Ｄｅｍｏｎｓｔｒａｔｉｏｎ ｏｆ ［４６］ Ｃｈｕ Ｊ Ｌ，Ｋｒｚｙｚａｋ Ａ．Ａｎａｌｙｓｉｓ ｏｆ ｆｅａｔｕｒｅ ｍａｐｓ ｓｅｌｅｃｔｉｏｎ ｉｎ
ｃｏｎｖｏｌｕｔｉｏｎ ｋｅｒｎｅｌ ｏｐｅｒａｔｉｏｎ ｏｎ ｒｅｓｉｓｔｉｖｅ ｃｒｏｓｓ－ｐｏｉｎｔ ａｒｒａｙ． ｓｕｐｅｒｖｉｓｅｄ ｌｅａｒｎｉｎｇ ｕｓｉｎｇ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／
ＩＥＥＥ Ｅｌｅｃｔｒｏｎ Ｄｅｖｉｃｅ Ｌｅｔｔｅｒｓ，２０１６，３７（７）：８７０－８７３
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２７ｔｈ Ｃａｎａｄｉａｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ
［３２］Ｊｉｎ Ｌｉｎ－Ｐｅｎｇ．Ｓｔｕｄｙ ｏｎ Ａｐｐｒｏａｃｈ ｏｆ Ｅｌｅｃｔｒｏｃａｒｄｉｏｇｒａｍ
Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，２０１４：５９－７０
Ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｆｏｒ Ｃｌｉｎｉｃａｌ Ａｐｐｌｉｃａｔｉｏｎ［Ｐｈ．Ｄ．ｄｉｓｓｅｒｔａｔｉｏｎ］．
［４７］ Ｃａｏ Ｋ，Ｊａｉｎ Ａ Ｋ．Ｌａｔｅｎｔ ｏｒｉｅｎｔａｔｉｏｎ ｆｉｅｌｄ ｅｓｔｉｍａｔｉｏｎ ｖｉａ
Ｓｕｚｈｏｕ Ｉｎｓｔｉｔｕｔｅ ｏｆ Ｎａｎｏ－ｔｅｃｈ ａｎｄ Ｎａｎｏ－ｂｉｏｎｉｃｓ，Ｃｈｉｎｅｓｅ
ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１５Ｉｎｔｅｒ－
Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ，Ｓｕｚｈｏｕ，２０１６（ｉｎ Ｃｈｉｎｅｓｅ）
ｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｂｉｏｍｅｔｒｉｃｓ．Ｐｈｕｋｅｔ，Ｔｈａｉｌａｎｄ，２０１５：
（金林鹏．面向临床应用的心电图分类方法研究［博士学位论
３４９－３５６
文］．中国科学院苏州纳米技术与纳米仿生研究所，苏州，２０１６）
［４８］Ｊｉｎ Ｌｉｎ－Ｐｅｎｇ，Ｄｏｎｇ Ｊｕｎ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ｒｅｓｅａｒｃｈ ｏｎ ｃｌｉｎｉｃａｌ
［３３］ Ｘｕ Ｂｉｎｇ，Ｗａｎｇ Ｎａｉ－Ｙａｎ，Ｃｈｅｎ Ｔｉａｎ－Ｑｉ，ｅｔ ａｌ．Ｅｍｐｉｒｉｃａｌ
ｅｌｅｃｔｒｏｃａｒｄｉｏｇｒａｍ ａｎａｌｙｓｉｓ．Ｓｃｉｅｎｃｅ Ｃｈｉｎａ：Ｉｎｆｏｒｍａｔｉｏｎ
ｅｖａｌｕａｔｉｏｎ ｏｆ ｒｅｃｔｉｆｉｅｄ ａｃｔｉｖａｔｉｏｎｓ ｉｎ ｃｏｎｖｏｌｕｔｉｏｎ ｎｅｔｗｏｒｋ．
Ｓｃｉｅｎｃｅｓ，２０１５，４５（３）：３９８－４１６（ｉｎ Ｃｈｉｎｅｓｅ）
ａｒＸｉｖ：１５０５．００８５３ｖ２，２０１５
（金林鹏，董军．面向临床心电图分析的深层学习算法研究．
［３４］Ｊａｒｒｅｔｔ Ｋ，Ｋａｖｕｋｃｕｏｇｌｕ Ｋ，Ｍａｒｃ’Ａｕｒｅｌｉｏ Ｒａｎｚａｔｏ，ｅｔ ａｌ．
Ｗｈａｔ ｉｓ ｔｈｅ ｂｅｓｔ ｍｕｌｔｉ－ｓｔａｇｅ ａｒｃｈｉｔｅｃｔｕｒｅ ｆｏｒ ｏｂｊｅｃｔ ｒｅｃｏｇｎｉｔｉｏｎ？
中国科学：信息科学，２０１５，４５（３）：３９８－４１６）
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２００９ ＩＥＥＥ １２ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ［４９］ Ｈｕａｎｇ Ｊｕｉ－Ｔｉｎｇ，Ｌｉ Ｊｉｎ－Ｙｕ，Ｇｏｎｇ Ｙｉ－Ｆａｎ．Ａｎ ａｎａｌｙｓｉｓ ｏｆ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｋｙｏｔｏ，Ｊａｐａｎ，２００９：２１４６－ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｓｐｅｅｃｈ ｒｅｃｏｇｎｉｔｉｏｎ／／
２１５３ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｃｏｕｓｔｉｃｓ，
［３５］ Ｂｅｎｇｉｏ Ｙ，Ｃｏｕｒｖｉｌｌｅ Ａ，Ｖｉｎｃｅｎｔ Ｐ．Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ： Ｓｐｅｅｃｈ ａｎｄ Ｓｉｇｎａｌ Ｐｒｏｃｅｓｓｉｎｇ（ＩＣＡＳＳＰ）．Ｓｏｕｔｈ Ｂｒｉｓｂａｎｅ，
Ａ ｒｅｖｉｅｗ ａｎｄ ｎｅｗ ｐｅｒｓｐｅｃｔｉｖｅｓ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｐａｔｔｅｒｎ Ａｕｓｔｒａｌｉａ，２０１５：４９８９－４９９３
Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０１３，３５（８）：１７９８－１８２８ ［５０］ Ｌｉｎ Ｍｉｎ，Ｃｈｅｎ Ｑｉａｎｇ，Ｙａｎ Ｓｈｕｉ－Ｃｈｅｎｇ．Ｎｅｔｗｏｒｋ ｉｎ ｎｅｔｗｏｒｋ．
［３６］ Ｈｅ Ｋａｉ－Ｍｉｎｇ，Ｓｕｎ Ｊｉａｎ．Ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ａｔ ａｒＸｉｖ：１３１２．４４００ｖ３，２０１３
ｃｏｎｓｔｒａｉｎｅｄ ｔｉｍｅ ｃｏｓｔ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ［５１］ Ｘｕ Ｃｈｕｎ－Ｙａｎ，Ｌｕ Ｃａｎ－Ｙｉ，Ｌｉａｎｇ Ｘｉａｏ－Ｄａｎ，ｅｔ ａｌ．Ｍｕｌｔｉ－ｌｏｓｓ
ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ （ＣＶＰＲ）． ｒｅｇｕｌａｒｉｚｅｄ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｃｉｒｃｕｉｔｓ
Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：５３５３－５３６０ ａｎｄ Ｓｙｓｔｅｍｓ Ｆｏｒ Ｖｉｄｅｏ Ｔｅｃｈｎｏｌｏｇｙ，２０１５，２６（１２）：２２７３－
［３７］ Ｇｕ Ｊｉｕ－Ｘｉａｎｇ，Ｗａｎｇ Ｚｈｅｎ－Ｈｕａ，Ｊａｓｏｎ Ｋｕｅｎ，ｅｔ ａｌ．Ｒｅｃｅｎｔ ２２８３
ａｄｖａｎｃｅｓ ｉｎ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ：１５１２． ［５２］Ｊａｄｅｒｂｅｒｇ Ｍ，Ｓｉｍｏｎｙａｎ Ｋ，Ｚｉｓｓｅｒｍａｎ Ａ，ｅｔ ａｌ．Ｓｐａｔｉａｌ
０７１０８ｖ５，２０１７ ｔｒａｎｓｆｏｒｍｅｒ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ：１５０６．０２０２５ｖ３，２０１６
［３８］ Ｂｏｕｒｅａｕ Ｙ－Ｌ，Ｒｏｕｘ Ｎ Ｌ，Ｂａｃｈ Ｆ，ｅｔ ａｌ．Ａｓｋ ｔｈｅ ｌｏｃａｌｓ： ［５３］ Ｚｅｉｌｅｒ Ｍ Ｄ，Ｋｒｉｓｈｎａｎ Ｄ，Ｔａｙｌｏｒ Ｇ Ｗ，ｅｔ ａｌ．Ｄｅｃｏｎｖｏｌｕｔｉｏｎａｌ
Ｍｕｌｔｉ－ｗａｙ ｌｏｃａｌ ｐｏｏｌｉｎｇ ｆｏｒ ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ
ｏｆ ｔｈｅ ２０１１Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．
Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１０：
Ｂａｒｃｅｌｏｎａ，Ｓｐａｉｎ，２０１１：２６５１－２６５８
２５２８－２５３５
［３９］ Ｚｅｉｌｅｒ Ｍ Ｄ，Ｆｅｒｇｕｓ Ｒ．Ｓｔｏｃｈａｓｔｉｃ ｐｏｏｌｉｎｇ ｆｏｒ ｒｅｇｕｌａｒｉｚａｔｉｏｎ
［５４］ Ｚｅｉｌｅｒ Ｍ Ｄ．Ｖｉｓｕａｌｉｚｉｎｇ ａｎｄ ｕｎｄｅｒｓｔａｎｄｉｎｇ ｃｏｎｖｏｌｕｔｉｏｎａｌ
ｏｆ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ：１３０１．３５５７ｖ１，
ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １３ｔｈ Ｅｕｒｏｐｅａｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
２０１３
Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ（ＥＣＣＶ）．Ｚｕｒｉｃｈ，Ｓｗｉｔｚｅｒｌａｎｄ，２０１４：８１８－
［４０］ Ｂｏｕｒｅａｕ Ｙ－Ｌ，Ｐｏｎｃｅ Ｊ，ＬｅＣｕｎ Ｙ．Ａ ｔｈｅｏｒｅｔｉｃａｌ ａｎａｌｙｓｉｓ ｏｆ
８３３
ｆｅａｔｕｒｅ ｐｏｏｌｉｎｇ ｉｎ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ．Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ
［５５］ Ｚｈａｏ Ｊｕｎ－Ｂｏ，Ｍａｔｈｉｅｕ Ｍ，Ｇｏｒｏｓｈｉｎ Ｒ，ｅｔ ａｌ．Ｓｔａｃｋｅｄ ｗｈａｔ－
ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ，２０１０，３２（４）：１１１－１１８
ｗｈｅｒｅ ａｕｔｏ－ｅｎｃｏｄｅｒｓ．ａｒＸｉｖ：１５０６．０２３５１ｖ８，２０１６
［４１］ Ｂｏｕｒｅａｕ Ｙ－Ｌ，Ｂａｃｈ Ｆ，ＬｅＣｕｎ Ｙ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ ｍｉｄ－ｌｅｖｅｌ
ｆｅａｔｕｒｅｓ ｆｏｒ ｒｅｃｏｇｎｉｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ
［５６］Ｊｉａｎｇ Ｚｏｎｇ－Ｌｉ．Ｉｎｔｒｏｄｕｃｔｉｏｎ ｔｏ Ａｒｉｔｉｆｉｃｉａｌ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ．
ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ， Ｂｅｉｊｉｎｇ：Ｈｉｇｈｅｒ Ｅｄｕｃａｔｉｏｎ Ｐｒｅｓｓ，２００１（ｉｎ Ｃｈｉｎｅｓｅ）
ＵＳＡ，２０１０：２５５９－２５６６
（蒋宗礼．人工神经网络导论．北京：高等教育出版社，
［４２］ Ｓａｉｎａｔｈ Ｔ Ｎ，Ｍｏｈａｍｅｄ Ａ，Ｋｉｎｇｓｂｕｒｙ Ｂ，ｅｔ ａｌ．Ｄｅｅｐ ｃｏｎｖｏ－
２００１）
ｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ＬＶＣＳＲ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ［５７］ Ｆａｕｓｅｔｔ Ｌ．Ｆｕｎｄａｍｅｎｔａｌｓ ｏｆ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ：Ａｒｃｈｉｔｅｃｔｕｒｅｓ，
ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｃｏｕｓｔｉｃｓ，Ｓｐｅｅｃｈ ａｎｄ Ａｌｇｏｒｉｔｈｍｓ，ａｎｄ Ａｐｐｌｉｃａｔｉｏｎｓ．Ｌｏｎｄｏｎ：Ｐｒｅｎｔｉｃｅ－Ｈａｌｌ，１９９４
Ｓｉｇｎａｌ Ｐｒｏｃｅｓｓｉｎｇ．Ｖａｎｃｏｕｖｅｒ，Ｃａｎａｄａ，２０１３：８６１４－８６１８ ［５８］ Ｎｇｉａｍ Ｊ，Ｋｏｈ Ｐ Ｗ，Ｃｈｅｎ Ｚ，ｅｔ ａｌ．Ｓｐａｒｓｅ ｆｉｌｔｅｒｉｎｇ／／
［４３］ Ｏ’Ｓｈｅａ Ｋ，Ｎａｓｈ Ｒ．Ａｎ ｉｎｔｒｏｄｕｃｔｉｏｎ ｔｏ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ
ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ：１５１１．０８４５８ｖ２，２０１５ Ｓｙｓｔｅｍｓ ２４（ＮＩＰＳ ２０１１）．Ｇｒａｎａｄａ，Ｓｐａｉｎ，２０１１：１１２５－１１３３ ６期 周飞燕等：卷积神经网络研究综述 １２４９
［５９］ Ｄｏｎｇ Ｚｈｅｎ，Ｐｅｉ Ｍｉｎｇ－Ｔａｏ，Ｈｅ Ｙａｎｇ，ｅｔ ａｌ．Ｖｅｈｉｃｌｅ ｔｙｐｅ ［７４］ Ｓｕｎ Ｙｉ，Ｃｈｅｎ Ｙｕ－Ｈｅｎｇ，Ｗａｎｇ Ｘｉａｏ－Ｇａｎｇ，ｅｔ ａｌ．Ｄｅｅｐ
ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｕｓｉｎｇ ｕｎｓｕｐｅｒｖｉｓｅｄ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ／／ ｌｅａｒｎｉｎｇ ｆａｃｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｂｙ ｊｏｉｎｔ ｉｄｅｎｔｉｆｉｃａｔｉｏｎ－ｖｅｒｉｆｉｃａｔｉｏｎ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２２ｎｄ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｐａｔｔｅｒｎ ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｓｔｏｃｋｈｏｌｍ，Ｓｗｅｄｅｎ，２０１４：１７２－１７７ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，２０１４：１９８８－１９９６
［６０］ Ｄｏｎｇ Ｚｈｅｎ，Ｗｕ Ｙｕ－Ｗｅｉ，Ｐｅｉ Ｍｉｎｇ－Ｔａｏ，ｅｔ ａｌ．Ｖｅｈｉｃｌｅ ｔｙｐｅ ［７５］ Ｓｕｎ Ｙｉ，Ｗａｎｇ Ｘｉａｏ－Ｇａｎｇ，Ｔａｎｇ Ｘｉａｏ－Ｏｕ．Ｄｅｅｐｌｙ ｌｅａｒｎｅｄ
ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｕｓｉｎｇ ａ ｓｅｍｉｓｕｐｅｒｖｉｓｅｄ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｆａｃｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ａｒｅ ｓｐａｒｓｅ，ｓｅｌｅｃｔｉｖｅ，ａｎｄ Ｒｏｂｕｓｔ／／
ｎｅｔｗｏｒｋ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｉｎｔｅｌｌｉｇｅｎｔ Ｔｒａｎｓｐｏｒｔａｔｉｏｎ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ
Ｓｙｓｔｅｍｓ，２０１５，１６（４）：２２４７－２２５６ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ（ＣＶＰＲ）．Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：２８９２－
［６１］Ｊｉｎ Ｌｉｎ－Ｐｅｎｇ，Ｄｏｎｇ Ｊｕｎ．Ｅｎｓｅｍｂｌｅ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆｏｒ ｂｉｏｍｅｄｉｃａｌ ２９００
ｔｉｍｅ ｓｅｒｉｅｓ ｃｌａｓｓｉｆｉｃａｔｉｏｎ．Ｃｏｍｐｕｔａｔｉｏｎａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ ａｎｄ ［７６］ Ｓｕｎ Ｙｉ，Ｌｉａｎｇ Ｄｉｎｇ，Ｗａｎｇ Ｘｉａｏ－Ｇａｎｇ，ｅｔ ａｌ．ＤｅｅｐＩＤ３：Ｆａｃｅ
Ｎｅｕｒｏｓｃｉｅｎｃｅ，２０１６，２０１６（３）：１－１３ ｒｅｃｏｇｎｉｔｉｏｎ ｗｉｔｈ ｖｅｒｙ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ：１５０２．
［６２］Ｊｉａ Ｙａｎｇ－Ｑｉｎｇ，Ｓｈｅｌｈａｍｅｒ Ｅ，Ｄｏｎａｈｕｅ Ｊ，ｅｔ ａｌ．Ｃａｆｆｅ：Ｃｏｎｖｏｌｕ－ ００８７３ｖ１，２０１５
ｔｉｏｎａｌ ａｒｃｈｉｔｅｃｔｕｒｅ ｆｏｒ ｆａｓｔ ｆｅａｔｕｒｅ ｅｍｂｅｄｄｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ［７７］ Ｓｃｈｒｏｆｆ Ｆ，Ｋａｌｅｎｉｃｈｅｎｋｏ Ｄ，Ｐｈｉｌｂｉｎ Ｊ．ＦａｃｅＮｅｔ：Ａ ｕｎｉｆｉｅｄ
ｔｈｅ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍｕｌｔｉｍｅｄｉａ．Ｏｒｌａｎｄｏ， ｅｍｂｅｄｄｉｎｇ ｆｏｒ ｆａｃｅ ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｃｌｕｓｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ＵＳＡ，２０１４：６７５－６７８ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
［６３］ Ａｌ－Ｒｆｏｕ Ｒ，Ａｌａｉｎ Ｇ，Ａｌｍａｈａｉｒｉ Ａ，ｅｔ ａｌ．Ｔｈｅａｎｏ：Ａ ｐｙｔｈｏｎ
Ｒｅｃｏｇｎｉｔｉｏｎ（ＣＶＰＲ）．Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：８１５－８２３
ｆｒａｍｅｗｏｒｋ ｆｏｒ ｆａｓｔ ｃｏｍｐｕｔａｔｉｏｎ ｏｆ ｍａｔｈｅｍａｔｉｃａｌ ｅｘｐｒｅｓｓｉｏｎｓ．
［７８］ Ｐａｒｋｈｉ Ｏ Ｍ，Ｖｅｄａｌｄｉ Ａ，Ｚｉｓｓｅｒｍａｎ Ａ．Ｄｅｅｐ ｆａｃｅ ｒｅｃｏｇｎｉｔｉｏｎ
ａｒＸｉｖ：１６０５．０２６８８ｖ１，２０１６ ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｂｒｉｔｉｓｈ Ｍａｃｈｉｎｅ Ｖｉｓｉｏｎ Ｃｏｎｆｅｒｅｎｃｅ
［６４］ Ｂａｈｒａｍｐｏｕｒ Ｓ，Ｒａｍａｋｒｉｓｈｎａｎ Ｎ，Ｓｃｈｏｔｔ Ｌ，ｅｔ ａｌ．Ｃｏｍｐａｒａ－
（ＢＭＶＣ ２０１５）．Ｓｗａｎｓｅａ，Ｅｎｇｌａｎｄ，２０１５：１－１２
ｔｉｖｅ ｓｔｕｄｙ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｓｏｆｔｗａｒｅ ｆｒａｍｅｗｏｒｋｓ．ａｒＸｉｖ： ［７９］ Ｃｈａｎｇ Ｌｉａｎｇ，Ｄｅｎｇ Ｘｉａｏ－Ｍｉｎｇ，Ｚｈｏｕ Ｍｉｎｇ－Ｑｕａｎ，ｅｔ ａｌ．
１５１１．０６４３５ｖ３，２０１６ Ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｉｎ ｉｍａｇｅ ｕｎｄｅｒｓｔａｎｄｉｎｇ．Ａｃｔａ
Ａｕｔｏｍａｔｉｃａ Ｓｉｎｉｃａ，２０１６，４２（９）：１３００－１３１２（ｉｎ Ｃｈｉｎｅｓｅ）
［６５］ Ｓｚｅｇｅｄｙ Ｃ，Ｌｉｕ Ｗｅｉ，Ｊｉａ Ｙａｎｇ－Ｑｉｎｇ，ｅｔ ａｌ．Ｇｏｉｎｇ ｄｅｅｐｅｒ
（常亮，邓小明，周明全等．图像理解中的卷积神经网络．自
ｗｉｔｈ ｃｏｎｖｏｌｕｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
动化学报，２０１６，４２（９）：１３００－１３１２）
Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ（ＣＶＰＲ）．Ｂｏｓｔｏｎ，
［８０］ Ａｂｄｅｌ－Ｈａｍｉｄ Ｏｓｓａｍａ，Ｍｏｈａｍｅｄ Ａｂｄｅｌ－ｒａｈｍａｎ，Ｊｉａｎｇ Ｈｕｉ，
ＵＳＡ，２０１５：１－９
ｅｔ ａｌ．Ａｐｐｌｙｉｎｇ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｃｏｎｃｅｐｔｓ ｔｏ
［６６］ Ｓｉｍｏｎｙａｎ Ｋ，Ｚｉｓｓｅｒｍａｎ Ａ．Ｖｅｒｙ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ
ｈｙｂｒｉｄ ＮＮ－ＨＭＭ ｍｏｄｅｌ ｆｏｒ ｓｐｅｅｃｈ ｒｅｃｏｇｎｉｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｆｏｒ ｌａｒｇｅ－ｓｃａｌｅ ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ．ａｒＸｉｖ：１４０９．１５５６ｖ６，２０１４
ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｃｏｕｓｔｉｃｓ，Ｓｐｅｅｃｈ
［６７］ Ｈｅ Ｋａｉ－Ｍｉｎｇ，Ｚｈａｎｇ Ｘｉａｎｇ－Ｙｕ，Ｒｅｎ Ｓｈａｏ－Ｑｉｎｇ，ｅｔ ａｌ．
ａｎｄ Ｓｉｇｎａｌ Ｐｒｏｃｅｓｓｉｎｇ （ＩＣＡＳＳＰ）．Ｋｙｏｔｏ，Ｊａｐａｎ，２０１２：
Ｓｐａｔｉａｌ ｐｙｒａｍｉｄ ｐｏｏｌｉｎｇ ｉｎ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ
４２７７－４２８０
ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ
［８１］ Ａｂｄｅｌ－Ｈａｍｉｄ Ｏｓｓａｍａ，Ｍｏｈａｍｅｄ Ａｂｄｅｌ－ｒａｈｍａｎ，Ｊｉａｎｇ Ｈｕｉ，
ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０１５，３７（９）：１９０４－１９１５
ｅｔ ａｌ．Ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｓｐｅｅｃｈ ｒｅｃｏｇｎｉｔｉｏｎ．
［６８］Ｉｏｆｆｅ Ｓ，Ｓｚｅｇｅｄｙ Ｃ．Ｂａｔｃｈ ｎｏｒｍａｌｉｚａｔｉｏｎ：Ａｃｃｅｌｅｒａｔｉｎｇ ｄｅｅｐ
ＩＥＥＥ／ＡＣＭ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ａｕｄｉｏ，Ｓｐｅｅｃｈ，ａｎｄ Ｌａｎｇｕａｇｅ
ｎｅｔｗｏｒｋ ｔｒａｉｎｉｎｇ ｂｙ ｒｅｄｕｃｉｎｇ ｉｎｔｅｒｎａｌ ｃｏｖａｒｉａｔｅ ｓｈｉｆｔ．ａｒＸｉｖ：
Ｐｒｏｃｅｓｓｉｎｇ，２０１４，２２（１０）：１５３３－１５４５
１５０２．０３１６７，２０１５
［８２］ Ｔｈｏｍａｓ Ｓ，Ｇａｎａｐａｔｈｙ Ｓ，Ｓａｏｎ Ｇ，ｅｔ ａｌ．Ａｎａｌｙｚｉｎｇ ｃｏｎｖｏｌｕ－
［６９］ Ｈｅ Ｋａｉ－Ｍｉｎｇ，Ｚｈａｎｇ Ｘｉａｎｇ－Ｙｕ，Ｒｅｎ Ｓｈａｏ－Ｑｉｎｇ，ｅｔ ａｌ．Ｄｅｅｐ
ｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｓｐｅｅｃｈ ａｃｔｉｖｉｔｙ ｄｅｔｅｃｔｉｏｎ ｉｎ
ｒｅｓｉｄｕａｌ ｌｅａｒｎｉｎｇ ｆｏｒ ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｍｉｓｍａｔｃｈｅｄ ａｃｏｕｓｔｉｃ ｃｏｎｄｉｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ
ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｃｏｕｓｔｉｃｓ，Ｓｐｅｅｃｈ ａｎｄ Ｓｉｇｎａｌ
Ｌａｓ Ｖｅｇａｓ，ＵＳＡ，２０１６：７７０－７７８
Ｐｒｏｃｅｓｓｉｎｇ（ＩＣＡＳＳＰ）．Ｆｌｏｒｅｎｃｅ，Ｉｔａｌｙ，２０１４：２５１９－２５２３
［７０］ Ｗａｎｇ Ｘｉａｏ－Ｇａｎｇ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ｉｎ ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ． ［８３］ Ｈｉｎｔｏｎ Ｇ，Ｄｅｎｇ Ｌｉ，Ｙｕ Ｄｏｎｇ，ｅｔ ａｌ．Ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ
Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ ｏｆ ｔｈｅ ＣＣＦ，２０１５，１１（８）：１５－２３（ｉｎ Ｃｈｉｎｅｓｅ） ｆｏｒ ａｃｏｕｓｔｉｃ ｍｏｄｅｌｉｎｇ ｉｎ ｓｐｅｅｃｈ ｒｅｃｏｇｎｉｔｉｏｎ：Ｔｈｅ ｓｈａｒｅｄ ｖｉｅｗｓ
（王晓刚．图像识别中的深度学习．中国计算机学会通讯，
ｏｆ ｆｏｕｒ ｒｅｓｅａｒｃｈ ｇｒｏｕｐｓ．ＩＥＥＥ Ｓｉｇｎａｌ Ｐｒｏｃｅｓｓｉｎｇ Ｍａｇａｚｉｎｅ，
２０１５，１１（８）：１５－２３）
２０１２，２９（６）：８２－９７
［７１］ Ｍｉｓｈｋｉｎ Ｄ，Ｓｅｒｇｉｅｖｓｋｉｙ Ｎ，Ｍａｔａｓ Ｊ．Ｓｙｓｔｅｍａｔｉｃ ｅｖａｌｕａｔｉｏｎ ｏｆ ［８４］ Ｈｕａｎｇ Ｊｕｉ－Ｔｉｎｇ，Ｌｉ Ｊｉｎ－Ｙｕ，Ｇｏｎｇ Ｙｉ－Ｆａｎ．Ａｎ ａｎａｌｙｓｉｓ ｏｆ
ＣＮＮ ａｄｖａｎｃｅｓ ｏｎ ｔｈｅ ｉｍａｇｅＮｅｔ．ａｒＸｉｖ：１６０６．０２２２８ｖ２，２０１６ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｓｐｅｅｃｈ ｒｅｃｏｇｎｉｔｉｏｎ／／
［７２］ Ｔａｉｇｍａｎ Ｙ，Ｙａｎｇ Ｍ，Ｒａｎｚａｔｏ Ｍ Ａ，ｅｔ ａｌ．ＤｅｅｐＦａｃｅ：Ｃｌｏｓｉｎｇ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｃｏｕｓｔｉｃｓ，
ｔｈｅ ｇａｐ ｔｏ ｈｕｍａｎ－ｌｅｖｅｌ ｐｅｒｆｏｒｍａｎｃｅ ｉｎ ｆａｃｅ ｖｅｒｉｆｉｃａｔｉｏｎ／／ Ｓｐｅｅｃｈ ａｎｄ Ｓｉｇｎａｌ Ｐｒｏｃｅｓｓｉｎｇ（ＩＣＡＳＳＰ）．Ｂｒｉｓｂａｎｅ，Ａｕｓｔｒａｌｉａ，
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ ２０１５：４９８９－４９９３
Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ （ＣＶＰＲ）．Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４： ［８５］ Ｄｏｎｇ Ｊｕｎ，Ｚｈａｎｇ Ｊｉａ－Ｗｅｉ，Ｚｈｕ Ｈｏｎｇ－Ｈａｉ，ｅｔ ａｌ．Ｗｅａｒａｂｌｅ
１７０１－１７０８ ＥＣＧ ｍｏｎｉｔｏｒｓ ａｎｄ ｉｔｓ ｒｅｍｏｔｅ ｄｉａｇｎｏｓｉｓ ｓｅｒｖｉｃｅ ｐｌａｔｆｏｒｍ．
［７３］ Ｓｕｎ Ｙｉ，Ｗａｎｇ Ｘｉａｏ－Ｇａｎｇ，Ｔａｎｇ Ｘｉａｏ－Ｏｕ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆａｃｅ ＩＥＥＥ Ｉｎｔｅｌｌｉｇｅｎｔ Ｓｙｓｔｅｍｓ，２０１２，２７（６）：３６－４３
ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｆｒｏｍ ｐｒｅｄｉｃｔｉｎｇ １００００ｃｌａｓｓｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ［８６］ Ｋａｄｉ Ｉ，Ｉｄｒｉ Ａ，Ｆｅｒｎａｎｄｅｚ－Ａｌｅｍａｎ Ｊ Ｌ．Ｋｎｏｗｌｅｄｇｅ ｄｉｓｃｏｖｅｒｙ
ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇ－ ｉｎ ｃａｒｄｉｏｌｏｇｙ：Ａ ｓｙｓｔｅｍａｔｉｃ ｌｉｔｅｒａｔｕｒｅ ｒｅｖｉｅｗ．Ｉｎｔｅｒｎａｔｉｏｎａｌ
ｎｉｔｉｏｎ．Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４：１８９１－１８９８ Ｊｏｕｒｎａｌ ｏｆ Ｍｅｄｉｃａｌ Ｉｎｆｏｒｍａｔｉｃｓ，２０１７，９７：１２－３２ １２５０ 计 算 机 学 报 ２０１７年
［８７］ Ｚｈｕ Ｈｏｎｇ－Ｈａｉ．Ｋｅｙ Ａｌｇｏｒｉｔｈｍｓ ｏｎ Ｃｏｍｐｕｔｅｒ－Ａｉｄｅｄ Ｅｌｅｃｔｒｏ－ ［９７］ Ｃｕｉ Ｚｈｉ－Ｃｈｅｎｇ，Ｃｈｅｎ Ｗｅｎ－Ｌｉｎ，Ｃｈｅｎ Ｙｉ－Ｘｉｎ．Ｍｕｌｔｉ－ｓｃａｌｅ
ｃａｒｄｉｏｇｒａｍ Ａｎａｌｙｓｉｓ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ Ｒｅｍｏｔｅ Ｍｕｌｔｉ－Ｓｉｇｎｓ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｔｉｍｅ ｓｅｒｉｅｓ ｃｌａｓｓｉｆｉｃａｔｉｏｎ．
Ｍｏｎｉｔｏｒｉｎｇ Ｓｙｓｔｅｍ［Ｐｈ．Ｄ．ｄｉｓｓｅｒｔａｔｉｏｎ］．Ｓｕｚｈｏｕ Ｉｎｓｔｉｔｕｔｅ ｏｆ ａｒＸｉｖ：１６０３．０６９９５，２０１６
Ｎａｎｏ－ｔｅｃｈ ａｎｄ Ｎａｎｏ－ｂｉｏｎｉｃｓ，Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ， ［９８］ Ｚｈｅｎｇ Ｙｉ，Ｌｉｕ Ｑｉ，Ｃｈｅｎ Ｅｎ－Ｈｏｎｇ，ｅｔ ａｌ．Ｃｏｎｖｏｌｕｔｉｏｎａｌ
Ｓｕｚｈｏｕ，２０１３（ｉｎ Ｃｈｉｎｅｓｅ） ｎｏｎｌｉｎｅａｒ ｎｅｉｇｈｂｏｕｒｈｏｏｄ ｃｏｍｐｏｎｅｎｔｓ ａｎａｌｙｓｉｓ ｆｏｒ ｔｉｍｅ ｓｅｒｉｅｓ
（朱洪海．心电图自动识别的关键算法及多体征监护系统研 ｃｌａｓｓｉｆｉｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １９ｔｈ Ｐａｃｉｆｉｃ－Ａｓｉａ Ｃｏｎｆｅｒｅｎｃｅ
制［博士学位论文］．中国科学院苏州纳米技术与纳米仿生研 ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｈｏ Ｃｈｉ Ｍｉｎｈ，
究所，苏州，２０１３） Ｖｉｅｔｎａｍ，２０１５：５３４－５４６
［８８］ Ｚｈａｎｇ Ｊｉａ－Ｗｅｉ，Ｌｉｕ Ｘｉａ，Ｄｏｎｇ Ｊｕｎ．ＣＣＤＤ：Ａｎ ｅｎｈａｎｃｅｄ ［９９］ Ｒｅｄｍｏｎ Ｊ，Ｄｉｖｖａｌａ Ｓ，Ｇｉｒｓｈｉｃｋ Ｒ，ｅｔ ａｌ．Ｙｏｕ ｏｎｌｙ ｌｏｏｋ ｏｎｃｅ：
ｓｔａｎｄａｒｄ ＥＣＧ ｄａｔａｂａｓｅ ｗｉｔｈ ｉｔｓ ｍａｎａｇｅｍｅｎｔ ａｎｄ ａｎｎｏｔａｔｉｏｎ Ｕｎｉｆｉｅｄ，ｒｅａｌ－ｔｉｍｅ ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ．ａｒＸｉｖ：１５０６．０２６４０ｖ５，
ｔｏｏｌｓ．Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｕｒｎａｌ ｏｎ Ａｒｔｉｃｌｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ Ｔｏｏｌｓ， ２０１５
２０１２，２１（５）：１－２６ ［１００］ Ｒｅｎ Ｓｈａｏ－Ｑｉｎｇ，Ｈｅ Ｋａｉ－Ｍｉｎｇ，Ｇｉｒｓｈｉｃｋ Ｒ，ｅｔ ａｌ．Ｆａｓｔｅｒ
［８９］ Ｆａｙｙａｚ－ｕｌ－Ａｆｓａｒ Ａｍｉｒ Ｍｉｎｈａｓ，Ｍｕｈａｍｍａｄ Ａｒｉｆ．Ｒｏｂｕｓｔ Ｒ－ＣＮＮ：Ｔｏｗａｒｄｓ ｒｅａｌ－ｔｉｍｅ ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ ｗｉｔｈ ｒｅｇｉｏｎ ｐｒｏｐｏｓａｌ
ｅｌｅｃｔｒｏｃａｒｄｉｏｇｒａｍ ｂｅａｔ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｕｓｉｎｇ ｄｉｓｃｒｅｔｅ ｗａｖｅｌｅｔ ｎｅｔｗｏｒｋｓ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ ａｎｄ
ｔｒａｎｓｆｏｒｍ．Ｐｈｙｓｉｏｌｏｇｉｃａｌ Ｍｅａｓｕｒｅｍｅｎｔ，２００８，２９（５）：５５５－ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０１６，ｄｏｉ：１０．１１０９／ＴＰＡＭＩ．２０１６．
５７０ ２５７７０３１
［９０］ Ｍａｒｔｉｓ Ｒ Ｊ，Ｃｈａｋｒａｂｏｒｔｙ Ｃ，Ｒａｙ Ａ Ｋ．Ａ ｔｗｏ－ｓｔａｇｅ ｍｅｃｈａ－ ［１０１］ Ｇｉｒｓｈｉｃｋ Ｒ．Ｆａｓｔ Ｒ－ＣＮＮ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１５ＩＥＥＥ
ｎｉｓｍ ｆｏｒ ｒｅｇｉｓｔｒａｔｉｏｎ ａｎｄ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｏｆ ＥＣＧ ｕｓｉｎｇ Ｇａｕｓｓｉａｎ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｓａｎｔｉａｇｏ，
ｍｉｘｔｕｒｅ ｍｏｄｅｌ．Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ，２００９，４２（１１）：２９７９－ Ｃｈｉｌｅ，２０１５：１４４０－１４４８
２９８８ ［１０２］ Ｌｉｕ Ｗｅｉ，Ａｎｇｕｅｌｏｖ Ｄ，Ｅｒｈａｎ Ｄ，ｅｔ ａｌ．ＳＳＤ：Ｓｉｎｇｌｅ ｓｈｏｔ
［９１］ Ｈａｋａｃｏｖａ Ｎ，Ｔｒａｇａｒｄｈ－Ｊｏｈａｎｓｓｏｎ Ｅ，Ｗａｇｎｅｒ Ｇ Ｓ，ｅｔ ａｌ． ｍｕｌｔｉｂｏｘ ｄｅｔｅｃｔｏｒ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １４ｔｈ Ｅｕｒｏｐｅａｎ
Ｃｏｍｐｕｔｅｒ－ｂａｓｅｄ ｒｈｙｔｈｍ ｄｉａｇｎｏｓｉｓ ａｎｄ ｉｔｓ ｐｏｓｓｉｂｌｅ ｉｎｆｌｕｅｎｃｅ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ａｍｓｔｅｒｄａｍ，Ｎｅｔｈｅｒｌａｎｄｓ，
ｏｎ ｎｏｎｅｘｐｅｒｔ ｅｌｅｃｔｒｏｃａｒｄｉｏｇｒａｍ ｒｅａｄｅｒｓ．Ｊｏｕｒｎａｌ ｏｆ Ｅｌｅｃｔｒｏ－ ２０１６：２１－３７
ｃａｒｄｉｏｌｏｇｙ，２０１２，４５（１）：１８－２２ ［１０３］ Ｘｕ Ｊｉａ－Ｍｉｎｇ，Ｗａｎｇ Ｐｅｎｇ，Ｔｉａｎ Ｇｕａｎ－Ｈｕａ，ｅｔ ａｌ．Ｓｈｏｒｔ ｔｅｘｔ
［９２］ Ｖｏｇｌ Ｔ Ｐ，Ｍａｎｇｉｓ Ｊ Ｋ，Ｒｉｇｌｅｒ Ａ Ｋ，ｅｔ ａｌ．Ａｃｃｅｌｅｒａｔｉｎｇ ｔｈｅ ｃｌｕｓｔｅｒｉｎｇ ｖｉａ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
ｃｏｎｖｅｒｇｅｎｃｅ ｏｆ ｔｈｅ ｂａｃｋ－ｐｒｏｐａｇａｔｉｏｎ ｍｅｔｈｏｄ．Ｂｉｏｌｏｇｉｃａｌ ｔｈｅ ＮＡＡＣＬ－ＨＬＴ ２０１５．Ｄｅｎｖｅｒ，ＵＳＡ，２０１５：６２－６９
Ｃｙｂｅｒｎｅｔｉｃｓ，１９８８，５９（４）：２５７－２６３ ［１０４］ Ｇａｏ Ｊｕｎ－Ｙｕ，Ｙａｎｇ Ｘｉａｏ－Ｓｈａｎ，Ｚｈａｎｇ Ｔｉａｎ－Ｚｈｕ，ｅｔ ａｌ．
［９３］ Ｗａｎｇ Ｌｉ－Ｐｉｎｇ．Ｓｔｕｄｙ ｏｎ Ａｐｐｒｏａｃｈ ｏｆ ＥＣＧ Ｃｌａｓｓｉｆｉｃａｔｉｏｎ Ｒｏｂｕｓｔ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ ｍｅｔｈｏｄ ｖｉａ ｄｅｅｐ ｌｅａｒｎｉｎｇ．Ｃｈｉｎｅｓｅ
ｗｉｔｈ Ｄｏｍａｉｎ Ｋｎｏｗｌｅｄｇｅ［Ｐｈ．Ｄ．ｄｉｓｓｅｒｔａｔｉｏｎ］．Ｅａｓｔ Ｃｈｉｎａ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１６，３９（７）：１４１９－１４３４（ｉｎ Ｃｈｉｎｅｓｅ）
Ｎｏｒｍａｌ Ｕｎｉｖｅｒｓｉｔｙ，Ｓｈａｎｇｈａｉ，２０１２（ｉｎ Ｃｈｉｎｅｓｅ） （高君宇，杨小汕，张天柱等．基于深度学习的鲁棒性视觉跟
（王丽苹．融合领域知识的心电图分类方法研究［博士学位论 踪方法．计算机学报，２０１６，３９（７）：１４１９－１４３２）
文］．华东师范大学，上海，２０１２） ［１０５］ Ｌｉ Ｈｏｎｇ，Ｌｉｕ Ｆａｎｇ，Ｙａｎｇ Ｓｈｕ－Ｙｕａｎ，ｅｔ ａｌ．Ｒｅｍｏｔｅ ｓｅｎｓｉｎｇ
［９４］ Ｚｈｏｕ Ｆｅｉ－Ｙａｎ，Ｊｉｎ Ｌｉｎ－Ｐｅｎｇ，Ｄｏｎｇ Ｊｕｎ．ＰＶＣ ｒｅｃｏｇｎｉｔｉｏｎ ｉｍａｇｅ ｆｕｓｉｏｎ ｂａｓｅｄ ｏｎ ｄｅｅｐ ｓｕｐｐｏｒｔ ｖａｌｕｅ ｌｅａｒｎｉｎｇ ｎｅｔｗｏｒｋｓ．
ａｌｇｏｒｉｔｈｍ ｂａｓｅｄ ｏｎ ｅｎｓｅｍｂｌｅ ｌｅａｒｎｉｎｇ．Ａｃｔａ Ｅｌｅｃｔｒｏｎｉｃａ Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１６，３９（８）：１５８３－１５９６（ｉｎ
Ｓｉｎｉｃａ，２０１７，４５（２）：５０１－５０７（ｉｎ Ｃｈｉｎｅｓｅ） Ｃｈｉｎｅｓｅ）
（周飞燕，金林鹏，董军．基于集成学习的室性早博识别方 （李红，刘芳，杨淑媛等．基于深度支撑值学习网络的遥感
法．电子学报，２０１７，４５（２）：５０１－５０７） 图像融合．计算机学报，２０１６，３９（８）：１５８３－１５９６）
［９５］ Ｚｈｅｎｇ Ｙｉ，Ｌｉｕ Ｑｉ，Ｃｈｅｎ Ｅｎ－Ｈｏｎｇ，ｅｔ ａｌ．Ｔｉｍｅ ｓｅｒｉｅｓ ［１０６］ Ｈｕ Ｘｉａｏ－Ｊｕａｎ．Ｔｈｅ Ｒｅｓｅａｒｃｈ ｏｎ Ｓｉｇｎａｌ Ｐｅｒｃｅｐｔｉｏｎ ａｎｄ
ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｕｓｉｎｇ ｍｕｌｔｉ－ｃｈａｎｎｅｌｓ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ Ｃｏｍｐｕｔｅｒ Ａｉｄｅｄ Ｒｅｃｏｇｎｉｔｉｏｎ ｏｆ Ｔｒａｄｉｔｉｏｎａｌ Ｃｈｉｎｅｓｅ Ｍｅｄｉｃｉｎｅ
ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １５ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ Ｐｕｌｓｅ Ｄｉａｇｎｏｓｉｓ［Ｐｈ．Ｄ．ｄｉｓｓｅｒｔａｔｉｏｎ］．Ｅａｓｔ Ｃｈｉｎａ Ｎｏｒｍａｌ
ｏｎ Ｗｅｂ－Ａｇｅ Ｉｎｆｏｒｍａｔｉｏｎ Ｍａｎａｇｅｍｅｎｔ（ＷＡＩＭ）．Ｍａｃａｕ， Ｕｎｉｖｅｒｓｉｔｙ，Ｓｈａｎｇｈａｉ，２０１３（ｉｎ Ｃｈｉｎｅｓｅ）
Ｃｈｉｎａ，２０１４：２９８－３１０ （胡晓娟．中医脉诊中医脉诊信号感知与计算机辅助识别
［９６］ Ｚｈｅｎｇ Ｙｉ，Ｌｉｕ Ｑｉ，Ｃｈｅｎ Ｅｎ－Ｈｏｎｇ，ｅｔ ａｌ．Ｅｘｐｌｏｉｔｉｎｇ ｍｕｌｔｉ－ 研究［博士学位论文］．华东师范大学，上海，２０１３）
ｃｈａｎｎｅｌｓ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｍｕｌｔｉｖａｒｉａｔｅ ［１０７］ Ｇｕｏ Ｙａｎ－Ｍｉｎｇ，Ｌｉｕ Ｙｕ，Ａｒｄ Ｏｅｒｌｅｍａｎｓ，ｅｔ ａｌ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ
ｔｉｍｅ ｓｅｒｉｅｓ ｃｌａｓｓｉｆｉｃａｔｉｏｎ．Ｆｒｏｎｔｉｅｒｓ ｏｆ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ， ｆｏｒ ｖｉｓｕａｌ ｕｎｄｅｒｓｔａｎｄｉｎｇ：Ａ ｒｅｖｉｅｗ．Ｎｅｕｒｏｃｏｍｐｕｔｉｎｇ，２０１６，
２０１５，１０（１）：９６－１１２ １８７（Ｓｐｅｃｉａｌ Ｉｓｓｕｅ）：２７－４８
ＺＨＯＵ Ｆｅｉ－Ｙａｎ，ｂｏｒｎ ｉｎ １９８６， ＪＩＮ Ｌｉｎ－Ｐｅｎｇ，ｂｏｒｎ ｉｎ １９８４，Ｐｈ．Ｄ．Ｈｉｓ ｍａｉｎ ｒｅｓｅａｒｃｈ
Ｐｈ．Ｄ．ｃａｎｄｉｄａｔｅ．Ｈｅｒ ｍａｉｎ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔ ｉｓ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ．
ｉｎｔｅｒｅｓｔ ｉｓ ｃｏｍｐｕｔｅｒ－ａｉｄｅｄ ｄｉａｇｎｏｓｉｓ ｏｆ ＤＯＮＧ Ｊｕｎ，ｂｏｒｎ ｉｎ １９６４，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ，Ｐｈ．Ｄ．
ｃａｒｄｉｏｖａｓｃｕｌａｒ ｄｉｓｅａｓｅｓ． ｓｕｐｅｒｖｉｓｏｒ．Ｈｉｓ ｍａｉｎ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ａｒｅ ａｒｔｉｆｉｃｉａｌ ｉｎｔｅｌｌｉ－
ｇｅｎｃｅ ａｎｄ ｉｔｓ ａｐｐｌｉｃａｔｉｏｎｓ ｉｎ ｈｅａｌｔｈ ｍｏｎｉｔｏｒ ａｎｄ ｔｒａｄｉｔｉｏｎａｌ
ｃｕｌｔｕｒｅ． ６期 周飞燕等：卷积神经网络研究综述 １２５１
Ｂａｃｋｇｒｏｕｎｄ
Ｓｈａｌｌｏｗ ａｒｃｈｉｔｅｃｔｕｒｅｓ ｓｕｃｈ ａｓ Ｇａｕｓｓｉａｎ ｍｉｘｔｕｒｅ ｍｏｄｅｌｓ， ｔｈａｔ ｏｆｓｔａｎｄａｒｄ ｆｕｌｌｙ ｃｏｎｎｅｃｔｅｄ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．Ｉｎ ｒｅｃｅｎｔ
ｓｕｐｐｏｒｔ ｖｅｃｔｏｒ ｍａｃｈｉｎｅｓ，ｌｏｇｉｓｔｉｃ ｒｅｇｒｅｓｓｉｏｎ ａｎｄ ｓｏ ｏｎ ｈａｖｅ ｙｅａｒｓ，ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｈａｓ ｍａｄｅ ｍａｊｏｒ ａｄｖａｎｃｅｓ
ｂｅｅｎ ｓｈｏｗｎ ｅｆｆｅｃｔｉｖｅ ｉｎ ｓｏｌｖｉｎｇ ｍａｎｙ ｓｉｍｐｌｅ ｐｒｏｂｌｅｍｓ，ｂｕｔ ｉｎ ｐｒａｃｔｉｃａｌ ａｐｐｌｉｃａｔｉｏｎｓ．
ｔｈｅｉｒ ｌｉｍｉｔｅｄ ｍｏｄｅｌｉｎｇ ａｎｄ ｔｈｅ ｐｏｗｅｒ ｏｆ ｆｅａｔｕｒｅ ｒｅｐｒｅｓｅｎｔａ－ Ｃｕｒｒｅｎｔｌｙ，ｃａｒｄｉｏｖａｓｃｕｌａｒ ｄｉｓｅａｓｅ ｉｓ ｏｎｅ ｏｆ ｔｈｅ ｄｅａｄｌｉｅｓｔ
ｔｉｏｎｓ ｍａｙ ｃａｕｓｅ ｄｉｆｆｉｃｕｌｔｉｅｓ ｗｈｅｎ ｄｅａｌｉｎｇ ｗｉｔｈ ｃｏｍｐｌｉｃａｔｅｄ ｄｉｓｅａｓｅｓ ｆｏｒ ｈｕｍａｎ ｂｅｉｎｇｓ．ＥＣＧ ｉｓ ｖｅｒｙ ｉｍｐｏｒｔａｎｔ ｆｏｒ ｃａｒｄｉｏ－
ｓｉｇｎａｌ ａｎｄ ｉｎｆｏｒｍａｔｉｏｎ ｔａｓｋｓ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ｗｉｔｈ ｍｕｌｔｉｐｌｅ ｖａｓｃｕｌａｒ ｄｉｓｅａｓｅｓ ｍｏｎｉｔｏｒ ａｎｄ ｄｉａｇｎｏｓｉｓ．Ｏｕｒ ｇｒｏｕｐ ｈａｓ ｂｅｅｎ
ｌｅｖｅｌｓ ｏｆ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｉｓ ａ ｒａｐｉｄｌｙ ｇｒｏｗｉｎｇ ｆｉｅｌｄ ｏｆ ｍａｃｈｉｎｅ ｗｏｒｋｉｎｇ ｏｎ ｃｏｍｐｕｔｅｒ－ａｉｄｅｄ ＥＣＧ ａｎａｌｙｓｉｓ ｍｅｔｈｏｄｓ ｆｏｒ ｍｏｒｅ
ｌｅａｒｎｉｎｇ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ａｌｌｅｖｉａｔｅｓ ｔｈｅ ｏｐｔｉｍｉｚａｔｉｏｎ ｄｉｆｆｉｃｕｌｔｙ ｔｈａｎ ｔｅｎ ｙｅａｒｓ．Ｗｈａｔ ｉｓ ｍｏｒｅ ｗｅ ｈａｖｅ ｔｒｉｅｄ ｍａｎｙ ｄｉｆｆｅｒｅｎｔ
ｕｓｉｎｇ ｔｈｒｅｅ ｔｅｃｈｎｉｑｕｅｓ： ｂｅｔｔｅｒ ｐａｒａｍｅｔｅｒ ｉｎｉｔｉａｌｉｚａｔｉｏｎ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ｍｅｔｈｏｄｓ ｉｎｃｌｕｄｉｎｇ ｓｕｐｐｏｒｔ ｖｅｃｔｏｒ ｍａｃｈｉｎｅ，
ｔｅｃｈｎｉｑｕｅｓ，ｂｅｔｔｅｒ ｌｅａｒｎｉｎｇ ａｌｇｏｒｉｔｈｍｓ ｓｕｃｈ ａｓ ｓｔｏｃｈａｓｔｉｃ ＢＰ ｈｉｄｄｅｎ Ｍａｒｋｏｖ ｍｏｄｅｌ，ｒｕｌｅｓ ｉｎｆｅｒｅｎｃｅ ｅｔ ａｌ．ｉｎ ｃａｒｄｉｏｖａｓｃｕｌａｒ
ａｌｇｏｒｉｔｈｍｓ，ａｎｄ ａ ｌａｒｇｅｒ ｎｕｍｂｅｒ ｏｆ ｈｉｄｄｅｎ ｕｎｉｔｓ ｗｈｉｃｈ ｃａｎ ｄｉｓｅａｓｅｓ ｓｔｕｄｉｅｓ ｓｕｃｈ ａｓ ｎｏｒｍａｌ／ａｂｎｏｒｍａｌ ＥＣＧ ｃｌａｓｓｉｆｉｃａｔｉｏｎ，
ｉｍｐｒｏｖｅ ｔｈｅ ｍｏｄｅｌｉｎｇ ｐｏｗｅｒ．Ｉｔ ｈａｓ ｓｏｌｖｅｄ ｓｏｍｅ ｐｒｏｂｌｅｍｓ ａｔｒｉａｌ ｆｉｂｒｉｌｌａｔｉｏｎ ａｎｄ ｐｒｅｍａｔｕｒｅ ｖｅｎｔｒｉｃｕｌａｒ ｃｏｎｔｒａｃｔｉｏｎ ｃｌａｓｓｉ－
ｔｈａｔ ｈａｖｅ ｒｅｓｉｓｔｅｄ ｔｈｅ ｂｅｓｔ ａｔｔｅｍｐｔｓ ｏｆ ｔｈｅ ｓｈａｌｌｏｗ ａｒｃｈｉｔｅｃ－ ｆｉｃａｔｉｏｎ ａｎｄ ｓｏ ｏｎ．Ｔｈｒｏｕｇｈ ａ ｓｅｒｉｅｓ ｏｆ ｅｘｐｅｒｉｍｅｎｔｓ，ｗｅ ｈａｖｅ
ｔｕｒｅｓ ｆｏｒ ｍａｎｙ ｙｅａｒｓ．Ａｓ ｏｎｅ ｏｆ ｔｈｅ ｍｏｓｔ ｒｅｐｒｅｓｅｎｔａｔｉｖｅ ｄｅｅｐ ｆｏｕｎｄ ｔｈａｔ ｔｈｅ ｍｅｔｈｏｄ ｃｏｍｂｉｎｇ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ
ｌｅａｒｎｉｎｇ ｍｏｄｅｌｓ，ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｉｓ ａｔｔｒａｃｔｉｎｇ ａｎｄ ｒｕｌｅｓ ｉｎｆｅｒｅｎｃｅ ｉｓ ｂｅｔｔｅｒ ｆｏｒ ｒｅｃｏｇｎｉｔｉｏｎ ｏｆ ｔｈｅｓｅ ｃａｒｄｉｏ－
ｔｈｅ ａｔｔｅｎｔｉｏｎ ｏｆ ｍａｎｙ ａｃａｄｅｍｉｃ ｒｅｓｅａｒｃｈｅｒｓ．Ｂｅｃａｕｓｅ ｏｆ ｔｈｅ ｖａｓｃｕｌａｒ ｄｉｓｅａｓｅｓ，ａｎｄ ｉｔ ｃａｎ ｇａｉｎ ｈｉｇｈｅｒ ａｃｃｕｒａｃｙ ｒａｔｅｓ ｔｈａｎ
ｌｏｃａｌ ｃｏｎｎｅｃｔｉｏｎｓ，ｓｈａｒｅｄ ｗｅｉｇｈｔｓ，ｐｏｏｌｉｎｇ ｏｐｅｒａｔｉｏｎ ｉｎ ｔｈｅ ｓｏｍｅ ｏｔｈｅｒ ｔｒａｄｉｔｉｏｎａｌ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ｍｅｔｈｏｄｓ．Ｎｏｗ ｗｅ
ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ，ｉｔ ｈａｓ ｆｅｗｅｒ ｐａｒａｍｅｔｅｒｓ ｔｏ ｂｅ ｈａｖｅ ｕｓｅｄ ｔｈｅ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｍｏｄｅｌ ｆｏｒ ｓｏｍｅ
ｔｒａｉｎｅｄ．Ｔｈｅｒｅｆｏｒｅ，ｉｔ ｉｓ ｍｏｒｅ ａｐｐｌｉｃａｂｌｅ ｔｏ ｏｐｔｉｍｉｚｅ ｔｈａｎ ｃａｒｄｉｏｖａｓｃｕｌａｒ ｄｉｓｅａｓｅｓ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｏｎ ｏｕｒ ｃｌｏｕｄ ｐｌａｔｆｏｒｍ． --------------------------------------------------------------------------------- 情报科学
综综综综综综综综综综综综综综综综综综综综综综综综综综综综综综综 述述述述述述述述述述述述述述述述述述述述述述述述述述述述述述述
第第3366卷卷第第77期期 22001188年年77月月
· ·
国外网络环境中信息过载研究进展
郭 佳，黄程松
（武汉大学信息管理学院，湖北武汉 ）
430072
摘 要：【目的/意义】以国外网络环境中信息过载相关研究为研究对象，为国内相关领域研究梳理研究脉络，为研
究者提供参考与借鉴。【方法/过程】采用文献调研方法，从理论基础、研究方法、研究情境、产生原因、症状或影响、
解决对策六个方面对网络环境中信息过载主题研究现状进行归纳与述评。【结果/结论】研究发现：网络环境中信息
过载研究涉及理论与模型呈现分散化、多样化特点；以调查研究、实验与访谈作为主要研究手段；对在线购物情境
与社交网络环境中的信息过载研究尤为集中；信息主体分别从主、客观信息过载影响因素入手，应对信息过载给信
息行为与心理带来的负面影响。此外揭示了网络信息过载研究的发展趋势，为国内信息过载理论与实践提供借
鉴。
关键词：信息过载；文献调研；网络环境
中图分类号：G250.2 DOI：
10.13833/j.issn.1007-7634.2018.07.028
ResearchReviewonInformationOverloadinNetworkEnvironmentAbroad
GUOJia,HUANGCheng-Song
(SchoolofInformationManagement,Wuhanuniversity,Wuhan ,China)
430072
Abstract:【 】
Purpose/significance The purpose of this study is to explore the research contents of information overload in
networkenvironmentabroad,andtrytosummarizethefindings,whichwillprovidethereferenceforthescholarsinthere⁃
【 】
latedfield. Method/process Thispaperprogressesonsixaspectswhichconcludetheoreticalbackground,methodology,re⁃
【
searchsituation,influencingfactors,symptomsoreffectsandcountermeasuresbymeansofliteraturesurvey. Result/con⁃
】
clusion Resultindicatesthattherelatedtheoryandresearchmodelofinformationoverloadinnetworkenvironmentpres⁃
，
entsadiversificationcharacteristic.Byutilizinginvestigation,experimentandinterviewasthemainresearchmethods espe⁃
，
ciallyfocusingonthesituationofonlineshoppingandsocialnetworkservice theinformationuserandinformationprovider
respectivelyfromsubjectiveandobjectivefactorstakeactionstoreducethenegativeeffectoninformationbehaviorandpsy⁃
chological bring by information overload. Theoretical and practical implications are discussed by analyzing the research
trendattheendofthepaper.
Keywords：
informationoverload;literatureresearch;networkenvironment
据产生的同时也带来了大量的数据噪音，大量涌入的无结构
1 引 言 信息对用户有限的信息处理能力、存储能力提出了挑战。信
息爆炸带来的负面效应，如信息过载、信息焦虑、信息冗余等
互联网技术的广泛与快速发展，为网络用户接受和处理 问题逐渐成为相关领域的热门研究方向。
信息方式带来了变革，同时促进了数字信息的爆炸式增长。 信息过载研究由来已久，作为术语首次出现在 对
Gross
预计到 年，全球累计生成的数据总量将有望突破 组织管理的研究中【 2】，随后在 的著作《 》【 3】
2020 Toffler FutureShock
，这一数据是 年产生数据总量的 倍【】。海量数 中运用而被广泛认知。信息过载的传统定义为信息处理需
1
40ZB 2010 50
收稿日期：2017-10-12
作者简介：郭 佳（1987-），女，博士研究生，主要从事信息资源配置与管理、信息行为、信息系统研究.
- 170 - 情报科学
综综综综综综综综综综综综综综综综综综综综综综综综综综综综综综综 述述述述述述述述述述述述述述述述述述述述述述述述述述述述述述述
第第3366卷卷第第77期期 22001188年年77月月
· ·
求大于信息处理能力。基于主观体验的角度来看，信息过载 认知、态度、主观状态的中介作用影响其行为意向为线索展
定义延伸包含了个体在面对信息时所感受到的紧张、困惑、 开。 等研究了信息过载、信息态度、信息共享及行为意
Crook
压力与焦虑等主观感受。信息过载研究广泛分布于信息检 向（包括对健康信息的关注和对信息提供者索求更多信息）
索，用户决策、组织管理、信息系统等主题中。本文通过对国 之间关系【】； 等基于信任水平研究网上商品评论信息
6
Furner
外网络环境中信息过载问题研究的梳理，可以为网络服务商 过载对用户购买行为意向的研究【】； 等将个体的心理状
7
Swar
针对网络信息过载症状，分析产生原因、寻找应对策略提供 态作为态度的反应，结合信息加工理论，研究信息过载对信
指引；尝试归纳与挖掘信息过载相关的研究进展与发展方 息搜寻者态度的作用进而影响用户持续搜寻健康信息行为
向，为本领域研究者提供参考与借鉴。 意向【】。
8
表1 国外网络环境中信息过载研究的理论/模型引用情况
2 文献采集与整理 理论模型名称 引用次数 来源文献
/
期望失验理论 【】
1 4
作为大型综合性涵盖多学科的核心期刊 认知失调理论 【】
1 4
Webofscience 认知匹配理论 【】
引文索引数据库，包括全世界范围内 多种高质量的期 1 5
8000 创新扩散理论 【】
刊。本研究采取文献调研的方法，以“ ” 1 6
InformationOverload 不确定性减少理论 【】
为“标题”关键字段，在 数据库中选中 1 6
计划行为理论 【 】
Web of science SSCI 3 6-8
（ ，社会科学引文索引）数据库， 信息加工理论 【，】
SocialSciencesCitationIndex 2 6 8
检索时间段为 年至今，检索得到 篇文献。对所得内 预期理论 【】
1990 198 1 9
适应性结构化理论 【】
容进行浏览后，选取网络背景下的信息过载研究，剔除其他
1 9
人与环境匹配模型 【 】
研究环境及与主题实质不相关文献，同时通过将“ 1 10
Informa⁃ 压力与应对模式 【 】
”分别与“ ”“ ”“ ”“ ” 1 10
tion Overload Online Internet Cyber Web 认知负荷理论 【 】
2 11-12
“ ”“ ”“ ”再次进行逐一组配作为检索 社会资本理论 【 】
Network Virtual Website 1 13
对象进行检索，最终筛选出 篇目标文献。 使用满足理论 【 】
34 1 13
33..22研研究究方方法法
3 文献分析
在进行网络环境下信息过载主题研究时，采用最多的研
究方法是问卷调查法，其次访谈法、实验法，二手数据分析也
33..11理理论论基基础础
较为常用（分布频次见图 ），该类研究方法多应用于实证层
1
目前关于信息过载的研究广泛分布在计算机科学、图书 面的研究，侧重于调查用户提供的主客观数据，研究较难量
情报、市场营销、法学、心理学和经济学等众多学科中，因研 化的用户心理状态和用户行为等问题。由于互联网的普及，
究领域广、研究线索分散，故该主题的研究理论基础呈现多 网络问卷调查因其调查不受时间地点限制、回收速度高、成
样化趋势。在检索得到的 篇目标文献中，有 篇显示有 本节约，便于统计分析等优点，成为学界作为研究用户意愿
34 10
明确的理论基础。经过本研究统计整理得出，共有 种理 与行为的主要方法，但该方法对于了解用户意图、动机和思
14
论和模型被涉及，其中以计划行为理论、认知负荷理论和认 维等动态过程往往效果不佳。
知中介理论使用次数较多，其他理论模型的使用都仅限于
/
一篇文章，引用理论模型的使用情况见表 。在研究信息过
/ 1
载问题中，一般单篇文献涵盖了多种基础理论与模型，研究
者在原有理论或模型中提取重要变量，通过组合、扩展、根据
情境细化生成新的研究模型。基于目标文献调研，信息过载
因子通常以三种方式与实际研究情境结合：以信息过载作为
前置动因研究信息行为，通过信息用户主观状态、态度、情绪
等中介效应作用于用户各种信息行为，在检得文献中信息过
载通过如满意度【 4】、感知风险【 5】、态度【 6】、信任【 7】、主观状态【 8】 图1 网络环境中信息过载主题研究方法使用次数分布
等中介变量来影响用户的信息行为；也有学者将信息过载作 本研究通过对目标文献梳理，发现在实际研究操作过
为压力源，研究其对用户主观状态、信任等精神状态的直接 程中，研究者在运用问卷调查法过程中，吸纳了多种形式的
影响【 9-10】；此外还有研究者从认知负荷出发探索了信息过载 研究方法作为补充，如实验法和访谈法，在一定程度上弱化
的形成过程【 11-12】。 了问卷调查法对于动态行为与心理活动的不适应性，为研
以计划行为理论为例，在信息过载研究中为模型提供了 究结果的稳定性与科学性提供了支撑。也有一些学者引入
重要的行为变量（ ），通过信息过载经用户 了新的研究方法，如模拟仿真、田野调查和案例分析等，丰
BehaviorIntention
- 171 - INFORMATION SCIENCE
Summarization
· ·
Vol.36,No.7 July,2018
富了该主题的研究工具，但以上方法一般用于理论与实践 购物环境中信息过载对消费者购买决策产生的主观状态的
中上信息过载影响因素推导，是研究信息过载前置动因的主 影响【】； 和 研究了信息过载对
9
Byung-KwanLee Wei-NaLee
要研究工具。 消费者选择与心理状态的影响【】； 等探索了消费者在
21
Kwon
阅读网络评价中是否会经历信息过载，并是否会对购买决策
33..33研研究究情情境境
产生影响【】。
22
从信息过载的传统定义上来讲，其概念构成是个人信息
33..44产产生生原原因因
处理能力（也就是个体能在一定时间内纳入决策过程的信息
量）与信息处理需求（个体完成任务所必需整合的信息量）的 和 提供了系统化的信息过载研究框架（见
Eppler Mengis
比较。“需求”与“能力”通常以可用时间来测量，需求指的是 图 ）【】。该框架不是基于简单的因果线性逻辑，而是强调
14
2
需在一定时间内处理给定信息量。在管理信息系统、组织研 了系统的循环，即信息过载成因、症状和缓解对策变量间的
究、消费者研究中，信息过载主要应用于研究个体如何伴随 关系。同时特别提出改善信息质量的技术应用、个体动机因
其面对的信息量做出决策。 和 将信息过载的 素和任务参数是以往的信息过载研究中被忽略的因素；信息
Eppler Mengis
研究情境划分为信息检索、组织和分析过程，决策过程和传 过载的解决途径并不能限定为一种或几种，需要在持续的信
播过程【】。本研究以此为基础梳理网络环境下的信息过载 息循环中改进与细化。通常组织层面或个人层面中信息过
14
研究情境。 载产生的原因可归纳为五个方面： 个体因素； 信息特点
① ②
表2 网络信息过载研究情境 （包括信息数量，频率，密度和质量）； 任务和进程参数（即
③
信息过载情境 来源文献 个体或团队、组织需要完成的任务与进程）； 组织设计（如
④
网络信息搜索 【，】 正式或非正式工作架构）； 信息技术（ ）。在网络环境中，
8 15 ⑤ IT
信息检索、组织、分析 信息筛选、过滤 【 】 信息过载产生多为几种因素的共同作用（见表 ）。
过程 评价信息产品功能 【16 】-18 3
19
知识管理 【 】
20
电子知识库使用 【】
4
网上购买决策 【 ，， 】
决策过程 5,7 9 21-22
决策创新过程 【】
6
虚拟团队管理 【 】
23
传播过程 社交网络 【 】
10,24-26
计算机媒介交流 【 】
11-12
网络媒介 【 】
13,27
网络新闻媒介 【 】
28-30
电子邮件 【 】
31
移动信息通信技术 【 】
32
在线交互空间 【 】
33
通过对 篇目标文献分析，剔除综述类和理论分析等 图2 信息过载研究框架
34
无情境文献，可以得出表 网络信息过载研究情境分析。 3.4.1 客体因素
2
其中以传播过程的研究情境出现总频次最多，契合了信息 信息过载的定义包含了主体与客体的内涵，大量的信息
通讯技术发展带来的信息沟通、信息传播方式的变革。在 作为客体影响信息使用者的主观感受与客观经验，因此需从
信息传播过程中以社交媒体和网络新闻媒体的信息过载研 信息特点入手研究信息过载的成因。由于网络媒介应用和
究最为集中： 等从压力角度研究了信息过载对社交媒体 推广带来的信息产生、加工与传播等方式变革，造成了信息
Lee
使用疲惫感的影响【 】； 等从推特接收数量、朋友数和 数量激增，为主体检索与利用信息带来了障碍。网络媒介频
10
Sasaki
个人社交网络密度三方面，剖析了推特使用中感知信息过 繁使用伴生着信息数量激增，根据文献分析可以看出网络
载的影响因素【】； 和 探索了不同新闻传送平台 媒介使用与信息数量激增成为网络环境中信息过载产生的
24
Holton Chyi
中与感知过载程度相关的影响因素【 】； 等研 最主要因素， 等指出健康信息正以夸张的速度增加，
28
EszterHargittai Swar
究了新媒体的采纳者在从被动播报到线上主动搜寻过程中 庞大的网络健康数据量改变了病患自我学习方式，也导致
的反应与感受【 】。 了信息过载现象的出现【】； 和 在研究电子邮件
29 8
Soucek Moser
用户网上购买决策是出现单次频次最多的研究情境，主 的信息过载中也指出电子邮件的使用、接收大量电子邮件
要将信息过载作为影响用户购买意向及购买决策质量的因 信息会导致员工的信息过载【 】； 和 指出随
31
Benselin Ragsdell
素进行研究。 等研究了信息过载和信息无序对消 着互联网发展，信息过载持续受到学界研究热捧，互联网带
Sotoacosta
费者购买决策的影响【】； 等综合了网络口碑、信息加 来了信息数量的激增，信息获取方式便捷多样，因此信息技
5
Furner
工与决策理论，以信息过载作为中介变量，构建了基于网络 术成为信息过载的主要原因，但也是解决信息过载问题的
商品评论的信任与购买意愿关系模型【】； 等考察了网络 主要手段【 】。
7 34
Chen
- 172 - 情报科学
综综综综综综综综综综综综综综综综综综综综综综综综综综综综综综综 述述述述述述述述述述述述述述述述述述述述述述述述述述述述述述述
第第3366卷卷第第77期期 22001188年年77月月
· ·
网络信息数量激增带来的无序信息增加、数据无序和无 客体的网络技术应用、信息通讯技术变革改变了人们的沟
结构、信息复杂等后果也经常作为研究信息过载的出发点。 通、学习和工作方式，带来便捷的同时大量涌入的信息潮为
信息技术、互联网发展是搜索引擎算法、信息过滤技术和社 用户带来了检索、决策低效以及负面心理状态，但与此同
交媒体软件使用的源头，网络通讯技术利用不当及其本身的 时，个体信息能力、个体特质以及所处社会影响是决定信息
局限性是信息技术层面中带来信息过载的根本原因。 过载能否对个体产生负面影响的重要因素。因个体差异信
Kao
和 指出读者通过搜索引擎来查找书评会面临信息过载 息过载往往对用户的影响程度不同， 等研究中认为信
Peng Chen
问题，是由于搜索引擎算法不能有效过滤无关信息，不能根 息过载并不会影响每一位受试者，拥有元认知处理能力的
据评论本身属性和特点定位，而且不同书评的组织方式也不 学生懂得如何管理信息过载问题【 】； 等明确表示健康
12
Chae
同，因而导致检索低效【】。 信息的增加本身并不能引起信息过载，拥有高焦虑度、癌症
19
3.4.2 主体因素 家族史、媒体使用率低等个人特质的用户更容易受到信息
个体能力及其态度、资历和经验是影响信息过载的重要 过载的侵害【 】。
18
主体因素。在检出文献中，由于网络信息激增带来的信息爆
33..55症症状状与与影影响响
炸与个体信息处理能力局限性的冲突，许多有用信息可能会
因无法获得用户的关注而被排除，从而使用户网络体验感下 在 和 的研究框架中，将信息过载产生后的
Eppler Mengis
降。 等研究认同当在有限时间内提供给消费者大 影响分解在信息检索、信息分析和信息组织、决策和个体心
Sotoacosta
量信息，超过其处理极限时会发生信息过载现象【 5】； 等研 理主观感受四个部分，本研究沿袭该框架对信息过载影响的
Pei
究了用户在信息过载的社交网络环境中所受的影响，指出了 划分【（】 见表 ）。
14
4
信息爆炸与用户信息处理能力局限的冲突，超过用户处理能 信息过载产生后最直接的影响主要体现在对用户信息
力的信息可能因无法唤起用户注意而被丢弃，因而信息竞争 行为的负面作用上。在信息检索阶段，信息过载带来的信息
引起了信息过载现象【 25】。另外有研究将个人网络经验、技 数量与信息质量变化、检索工具中机器语言与自然语言的不
能、教育背景和年龄等都作为信息过载的前因变量进行了研 匹配等，都能导致用户无法快速定位所需信息。 和
Liang Fu
究；还有学者拓展了个体因素的外延，将个体所处的信息场 在研究中表明如果在推特上关注内容特征相似的用户，可能
景和个体社交互动也纳入了考量范围。 会接收过多重复信息，从而导致相似选择趋势增加【】；
26
表3 信息过载产生原因 和 总结了电子邮件交流中信息过载的三个侧
Soucek Moser
信息过载成因 来源文献 面：收件箱混和了包含相关信息与无关信息的邮件，影响了
个体处理信息能力局限 【 】 信息处理效率；大量涌入信息包含不恰当的工作习惯会损害
5,8,25,27,30,33
个人特质（经验、技能、观
【 】 信息处理能力，导致工作流程低效；电子邮件信息由于格式、
念、年龄、性格等） 6,9,11-12,18
主体因素 个体所处情境 【】 交流语境、时效等，降低了沟通交流质量【】。
7 31
个体社会资本 【 】
表4 信息过载的症状与影响
13,24
动机因素 【 】
18 症状与影响 来源文献
信息数量激增 【 ， 】
4,8,16 24-25,31 难以获得有用或相关信息 【 】
信息载荷量大 【 】 降低检索效率 13,15
9,36 难以获得特定信息 【 】
无关信息激增 【 】 17,
信息特点 15,23 难以检出个体感兴趣信息 【 】
信息竞争 【 】 19
信息需求与可用信息不 25 工作效率低，时间管理问题 【 ，】
【 】 6 31
对称 27 降低参与度、信息处理能力 【 】
信息分析与组 12
信息无序化，无结构 【 】 降低知识组织、管理效率 【 】
计算机、互联网、电子媒 【33 织 20
介使用 8,10】-13,17,21,28-32, 组织中低质量信息交换 【 23,31】
过滤技术 【35,37 】 缺乏差异性，相似选择趋势增加 【 】
信息技术 8-9 26
搜索引擎算法 【 】 次优决策 影响（购买、使用）意向 【 】
8,15 4-5,7
社交媒体软件的使用 【 】 降低决策质量 【 】
10,16,26 21,27
数据（用户生成内容）上 负面心理（消极、抑郁、焦虑、愤怒） 【 】
【 】 8,34
传频率 16 决策结果的主观状态 【】
组织设计 组织环境与组织文化 【 】 9
32 个体主客观状 社交网络疲惫 【 】
10
此外，信息过载最早是出现在组织研究中，在检出的目 态 认知过载 【 】
12,33
标文献中仍有部分组织内部信息过载研究，但都是围绕处在 个体健康与心理压力 【 】
35
组织环境中的个体展开，仅在 和 的研究中不仅 信息焦虑、信息肥胖、追求最低满意度 【 】
Allen Shoard 36
考虑了网络与移动电子设备使用因素，还指出了复杂的工作 与网络环境中信息过载研究情境相对应的，信息过载的
环境和高度结构化与官僚主义的工作属性也是产生信息过 症状与影响信息用户的决策方面表现较为集中。
Sotoacosta
载的重要诱因【】。 等通过实证研究验证了感知信息过载通过感知风险负向影
32
综上所述，信息过载的原因主要集中在主客体两方面， 响消费者购买决策【 5】； 等发现了信息载荷与信任和购
Furner
- 173 - INFORMATION SCIENCE
Summarization
· ·
Vol.36,No.7 July,2018
买意向之间的倒 形曲线，合理适中的评论字数对用户购 的研究中不仅提出了过滤策略（即将用户关
U Savolainen
买意向的推动作用最大，过多或过少的信息载荷都能降低 注点集中在最有用的信息上，过滤清除无用信息），还提出了
用户的购买意向【】； 提供了信息过载对近乎理性决策 将日常信息源数量控制在最小范围的收回策略【】； 和
7 17
Zandt Misra
者在接受过多信息后决策质量更低的解释，并提供了理论 认为理解用户持续增加使用数字通信技术带来的心
Stokols
应对方法【 】。 理与健康影响非常重要，个体与组织按规定比例缩减或更好
27
另外，网络环境中信息过载不仅影响信息用户的客观信 地调整对数字信息通信技术的使用，对于应对信息过载、获
息行为，还会带来一系列如认知过载、负面心理、信息焦虑等 得与周围环境的可持续的平衡非常必要【】。
17
主观状态失衡现象（见表 ）。研究者更关注用户的在遭遇 3.6.2 信息服务者
4
信息过载后的主观状态，如 等研究了社交网络过载的构 （）改善平台信息服务环境，改进平台信息服务技术。
Lee 1
成，将信息过载作为三大压力源之一，成为社交网络使用疲 等建议在线健康信息网站的管理者可以通过建立
Swar
惫感的触发因素【】； 等则提出信息过载是认知过载的 在线健康信息内容（关于疾病症状和可能治疗手段）的共享
10
Chen
前导【】。 平台，使各类专业、一致、无歧义的信息资源得以共享以降低
12
在线健康信息搜寻者的信息过载和负面心理【】； 等提出
8
33..66应应对对策策略略 Lee
社交网络服务商应对社交网络服务使用疲惫感的解决途径，
在网络环境信息过载研究中，研究者们不仅讨论了信息 即为用户提供更多可控的、有自主权的网络环境，如用户可
过载现象的主要成因和影响，还提出了在实践中处理信息过 以自行设置通讯请求的次数限制，提供可选的内容过滤工具
载问题的相关对策，既包括了制度、技术、态度等宏观层面的 等【 10】；另外还有学者提出了在网络服务或 中应用可视
APP
实施建议，还具体到了某项工具的引进和介绍。根据文献调 化技术，设计带记忆功能的信息推荐系统等建议来应对网络
研结果，本文从信息用户和信息服务商两个层面对信息过载 环境中的信息过载问题。
的对策进行了总结： （）合理组织信息内容，提高信息质量。
2
3.6.1 信息用户 等在网络口碑与信息处理和决策的研究中，发现
Furner
笔者认为，信息用户应对网络环境信息过载的策略可分 了信息负荷与信任和购买意向的倒“ ”形曲线，建议评论平
U
为主动策略与被动策略。主动策略是指在接受网络环境中 台操作者应优先和强调长度适中的评论，并将新的商品评论
信息体量大、信息增长速度快的情况下，通过自身努力或借 设置最少与最多字数限制【 7】； 等发现研究中的受试者
Kwon
助技术、工具与组织干预，提高个体或组织信息素养、数字技 无信息过载感的原因不是其了解所有评论信息，而是他们大
术使用能力等个体能力，从而降低信息过载对信息用户心理 部分忽略了目前的数据，即受试者很少阅读超过一页的评
与生理的负面影响。被动策略是在维持环境、自身能力、信 论，故提供一个有用的评价首页是非常重要的，且需合理组
息处理方法等条件不变的情况下，仅靠减少接收信息量、缩 织商品好评与差评信息，从而实现消费者合理化选择【 22】。
减数字信息技术的使用来降低信息过载的影响。 （）分析不同信息需求，提供个性化信息服务。
3
（）主动策略。 等在研究信息过载与信息无序时提出要发挥
1 Sotoacosta
提高信息素养：即提高用户识别、分析和利用信息能 信息过载对用户购买意向的正面影响，为网络经验丰富的顾
①
力。 等认为作为用户信息素养的一部分，提高用户的信息 客提供包含综合信息的网页，由于信息过载通过感知风险负
Ji
搜寻效率能有效减轻信息过载问题【】； 和 向影响购买意向，故需对目标客户进行区分，仅针对网络经
30
Benselin Ragsdell
指出年轻人由于接触网络信息较多，相较老年人更容易受信 验丰富的顾客提供大量商品信息【 5】； 等针对缺乏网购经
Chen
息过载影响，特别是信息素养较低的年轻人，因而提高信息 验的顾客提出设计简洁与用户友好的设计界面，信息个性化
搜寻与管理能力是克服信息过载问题的重要途径【 34】。 也是过滤无关信息的有效技术【 9】； Lee等认为与其为用户提
借助技术、工具与组织干预： 提出帮助学生减 供过多复杂功能，不如提供可供选择的基础设计要素，允许
② Ronald
少在使用网络资源研究工程主题时信息过载的方法，即通过 用户自主设计其社交网络页面【 10】。
对现有元搜索引擎的综合使用、对在线技术类杂志的查新，
或者对企业在线网页的商品与服务简介的解读，都可以帮助 4 结 语
研究者定位到相关信息【】； 和 设计
15
RudolfHanka KarelFuka
了 系统作为一种知识管理工具，可以帮助全科医生在 研究基于 和 提出的信息过载研究框架【 14】，
WaX Eppler Mengis
秒内快速获得所需信息，从而降低信息过载带来的检 移植于网络环境中研究信息过载现象发生的情境、原因，研
15-30
索低效问题【】； 和 为应对电子邮件交流中大量 究发现信息过载多出现于信息传播过程，尤其以社交网络环
20
Soucek Moser
信息涌入、工作流程低效和低质量沟通等问题，通过实证揭 境的信息过载研究最为集中，针对其产生原因也分别从主观
示培训干预能有效提高员工知识管理与媒介使用能力，显著 与客观两方面进行论述；此外应对信息过载对用户信息行为
地改善信息过载问题【】。 与心理负面影响，本研究对文献提出的策略进行了分析总
31
（）被动策略。 结，归纳了信息用户与信息服务商两大利益主体的应对策
2
- 174 - 情报科学
综综综综综综综综综综综综综综综综综综综综综综综综综综综综综综综 述述述述述述述述述述述述述述述述述述述述述述述述述述述述述述述
第第3366卷卷第第77期期 22001188年年77月月
· ·
略，是对 和 （ ）信息过载研究框架的发 mation Review, 2014, 38(4):543-561.
Eppler Mengis 2004
展。另外，通过对网络信息过载理论基础和研究方法的总结 6 Crook B, Stephens K K, Pastorek A E, et al. Sharing
与分析，也充分揭示了网络环境中信息过载已逐渐转向基于 Health Information and Influencing Behavioral Inten⁃
用户心理与行为的实证研究，研究线索相对分散，设计变量 tions: The Role of Health Literacy, Information
多贴合实际研究情境，并没有固定的研究路径与研究模型， Overload, and the Internet in the Diffusion of
是对 和 研究框架内容的补充。 Healthy Heart Information[J]. Healthy communica⁃
Eppler Mengis
本研究文献调研基本可以揭示在网络环境中信息过载 tion,2016,31(1):60-71.
问题研究的几个趋势： 7 Furner C P, Zinko R A, Zhu Z. Electronic
（）网络环境中信息过载研究对象逐渐从组织到个体， Word-Of-Mouth and Information Overload in an
1
特别是网络通讯技术的发展催生了信息传播方式、信息生成 Experiential Service Industry[J]. Journal of service
方式的变革，虚拟社区与社交媒体的盛行，越来越多的学者 theory and practice, 2016, 26(6):788-810.
开始关注信息用户在网络媒介下的信息心理与信息行为； 8 Swar B, Hameed T, Reychav I. Information over⁃
（）网络环境中信息过载的影响逐渐从信息检索效率、 load, psychological ill-being, and behavioral inten⁃
2
信息管理、决策质量等客观影响，转移到关乎信息用户在信 tion to continue online health information search[J].
息过载环境下的主观压力与负面情绪； Computers in Human Behavior, 2017,70(5):416-425.
（）网络信息服务商针对用户的信息过载问题，不仅关 9 ChenYC,ShangRA,KaoCY.Theeffectsofinformation
3
注信息技术改进与信息内容筛选，已逐渐突显以用户为中心 overloadonconsumers’subjectivestatetowardsbuyingde⁃
的思想，分析目标群体特点，针对用户特质，为用户提供个性 cision in the internet shopping environment[J]. Electronic
化信息服务已成为信息服务的主流。 CommerceResearchandApplications,2009,8(1):48-58.
由于国内学界已逐步开始关注信息过载研究，何仲等研 10 Lee A R, Son S M, Kim K K. Information and com⁃
究了信息过载环境下网络消费者购买意愿的形成机制【 38】；王 munication technology overload and social network⁃
又然以加权小世界理论为基础研究了社交网络站点社群信 ing service fatigue: A stress perspective[J]. Comput⁃
息过载的影响因素【】；王娜、任婷对移动社交网站的信息过 ers in Human Behavior, 2016, (55):51–61.
39
载与个性化推荐机制进行了研究【】。因此通过对国外较早 11 Chen C Y, Pedersen S, Murphy K L. Learners’perceived
40
起步的网络信息过载研究进行文献内容分析，对国内学者未 information overload in online learning via computer-me⁃
来更深一步揭露网络信息过载的复杂形成机制、影响因素有 diated communication[J]. New Educational Review,2011,
重要的理论意义；对信息服务商进一步改进信息技术、改善 23(1):141-158.
信息服务，提高用户满意度有实践指导意义。 12 ChenCY,PedersenS,MurphyKL.Theinfluenceofper⁃
ceived information overload on student participation and
参考文献
knowledge construction in computer-mediated communi⁃
cation[J].InstructionalScience,2012,40(2):325-349.
1 Gantz J ,Reinsel D. The digital Universe in 2020: Big
13 Beaudoin C E. Explaining the Relationship between Inter⁃
data, Bigger digital Shadows, and Biggest Growth in
net Use and Interpersonal Trust: Taking into Account Mo⁃
the far East[R]. Framingham: IDC Analyze the Fu⁃
tivation and Information Overload[J]. Journal of Comput⁃
ture,2012.
er-MediatedCommunication,2008,13(3):550–568.
2 Gross, B.M. The Managing of Organizations: The Ad⁃
14 Eppler MJ, Mengis J. The Concept of Information Over⁃
ministrative Struggle[M]. New York: Free Press of
load: A Review of Literature from Organization Science,
Glencoe,1964:606.
Accounting, Marketing, MIS, and Related Disciplines[J].
3 Toffler A. Future shock[J]. American Journal of Soci⁃
InformationSociety,2004,20(5):325-344.
ology, 1970, 429(1):104.
15 Rockland R H. Reducing the information overload: a
4 Gee-Woo Bock, Mimrah Mahmood, Sanjeev Shar⁃
method on helping students research engineering topics us⁃
ma, et al. The Impact of Information Overload and
ing the Internet[J]. IEEE Transactions on Education, 2000,
Contribution Overload on Continued Usage of Elec⁃
43(4):420-425.
tronic Knowledge Repositories[J]. Journal of Organi⁃
16 SasakiY,KawaiD,KitamuraS.Unfriendorignoretweets?:
zational Computing and Electronic Commerce, 2010,
A time series analysis on Japanese Twitter users suffering
20(3):257-278.
frominformationoverload[J].ComputersinHumanBehav⁃
5 Sotoacosta P, Molinacastillo F J, Lopeznicolas C, et
ior,2016,(64):914-922.
al. The effect of information overload and disorganisa⁃
17 SavolainenR.Filteringandwithdrawing:strategiesforcop⁃
tion on intention to purchase online[J]. Online Infor⁃
- 175 - INFORMATION SCIENCE
Summarization
· ·
Vol.36,No.7 July,2018
ing with information overload in everyday contexts.[J]. consumers[J]. Cyberpsychology Behavior and Social Net⁃
JournalofInformationScience,2007,33(5):611-621. working,2012,15(11):619-624.
18 Chae J, Lee C J, Jensen J D. Correlates of Cancer Informa⁃ 29 Eszter Hargittai, W. Russell Neuman, Olivia Curry. Tam⁃
tion Overload: Focusing on Individual Ability and Motiva⁃ ingtheInformationTide:PerceptionsofInformationOver⁃
tion.[J].HealthCommunication,2016,31(5):626-634. load in the American Home[J]. Information Society, 2012,
19 Kao Y M, Peng C C. A multi-source book review system 28(3):161-173.
forreducinginformationoverloadandaccommodatingindi⁃ 30 Ji Q, Ha L, Sypher U. The Role of News Media Use and
vidualstyles[J].LibraryHiTech,2015,33(3):310-328. Demographic Characteristics in the Prediction of Informa⁃
20 Rudolf Hanka, Karel Fuka. Information overload and“just tion Overload[J]. International Journal of Communication,
‐in‐time”knowledge[J].ElectronicLibrary,2000,18(4): 2014,8(1):699-714.
279-285. 31 Soucek R, Moser K. Coping with information overload in
21 Lee B K, Lee W N. The effect of information overload on emailcommunication:Evaluationofatrainingintervention.
consumer choice quality in an on‐line environment[J]. [J].ComputersinHumanBehavior,2010,26(6):1458-1466.
Psychology&Marketing,2004,21(3):159–183. 32 Allen DK, Shoard M.Spreading the load: mobile informa⁃
22 KwonBC,KimSH,DuketT,etal.DoPeopleReallyEx⁃ tion and communications technologies and their effect on
perienceInformationOverloadWhileReadingOnlineRe⁃ informationoverload[J].InformationResearch-AnInterna⁃
views?[J].InternationalJournalofHuman-ComputerInter⁃ tionalElectronicJournal,2005,10(2):227-227.
action,2015,31(12):959-973. 33 Jones Q, Ravid G, Rafaeli S. Information overload and the
23 EllwartT,HappC,GurtnerA,etal.Managinginformation message dynamics of online interaction spaces: a theoretical
overload in virtual teams: Effects of a structured online model and empirical exploration[J]. Information Systems
team adaptation on cognition and performance[J]. Europe⁃ Research,2004,15(2):194-210.
an Journal of Work & Organizational Psychology,2015, 24 34 BenselinJC,RagsdellG.Informationoverload:Thediffer⁃
(5):311–317. ences that age makes[J]. Journal of Librarianship and Infor⁃
24 Sasaki Y, Kawai D, Kitamura S. The anatomy of tweet mationScience,2016,48(3):284-297.
overload: How number of tweets received, number of 35 Misra S, Stokols D. Psychological and Health Outcomes of
friends, and egocentric network density affect perceived in⁃ Perceived Information Overload[J]. Environment & Behav⁃
formation overload[J]. Telematics and Informatics,2015, 32 ior,2012,44(6):737-759.
(4):853-861. 36 Bawden D, Robinson L. The dark side of information:
25 PeiL,YunchuanS,YingwenCH.et.al.Estimatinguserin⁃ overload, anxiety and other paradoxes and pathologies[J].
fluence in online social networks subject to information JournalofInformationScience,2009,35(2):180-191.
overload[J]. International Journal of Modern Physics B, 37 PorcelC,CastilloJMMD,CoboMJ,etal.Animproved
2014,28(3):291-360. recommender system to avoid the persistent information
26 Liang H, Fu K. Information Overload, Similarity, and Re⁃ overload in a university digital library[J]. Control and Cy⁃
dundancy: Unsubscribing Information Sources on Twitter bernetics,2010,39(4):899-923.
[J]. Journal of Computer-Mediated Communication, 2017, 38 何 仲,张念照,吕廷杰.信息过载环境下网络消费者购
22(1):1-17. 买意愿的形成研究[J].价格理论与实践,2013,(4):95-96.
27 ZandtTV.InformationOverloadinaNetworkofTarget⁃ 39 王又然. 社交网络站点社群信息过载的影响因素研究
ed Communication[J]. Rand Journal of Economics, 2004, ——加权小世界网络视角的分[J]. 情报科学, 2015,(9):
35(3):542-560. 76-80.
28 Holton A E, Chyi H I. News and the overloaded consum⁃ 40 王 娜,任 婷.移动社交网站中的信息过载与个性化推
er: factors influencing informationoverload among news 荐机制研究[J].情报杂志,2015,(8):190-194.
（责任编辑：毛秀梅）
- 176 - --------------------------------------------------------------------------------- 第 42 卷 第 9 期 自 动 化 学 报 Vol.42, No.9
2016 年 9 月 ACTA AUTOMATICA SINICA September, 2016
图像理解中的卷积神经网络
常 亮1,2 邓小明3 周明全1,2 武仲科1,2 袁 野3,4 杨 硕3,4 王宏安3
摘 要 近年来, 卷积神经网络(Convolutional neural networks, CNN) 已在图像理解领域得到了广泛的应用, 引起了研究
者的关注. 特别是随着大规模图像数据的产生以及计算机硬件(特别是GPU) 的飞速发展, 卷积神经网络以及其改进方法在
图像理解中取得了突破性的成果, 引发了研究的热潮. 本文综述了卷积神经网络在图像理解中的研究进展与典型应用. 首先,
阐述卷积神经网络的基础理论; 然后, 阐述其在图像理解的具体方面, 如图像分类与物体检测、人脸识别和场景的语义分割等
的研究进展与应用.
关键词 卷积神经网络, 图像理解, 深度学习, 图像分类, 物体检测
引用格式 常亮, 邓小明, 周明全, 武仲科, 袁野, 杨硕, 王宏安. 图像理解中的卷积神经网络. 自动化学报, 2016, 42(9):
1300−1312
DOI 10.16383/j.aas.2016.c150800
Convolutional Neural Networks in Image Understanding
CHANG Liang1,2 DENG Xiao-Ming3 ZHOU Ming-Quan1,2 WU Zhong-Ke1,2 YUAN Ye3,4
YANG Shuo3,4 WANG Hong-An3
Abstract Convolutionalneuralnetworks(CNN)havebeenwidelyappliedtoimageunderstanding,andtheyhavearose
muchattentionfromresearchers. Specifically,withtheemergenceoflargeimagesetsandtherapiddevelopmentofGPUs,
convolutionalneuralnetworksandtheirimprovementshavemadebreakthroughsinimageunderstanding,bringingabout
wideapplicationsintothisarea. Thispapersummarizestheup-to-dateresearchandtypicalapplicationsforconvolutional
neuralnetworksinimageunderstanding. Wefirstlyreviewthetheoreticalbasis,andthenwepresenttherecentadvances
and achievements in major areas of image understanding, such as image classification, object detection, face recognition,
semantic image segmentation etc.
Key words Convolutional neural networks (CNN), image understanding, deep learning, image classification, object
detection
Citation Chang Liang, Deng Xiao-Ming, Zhou Ming-Quan, Wu Zhong-Ke, Yuan Ye, Yang Shuo, Wang Hong-An.
Convolutional neural networks in image understanding. Acta Automatica Sinica, 2016, 42(9): 1300−1312
1986 年, Rumelhart 等[1] 提出人工神经网络 练时间长的缺陷, 但是与基于规则的学习相比已
的反向传播算法 (Back propagation, BP), 掀起 经具有优越性. 基于统计学习理论的支持向量
了神经网络在机器学习中的研究热潮. 神经网 机[2]、Boosting、Logistic 回归方法可以被看作具
络中存在大量的参数, 存在容易发生过拟合、训 有一层隐节点或者不含隐节点的学习模型, 被称为
浅层机器学习模型. 浅层学习模型通常需要由人工
收稿日期2015-12-11 录用日期2016-05-03 方法获取好的样本特征, 在此基础上进行识别和预
ManuscriptreceivedDecember11,2015;acceptedMay3,2016 测, 因此方法的有效性很大程度上受到特征提取的
国家自然科学基金(61402040,61473276), 中国科学院青年创新促进
会资助
制约[3].
Supported by National Natural Science Foundation of China 2006 年, Hinton 等[4] 在Science上提出了深度
(61402040,61473276)andYouthInnovationPromotionAssoci-
ation,ChineseAcademyofSciences 学习. 这篇文章的两个主要观点是: 1) 多隐层的人
本文责任编委柯登峰 工神经网络具有优异的特征学习能力, 学习到的数
RecommendedbyAssociateEditorKEDeng-Feng
1. 北京师范大学信息科学与技术学院北京100875 2. 教育部虚拟 据更能反映数据的本质特征, 有利于可视化或分类;
现实应用工程研究中心北京100875 3. 中国科学院软件研究所人机 2) 深度神经网络在训练上的难度, 可以通过逐层无
交互北京市重点实验室北京100190 4. 中国科学院大学计算机与控
监督训练有效克服. 理论研究表明为了学习到可表
制学院北京100049
1. College of Information Science and Technology, Beijing 示高层抽象特征的复杂函数, 需要设计深度结构. 深
Normal University, Beijing 100875 2. Engineering Research
度结构由多层非线性算子构成, 典型设计是具有多
CenterofVirtualRealityandApplications, MinistryofEduca-
tion, Beijing 100875 3. Beijing Key Laboratory of Human- 层隐节点的神经网络. 随着网络层数的加大, 如何搜
ComputerInteractions,InstituteofSoftware,ChineseAcademy 索深度结构的参数空间成为具有挑战性的任务. 近
ofSciences,Beijing100190 4. SchoolofComputerandControl
年来, 深度学习取得成功的主要原因有: 1) 在训练
Engineering,UniversityofChineseAcademyofSciences,Beijing
100049 9期 常亮等: 图像理解中的卷积神经网络 1301
数据上, 大规模训练数据的出现 (如 ImageNet[5]), 序列的分析, 得到景物的尽可能完全正确的描述[13].
为深度学习提供了好的训练资源; 2) 计算机硬件的 图像理解与计算机视觉紧密相关, 研究内容交叉重
飞速发展(特别是GPU 的出现) 使得训练大规模神 合, 图像理解侧重在图像分析的基础上, 理解图像内
经网络成为可能. 与浅层学习模型相比, 深度学习构 容的含义以及解释原来的客观场景, 从而指导和规
造了具有多隐层的学习模型, 设计了有效的学习算 划行动[14]. 图像理解是深度学习应用最早的领域,
法并能够加速计算, 从而能够对大数据进行处理; 通 也是其应用最广的领域之一. 随着互联网大数据的
过深度学习能够得到更高层的特征, 从而提高样本 兴起, 深度学习在大规模图像的处理中显示了不可
的识别率或预测的准确率. 替代的优越性. 卷积神经网络的研究已经在图像理
卷积神经网络 (Convolutional neural net- 解中广泛应用[3]. 本文着重阐述卷积神经网络的理
works, CNN) 是一种带有卷积结构的深度神经网 论和面向图像理解几个不同方面的卷积神经网络的
络, 卷积结构可以减少深层网络占用的内存量, 也 提出、进展和应用, 包括: 图像分类和物体检测、人
可以减少网络的参数个数, 缓解模型的过拟合问题. 脸识别和验证、场景的语义分割和深度恢复、人体
1989 年, LeCun 等[6] 在手写数字识别中采用神经 关节检测, 通过这些介绍希望能帮助读者了解相关
网络误差反向传播算法, 在网络结构设计中加入下 工作的方法和思路并启发新的研究思路.
采样 (Undersampling) 与权值共享 (Weight shar- 表1 ImageNet 竞赛历年来图像分类任务的部分领先结果
ing). 1998 年, LeCun 等[7] 提出用于文档识别的卷 Table 1 Representative top ranked results in image
积神经网络, 为了保证一定程度的平移、尺度、畸 classification task of “ImageNet Large Scale Visual
变不变性, CNN 设计了局部感受野、共享权重和 Recognition Challenge”
空间或时间下采样, 提出用于字符识别的卷积神经
网络 LeNet-5. LeNet-5 由卷积层、下采样层、全 公布时间 机构 Top-5错误率(%)
2015.12.10 MSRA 3.57[15]
连接层构成, 该系统在小规模手写数字识别中取得
2014.8.18 Google 6.66[11]
了较好的结果. 2012 年, Krizhevsky 等[8] 采用称为 2014.8.18 Oxford 7.33[12]
AlexNet 的 CNN 在 ImageNet 竞赛图像分类任务 2013.11.14 NYU 11.7
2012.10.13 U.Toronto 16.4[8]
中取得了最好的成绩, 是 CNN 在大规模图像分类
中的巨大成功. AlexNet 网络具有更深层的结构, 并
1 卷积神经网络
设计了ReLU (Rectified linear unit) 作为非线性激
活函数以及Dropout 来避免过拟合. 在图像分类中, 卷积神经网络是深度学习的一种, 已成为当前
一个重要的图像数据库是 ImageNet[5]. 针对具有 图像理解领域的研究热点[6,16−17] 它的权值共享网
80000 个同义词的词汇网络(WordNet), ImageNet 络结构使之更类似于生物神经网络, 降低了网络模
旨在分别使用 500∼1000 个清晰的全分辨率图像 型的复杂度, 减少了权值的数量. 这个优点在网络的
来表示其中的大部分词汇, 这样就形成了上百万张 输入是多维图像时表现得更为明显, 图像可以直接
有标记的图像, 它们通过词汇网络的语义结构组织 作为网络的输入, 避免了传统识别算法中复杂的特
起来. ImageNet 总共包括 12 个子树、5247 个同 征提取和数据重建过程. 卷积网络是为识别二维形
义词集、320 万图像, 是目标检测、图像分类、图像 状而特殊设计的一个多层感知器, 这种网络结构对
定位研究的优越资源, ImageNet 在大规模、准确 平移、比例缩放以及其他形式的变形具有一定不变
度、分层结构方面为计算机视觉研究者提供了前所 性. 在典型的CNN 中, 开始几层通常是卷积层和下
未有的机会. 表 1 是 ImageNet 竞赛历年来图像分 采样层的交替, 在靠近输出层的最后几层网络通常
类任务的部分领先结果. 在 AlexNet 之后, 研究者 是全连接网络(如图1 所示). 卷积神经网络的训练
又进一步改善网络性能, 提出能有效分类检测的R- 过程主要是学习卷积层的卷积核参数和层间连接权
CNN (Region-based CNN)[9]、SPP (Spatial pyra- 重等网络参数, 预测过程主要是基于输入图像和网
midpooling)-net[10]、GoogLeNet[11]、VGG(Visual 络参数计算类别标签. 卷积神经网络的关键是: 网
geometry group)[12] 等. 为了更好地改进卷积神经 络结构(含卷积层、下采样层、全连接层等) 和反向
网络, 使其在应用中发挥更大的功效, 研究者不仅从 传播算法等.
应用的特殊性、网络的结构等方面进一步探讨卷积 在本节中, 我们先介绍典型 CNN 的网络结构
神经网络, 而且从其中的网络层设计、损失函数的设 和反向传播算法, 然后概述常用的其他 CNN 网络
计、激活函数、正则项等多方面对现有网络进行改 结构和方法. 神经网络参数的中文名称主要参考文
进, 取得了一系列成果. 献[18] 卷积神经网络的结构和反向传播算法主要参
计算机视觉的中心任务就是通过对图像或图像 考文献[17]. 1302 自 动 化 学 报 42卷
图1 卷积神经网络示例
Fig.1 Illustration of convolutional neural networks
1.1 网络结构 其中, ul 称为全连接层l 的净激活, 它由前一层输出
特征图 xl−1 进行加权和偏置后得到的. wl 是全连
1.1.1 卷积层
接网络的权重系数, bl 是全连接层l 的偏置项.
在卷积层, 上一层的特征图 (Feature map) 被
一个可学习的卷积核进行卷积, 然后通过一个激活 1.2 反向传播算法
函数 (Activation function), 就可以得到输出特征 神经网络有两类基本运算模式: 前向传播和学
图. 每个输出特征图可以组合卷积多个特征图的 习. 前向传播是指输入信号通过前一节中一个或多
值[17]: 个网络层之间传递信号, 然后在输出层得到输出的
xl j = f (cid:80)(ul j) 过程. 反向传播算法是神经网络有监督学习中的一
ul = xl−1∗kl +bl (1) 种常用方法, 其目标是根据训练样本和期望输出来
j i ij j
i∈Mj 估计网络参数. 对于卷积神经网络而言, 主要优化卷
其中, ul 称为卷积层l 的第j 个通道的净激活(Net 积核参数k、下采样层网络权重β、全连接层网络权
j
activation), 它通过对前一层输出特征图 xl−1 进行 重w 和各层的偏置参数b 等. 反向传播算法的本质
i
卷积求和与偏置后得到的, xl 是卷积层l 的第j 个 在于允许我们对每个网络层计算有效误差, 并由此
j
通道的输出. f(·) 称为激活函数, 通常可使用 sig- 推导出一个网络参数的学习规则, 使得实际网络输
moid 和tanh 等函数. M 表示用于计算ul 的输入 出更加接近目标值[18].
j j
特征图子集, kl 是卷积核矩阵, bl 是对卷积后特征 我们以平方误差损失函数的多分类问题为例介
ij j
图的偏置. 对于一个输出特征图xl, 每个输入特征图 绍反向传播算法的思路. 考虑一个多分类问题的训
j
xl−1 对应的卷积核kl 可能不同, “*” 是卷积符号. 练总误差, 定义为输出端的期望输出值和实际输出
i ij
值的差的平方[17]:
1.1.2 下采样层
下采样层将每个输入特征图通过下面的公式下 1
(cid:88)N
E(w,β,k,b) = (cid:107)t −y (cid:107)2 (4)
采样输出特征图[17]: 2 n n
n=1
xl = f(ul)
j j (2) 其中, t n 是第n 个样本的类别标签真值, y n 是第n
ul = βldown(xl−1)+bl 个样本通过前向传播网络预测输出的类别标签. 对
j j j j
于多分类问题, 输出类别标签常用一维向量表示, 即
其中, ul 称为下采样层 l 的第 j 通道的净激活, 它
j 输入样本对应的类别标签维度为正数, 输出类别标
由前一层输出特征图xl−1 进行下采样加权、偏置后
i 签的其他维为 0 或负数, 这取决于选择的激活函数
得到, β 是下采样层的权重系数, bl 是下采样层的偏
j 类型, 当激活函数选为sigmoid, 输出标签为0, 当激
置项. 符号down(·) 表示下采样函数, 它通过对输入
活函数为tanh, 输出标签为−1.
特征图xl−1 通过滑动窗口方法划分为多个不重叠的
j 反向传播算法主要基于梯度下降方法, 网络参
n×n 图像块, 然后对每个图像块内的像素求和、求
数首先被初始化为随机值, 然后通过梯度下降法向
均值或最大值, 于是输出图像在两个维度上都缩小
训练误差减小的方向调整. 接下来, 我们以多个“卷
了n 倍.
积层–采样层” 连接多个全连接层的卷积神经网络
1.1.3 全连接层 为例介绍反向传播算法.
在全连接网络中, 将所有二维图像的特征图拼 首先介绍网络第 l 层的灵敏度 (Sensitiv-
接为一维特征作为全连接网络的输入. 全连接层 l ity)[17−18]:
的输出可通过对输入加权求和并通过激活函数的响 ∂E
δl = (5)
应得到[17]: ∂ul
xl = f(ul) 其中, δl 描述了总误差 E 怎样随着净激活 ul 而变
(3)
ul = wlxl−1+bl 化. 反向传播算法实际上通过所有网络层的灵敏度 9期 常亮等: 图像理解中的卷积神经网络 1303
建立总误差对所有网络参数的偏导数, 从而得到使 其中, 对卷积核旋转 180 度使用卷积函数计算互相
得训练误差减小的方向. 关(在Matlab 中, 可用conv2 函数实现), 对卷积边
1.2.1 卷积层 界进行补零处理.
然后, 总误差对偏移量 b 的偏导与前面卷积层
为计算卷积层 l 的灵敏度, 需要用下一层下采
的一样, 只要对灵敏度中所有元素的灵敏度求和即
样层l+1 的灵敏度表示卷积层l 的灵敏度, 然后计
可:
算总误差 E 对卷积层参数 (卷积核参数 k、偏置参 ∂E (cid:88)
数b) 的偏导数. = (δl) (10)
∂bl j u,v
由于下采样层的灵敏度尺寸小于卷积层的灵敏 j u,v
度尺寸, 因此需要将下采样层l+1 的灵敏度上采样 对于下采样权重 β, 我们先定义下采样算子
到卷积层l 的灵敏度大小, 然后将第l 层净激活的激 dl = down(xl−1), 然后可通过下面的公式计算总误
j j
活函数偏导与从第 l +1 层的上采样得到的灵敏度 差E 对β 的偏导:
逐项相乘. 分别由式 (1) 和 (2), 通过链式求导可得
∂E (cid:88)
第l 层中第j 个通道的灵敏度[17]: = (δl ◦dl) (11)
∂βl j j u,v
∂E j u,v
δl = = βl+1(f(cid:48)(ul)◦up(δl+1)) (6)
j ∂ul j j j 这里我们假定下采样层的下一层为卷积层, 如
j
果下一层为全连接层, 也可以做类似的推导.
其中, up(·) 表示一个上采样操作, 符号◦ 表示每个
1.2.3 全连接层
元素相乘. 若下采样因子为n, 则up(·) 将每个像素
全连接层l 的灵敏度可通过下式计算:
在水平和垂直方向上复制n 次, 于是就可以从l+1
层的灵敏度上采样成卷积层 l 的灵敏度大小. 函数 δl = (wl+1)Tδl+1◦f(cid:48)(ul) (12)
up(·) 可以用Kronecker 乘积up(x) ≡ x⊗1 来
n×n
实现. 输出层的神经元灵敏度可由下面的公式计算:
然后, 使用灵敏度对卷积层 l 中的参数计算偏 δL = f(cid:48)(uL)◦(yn−tn) (13)
导. 对于总误差E 对偏移量bl 的偏导, 可以对卷积
j
层l 的灵敏度中所有节点进行求和来计算: 总误差对偏移项的偏导如下:
∂E (cid:88) ∂E ∂E ∂ul
= (δl) (7) = = δl (14)
∂bl j u,v ∂bl ∂ul ∂bl
j u,v
接下来可以对每个神经元运用灵敏度进行权值
对于总误差关于卷积核参数的偏导, 由式 (1),
更新. 对一个给定的全连接层l, 权值更新方向可用
使用链式求导时需要用所有与该卷积核相乘的特征
该层的输入xl−1 和灵敏度δl 的内积来表示:
图元素来求偏导:
∂E
∂E (cid:88) = xl−1(δl)T (15)
= (δl) (pl−1) (8) ∂wl
∂kl j u,v i u,v
ij u,v 1.2.4 网络参数更新过程
其中, (pl−1) 是在计算 xl 时, 与 kl 逐元素相乘 卷积层参数可用下式更新:
i u,v j ij
的xl−1 元素. ∂E
i ∆kl = −η (16)
1.2.2 下采样层 ij ∂kl
ij
为计算下采样层 l 的灵敏度, 需要用下一层卷
∂E
积层l+1 的灵敏度表示下采样层l 的灵敏度, 然后 ∆bl = −η (17)
∂bl
计算总误差E 对下采样参数权重系数β、偏置参数
下采样层参数可用下式更新:
b 的偏导数.
为计算我们需要下采样层 l 的灵敏度, 我们必 ∂E
∆βl = −η (18)
须找到当前层的灵敏度与下一层的灵敏度的对应点, ∂βl
这样才能对灵敏度δ 进行递推. 另外, 需要乘以输入
∂E
特征图与输出特征图之间的连接权值, 这个权值实 ∆bl = −η (19)
∂bl
际上就是卷积核的参数. 分别由式 (1) 和 (2), 通过
全连接层参数可用下式更新:
链式求导可得第l 层第j 个通道的灵敏度[17]:
∂E
δl = f(cid:48)(ul)◦conv2(δl+1,rot180(kl+1)(cid:48), full(cid:48)) (9) ∆wl = −η (20)
j j j j ∂wl 1304 自 动 化 学 报 42卷
其中, 对于每个网络参数都有一个特定的学习率 η. 积神经网络以其权值共享的特殊结构在图像理解领
若学习率太小, 则训练的速度慢; 若学习率太大, 则 域中有着独特的优越性, 通过权值共享降低了网络
可导致系统发散. 在实际问题中, 如果总误差在学习 的复杂性.
过程中发散, 那么将学习率调小; 反之, 如果学习速 总之, 卷积神经网络相比于一般神经网络在图
度过慢, 那么将学习率调大. 像理解中有其特殊的优点: 1) 网络结构能较好适应
图像的结构; 2) 同时进行特征提取和分类, 使得特
1.3 常用的其他网络结构和方法
征提取有助于特征分类; 3) 权值共享可以减少网络
1.3.1 卷积层
的训练参数, 使得神经网络结构变得更简单、适应性
传统卷积神经网络的卷积层采用线性滤波器与 更强.
非线性激活函数, 一种改进的方法在卷积层使用多
层感知机模型作为微型神经网络, 通过在输入图像 2 卷积神经网络在图像理解中的进展与应用
中滑动微型神经网络来得到特征图, 该方法能够增
本节将介绍卷积神经网络在图像分类与物体检
加神经网络的表示能力, 被称为 Network in net-
测、人脸识别和验证、语义图像分割等方面的进展
work[19]. 为了解决既能够保证网络的稀疏性, 又能
与应用.
够利用稠密矩阵的高性能计算, Szegedy 等[11] 提出
Inception 网络. Inception 网络的一层含有一个池 2.1 图像分类和物体检测
化操作和三类卷积操作: 1×1、3×3、5×5 卷积.
图像分类和物体检测是图像理解中的核心问题
1.3.2 池化
之一. 图像分类是指给定图像, 对图像的类别进行预
池化 (Pooling) 是卷积神经网络中一个重要 测; 物体检测是指对于图像中的同一物体或者同一
的操作, 它能够使特征减少, 同时保持特征的局 类别物体进行检测, 找到可能出现物体的区域.
部不变性. 常用的池化操作有: 空间金字塔池 在图像分类和物体检测中, 传统的方法包含基
化 (Spatial pyramid pooling, SPP)[10]、最大池化 于词袋(Bag of words, BOW) 的方法和基于变形模
(Max pooling)、平均池化(Mean pooling)、随机池 板模型(Deformablepartmodels, DPM)[23] 的方法
化(Stochastic pooling)[20] 等. 本文第1.1.2 节介绍 等. 这些方法虽然在某些特定应用(如人脸检测、行
的下采样层实际上也属于池化. 人检测等) 中取得了很好的效果, 但在准确性方面仍
1.3.3 激活函数 存在较大提升空间. 随着深度学习的兴起, 人们将
常 用 激 活 函 数 有: ReLU[8]、 Leakly 深度学习应用于图像分类和物体检测问题中, 并在
ReLU[21]、 Parametric ReLU、 Randomized 许多应用中取得明显好于传统方法的结果. 在图像
ReLU、ELU 等. 分类中, Krizhevsky 等[8] 提出了新型卷积神经网络
结构(AlexNet), GoogLeNet[11] 和VGG[12] 通过加
1.3.4 损失函数
深网络层数同时保证优化性能, 设计了更深层次的
损失函数的选择在卷积神经网络中起重要作
卷积神经网络. 在物体检测中, 研究者使用区域选
用, 代表性的损失函数有: 平方误差损失、互熵损失
择性搜索[9] 等技术提升检测的准确率, 通过加入感
(Cross entropy loss)、Hinge 损失等.
兴趣区域池化层(Region of interest (ROI) pooling
1.3.5 优化方法和技巧
layer)[24] 和空间金字塔池化[10] 等技术加速网络计
卷积神经网络常用的优化方法包含随机梯度 算速度. 此外, 也有一部分工作将卷积神经网络特征
下降方法 (Stochastic gradient descent, SGD), 常 与传统视觉识别模型结合起来. Girshick 等[25] 利用
用的技巧有权值初始化[8]、权值衰减 (Weight de- 深度学习的特征代替原有人工设计的方向梯度直方
cay)[18]、Batch normalization[22] 等. 图(Histogram of oriented gradient, HOG) 特征[26]
1.4 卷积神经网络的优势 建立变形模板, 提升了传统变形模板方法(DPM) 的
识别率, 并且在取得了与完全使用深度学习方法可
卷积神经网络在下采样层可以保持一定局部平
比结果的同时, 提升了检测速度. 表2 给出部分具有
移不变形, 在卷积层通过感受野和权值共享减少了
代表性的图像分类和物体检测模型对比.
神经网络需要训练的参数的个数. 每个神经元只需
接下来, 我们分别介绍面向图像分类和物体检
要感受局部的图像区域, 在更高层将这些感受不同
测任务的AlexNet 及代表性的改进方法、其他代表
局部区域的神经元综合起来就可以得到全局的信息.
性的改进方向.
因此, 可以减少网络连接的数目, 即减少神经网络需
2.1.1 AlexNet及代表性的改进方法
要训练的权值参数的个数. 由于同一特征通道上的
神经元权值相同, 所以网络可以并行学习, 这也是卷 Krizhevsky 等[8] 提出新型卷积神经网络结构
积网络相对于神经元彼此相连网络的一大优势. 卷 (简称为AlexNet, 其网络结构如图 2 所示), 并在 9期 常亮等: 图像理解中的卷积神经网络 1305
图2 AlexNet 卷积神经网络结构示意图[8]
Fig.2 Network architecture of AlexNet convolutional neural networks[8]
ImageNet ILSVRC-2012 图像分类问题中取得最好 于图像分类、定位和物体检测问题的统一, Overfeat
成绩 (Top-5 错误率为 15.3%), 其结果明显好于使 采用复用权重的方式, 即在每一个尺度上同时运行
用传统方法的第二名取得的结果 (Top-5 错误率为 分类网络和定位回归网络. 对于每一个尺度, 分类网
26.2%). 该方法训练了一个端对端(End to end) 的 络给出了图像块的类别概率分布, 回归网络进一步
卷积神经网络实现图像特征提取和分类, 网络结构 为每一类给出了包围盒和置信度. 最后, 综合这些信
共7 层, 包含5 层卷积层和2 层全连接层. AlexNet 息, 给出分类与检测结果. Overfeat 虽然提出了将分
在训练阶段使用了 Dropout 技巧, 并通过图像平 类、定位、检测任务一起解决的思想, 但这三个任务
移、图像水平翻转、调整图像灰度等方法扩充训练 在训练阶段仍是分开进行的[24].
数据集, 后者一方面通过扩充样本缓解了神经网络 AlexNet 用于物体检测时, 需要在图像金字塔
的过拟合以及对网络参数优化时陷入局部最优的 上采用滑动窗口的方式逐个判断, 随着图像的增大
问题, 也使得训练得到的网络对局部平移和光照变 待检测区域的数目呈平方上升. 为了解决这一问题,
化具有一定的不变性. 为了加快网络训练的速度, Girshick 等将候选框(Region proposals) 方法与卷
AlexNet 采用 ReLU 代替传统神经网络常用的激 积神经网络相结合 (Girshick 等称之为 R-CNN),
活函数 tanh/sigmod, ReLU 是一种非饱和非线性 采用仅对候选框逐个使用卷积神经网络判断的方
(Non-saturating nonlinearity) 变换. 式, 不仅提高了物体检测的效率, 也提高了检测的
Overfeat[27] 首次使用同一个模型完成图像分 精度, 在 VOC2012 上取得了当时最好的检测平均
类、定位和物体检测三个任务, 其主要观点是通过共 精度 mAP (Mean average precision), 把在该数据
享部分网络完成这三个任务, 能相互促进每个任务 集上的历史最好检测平均精度提高了约30%[9]. R-
的结果. Overfeat 继承了 AlexNet 的网络结构, 主 CNN 通过选择性搜索方法(Selective search)[28] 对
要区别在于: AlexNet 在提出时主要面向图像分类 图像进行过分割 (Over-segmentation) 得到大量分
任务, Overfeat 可以完成图像分类、定位和物体检 割块, 根据分割图像块之间的纹理相似性和位置关
测三个任务; Overfeat 在训练时输入固定大小的图 系对分割图像块进行合并, 可以得到许多连通的稳
像, 测试时用多尺度输入, 没有使用AlexNet 中的对 定区域. 由于这些稳定区域通常包含待检测物体, 也
比度归一化, 采用无重叠区域的最大池化, 前两层的 称之为候选区域. 对于这些候选区域 R-CNN, 通过
特征图更大. 对于分类与检测问题, 常采用滑动窗口 AlexNet 网络可以得到具有较强分辨力的特征, 最
对每一个图像块进行检测, 从而确定目标物体的类 后用这个特征进行分类. 该方法用于物体检测时, 为
别与位置, 即都需要一个滑动窗口对整幅图像进行 了提高物体定位精度, 采用了类似于 DPM 方法[23]
密集采样. 为提高计算效率, Overfeat 舍弃在图像 中使用的包围盒回归方法 (Bounding box regres-
层级的滑动, 转而在特征层级进行滑动, 明显减少了 sion). 与基于滑动窗口的物体检测方法相比, 使用
滑动窗口个数. 为了避免特征层级采样带来的稀疏 候选框将显著减少判断的窗口个数, 提高物体检测
问题, Overfeat 采用多次采样插值的方法解决. 对 效率; 此外通过调整候选框方法, 可以在保证召回率 1306 自 动 化 学 报 42卷
表2 部分具有代表性的图像分类和物体检测模型对比
Table 2 Comparison of representative image classification and object detection models
方法 输入 优点 缺点
整张图像(需要对图 网络简单易于训练,对图像分类有较强的鉴 网络输入图像要求固定大小,容易破环物体的
AlexNet[8]
像放缩到固定大小) 别力 纵横比和上下文信息
整张图像(需要对图 对图像分类拥有非常强的鉴别力,参数
GoogLeNet[11] 网络复杂,对样本数量要求较高,训练耗时
像放缩到固定大小) 相对AlexNet较少
整张图像(需要对图 网络复杂,对样本数量要求较高,训练耗时,需
VGG[12] 对图像分类拥有非常强的鉴别力
像放缩到固定大小) 要多次对网络参数的微调(Fine-tuning)
对物体检测拥有较强的鉴别力,对形变 使用人工设计的HOG特征[26];对物体检测的
DPM[23] 整张图像
和遮挡具有一定的处理能力 精度通常比本表中其他的CNN网络低
依赖于区域选择算法;网络输入图像要求固定
对物体检测拥有很强的鉴别力;比在图像 大小,容易破环物体的纵横比和上下文信息;
金字塔上逐层滑动窗口的物体检测方法效 训练是多阶段过程: 在特定检测数据集上对网
R-CNN[9] 图像区域 率高;使用包围盒回归(Boundingbox 络参数进行微调、提取特征、训练SVM(Sup-
regression)提高物体的定位精度 portvectormachine)分类器、包围盒回归
(Boundingboxregression);训练时间耗时、
耗存储空间
网络结构复杂时,池化对图像造成一定的信
对物体检测拥有很强的鉴别力,输入图像可 息丢失;SPP层前的卷积层不能进行网络参
SPP-net[10] 整张图像(不要求固 以任意大小,可保证图像的比例信息训练速 数更新[24];训练是多阶段过程: 在特定检测数
定大小) 度比R-CNN快3倍左右,测试比R-CNN 据集上对网络参数进行微调、提取特征、训练
快10∼100倍 SVM分类器、包围盒回归;训练时间耗时、
耗存储空间
训练和测试都明显快于SPP-net(除了候选
整张图像(不要求固 区域提取以外的环节接近于实时),对物体检
FastR-CNN[24] 定大小) 测拥有很强的鉴别力,输入图像可以任意大 依赖于候选区域选择,它仍是计算瓶颈
小,保证图像比例信息,同时进行分类与定位
比FastR-CNN更加快速,对物体检测拥有
整张图像(不要求固 很强的鉴别力;不依赖于区域选择算法;输入 训练过程较复杂;计算流程仍有较大优化空
FasterR-CNN[29] 定大小) 图像可以任意大小,保证图像比例信息,同时 间;难以解决被遮挡物体的识别问题
进行区域选择算法、分类与定位
的同时, 减少虚警 (False alarm), 进而提高物体检 尺寸的图像输入, 提出基于空间金字塔池化(Spatial
测精度. 在网络优化方面, R-CNN 采用AlexNet 网 pyramid pooling, SPP) 的网络层, SPP 层放在最
络参数作为初值, 利用训练图像的候选区域数据对 后一个卷积层后, 通过SPP 层可得到固定长度的输
网络参数进行微调 (Fine-tuning), 这种方式比随机 出, 然后送入并重新学习全连接网络层(这样的网络
选取网络参数初值具有更快的收敛速度, 所需样本 称为SPP-net). 使用的网络结构类似于AlexNet 的
也更少. 在物体检测问题中, R-CNN 比 AlexNet 7 层网络, 包含5 层卷积层和2 个全连接层网络, 主
有明显的优势, 但仍存在一些不足: 1) 全连接层 要区别是通过空间金字塔池化层连接卷积层与全连
(Full-connected layer) 只能接受固定尺寸的输入, 接层. 在该方法中, 对卷积第 5 层 conv5 输出的特
R-CNN 要求对候选框进行缩放或裁减填充到固定 征图分别进行1 等分、4 等分、9 等分, 然后在每个
大小, 这不仅会破坏物体的纵横比和图像大小信息, 分块进行池化操作(如Max pooling) 可得到定长的
也会破坏物体的上下文信息; 2) R-CNN 使用包围 特征. SPP 既可保证特征包含图像的整体信息 (1
盒回归有助于提高物体的定位精度, 但如果待检测 等分), 也保留了图像的局部信息(4 等分、9 等分及
物体存在遮挡或交叉时, 该方法很难提高定位精度. 更多等分), 由于特征是定长的, 无需关心空间金字
He 等[10] 针对之前卷积神经网络仅能接受固定 塔池化前的上层网络输出特征图尺寸, 可以直接传 9期 常亮等: 图像理解中的卷积神经网络 1307
递给全连接网络层. 因此, SPP 可以解除对输入图 积神经网络的一次系统尝试, 在 ILSVRC-2014 比
像大小固定的限制, 图像可以保留原有大小直接进 赛中获得第二名的成绩. 相比于传统浅层网络问
入网络进行训练与测试. 由于每张图像只需通过一 题 (5∼7 层), 网络随着层数的加深, 参数呈现指数
次 5 层前向卷积, 避免了 R-CNN 用于物体检测时 级增长, VGG 模型采用多层小窗口卷积核代替一
每个候选区域都需要通过5 层前向卷积的耗时计算, 个大卷积核的方式减少参数的增长. 如使用三层具
该方法于2014 年在VOC2007, Caltech101 数据集 有 3×3 卷积核的卷积层代替一层具有 7×7 卷积
上取得当时最好成绩, 并在速度上比 R-CNN 提高 核的卷积层, 如果通道数为 C, 那么一层具有 7×7
了24∼64 倍. 卷积核的卷积层共有 7×7×C×C = 49C ×C
与SPP-net 类似, Fast R-CNN[24] 也能用于不 个参数, 而三层具有 3×3 卷积核的卷积网络共有
同大小的图像上的物体检测, 提出感兴趣区域池化 3×(3×3)×C ×C = 27C ×C 个参数, 明显地减
(RoI pooling). Fast R-CNN 可以完成提取特征, 分 少了参数数目, 并且三层网络比一层网络更具有判
类和包围盒回归的端对端联合训练. 首先, 通过选 别性. 该方法还使用1×1 的卷积核[19], 可以在不影
择性搜索 (Selective search) 得到图像中的候选区 响卷积层感受野的情况下增加决策函数的非线性.
域 (文中称为 ROI), 对图像建立图像金字塔并通过
将卷积神经网络与传统视觉识别模型融合.
前向传播可得到 conv5 特征金字塔; 然后, 对于特
Felzenszwalb 等[23] 提出的变形模板模型 DPM 将
征金字塔每个尺度的每个 ROI, 在 conv5 特征中取
物体分解为多个可形变的基础语义组件, 这种目标
出对应的区域, 用一个称为 RoI pooling 的特殊单
检测方法融合物体整体信息, 语义组件信息与形变
层 SPP 来统一到同样的大小的特征. 最后, 经过
信息进行目标检测. 该方法结合了整体上下文信息
全连接层输出两任务的优化目标: 第一个任务是分
与局部信息, 对形变、遮挡都有很好的鲁棒性. 该
类, 第二个任务是包围盒回归. Fast R-CNN 相比
方法采用 HOG 特征[26], 但这种人工设计的特征不
SPP-net 的优势在于: SPP-net 中SPP 层前的卷积
能保证对物体检测有很好的鉴别力. Girshick 等[25]
层不能进行网络参数更新[24], 而Fast R-CNN 可以;
使用卷积神经网络的特征代替 HOG 这种人工设
SPP-net 为进行包围盒回归, 需要使用额外的回归
计的特征, 应用于可形变的组件模型 DPM, 该方法
模型 (如线性 SVM 等), 包围盒回归不能融入整个
被称为 DP-DPM (Deep pyramid DPM). 由于可
网络训练. Fast R-CNN 在除了候选区域提取以外
形变的组件模型本身的复杂性, 不能很好嵌入卷积
的环节接近于实时, 候选区域提取是计算中的瓶颈
神经网络中, DP-DPM 采用截断训练的方式, 使用
问题.
AlexNet 前 5 层网络得到具有强鉴别力的特征, 然
鉴于候选区域提取是 Fast R-CNN 的计算瓶
后把这些特征输入 DPM 中进行训练. DP-DPM
颈, Ren 等[29] 提出了用于实时目标检测的候选框网
与传统 DPM 模型相比平均精度 mAP 有着大幅提
络(Region proposal network, RPN), RPN 是一个
升, 与 R-CNN 相比 mAP 相近, 速度却明显快于
全卷积网络 (Fully convolutional network, FCN),
R-CNN.
它可以从任意尺寸的图像中得到一系列的带有分数
已有视觉目标识别方法通常依赖于含有大量标
(Objectness score) 的物体候选区域. RPN 能够生
注图像的训练数据, 基于包围盒的图像标注方法通
成高质量的候选区域, 并可以嵌入卷积神经网络中
常代价昂贵并且具有主观性. 近来, 提出了仅依赖于
进行端对端的训练. RPN 与 Fast R-CNN 结合并
图像级类别标注的弱监督卷积神经网络[31]. 该方法
共享卷积层特征的网络称为 Faster R-CNN, 它在
研究了 CNN 是否能够从仅标注目标信息而不标注
PASCAL VOC 2007、2012 和 MS COCO 数据集
目标位置的混杂图像场景中, 学习得到目标的定位
上取得了当时最好的检测结果, 并且整个计算过程
模型. 该方法对全监督网络结构进行了改进, 构造
接近于实时(使用较深的VGG模型也可达到5fps).
了基于图像级别标注数据构造端对端的弱监督卷积
2.1.2 其他代表性的改进方向 神经网络结构. 该网络的特点是: 在输出端增加全
局最大池化层来搜索最高得分的目标位置; 设计了
AlexNet 网络提出后, 许多工作开始关注改进
对图像中多个目标建模的损失函数. 基于PASCAL
CNN 的结构, 如在最初的若干个卷积层使用更小
的卷积窗口[19] 与卷积步长, 使用多尺度的训练与 VOC2012 和MS COCO 数据的大量实验表明该弱
测试数据等, 但仍基于浅层网络. Zeiler 等[30] 对 监督网络具有以下优点: 1) 能够输出精确的图像类
别标记; 2) 能够预测目标的近似位置; 3) 与基于目
网络中层特征和分类器进行可视化分析, 得到在
标包围盒标注训练的方法相比可得到相近的结果.
ImageNet 上分类效果优于 AlexNet 的网络结构
ZF-net. ZF-net 把 AlexNet 中第一层卷积核的大 对预处理部分进行了改进, 采用新的网络结
小由11×11 缩小为7×7, 把卷积步长由4 减小2, 构[10,24,29]、训练策略、提出有形变约束的池化层[32]
可得到更丰富的特征. VGG 模型[12] 是对深层卷 等改进方法. 在物体检测问题中, R-CNN 等算法依 1308 自 动 化 学 报 42卷
赖于额外的候选区域检测过程. 在 SPP-net[10] 与 神经网络的人脸识别方法使用了多层非线性特征变
Fast R-CNN[24] 中, 虽然候选区域检测的计算是一 换进行识别, 通常可取得明显优于传统方法的实验
个瓶颈问题, 通过共享整张图像的卷积层特征图, 物 结果[33].
体检测时间已明显缩减. 在 Fast R-CNN 的基础 DeepID 是一种用于人脸辨识的深度学习提取
上, Ren 等[29] 提出了候选框网络(Region proposal 高层特征方法[42], 将深度卷积网络最后隐层神经
network, RPN), 可以用于实时目标检测. 王晓刚 元的输出作为 DeepID 特征. 在训练中区分 10000
等[33] 研究了如何不依赖于人工设计特征和滑动窗 个类别的人脸并缩减特征抽取层的神经元数量, 深
口来提取感兴趣的目标, 该方法同时求解了两个任 度卷积网络将由一小部分隐层神经元逐步形成顶
务: 在图像中对感兴趣的目标快速定位; 基于定位的 层辨识相关特征. DeepID 在 LFW 数据上可得到
快速目标分割. 该方法提出一种联合学习框架, 在该 97.45% 的识别率. 传统人脸识别分为4 步: 人脸检
框架下每一个任务由一个多层卷积神经网络进行求 测、配准、表示、分类; 在 DeepFace[43] 中, 配准和
解, 两个网络合作来增强性能. 此外, Yan 等[34] 提 表示采用三维人脸模型用分段仿射变换得到, 分类
出了面向视觉识别的层次深度卷积神经网络. 将卷 器采用了一个 9 层神经网络. 该方法在包含 4000
积神经网络嵌入到一个两层分类结构中: 粗分类器 类的人脸图像数据库上进行训练, 在 LFW 数据得
和精细分类器. 首先得到基于部件的预训练, 然后由 到 97.35% 准确率, 在 YouTube 人脸数据 (YTF)
多项式 Logistic 损失正则项进行全局调优. 可选性 上能够缩减 50% 错误率. 人脸识别的关键是提出
精细分类器以及卷积神经网络参数的缩减使得层次 有效的特征来缩减同一人的差异并增大不同人之间
深度卷积神经网络对于大规模视觉识别可伸缩. 实 差异, 将人脸识别和人脸验证信号作为监督, 由设
验设计了两层次的深度卷积神经网络, 得到了较高 计的深度卷积网络可以学习到深度识别–验证特征
的识别率. Liu 等[35] 提出了稀疏卷积神经网络, 解 (DeepID2)[44]. 由于学习到的DeepID2 特征对于不
决了卷积神经网络中需要大量的参数计算、计算复 同的身份具有差异而对同一身份一致, 使得人脸识
杂度高的问题; 通过使用稀疏分解, 有效地缩减参数 别更加容易. 由学习得到的特征表示以及人脸识别
冗余. 在ILSVRC2012 数据进行实验, 缩减了90% 模型, 在 LFW 数据上达到了最高 99.15% 的人脸
参数, 仅仅损失1% 的准确性. 识别准确性.
随着待处理图像数据规模和场景复杂程度的 尽管基于卷积神经网络的人脸识别方法在
增加, 卷积神经网络可以演化出各种图像理解模 LFW 等测试数据上得到了较高的识别率, 但是与
型. 如面向局部对应点匹配的模型3DMatch[36] (局 基于传统方法的人脸识别方法类似, 基于 CNN 的
部小规模数据), 面向物体检测的模型 Deep sliding 人脸识别方法仍存在许多挑战性的问题, 如面部特
shapes[37] (物体级别中等规模数据), 和面向复杂场 征点定位、人脸、姿态等对人脸识别效果的影响, 都
景理解的新颖计算模型DeepContext[38] (场景级别 是需要深入研究的问题[45].
大规模数据) 等.
2.3 场景的语义分割和深度恢复
此外, 许多工作将卷积神经网络应用在与图像
分类和物体检测目标相近的新问题或应用上, 如细
场景的语义分割是指对于一幅图像中的每一个
粒度识别[39]、图像属性检测、实例检索、医学影像
像素给出其所属于的场景类别[46−48], 场景深度恢复
检测[40], 并且取得了良好的效果, 卷积神经网络已
是基于彩色或灰度图像恢复每个像素对应深度值的
成为许多视觉识别问题的首选.
问题, 两者实质都是对输入图像的每个像素进行分
已有的卷积神经网络在图像分类和物体检测领
类或回归, 已有方法集中在如何同时考虑单个像素
域取得一定的进展, 但仍面临许多的挑战: 1) 不断加
的预测以及场景蕴含的上下文约束.
深的深层神经网络保证了图像分类和物体检测的精
场景语义分割的参数化方法通常学习不同标注
度, 但也带来了巨大的计算压力, 如何快速精确地解
区域的外观 (Appearance) 和结构关系 (Structural
决问题是一个不小的挑战; 2) 在对于多物体相互交
relationship)[49−52], 这些方法扩展性往往不够好,
叉或相互遮挡时, 大多数方法都不能很好地处理; 3)
对新数据需要重新训练[53]. 场景语义分割的非参
运动模糊也会降低图像分类和物体检测的精度.
数化方法通常学习测试数据和训练数据间的差异
2.2 人脸识别和验证
模型, 将训练数据的语义标注转化为测试数据的预
人脸识别是指对输入图像的身份进行分类, 人 测[54−56], 逐个像素(Per-pixel) 或者超像素(Super-
脸验证是指区分一对图像是否属于同一身份 (可转 pixel) 分割, 使得最终结果依赖于超像素分割和假
化为一个二分类问题). 代表性的人脸识别方法包含 设的结果.
Eigenface、Fisherface 等子空间分析法[41], 通过比 Farabet 等[46] 使用多尺度的卷积神经网络对输
较人脸图像在低维空间的投影进行识别. 基于卷积 入图像进行特征提取, 并结合超像素划分和条件随 9期 常亮等: 图像理解中的卷积神经网络 1309
机场(Conditional random fields, CRF), 得到像素 S ), 将这些相似度度量输入一个全连接层得到相
pqk
语义的类别. 这种方法减小了对人工设计特征的需 似度值 R ; 将所有超像素预测的深度值和所有的
pq
求, 生成对于纹理、形状、上下文信息的有效表示. 超像素对的相似度值R 输入CRF 损失层计算网
pq
Pinheiro 等[57] 将场景分割与目标检测相结合, 联 络损失, 该损失函数的优化可直接使用反向传播方
合训练两个目标. Mohan[58] 在卷积神经网络中加入 法求解.
了反卷积层, 从而实现了一种端对端的场景语义分 已有的卷积神经网络已经能在一定程度上解决
割方法, 但是需要固定大小的输入. Long 等[59] 在 图像语义分割和深度恢复的问题, 为了得到更加精
此基础上提出一种端对端的全卷积神经网络 FCN 细和准确的结果, 需要根据特定的问题设计出能够
(Fully convolutional networks), 将全连接层变为核 更好满足上下文约束的网络结构.
大小为 1 的全卷积层, 使得 FCN 可以接受任意大
2.4 人体关节检测
小的输入. 该网络使用了池化–反卷积结构来保证
输出图像和输入图像具有相同的大小, 通过融合低 本节主要介绍使用卷积神经网络从图像中估计
层特征和高层特征得到具有更多细节的分割结果. 人体关节位置的方法. 基于人体关节点位置, 可以较
Zheng 等[60] 将条件随机场转变成为一种递归神经 为容易地恢复人体姿态信息. 已有方法通常使用关
网络 (Recurrent neural networks, RNN) 网络层, 节的空间位置约束、上下文约束来减少不合理的关
连接在FCN 之后, 对FCN 的结果进行平滑和优化, 节位置识别结果.
得到细节更具体更平滑的分割效果. Tompson 等[63] 直接从深度图像学习人手关节
Liu 等[53] 研究了一种半参数化人体服饰分割方 位置进而重建模型 (网络结构见图 3), 将卷积神经
网络应用于人手关节检测问题. 该方法提出了一个
法. 该方法不需要对数据进行预处理, 而且对新的
针对人手等链状物体的实时连续姿态估计系统, 通
标注数据(如新类别数据) 具有良好的扩展性. 在基
过可端对端训练的卷积神经网络得到人手关节点的
于K 近邻的非参数方法框架下, 参数化的匹配卷积
二维位置, 然后结合原始的深度图像重构人手姿态.
神经网络(Matchingconvolutionalneuralnetwork,
该方法分为三个阶段: 随机森林分类器分割出人手
MCNN) 根据K 近邻图像标注的语义区域, 在测试
区域; 卷积神经网络学习关节点位置; 使用逆向运
图像上能够找到最佳匹配区域, 并预测出匹配的置
动学 (Inverse kinematic, IK) 方法进行姿态恢复.
信度和位置偏移. 具体来说, 提取出输入图像中的人
Jain 等[64] 在Tompson 等方法[63] 的基础上加入关
体区域, 使用 K 近邻方法从训练库里找出 K 个近
节位置的空间约束, 提出一种新的人体姿态估计方
邻, 得到 K 个图像对, 每个图像对使用卷积神经网
法. 该方法结合了底层特征和高层弱结构模型, 由卷
络学习两者之间的相似性和位置偏差, 融合所有的
积神经网络来找出图像中身体关节的位置, 并加上
结果得到最终的划分结果. 最后采用超像素间平滑
身体各个部位的位置关系约束, 构成了一个对身体
性等方法对划分结果进行平滑处理.
姿态的描述. 训练多个卷积神经网络, 每个卷积神经
Eigen 等[61] 提出基于单幅图像的深度图和法向
网络输出关节位置的空间分布概率图. 采用滑动窗
图恢复以及场景语义分割的 CNN 网络. 该网络由
口方法, 将图像输入卷积神经网络可得到各个关节
三部分构成: 第一部分网络提取图像特征, 第二部分
的空间概率分布, 然后结合身体多个关节的位置约
网络得到低分辨率的预测结果, 第三部分网络得到
束优化关节位置, 该方法可减少不合理的关节位置.
高分辨率的预测结果, 第一部分和第二部分网络的
Oberweger 等[65] 对比了不同层数和结构的卷积神
结果经过上采样并结合卷积后的原始图像输入至第
经网络对关节位置的识别效果, 在多尺度卷积神经
三部分网络. 对于深度图和法向图恢复任务, 同时恢
网络、深的卷积神经网络、浅的卷积神经网络中加
复深度图和法向图的效果优于分别恢复这两个任务,
上三维姿态的先验信息, 可以显著提升关节位置识
完成对深度图和法向图的预测后, 输入原始图像、深
别效果. 该方法还通过加入关节点的上下文信息迭
度图和法向图即可进行语义分割. 对于语义分割, 基
于多通道输入(彩色图像、深度图和法向图) 的预测
结果优于基于单通道(彩色图像) 输入得到的结果.
Liu 等[62] 研究了将 CNN 和条件随机场 CRF
结合起来从单目图像预测深度的方法. 网络前面几
层网络用CNN 提取特征, 然后用条件随机场计算网
络的损失并反馈至前面几层网络. 将输入图像划分
为超像素, 以每个超像素为中心的一个图像块作为
图3 基于卷积神经网络的关节检测方法[63]
CNN 的输入, 得到预测的深度. 每组相邻的超像素
Fig.3 Hand joint detection with convolutional neural
对 (S ,S ) 计算 K 个相似度度量 (S , S , ···,
p q pq1 pq2 networks[63] 1310 自 动 化 学 报 42卷
代优化关节点的位置, 能使得关节估计结果更准确. 7 LeCun Y, Bottou L, Bengio Y, Haffner P. Gradient-based
这类方法的主要挑战在于如何解决人体肢体自遮挡 learning applied to document recognition. Proceedings of
theIEEE,1998,86(11): 2278−2324
导致的关节检测误差以及如何提高检测精度.
8 Krizhevsky A, Sutskever I, Hinton G E. ImageNet classi-
fication with deep convolutional neural networks. In: Pro-
3 总结和讨论
ceedingsofAdvancesinNeuralInformationProcessingSys-
tems25.LakeTahoe,Nevada,USA:CurranAssociates,Inc.,
本文阐述了卷积神经网络在图像理解, 特别是 2012.1097−1105
图像分类、物体检测、人脸识别、语义图像分割等领 9 Girshick R, Donahue J, Darrell T, Malik J. Rich feature
hierarchies for accurate object detection and semantic seg-
域的研究进展与典型应用. 图像理解也推动了卷积
mentation. In: Proceedings of the 2014 IEEE Conference
神经网络在网络结构、训练方法等方面的完善. 卷 on Computer Vision and Pattern Recognition. Columbus,
积神经网络虽然在一些数据上, 如 ImageNet 上取 USA:IEEE,2014.580−587
10 He K M, Zhang X Y, Ren S Q, Sun J. Spatial pyramid
得了成功, 但是如何针对实际特定问题、特定图像训
pooling in deep convolutional networks for visual recogni-
练库设计更有效的网络结构, 融合问题先验信息、从 tion. IEEE Transactions on Pattern Analysis and Machine
理论和应用上评估网络性能等都是需要深入研究的 Intelligence,2015,37(9):1904−1916
问题. 我们觉得可能的研究方向有: 11 SzegedyC,LiuW,JiaYQ,SermanetP,ReedS,Anguelov
D,ErhanD,VanhouckeV,RabinovichA.Goingdeeperwith
1) 卷积神经网络将卷积、池化与神经网络结合,
convolutions.In: Proceedingsofthe2015IEEEConference
有效地利用了图像的结构信息. 进一步, 如何有效利 onComputerVisionandPatternRecognition.Boston,MA:
IEEE,2015.1−9
用领域知识, 改进网络结构来获取视觉上的不变性
12 Simonyan K, Zisserman A. Very deep convolutional net-
值得引起关注;
works for large-scale image recognition [Online], available:
2) 在理论上, 如何在算法中利用深度模型的选 http://arxiv.org/abs/1409.1556,May16,2016
择性、稀疏性, 如何设计算法保证收敛性; 13 Forsyth D A, Ponce J. Computer Vision: A Modern Ap-
proach(2ndEdition).Boston: PearsonEducation,2012.
3) 目前, GoogLeNet, VGG 的网络结构已超过
14 Zhang Yu-Jin. Image Engineering (Part 2): III-Image Un-
20 层, 如何针对更大规模数据、更深结构网络设计
derstanding (3rd Edition). Beijing: Tsinghua University
高效的数值优化、并行计算方法和平台. Press,2012.
(章毓晋.图像工程(下册): III-图像理解.第3版.北京: 清华大学
随着理论和应用的深入研究, 卷积神经网络在
出版社,2012.)
图像理解中将会得到更好的应用.
15 He K M, Zhang X Y, Ren S Q, Sun J. Deep resid-
ual learning for image recognition [Online], available:
致谢 http://arxiv.org/abs/1512.03385,May3,2016
16 LeCun Y, Bottou L, Bengio Y, Haffner P. Gradient-based
感谢张寅达博士、白延成博士、王文中博士的 learning applied to document recognition. Proceedings of
帮助和讨论, 感谢审稿人的宝贵意见以及 NVIDIA theIEEE,1998,86(11): 2278−324
17 Bouvrie J. Notes On Convolutional Neural Networks, MIT
提供的Hardware Grant Program.
CBCLTechReport,Cambridge,MA,2006.
18 Duda R O, Hart P E, Stork D G [Author], Li Hong-Dong,
References
YaoTian-Xiang[Translator].PatternClassification.Beijing:
ChinaMachinePress,2003.
1 Rumelhart D E, Hinton G E, Williams R J. Learning
(DudaRO,HartPE,StorkDG[著],李宏东,姚天翔[译].模
representations by back-propagating errors. Nature, 1986,
式分类.北京: 机械工业出版社,2003.)
323(6088): 533−536
19 Lin M, Chen Q, Yan S C. Network in network. In: Pro-
2 VapnikVN.StatisticalLearningTheory.NewYork: Wiley, ceedings of the 2014 International Conference on Learning
1998. Representations. Banff, Canada: Computational and Bio-
logicalLearningSociety,2014.
3 WangXiao-Gang.Deeplearninginimagerecognition.Com-
20 ZeilerMD,FergusR.Stochasticpoolingforregularization
municationsoftheCCF,2015,11(8): 15−23
of deep convolutional neural networks [Online], available:
(王晓刚. 图像识别中的深度学习. 中国计算机学会通讯, 2015,
http://arxiv.org/abs/1301.3557,May16,2016
11(8): 15−23)
21 Maas A L, Hannun A Y, Ng A Y. Rectifier nonlinearities
4 HintonGE,SalakhutdinovRR.Reducingthedimensional- improveneuralnetworkacousticmodels.In: Proceedingsof
ityofdatawithneuralnetworks.Science,2006,313(5786): ICMLWorkshoponDeepLearningforAudio,Speech,and
504−507 LanguageProcessing.Atlanta,USA:IMLS,2013.
22 Ioffe S, Szegedy C. Batch normalization: accelerating deep
5 DengJ,DongW,SocherR,LiLJ,LiK,LiFF.ImageNet:
network training by reducing internal covariate shift. In:
alarge-scalehierarchicalimagedatabase.In: Proceedingsof
Proceedings of the 32nd International Conference on Ma-
the2009IEEEConferenceonComputerVisionandPattern
chineLearning.Lille,France: IMLS,2015.448−456
Recognition.Miami,FL:IEEE,2009.248−255
23 Felzenszwalb P, McAllester D, Ramanan D. A discrimina-
6 LeCunY,BoserB,DenkerJS,HendersonD,HowardRE, tively trained, multiscale, deformable part model. In: Pro-
HubbardW,JackelLD.Backpropagationappliedtohand- ceedings of the 2008 IEEE Conference on Computer Vi-
written zip code recognition. Neural Computation, 1989, sionandPatternRecognition.Anchorage,USA:IEEE,2008.
1(4): 541−51 1−8 9期 常亮等: 图像理解中的卷积神经网络 1311
24 GirshickR.FastR-CNN.In: Proceedingsofthe2015IEEE 39 ZhangN,DonahueJ,GirshickR,DarrellT.Part-basedR-
International Conference on Computer Vision. Santiago, CNNsforfine-grainedcategorydetection.In: Proceedingsof
Chile: IEEE,2015.1440−1448 the13thEuropeanConferenceonComputerVision.Zurich,
Switzerland: Springer,2014.834−849
25 GirshickR,IandolaF,DarrellT,MalikJ.Deformablepart
models are convolutional neural networks. In: Proceedings 40 Shin H C, Roth H R, Gao M C, Lu L, Xu Z Y, Nogues
ofthe2015IEEEConferenceonComputerVisionandPat- I, Yao J H, Mollura D, Summers R M. Deep convolutional
ternRecognition.Boston,MA:IEEE,2015.437−446 neural networks for computer-aided detection: CNN archi-
tectures,datasetcharacteristicsandtransferlearning.IEEE
26 DalalN,TriggsB.Histogramsoforientedgradientsforhu-
TransactionsonMedicalImaging,2016,35(5): 1285−1298
mandetection.In: Proceedingsofthe2005IEEEComputer
SocietyConferenceonComputerVisionandPatternRecog- 41 Belhumeur P N, Hespanha J P, Kriegman D J. Eigenfaces
nition.SanDiego,CA,USA:IEEE,2005.886−893 vs.fisherfaces: recognitionusingclassspecificlinearprojec-
tion. IEEE Transactions on Pattern Analysis and Machine
27 Sermanet P, Eigen D, Zhang X, Mathieu M, Fergus R, Le-
Intelligence,1997,19(7): 711−720
Cun Y. Overfeat: integrated recognition, localization and
detection using convolutional networks [Online], available: 42 Sun Y, Wang X G, Tang X O. Deep learning face repre-
http://arxiv.org/abs/1312.6229,May16,2016 sentationfrompredicting10,000classes.In: Proceedingsof
the2014IEEEConferenceonComputerVisionandPattern
28 UijlingsJRR,vandeSandeKEA,GeversT,SmeuldersA
Recognition.Columbus,USA:IEEE,2014.1891−1898
W M. Selective search for object recognition. International
JournalofComputerVision,2013,104(2): 154−171 43 TaigmanY,YangM,RanzatoMA,WolfL.Deepface: clos-
ingthegaptohuman-levelperformanceinfaceverification.
29 Ren S, He K, Girshick R, Sun J. Faster R-CNN: towards
In: Proceedingsofthe2014IEEEConferenceonComputer
real-timeobjectdetectionwithregionproposalnetworks.In:
Vision and Pattern Recognition. Columbus, USA: IEEE,
Proceedings of Advances in Neural Information Processing
2014.1701−1708
Systems28.Montr´eal,Canada: MIT,2015.91−99
44 SunY,WangYH,WangXG,TangXO.Deeplearningface
30 Zeiler M D, Fergus R. Visualizing and understanding con-
representation by joint identification-verification. In: Pro-
volutional networks. In: Proceedings of the 13th Euro-
ceedingsofAdvancesinNeuralInformationProcessingSys-
peanConferenceonComputerVision.Zurich,Switzerland:
tems 27. Montreal, Canada: Curran Associates, Inc., 2014.
Springer,2014.818−833
1988−1996
31 Oquab M, Bottou L, Laptev I, Sivic J. Is object localiza-
45 Shan Shi-Guang, Kan Mei-Na, Li Shao-Xin, Zhang Jie,
tionforfree?-weakly-supervisedlearningwithconvolutional
ChenXi-Lin.Faceimageanalysisandrecognitionwithdeep
neuralnetworks.In: Proceedingsofthe2015IEEEConfer-
learning.CommunicationsoftheCCF,2015,11(4): 15−21
enceonComputerVisionandPatternRecognition.Boston,
(山世光, 阚美娜,李绍欣, 张杰, 陈熙霖.深度学习在人脸分析与识
USA:IEEE,2015.685−694
别中的应用.中国计算机学会通讯,2015,11(4): 15−21)
32 OuyangWL,WangXG,ZengXY,QiuS,LuoP,TianYL,
46 Farabet C, Couprie C, Najman L, LeCun Y. Learning hi-
LiHS,YangS,WangZ,LoyCC,TangXO.Deepid-net:
erarchical features for scene labeling. IEEE Transactions
deformable deep convolutional neural networks for object
onPatternAnalysisandMachineIntelligence,2013,35(8):
detection.In: Proceedingsofthe2015IEEEConferenceon
1915−29
Computer Vision and Pattern Recognition. Boston, USA:
IEEE,2015.2403−2412 47 Yu Miao, Hu Zhan-Yi. Higher-order Markov random fields
and their applications in scene understanding. Acta Auto-
33 WangXiao-Gang,SunYi,TangXiao-Ou.Fromunifiedsub-
maticaSinica,2015,41(7): 1213−1234
spaceanalysistojointdeeplearning: progressoffacerecog-
(余淼, 胡占义. 高阶马尔科夫随机场及其在场景理解中的应用. 自
nitioninthelastdecade.CommunicationsoftheCCF,2015,
动化学报,2015,41(7): 1213−1234)
11(4): 8−14
(王晓刚, 孙衤韦, 汤晓鸥. 从统一子空间分析到联合深度学习: 人脸 48 GuoPing, QianYin, ZhouXiu-Ling.Imagesemanticanal-
识别的十年历程.中国计算机学会通讯,2015,11(4): 8−14) ysis.Beijing: SciencePress,2015.
(郭平,尹乾,周秀玲.图像语义分析.北京: 科学出版社,2015.)
34 YanZC,ZhangH,PiramuthuR,JagadeeshV,DeCosteD,
Di W, Yu Y Z. HD-CNN: hierarchical deep convolutional 49 YamaguchiK,KiapourMH,OrtizLE,BergTL.Parsing
neural networks for large scale visual recognition. In: Pro- clothinginfashionphotographs.In: Proceedingsofthe2012
ceedingsofthe2015IEEEInternationalConferenceonCom- IEEE Conference on Computer Vision and Pattern Recog-
puterVision.Boston,USA:IEEE,2015.2740−2748 nition.Providence,RI:IEEE,2012.3570−3577
35 LiuBY,WangM,ForooshH,TappenM,PenskyM.Sparse 50 LiuS,FengJS,DomokosC,XuH,HuangJS,HuZZ,Yan
convolutional neural networks. In: Proceedings of the 2015 SC.Fashionparsingwithweakcolor-categorylabels.IEEE
IEEE Conference on Computer Vision and Pattern Recog- TransactionsonMultimedia,2014,16(1): 253−265
nition.Boston,USA:IEEE,2015.806−814
51 Dong J, Chen Q, Shen X H, Yang J C, Yan S C. Towards
36 Zeng A, Song S, Nießner M, Fisher M, Xiao J. 3DMatch: unified human parsing and pose estimation. In: Proceed-
learning the matching of local 3D geometry in range scans ingsofthe2014IEEEConferenceonComputerVisionand
[Online], available: http://arxiv.org/abs/1603.08182, Au- PatternRecognition.Columbus,OH:IEEE,2014.843−850
gust11,2016
52 DongJ,ChenQ,XiaW,HuangZY,YanSC.Adeformable
37 Song S, Xiao J. Deep sliding shapes for amodal 3D object mixtureparsingmodelwithparselets.In: Proceedingsofthe
detection in RGB-D images. In: Proceedings of the IEEE 2013 IEEE International Conference on Computer Vision.
Conference on Computer Vision and Pattern Recognition. Sydney,Australia: IEEE,2013.3408−3415
LasVegas,USA:IEEE,2016.685−694
53 Liu S, Liang X D, Liu L Q, Shen X H, Yang J C, Xu C
38 Zhang Y, Bai M, Kohli P, Izadi S, Xiao J. Deep- S, Lin L, Cao X C, Yan S C. Matching-CNN meets KNN:
Context: context-encoding neural pathways for quasi-parametric human parsing. In: Proceedings of the
3D holistic scene understanding [Online], available: 2015 IEEE Conference on Computer Vision and Pattern
http://arxiv.org/abs/1603.04922,August11,2016 Recognition.Boston,MA:IEEE,2015.1419−1427 1312 自 动 化 学 报 42卷
邓小明 中国科学院软件研究所副研究
54 YamaguchiK,KiapourMH,BergTL.Paperdollparsing:
retrievingsimilarstylestoparseclothingitems.In: Proceed- 员. 主要研究方向为计算机视觉. 本文通
ings of the 2013 IEEE International Conference on Com- 信作者. E-mail: xiaoming@iscas.ac.cn
puterVision.Sydney,Australia: IEEE,2013.3519−3526 (DENG Xiao-Ming Associatepro-
55 LiuC,YuenJ,TorralbaA.Nonparametricsceneparsingvia fessorattheInstituteofSoftware,Chi-
label transfer. IEEE Transactions on Pattern Analysis and neseAcademyofSciences. Hismainre-
MachineIntelligence,2011,33(12): 2368−2382
searchinterestiscomputervision. Cor-
56 Tung F, Little J J. CollageParsing: nonparametric scene responding author of this paper.)
parsingbyadaptiveoverlappingwindows.In: Proceedingsof
the13thEuropeanConferenceonComputerVision.Zurich,
Switzerland: Springer,2014.511−525 周明全 北京师范大学信息科学与技术
57 Pinheiro P O, Collobert R, Dollar P. Learning to segment 学院教授. 主要研究方向为计算机可视
objectcandidates.In: ProceedingsofAdvancesinNeuralIn- 化技术, 虚拟现实.
formation Processing Systems 28. Montr´eal, Canada: Cur- E-mail: mqzhou@bnu.edu.cn
ranAssociates,Inc.,2015.1981−1989
(ZHOU Ming-Quan Professor at
58 MohanR.Deepdeconvolutionalnetworksforsceneparsing the College of Information Science and
[Online],available: http://arxiv.org/abs/1411.4101,May3,
Technology,BeijingNormalUniversity.
2016
Hisresearchinterestcoversinformation
59 Long J, Shelhamer E, Darrell T. Fully convolutional net- visualization and virtual reality.)
works for semantic segmentation. In: Proceedings of the
2015 IEEE Conference on Computer Vision and Pattern
Recognition.Boston,MA:IEEE,2015.3431−3440 武仲科 北京师范大学信息科学与技术
60 Zheng S, Jayasumana S, Romera-Paredes B, Vineet V, Su 学院教授. 主要研究方向为计算机图形
Z Z, Du D L, Huang C, Torr P H S. Conditional random 学, 计算机辅助几何设计, 计算机动画,
fields as recurrent neural networks. In: Proceedings of the
虚拟现实. E-mail: zwu@bnu.edu.cn
2015 IEEE International Conference on Computer Vision.
(WU Zhong-Ke Professor at the
Santiago,Chile: IEEE,2015.1529−1537
College of Information Science and
61 Eigen D, Fergus R. Predicting depth, surface normals and
Technology,BeijingNormalUniversity.
semanticlabelswithacommonmulti-scaleconvolutionalar-
His research interest covers computer
chitecture. In: Proceedings of the 2015 IEEE International
Conference on Computer Vision. Santiago, Chile: IEEE, graphics,computer-aideddesign,computeranimation,and
2015.2650−2658 virtual reality.)
62 LiuFY,ShenCH,LinGS.Deepconvolutionalneuralfields
fordepthestimationfromasingleimage.In: Proceedingsof
袁 野 中国科学院软件研究所硕士研
the2015IEEEConferenceonComputerVisionandPattern
Recognition.Boston,MA:IEEE,2015.5162−5170 究生. 主要研究方向为计算机视觉.
E-mail: yuanye13@mails.ucas.ac.cn
63 TompsonJ,SteinM,LecunY,PerlinK.Real-timecontinu-
(YUAN Ye Master student at the
ousposerecoveryofhumanhandsusingconvolutionalnet-
works.ACMTransactionsonGraphics(TOG),2014,33(5): InstituteofSoftware,ChineseAcademy
ArticleNo.169 of Sciences. His main research interest
64 Jain A, Tompson J, Andriluka M, Taylor G W, Bregler C. is computer vision.)
Learninghumanposeestimationfeatureswithconvolutional
networks.In: Proceedingsofthe2014InternationalConfer-
enceonLearningRepresentations.Banff,Canada: Compu- 杨 硕 中国科学院软件研究所硕士研
tationalandBiologicalLearningSociety,2014.1−14 究生. 主要研究方向为计算机视觉.
E-mail: yangshuo114@mails.ucas.ac.cn
65 Oberweger M, Wohlhart P, Lepetit V. Hands deep in deep
learning for hand pose estimation. In: Proceedings of the (YANGShuo Masterstudentatthe
20thComputerVisionWinterWorkshop(CVWW).Seggau, InstituteofSoftware,ChineseAcademy
Austria,2015.21−30 of Sciences. His main research interest
is computer vision.)
常 亮 北京师范大学信息科学与技术
学院副教授. 主要研究方向为计算机视 王宏安 中国科学院软件研究所研究员.
觉与机器学习. 主要研究方向为实时智能, 自然人机交
E-mail: changliang@bnu.edu.cn 互. E-mail: hongan@iscas.ac.cn
(CHANG Liang Associate profes- (WANGHong-An Professoratthe
sor at the College of Information Sci- InstituteofSoftware,ChineseAcademy
ence and Technology, Beijing Normal of Sciences. His research interest cov-
University. Herresearchinterestcovers ers real-time intelligence and natural
computer vision and machine learning.) human-computer interactions.) --------------------------------------------------------------------------------- 第４３卷 第５期 计 算 机 学 报 Ｖｏｌ．４３ Ｎｏ．５
２０２０年５月 ＣＨＩＮＥＳＥ ＪＯＵＲＮＡＬ ＯＦ ＣＯＭＰＵＴＥＲＳ Ｍａｙ ２０２０
图卷积神经网络综述
徐冰冰１），２），３） 岑科廷１），２），３） 黄俊杰１），２），３） 沈华伟１），２） 程学旗１），２）
１）（中国科学院网络数据科学与技术重点实验室 北京 １００１９０）
２）（中国科学院计算技术研究所 北京 １００１９０）
３）（中国科学院大学 北京 １０００４９）
摘 要 过去几年，卷积神经网络因其强大的建模能力引起广泛关注，在自然语言处理、图像识别等领域成功应
用．然而，传统的卷积神经网络只能处理欧氏空间数据，而现实生活中的许多场景，如交通网络、社交网络、引用网
络等，都是以图数据的形式存在．将卷积神经网络迁移到图数据分析处理中的核心在于图卷积算子的构建和图池
化算子的构建．本文对图卷积神经网络进行综述，首先介绍了图卷积神经网络的背景并梳理了两类经典方法———
谱方法和空间方法．针对图数据上平移不变性的缺失给图卷积算子的定义带来的困难，谱方法借助卷积定理在谱
域定义图卷积，而空间方法通过在节点域定义节点相关性来实现图卷积．进而，本文介绍了图卷积神经网络的最新
进展，这其中包括如何利用图卷积神经网络建模图上的复杂信息，如异质连接、高阶连接等，以及如何在大规模图
上实现图卷积神经网络；此外，本文介绍了图卷积神经网络的相关应用，包括推荐系统领域、交通预测领域等；最后
本文对图卷积神经网络的发展趋势进行了总结和展望．
关键词 图卷积神经网络；卷积；池化；非欧空间
中图法分类号 ＴＰ１８ ＤＯＩ号 １０．１１８９７／ＳＰ．Ｊ．１０１６．２０２０．００７５５
Ａ Ｓｕｒｖｅｙ ｏｎ Ｇｒａｐｈ Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ
ＸＵ Ｂｉｎｇ－Ｂｉｎｇ１），２），３） ＣＥＮ Ｋｅ－Ｔｉｎｇ１），２），３） ＨＵＡＮＧ Ｊｕｎ－Ｊｉｅ１），２），３）
ＳＨＥＮ Ｈｕａ－Ｗｅｉ １），２） ＣＨＥＮＧ Ｘｕｅ－Ｑｉ １），２）
１）（Ｋｅｙ Ｌａｂｏｒａｔｏｒｙ ｏｆ Ｎｅｔｗｏｒｋ Ｄａｔａ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ，Ｂｅｉｊｉｎｇ １００１９０）
２）（Ｉｎｓｔｉｔｕｔｅ ｏｆ Ｃｏｍｐｕｔｉｎｇ Ｔｅｃｈｎｏｌｏｇｙ，Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ，Ｂｅｉｊｉｎｇ １００１９０）
３）（Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ，Ｂｅｉｊｉｎｇ １０００４９）
Ａｂｓｔｒａｃｔ Ｉｎ ｔｈｅ ｐａｓｔ ｆｅｗ ｙｅａｒｓ，ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｈａｓ ａｔｔｒａｃｔｅｄ ｗｉｄｅｓｐｒｅａｄ ａｔｔｅｎｔｉｏｎ
ｄｕｅ ｔｏ ｉｔｓ ｐｏｗｅｒｆｕｌ ｍｏｄｅｌｉｎｇ ｃａｐａｂｉｌｉｔｉｅｓ，ａｎｄ ｈａｓ ａｃｈｉｅｖｅｄ ｇｒｅａｔ ｉｍｐｒｏｖｅｍｅｎｔ ｉｎ ａｒｅａｓ ｓｕｃｈ ａｓ
ｎａｔｕｒａｌ ｌａｎｇｕａｇｅ ｐｒｏｃｅｓｓｉｎｇ ａｎｄ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ．Ｔｒａｄｉｔｉｏｎａｌ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｃａｎ
ｏｎｌｙ ｐｒｏｃｅｓｓ Ｅｕｃｌｉｄｅａｎ ｄａｔａ．Ｈｏｗｅｖｅｒ，ｍａｎｙ ｒｅａｌ－ｌｉｆｅ ｓｃｅｎａｒｉｏｓ，ｓｕｃｈ ａｓ ｔｒａｎｓｐｏｒｔａｔｉｏｎ ｎｅｔｗｏｒｋｓ，
ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ ａｎｄ ｃｉｔａｔｉｏｎ ｎｅｔｗｏｒｋｓ，ａｒｅ ｌｏｃａｔｅｄ ｉｎ ｔｈｅ ｆｏｒｍ ｏｆ ｇｒａｐｈ ｄａｔａ．Ｔｈｅ ｍｅｔｈｏｄ ｕｓｅｄ
ｔｏ ｐｒｏｃｅｓｓ ｇｒａｐｈ ｄａｔａ ｐｒｅｖｉｏｕｓｌｙ ｉｓ ｎｅｔｗｏｒｋ ｅｍｂｅｄｄｉｎｇ．Ｓｐｅｃｉｆｉｃａｌｌｙ，ｔｈｅ ｒｅｓｅａｒｃｈｅｒｓ ｍｏｄｅｌ ｔｈｅ
ｇｒａｐｈ－ｂａｓｅｄ ｍｉｓｓｉｏｎ ｉｎｔｏ ａ ｔｗｏ－ｓｔａｇｅ ｍｏｄｅｌ．Ｉｎ ｔｈｅ ｆｉｒｓｔ ｓｔａｇｅ，ａ ｆｉｘｅｄ－ｌｅｎｇｔｈ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｉｓ
ｌｅａｒｎｅｄ ｆｏｒ ｅａｃｈ ｎｏｄｅ ｖｉａ ｃａｐｔｕｒｉｎｇ ｔｈｅ ｐｒｏｘｉｍｉｔｙ ｏｖｅｒ ｎｏｄｅｓ，ｔｈｉｓ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｉｓ ｆｅｄ ｉｎｔｏ ｔｈｅ
ｓｅｃｏｎｄ ｓｔａｇｅ ｔｏ ｓｏｌｖｅ ｄｏｗｎｓｔｒｅａｍ ｔａｓｋｓ，ｅ．ｇ．，ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ，ｎｏｄｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ａｎｄ ｇｒａｐｈ
ｃｌａｓｓｉｆｉｃａｔｉｏｎ．Ｉｎ ｒｅｃｅｎｔ ｙｅａｒｓ，ｔｈｅ ｐｏｗｅｒｆｕｌ ｍｏｄｅｌｉｎｇ ｃａｐａｂｉｌｉｔｉｅｓ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ
收稿日期：２０１９－０５－０６；在线出版日期：２０１９－１１－０４．本课题得到国家自然科学基金项目（６１４２５０１６，９１７４６３０１）、北京智源人工智能研究院
和王宽诚教育基金会资助．徐冰冰，博士研究生，中国计算机学会（ＣＣＦ）学生会员，主要研究方向为图神经网络、图上半监督学习．Ｅ－
ｍａｉｌ：ｘｕｂｉｎｇｂｉｎｇ＠ｉｃｔ．ａｃ．ｃｎ．岑科廷（共同第一作者），博士研究生，中国计算机学会（ＣＣＦ）学生会员，主要研究方向为网络表示学习、图
神经网络．Ｅ－ｍａｉｌ：ｃｅｎｋｅｔｉｎｇ＠ｉｃｔ．ａｃ．ｃｎ．黄俊杰（共同第一作者），硕士研究生，主要研究方向为社会媒体计算、图神经网络．Ｅ－ｍａｉｌ：
ｈｕａｎｇｊｕｎｊｉｅ１７ｓ＠ｉｃｔ．ａｃ．ｃｎ．沈华伟（通信作者），博士，研究员，中国计算机学会（ＣＣＦ）高级会员，主要研究领域为社交网络分析和社会媒
体计算．Ｅ－ｍａｉｌ：ｓｈｅｎｈｕａｗｅｉ＠ｉｃｔ．ａｃ．ｃｎ．程学旗，博士，研究员，中国计算机学会（ＣＣＦ）会士，主要研究领域为大数据分析与挖掘、网络科
学、网络信息安全以及互联网搜索与数据挖掘．
书书书 ７５６ 计 算 机 学 报 ２０２０年
ａｎｄ ｔｈｅ ｕｂｉｑｕｉｔｙ ｏｆ ｇｒａｐｈ ｄａｔａ ｈａｖｅ ｉｎｓｐｉｒｅｄ ｒｅｓｅａｒｃｈｅｒｓ ｔｏ ｔｒａｎｓｆｅｒ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ
ｔｏ ｇｒａｐｈｓ，ｗｈｉｃｈ ｃａｎ ｓｏｌｖｅ ｔｈｅ ｇｒａｐｈ－ｂａｓｅｄ ｔａｓｋ ｖｉａ ａｎ ｅｎｄ－ｔｏ－ｅｎｄ ｍａｎｎｅｒ．Ｔｈｅ ｃｏｒｅ ｏｆ ｇｒａｐｈ
ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｉｓ ｔｈｅ ｃｏｎｓｔｒｕｃｔｉｏｎ ｏｆ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ ｏｐｅｒａｔｏｒ ａｎｄ ｐｏｏｌｉｎｇ ｏｐｅｒａｔｏｒ．
Ｉｎ ｔｈｉｓ ｐａｐｅｒ，ｗｅ ｒｅｖｉｅｗ ｔｈｅ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ．Ｆｉｒｓｔｌｙ，ｔｈｅ ｂａｃｋｇｒｏｕｎｄ ｏｆ
ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｎｄ ｉｔｓ ｃｌａｓｓｉｃａｌ ｍｅｔｈｏｄｓ ａｒｅ ｉｎｔｒｏｄｕｃｅｄ，ｉｎｃｌｕｄｉｎｇ ｓｐｅｃｔｒａｌ
ｍｅｔｈｏｄｓ ａｎｄ ｓｐａｔｉａｌ ｍｅｔｈｏｄｓ．Ｔｈｅ ｌａｃｋ ｏｆ ｔｒａｎｓｌａｔｉｏｎ ｉｎｖａｒｉａｎｃｅ ｏｎ ｔｈｅ ｇｒａｐｈ ｄａｔａ ｍａｋｅｓ ｉｔ ｄｉｆｆｉｃｕｌｔ
ｔｏ ｄｅｆｉｎｅ ｔｈｅ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ ｏｐｅｒａｔｏｒ．Ｔｈｅ ｓｐｅｃｔｒａｌ ｍｅｔｈｏｄｓ ｄｅｆｉｎｅ ｔｈｅ ｃｏｎｖｏｌｕｔｉｏｎ ｉｎ ｔｈｅ ｓｐｅｃｔｒａｌ
ｄｏｍａｉｎ ｖｉａ ｔｈｅ ｃｏｎｖｏｌｕｔｉｏｎ ｔｈｅｏｒｅｍ，ｗｈｉｌｅ ｔｈｅ ｓｐａｔｉａｌ ｍｅｔｈｏｄｓ ｉｍｐｌｅｍｅｎｔ ｔｈｅ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ
ｂｙ ｄｅｆｉｎｉｎｇ ｔｈｅ ｎｏｄｅ ｃｏｒｒｅｌａｔｉｏｎ ｉｎ ｔｈｅ ｎｏｄｅ ｄｏｍａｉｎ．Ｔｈｅｎ，ｔｈｅ ｌａｔｅｓｔ ｄｅｖｅｌｏｐｍｅｎｔｓ ａｒｅ ｉｎｔｒｏｄｕｃｅｄ．
Ｒｅｃｅｎｔ ｒｅｓｅａｒｃｈｅｒｓ ｆｏｃｕｓ ｏｎ ｈｏｗ ｔｏ ｍｏｄｅｌ ｔｈｅ ｃｏｍｐｌｉｃａｔｅｄ ｉｎｆｏｒｍａｔｉｏｎ ｏｎ ｇｒａｐｈ ｖｉａ ｇｒａｐｈ
ｃｏｎｖｏｌｕｔｉｏｎ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ，ｅ．ｇ．，ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｃｏｎｎｅｃｔｉｏｎ ａｎｄ ｈｉｇｈ－ｏｒｄｅｒ ｃｏｎｎｅｃｔｉｏｎ．Ｉｎ
ａｄｄｉｔｉｏｎ，ｈｏｗ ｔｏ ｃｏｎｓｔｒｕｃｔ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｏｎ ｌａｒｇｅ－ｓｃａｌｅ ｎｅｔｗｏｒｋ ａｌｓｏ ａｔｔｒａｃｔｓ
ｍｕｃｈ ａｔｔｅｎｔｉｏｎ．Ｍｏｒｅｏｖｅｒ，ｗｅ ｃｏｎｃｌｕｄｅ ｔｈｅ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｉｎ ｍａｎｙ ａｐｐｌｉｃａｔｉｏｎｓ，
ｉｎｃｌｕｄｉｎｇ ｔｒａｆｆｉｃ ｐｒｅｄｉｃｔｉｏｎ ａｎｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ．Ｆｉｎａｌｌｙ，ｔｈｅ ｄｅｖｅｌｏｐｉｎｇ ｔｒｅｎｄ ｏｆ ｇｒａｐｈ
ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｉｓ ｓｕｍｍａｒｉｚｅｄ ａｎｄ ｆｏｒｅｃａｓｔｅｄ．
Ｋｅｙｗｏｒｄｓ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ；ｃｏｎｖｏｌｕｔｉｏｎ；ｐｏｏｌｉｎｇ；ｎｏｎ－Ｅｕｃｌｉｄｅａｎ ｓｐａｃｅ
始关注如何在图上构造深度学习模型．借助于卷积
１ 引 言 神经网络对局部结构的建模能力及图上普遍存在的
节点依赖关系，图卷积神经网络成为其中最活跃最
过去几年，卷积神经网络［１－２］快速发展，并借由 重要的一支．近期陆续涌现出一些文章探索图上深
其强大的建模能力引起广泛关注．相比传统方法，卷 度学习并对其进行综述［８－９］，但是针对其中最重要的
积神经网络的引入给图像处理［３］和自然语言处理等 分支，图卷积神经网络，其建模方法和应用方面的深
领域带来了很大的提升，如机器翻译［４］、图像识别［５］ 入探讨和总结仍为空白．对此，我们在本篇文章中深
和语音识别［６］等．但是，传统的卷积神经网络只能处 入整理总结了图卷积神经网络的发展历程及其未来
理欧氏空间数据（如图像、文本和语音），这些领域的 趋势．
数据具有平移不变性．平移不变性使得我们可以在 图卷积神经网络的构建所面临的挑战主要来源
输入数据空间定义全局共享的卷积核，从而定义卷 于以下几个方面：
积神经网络．以图像数据为例，一张图片可以表示为 （１）图数据是非欧空间数据
欧氏空间中一组规则散布的像素点，平移不变性则 图数据作为非欧空间数据，不满足平移不变性，
表示以任意像素点为中心，可以获取相同尺寸的局 即每个节点具有各异的局部结构．而传统卷积神经
部结构．基于此，卷积神经网络通过学习在每个像素 网络中的基本算子：卷积和池化，依赖于数据的平移
点共享的卷积核来建模局部连接，进而为图片学习 不变性．此时如何在图数据上定义卷积和池化算子
到意义丰富的隐层表示． 成为一个有挑战的工作．
尽管传统的卷积神经网络在文本和图像领域带 （２）图数据具有多样的特性
来提升，但是它仅能处理欧氏空间数据．而同时，一 实际生活中的多种应用都可以用图数据自然的
种非欧空间数据：图数据，因其普遍存在性逐渐受到 表示，这使得图数据具有多样的特性，如社交网络中
关注．图数据可以自然的表达实际生活中的数据结 用户的有向连接，引文网络中作者和引文的异质连
构，如交通网络、万维网和社交网络等．不同于图像 接，政治关系网络中的正负倾向带符号连接等．多样
和文本数据，图数据中每个节点的局部结构各异，这 的图特性给图卷积神经网络的构建带来更多信息，
使得平移不变性不再满足［７］．平移不变性的缺失给 但是多种特性的建模也要求图卷积神经网络的设计
在图数据上定义卷积神经网络提出了挑战． 更加复杂精细，给图卷积神经网络带来新的挑战．
近年来，由于图数据的普遍存在性，研究人员开 （３）图数据的规模很大 ５期 徐冰冰等：图卷积神经网络综述 ７５７
在大数据时代，实际应用中的图可能规模极大， 网络则是其中最活跃的一支．
含有百万甚至千万级别的节点，如推荐系统中的用 在建模图卷积神经网络时，研究人员关注如何
户商品网络，社交网络中的用户网络．如何在时间和 在图上构建卷积算子．Ｂｒｕｎａ等人［１７］在２０１３年提出
空间可接受范围内在大规模图上构建图卷积神经网 第一个图卷积神经网络，他们基于图谱理论从卷积
络也是非常大的挑战． 定理出发，在谱空间定义图卷积．这一支后来发展为
１．１ 现有方法及分类 图卷积领域的谱方法．最初的谱方法具有时空复杂
图数据建模的历史由来已久．起初，研究人员关 度较高的弊端，ＣｈｅｂＮｅｔ［１８］和 ＧＣＮ［１９］对谱方法中
注统计分析的方法，这个时期没有机器学习模型的参 的卷积核进行参数化，大大降低了时空复杂度．这两
与，如网页排序的常用算法ＰａｇｅＲａｎｋ［１０］、ＨＩＴＳ［１１］ 个方法虽然被归为谱方法，但已经开始从空间角度
等．此外，研究人员也借用图谱理论的知识，如用拉 定义节点的权重矩阵．在这两个方法的启发下，空间
普拉斯矩阵的特征值和特征向量做社区分析或者人 方法应用而生，开始考虑在节点域用注意力机制、序
群聚类［１２］等．随着深度学习的崛起，研究人员开始 列化模型等建模节点间的权重．这一时期的图卷积
考虑把深度学习的模型引入到图数据中，代表性的 神经网络在构建卷积算子过程中没有过多的考虑图
研究工作是网络嵌入（Ｎｅｔｗｏｒｋ Ｅｍｂｅｄｄｉｎｇ）［１３］，即 特性，随着卷积算子的逐渐完善，人们开始考虑多样
通过约束节点的邻近性为每个节点学习固定长度的 的图特性，如开始关注如何建模图上的高阶信息，并
表达，如ＤｅｅｐＷａｌｋ［１４］、ＬＩＮＥ［１５］、ｎｏｄｅ２ｖｅｃ［１６］等．这 分别针对边上带特征的图、异质图等进行精细设计．
一时期，在解决具体的应用问题时，研究人员通常将 此外，如何训练更高效的图卷积神经网络也受到广
其建模为两阶段问题，以节点分类为例，第一阶段为 泛关注．研究人员开始试图训练更深层的图卷积神
每个节点学习统一长度的表达，第二阶段将节点表 经网络，以增强模型的泛化能力．同时，模型到大规
达作为输入，训练分类模型．近年来，研究人员对图 模图的可扩展性以及训练的速度也是图卷积神经网
数据建模的关注逐渐转移到如何将深度学习的模型 络中非常重点的研究方向．表１展示了图卷积神经
迁移到图数据上，进行端到端的建模，而图卷积神经 网络的主要方法．
表１ 图卷积神经网络的主要方法
关注领域 方法 相关论文
Ｓｐｅｃｔｒａｌ ＣＮＮ［１７］，ＣｈｅｂｙＮｅｔ［１８］，ＧＣＮ［１９］，Ｈｅｎａｆｆ等人［２０］，ＧＷＮＮ［２１］，ＧｒａｐｈＨｅａｔ［２２］，
基于卷积定理的图卷积神经网络
关注卷积 ＰＰＮＰ［２３］，ＳＰＣ［２４］
算子构建 ＭｏＮｅｔ［２５］，ＭＰＮＮｓ［２６］，ＧＮＮｓ［２７］，ＧＡＴ［２８］，ＧｒａｐｈＳＡＧＥ［２９］，ＤＣＮＮ［３０］，ＣｏｎｆＧＣＮ［３１］，
基于聚合函数的图卷积神经网络
ＨＧＮＮ［３２］
关注图上复杂 建模边上信息的图卷积神经网络 Ｒ－ＧＣＮｓ［３３］，Ｒ－ＧＡＴ［３４］，ＳＧＣＮ［３５］，ＤＰＧＣＮＮ［３６］，ＥＧＡＴ［３７］，ＥＣＣ［３８］
信息建模 建模高阶信息的图卷积神经网络 ＨＡ－ＧＣＮ［３９］，Ｍｏｔｉｆ－ＣＮＮ［４０］，ＨＡＮ［４１］，ＭＣＮ［４２］，Ｍｏｔｉｆ－Ｎｅｔ［４３］
关注训练 深层图卷积神经网络 Ｊｕｍｐｉｎｇ Ｋｎｏｗｌｅｄｇｅ Ｎｅｔｗｏｒｋ［４４］，Ｃｏ－Ｔｒａｉｎ［４５］
过程优化 大规模图卷积神经网络 ＧｒａｐｈＳＡＧＥ［２９］，ＰｉｎＳａｇｅ［４６］，Ｃｏｎｔｒｏｌ Ｖａｒｉａｔｅ Ｂａｓｅｄ Ａｌｇｏｒｉｔｈｍ（ＣＶ）［４７］，ＦａｓｔＧＣＮ［４８］，Ａｄａｐｔ［４９］
池化算子作为卷积神经网络的主要组成部分， １．３ 章节组织
作用是扩大感受野，降低参数．近期，也有研究开始 本文第２节给定全文的符号定义；第３节回顾
关注图上池化算子的构建．图上池化算子主要用于
初期图卷积网络中卷积算子和池化算子的定义，其
图分类问题，目的是学习到图的层级结构．
中卷积算子定义部分又包括了空间方法和谱方法；
第４节主要关注图卷积神经网络的一些新进展，包
１．２ 任务
括图特性建模和训练优化两个部分；第５节我们详
图数据建模所针对的应用场景非常广泛，这也
细介绍了图卷积神经网络在现有各种典型应用下图
使得图数据建模所处理的任务多样．我们将下游任
的构造及卷积的定义；在第６节和第７节中，我们给
务分为节点级别的任务和图级别的任务，节点级别
出图卷积神经网络的未来发展展望，并总结全文．
的任务包括节点分类，链接预测等，如引文网络中的
文章分类，推荐系统中用户对商品的偏好推断．图级 ２ 符号定义
别的任务包括图生成，图分类等，如药物网络生成，
蛋白质网络中的蛋白质分类． 在这一节中，我们给出文中常见符号的定义． ７５８ 计 算 机 学 报 ２０２０年
表２展示了每种符号的代表含义． 方法．现有的图卷积神经网络分为谱方法和空间方
法两类，谱方法利用图上卷积定理从谱域定义图卷
表２ 符号定义
积，而空间方法从节点域出发，通过定义聚合函数来
符号 表示含义
Ｇ 图 聚合每个中心节点和其邻近节点．
Ｖ 节点集合 ３．１．１ 图卷积神经网络谱方法
Ｅ 连边集合
图上平移不变性的缺失，给在节点域定义卷积
ｎ 节点个数
Ｉｎ∈Ｒｎ×ｎ 单位阵 神经网络带来困难．谱方法利用卷积定理从谱域定
Ａ∈Ｒｎ×ｎ 邻接矩阵
义图卷积．我们首先给出卷积定理的背景知识．
Ｄ∈Ｒｎ×ｎ 度矩阵（对角阵）
Ｌ∈Ｒｎ×ｎ 拉普拉斯矩阵
（１）图信号处理
Ｕ∈Ｒｎ×ｎ 特征向量矩阵 卷积定理：信号卷积的傅立叶变换等价于信号
Λ∈Ｒｎ×ｎ 特征值矩阵（对角阵）
傅立叶变换的乘积［７］：
ｕｉ∈Ｒｎ 第ｉ个特征向量
Ｘ∈Ｒｎ×Ｄ 节点特征矩阵 Ｆ（ｆ×ｇ）＝Ｆ（ｆ）·Ｆ（ｇ） （１）
Ｘｉ∈ＲＤ 第ｉ个节点的特征 其中，ｆ，ｇ表示两个原始信号，Ｆ（ｆ）表示ｆ的傅立
ｆ∈Ｒｎ 信号
叶变换，·表示乘积算子，＊表示卷积算子．对式（１）
我们用Ｇ＝｛Ｖ，Ｅ，Ａ｝表示无向图，其中Ｖ表示
两端做傅立叶逆变换，可以得到
节点集合，｜Ｖ｜＝ｎ表示图上共有ｎ个节点，Ｅ表示
ｆ＊ｇ＝Ｆ－１（Ｆ（ｆ）·Ｆ（ｇ）） （２）
边集合，Ａ表示邻接矩阵，定义节点之间的相互连
其中，Ｆ－１（ｆ）表示信号ｆ的傅立叶逆变换．
接，且在无向图中Ａ ＝Ａ ．Ｌ＝Ｄ－Ａ表示图上的
利用卷积定理，我们可以对谱空间的信号做乘
ｉ，ｊ ｊ，ｉ
拉普拉斯矩阵，其中Ｄ是一个对角阵，Ｄ 表示第ｉ
法，再利用傅里叶逆变换将信号转换到原空间来实
ｉ，ｉ
现图卷积，从而避免了因图数据不满足平移不变性
个节点的度且Ｄ ＝∑Ａ ．归一化后的拉普拉斯矩
ｉ，ｉ ｉ，ｊ
ｊ
而造成的卷积定义困难问题．图上傅立叶变换依赖
阵定义为Ｌ＝Ｉ ｎ－Ｄ－１ ２ＡＤ－１ ２，其中Ｉ ｎ∈Ｒｎ×ｎ是单位 于图上的拉普拉斯矩阵，在下文中，我们将给出图上
阵．因为Ｌ是一个实对称矩阵，对Ｌ做特征分解得 傅立叶变换的定义．
到Ｌ＝ＵΛＵＴ．其中Ｕ＝｛ｕ｝ｎ 表示ｎ个相互正交的 图上傅立叶变换的定义依赖于拉普拉斯矩阵的
ｉｉ＝１
特征向量．Λ＝ｄｉａｇ（｛λ｝ｎ ）是一个对角阵，λ表示 特征向量．以特征向量作为谱空间下的一组基底，图
ｉｉ＝１ ｉ
ｕ对应的特征值． 上信号ｘ的傅立叶变换为
ｉ
我们用Ｘ表示图Ｇ上的节点特征，其中Ｘ∈ ｘ＾＝ＵＴｘ （３）
Ｒｎ×Ｄ，Ｘ∈ＲＤ是第ｉ节点的特征，Ｘ 表示矩阵Ｘ的 其中，ｘ指信号在节点域的原始表示．ｘ＾指信号ｘ变
ｉ ｉｊ
第ｉ行第ｊ列，即第ｉ节点的第ｊ个特征．ｆ，ｘ，ｙ∈ 换到谱域后的表示，ＵＴ表示特征向量矩阵的转置，
Ｒｎ表示图上的信号，其中ｆ表示节点ｉ在信号ｆ上 用于做傅立叶变换．信号ｘ的傅立叶逆变换为
ｉ
的取值． ｘ＝Ｕｘ＾ （４）
利用图上傅立叶变换和逆变换，我们可以基于卷积
３ 图卷积神经网络 定理实现图卷积算子
ｘ＊ｙ＝Ｕ（（ＵＴｘ）⊙（ＵＴｙ）） （５）
Ｇ
图卷积神经网络主要包括卷积算子和池化算子 其中，＊表示图卷积算子，ｘ，ｙ表示图上节点域的信
Ｇ
的构建，其中卷积算子的目的是刻画节点的局部结 号，⊙指哈达玛乘法，表示两个向量的对应元素相
构，而池化算子的目的是学到网络的层级化表示，降 乘．我们用一个对角阵ｇ代替向量ＵＴｙ，那么哈达玛
θ
低参数．在解决节点级别的任务时，研究人员更关注 乘法可以转化成矩阵乘法．将卷积核ｇ作用在信号
θ
如何给每个节点学到更好的表达，此时池化算子并 上，图卷积可以表示成如下形式
不必要，因此前期大量的工作仅关注图上卷积算子 ＵｇＵＴｘ （６）
θ
的构建，而池化算子通常用在图级别的任务上．在这 卷积定理提供了通过傅立叶变换在图上定义卷
一章节中，我们将详细介绍图上卷积算子和池化算 积的方式．基于此卷积算子的定义，国内外陆续涌现
子的构建． 出一些图卷积神经网络．
３．１ 图卷积算子的构建 （２）基于卷积定理的图卷积神经网络
本节介绍关注卷积算子构建的图卷积神经网络 谱卷积神经网络（Ｓｐｅｃｔｒａｌ ＣＮＮ）［１７］是最早提 ５期 徐冰冰等：图卷积神经网络综述 ７５９
出在图上构建卷积神经网络的方法，该方法利用卷 效；（４）热核函数中的超参数ｓ用以表示热量扩散的
积定理在每一层定义图卷积算子，在损失函数指导 范围，通过调节超参数ｓ可以灵活的适应于不同任
下通过梯度反向回传学习卷积核，并堆叠多层组成 务场景．图１指在不同ｓ下黄色节点对应的小波变
神经网络．谱卷积神经网络第ｍ层的结构如下 换基底．图１（ａ）表示在ｓ较小时，以黄色节点为中心
ｐ 进行的热量扩散，图１（ｂ）表示当ｓ增大时，热量扩
Ｘｍ＋１＝ｈ （ Ｕ∑ＦｍＵ⊥ Ｘｍ），ｊ＝１，…，ｑ （７）
ｊ ｉ，ｊ ｉ 散范围也变大；此外，图１（ａ）也反应了小波基底的
ｉ＝１
其中，ｐ，ｑ分别是输入特征和输出特征的维度，Ｘｍ∈ 局部性和稀疏性．
ｉ
Ｒｎ表示图上节点在第ｍ层的第ｉ个输入特征，Ｆｍ
ｉ，ｊ
表示谱空间下卷积核，ｈ表示非线性激活函数．在谱
卷积神经网络中，这样一层结构将特征从ｐ维转化
到ｑ维，且基于卷积定理通过学习卷积核实现了图
卷积．
谱卷积神经网络将卷积核作用在谱空间的输入
信号上，并利用卷积定理实现图卷积，以完成节点之
图１ 不同ｓ下的小波变换基底［２１］（（ａ）当ｓ较小时，以黄色
间的信息聚合，然后将非线性激活函数作用在聚合 节点为中心的热量扩散范围较小；（ｂ）当ｓ增大时，热
结果上，并堆叠多层形成神经网络．该模型不满足局 量扩散范围增大）
部性，使得谱卷积神经网络的局部性没有保证，即产 利用图上小波变换代替傅立叶变换，小波神经
生信息聚合的节点并不一定是邻近节点． 网络的第ｍ层结构定义如下：
建模图卷积神经网络的初衷是为了利用图结构 ｐ
Ｘｍ＋１＝ｈ（ Ψ∑ＦｍΨ－１Ｘｍ），ｊ＝１，…，ｑ （８）
刻画邻近节点的信息聚合，而上文介绍的谱卷积神 ｊ ｓ ｉ，ｊ ｓ ｉ
ｉ＝１
经网络并不满足局部性，Ｈｅｎａｆｆ等人［２０］提出用带有 与谱卷积神经网络相比，小波神经网络用小波
平滑性约束的插值卷积核，这种方法降低参数个数 变换代替傅立叶变换，即用Ψ和Ψ－１替代了Ｕ和
ｓ
且实现了图卷积神经网络的局部化．最近，小波神经 Ｕ⊥ ．在这样一组小波基底下，图卷积神经网络满足
网络（ＧＷＮＮ）［２１］提出用小波变换代替傅立叶变换 了局部性，且由于小波基底的可加速计算以及稀疏
实现卷积定理． 性，图卷积神经网络的计算复杂度也大大降低．
小波神经网络指出，与傅立叶变换相似，小波变 除小波神经网络外，还有一些工作致力于实现
换也定义了一种将信号从节点域变换到谱域的方 图卷积神经网络的局部性和加速计算，但不同于小
法［５０］．这里用Ψ ｓ＝｛ ψｓ１， ψｓ２，…， ψｓｎ｝表示小波变换 波神经网络更换基底的方式，这些工作通过参数化
的基底，其中ψｓｉ表示从第ｉ个节点出发的能量扩
卷积核实现局部性，同时降低参数复杂度和计算复
散，刻画了第ｉ个节点的局部结构．小波基底的定义
杂度．下文我们将给出这类工作的具体介绍．
依赖于拉普拉斯矩阵的特征向量，即Ψ ｓ＝ＵＧ ｓＵＴ， 在式（６）中，ｇ是需要学的卷积核，在谱卷积神
θ
其中Ｇ ｓ＝ｄｉａｇ（｛ｇ ｓ（λ ｉ）｝ ｉｎ ＝１），对角线元素由ｇ函数 经网络中，ｇ是对角阵的形式，且有ｎ个需要学的参
θ
作用到特征值上得到．不同的ｇ函数赋予小波基底 数．切比雪夫网络（ＣｈｅｂｙＮｅｔ）［１８］对卷积核ｇ进行
θ
不同的性质，在小波神经网络中，作者使用热核函
参数化
数，即ｇ ｓ（λ ｉ）＝ｅｓλｉ．
Ｋ－１
以Ψ ｓ为谱空间的基底，图上小波逆变换的变换 ｇ θ＝ ∑θ ｋＴ ｋ（＾ Λ） （９）
ｉ＝０
矩阵为Ψ ｓ－１＝ＵＧ －ｓＵＴ，其中Ｇ －ｓ表示将上述ｇ函数
其中，θ是需要学的系数，＾ Λ＝２Λ －Ｉ．切比雪夫多
替换为ｇ －ｓ（λ ｉ）＝ｅ－ｓλｉ． ｋ λ
ｍａｘ
ｎ
和傅立叶变换相比，小波变换的基底具有几个 项式是通过递归得到，递归表达式为
很好的性质：（１）小波变换的基底可以通过切比雪 Ｔ（ｘ）＝２ｘＴ （ｘ）－Ｔ （ｘ） （１０）
ｋ ｋ－１ ｋ－２
夫多项式近似得到，避免拉普拉斯矩阵特征分解的 其中，Ｔ（ｘ）＝１，Ｔ（ｘ）＝ｘ．
０ １
高昂代价；（２）小波变换的基底具有局部性；（３）小 令＾ Ｌ＝２Ｌ －Ｉ，切比雪夫网络第ｍ层的结构定
波基底的局部性使得小波变换矩阵非常稀疏，这大 λ ｍａｘ ｎ
大降低了Ψ－１ｘ的计算复杂度，使计算过程更加高 义如下：
ｓ ７６０ 计 算 机 学 报 ２０２０年
ｐ Ｋ－１ 指出随着模型层数加深，网络拟合能力增强，但是在
Ｘｍ＋１＝ｈ （ Ｕ∑（ ∑θＴ （＾ Λ）） Ｕ⊥ Ｘｍ）
ｊ ｋ ｋ ｉ 一阶图卷积神经网络中会引起节点表达过于平滑，
ｉ＝１ ｋ＝０
ｐ Ｋ－１ 进而导致节点不可区分的问题．基于此，ＰＰＮＰ解耦
＝ｈ（ ∑∑θＴ （＾ Ｌ）Ｘｍ），ｊ＝１，…，ｑ （１１）
ｋ ｋ ｉ 维度变换和特征传播，并引入个性化ＰａｇｅＲａｎｋ，对
ｉ＝１ｋ＝０
切比雪夫网络利用特征值矩阵的多项式参数化卷积 输入数据先完成较少层数的维度变换，然后基于个
核，实现谱卷积神经网络，且巧妙的利用Ｌ＝ＵΛＵＴ 性化ＰａｇｅＲａｎｋ进行特征传播，特征传播过程不进
引入拉普拉斯矩阵，从而避免了拉普拉斯矩阵的特征 行参数学习，因此可以用在半监督学习任务中．
分解，同时参数复杂度从Ｏ（ｎ×ｐ×ｑ）下降到Ｏ（Ｋ× ＰＰＮＰ的结构如图３所示．
ｐ×ｑ）．此外，在拉普拉斯矩阵中，当且仅当节点ｉ，ｊ
满足Ｋ跳可达时，Ｌ ｉＫ ，ｊ≠０，这一性质使得当Ｋ较小
时，切比雪夫网络具有局部性．
为了使图卷积神经网络在图上半监督学习领域
发挥作用，Ｋｉｐｆ等人［１９］对切比雪夫网络简化并提出
一阶图卷积神经网络，Ｋｉｐｆ等人［１９］令Ｋ＝２且λ ＝
ｍａｘ
图３ 基于个性化ＰａｇｅＲａｎｋ的图卷积神经网络结构［２３］
２，则式（１１）可以写成
ｐ
简明一阶图卷积神经网络（ＳＧＣ）指出，非线性
Ｘｍ＋１＝ｈ（ ∑（θ－θ（Ｌ－Ｉ））Ｘｍ），ｊ＝１，…，ｑ
ｊ ０ １ ｎ ｉ 变换在一阶图卷积神经网络中无足轻重，使得ＧＣＮ
ｉ＝１ （１２）
发挥作用的是每一层的特征传播机制．基于此，ＳＧＣ
在图上半监督学习场景下，带标签的数据非常少，
抛弃层之间的非线性变换，将多个层的特征传播融
为了避免模型过拟合，Ｋｉｐｆ等人约束θ＝θ＝－θ来
０ １ 合到一个层内，在完成特征传播后，ＳＧＣ对样本做
降低模型参数，并对权重矩阵做归一化处理，最终得
一次维度变换．此模型等价于不含非线性变换的多
到如下的一阶图卷积神经网络
层一阶图卷积神经网络．
ｐ
Ｘｍ＋１＝ｈ（ ∑θ＾ Ｄ－１ ２＾ Ａ＾ Ｄ－１ ２Ｘｍ），ｊ＝１，…，ｑ （１３） 切比雪夫网络和一阶图卷积神经网络着眼于参
ｊ ｉ
ｉ＝１ 数化卷积核，图热核网络着眼于低通滤波器，以上方
其中，Ａ＾ ＝Ａ＋Ｉ，且＾
Ｄ
＝∑＾
Ａ ．
ｎ ｉｉ ｉ，ｊ 法虽然是从谱空间出发，但其最终形式已经包含定
ｊ
图热核网络（ＧｒａｐｈＨｅａｔ）［２２］从滤波器的角度 义节点相关性的聚合函数，从空间方法角度看，切比
对以上谱方法进行分析，指出谱卷积神经网络是非 雪夫网络以拉普拉斯矩阵多项式作为聚合函数，一
参滤波器，而切比雪夫网络和一阶图卷积神经网络 阶卷积神经网络以＾ Ｄ－１ ２＾ Ａ＾ Ｄ－１ ２作为聚合函数，图热
都是高通滤波器，但这与图半监督学习的任务中的
核网络以ｅ－ｓＬ作为聚合函数，其输出结果表示每个
平滑性先验不一致，基于此，图热核网络利用热核函
节点在该聚合函数下由自身和邻近节点加权得到的
数参数化卷积核，进而实现低通滤波器．图热核网络
新表达．而基于个性化ＰａｇｅＲａｎｋ的图卷积神经网
的思想如图２所示． 络（ＰＰＮＰ）和简明一阶图卷积神经网络（ＳＧＣ）虽然
是从谱方法一阶图卷积神经网络出发，但其已经是
通过聚合函数分析节点特征传播．以上方法可以看
作是谱方法和空间方法的桥梁．
３．１．２ 图卷积神经网络空间方法
上述方法都是从卷积定理出发在谱域定义图卷
积，空间方法旨在从节点域出发，通过定义聚合函数
来聚合每个中心节点和其邻近节点．上文中的切比
图２ 图热核网络与原有谱方法对比［２２］
雪夫网络和一阶图卷积网络可以看作以拉普拉斯矩
基于个性化 ＰａｇｅＲａｎｋ 的图卷积神经网络 阵或其变体作为聚合函数．在此启发下，近期出现一
（ＰＰＮＰ）［２３］和简明一阶图卷积神经网络（ＳＧＣ）［２４］
些工作通过注意力机制或递归神经网络等直接从节
则是对一阶图卷积神经网络方法进行分析，并提出 点域学习聚合函数，此外，也有一些工作从空间角度
了一些简化和变体．ＰＰＮＰ从深层网络的搭建出发， 定义了图卷积神经网络的通用框架并解释图卷积神 ５期 徐冰冰等：图卷积神经网络综述 ７６１
经网络的内部机制． 表达，Ｕ表示第ｔ步的更新函数．通过将神经网络的
ｔ
（１）通用框架 每一层设计成上述的聚合函数和更新函数，每个节
通用框架的定义指出图卷积网络的核心问题， 点可以不断以自身和邻近节点为源信息更新自身，
同时给已有工作提供一个对比分析的平台．近期出 进而得到依赖于节点局部结构的新表达．
现两篇文章旨在定义图卷积网络的通用框架，其中 在以上空间框架下，一些方法不再依赖于拉普
混合卷积网络（ＭｏＮｅｔ）［２５］着眼于图上平移不变性 拉斯矩阵，而是设计神经网络来学习聚合函数．这些
的缺失，通过定义映射函数将每个节点的局部结构 方法学到的聚合函数可以自适应于任务和具体的图
映射为相同尺寸的向量，进而在映射后的结果上学 结构，有更大的灵活性．下文我们将给出这类方法的
习共享的卷积核；而消息传播网络（ＭＰＮＮｓ）［２６］立 具体分析．
足于节点之间的信息传播聚合，通过定义聚合函数 （２）基于聚合函数的图卷积神经网络
的通用形式提出框架． 图神经网络（ＧＮＮｓ）［２７］是最早提出在图上搭建
平移不变性的缺失给图卷积神经网络的定义带 神经网络的模型．在图神经网络中，聚合函数被定义
来困难．混合卷积网络在图上定义坐标系，并将节点 成循环递归函数的形式，每个节点以周围节点和连
之间的关系表示为新坐标系下的一个低维向量．同 边作为来源信息更新自身的表达，
时，混合卷积网络定义一簇权重函数，权重函数作用 ｈ ｘ＝ｆ ｗ（ｌ ｘ，ｌ ｃ０［ｘ］，ｌ ｎｅ［ｘ］，ｈ ｎｅ［ｘ］） （１７）
在以一个节点为中心的所有邻近节点上，其输入为 其中，ｌ，ｌ ，ｌ ，ｈ 分别表示节点ｘ的标签，
ｘ ｃ０［ｘ］ ｎｅ［ｘ］ ｎｅ［ｘ］
节点间的关系表示（一个低维向量），输出为一个标 与节点ｘ相连的边的标签，ｘ的邻居节点的标签，以
量值．通过这簇权重函数，混合卷积网络为每个节点 及ｘ的邻居节点上一个时间步的表达，ｆ 是聚合函
ｗ
获得相同尺寸的向量表示： 数，其在文章中被定义成递归函数，根据ｆ 迭代更
ｗ
Ｄ（ｘ）ｆ＝∑ｗ（ｕ（ｘ，ｙ））ｆ（ｙ），ｊ＝１，…，Ｊ（１４） 新节点ｘ的表达直到收敛．此外，图神经网络定义
ｊ ｊ
ｙ∈Ｎ（ｘ） 全局输出函数并作用在收敛后每个节点的表达上得
其中，Ｎ（ｘ）表示ｘ的邻近节点集合，ｆ（ｙ）表示节点
到最终输出结果，我们用ｇ 表示全局输出函数，最
ｙ在信号ｆ上的取值，ｕ（ｘ，ｙ）指坐标系ｕ下节点，关 ｗ
终结果为
系的低维向量表示，ｗ表示第ｊ个权重函数，Ｊ表示
ｊ ｏ ＝ｇ （ｈ，ｌ） （１８）
ｘ ｗ ｘ ｘ
权重函数的个数．这步操作使得每个节点都得到一
近期，注意力机制引起广泛关注，图注意力网络
个Ｊ维的表示，且这个表示融合了节点的局部结构
（ＧＡＴ）［２８］正是通过注意力机制定义聚合函数，但是
信息．而混合卷积模型正是在这个Ｊ维表示上定义
和以往关心边上信息的模型不同，在图注意力网络
共享卷积核，
中，邻接矩阵仅被用来定义相关节点，而关联权重的
Ｊ
（ｆ＊ｇ）（ｘ）＝∑ｇ（ｊ）Ｄ（ｘ）ｆ （１５） 计算则是依赖节点的特征表达．图注意力网络每一
Ｇ ｊ
ｊ＝１ 层的结构如图４所示，图４（ａ）以节点ｉ，ｊ的特征表
其中，｛ｇ（ｊ）｝Ｊ 指卷积核．
ｊ＝１
达作为输入，计算ｉ，ｊ之间的注意力权重并归一化，
不同于混合卷积网络，消息传播网络指出图卷
图４（ｂ）利用注意力权重将周围节点的表达以加权
积的核心在于定义节点之间的聚合函数，基于聚合
和的形式聚合到自身，对于多种注意力机制下的计
函数，每个节点可以表示为周围节点和自身的信息
算结果，图注意力网络提供了拼接和均值两种计算
叠加．因此，该模型通过定义通用的聚合函数提出图
方式．注意力权重和表达更新的计算公式分别如下
卷积网络的通用框架．消息传播网络分为两个步骤，
ｅｘｐ（ＬｅａｋｌｙＲｅＬＵ（ａ［Ｗｈ‖Ｗｈ］））
首先将聚合函数作用在每个节点及其邻近节点上， α ｉ，ｊ＝ ｉ ｊ ，
∑ｅｘｐ（ＬｅａｋｌｙＲｅＬＵ（ａ［Ｗｈ‖Ｗｈ］））
得到节点的局部结构表达；然后，将更新函数作用在 ｉ ｋ
ｋ∈Ｎ（ｉ）
自身和局部结构表达上，得到当前节点的新表达， ｈ ｉ＝σ（ ∑α ｉ，ｊＷｈ ｊ） （１９）
ｍｔ＋１＝∑Ｍ（ｈｔ，ｈｔ，ｅ ），ｈｔ＋１＝Ｕ（ｈｔ，ｍｔ＋１）（１６） ｊ∈Ｎ（ｉ）
ｘ ｔ ｘ ｙ ｘ，ｙ ｘ ｔ ｘ ｘ 其中，参数Ｗ 用于完成每个节点的特征维度变换，
ｙ∈Ｎ（ｘ）
其中，ｈｔ ｘ表示第ｔ步节点ｘ的隐层表示，ｅ ｘ，ｙ表示节 参数ａ用于计算节点间的注意力权重，‖表示向量
点ｘ，ｙ的连边特征，Ｍ ｔ表示第ｔ步的聚合函数， 拼接，α ｉ，ｊ表示在ａ下计算得到的ｉ，ｊ节点间的权重，
ｍｔ＋１表示节点ｘ通过聚合函数后得到的局部结构 σ表示非线性激活函数．
ｘ ７６２ 计 算 机 学 报 ２０２０年
此外，ＤＣＮＮ［３０］利用随机行走后得到的Ｋ跳转
移概率定义节点间的权重，第ｍ层的结构如下：
Ｈｍ＋１ ＝ｈ（ＰＫＨｍＷ） （２０）
其中，ＰＫ表示两个节点在随机行走下Ｋ跳可达概率，
Ｗ是需要学习的参数．此类模型刻画了节点之间的高
阶信息，但是由于ＰＫ的计算复杂度为Ｏ（ｎ２ Ｋ），难以
扩展到大图上．
不同于以往认为节点只属于唯一标签的方法，
基于置信度的图卷积网络（ＣｏｎｆＧＣＮ）［３１］认为节点
图４ 图注意力网络结构［２８］（（ａ）利用注意力机制计算两个
是以一定的置信度为一个标签，因此ＣｏｎｆＧＣＮ给
节点之间的权重；（ｂ）根据计算的权重更新目标节点）
每个节点学习置信度函数，并将其作用在节点相关
从图注意力网络开始，节点之间的权重计算开 性上，修正聚合函数．图６给出了ＣｏｎｆＧＣＮ在应用
始从依赖于网络的结构信息转移到依赖于节点的 到节点二分类问题上的结构，在置信度作用后的聚
特征表达，但是以上模型在处理时需要加载整个网 合函数上，异配连接更容易被识别出来，进而降低相
络的节点特征，这阻碍了模型在大规模网络上的应 关系数．超图卷积网络（ＨＧＮＮ）［３２］则认为节点间的
用．基于此，Ｈａｍｉｌｔｏｎ等人［２９］提出图采样聚合网络 相关性不应该是节点两两之间产生，而是一组节点
（ＧｒａｐｈＳＡＧＥ），不同于以往模型考虑所有邻近节 相互影响进而构建组内节点相关性．基于此想法，
点，图采样聚合网络对邻近节点做随机采样，使得每 ＨＧＮＮ将边拓展到连接多个节点的超边，在超边上
个节点的邻近节点都小于给定的采样个数．图采样 定义聚合函数进行节点特征传播．
聚合网络的结构如图５所示．
图５ 图采样聚合网络结构［２９］（（ａ）以每个节点为中心，对
其邻近节点采样；（ｂ）利用采样节点更新目标节点的 图６ 基于置信度的图卷积网络［３１］
表达；（ｃ）利用更新后的节点表达预测节点的Ｌａｂｅｌ）
以上基于聚合函数的空间方法着眼于空间方法
以红色节点为目标节点，图采样聚合网络首先 中的根本问题，即聚合函数的构造．随着图卷积神经
对其一阶邻居和二阶邻居做随机采样，并仅把采样 网络的发展，研究人员开始考虑更复杂的场景，并涌
到的节点作为相关节点，然后，模型将聚合函数作 现出一类建模信息更为丰富的空间方法，包括如何
用在相关节点的特征表达上，并用聚合结果更新红 在具备连边信息的网络上搭建图卷积神经网络，如
色节点的特征表达来完成对应任务．此外，图采样聚 何建模高阶信息等，我们在第４节对这类空间方法
合网络给出多种聚合函数的形式，分别是基于最大 做详细介绍．
值的聚合，基于均值的聚合和长短时记忆力网络 （３）深度理解图卷积网络
（ＬＳＴＭ）．最大值聚合和均值聚合分别指取相关节 上文已经介绍了图卷积神经网络的通用框架和
点的最大值和均值作为聚合结果；长短时记忆网络 建模方法，在这一节中，我们将分析图卷积模型的内
指将相关节点输入 ＬＳＴＭ，并把输出作为聚合结 部机制及不同模型的建模能力．
果．图采样聚合网络也提出用分批量（Ｍｉｎｉ－ｂａｔｃｈ） Ｌｉ等人［４５］在图卷积神经网络的协同训练（Ｃｏ－
处理数据的方法训练模型，在每个批量输入数据下 Ｔｒａｉｎ ＧＣＮ）一文中对一阶图卷积神经网络（ＧＣＮ）
只需要加载对应节点的局部结构，避免了整张网络 展开详细分析，并指出ＧＣＮ的本质是拉普拉斯平
的加载，这使得在大规模数据集上搭建图卷积神经 滑．Ｌｉ等人指出单层的ＧＣＮ也显著优于全连接网
网络成为可能． 络（ＦＣＮ），而ＦＣＮ和ＧＣＮ的区别仅在于式（１３）中 ５期 徐冰冰等：图卷积神经网络综述 ７６３
的＾ Ｄ－１ ２＾ Ａ＾ Ｄ－１ ２．对图做拉普拉斯平滑，其形式如下 操作，主要目的是刻画出网络的等级结构．
（Ｉ－γ＾ Ｄ－１＾ Ｌ）Ｘ （２１） 图上的池化操作通常对应的是图分类任务，对
其中，＾ Ｌ＝＾ Ｄ－＾ Ａ，０＜γ＜１是超参数，用以调节源节点 于图Ｇ＝（Ａ，Ｘ），其中Ａ为邻接矩阵，Ｘ为节点的特
和周围节点的权重．令γ＝１，则拉普拉斯平滑形式为 征矩阵，给定一些标注的图数据 Ｄ＝｛（Ｇ １，ｙ １），
＾ Ｄ－１＾ ＡＸ，此时如果用对称标准化的拉普拉斯算子 （Ｇ ２，ｙ ２），…｝和图对应的标签集合Ｙ，通过一个映射
＾ Ｄ－１ ２＾ Ｌ＾ Ｄ－１ ２替代＾ Ｄ－１＾ Ｌ，则式（２１）等价为＾ Ｄ－１ ２Ａ＾＾ Ｄ－１
２Ｘ．
函数ｆ：Ｇ→Ｙ，能够将图结构映射到对应的标签．
切比雪夫网络（ＣｈｅｂｙＮｅｔ）［１８］利用完全二叉树
由此可见，ＧＣＮ的本质是在网络上做拉普拉斯平
实现池化算子，其提出基于 Ｇｒａｃｌｕｓ贪婪准则为
滑．拉普拉斯平滑使用每个节点的邻居及自身表达
每个节点计算最为匹配的节点，并将此对节点池化
的加权和作为当前节点的新特征，由于在分类任务
为一个节点．同时，ＣｈｅｂｙＮｅｔ通过增加虚假节点保
中，同类节点倾向于稠密连接，平滑使得同类节点的
证整个池化过程是一个完全二叉树，图８展示了
特征更为相似，进而提升了下游的分类任务．同时文
ＣｈｅｂｙＮｅｔ将八节点的图池化为三个节点的过程．
章指出，多层的ＧＣＮ在更新目标节点表达时，会混
合其他类节点的信息，进而导致效果降低．
Ｘｕ等人［５１］把 Ｗｅｉｓｆｅｉｌｅｒ－Ｌｅｈｍａｎ测试泛化到
图卷积模型上并分析了不同图卷积网络的能力．他
们在文章中指出图卷积网络都是在更新节点的特征
图８ 切比雪夫网络利用完全二叉树实现池化算子［１８］
表达．当一个模型满足以下性质，仅当两个节点的特
由输入图Ｇ经过Ｇｒａｃｌｕｓ贪婪准则得到Ｇ 包
征一致且局部结构一致时，这两个节点才会被映射 ０ １
含５个节点，为保证池化过程是一棵完全二叉树，则
到相同位置，该模型被称为能力最强的图卷积网络．
Ｇ包含３个节点，并为Ｇ增加一个蓝色虚假节点，
如图７所示，基于这种定义，均值聚合的能力大于最 ２ １
为Ｇ增加４个虚假节点．
大值聚合的能力，小于求和聚合的能力． ０
不同于ＣｈｅｂｙＮｅｔ，Ｙｉｎｇ等人［５２］抛弃了预定义
的贪婪准则，并提出微分池化（ＤＩＦＦＰＯＯＬ）模型，
其提出将图神经网络应用于节点嵌入和池化操作，
模型结构如图９所示．模型在第ｌ层学习到一个类
别分配矩阵Ｓ（ｌ）∈Ｒｎｌ×ｎｌ＋１，Ｓ（ｌ）的每一行对应于ｌ层
图７ 聚合函数能力比较［５１］（均值聚合的能力大于最大值 次ｎ类，每一列对应于ｌ层的ｎ 节点．对于给定ｌ
聚合的能力，小于求和聚合的能力） ｌ ｌ＋１
层，输入的节点表达矩阵为Ｚ（ｌ），产生新的粗粒度
在这种定义下，基于均值聚合的函数能力并不
的ｌ层邻接矩阵Ａ（ｌ＋１）和新的表达矩阵Ｘ（ｌ＋１），即
是最强大的，但是ＧｒａｐｈＳＡＧＥ，ＧＣＮ等基于均值或
Ａ（ｌ＋１），Ｘ（ｌ＋１）＝ＤＩＦＦＰＯＯＬ（Ａ（ｌ），Ｚ（ｌ）），具体的计算
加权均值聚合的模型也取得了很好的效果．文章指
过程如式（２２）所示：
出，均值聚合关心节点的特征分布，当节点特征各异
Ｘ（ｌ＋１）＝Ｓ（ｌ）ＴＺ（ｌ），Ａ（ｌ＋１）＝Ｓ（ｌ）ＴＡｌＳ（ｌ），
时，均值聚合的能力等同于求和聚合．因此，在节点
Ｚ（ｌ）＝ＧＮＮ ｌ，ｅｍｂｅｄ（Ａ（ｌ），Ｘ（ｌ）），
分类等特征丰富的任务上，ＧｒａｐｈＳＡＧＥ，ＧＣＮ等也
Ｓ（ｌ）＝ｓｏｆｔｍａｘ （ＧＮＮ ｌ，ｐｏｏｌ（Ａ（ｌ），Ｘ（ｌ））） （２２）
得到了非常有效的结果．
其中，Ｘ（ｌ＋１）∈!ｎｌ＋１×ｄ，Ａ（ｌ＋１）∈Ｒｎｌ＋１×ｎｌ＋１．
３．２ 图池化操作
前文介绍了在图上进行的卷积算子，而在传统
的卷积神经网络中，卷积会和池化相结合，池化算子
一方面能够减少学习的参数，另外一方面能反应输
入数据的层次结构．而在图卷积神经网络中，在解决
节点级别的任务如节点分类、链接预测时，池化算子 图９ 微分池化模型结构［５２］（对于每个等级层，使用图神经
并非必要．因此，在图卷积神经网络领域，池化算子 网络模型获取节点的表达，然后使用学习的表达对节
点进行聚类，并使用另一个图神经网络模型作用于这
受到的关注较少．近期，也有一些研究人员为了解决
个更加粗粒度的图上．整个过程重复Ｌ层，使用最后
图级别的问题引入池化算子．在图结构中使用池化 的输出进行分类） ７６４ 计 算 机 学 报 ２０２０年
该模型被用来做软聚类和网络节点表示学习， 的信息；真实的网络化数据规模巨大，如何降低图卷
其需要存储分配矩阵，因此空间复杂度为Ｏ（ｋＶ２）， 积算子的空间和时间消耗使得其能应用在大规模网
ｋ为池化比例．Ｃａｎｇｅａ等人［５３］提出丢掉Ｎ－ｋＮ个 络化数据上等．本节将介绍图神经网络的最新进展，
节点代替聚合这些节点表达，该方法能够减少内存 并且依据它们解决的问题不同，分成了建模网络额
的开销，从而可以建模更大规模的网络结构． 外信息的图卷积网络和适应大规模网络化数据的图
为了在池化过程中充分利用节点特征和局部结 神经网络训练方法两部分内容．
构，谱池化（ＥｉｇｅｎＰｏｏｌｉｎｇ）［５４］利用谱聚类将整个大 ４．１ 建模网络额外信息的图卷积网络
图划分成几个不存在重叠的子图，而每个子图即作 图卷积算子（按特定权重聚合邻居节点的特征）
为池化后的一个新节点，新节点间的连边则基于原 是图卷积神经网络空间方法的核心算子．部分空间
子图连边产生．ＥｉｇｅｎＰｏｏｌｉｎｇ可以控制每次划分后 方法虽然能够利用节点的特征来区分不同邻居的重
的子图个数，进而控制每一层的池化比例．图１０展 要程度，但依然具有局限性．它们忽略了网络上除了
示了将ＥｉｇｅｎＰｏｏｌｉｎｇ池化算子和一阶图卷积神经 连边和节点特征之外的其他重要信息，例如：边上的
网络结合，完成图分类任务的框架． 属性，高阶网络结构信息等．本节将介绍显式建模网
络上各种丰富信息的图卷积神经网络．
４．１．１ 建模边上信息的图卷积网络
边是网络重要的组成部分，刻画了节点之间的
关联关系．在实际中，不同网络的边蕴含的信息的类
型也大不相同：低维离散的类型信息、低维连续的权
重信息、高维连续的属性信息等．根据建模边上信息
方式的不同，本文将现有的方法分成了三类：
图１０ 池化算子和一阶图卷积神经网络结合，完成图分类
任务［５４］（每种颜色表示一个子图，在池化后成为一 （１）子图拆解法
个新的节点） 此类方法将包含复杂额外信息的网络化数据拆
无独有偶，基于注意力机制的池化算子（ＳＡＧ－ 解成多个不同的子图，拆解后每个子图只包含单一
Ｐｏｏｌ）［５５］同样着眼于在池化过程中同时考虑节点属 的连边类型，对拆解后的每个子图利用传统的图卷
性信息和结构信息，ＳＡＧＰｏｏｌ基于注意力机制通过 积神经网络建模，最后将不同子图上得到的结果按
结构和属性信息为每个节点学到一个标量，以此标 特定方式进行聚合．
量表征对应节点在整个图上的重要性，并对此标量 关系图神经网络（Ｒ－ＧＣＮｓ）［３３］根据连边的方
进行排序，根据排序结果保留最重要的一部分节点 向、边上的标签类型将原来的网络拆分成不同的子
及其连边进而完成池化操作． 网络，在每个子图上独立地进行邻居特征的聚合．每
池化算子是为了学到图的等级结构，进而完成 一层在聚合操作结束后，将节点在不同子图上得到
图级别的任务．起初的池化算子基于图的拓扑结构， 的结果相加，作为下一层网络的输入．关系图神经网
启发式的定义一些节点的舍弃或者融合方式，近期， 络的卷积操作可以形式化成如式（２３）：
池化算子不仅依赖于拓扑结构，同样依赖于节点的 ｈｌ＋１ ＝σ（ ∑ ∑ １ Ｗ（ｌ）ｈ（ｌ） ＋Ｗ（ｌ）ｈ（ｌ）） （２３）
ｉ ｃ ｒ ｊ ０ ｉ
属性信息，同时池化过程也开始通过注意力机制参 ｒ∈! ｊ∈" ｉｒ ｉ，ｒ
数学习等由模型指导完成． 其中，ｃｉ是归一化因子，可以根据不同任务进行选择，
ｒ
常见的方式是用邻居个数作为归一化因子即ｃ ＝
ｉ，ｒ
４ 图卷积神经网络的新进展 ｜Ｎｒ｜．Ｒ表示不同的边类型，Ｗｌ表示第ｌ层对于边
ｉ ｒ
类型为ｒ的子图需要学习的参数．当边类型是高维
上一节介绍了经典的图卷积神经网络算法，他 向量时，连边的类型随维度增长呈指数增长．此时直
们在很多任务上取得了显著的提升．然而将这些方 接应用关系图神经网络，需要分解成大量的子图，同
法应用到实际的网络化数据上时，仍就面临着一些 时每个子图非常稀疏，在这种情况下节点很难学习
挑战，例如：真实的网络化数据除了节点和连边还有 到有效地表达．为了减少参数关系，图神经网络使用
很多额外的信息，如何在卷积操作中建模这些额外 两种不同的方式，偏置分解（ｂａｓｉｓ－ｄｅｃｏｍｐｏｓｉｔｉｏｎ）和 ５期 徐冰冰等：图卷积神经网络综述 ７６５
区块对角化分解（ｂｌｏｃｋ－ｄｉａｇｏｎａｌ ｄｅｃｏｍｐｏｓｉｔｉｏｎ）． 对偶图上直接应用传统的图卷积神经网络，同时原
关系图注意力网络（Ｒ－ＧＡＴ）［３４］在关系图神经网络 图中边上特征变成了对偶图中节点上的特征，可以
的基础上引入了注意力机制，作者提出了两种引入 通过在对偶图上定义的图卷积刻画．
注意力机制的邻居聚合函数替换关系图神经网络中 原始对偶图卷积神经网络（ＤＰＧＣＮＮ）［３６］提出
只利用网络结构的聚合函数，进一步提升了实验结 了一种构建对偶网络的方法．以图１２为例，原始对
果．关系图神经网络和关系图注意力网络更适用于 偶图卷积神经网络将原网络中的边映射成对偶网络
具有离散类型的边特征的网络． 中的节点（例如右侧图中（０，４）节点表示左侧图中０
符号网络（ｓｉｇｎｅｄ ｎｅｔｗｏｒｋ）是一种特殊的边上
节点和４节点之间的连边）．同时，如果原网络中的
包含类型信息的网络．除了包括“朋友关系（ｐｏｓｉｔｉｖｅ
两条连边有共同节点（如左侧图中边〈０，１〉和〈０，２〉
ｌｉｎｋ）”，“敌对关系（ｎｅｇａｔｉｖｅ ｌｉｎｋ）”两种类型的连
有共同节点０），那么这两条边对应的对偶网络中的
边，符号网络还具有结构平衡（ｓｔｒｕｃｔｕｒａｌ ｂａｌａｎｃｅ）
节点（（０，１），（０，２））之间存在一条连边，此外，原网
等特殊的社会学性质．其中“敌人的敌人是朋友”（距
络边上的特征被保存在对偶网络的节点上．
离中心节点两跳“敌对关系”的节点和其具有“朋友”
关系）这一性质使得仅根据边类型划分聚合函数不
可行．符号图卷积网络（ＳＧＣＮ）［３５］针对符号网络的
特殊性质进行设计．在符号图卷积网络中，每个节点
包含“朋友表达（ｆｒｉｅｎｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ）”和“敌人表达 图１２ 左侧为原始网络，右侧对对应的对偶网络［３６］
（ｅｎｅｍｙ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ）”两部分，分别利用“朋友”聚
原始对偶图卷积神经网络分别在对偶网络和原
合器（ｆｒｉｅｎｄ ａｇｇｒｅｇａｔｏｒ）和“敌人”聚合器（ｅｎｅｍｙ
始网络上定义了对应的卷积操作．对偶卷积的形式
ａｇｇｒｅｇａｔｏｒ）学习得到．卷积层结构如图１１所示．由
如式（２４）和（２５）：
于第一层网络只能刻画到一阶邻居，因此不存在结
构平衡问题．第一层的“朋友表达”通过聚合直接“朋
ｆ珘′ ｉｊ＝ξｄ（ ∑α珘 ｉｊ，ｉｒｆ珟 ｉｒＷ珮 ＋∑α珘 ｉｊ，ｔｊｆ珟 ｔｊＷ珮） （２４）
ｒ∈"
ｉ
ｔ∈"
ｊ
友 络” 开的 始表 ，达 由即 于可 结得 构平到， 衡“ 性敌 的人 存表 在达 ，” “同 朋理 友． ”从 集第 合二 和层 “网
敌
α珘 ｉｊ，ｉｋ＝
∑ｅη（α珘（［ｆ珟
ｉｊＷ珮ｅ ，ｆ珟η ｉｒ（α珘 Ｗ珮（［ ］ｆ珟 ）ｉｊ ）＋Ｗ珮， ∑ｆ珟 ｉｋＷ珮 ｅ］ η））
（α珘（［ｆ珟 ｉｊＷ珮，ｆ珟 ｔｊＷ珮］））
（２５）
人”集合得到了拓展．当前节点ｉ的“朋友表达”将由 ｒ∈"
ｉ
ｔ∈"
ｊ
自身“朋友”的“朋友”，自身“敌人”的“敌人”，以及自 其中， ξｄ表示对偶网络中的激活函数（例如ＲｅＬＵ），
身的“朋友”三部分通过朋友聚合器得到．同理“敌人 ｆ表示原图中节点ｉ的特征，ｆ珘′表示对偶网络中节
ｉ ｉｊ
表达”由自身的“敌人”、自身“敌人”的“朋友”以及自 点（ｉ，ｊ）的特征（对应原网络中的边〈ｉ，ｊ〉）当边上缺
身“朋友”的“敌人”通过“敌人聚合器”得到． 少特征时可以通过拼接两段节点的特征代替：ｆ珘′＝
ｉｊ
［ｆ，ｆ］，也可以同时使用两者．其中Ｗ珮 表示需要学
ｉ ｊ
习的参数， η表示Ｌｅａｋｙ ＲｅＬＵ激活函数，Ｎ ｉ表示原
网络中节点ｉ的邻居节点构成的集合．
原始卷积与传统图注意力网络的形式类似，唯
一的区别在于计算注意力系数时输入特征采用的是
由对偶卷积计算得到的边上的特征，
图１１ 符号图卷积网络卷积操作示意图［３５］
ｆ′ ｉ＝ξＰ（ ｒ∑
∈"
ｉα ｉｊｆ ｉＷ），α ｉｊ＝ ∑ｅη ｅ（ａ η（ｆ珘 （ａ′ｉｊ （ｆ珟） ′ｉ）
ｋ））
（２６）
ｋ∈"
ｉ
（２）对偶图构建法 直观上理解，对偶图上的图卷积网络，为原始图
第二类方法为对偶图构建法．此类方法通过构 中的每一条边学到了一个表示，该表示能反映节点
建对偶网络的方式，将原网络中的边转换成对偶网
特征沿着这条边传播的权重．而原始图中的图卷积
络中的节点，将原图中边上的特征转移到了对偶图
网络依据边的传播权重，进行特征的传播，为节点学
的节点上．对偶图的连边不再具有特征，因此可以在
习表达． ７６６ 计 算 机 学 报 ２０２０年
该方法能适用于具有高维边特征的场景，但是
需要将原网络转换成对偶网络．在实际中，网络的边
数往往远大于网络的节点数，因此对偶网络的规模
往往会远大于原网络．在对偶网络中应用卷积操作
会有很大的计算代价．故此方法难以应用到大规模
的网络中．
（３）权重重调法
第三类方法为权重重调法．此类方法认为边上
的特征信息只会影响中心节点聚合邻居节点特征的
权重，因此这类方法在计算聚合权重时引入了边上
的特征信息．
图１３ 边约束卷积神经网络结构［３８］（图上连边的类型用低维
边注意力网络（ＥＧＡＴ）［３７］定义卷积操作如下 向量表示，并将这些向量通过参数转化为该连边对应
所示：
两个节点间的权重，基于以上权重做节点表达更新）
ｘ′ ｉ＝σ［ ‖ ｐＰ ＝１（ ∑α（ｘ ｉ，ｘ ｊ，ｅ ｉｊｐ）ｇ（ｘ ｊ））］，ｇ（ｘ ｊ）＝Ｗｘ
ｊ
据．在图１４中，方形色块的颜色表示对应节点的类
ｊ∈"
ｉ （２７） 别，以中心节点为目标节点，目标节点的类别为机器
其中，Ｐ表示边上特征的维度，ｅ ｉｊｐ表示连边〈ｉ，ｊ〉特 学习（绿色类别）．当仅考虑一阶邻居时，与目标节点
征在第ｐ维上的值，ｇ（ｘ）＝Ｗｘ表示节点ｊ经过线 连接最多的点是可视化（蓝色类别）的节点，因此
ｊ ｊ
性变换后的特征，Ｗ是需要学习的参数，ｘ ｊ是输入特 ＧＣＮ会将目标节点误分成可视化．但是当引入高阶
征．边注意力网络改变了传统图注意力网络计算节 结构（三角形模体）时，可以发现目标节点只剩下三
点之间注意力权重的方式，将边上的特征也作为一 个标签为机器学习的邻居了，因此目标节点在高阶
个重要的输入参与权重的计算．具体形式如式（２８）： 结构下可以被正确分类．
１
α（ｘ，ｘ，ｅ ）＝ ｆ（ｘ，ｘ）ｅ ，# ＝∑ｆ（ｘ，ｘ）ｅ
ｉ ｊ ｉｊｐ # ｉ ｊ ｉｊｐ ｉｐ ｉ ｊ ｉｊｐ
ｉｐ ｊ∈"
ｉ
（２８）
其中，# 是归一化因子．而ｆ（ｘ，ｘ）可以采用计算
ｉｐ ｉ ｊ
注意力权重时常用的一些形式，例如单层全连接网
络等．该方法可以理解成在传统图注意力网络基础
上，利用边上的特征对注意力的权重再额外加权，同
时认为边上的特征的每一个维度之间是独立的．
图１４ 对节点分类时，仅用一阶邻居和考虑高阶结构对
边约束卷积网络（ＥＣＣ）［３８］，将图上连边的类型
比［４２］（（ａ）将所有一阶邻居视为同等重要的节点，可
用低维向量表示，并将这些向量通过单层线性神经 能会导致推测错目标节点真实的标签；（ｂ）利用三角
模体来筛选邻居节点，可以找到与中心点关系更密
网络转化为该连边对应两个节点间的聚合权重．边
切的节点，使得中心点更可能被推测出真实的标签）
约束卷积网络每一层的结构如图１３所示，其中
为了在引入高阶关系的同时更好地区分每个
Ｌ（ｉ，ｊ）表示ｉ，ｊ节点连边的低维向量表示，Ｆｌ（·）表
“邻居”节点的重要性，高阶图卷积神经网络（ＨＡ－
示第ｌ层的参数，用于将输入的边向量转化为节点
ＧＣＮ）［３９］用ｋ阶邻接矩阵Ａ＾ 替换 ＧＣＮ［１９］中的Ａ＾ ．
间的权重，Ｘｌ（ｉ）表示ｉ节点在ｌ层的特征表达．该 ｋ
同时为了区分每个节点的重要性，ＨＡ－ＧＣＮ引入了
模型通过学习参数将边关系转化为权重，并用该权
元素级的自适应权重矩阵．高阶图卷积神经网络的
重做节点的聚合，使得为每个节点学到局部结构相
卷积层形式化如式（２９）：
关的表达．但该方法仅考虑了边上特征各个维度之
＾ Ｌ（ｋ） ＝ （Ｗ珦 ⊙Ａ＾ｋ）Ｘ＋Ｂ （２９）
间的关系，忽略了两端节点特征之间的相似性． ＨＡ ｋ ｋ
其中，Ａ＾ｋ表示ｋ阶邻接矩阵，Ｂ表示第ｋ阶的偏置
４．１．２ 建模网络高阶信息的图卷积网络 ｋ
（ｂｉａｓｅｓ）矩阵，Ｗ珦ｋ表示自适应权重矩阵，根据节点的
除了节点特征和边特征，网络的高阶结构特征
特征、邻接关系以及原始权重矩阵计算得到，
也是筛选邻居，以及区分邻居节点重要性的有效依 ５期 徐冰冰等：图卷积神经网络综述 ７６７
Ｗ珦 ＝ｇ⊙Ｗ ，ｇ＝ｆ ＝（＾ Ａｋ，Ｘ） （３０） 在模体ｋ下的注意力权重．
ｋ ｋ ａｄｐ
自适应权重矩阵由式（３０）计算得到，其中ｇ是 Ｕ
ｈ（ｖ ｉ）＝∑α ｋ，ｉｈｋ（ｖ ｉ） （３４）
非线性算子（单层神经网络），输入特征由节点的特
ｋ＝１
最终目标节点的表达由不同模体下表达的加
征和高阶邻接矩阵的拼接得到．
权和得到．
在异质信息网络中，节点和边具有多种类型，单
和模体卷积网络类似，异质注意力网络（ＨＡＮ）［４１］
纯使用ｋ阶邻接矩阵丢失了重要的语义信息．例如
利用元路径（ｍｅｔａ－ｐａｔｈ）来定义卷积操作，对于同一
在图１５所示的ＤＢＬＰ网络中，节点具有三种不同的
种元路径共享参数．其模型结构如图１６所示．
类型：作者（Ａ），论文（Ｐ），会议（Ｖ）．ｖ和ｐ都是中
１ ６
心节点ａ的二阶邻居，无法用ｋ阶邻居矩阵区分，但
是显然两者对ａ提供的语义信息不相同．因此异质
信息网络上的图卷积神经网络需要能刻画具有更加
复杂的高阶语义信息．
图１５ ＤＢＬＰ数据集中的模体类型［４０］（（ａ）列举了ＤＢＬＰ 图１６ ＨＡＮ模型结构［４１］
数据集中出现的模体类型．节点包含三种类型作
聚合邻居节点的特征是图卷积网络的关键步
者（Ａ），论文（Ｐ），会议（Ｖ）；（ｂ）展示了以ａ为中
心节点的Ｍ 模体实例） 骤，此问题的关键是如何根据任务选择合适的邻居
１
节点，同时区分各个邻居节点的重要性．前文提到的
模体卷积网络（Ｍｏｔｉｆ－ＣＮＮ）［４０］通过显式定义
几个方法利用网络的高阶结构筛选候选邻居节点，
的模体（ｍｏｔｉｆ），来区分邻居节点对中心节点不同的
用注意力机制计算邻居节点的重要程度．而模体卷
语义作用．模体卷积网络利用模体来定义网络上的
积决策网络（ＭＣＮ）［４２］将这个关键点形式化成了决
卷积算子，根据节点的语义角色信息来共享参数．其
策问题：如何选择合适的邻居，以及对选择的邻居赋
卷积形式如式（３１）所示：
予多大的聚合权重？模体卷积决策网络认为选择邻
（ １
Ｎ ＫＭ
）
ｈＭ（ｖ ｉ）＝σｗ ０ｘ ｉ＋ ＤＭ∑∑ｗ ｋ（Ａ） ｋＭ ｉｊｘ
ｊ
（３１） 居节点集合就是为每个节点选择最合适的模体关
ｉｉｊ＝１ｋ＝１
系，而共同在模体中出现的频率作为聚合权重．与之
其中，ＤＭ是对角矩阵，对角元素表示每个节点参与
前的方法类似，模体卷积决策网络也通过定义ｋ步
的不同的模体的个数．ＡＭ是邻接模体张量，ＡＭ 表
ｋ，ｉ，ｊ
模体矩阵的方式构建候选的邻居节点集合．模体卷
示节点ｊ以ｋ角色出现在以节点ｉ为中心的模体实
积决策网络采用Ｔ种不同的模体结构，每一种模体
例Ｍ的次数．ｗ是共享参数，相同语义角色的节点
ｋ
计算ｋ个不同步长的模体矩阵．ｋ阶模体定义和ｋ
之间共享参数．不同的任务需要的语音信息不一样，
阶邻接矩阵类似，为ｋ个相同模体矩阵的乘积．
即在不同任务下不同模体的重要程度不同．模体卷
Ψ（Ａｋ）＝Ψ（Ａ…Ａ） （３５）
积网络采用注意力机制给不同的模体学习重要程度 ｔ 烏ｔ 烐 ｔ 烑
ｋ
的权重，形式如式（３２）和（３３）， 模体卷积决策网络的决策过程分为两步：第１
ｚＴｈｋ（ｖ） 步选择与目标节点最相关的模体，第２步选择最相
ｅ ｋ，ｉ＝ａ（ｈｋ（ｖ ｉ），ｚ ｋ）＝ ｋ ｉ （３２）
槡ｚ 关的步长．模体卷积决策网络采用注意力机制计算
ｋ
α ｋ，ｉ＝ｓｏｆｔｍａｘ ｋ（ｅ ｋ，ｉ）＝
Ｕｅｘｐ（ｅ ｋ，ｉ）
（３３）
模体被选中的概率以及各个步长的相关程度．模体
∑ｅｘｐ（ｅ ｊ，ｉ）
卷积决策网络的目标函数包含两部分：分类的损失
ｊ＝１ 函数以及决策的损失函数．分类的损失函数使用交
模体卷积网络采用点积形式计算注意力权重，
叉熵度量节点分类的准确性，而决策的损失函数用
其中ｚ表示模体Ｍ 的共享注意力向量，不同的模
Ｋ Ｋ
来衡量决策的准确性，对于每个节点ｖ，如果分类准
体独立计算注意力权重，不共享参数．α ｋ，ｉ表示节点ｉ ７６８ 计 算 机 学 报 ２０２０年
确则回报（ｒｅｗａｒｄ）为正，否则回报为负．由于每一层
决策的结果都会影响最终的结果，此方法通过为每
一层的所有节点都计算回报来约束每一层都做出正
确决策．
除了作为选择邻居的依据，模体矩阵由于其对
称性，可以用来解决图卷积神经网络谱方法不能用
于有向网络的缺点．模体网络（Ｍｏｔｉｆ－Ｎｅｔ）［４３］提出
利用模体矩阵替换基于谱方法卷积中的拉普拉斯矩
阵，就可以将图卷积神经网络谱方法应用在有向网
络上．
根据算法适用的网络类型，将本节提到的方法
图１７ ４层Ｊｕｍｐｉｎｇ Ｋｎｏｗｌｅｄｇｅ Ｎｅｔｗｏｒｋ的示意图［４４］（Ｎ．
总结如表３． Ａ．表示从邻居节点聚合特征的操作）
的最后一层，并且在最后一层引入自适应的聚合机
表３ 本节方法总结
模型 节点类型 边属性 邻居范围
制，为每个节点选择合适的邻居范围．跳跃知识网络
ＲＧＣＮ［３３］ 多种类型 高维离散 直接邻居 可以使用多种聚合方式，包括拼接、最大池化以及递
ＳＧＣＮ［３５］ 单一类型 离散标量 高阶邻居（结构平衡）
归神经网络．
ＤＰＧＣＮ［３６］ 单一类型 高维连续 直接邻居
ＥＧＡＴ［３７］ 单一类型 连续标量 直接邻居 ４．２．２ 大规模网络图卷积技术
ＥＣＣ［３８］ 多种类型 高维连续 高阶邻居（模体） 传统的机器学习方法，例如：多层感知机
ＨＡ－ＧＣＮ［３９］ 多种类型 单一类型 高阶邻居（模体） （ＭＬＰ）等，认为样本之间是独立的，因此可以使用
Ｍｏｔｉｆ－ＧＣＮ［４０］ 多种类型 单一类型 高阶邻居（模体）
分批量（Ｍｉｎｉ－Ｂａｔｃｈ）处理数据的方式来应对大规模
ＨＡＮ［４１］ 多种类型 单一类型 高阶邻居（模体）
ＭＣＮ［４２］ 多种类型 单一类型 高阶邻居（模体） 的训练的数据．而在图卷积神经网络中，由于卷积操
Ｍｏｔｉｔ－Ｎｅｔ［４３］ 多种类型 单一类型 高阶邻居（模体） 作依赖于邻居节点，因此直接使用分批量的训练方
式需要引入大量的相关节点．即对于某个中心节点，
４．２ 图卷积网络的训练技术
更新其表达需要用到的邻居节点个数随着网络层数
图卷积网络已经在很多场景下取得了显著的结
增加呈现指数增长．同时在大规模网络中，某些大度
果，但是依然面临着一些问题：难以直接应用在大规
节点即使只考虑二阶邻居计算量也过于庞大．这两
模网络上，堆叠多层图卷积网络会造成效果的下降
者导致直接使用分批量的训练方法不能解决ＧＣＮ
等．本节介绍了将图卷积网络应用在大规模网络上
难以应用在大规模网络上的问题．
时采用的训练技术．
ＧｒａｐｈＳＡＧＥ［２９］使用分批量的训练方法，结合
４．２．１ 深层图卷积神经网络
采样邻居节点 Ｎｅｉｇｈｂｏｒ Ｓａｍｐｌｉｎｇ（ＮＳ）的方法，将
残差网络解决了传统神经网络在网络层数很深
每次计算所需要的节点数目控制在一定范围之内．
时拟合能力反而下降的问题．在堆叠多层图卷积层
例如，假设模型采用两层卷积，同时限定第一层采样
后，由于节点之间的特征变得过于平滑缺少区分性，
邻居个数为Ｄ，第二层采样邻居个数为Ｄ，那么对
１ ２
也会导致网络的效果变差．简单的应用残差连接并
于每一个节点的感受野范围为Ｄ ×Ｄ．若批量大
１ ２
不能解决这个问题，因为在ＧＣＮ中每一层节点只
小（Ｂａｔｃｈ ｓｉｚｅ）为ｋ，那么对于一个批量内的数据可
将特征传递给自己的直接邻居，不同的节点传播特
以将需要计算的节点上限控制为ｋ×Ｄ×Ｄ．
１ ２
征的速度并不相同：中心节点（ｈｕｂ）可能经过一两
ＧｒａｐｈＳＡＧＥ使用随机采样邻居节点的方式降
层图卷积就将特征传递给了整个网络中的大部分节 低了每次卷积需要计算的节点数目，但是这种估计
点，而对于网络中的边缘节点，需要很多次的传播才
方式是有偏差的，同时无法保证收敛性．基于方差控
能影响网络中的部分节点．跳跃知识网络（Ｊｕｍｐｉｎｇ
制的算法Ｃｏｎｔｒｏｌ Ｖａｒｉａｔｅ Ｂａｓｅｄ Ａｌｇｏｒｉｔｈｍ（ＣＶ）［４７］
Ｋｎｏｗｌｅｄｇｅ Ｎｅｔｗｏｒｋ）［４４］使用跳跃连接（ｊｕｍｐ ｃｏｎ－ 在ＮＳ的基础上利用那些没有被采样到的节点的历
ｎｅｃｔｉｏｎｓ）和注意力机制为每个节点选择合适的传播
史表达（ｈｉｓｔｏｒｉｃａｌ ａｃｔｉｖａｔｉｏｎ）来控制方差．该方法认
范围．跳跃知识网络的模型结构如图１７所示． 为节点ｖ的表达ｈ和它的历史表达ｈ珔 在参数变化
ｖ ｖ
跳跃连接将每一层图卷积的结果都连接到网络 不大的情况下，应该很接近．因此对于没有采样到的 ５期 徐冰冰等：图卷积神经网络综述 ７６９
节点，用它的历史表达来近似． 能重复共享父亲节点减少了重复计算．
ＣＶ，ＮＳ以及原始 ＧＣＮ的区别如图１８所示， 节点级的采样和层级采样的区别如图１９所示．
红色的节点表示最新的表达，蓝色的节点表示历史 在节点级的采样中，每个父节点的邻域不会被其他
的表达．如图所示，ＮＳ和 ＣＶ 方法相比于传统的 父节点看到，因此邻居和其他父节点之间的连接未
ＧＣＮ明显减少了每次卷积操作需要用到的邻居个 被使用．相反，对于层级采样，所有邻居由上一层的
数．ＮＳ仅仅使用采样的邻居节点来估计整个邻居 节点共享，因此所有层间连接都被利用了［４９］．
的表达，方差大．而ＣＶ方法每次需要采样的邻居节
点数目和ＮＳ方法相同，同时利用上一轮迭代的邻
居节点的表达来估计那些没有被采样到的节点的表
达，可以减少对中心节点表达估计的方差．
图１９ 不同采样方法示意图［４９］
４．２．３ 半监督节点分类问题的训练技术
ＧＣＮ在半监督节点分类问题中取得了有效地
结果，但是由于所采用的卷积算子隐式地认为所有
图１８ 邻居采样方法对比示意图［４７］（ＣＶ，ＮＳ以及原始ＧＣＮ 一阶邻居同等重要，导致ＧＣＮ对于处于网络数据
在更新节点表达时需要依赖节点的对比，红色的节 中心的节点的分类效果不佳［５６］．ＤＧＣＮ［５６］指出当去
点代表更新后的表示，蓝色的节点是更新前的表达
（（ａ）原始的ＧＣＮ更新所有依赖的节点，（ｂ）ＮＳ采 除掉这类节点中的某些连边后能提升 ＧＣＮ 的效
样的方法只依赖于部分邻居节点，（ｃ）ＣＶ方法需要 果，说明只利用一阶邻居的邻近性具有一定的局限
依赖的节点））
性，需要引入额外的信息来区分一阶邻居．ＤＧＣＮ
ＣＶ和ＮＳ是节点级的采样方法，以ＧＣＮ［１９］为
通过引入ＰＰＭＩ矩阵的方式减少了一阶邻居对节点
例，其图卷积操作可以写成期望形式：
的影响，同时引入了相比一阶邻居更加丰富的关系．
ｈ（ｌ＋１）（ｖ ｉ）＝σ Ｗ（ｌ）（Ｎ（ｖ ｉ）" ｐ（ｕｊ｜ｖｉ）［ｈ（ｌ）（ｕ ｊ）］）（３６）
利用ＰＰＭＩ进行卷积能够将ＧＣＮ中分错的一些点
σ Ｗ（ｌ）表示线性特征变换以及非线性激活函数，ｐ（ｕ ｊ｜
纠正，但同时也引入了新的错误，因此作者采用集成
ｖ）是给定节点ｖ的情况下，采样到节点ｕ的概率．此
ｉ ｉ ｊ 学习的方式结合两种不同卷积的优势，提升分类效
类方法的关键在于如何很好地估计概率ｐ（ｕ｜ｖ）．
ｊ ｉ 果．其模型结构如图２０所示：两个卷积算子共享降
虽然此类方法可以将每个节点需要考虑的节点数限
维参数Ｗ，Ｌ表示交叉熵，希望图卷积网络Ａ能够
定在常数级别，但是对于每个节点需要考虑的节点 ０
将节点正确分类，Ｌ 是无监督的约束，希望对于同
数随着网络层数增加依旧是呈指数增长的．同时各 ｒｅｇ
一个节点，经过两个卷积神经网络得到的表示相同．
个节点之间的采样过程是独立的，因此在邻居节点
之间没法复用上一层出现的节点．
层级采样方法不再以节点为单位进行采样，而
是对于每一层卷积网络采样需要用到的节点，即每
一层从原图中采样出一个子图，只对采样到的节点
进行卷积操作，同时所有的节点共享上一层的父亲
图２０ ＤＧＣＮ模型结构示意图［５６］
节点．层级采样方法可以理解成一种重要性采样方法
（ｉｍｐｏｒｔａｎｃｅ ｓａｍｐｌｉｎｇ），用全局的概率ｑ（ｕ｜ｖ，…，
ｊ １ ５ 应 用
ｖ）估计采样概率ｐ（ｕ｜ｖ）．ＦａｓｔＧＣＮ［４８］和Ａｄａｐｔ［４９］
ｎ ｊ ｉ
均采用层级采样方法来加速ＧＣＮ．两者的区别在于
图卷积神经网络自提出以来，受到了研究人员
ＦａｓｔＧＣＮ认为层与层之间的采样是独立的 ，而
的大量关注，主要集中于以下几个领域：网络分析、
Ａｄａｐｔ认为低层网络在采样时应该受到上层采样结
推荐系统、生物化学、交通预测、计算机视觉、自然语
果的影响（越低层越靠近输入）．在这种模式下，需要
言处理等．图卷积神经网络的应用领域既包括计算
采样的节点个数和网络层数变成了线性关系，同时 ７７０ 计 算 机 学 报 ２０２０年
机科学、人工智能、信号处理等传统机器学习领域， 关系也各有不同，如何结合领域知识对给定的图数据
也包括物理、生物、化学、社会科学等跨学科的研究． 利用图卷积神经网络进行建模是图卷积神经网络应
不同的领域包含各种不同的图数据，节点和连边 用的关键问题．我们在表４总结了常见的应用分类．
表４ 图卷积神经网络应用领域总结表
应用领域 节点 连边 应用问题 任务 相关论文
用户 社交关系 用户影响力预测 图回归 ＤｅｅｐＩｎｆ［５７］
网络分析
论文 引用关系 半监督节点分类 节点分类 ＧＣＮ［１９］，ＧＡＴ［２８］，ＧＷＮＮ［２１］
道路中的 ＤＣＲＮＮ［５８］，ＴＧＣ－ＬＳＴＭ［５９］，ＧＧＲＵ［６０］，Ｙｕ等人［６１］，
交通预测 物理距离 道路流量预测 节点回归
传感器 ＧＣＮ－ＧＡＮ［６２］
推荐系统 用户，商品
购买某商品的
用户偏好推荐
矩阵补全／ ＭＧＣＮＮ［２５］，ＧＣ－ＭＣ［６３］，ＰｉｎＳａｇｅ［４６］，ＲｉｐｐｌｅＮｅｔ［６４］，
可能性分数 链接预测 ＧｒａｐｈＲｅｃ［６５］
Ｄｕｖｅｎａｕｄ等人［６６］，Ｋｅａｒｎｅｓ等人［６７］，ＭＰＮＮｓ［２６］，
小分子 化学键 化学功能预测 图分类
ＤＩＦＦＰＯＯＬ［５２］，ＧＡＭ［６８］
生物化学 小分子 化学键 分子发现 图生成 ＭｏｌＧＡＮ［６９］，ＧＣＰＮ［７０］
蛋白质 相互作用 蛋白质预测 图分类 Ｆｏｕｔ等人［７１］，Ｇｒａｐｈ－ＣＮＮｓ［７２］
蛋白质／药物 相互作用 副作用预测 链接预测 Ｄｅｃａｇｏｎ［７３］
少样本学习／ Ｇａｒｃｉａ等人［７４］，Ｍａｒｉｎｏ等人［７５］，Ｌｅｅ等人［７６］，
实体概念 语义关系 图片分类
零样本学习 Ｗａｎｇ等人［７７］，ＡＤＧＰＭ［７８］
计算机 语义分割／
３Ｄ点云图 距离信息 语义分割 ３ＤＧＮＮ［７９］，Ｗａｎｇ等人［８０］，ＳＰＧ［８１］，ＲＧＣＮＮ［８２］
视觉 形状分类
对象之间的 场景图生成／
对象 图生成 Ｇｒａｐｈ ＶＱＡ［８３］，ＧＲＭ［８４］，Ｃｈｅｎ等人［８５］
关联 视觉推理
概念实体 语义关系 知识推理 链接预测 ＧＮＮ－ｆｏｒ－ＯＯＫＢ［８６］
语义角色标注／
Ｓｅｍａｎｔｉｃ ＧＣＮ［８７］，ＬＳＴＭ＋ＧＣＮ［８８］，Ｃ－ＧＣＮ［８９］，
词 依赖关系 抽象含义 关系提取
自然语言 Ｓｏｎｇ等人［９０］
表达
处理
词 依赖关系 事件提取 序列标注 ＪＭＥＥ［９１］，Ｎｇｕｙｅｎ等人［９２］
词 关系标记 机器翻译 序列生成 Ｂａｓｔｉｎｇｓ等人［９３］，Ｂｅｃｋ等人［９４］
词 共现关系 文本分类 图分类 ＨＲ－ＤＧＣＮＮ［９５］，ＴｅｘｔＧＣＮ［９６］
５．１ 网络分析 表５ 半监督节点分类常用数据集
在社会网络分析领域，引文网络是最为常见的
数据集 Ｃｏｒａ ＣｉｔｅＳｅｅｒ ＰｕｂＭｅｄ ＮＥＬＬ
数据，即节点为论文，连边关系为引用关系，常见的 类别 引用网络 知识图谱
节点数 ２７０８ ３３２７ １９７１７ ６５７５５
数据集包括Ｃｏｒａ，ＤＢＬＰ，Ｃｉｔｅｓｅｅｒ等．这些常见的
边数 ５４２９ ４７３２ ４４３３８ ２６６１４４
网络的数据集的描述如表５．一个典型的分类任务 类别数 ７ ６ ３ ２１０
特征 １４３３ ３７０３ ５００ ５４１４
是给定每篇文章的内容信息和文章之间的引用关
标签比例 ０．０５２ ０．０３６ ０．００３ ０．００３
系，将每篇文章分类到对应的领域中．例如，在节点
的半监督分类场景下，已知节点的属性信息包括文 表６ 半监督节点分类不同模型结果 （单位：％）
章的标题或摘要信息，以及节点之间的引用关系构 数据集属性
方法
Ｃｏｒａ ＣｉｔｅＳｅｅｒ ＰｕｂＭｅｄ
成的网络信息，给定少量的数据标签，通过机器学习
ＭＬＰ ５５．１ ４６．５ ７１．４
的方式，对网络中的每个节点的所属领域进行划分． ＭａｎｉＲｅｇ ５９．５ ６０．１ ７０．７
在该任务中，图卷积神经网络将节点文本属性和引 ＳｅｍｉＥｍｂ ５９．０ ５９．６ ７１．７
ＬＰ ６８．０ ４５．３ ６３．０
用网络结构有效的建模，取得了巨大的成功．如表６
ＤｅｅｐＷａｌｋ ６７．２ ４３．２ ６５．３
所示，相比直接使用内容信息（如 ＭＬＰ），仅使用结 ＩＣＡ ７５．１ ６９．１ ７３．９
Ｐｌａｎｅｔｏｉｄ ７５．７ ６４．７ ７７．２
构信息（如ＤｅｅｐＷａｌｋ［１４］）和传统图上半监督节点分
Ｓｐｅｃｔｒａｌ ＣＮＮ ７３．３ ５８．９ ７３．９
类方法（如Ｐｌａｎｅｔｏｉｄ［９７］），以ＧＣＮ为代表的图卷积 ＣｈｅｂｙＮｅｔ ８１．２ ６９．８ ７４．４
ＭｏＮｅｔ ８１．７±０．５ ７０．３ ７９．０
神经网络算法的分类准确率远高于传统的方法，其 ＧＣＮ ８１．５ — ７８．８±０．３
中，ＧＡＴ 相比 Ｐｌａｎｅｔｏｉｄ模型在 Ｃｏｒａ、Ｃｉｔｅｓｅｅｒ、 ＧＡＴ ８３．０±０．７ ７２．５±０．７ ７９．０±０．３
ＧＷＮＮ ８２．８ ７１．７ ７９．１
Ｐｕｂｍｅｄ上，分别提升７．３％，７．８％和１．８％．该任
务也通常被视为衡量一个图卷积神经网络模型是否 另外一个较为常见的基准任务为图分类任务，
有效的基准任务．ＧＣＮ［１９］，ＧＡＴ［２８］，ＧＷＮＮ［２１］等 对于给定的图结构，每个图有一个标签，通过学习图
都使用该任务验证模型的有效性． 结构的模式，达到图分类的任务．图分类的数据集［９８］ ５期 徐冰冰等：图卷积神经网络综述 ７７１
主要包括生物化学结构分类（如 Ｅｎｚｙｍｅｓ、Ｄ＆Ｄ、 测问题，提出基于不同消息传播的图自编码框架对
Ｐｒｏｔｅｉｎｓ等）、社交网络分类（如Ｒｅｄｄｉｔ－Ｍｕｌｔｉ－１２ｋ） 推荐系统的二部图进行建模，在包含社交网络的数
和科学合作网络（如Ｃｏｌｌａｂ）等．相关的数据集描述 据上取得了最好的结果．Ｌｅｓｋｏｖｅｃ等人［４６］将卷积
见表７．而不同的模型的分类结果见表８，图卷积神 神经网络应用到推荐系统中，其提出一个数据高效
经网络相比传统的图核的方法，也取得了明显的提 的图卷积神经网络算法ＰｉｎＳａｇｅ，对商品节点产生
升．其中，ＤＩＦＦＰＯＯＬ相比 Ｇｒａｐｈｌｅｔ，在Ｅｎｚｙｍｅｓ、 嵌入表达．这些表达包含了图结构和节点特征信息，
Ｄ＆Ｄ、Ｐｒｏｔｅｉｎｓ、Ｒｅｄｄｉｔ－Ｍｕｌｔｉ－１２ｋ和Ｃｏｌｌａｂ上，分别提 相比传统的图卷积方式，其提出了一个高效的随机
升２１．５％、５．８０％、３．３４％、２５．３５％和１０．８２％．图卷 游走策略建模卷积，设计了一个新的训练策略，成功
积神经网络在图节点分类和图分类的机器学习任务 地将图卷积神经网络应用到节点数为１０亿级的超
上相比传统的图表示学习和图核方法取得了效果上 大规模推荐系统中．Ｗａｎｇ等人［６４］提出 ＲｉｐｐｌｅＮｅｔ
的明显提升． 框架，引入知识图谱信息，提高了推荐系统的性能．
Ｆａｎ等人［６５］提出ＧｒａｐｈＲｅｃ框架，包括用户建模，商
表７ 图分类任务常用数据集
品建模和打分预测３个部分，使用注意力机制，有效
数据集属性
数据集
图的数量 类别数 图平均节点数 图平均边数 地建模了用户的交互信息和用户的社交网络信息．
Ｅｎｚｙｍｅｓ ６００ ６ ３２．６３ ６２．１４
Ｄ＆Ｄ １１７８ ２ ２８４．３２ ７１５．６６
Ｐｒｏｔｅｉｎｓ １１１３ ２ ３９．０６ ７２．８３
Ｒｅｄｄｉｔ－Ｍｕｌｔｉ－１２ｋ １１９２９ １１ ３９１．４１ ４５６．８９
Ｃｏｌｌａｂ ５０００ ３ ７４．４９ ２４５７．７８
表８ 图分类不同模型结果 （单位：％）
数据集
方法
Ｅｎｚｙｍｅｓ Ｄ＆Ｄ Ｐｒｏｔｅｉｎｓ Ｒｅｄｄｉｔ－Ｍｕｌｔｉ－１２ｋＣｏｌｌａｂ
Ｇｒａｐｈｌｅｔ ４１．０３ ７４．８５ ７２．９１ ２１．７３ ６４．６６
Ｓｈｏｒｔｅｓｔ－ｐａｔｈ ４２．３２ ７８．８６ ７６．４３ ３６．９３ ５９．１０
图２１ 推荐系统中的矩阵补全和链接预测建模示意图［２５］
１－ＷＬ ５３．４３ ７４．０２ ７３．７６ ３９．０３ ７８．６１
ＷＬ－ＯＡ ６０．１３ ７９．０４ ７５．２６ ４４．３８ ８０．７４
图卷积神经网络被认为能够很好地建模图的结
ＰａｔｃｈｙＳａｎ — ７６．２７ ７５．００ ４１．３２ ７２．６０
ＧｒａｐｈＳＡＧＥ ５４．２５ ７５．４２ ７０．４８ ４２．２４ ６８．２５
构属性和节点特征信息，而推荐系统既可以被视为
ＥＣＣ ５３．５０ ７４．１０ ７２．６５ ４１．７３ ６７．７９ 一个矩阵补全问题，也可以被视为是二部图（用户和
Ｓｅｔ２ｓｅｔ ６０．１５ ７８．１２ ７４．２９ ４３．４９ ７１．７５
商品）的链接预测问题．相比传统的方法，图卷积神
ＳｏｒｔＰｏｏｌ ５７．１２ ７９．３７ ７５．５４ ４１．８２ ７３．７６
ＤＩＦＦＰＯＯＬ ６２．５３ ８０．６４ ７６．２５ ４７．０８ ７５．４８ 经网络能够更好地利用在推荐系统中普遍存在的用
ＥｉｇｅｎＧＣＮ ６４．５０ ７８．６０ ７６．６０ — — 户属性和商品属性信息，这也是图卷积神经网络能
此外，在社区发现问题上，过去的算法主要是将 够在推荐系统任务上引起人们广泛关注的原因．
其显式的定义和优化图分区最小割问题．Ｃｈｅｎ等 ５．３ 交通预测
人［９９］提出了一个新的图神经网络模型用于社区发 交通预测问题也是图卷积神经网络得到广泛应
现，该方法是纯数据驱动而无需基础生成模型，其在 用的任务之一．其目的是在给定历史交通速度和路
线图的情况下，预测未来的交通的速率．在交通预测
社区发现任务上取得了良好的结果．其他的网络分
析例如信息传播［５７，１００］、社交网络地理位置信息预
问题中，如图２２所示，节点表示在道路中放置的传
测［１０１］等都有相关研究者引入图卷积神经网络，使得
感器，而边则表示节点对的物理距离．每个节点包含
一个时序的特征．相比于传统的图分析问题．交通预
网络的结构信息和节点属性信息得到了有效的建模．
测问题中包括时间和空间两个方面的建模，而如何
５．２ 推荐系统
利用图卷积神经网络更好地建模交通中的路网带来
人们通过将其视为矩阵补全或者链接预测的方
了机遇和挑战．
式，能够有效地建模商品和用户之间的联系如图２１．
Ｌｉ等人［５８］提出扩散卷积循环神经网络（ＤＣＲＮＮ）
Ｍｏｎｔｉ等人［２６］将多图卷积神经网络和循环神经网
建模交通预测．在该模型中，其将交通流量视为一个
络相结合，其中多图卷积神经网络被用来提取局部
有向图上的扩散问题，提出通过使用扩散卷积的方
静止的特征，而循环神经网络能够扩散分数值，重建
式来建模图结构化数据．使用循环神经网络来建模
矩阵．Ｂｅｒｇ等人［６３］将推荐系统建模为图上的链接预 ７７２ 计 算 机 学 报 ２０２０年
图２３ 分子图［６７］和蛋白质交互网络示意图
Ｄｕｖｅｎａｕｄ等人［６６］直接在图上定义卷积神经网
图２２ 加利福利亚州第七街区ＰｅＭＳ传感器网络示
意图［６１］（其中每个点表示传感器，图中包含两 络．该神经网络模型输入为任意大小或形状的分子，
组数据ＰｅＭＳＤ７（Ｍ）和ＰｅＭＳＤ７（Ｌ））
通过端到端地学习分子指纹．该模型能够更好地帮
时间依赖．在两个大规模道路网络交通数据集上 助实现特定功能的分子设计．Ｋｅａｒｎｅｓ等人［６７］使用
取得了１２％～１５％的提升．Ｃｕｉ等人［５９］提出一个交 图卷积神经网络对原子、键和距离进行编码，能够更
通图卷积长短时记忆网络（ＴＧＣ－ＬＳＴＭ）学习道路 好地利用图结构中的信息．其提供了新的基于配体
网络和时变的交通模式．其定义图卷积神经网络 的虚拟筛选的范式．Ｇｉｌｍｅｒ等人［２６］提出消息传播模
在物理的路网拓扑结构上．实验结果表明该方法 型 ＭＰＮＮｓ预测给定分子的化学性质．Ｌｅｅ等人［６８］
能够捕获有效存在于车辆交通网络中的复杂的时 提出图注意力模型（ＧＡＭ），自适应地选择一些“信
空依赖．Ｚｈａｎｇ等人［６０］提出图门递归单元（ＧＧＲＵ） 息节点”进而收集整个图的信息，用于图分类问题．
解决交通流量预测问题，其将图门递归单元应用 Ｓｕｃｈ等人［７２］直接将滤波器定义为图邻接矩阵
于循环神经网络的编码解码模型，应用在洛杉矶 的函数的多项式，提出 Ｇｒａｐｈ－ＣＮＮｓ模型，能够处
高数公路数据集上．Ｙｕ等人［６１］提出一个新的深度 理异构和同质的图数据．在分子分类问题上，表现出
学习框架，空间时间图卷积神经网络（ＳＴＧＣＮ），解 了最好的实验结果．Ｚｉｔｎｉｋ等人［７３］使用图卷积神经
决在交通领域中的时序预测问题．在该框架中，其首 网络建模多种药物副作用．其首先构建蛋白质－蛋白
先形式化问题到图上使用卷积结构进行建模，由于 质交互，药物－蛋白质靶标相互作用和多种药物相互
更好地利用了拓扑结构，其在短期和中长期交通预 作用的多模态图．在图中，每种副作用被视为一个不
测上取得了相比传统机器学习方法显著的提升． 同类型的边缘．进而将对与药物副作用的建模转化
在交通预测相关的场景下，如何解决时空依赖 为一个链接预测问题，为进一步研究药理学提供了
是重要的研究方向，由于图卷积神经网络提供了一 新的研究思路．Ｆｏｕｔ等人［７１］提出将图卷积神经网
种解决图数据问题建模的方案，其通过和循环神经 络应用到蛋白质交互预测中．在该任务中，蛋白质是
网络等时序模型的结合，给出了一个建模交通预测 氨基酸残基链，折叠成三维结构，赋予它们生化功
问题的良好的解决思路．而如何进一步更细粒度考 能．蛋白质通过与其他蛋白质相互作用的复杂网络
虑时空数据建模依然是未来研究的热点． 发挥其功能．Ｃａｏ等人［６９］提出 ＭｏｌＧＡＮ，该模型通
５．４ 生物化学 过生成对抗网络结合图卷积神经网络，设计出包含
除了传统的图数据的建模外，图卷积神经网络 特定化学性质的分子结构．Ｙｏｕ等人［７０］提出图卷积
在生物化学等领域也受到了研究人员的大量关注． 策略网络（ＧＣＰＮ），一个基于通用图卷积和强化学
相比传统的图数据的研究，在生物化学领域，人们通 习来生成目标图的模型．该模型通过消息传播的方
常将一个化学结构或一个蛋白质视为一个图，图中 式令隐藏状态为节点表达，然后产生策略π．通过采
的节点是更小的分子，边代表键或者相互作用．其中 样的方式选择策略ａ，然后环境给出化学检测的状
图２３（ａ）是布洛芬分子图，节点为碳氢氧原子，连边 态和奖励ｒ．实验表明该方法相比基线方法，在化学
ｔ
为化学键．图２３（ｂ）是ＦＡＡ４蛋白质交互网络，节点 性质优化上有６１％的提升．
代表蛋白质，连边为相互作用．研究人员关注于一个 生物化学领域主要集中于对于分子拓扑结构的
图的化学功能，即研究对象不再是图中的节点，而是 建模，这些问题中，许多的化学结构和性质体现在图
整个图本身． 本身的结构特性上．使用图卷积神经网络对这些分 ５期 徐冰冰等：图卷积神经网络综述 ７７３
子结构的刻画能够显著地帮助到包括新药发现、药 场景图（Ｓｅｎｃｅ ｇｒａｐｈ）等，如图２４．
物分类等任务． 其中，少样本学习旨在使用较少的样本训练能
５．５ 计算机视觉 够识别出一个全新的样本．其通常包含两个阶段：元
在计算机视觉中，图卷积神经网络的应用主要 训练和元测试，如图２５（ａ）所示．在该任务中，数据集
集中于少样本学习（Ｆｅｗ－Ｓｈｏｔ Ｌｅａｒｎｉｎｇ）、零样本学 包括：训练集，支持集和测试集．支持集和测试集共享
习（Ｚｅｒｏ－Ｓｈｏｔ Ｌｅａｒｎｉｎｇ）、点云建模（Ｐｏｉｎｔ Ｃｌｏｕｄｓ）、 相同的标签空间，但训练集有单独的标签空间，且与
支持／测试集不相交．如果支持集包含每个类包含
Ｋ个标签样本，Ｃ个类别，则该问题被称为Ｃ－ｗａｙ
Ｋ－ｓｈｏｔ问题［１０３］．常见的数据集包括：Ｏｍｎｉｇｌｏｔ和
ｍｉｎｉＩｍａｇｅＮｅｔ．其中 Ｏｍｎｉｇｌｏｔ包含 Ｏｍｎｉｇｌｏｔ数据
集包含来自５０个不同字母的１６２３个不同手写字
符．ｍｉｎｉＩｍａｇｅＮｅｔ则包含１００个不同类别，每个类
别６００样本的８４×８４的ＲＧＢ图片．少样本学习由
于存在较少的训练样本，因此需要进一步刻画出不
图２４ 计算机视觉中常见的图卷积神经网络应用场
同的物体或者概念之间的语义关系，常见的方法包
景：３Ｄ点云图片和场景图生成［７９，１０２］
括引入知识图谱，构建图片之间的全链接图等方式．
图２５ 自然语言处理中常见的图结构场景：依存句法图，抽象含义表达和文档共词矩阵［９０，９２，９５］
Ｇａｒｃｉａ等人［７４］定义一个全连接的图，其中节点 点云图是指３Ｄ扫描器产生的，某个坐标系下
是图片，连边是图片和图片之间的相似度，他们使用 的点的集合，其包含了３Ｄ的坐标信息、颜色等相比
图神经网络对节点进行编码，使用神经消息传播模 ２Ｄ图片更多的几何信息．Ｑｉ等人［７９］使用图神经网
型能够更好地利用图片之间的关联结构信息，其在 络实现了 ＲＧＢＤ图片的语义分割任务．Ｗａｎｇ等
少样本、半监督和主动学习等任务上取得了较好的 人［８０］在点云上使用图卷积神经网络，提出通过边卷
实验结果，其结果见表９．Ｍａｒｉｎｏ等人［７５］将知识图 积的方式收集边的特征，既包含了局部领域的信息，
谱引入到图片分类任务中，其使用图卷积神经网络 也通过堆叠或循环的方式学习到全局的几何属性．
更好地利用在知识图谱中的先验知识．在ＣＯＣＯ数 该模型在形状分类（Ｓｈａｐｅ Ｃｌａｓｓｉｆｉｃａｔｉｏｎ）和局部分
据集的多标签分类任务上取得了提升．Ｌｅｅ等人［７６］ 割（Ｐａｒｔ Ｓｅｇｍｅｎｔａｔｉｏｎ）任务上取得了不错的结果．
同样将知识图谱引入到零样本学习任务中，在多标 Ｌａｎｄｒｉｅｕ等人［８１］使用消息传播机制在点云图上进
签分类任务中取得了提升．Ｋａｍｐｆｆｍｅｙｅｒ等人［７８］在 行建模．
使用知识图谱时，定义先祖和后继传播两种方式，能 场景图是另一类在计算机视觉领域较为常见的
够更好地利用图谱中的语义信息． 图结构数据，其节点是物体，边的特征代表其空间关 ７７４ 计 算 机 学 报 ２０２０年
表９ 不同模型在少样本数据集Ｏｍｎｉｇｌｏｔ和Ｍｉｎｉ－Ｉｍａｇｅｎｅｔ的结果 （单位：％）
Ｏｍｎｉｇｌｏｔ ｍｉｎｉＩｍａｇｅＮｅｔ
模型 ５－Ｗａｙ ２０－Ｗａｙ ５－Ｗａｙ
１－ｓｈｏｔ ５－ｓｈｏｔ １－ｓｈｏｔ ５－ｓｈｏｔ １－ｓｈｏｔ ５－ｓｈｏｔ
Ｐｉｘｅｌｓ ４１．７０ ６３．２０ ２６．７０ ４２．６０ — —
Ｓｉａｍｅｓｅ Ｎｅｔ ９７．３０ ９８．４０ ８８．２０ ９７．００ — —
Ｍａｔｃｈｉｎｇ Ｎｅｔｗｏｒｋｓ ９８．１０ ９８．９０ ９３．８０ ９８．５０ ４３．６０ ５５．３０
Ｎ．Ｓｔａｔｉｓｔｉｃｉａｎ ９８．１０ ９９．５０ ９３．２０ ９８．１０ — —
Ｐｒｏｔｏｔｙｐｉｃａｌ Ｎｅｔｗｏｒｋｓ ９７．４０ ９９．３０ ９５．４０ ９８．８０ ４６．６１±０．７８ ６５．７７±０．７０
ＣｏｎｖＮｅｔ ｗｉｔｈ Ｍｅｍｏｒｙ ９８．４０ ９９．６０ ９５．００ ９８．６０ — —
Ａｇｎｏｓｔｉｃ Ｍｅｔａ－ｌｅａｒｎｅｒ ９８．７±０．４ ９９．９±０．３ ９５．８±０．３ ９８．９±０．２ ４８．７０±１．８４ ６３．１±０．９２
Ｍｅｔａ Ｎｅｔｗｏｒｋｓ ９８．９０ — ９７．００ — ４９．２１±０．９６ —
ＴＣＭＬ ９８．９６±０．２０ ９９．７５±０．１１ ９７．６４±０．３０ ９９．３６±０．１８ ５５．７１±０．９９ ６８．８８±０．９２
Ｇａｒｃｉａ等人ＧＮＮ ９９．２０ ９９．７０ ９７．４０ ９９．００ ５０．３３±０．３６ ６６．４１±０．６３
系．相比传统描述的句子线性结构，图结构包含了更 加使用，应用于语义角色标注上．
多有价值的语义信息．如何使用图卷积神经网络建 除了上述的图谱外，词共现网络也被应用于文
模场景图受到了大量的关注．Ｔｅｎｅｙ等人［８３］通过场 本分类任务上．其中节点是非停用词，连边是在给定
景图和句子依存句法图的建模，在视觉问答上得到 窗口下的词共现关系．Ｄｅｆｆｅｒｒａｒｄ等人［１８］提出了一
了有效的应用．Ｃｈｅｎ等人［８５］则提出３个图模块：知 个在图谱理论上定义的卷积神经网络，它提供了必
识图谱、图片区域空间关联图和区域类别分布图，在 要的数学背景和有效的数值方案来设计图上的快速
可视化回答上进行了有效地建模． 局部卷积滤波器．Ｈｅｎａｆｆ等人［２０］使用图卷积神经网
总的来说，在计算机视觉领域，人们在完成了包 络在 Ｒｅｕｔｅｒｓ数据集上的文本分类任务．Ｙａｏ等
括物体识别，图片分类，语义分割后，计算机视觉更 人［９６］通过构建共词网络和文档关系网络，将图卷积
关注物体在少量样本，复杂语义情况下的建模和学 神经网络应用到文本分类任务上，在不使用外部知
习．在这些场景下，图是重要的数据结构，而图卷积 识和单词表达的情况下，取得了最好的结果．Ｐｅｎｇ
神经网络是建模该图数据有效的方法． 等人［９５］从原始文本基于词共现网络和一个给定的
５．６ 自然语言处理 窗口大小，构建了一个图．然后使用图卷积操作进而
图卷积神经网络在自然语言处理领域有大量的 实现对于文本的分类任务．
应用．在该领域中，较为常见的图数据为知识图谱、 大量的研究表明，在使用图卷积神经网络模型
句法依赖图和抽象含义表达图、词共现图以及其他 后，各项自然语言处理任务的结果都出现了一定的
方式构建的图．抽象含义表达 Ａｂｓｔｒａｃｔ Ｍｅａｎｉｎｇ 提升．图结构的使用，使得对象之间的复杂的语义关
Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ（ＡＭＲ）是一种将一个句子的含义编 系得到了有效地挖掘．相比传统的对于自然语言处
码为有根有向图．Ｂａｓｔｉｎｇｓ等人［９３］将图卷积神经网 理的序列化建模，使用图卷积神经网络能够挖掘出
络作用于依存句法树上，应用在英语和德语、英语和 非线性的复杂语义关系．
捷克语的机器翻译任务．Ｂｅｃｋ等人［９４］使用门限图 ５．７ 其他
神经网络（ＧＧＮＮ）在抽象含义图上，作用于基于语 在除了上述的应用领域外，包括程序推断、优化
法的机器翻译任务． 求解［１０５－１０６］等任务上，图卷积神经网络都开始被人
依存句法图或树，节点是单词，连边是语义关 们使用．由于其可以建模在现实生活中常见的图数
系．Ｌｉｕ等人［９１］和Ｎｇｕｙｅｎ等人［９２］使用图卷积神经 据，并且通过卷积、注意力或消息传播等机制，能够
网络应用于事件提取，这里使用的图是依存句法树． 将网络的拓扑结构和节点属性等信息以神经网络进
Ｓｏｎｇ等人［１０４］将图卷积神经网络作用于阅读理解、 行捕获和建模，因此图卷积神经网络有广泛的应用
抽象含义图到文本的生成任务和关系提取等任务 前景．
上．语义角色标注Ｓｅｍａｎｔｉｃ Ｒｏｌｅ Ｌａｂｅｌｉｎｇ（ＳＲＬ）的
任务是给定一个句子，识别出句子中的谓语和对应 ６ 未来研究方向展望
的对象．Ｍａｒｃｈｅｇｇｉａｎｉ等人［８７］提出使用图卷积神经
网络作用于句法依赖图，并且和长短时记忆网络叠 虽然图卷积网络在近些年取得了成功，但仍然 ５期 徐冰冰等：图卷积神经网络综述 ７７５
有些没有克服的问题和值得深入研究的方向． ６．５ 图数据的复杂特性
６．１ 深层的网络结构 在实际场景中，网络往往具有复杂的结构特
传统的深度学习模型，在堆叠了大量网络层后， 性［１１０］．例如节点的类型，边上的复杂特征［１１１］，网络
由于其强大的表示能力，在很多问题上了取得了显 的社区结构［１１２］等等．虽然目前有不少工作提出了
著地效果．但是在图卷积神经网络模型中，在堆叠了 一些解决方案，但它们都是针对某一种特性设计的
较少的层数后，网络就达到最好效果，同时再增加图 网络．能否设计一种网络能同时建模网络的各种复
卷积层反而会使得结果变差．因为图卷积包含了聚 杂特性，也是一个值得探讨的问题．
合邻居节点特征的操作，当网络堆叠多层后使得节 ６．６ 图神经网络上的对抗攻击
点之间的特征过于平滑，缺乏区分性．ＧＣＮ的实验 神经网络在各项任务中大放异彩，但仍然具有
结果显示［１９］，当网络层数超过两层后，随着层数增 不稳定的问题［１１３］．例如对图片增加一定噪声，在人
加，ＧＣＮ在半监督节点分类问题上的效果反而会下 眼看来图片的类型没有发生变化，但是神经网络已
降．同时随着网络的不断叠加，最终所有的节点会学 经将其判断成其他的类型．通过设计一种有针对性
到相同的表达．图神经网络是否需要深层的结构，或 的样本从而让机器学习模型做出误判，这便被称为
者说能否设计出一种深层的网络结构能避免过于平 对抗性攻击．在图神经网络领域，利用节点自身的特
滑的问题，是一个迫切需要解决的研究问题． 征和网络结构构造对抗样本［１１４］，以及设计能防御
６．２ 大规模数据 对抗攻击的图神经网络，都是未来发展的一个重要
在实际场景中，网络的规模往往非常大，比如新 方向．
浪微博，Ｔｗｉｔｔｅｒ等社交关系网络，往往包含了数亿 ６．７ 图神经网络的可解释性
级的节点和边．而目前绝大部分的图卷积神经网络 深度学习模型的可解释性与可视化一直是深度
模型都不适用于这种大规模的网络．比如基于谱方 学习领域备受关注的方向，图结构给图神经网络的
法的图卷积神经网络需要计算图拉普拉斯矩阵的特 可解释性与可视化带来了新的挑战．如何可视化图
征向量矩阵，而这个操作的计算复杂度和空间复杂 神经网络学到的结构模式对于理解图神经网络的工
度都很高，难以用于大规模网络．而空间方法，在更 作原理有重要意义［１１５］．图神经网络已经在很多场
新节点表达时依赖于大量的邻居节点，也使得计算 景下取得了显著的效果，Ｘｕ等人［５１］尝试给出了一
代价过大，不适用于大规模网络．虽然近些年已经有 种解释，但是如何从理论上说明图神经网络为什么
一些基于采样的方法来处理大规模网络数据的问 能取得显著的提升仍然是一个没有解决的问题．
题［２９，４６，４８］，但是这一问题仍然没有得到有效解决．
６．３ 多尺度的图上任务 ７ 总 结
图挖掘任务，根据主体对象的不同可以分成节
点级的问题［１９］，图以及子图级的问题［６６］以及信号级 图卷积神经网络是处理图数据的高效模型，在
的问题［５８］．节点级任务的关键点在于为每个节点学 过去几年受到研究者的广泛关注，本文充分总结了
习有效地表达，而为图学习表达是图级别任务的关 近些年的图卷积神经网络模型．
键．信号级任务的关键点在网络结构不变的情况下， 图卷积神经网络主要面对的三个挑战：图数据
为不同的图信号学习有效地表达．目前绝大部分的 是非欧空间数据，图数据具有多样的特性，以及图数
图卷积神经网络是针对节点级任务设计的，对于图 据的规模很大．
级别和信号级别的任务关注较少． 在第３节中重点介绍了该领域的主流方法，现
６．４ 动态变化的图数据 有的方法主要分为谱方法和空间方法两类，谱方法
在实际场景中，网络往往具有动态性．这种动态 利用图上傅里叶变换和卷积定理从谱域定义图卷
性包括不断随时间变换的节点与边上的特征，不断 积，空间方法在节点域定义加权函数在聚合中心节
变换的网络的结构（有新的边，节点加入网络也有节 点及其邻居节点的特征．我们同时还总结了最近新
点和边从网络中消失）．考虑网络的动态性也是图挖 涌现出的图卷积神经网络模型，并且分析了其适用
掘的算法的趋势［１０７－１０９］．而目前的图卷积神经网络都 场景优缺点．对于图卷积神经网络适用的应用问题
是针对静态的网络设计的，因此设计能建模网络动态 进行了整理分类，讨论了未来可能的发展方向．总的
变化的图卷积神经网络也是未来的一个重要方向． 来说，目前图卷积神经网络取得了一定的效果，但是 ７７６ 计 算 机 学 报 ２０２０年
仍然有一些问题需要解决，相信图卷积神经网络会 ［１３］ Ｑｉ Ｊｉｎ－Ｓｈａｎ，Ｌｉａｎｇ Ｘｕｎ，Ｌｉ Ｚｈｉ－Ｙｕ，ｅｔ ａｌ．Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ
在图数据的场景中被充分地使用． ｌｅａｒｎｉｎｇ ｏｆ ｌａｒｇｅ－ｓｃａｌｅ ｃｏｍｐｌｅｘ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋ：Ｃｏｎｃｅｐｔｓ，
ｍｅｔｈｏｄｓ ａｎｄ ｃｈａｌｌｅｎｇｅｓ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，
２０１８，４１（１０）：２３９４－２４１９（ｉｎ Ｃｈｉｎｅｓｅ）
参 考 文 献
（齐金山，梁循，李志宇等．大规模复杂信息网络表示学习：
概念、方法与挑战．计算机学报，２０１８，４１（１０）：２３９４－２４１９）
［１］ ＬｅＣｕｎ Ｙ，Ｂｏｔｔｏｕ Ｌ，Ｂｅｎｇｉｏ Ｙ，Ｈａｆｆｎｅｒ Ｐ．Ｇｒａｄｉｅｎｔ－ｂａｓｅｄ ［１４］ Ｐｅｒｏｚｚｉ Ｂ，Ａｌ－Ｒｆｏｕ Ｒ，Ｓｋｉｅｎａ Ｓ．ＤｅｅｐＷａｌｋ：Ｏｎｌｉｎｅ ｌｅａｒｎｉｎｇ
ｌｅａｒｎｉｎｇ ａｐｐｌｉｅｄ ｔｏ ｄｏｃｕｍｅｎｔ ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ｏｆ ｓｏｃｉａｌ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０ｔｈ ＡＣＭ
ＩＥＥＥ，１９９８，８６（１１）：２２７８－２３２４
ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ
［２］ Ｚｈｏｕ Ｆｅｉ－Ｙａｎ，Ｊｉｎ Ｌｉｎ－Ｐｅｎｇ，Ｄｏｎｇ Ｊｕｎ．Ｒｅｖｉｅｗ ｏｆ ｃｏｎｖｏｌｕ－ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１４：７０１－７１０
ｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１７， ［１５］ Ｔａｎｇ Ｊｉａｎ，Ｑｕ Ｍｅｎｇ，Ｗａｎｇ Ｍｉｎｇｚｈｅ，ｅｔ ａｌ．Ｌｉｎｅ：Ｌａｒｇｅ－ｓｃａｌｅ
４０（６）：１２２９－１２５１（ｉｎ Ｃｈｉｎｅｓｅ）
ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋ ｅｍｂｅｄｄｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ
（周飞燕，金林鹏，董军．卷积神经网络研究综述．计算机学
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｆｌｏｒｅｎｃｅ，
报，２０１７，４０（６）：１２２９－１２５１）
Ｉｔａｌｙ，２０１５：１０６７－１０７７
［３］ Ｚｈａｎｇ Ｓｈｕｎ，Ｇｏｎｇ Ｙｉ－Ｈｏｎｇ，Ｗａｎｇ Ｊｉｎ－Ｊｕｎ．Ｔｈｅ ｄｅｖｅｌｏｐｍｅｎｔ
［１６］ Ｇｒｏｖｅｒ Ａ，Ｌｅｓｋｏｖｅｃ Ｊ．ｎｏｄｅ２ｖｅｃ：Ｓｃａｌａｂｌｅ ｆｅａｔｕｒｅ ｌｅａｒｎｉｎｇ
ｏｆ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｎｄ ｉｔｓ ａｐｐｌｉｃａｔｉｏｎｓ ｏｎ
ｆｏｒ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２２ｎｄ ＡＣＭ ＳＩＧＫＤＤ
ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１９，４２（３）：
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ
４５３－４８２（ｉｎ Ｃｈｉｎｅｓｅ）
Ｍｉｎｉｎｇ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１６：８５５－８６４
（张顺，龚怡宏，王进军．深度卷积神经网络的发展及其在计
［１７］ Ｂｒｕｎａ Ｊ，Ｚａｒｅｍｂａ Ｗ，Ｓｚｌａｍ Ａ，ＬｅＣｕｎ Ｙ．Ｓｐｅｃｔｒａｌ ｎｅｔｗｏｒｋｓ
算机视觉领域的应用．计算机学报，２０１９，４２（３）：４５３－４８２）
ａｎｄ ｌｏｃａｌｌｙ ｃｏｎｎｅｃｔｅｄ ｎｅｔｗｏｒｋｓ ｏｎ ｇｒａｐｈｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
［４］ Ｈｕ Ｂａｏｔｉａｎ，Ｌｕ Ｚｈｅｎｇｄｏｎｇ，Ｌｉ Ｈａｎｇ，Ｃｈｅｎ Ｑｉｎｇｃａｉ．Ｃｏｎｖｏ－
ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｌｅａｒｎｉｎｇ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ
ｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｒｃｈｉｔｅｃｔｕｒｅｓ ｆｏｒ ｍａｔｃｈｉｎｇ ｎａｔｕｒａｌ
（ＩＣＬＲ２０１４）．Ｂａｎｆｆ，Ｃａｎａｄａ，２０１４：ＵＲＬ ｈｔｔｐ：／／ａｒｘｉｖ．ｏｒｇ／
ｌａｎｇｕａｇｅ ｓｅｎｔｅｎｃｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ
ａｂｓ／１３１２．６２０３
Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，２０１４：
［１８］ Ｄｅｆｆｅｒｒａｒｄ Ｍ，Ｂｒｅｓｓｏｎ Ｘ，Ｖａｎｄｅｒｇｈｅｙｎｓｔ Ｐ．Ｃｏｎｖｏｌｕｔｉｏｎａｌ
２０４２－２０５０
ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｏｎ ｇｒａｐｈｓ ｗｉｔｈ ｆａｓｔ ｌｏｃａｌｉｚｅｄ ｓｐｅｃｔｒａｌ
［５］ Ｈｅ Ｋａｉｍｉｎｇ，Ｚｈａｎｇ Ｘｉａｎｇｙｕ，Ｒｅｎ Ｓｈａｏｑｉｎｇ，Ｓｕｎ Ｊｉａｎ．Ｄｅｅｐ
ｆｉｌｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ
ｒｅｓｉｄｕａｌ ｌｅａｒｎｉｎｇ ｆｏｒ ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｂａｒｃｅｌｏｎａ，Ｓｐａｉｎ，２０１６：３８４４－３８５２
ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
［１９］ Ｋｉｐｆ Ｔ Ｎ，Ｗｅｌｌｉｎｇ Ｍ．Ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｗｉｔｈ
Ｌａｓ Ｖｅｇａｓ，ＵＳＡ，２０１６：７７０－７７８
ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１６０９．
［６］ Ｈｉｎｔｏｎ Ｇ，Ｄｅｎｇ Ｌ，Ｙｕ Ｄ，ｅｔ ａｌ．Ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ
０２９０７，２０１６
ａｃｏｕｓｔｉｃ ｍｏｄｅｌｉｎｇ ｉｎ ｓｐｅｅｃｈ ｒｅｃｏｇｎｉｔｉｏｎ：Ｔｈｅ ｓｈａｒｅｄ ｖｉｅｗｓ ｏｆ
［２０］ Ｈｅｎａｆｆ Ｍ，Ｂｒｕｎａ Ｊ，ＬｅＣｕｎ Ｙ．Ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ
ｆｏｕｒ ｒｅｓｅａｒｃｈ ｇｒｏｕｐｓ．ＩＥＥＥ Ｓｉｇｎａｌ Ｐｒｏｃｅｓｓｉｎｇ Ｍａｇａｚｉｎｅ，
ｏｎ ｇｒａｐｈ－ｓｔｒｕｃｔｕｒｅｄ ｄａｔａ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１５０６．０５１６３，
２０１２，２９（６）：８２－９７
２０１５
［７］ Ｓｈｕｍａｎ Ｄ Ｉ，Ｎａｒａｎｇ Ｓ Ｋ，Ｆｒｏｓｓａｒｄ Ｐ，ｅｔ ａｌ．Ｔｈｅ ｅｍｅｒｇｉｎｇ
ｆｉｅｌｄ ｏｆ ｓｉｇｎａｌ ｐｒｏｃｅｓｓｉｎｇ ｏｎ ｇｒａｐｈｓ：Ｅｘｔｅｎｄｉｎｇ ｈｉｇｈ－ｄｉｍｅｎ－
［２１］ Ｘｕ Ｂｉｎｇｂｉｎｇ，Ｓｈｅｎ Ｈｕａｗｅｉ，Ｃａｏ Ｑｉ，ｅｔ ａｌ．Ｇｒａｐｈ ｗａｖｅｌｅｔ
ｎｅｕｒａｌ ｎｅｔｗｏｒｋ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ
ｓｉｏｎａｌ ｄａｔａ ａｎａｌｙｓｉｓ ｔｏ ｎｅｔｗｏｒｋｓ ａｎｄ ｏｔｈｅｒ ｉｒｒｅｇｕｌａｒ ｄｏｍａｉｎｓ．
ＩＥＥＥ Ｓｉｇｎａｌ Ｐｒｏｃｅｓｓｉｎｇ Ｍａｇａｚｉｎｅ，２０１３，３０（３）：８３－９８
ｏｎ Ｌｅａｒｎｉｎｇ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ．Ｎｅｗ Ｏｒｌｅａｎｓ，ＵＳＡ，２０１９
［８］ Ｚｈｏｕ Ｊｉｅ，Ｃｕｉ Ｇａｎｑｕ，Ｚｈａｎｇ Ｚｈｅｎｇｙａｎ，Ｙａｎｇ Ｃｈｅｎｇ，ｅｔ ａｌ． ［２２］ Ｘｕ Ｂｉｎｇｂｉｎｇ，Ｓｈｅｎ Ｈｕａｗｅｉ，Ｃａｏ Ｑｉ，ｅｔ ａｌ．Ｇｒａｐｈ ｃｏｎｖｏｌｕ－
Ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ：Ａ ｒｅｖｉｅｗ ｏｆ ｍｅｔｈｏｄｓ ａｎｄ ａｐｐｌｉｃａｔｉｏｎｓ． ｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｕｓｉｎｇ ｈｅａｔ ｋｅｒｎｅｌ ｆｏｒ ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ｌｅａｒｎｉｎｇ
ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１８１２．０８４３４，２０１８ ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２８ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
［９］ Ｗｕ Ｚｏｎｇｈａｎ，Ｐａｎ Ｓｈｉｒｕｉ，Ｃｈｅｎ Ｆｅｎｇｗｅｎ，ｅｔ ａｌ．Ａ ｃｏｍｐｒｅ－ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｍａｃａｏ，Ｃｈｉｎａ，２０１９：１９２８－１９３４
ｈｅｎｓｉｖｅ ｓｕｒｖｅｙ ｏｎ ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ［２３］ Ｋｌｉｃｐｅｒａ Ｊ，Ｂｏｊｃｈｅｖｓｋｉ Ａ，Ｇüｎｎｅｍａｎｎ Ｓ．Ｐｒｅｄｉｃｔ ｔｈｅｎ
ａｒＸｉｖ：１９０１．００５９６，２０１９ ｐｒｏｐａｇａｔｅ：Ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｍｅｅｔ ｐｅｒｓｏｎａｌｉｚｅｄ ＰａｇｅＲａｎｋ
［１０］ Ｐａｇｅ Ｌ，Ｂｒｉｎ Ｓ，Ｍｏｔｗａｎｉ Ｒ，Ｗｉｎｏｇｒａｄ Ｔ．Ｔｈｅ ＰａｇｅＲａｎｋ ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｌｅａｒｎｉｎｇ
ｃｉｔａｔｉｏｎ ｒａｎｋｉｎｇ：Ｂｒｉｎｇｉｎｇ ｏｒｄｅｒ ｔｏ ｔｈｅ Ｗｅｂ．Ｓｔａｎｆｏｒｄ Ｄｉｇｉｔａｌ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ．Ｎｅｗ Ｏｒｌｅａｎｓ，ＵＳＡ，２０１９
Ｌｉｂｒａｒｉｅｓ Ｗｏｒｋｉｎｇ Ｐａｐｅｒ，１９９８，９（１）：１－１４ ［２４］ Ｗｕ Ｆ，Ｚｈａｎｇ Ｔ，ｄｅ Ｓｏｕｚａ Ｊｒ Ａ Ｈ，ｅｔ ａｌ．Ｓｉｍｐｌｉｆｙｉｎｇ ｇｒａｐｈ
［１１］ Ｋｌｅｉｎｂｅｒｇ Ｊ Ｍ．Ｈｕｂｓ，ａｕｔｈｏｒｉｔｉｅｓ，ａｎｄ ｃｏｍｍｕｎｉｔｉｅｓ．ＡＣＭ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１９０２．０７１５３，
Ｃｏｍｐｕｔｉｎｇ Ｓｕｒｖｅｙｓ，１９９９，３１（４ｅｓ）：５ ２０１９
［１２］ Ｎｇ Ａ Ｙ，Ｊｏｒｄａｎ Ｍ Ｉ，Ｗｅｉｓｓ Ｙ．Ｏｎ ｓｐｅｃｔｒａｌ ｃｌｕｓｔｅｒｉｎｇ： ［２５］ Ｍｏｎｔｉ Ｆ，Ｂｏｓｃａｉｎｉ Ｄ，Ｍａｓｃｉ Ｊ，ｅｔ ａｌ．Ｇｅｏｍｅｔｒｉｃ ｄｅｅｐ ｌｅａｒｎｉｎｇ
Ａｎａｌｙｓｉｓ ａｎｄ ａｎ ａｌｇｏｒｉｔｈｍ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ ｏｎ ｇｒａｐｈｓ ａｎｄ ｍａｎｉｆｏｌｄｓ ｕｓｉｎｇ ｍｉｘｔｕｒｅ ｍｏｄｅｌ ＣＮＮｓ／／
Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｖａｎｃｏｕｖｅｒ，Ｃａｎａｄａ， Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ
２００２：８４９－８５６ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｈｏｎｏｌｕｌｕ，ＵＳＡ，２０１７：５４２５－５４３４ ５期 徐冰冰等：图卷积神经网络综述 ７７７
［２６］ Ｇｉｌｍｅｒ Ｊ，Ｓｃｈｏｅｎｈｏｌｚ Ｓ Ｓ，Ｒｉｌｅｙ Ｐ Ｆ，ｅｔ ａｌ．Ｎｅｕｒａｌ ｍｅｓｓａｇｅ ［４１］ Ｗａｎｇ Ｘｉａｏ，Ｊｉ Ｈｏｕｙｅ，Ｓｈｉ Ｃｈｕａｎ，ｅｔ ａｌ．Ｈｅｔｅｒｏｇｅｎｅｏｕｓ
ｐａｓｓｉｎｇ ｆｏｒ ｑｕａｎｔｕｍ ｃｈｅｍｉｓｔｒｙ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３４ｔｈ ｇｒａｐｈ ａｔｔｅｎｔｉｏｎ ｎｅｔｗｏｒｋ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｗｏｒｌｄ Ｗｉｄｅ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｓｙｄｎｅｙ， Ｗｅｂ Ｃｏｎｆｅｒｅｎｃｅ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１９：２０２２－２０３２
Ａｕｓｔｒａｌｉａ，２０１７：１２６３－１２７２ ［４２］ Ｌｅｅ Ｊ Ｂ，Ｒｏｓｓｉ Ｒ Ａ，Ｋｏｎｇ Ｘ，ｅｔ ａｌ．Ｈｉｇｈｅｒ－ｏｒｄｅｒ ｇｒａｐｈ
［２７］ Ｓｃａｒｓｅｌｌｉ Ｆ，Ｇｏｒｉ Ｍ，Ｔｓｏｉ Ａ Ｃ，ｅｔ ａｌ．Ｔｈｅ ｇｒａｐｈ ｎｅｕｒａｌ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１８０９．０７６９７，
ｎｅｔｗｏｒｋ ｍｏｄｅｌ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ， ２０１８
２００９，２０（１）：６１－８０ ［４３］ Ｍｏｎｔｉ Ｆ，Ｏｔｎｅｓｓ Ｋ，Ｂｒｏｎｓｔｅｉｎ Ｍ Ｍ．ＭｏｔｉｆＮｅｔ：Ａ ｍｏｔｉｆ－
［２８］ Ｖｅｌｉˇｃｋｏｖｉ＇ｃ Ｐ，Ｃｕｃｕｒｕｌｌ Ｇ，Ｃａｓａｎｏｖａ Ａ，ｅｔ ａｌ．Ｇｒａｐｈ ａｔｔｅｎｔｉｏｎ ｂａｓｅｄ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋ ｆｏｒ ｄｉｒｅｃｔｅｄ ｇｒａｐｈｓ／／
ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｄａｔａ Ｓｃｉｅｎｃｅ Ｗｏｒｋｓｈｏｐ．Ｌａｕｓａｎｎｅ，
Ｌｅａｒｎｉｎｇ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ．Ｖａｎｃｏｕｖｅｒ，Ｃａｎａｄａ，２０１８ Ｓｗｉｔｚｅｒｌａｎｄ，２０１８：２２５－２２８
［２９］ Ｈａｍｉｌｔｏｎ Ｗ，Ｙｉｎｇ Ｚ，Ｌｅｓｋｏｖｅｃ Ｊ．Ｉｎｄｕｃｔｉｖｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ［４４］ Ｘｕ Ｋ，Ｌｉ Ｃ，Ｔｉａｎ Ｙ，ｅｔ ａｌ．Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｏｎ
ｌｅａｒｎｉｎｇ ｏｎ ｌａｒｇｅ ｇｒａｐｈｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ ｇｒａｐｈｓ ｗｉｔｈ ｊｕｍｐｉｎｇ ｋｎｏｗｌｅｄｇｅ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｌｏｎｇ Ｂｅａｃｈ，ＵＳＡ， ｔｈｅ ３５ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．
２０１７：１０２４－１０３４ Ｓｔｏｃｋｈｏｌｍ，Ｓｗｅｄｅｎ，２０１８：５４４９－５４５８
［３０］ Ａｔｗｏｏｄ Ｊ，Ｔｏｗｓｌｅｙ Ｄ．Ｄｉｆｆｕｓｉｏｎ－ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ［４５］ Ｌｉ Ｑｉｍａｉ，Ｈａｎ Ｚｈｉｃｈａｏ，Ｗｕ Ｘｉａｏ－Ｍｉｎｇ．Ｄｅｅｐｅｒ ｉｎｓｉｇｈｔｓ ｉｎｔｏ
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ｌｅａｒｎｉｎｇ／／
Ｓｙｓｔｅｍｓ．Ｂａｒｃｅｌｏｎａ，Ｓｐａｉｎ，２０１６：１９９３－２００１ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３２ｎｄ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ
［３１］ Ｖａｓｈｉｓｈｔｈ Ｓ，Ｙａｄａｖ Ｐ，Ｂｈａｎｄａｒｉ Ｍ，Ｔａｌｕｋｄａｒ Ｐ．Ｃｏｎｆｉｄｅｎｃｅ－ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｎｅｗ Ｏｒｌｅａｎｓ，ＵＳＡ，２０１８：３５５８－３５６５
ｂａｓｅｄ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ［４６］ Ｙｉｎｇ Ｒ，Ｈｅ Ｒｕｉｎｉｎｇ，Ｃｈｅｎ Ｋａｉｆｅｎｇ，ｅｔ ａｌ．Ｇｒａｐｈ ｃｏｎｖｏｌｕ－
ｌｅａｒｎｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｗｅｂ－ｓｃａｌｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／
Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ ａｎｄ Ｓｔａｔｉｓｔｉｃｓ．Ｎａｈａ，Ｊａｐａｎ，２０１９： Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒ－
１７９２－１８０１ ｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ＆ Ｄａｔａ Ｍｉｎｉｎｇ．Ｌｏｎｄｏｎ，
［３２］ Ｆｅｎｇ Ｙｉｆａｎ，Ｙｏｕ Ｈａｏｘｕａｎ，Ｚｈａｎｇ Ｚｉｚｈａｏ，ｅｔ ａｌ．Ｈｙｐｅｒｇｒａｐｈ Ｕｎｉｔｅｄ Ｋｉｎｇｄｏｍ，２０１８，９７４－９８３
ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３３ｒｄ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ［４７］ Ｃｈｅｎ Ｊｉａｎｆｅｉ，Ｚｈｕ Ｊｕｎ．Ｓｔｏｃｈａｓｔｉｃ ｔｒａｉｎｉｎｇ ｏｆ ｇｒａｐｈ ｃｏｎｖｏｌｕ－
ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｈｏｎｏｌｕｌｕ，ＵＳＡ，２０１９：３５５８－３５６５ ｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３５ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ
［３３］ Ｓｃｈｌｉｃｈｔｋｒｕｌｌ Ｍ，Ｋｉｐｆ Ｔ Ｎ，Ｂｌｏｅｍ Ｐ，ｅｔ ａｌ．Ｍｏｄｅｌｉｎｇ ｒｅｌａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｓｔｏｃｋｈｏｌｍ，Ｓｗｅｄｅｎ，
ｄａｔａ ｗｉｔｈ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１７：９４１－９４９
Ｅｕｒｏｐｅａｎ Ｓｅｍａｎｔｉｃ Ｗｅｂ Ｃｏｎｆｅｒｅｎｃｅ．Ｈｅｒａｋｌｉｏｎ，Ｇｒｅｅｃｅ， ［４８］ Ｃｈｅｎ Ｊｉｅ，Ｍａ Ｔｅｎｇｆｅｉ，Ｘｉａｏ Ｃａｏ．ＦａｓｔＧＣＮ：Ｆａｓｔ ｌｅａｒｎｉｎｇ
２０１８：５９３－６０７ ｗｉｔｈ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｖｉａ ｉｍｐｏｒｔａｎｃｅ ｓａｍｐｌｉｎｇ／／
［３４］ Ｂｕｓｂｒｉｄｇｅ Ｄ，Ｓｈｅｒｂｕｒｎ Ｄ，Ｃａｖａｌｌｏ Ｐ，Ｈａｍｍｅｒｌａ Ｎ Ｙ． Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｌｅａｒｎｉｎｇ
Ｒｅｌａｔｉｏｎａｌ ｇｒａｐｈ ａｔｔｅｎｔｉｏｎ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ： Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ．Ｖａｎｃｏｕｖｅｒ，Ｃａｎａｄａ，２０１８
１９０４．０５８１１，２０１９ ［４９］ Ｈｕａｎｇ Ｗｅｎｂｉｎｇ，Ｚｈａｎｇ Ｔｏｎｇ，Ｒｏｎｇ Ｙｕ，Ｈｕａｎｇ Ｊｕｎｚｈｏｕ．
［３５］ Ｄｅｒｒ Ｔ，Ｍａ Ｙ，Ｔａｎｇ Ｊ．Ｓｉｇｎｅｄ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ Ａｄａｐｔｉｖｅ ｓａｍｐｌｉｎｇ ｔｏｗａｒｄｓ ｆａｓｔ ｇｒａｐｈ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ／／
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１８ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ
Ｄａｔａ Ｍｉｎｉｎｇ（ＩＣＤＭ）．Ｓｉｎｇａｐｏｒｅ，２０１８：９２９－９３４ Ｓｙｓｔｅｍｓ．Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，２０１８：４５６３－４５７２
［３６］ Ｍｏｎｔｉ Ｆ，Ｓｈｃｈｕｒ Ｏ，Ｂｏｊｃｈｅｖｓｋｉ Ａ，ｅｔ ａｌ．Ｄｕａｌ－ｐｒｉｍａｌ ｇｒａｐｈ ［５０］ Ｈａｍｍｏｎｄ Ｄ Ｋ，Ｖａｎｄｅｒｇｈｅｙｎｓｔ Ｐ，Ｇｒｉｂｏｎｖａｌ Ｒ．Ｗａｖｅｌｅｔｓ
ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１８０６．００７７０， ｏｎ ｇｒａｐｈｓ ｖｉａ ｓｐｅｃｔｒａｌ ｇｒａｐｈ ｔｈｅｏｒｙ．Ａｐｐｌｉｅｄ ａｎｄ Ｃｏｍｐｕｔａ－
２０１８ ｔｉｏｎａｌ Ｈａｒｍｏｎｉｃ Ａｎａｌｙｓｉｓ，２０１１，３０（２）：１２９－１５０
［３７］ Ｇｏｎｇ Ｌｉｙｕ，Ｃｈｅｎｇ Ｑｉａｎｇ．Ａｄａｐｔｉｖｅ ｅｄｇｅ ｆｅａｔｕｒｅｓ ｇｕｉｄｅｄ ［５１］ Ｘｕ Ｋ，Ｈｕ Ｗ，Ｌｅｓｋｏｖｅｃ Ｊ，Ｊｅｇｅｌｋａ Ｓ．Ｈｏｗ ｐｏｗｅｒｆｕｌ ａｒｅ
ｇｒａｐｈ ａｔｔｅｎｔｉｏｎ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１８０９．０２７０９， ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ？／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ
２０１８ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｌｅａｒｎｉｎｇ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ．Ｎｅｗ Ｏｒｌｅａｎｓ，
［３８］ Ｓｉｍｏｎｏｖｓｋｙ Ｍ，Ｋｏｍｏｄａｋｉｓ Ｎ．Ｄｙｎａｍｉｃ ｅｄｇｅ－ｃｏｎｄｉｔｉｏｎｅｄ ＵＳＡ，２０１９
ｆｉｌｔｅｒｓ ｉｎ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｏｎ ｇｒａｐｈｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ［５２］ Ｙｉｎｇ Ｚ，Ｙｏｕ Ｊ，Ｍｏｒｒｉｓ Ｃ，ｅｔ ａｌ．Ｈｉｅｒａｒｃｈｉｃａｌ ｇｒａｐｈ ｒｅｐｒｅ－
ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ ｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｗｉｔｈ ｄｉｆｆｅｒｅｎｔｉａｂｌｅ ｐｏｏｌｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｈｏｎｏｌｕｌｕ，ＵＳＡ，２０１７：３６９３－３７０２ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．
［３９］ Ｚｈｏｕ Ｚｈｅｎｐｅｎｇ，Ｌｉ Ｘｉａｏｃｈｅｎｇ．Ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ：Ａ ｈｉｇｈ－ Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，２０１８：４８０５－４８１５
ｏｒｄｅｒ ａｎｄ ａｄａｐｔｉｖｅ ａｐｐｒｏａｃｈ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１７０６． ［５３］ Ｃａｎｇｅａ Ｃ，Ｖｅｌｉˇｃｋｏｖｉ＇ｃ Ｐ，Ｊｏｖａｎｏｖｉ＇ｃ Ｎ，ｅｔ ａｌ．Ｔｏｗａｒｄｓ ｓｐａｒｓｅ
０９９１６，２０１７ ｈｉｅｒａｒｃｈｉｃａｌ ｇｒａｐｈ ｃｌａｓｓｉｆｉｅｒｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１８１１．
［４０］ Ｓａｎｋａｒ Ａ，Ｚｈａｎｇ Ｘ，Ｃｈａｎｇ Ｋ Ｃ Ｃ．Ｍｏｔｉｆ－ｂａｓｅｄ ｃｏｎｖｏｌｕｔｉｏｎａｌ ０１２８７，２０１８
ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｏｎ ｇｒａｐｈｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１７１１．０５６９７， ［５４］ Ｍａ Ｙ，Ｗａｎｇ Ｓ，Ａｇｇａｒｗａｌ Ｃ Ｃ，Ｔａｎｇ Ｊ．Ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ
２０１７ ｎｅｔｗｏｒｋｓ ｗｉｔｈ ｅｉｇｅｎｐｏｏｌｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２５ｔｈ ＡＣＭ ７７８ 计 算 机 学 报 ２０２０年
ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ＆ ［６８］ Ｌｅｅ Ｊ Ｂ，Ｒｏｓｓｉ Ｒ，Ｋｏｎｇ Ｘ．Ｇｒａｐｈ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｕｓｉｎｇ
Ｄａｔａ Ｍｉｎｉｎｇ．Ａｎｃｈｏｒａｇｅ，ＵＳＡ，２０１９：７２３－７３１ ｓｔｒｕｃｔｕｒａｌ ａｔｔｅｎｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ ＡＣＭ ＳＩＧＫＤＤ
［５５］ Ｌｅｅ Ｊ，Ｌｅｅ Ｉ，Ｋａｎｇ Ｊ．Ｓｅｌｆ－ａｔｔｅｎｔｉｏｎ ｇｒａｐｈ ｐｏｏｌｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ＆Ｄａｔａ
ｏｆ ｔｈｅ ３６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ． Ｍｉｎｉｎｇ．Ｌｏｎｄｏｎ，ＵＫ，２０１８：１６６６－１６７４
Ｌｏｎｇ Ｂｅａｃｈ，ＵＳＡ，２０１９：３７３４－３７４３ ［６９］ Ｄｅ Ｃａｏ Ｎ，Ｋｉｐｆ Ｔ．ＭｏｌＧＡＮ：Ａｎ ｉｍｐｌｉｃｉｔ ｇｅｎｅｒａｔｉｖｅ ｍｏｄｅｌ
［５６］ Ｚｈｕａｎｇ Ｃｈｅｎｙｉ， Ｍａ Ｑｉａｎｇ．Ｄｕａｌ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｆｏｒ ｓｍａｌｌ ｍｏｌｅｃｕｌａｒ ｇｒａｐｈｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１８０５．
ｎｅｔｗｏｒｋｓ ｆｏｒ ｇｒａｐｈ－ｂａｓｅｄ ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ｃｌａｓｓｉｆｉｃａｔｉｏｎ／／ １１９７３，２０１８
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１８ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ［７０］ Ｙｏｕ Ｊｉａｘｕａｎ，Ｌｉｕ Ｂｏｗｅｎ，Ｙｉｎｇ Ｚｈｉｔａｏ，ｅｔ ａｌ．Ｇｒａｐｈ ｃｏｎｖｏ－
Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｌｙｏｎ，Ｆｒａｎｃｅ，２０１８：４９９－５０８ ｌｕｔｉｏｎａｌ ｐｏｌｉｃｙ ｎｅｔｗｏｒｋ ｆｏｒ ｇｏａｌ－ｄｉｒｅｃｔｅｄ ｍｏｌｅｃｕｌａｒ ｇｒａｐｈ
［５７］ Ｑｉｕ Ｊｉｅｚｈｏｎｇ，Ｔａｎｇ Ｊｉａｎ，Ｍａ Ｈａｏ，ｅｔ ａｌ．ＤｅｅｐＩｎｆ：Ｓｏｃｉａｌ ｇｅｎｅｒａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ
ｉｎｆｌｕｅｎｃｅ ｐｒｅｄｉｃｔｉｏｎ ｗｉｔｈ ｄｅｅｐ ｌｅａｒｎｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｍｏｎｔｒéａｌ，Ｃａｎａｄａ，２０１８：６４１２－６４２２
２４ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ ［７１］ Ｆｏｕｔ Ａ，Ｂｙｒｄ Ｊ，Ｓｈａｒｉａｔ Ｂ，Ｂｅｎ－Ｈｕｒ Ａ．Ｐｒｏｔｅｉｎ ｉｎｔｅｒｆａｃｅ
Ｄｉｓｃｏｖｅｒｙ＆Ｄａｔａ Ｍｉｎｉｎｇ．Ｌｏｎｄｏｎ，ＵＫ，２０１８：２１１０－２１１９ ｐｒｅｄｉｃｔｉｏｎ ｕｓｉｎｇ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
［５８］ Ｌｉ Ｙ，Ｙｕ Ｒ，Ｓｈａｈａｂｉ Ｃ，Ｌｉｕ Ｙ．Ｄｉｆｆｕｓｉｏｎ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．
ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ：Ｄａｔａ－ｄｒｉｖｅｎ ｔｒａｆｆｉｃ ｆｏｒｅｃａｓｔｉｎｇ／／ Ｌｏｎｇ Ｂｅａｃｈ，ＵＳＡ，２０１７：６５３０－６５３９
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｌｅａｒｎｉｎｇ ［７２］ Ｓｕｃｈ Ｆ Ｐ，Ｓａｈ Ｓ，Ｄｏｍｉｎｇｕｅｚ Ｍ Ａ，ｅｔ ａｌ．Ｒｏｂｕｓｔ ｓｐａｔｉａｌ
Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ．Ｖａｎｃｏｕｖｅｒ，ＢＣ，Ｃａｎａｄａ，２０１８ ｆｉｌｔｅｒｉｎｇ ｗｉｔｈ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．ＩＥＥＥ
［５９］ Ｃｕｉ Ｚ，Ｈｅｎｒｉｃｋｓｏｎ Ｋ，Ｋｅ Ｒ，Ｗａｎｇ Ｙ．Ｔｒａｆｆｉｃ ｇｒａｐｈ ｃｏｎｖｏ－ Ｊｏｕｒｎａｌ ｏｆ Ｓｅｌｅｃｔｅｄ Ｔｏｐｉｃｓ ｉｎ Ｓｉｇｎａｌ Ｐｒｏｃｅｓｓｉｎｇ，２０１７，１１（６）：
ｌｕｔｉｏｎａｌ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ：Ａ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆｒａｍｅｗｏｒｋ ８８４－８９６
ｆｏｒ ｎｅｔｗｏｒｋ－ｓｃａｌｅ ｔｒａｆｆｉｃ ｌｅａｒｎｉｎｇ ａｎｄ ｆｏｒｅｃａｓｔｉｎｇ．ａｒＸｉｖ： ［７３］ Ｚｉｔｎｉｋ Ｍ，Ａｇｒａｗａｌ Ｍ，Ｌｅｓｋｏｖｅｃ Ｊ．Ｍｏｄｅｌｉｎｇ ｐｏｌｙｐｈａｒｍａｃｙ
１８０２．０７００７，２０１８ ｓｉｄｅ ｅｆｆｅｃｔｓ ｗｉｔｈ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ．Ｂｉｏｉｎｆｏｒｍａｔｉｃｓ，
［６０］ Ｚｈａｎｇ Ｊｉａｎｉ，Ｓｈｉ Ｘｉｎｇｊｉａｎ，Ｘｉｅ Ｊｕｎｙｕａｎ，ｅｔ ａｌ．ＧａＡＮ：Ｇａｔｅｄ ２０１８，３４（１３）：ｉ４５７－ｉ４６６
ａｔｔｅｎｔｉｏｎ ｎｅｔｗｏｒｋｓ ｆｏｒ ｌｅａｒｎｉｎｇ ｏｎ ｌａｒｇｅ ａｎｄ ｓｐａｔｉｏｔｅｍｐｏｒａｌ ［７４］ Ｇａｒｃｉａ Ｖ，Ｂｒｕｎａ Ｊ．Ｆｅｗ－ｓｈｏｔ ｌｅａｒｎｉｎｇ ｗｉｔｈ ｇｒａｐｈ ｎｅｕｒａｌ
ｇｒａｐｈｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
Ｕｎｃｅｒｔａｉｎｔｙ ｉｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｃａｌｉｆｏｒｎｉａ，ＵＳＡ， Ｌｅａｒｎｉｎｇ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ．Ｖａｎｃｏｕｖｅｒ，Ｃａｎａｄａ，２０１８
２０１８：３３９－３４９ ［７５］ Ｍａｒｉｎｏ Ｋ，Ｓａｌａｋｈｕｔｄｉｎｏｖ Ｒ，Ｇｕｐｔａ Ａ．Ｔｈｅ ｍｏｒｅ ｙｏｕ ｋｎｏｗ：
［６１］ Ｙｕ Ｂｉｎｇ，Ｙｉｎ Ｈａｏｔｅｎｇ，Ｚｈｕ Ｚｈａｎｘｉｎｇ．Ｓｐａｔｉｏ－ｔｅｍｐｏｒａｌ Ｕｓｉｎｇ ｋｎｏｗｌｅｄｇｅ ｇｒａｐｈｓ ｆｏｒ ｉｍａｇｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ：Ａ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆｒａｍｅｗｏｒｋ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
ｆｏｒ ｔｒａｆｆｉｃ ｆｏｒｅｃａｓｔｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｈｏｎｏｌｕｌｕ，ＨＩ，ＵＳＡ，２０１７：２０－２８
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｓｔｏｃｋｈｏｌｍ，Ｓｗｅｄｅｎ， ［７６］ Ｌｅｅ Ｃｈｕｎｇ－Ｗｅｉ，Ｆａｎｇ Ｗｅｉ，Ｙｅｈ Ｃｈｉｈ－Ｋｕａｎ，Ｗａｎｇ Ｙｕ－Ｃｈｉａｎｇ
２０１８：３６３４－３６４０ Ｆｒａｎｋ．Ｍｕｌｔｉ－ｌａｂｅｌ ｚｅｒｏ－ｓｈｏｔ ｌｅａｒｎｉｎｇ ｗｉｔｈ ｓｔｒｕｃｔｕｒｅｄ ｋｎｏｗｌｅｄｇｅ
［６２］ Ｌｅｉ Ｋａｉ，Ｑｉｎ Ｍｅｎｇ，Ｂａｉ Ｂｏ，ｅｔ ａｌ．ＧＣＮ－ＧＡＮ：Ａ ｎｏｎ－ｌｉｎｅａｒ ｇｒａｐｈｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ
ｔｅｍｐｏｒａｌ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｍｏｄｅｌ ｆｏｒ ｗｅｉｇｈｔｅｄ－ｄｙｎａｍｉｃ ｎｅｔｗｏｒｋｓ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｓａｌｔ Ｌａｋｅ Ｃｉｔｙ，ＵＳＡ，
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ２０１８：１５７６－１５８５
Ｃｏｍｐｕｔｅｒ Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ．Ｐａｒｉｓ，Ｆｒａｎｃｅ，２０１９：３８８－３９６ ［７７］ Ｗａｎｇ Ｘ，Ｙｅ Ｙ，Ｇｕｐｔａ Ａ．Ｚｅｒｏ－ｓｈｏｔ ｒｅｃｏｇｎｉｔｉｏｎ ｖｉａ ｓｅｍａｎｔｉｃ
［６３］ ｖａｎ ｄｅｎ Ｂｅｒｇ Ｒ，Ｋｉｐｆ Ｔ Ｎ，Ｗｅｌｌｉｎｇ Ｍ．Ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｅｍｂｅｄｄｉｎｇｓ ａｎｄ ｋｎｏｗｌｅｄｇｅ ｇｒａｐｈｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ
ｍａｔｒｉｘ ｃｏｍｐｌｅｔｉｏｎ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１７０６．０２２６３，２０１７ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
［６４］ Ｗａｎｇ Ｈｏｎｇｗｅｉ，Ｚｈａｎｇ Ｆｕｚｈｅｎｇ，Ｗａｎｇ Ｊｉａｌｉｎ，ｅｔ ａｌ．Ｅｘｐｌｏｒｉｎｇ Ｓａｌｔ Ｌａｋｅ Ｃｉｔｙ，ＵＳＡ，２０１８：６８５７－６８６６
ｈｉｇｈ－ｏｒｄｅｒ ｕｓｅｒ ｐｒｅｆｅｒｅｎｃｅ ｏｎ ｔｈｅ ｋｎｏｗｌｅｄｇｅ ｇｒａｐｈ ｆｏｒ ［７８］ Ｋａｍｐｆｆｍｅｙｅｒ Ｍ，Ｃｈｅｎ Ｙ，Ｌｉａｎｇ Ｘ，ｅｔ ａｌ．Ｒｅｔｈｉｎｋｉｎｇ
ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ．ＡＣＭ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ ｋｎｏｗｌｅｄｇｅ ｇｒａｐｈ ｐｒｏｐａｇａｔｉｏｎ ｆｏｒ ｚｅｒｏ－ｓｈｏｔ ｌｅａｒｎｉｎｇ／／
Ｓｙｓｔｅｍｓ，２０１９，３７（３）：３２ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ
［６５］ Ｗａｎｇ Ｘｉａｏ，Ｊｉ Ｈｏｕｙｅ，Ｓｈｉ Ｃｈｕａｎ，ｅｔ ａｌ．Ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔ－ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｌｏｎｇ Ｂｅａｃｈ，ＵＳＡ，２０１９：１１４８７－１１４９６
ｗｏｒｋｓ ｆｏｒ ｓｏｃｉａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｗｏｒｌｄ ［７９］ Ｑｉ Ｘｉａｏｊｕａｎ，Ｌｉａｏ Ｒｅｎｊｉｅ，Ｊｉａ Ｊｉａｙａ，ｅｔ ａｌ．３Ｄｇｒａｐｈ ｎｅｕｒａｌ
Ｗｉｄｅ Ｗｅｂ Ｃｏｎｆｅｒｅｎｃｅ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１９：４１７－４２６ ｎｅｔｗｏｒｋｓ ｆｏｒ ｒｇｂｄ ｓｅｍａｎｔｉｃ ｓｅｇｍｅｎｔａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
［６６］ Ｄｕｖｅｎａｕｄ Ｄ Ｋ，Ｍａｃｌａｕｒｉｎ Ｄ，Ｉｐａｒｒａｇｕｉｒｒｅ Ｊ，ｅｔ ａｌ．Ｃｏｎｖｏｌｕ－ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．
ｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｏｎ ｇｒａｐｈｓ ｆｏｒ ｌｅａｒｎｉｎｇ ｍｏｌｅｃｕｌａｒ ｆｉｎｇｅｒｐｒｉｎｔｓ／／ Ｖｅｎｉｃｅ，Ｉｔａｌｙ，２０１７：５２０９－５２１８
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ ［８０］ Ｗａｎｇ Ｙｕｅ，Ｓｕｎ Ｙｏｎｇｂｉｎ，Ｌｉｕ Ｚｉｗｅｉ，ｅｔ ａｌ．Ｄｙｎａｍｉｃ ｇｒａｐｈ
Ｓｙｓｔｅｍｓ．Ｍｏｎｔｒｅａｌ，Ｑｕｅｂｅｃ，Ｃａｎａｄａ，２０１５：２２２４－２２３２ ｃｎｎ ｆｏｒ ｌｅａｒｎｉｎｇ ｏｎ ｐｏｉｎｔ ｃｌｏｕｄｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：
［６７］ Ｋｅａｒｎｅｓ Ｓ，ＭｃＣｌｏｓｋｅｙ Ｋ，Ｂｅｒｎｄｌ Ｍ，ｅｔ ａｌ．Ｍｏｌｅｃｕｌａｒ ｇｒａｐｈ １８０１．０７８２９，２０１８
ｃｏｎｖｏｌｕｔｉｏｎｓ：Ｍｏｖｉｎｇ ｂｅｙｏｎｄ ｆｉｎｇｅｒｐｒｉｎｔｓ．Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ－ ［８１］ Ｌａｎｄｒｉｅｕ Ｌ，Ｓｉｍｏｎｏｖｓｋｙ Ｍ．Ｌａｒｇｅ－ｓｃａｌｅ ｐｏｉｎｔ ｃｌｏｕｄ ｓｅｍａｎｔｉｃ
Ａｉｄｅｄ Ｍｏｌｅｃｕｌａｒ Ｄｅｓｉｇｎ，２０１６，３０（８）：５９５－６０８ ｓｅｇｍｅｎｔａｔｉｏｎ ｗｉｔｈ ｓｕｐｅｒｐｏｉｎｔ ｇｒａｐｈｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ ５期 徐冰冰等：图卷积神经网络综述 ７７９
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ． ［９３］ Ｂａｓｔｉｎｇｓ Ｊ，Ｔｉｔｏｖ Ｉ，Ａｚｉｚ Ｗ，ｅｔ ａｌ．Ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ
Ｓａｌｔ Ｌａｋｅ Ｃｉｔｙ，ＵＳＡ，２０１８：４５５８－４５６７ ｅｎｃｏｄｅｒｓ ｆｏｒ ｓｙｎｔａｘ－ａｗａｒｅ ｎｅｕｒａｌ ｍａｃｈｉｎｅ ｔｒａｎｓｌａｔｉｏｎ／／
［８２］ Ｔｅ Ｇ，Ｈｕ Ｗ，Ｇｕｏ Ｚ，Ｚｈｅｎｇ Ａ．ＲＧＣＮＮ：Ｒｅｇｕｌａｒｉｚｅｄ ｇｒａｐｈ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１７Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｅｍｐｉｒｉｃａｌ Ｍｅｔｈｏｄｓ ｉｎ
ＣＮＮ ｆｏｒ ｐｏｉｎｔ ｃｌｏｕｄ ｓｅｇｍｅｎｔａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＡＣＭ Ｎａｔｕｒａｌ Ｌａｎｇｕａｇｅ Ｐｒｏｃｅｓｓｉｎｇ．Ｃｏｐｅｎｈａｇｅｎ，Ｄｅｎｍａｒｋ，２０１７：
Ｍｕｌｔｉｍｅｄｉａ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍｕｌｔｉｍｅｄｉａ Ｃｏｎｆｅｒｅｎｃｅ．Ｓｅｏｕｌ， １９５７－１９６７
Ｋｏｒｅａ，２０１８：７４６－７５４ ［９４］ Ｂｅｃｋ Ｄ，Ｈａｆｆａｒｉ Ｇ，Ｃｏｈｎ Ｔ．Ｇｒａｐｈ－ｔｏ－ｓｅｑｕｅｎｃｅ ｌｅａｒｎｉｎｇ
［８３］ Ｔｅｎｅｙ Ｄ，Ｌｉｕ Ｌ，ｖａｎ ｄｅｎ Ｈｅｎｇｅｌ Ａ．Ｇｒａｐｈ－ｓｔｒｕｃｔｕｒｅｄ ｒｅｐｒｅ－ ｕｓｉｎｇ ｇａｔｅｄ ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ５６ｔｈ
ｓｅｎｔａｔｉｏｎｓ ｆｏｒ ｖｉｓｕａｌ ｑｕｅｓｔｉｏｎ ａｎｓｗｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｎｎｕａｌ Ｍｅｅｔｉｎｇ ｏｆ ｔｈｅ Ａｓｓｏｃｉａｔｉｏｎ ｆｏｒ Ｃｏｍｐｕｔａｔｉｏｎａｌ
ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ． Ｌｉｎｇｕｉｓｔｉｃｓ．Ｍｅｌｂｏｕｒｎｅ，Ａｕｓｔｒａｌｉａ，２０１８：２７３－２８３
Ｈｏｎｏｌｕｌｕ，ＵＳＡ，２０１７：３２３３－３２４１ ［９５］ Ｐｅｎｇ Ｈ，Ｌｉ Ｊ，Ｈｅ Ｙ，ｅｔ ａｌ．Ｌａｒｇｅ－ｓｃａｌｅ ｈｉｅｒａｒｃｈｉｃａｌ ｔｅｘｔ
［８４］ Ｗａｎｇ Ｚ，Ｃｈｅｎ Ｔ，Ｒｅｎ Ｊ，ｅｔ ａｌ．Ｄｅｅｐ ｒｅａｓｏｎｉｎｇ ｗｉｔｈ ｋｎｏｗｌｅｄｇｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｗｉｔｈ ｒｅｃｕｒｓｉｖｅｌｙ ｒｅｇｕｌａｒｉｚｅｄ ｄｅｅｐ ｇｒａｐｈ－ＣＮＮ／／
ｇｒａｐｈ ｆｏｒ ｓｏｃｉａｌ ｒｅｌａｔｉｏｎｓｈｉｐ ｕｎｄｅｒｓｔａｎｄｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ
ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ． Ｗｅｂ．Ｌｙｏｎ，Ｆｒａｎｃｅ，２０１８：１０６３－１０７２
Ｓｔｏｃｋｈｏｌｍ，Ｓｗｅｄｅｎ，２０１８：１０２１－１０２８
［９６］ Ｙａｏ Ｌｉａｎｇ，Ｍａｏ Ｃｈｅｎｇｓｈｅｎｇ，Ｌｕｏ Ｙｕａｎ．Ｇｒａｐｈ ｃｏｎｖｏｌｕ－
［８５］ Ｃｈｅｎ Ｘ，Ｌｉ Ｌ Ｊ，Ｆｅｉ－Ｆｅｉ Ｌ，Ｇｕｐｔａ Ａ．Ｉｔｅｒａｔｉｖｅ ｖｉｓｕａｌ ｒｅａｓｏｎｉｎｇ
ｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｔｅｘｔ ｃｌａｓｓｉｆｉｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｂｅｙｏｎｄ ｃｏｎｖｏｌｕｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ
３３ｒｄ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｈｏｎｏｌｕｌｕ，
ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｓａｌｔ Ｌａｋｅ Ｃｉｔｙ，
ＵＳＡ，２０１９：７３７０－７３７７
ＵＳＡ，２０１８：７２３９－７２４８
［９７］ Ｙａｎｇ Ｚ，Ｃｏｈｅｎ Ｗ，Ｓａｌａｋｈｕｄｉｎｏｖ Ｒ．Ｒｅｖｉｓｉｔｉｎｇ ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ
［８６］ Ｈａｍａｇｕｃｈｉ Ｔ，Ｏｉｗａ Ｈ，Ｓｈｉｍｂｏ Ｍ，Ｍａｔｓｕｍｏｔｏ Ｙ．Ｋｎｏｗｌｅｄｇｅ
ｌｅａｒｎｉｎｇ ｗｉｔｈ ｇｒａｐｈ ｅｍｂｅｄｄｉｎｇｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３３ｒｄ
ｔｒａｎｓｆｅｒ ｆｏｒ ｏｕｔ－ｏｆ－ｋｎｏｗｌｅｄｇｅ－ｂａｓｅ ｅｎｔｉｔｉｅｓ：Ａ ｇｒａｐｈ ｎｅｕｒａｌ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｎｅｗ Ｙｏｒｋ，
ｎｅｔｗｏｒｋ ａｐｐｒｏａｃｈ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ
ＵＳＡ，２０１６：４０－４８
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｍｅｌｂｏｕｒｎｅ，Ａｕｓｔｒａｌｉａ，
［９８］ Ｓｈｅｒｖａｓｈｉｄｚｅ Ｎ，Ｓｃｈｗｅｉｔｚｅｒ Ｐ，ｖａｎ Ｌｅｅｕｗｅｎ Ｅ Ｊ，ｅｔ ａｌ．
２０１７：１８０２－１８０８
Ｗｅｉｓｆｅｉｌｅｒ－ｌｅｈｍａｎ ｇｒａｐｈ ｋｅｒｎｅｌｓ．Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ
［８７］ Ｍａｒｃｈｅｇｇｉａｎｉ Ｄ，Ｂａｓｔｉｎｇｓ Ｊ，Ｔｉｔｏｖ Ｉ．Ｅｘｐｌｏｉｔｉｎｇ ｓｅｍａｎｔｉｃｓ ｉｎ
Ｒｅｓｅａｒｃｈ，２０１１，（２０１１）：２５３９－２５６１
ｎｅｕｒａｌ ｍａｃｈｉｎｅ ｔｒａｎｓｌａｔｉｏｎ ｗｉｔｈ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ
［９９］ Ｃｈｅｎ Ｚｈｅｎｇｄａｏ，Ｌｉ Ｌｉｓｈａ，Ｂｒｕｎａ Ｊ．Ｓｕｐｅｒｖｉｓｅｄ ｃｏｍｍｕｎｉｔｙ
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１８Ｃｏｎｆｅｒｅｎｃｅ ｏｆ ｔｈｅ Ｎｏｒｔｈ Ａｍｅｒｉｃａｎ
ｄｅｔｅｃｔｉｏｎ ｗｉｔｈ ｌｉｎｅ ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
Ｃｈａｐｔｅｒ ｏｆ ｔｈｅ Ａｓｓｏｃｉａｔｉｏｎ ｆｏｒ Ｃｏｍｐｕｔａｔｉｏｎａｌ Ｌｉｎｇｕｉｓｔｉｃｓ：
ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｌｅａｒｎｉｎｇ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ．
Ｈｕｍａｎ Ｌａｎｇｕａｇｅ Ｔｅｃｈｎｏｌｏｇｉｅｓ．Ｎｅｗ Ｏｒｌｅａｎｓ，ＵＳＡ，２０１８：
Ｎｅｗ Ｏｒｌｅａｎｓ，ＵＳＡ，２０１８
４８６－４９２
［１００］ Ｃａｏ Ｑｉ，Ｓｈｅｎ Ｈｕａｗｅｉ，Ｇａｏ Ｊｉｎｈｕａ，ｅｔ ａｌ．Ｐｏｐｕｌａｒｉｔｙ ｐｒｅｄｉｃ－
［８８］ Ｍａｒｃｈｅｇｇｉａｎｉ Ｄ，Ｔｉｔｏｖ Ｉ．Ｅｎｃｏｄｉｎｇ ｓｅｎｔｅｎｃｅｓ ｗｉｔｈ ｇｒａｐｈ
ｔｉｏｎ ｏｎ ｓｏｃｉａｌ ｐｌａｔｆｏｒｍｓ ｗｉｔｈ ｃｏｕｐｌｅｄ ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔ－
ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｓｅｍａｎｔｉｃ ｒｏｌｅ ｌａｂｅｌｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １３ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
ｏｆ ｔｈｅ ２０１７Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｅｍｐｉｒｉｃａｌ Ｍｅｔｈｏｄｓ ｉｎ Ｎａｔｕｒａｌ
Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｈｏｕｓｔｏｎ，Ｔｅｘａｓ，ＵＡＳ，２０２０：
Ｌａｎｇｕａｇｅ Ｐｒｏｃｅｓｓｉｎｇ．Ｃｏｐｅｎｈａｇｅｎ，Ｄｅｎｍａｒｋ，２０１７：１５０６－
７０－７８
１５１５
［８９］ Ｚｈａｎｇ Ｙ，Ｑｉ Ｐ，Ｍａｎｎｉｎｇ Ｃ Ｄ．Ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ ｏｖｅｒ ［１０１］ Ｒａｈｉｍｉ Ａ，Ｃｏｈｎ Ｔ，Ｂａｌｄｗｉｎ Ｔ．Ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ｕｓｅｒ ｇｅｏｌｏ－
ｐｒｕｎｅｄ ｄｅｐｅｎｄｅｎｃｙ ｔｒｅｅｓ ｉｍｐｒｏｖｅｓ ｒｅｌａｔｉｏｎ ｅｘｔｒａｃｔｉｏｎ／／ ｃａｔｉｏｎ ｖｉａ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１８Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｅｍｐｉｒｉｃａｌ Ｍｅｔｈｏｄｓ ｉｎ
５６ｔｈ Ａｎｎｕａｌ Ｍｅｅｔｉｎｇ ｏｆ ｔｈｅ Ａｓｓｏｃｉａｔｉｏｎ ｆｏｒ Ｃｏｍｐｕｔａｔｉｏｎａｌ
Ｎａｔｕｒａｌ Ｌａｎｇｕａｇｅ Ｐｒｏｃｅｓｓｉｎｇ，Ｓｙｓｔｅｍ Ｄｅｍｏｎｓｔｒａｔｉｏｎｓ．
Ｌｉｎｇｕｉｓｔｉｃｓ．Ｍｅｌｂｏｕｒｎｅ，Ａｕｓｔｒａｌｉａ，２０１８：２００９－２０１９
Ｂｒｕｓｓｅｌｓ，Ｂｅｌｇｉｕｍｍ，２０１８：２２０５－２２１５ ［１０２］ Ｘｕ Ｄａｎｆｅｉ，Ｚｈｕ Ｙｕｋｅ，Ｃｈｏｙ Ｃ Ｂ，Ｌｉ Ｆｅｉ－Ｆｅｉ．Ｓｃｅｎｅ ｇｒａｐｈ
［９０］ Ｓｏｎｇ Ｌ，Ｚｈａｎｇ Ｙ，Ｗａｎｇ Ｚ，Ｇｉｌｄｅａ Ｄ．Ａ ｇｒａｐｈ－ｔｏ－ｓｅｑｕｅｎｃｅ ｇｅｎｅｒａｔｉｏｎ ｂｙ ｉｔｅｒａｔｉｖｅ ｍｅｓｓａｇｅ ｐａｓｓｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｍｏｄｅｌ ｆｏｒ ａｍｒ－ｔｏ－ｔｅｘｔ ｇｅｎｅｒａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ５６ｔｈ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
Ａｎｎｕａｌ Ｍｅｅｔｉｎｇ ｏｆ ｔｈｅ Ａｓｓｏｃｉａｔｉｏｎ ｆｏｒ Ｃｏｍｐｕｔａｔｉｏｎａｌ
Ｈｏｎｏｌｕｌｕ，ＵＳＡ，２０１７：３０９７－３１０６
Ｌｉｎｇｕｉｓｔｉｃｓ．Ｍｅｌｂｏｕｒｎｅ，Ａｕｓｔｒａｌｉａ，２０１８：１６１６－１６２６ ［１０３］ Ｗａｎｇ Ｙａｑｉｎｇ，Ｙａｏ Ｑｕａｎｍｉｎｇ．Ｆｅｗ－ｓｈｏｔ ｌｅａｒｎｉｎｇ：Ａ ｓｕｒｖｅｙ．
［９１］ Ｌｉｕ Ｘｉａｏ，Ｌｕｏ Ｚｈｕｎｃｈｅｎ，Ｈｕａｎｇ Ｈｅｙａｎ．Ｊｏｉｎｔｌｙ ｍｕｌｔｉｐｌｅ ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１９０４．０５０４６，２０１９
ｅｖｅｎｔｓ ｅｘｔｒａｃｔｉｏｎ ｖｉａ ａｔｔｅｎｔｉｏｎ－ｂａｓｅｄ ｇｒａｐｈ ｉｎｆｏｒｍａｔｉｏｎ ［１０４］ Ｓｏｎｇ Ｌｉｎｆｅｎｇ，Ｗａｎｇ Ｚｈｉｇｕｏ，Ｙｕ Ｍｏ，ｅｔ ａｌ．Ｅｘｐｌｏｒｉｎｇ
ａｇｇｒｅｇａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１８Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｅｍｐｉｒｉｃａｌ ｇｒａｐｈ－ｓｔｒｕｃｔｕｒｅｄ ｐａｓｓａｇｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｆｏｒ ｍｕｌｔｉ－ｈｏｐ ｒｅａｄｉｎｇ
Ｍｅｔｈｏｄｓ ｉｎ Ｎａｔｕｒａｌ Ｌａｎｇｕａｇｅ Ｐｒｏｃｅｓｓｉｎｇ，Ｓｙｓｔｅｍ Ｄｅｍｏｎ－ ｃｏｍｐｒｅｈｅｎｓｉｏｎ ｗｉｔｈ ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ
ｓｔｒａｔｉｏｎｓ．Ｂｒｕｓｓｅｌｓ，Ｂｅｌｇｉｕｍｍ，２０１８：１２４７－１２５６ ａｒＸｉｖ：１８０９．０２０４０，２０１８
［９２］ Ｎｇｕｙｅｎ Ｔ Ｈ，Ｇｒｉｓｈｍａｎ Ｒ．Ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ［１０５］ Ｋｈａｌｉｌ Ｅ，Ｄａｉ Ｈ，Ｚｈａｎｇ Ｙ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ ｃｏｍｂｉｎａｔｏｒｉａｌ
ｗｉｔｈ ａｒｇｕｍｅｎｔ－ａｗａｒｅ ｐｏｏｌｉｎｇ ｆｏｒ ｅｖｅｎｔ ｄｅｔｅｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｐｔｉｍｉｚａｔｉｏｎ ａｌｇｏｒｉｔｈｍｓ ｏｖｅｒ ｇｒａｐｈｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｏｆ ｔｈｅ ３２ｎｄ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｎｅｗ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｌｏｎｇ
Ｏｒｌｅａｎｓ，ＵＳＡ，２０１８：５９００－５９０７ Ｂｅａｃｈ，ＵＳＡ，２０１７：６３４８－６３５８ ７８０ 计 算 机 学 报 ２０２０年
［１０６］ Ｌｉ Ｚ，Ｃｈｅｎ Ｑ，Ｋｏｌｔｕｎ Ｖ．Ｃｏｍｂｉｎａｔｏｒｉａｌ ｏｐｔｉｍｉｚａｔｉｏｎ ｗｉｔｈ ｚａｔｉｏｎ ｏｆ ｃｏｍｐｌｅｘ ｎｅｔｗｏｒｋｓ．Ｓｃｉｅｎｃｅ，２０１６，３５３（６２９５）：
ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ａｎｄ ｇｕｉｄｅｄ ｔｒｅｅ ｓｅａｒｃｈ／／ １６３－１６６
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ ［１１１］ Ｈｕａｎｇ Ｊｕｎｊｉｅ，Ｓｈｅｎ Ｈｕａｗｅｉ，Ｈｏｕ Ｌｉａｎｇ，Ｃｈｅｎｇ Ｘｕｅｑｉ．
Ｓｙｓｔｅｍｓ．Ｍｏｎｔｒéａｌ，Ｃａｎａｄａ，２０１８：５３７－５４６ Ｓｉｇｎｅｄ ｇｒａｐｈ ａｔｔｅｎｔｉｏｎ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒ－
［１０７］ Ｄｕ Ｌｕｎ，Ｗａｎｇ Ｙｕｎ，Ｓｏｎｇ Ｇｕｏｊｉｅ，ｅｔ ａｌ．Ｄｙｎａｍｉｃ ｎｅｔｗｏｒｋ ｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ．Ｍｕｎｉｃｈ，
ｅｍｂｅｄｄｉｎｇ：Ａｎ ｅｘｔｅｎｄｅｄ ａｐｐｒｏａｃｈ ｆｏｒ ｓｋｉｐ－ｇｒａｍ ｂａｓｅｄ Ｇｅｒｍａｎｙ，２０１９：５６６－５７７
ｎｅｔｗｏｒｋ ｅｍｂｅｄｄｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ ［１１２］ Ｆｏｒｔｕｎａｔｏ Ｓ．Ｃｏｍｍｕｎｉｔｙ ｄｅｔｅｃｔｉｏｎ ｉｎ ｇｒａｐｈｓ．Ｐｈｙｓｉｃｓ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｓｔｏｃｋｈｏｌｍ，Ｓｗｅｄｅｎ， Ｒｅｐｏｒｔｓ，２０１０，４８６（３－５）：７５－１７４
２０１８：２０８６－２０９２ ［１１３］ Ａｋｈｔａｒ Ｎ，Ｍｉａｎ Ａ．Ｔｈｒｅａｔ ｏｆ ａｄｖｅｒｓａｒｉａｌ ａｔｔａｃｋｓ ｏｎ ｄｅｅｐ
［１０８］ Ｚｈｏｕ Ｌｅｋｕｉ，Ｙａｎｇ Ｙａｎｇ，Ｒｅｎ Ｘｉａｎｇ，ｅｔ ａｌ．Ｄｙｎａｍｉｃ ｌｅａｒｎｉｎｇ ｉｎ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ：Ａ ｓｕｒｖｅｙ．ＩＥＥＥ Ａｃｃｅｓｓ，２０１８，
ｎｅｔｗｏｒｋ ｅｍｂｅｄｄｉｎｇ ｂｙ ｍｏｄｅｌｉｎｇ ｔｒｉａｄｉｃ ｃｌｏｓｕｒｅ ｐｒｏｃｅｓｓ／／ ６：１４４１０－１４４３０
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３２ｎｄ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ ［１１４］ Ｚüｇｎｅｒ Ｄ，Ａｋｂａｒｎｅｊａｄ Ａ，Ｇüｎｎｅｍａｎｎ Ｓ．Ａｄｖｅｒｓａｒｉａｌ ａｔｔａｃｋｓ
Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｎｅｗ Ｏｒｌｅａｎｓ，ＵＳＡ，２０１８：５７１－５７８ ｏｎ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｇｒａｐｈ ｄａｔａ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ
［１０９］ Ｎｇｕｙｅｎ Ｎ Ｐ，Ｄｉｎｈ Ｔ Ｎ，Ｘｕａｎ Ｙ，Ｔｈａｉ Ｍ Ｔ．Ａｄａｐｔｉｖｅ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ
ａｌｇｏｒｉｔｈｍｓ ｆｏｒ ｄｅｔｅｃｔｉｎｇ ｃｏｍｍｕｎｉｔｙ ｓｔｒｕｃｔｕｒｅ ｉｎ ｄｙｎａｍｉｃ Ｄｉｓｃｏｖｅｒｙ＆Ｄａｔａ Ｍｉｎｉｎｇ．Ｌｏｎｄｏｎ，ＵＫ，２０１８：２８４７－２８５６
ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ ［１１５］ Ｙｉｎｇ Ｒ，Ｂｏｕｒｇｅｏｉｓ Ｄ，Ｙｏｕ Ｊ，ｅｔ ａｌ．ＧＮＮ ｅｘｐｌａｉｎｅｒ：Ａ ｔｏｏｌ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ．Ｓｈａｎｇｈａｉ，Ｃｈｉｎａ， ｆｏｒ ｐｏｓｔ－ｈｏｃ ｅｘｐｌａｎａｔｉｏｎ ｏｆ ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ
２０１１：２２８２－２２９０ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１９０３．０３８９４，２０１９
［１１０］ Ｂｅｎｓｏｎ Ａ Ｒ，Ｇｌｅｉｃｈ Ｄ Ｆ，Ｌｅｓｋｏｖｅｃ Ｊ．Ｈｉｇｈｅｒ－ｏｒｄｅｒ ｏｒｇａｎｉ－
ＸＵ Ｂｉｎｇ－Ｂｉｎｇ，Ｐｈ．Ｄ．ｃａｎｄｉｄａｔｅ．Ｈｅｒ ＣＥＮ Ｋｅ－Ｔｉｎｇ，Ｐｈ．Ｄ．ｃａｎｄｉｄａｔｅ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ
ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｇｒａｐｈ ｎｅｕｒａｌ ｉｎｃｌｕｄｅ ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｎｄ ｎｅｔｗｏｒｋ ｅｍｂｅｄｄｉｎｇ．
ｎｅｔｗｏｒｋ ａｎｄ ｇｒａｐｈ－ｂａｓｅｄ ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ＨＵＡＮＧ Ｊｕｎ－Ｊｉｅ，Ｍ．Ｓ．ｃａｎｄｉｄａｔｅ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ
ｌｅａｒｎｉｎｇ． ｉｎｃｌｕｄｅ ｓｏｃｉａｌ ｍｅｄｉａ ｃｏｍｐｕｔｉｎｇ ａｎｄ ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ．
ＳＨＥＮ Ｈｕａ－Ｗｅｉ，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ
ｉｎｃｌｕｄｅ ｓｏｃｉａｌ ｎｅｔｗｏｒｋ ａｎａｌｙｓｉｓ ａｎｄ ｓｏｃｉａｌ ｍｅｄｉａ ｃｏｍｐｕｔｉｎｇ．
ＣＨＥＮＧ Ｘｕｅ－Ｑｉ，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ
ｉｎｃｌｕｄｅ ｂｉｇ ｄａｔａ ａｎａｌｙｓｉｓ ａｎｄ ｍｉｎｉｎｇ，ｎｅｔｗｏｒｋ ｓｃｉｅｎｃｅ，ｎｅｔｗｏｒｋ
ａｎｄ ｉｎｆｏｒｍａｔｉｏｎ ｓｅｃｕｒｉｔｙ，ｗｅｂ ｓｅａｒｃｈ ａｎｄ ｄａｔａ ｍｉｎｉｎｇ．
Ｂａｃｋｇｒｏｕｎｄ
Ｍａｎｙ ｒｅａｌ－ｌｉｆｅ ｓｃｅｎａｒｉｏｓ，ｓｕｃｈ ａｓ ｔｒａｎｓｐｏｒｔａｔｉｏｎ ｎｅｔ－ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ ｉｎ ｈｕｇｅ ｏｒ ｃｏｍｐｌｉｃａｔｅｄ ｇｒａｐｈ，ｅ．ｇ．，ｇｒａｐｈ
ｗｏｒｋｓ，ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ ａｎｄ ｃｉｔａｔｉｏｎ ｎｅｔｗｏｒｋｓ，ａｒｅ ｌｏｃａｔｅｄ ｉｎ ｗｉｔｈ ｍｉｌｌｉｏｎ ｎｏｄｅｓ，ｓｉｇｎｅｄ ｇｒａｐｈ ａｎｄ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｇｒａｐｈ．
ｔｈｅ ｆｏｒｍ ｏｆ ｇｒａｐｈ ｄａｔａ．Ｉｎ ｒｅｃｅｎｔ ｙｅａｒｓ，ｔｈｅ ｐｏｗｅｒｆｕｌ ｍｏｄｅｌｉｎｇ Ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ ｎｅｔｗｏｒｋｓ ｈａｖｅ ｓｈｏｗｎ ｐｏｗｅｒｆｕｌ ｍｏｄｅｌｉｎｇ
ｃａｐａｂｉｌｉｔｉｅｓ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｎｄ ｔｈｅ ｕｂｉｑｕｉｔｙ ｏｆ ｃａｐａｂｉｌｉｔｉｅｓ ｉｎ ｍａｎｙ ａｐｐｌｉｃａｔｉｏｎｓ，ｅ．ｇ．，ｔｒａｆｆｉｃ ｎｅｔｗｏｒｋ，
ｇｒａｐｈ ｄａｔａ ｈａｖｅ ｉｎｓｐｉｒｅｄ ｒｅｓｅａｒｃｈｅｒｓ ｔｏ ｔｒａｎｓｆｅｒ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｍｏｌｅｃｕｌａｒ ｎｅｔｗｏｒｋ．
ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｔｏ ｇｒａｐｈｓ．Ｔｈｉｓ ｐａｐｅｒ ｓｕｒｖｅｙｓ ａｎｄ ｓｕｍｍａｒｉｚｅｓ Ｔｈｉｓ ｐａｐｅｒ ｉｓ ｆｕｎｄｅｄ ｂｙ ｔｈｅ Ｎａｔｉｏｎａｌ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ
ｔｈｅ ｒｅｓｅａｒｃｈ ａｎｄ ｄｅｖｅｌｏｐｍｅｎｔｓ ｏｆ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ ｎｅｔ－ Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｃｈｉｎａ ｕｎｄｅｒ Ｇｒａｎｔ Ｎｏｓ．６１４２５０１６ ａｎｄ
ｗｏｒｋｓ．Ｔｈｅ ｃｌａｓｓｉｃａｌ ｍｅｔｈｏｄｓ ｉｎ ｔｈｉｓ ａｒｅａ ａｒｅ ｄｉｖｉｄｅｄ ｉｎｔｏ ９１７４６３０１．Ｓｈｅｎ Ｈｕａｗｅｉ ｉｓ ａｌｓｏ ｆｕｎｄｅｄ ｂｙ Ｋ．Ｃ．Ｗｏｎｇ Ｅｄｕ－
ｔｗｏ ｇｒｏｕｐｓ：ｓｐｅｃｔｒａｌ ｍｅｔｈｏｄｓ ａｎｄ ｓｐａｔｉａｌ ｍｅｔｈｏｄｓ．Ｓｐｅｃｔｒａｌ ｃａｔｉｏｎ Ｆｏｕｎｄａｔｉｏｎ ａｎｄ Ｂｅｉｊｉｎｇ Ａｃａｄｅｍｙ ｏｆ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉ－
ｍｅｔｈｏｄｓ ｉｍｐｌｅｍｅｎｔ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ ｖｉａ ｃｏｎｖｏｌｕｔｉｏｎ ｔｈｅｏｒｅｍ， ｇｅｎｃｅ（ＢＡＡＩ）．Ｔｈｅｓｅ ｐｒｏｊｅｃｔｓ ｆｏｃｕｓ ｏｎ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ，
ｗｈｉｌｅ ｓｐａｔｉａｌ ｍｅｔｈｏｄｓ ｄｅｆｉｎｅ ａｇｇｒｅｇａｔｏｒ ｆｕｎｃｔｉｏｎ ｉｎ ｖｅｒｔｅｘ ｉｎｆｏｒｍａｔｉｏｎ ｄｉｆｆｕｓｉｏｎ ａｎｄ ｏｎｌｉｎｅ ｓｏｃｉａｌ ｍｅｄｉａ．Ｏｕｒ ｇｒｏｕｐ ｈａｓ
ｓｐａｃｅ ｄｉｒｅｃｔｌｙ ｔｏ ｉｍｐｌｅｍｅｎｔ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎ．Ｔｈｅ ｌａｔｅｓｔ ｂｅｅｎ ｗｏｒｋｉｎｇ ｏｎ ｔｈｉｓ ａｒｅａ ｆｏｒ ｓｅｖｅｒａｌ ｙｅａｒｓ ａｎｄ ｐｕｂｌｉｓｈｅｄ ａ
ｄｅｖｅｌｏｐｍｅｎｔｓ ｉｎ ｔｈｉｓ ｆｉｅｌｄ ａｒｅ ｆｏｃｕｓ ｏｎ ｈｏｗ ｔｏ ｃｏｎｓｔｒｕｃｔ ｎｕｍｂｅｒ ｏｆ ｐａｐｅｒｓ． --------------------------------------------------------------------------------- 第 卷 第 期 计 算 机 学 报
45 1 Vol.45 No.1
年 月
2022 1 CHINESEJOURNALOFCOMPUTERS Jan.2022
图神经网络前沿进展与应用
吴 博 梁 循 张树森 徐 睿
中国人民大学信息学院 北京
( 100872)
摘 要 图结构数据是现实生活中广泛存在的一类数据形式 宏观上的互联网 知识图谱 社交网络数据 微观上
. 、 、 ,
的蛋白质 化合物分子等都可以用图结构来建模和表示 由于图结构数据的复杂性和异质性 对图结构数据的分析
、 . ,
和处理一直是研究界的难点和重点 图神经网络 是近年来出现的一种利用深度学
. (GraphNeuralNetwork,GNN)
习直接对图结构数据进行学习的框架 其优异的性能引起了学者高度的关注和深入的探索 通过在图中的节点和
, .
边上制定一定的策略 将图结构数据转化为规范而标准的表示 并输入到多种不同的神经网络中进行训练
,GNN , ,
在节点分类 边信息传播和图聚类等任务上取得优良的效果 与其他图学习算法相比较 能够学习到图结构
、 . ,GNN
数据中的节点以及边的内在规律和更加深层次的语义特征 由于具有对图结构数据强大的非线性拟合能力 因此
. ,
在不同领域的图相关问题上 都表现出更高的准确率和更好的鲁棒性 本文在现有 研究的基础上 首先
,GNN . GNN ,
概述了 的出现历程 并介绍了相关概念和定义 之后本文着重讨论和对比了 中的各种算法框架 包括
GNN , . GNN ,
核心思想 任务划分 学习方式 优缺点 适用范围 实现成本等 此外 本文对 算法在多个不同领域下的应用
、 、 、 、 、 . , GNN
场景进行了详细的阐述 将 与其他图学习算法的优缺点作了联系和比较 针对存在的一些问题和挑战 本文
, GNN . ,
勾画了 的未来方向和发展趋势 最后对全文进行了全面而细致的总结
GNN , .
关键词 图神经网络 深度学习 图结构数据 拉普拉斯矩阵 谱分解 节点特征聚合 图生成
; ; ; ; ; ;
中图法分类号 DOI号
TP18 10.11897/SP.J.1016.2022.00035
AdvancesandApplicationsinGraphNeuralNetwork
WUBo LIANGXun ZHANGShu-Sen XURui
Schoolo fI nformation Renmin Universityo f China Beijing
( , , 100872)
Abstract
Asisknowntoall,Graph-structuredataisakindofdataformwidelyexistinginreal
life.Internetnetwork,knowledgegraph,socialnetworkdatainmacroperspective,together
withprotein,compoundmoleculesdatainmicroperspective,areallcanbemodeledandrepre-
sentedbygraph-structure.Becausegraph-structuredatahascomplexityandheterogeneityattrib-
ute,theanalysisandprocessingofgraph-structuredatahavealwaysbeenadifficultyinresearch
community.Theresearchershavebeenstudyingthepropertyinformationandtopologicalstruc-
tureinformationingraphandtrytofindoutawayormethodtolearnandexplorethegraphauto-
matically.Inordertosolvetheproblemsabove,GraphNeuralNetwork(GNN)appearsasa
kindofframeworkthatusesdeeplearningtolearngraph-structuredatadirectlyinrecentyears.
Ontheonehand,theexcellentperformanceofGNNhasarousedhighattentionanddeepexplora-
tioninresearchcommunity.GNNtransformsthegraph-structuredataintostandardrepresenta-
tionbymakingaseriesofcertainstrategiesonthemultifariousnodesandedgesofthegraph,and
thentherepresentationcanbeinputintoavarietyofdifferentartificialneuralnetworksfortrain-
收稿日期 在线发布日期 本课题得到国家自然科学基金 国家社会科学基金
:2019-11-24; :2020-02-04. (No.62072463,No.71531012)、
北京市自然科学基金 京东商城电子商务研究项目 北大方正集团有限公司数字出版
(No.18ZDA309)、 (No.4172032)、 (No.413313012)、
技术国家重点实验室开放课题资助 吴 博 博士研究生 主要研究领域为图神经网络 深度学习 梁
. , , 、 .E-mail:wubochn@ruc.edu.cn.
循 通信作者 博士 教授 计算机学会 会员 主要研究领域为神经网络 社会计算 自然语言处理 张
( ), , , (CCF) , 、 、 .E-mail:xliang@ruc.edu.cn.
树森 博士研究生 主要研究领域为数据挖掘 社会计算 徐 睿 博士研究生 主要研究领域为图像处理 机器学习
, , 、 . , , 、 . 计 算 机 学 报 年
36 2022
ing,andachievesexcellentresultsintaskssuchasnodeclassification,edgeinformationdissemi-
nation,graphclusteringandsoon.Ontheotherhand,whenitiscomparedwithothergraph
learningalgorithms,GNNcanlearntheinternalrulesandsemanticfeaturesofnodeandedgefea-
turesingraph-structuredata.Becauseithasastrongnonlinearfittingabilitytograph-structure
data,GNNhashigheraccuracyandbetterrobustnessongraph-structurerelatedproblemsindif-
ferentfields.Tomakeitmoresuitableandefficientforspecificapplications,thereisagreatdeal
ofvariantsofGNNalgorithmandframeworkareproposedinpastfewyears.Basedontheexist-
ingGNNresearch,thispaperfirstsummarizesthehistoryofGNN,andintroducestherelated
conceptsanddefinitions.AfteranoverviewofGNNtheory,wethenfocusonthediscussionand
comparisonofvariousalgorithmsinGNN,includingthecoreidea,taskdivision,typesofgraphs,
activationfunction,differentdataset,advantagesanddisadvantages,thescopeofapplication,imple-
mentationcosts,learningmethodsandbenchmarknetwork.Wegiveanovelclassificationanddivide
GNNintofivedifferentartificialneuralnetworks.Inaddition,theapplicationofGNNalgorithmin
manydifferentfieldsisdescribedindetailssuchasnaturallanguageprocessing,moleculegraphgen-
erationandsoon.Thispapergivesanintroductiontotheotherkindsofgraphlearningalgorithm
whicharerecognizedasnetworkembeddingandgraphkernel.Wecomparetheadvantagesanddis-
advantagesbetweenGNNandnetworkembeddingaswellasgraphkernel.AlthoughGNNhasbeen
verypopularoverpastyears,thesetwokindsofgraphlearningalgorithmarealsotobeprovedcom-
petitiveinsometasks.Inviewoftheexistingproblemsandchallenges,thispaperoutlinesthefuture
directionanddevelopmenttrendofGNN,whichincludesdepthofartificialneuralnetwork,dynam-
ics,receptivefieldofGNN,thefusionofmultiartificialneuralnetworks,andthecombinationbe-
tweenartificialnetworkembeddingandGNN.Lastbutnotleast,wemakeacomprehensiveandde-
tailedsummaryofthefulltext.
Keywords
graphneuralnetwork;deeplearning;graph-structuredata;laplacianmatrix;spec-
traldecomposition;nodefeatureaggregating;graphgenerating
[6]和自编码器 [7]等性能优
1 引 言 GAN) (Auto-encoder,AE
异的神经网络已经成为许多研究领域解决问题的通
用网络框架
近年来 深度学习[1]在多个领域取得明显优 .
, 但是随着研究的深入 研究人员发现深度学习
异的效果 特别是在计算机视觉 音频识别以及自 ,
, 、 并不能适应和解决所有的情况和问题 在过去十多
然语言处理三个方面取得突破性进展 深度学习 .
. 年的发展中 深度学习取得的成就主要限定在了计
通过建立人工神经网络 对输入的信息和数据逐 ,
, 算机视觉 自然语言处理和音频分析领域上 这些领
层进行特征的提取和筛选 最终获得分类和预测 、 .
, 域上的数据和信息有着比较显著的特点 文本 图
等任务的结果 相较于统计机器学习等浅层学习 . 、
. 像 音频 视频的数据格式在形式上有着统一而规整
模式 深度学习所使用的神经网络架构具有多个 、 、
, 的尺寸和维度 它们也被称作欧式结构
功能各异的复杂网络层 其特征提取和识别的数
, (Euclidean
, 或者网格结构 数据 除
量和质量显著提高 并且能够自底向上生成更加 Structure) (GridStructure) .
, 此之外 现实生活中存在大量的非欧式结构的图数
,
高级的特征表示 这使得机器能够获得抽象概念
. , 据 ,例如互联网 、知识图谱 、社交网络 、蛋白质 、化合
具备更强的表征学习能力[2] 诸如多层感知机
物分子等 尽管深度学习在欧式结构数据上取得巨
.
.
[3] 卷积神经网络 大的成功 但在图结构数据上 基于神经网络的深度
(MultilayerPerceptron,MLP) 、 , ,
[4] 循环神 学习表现得并不好 在图结构数据中 节点与节点之
(ConvolutionalNeuralNetwork,CNN) 、 . ,
经网络 [5] 生成 间的边连接可能是均匀分布的 也可能是不均匀的
(RecurrentNeuralNetwork,RNN) 、 , .
对 抗 网 络 节点与节点之间没有严格意义上的先后顺序 对于
(Generative Adversarial Network, . 期 吴 博等 图神经网络前沿进展与应用
1 : 37
神经网络的输入端而言 这些数据没有固定的输入 人工智能推理任务的发展
, .
尺寸 在数学表达上 这些数据与欧式结构数据相 本文针对近年来出现的 学习方法和研究
. , GNN
比 每一个区块的特征矩阵维度都不是统一的 如图 现状进行了系统的归纳和梳理 并对它们的主要思
, , ,
所示 由于无法使用统一规整的算子对数据编排 想 改进以及局限性做了详尽分析 目前已有 等
1 . , 、 . Xu
导致 等神经网络不能再直接对其进行诸如卷 人[11]关于图卷积神经网络的综述 本文在全面对比
CNN ,
积和池化等操作 也就不再有局部连接 权值共享 分析的基础上 对目前主要的 算法进行了更
, 、 、 , GNN
特征抽象等性质[8] 如何将 等深度学习算法 加合理的分类和介绍 除了图卷积神经网络
. CNN . ,GNN
用于分析图结构数据上成为一个有挑战性和前沿性 主流算法还包括有图自编码器 图生成网络 图循环
、 、
的课题 近年来 等人[9]用 来压缩节点信 网络以及图注意力网络 本文对每类 算法都
. Gori RNN . GNN
息和学习图节点标签 首次提出图神经网络 给出了其定义和典型方法 将 中每种算法的
, (Graph , GNN
这一概念 之后文献[10]提出 机制 优势 缺点 适用范围 实现成本等进行了提炼
NeuralNetwork,GNN) . 、 、 、 、
图 卷 积 网 络 总结 在进行了相应的数据实验基础上 与其他基准
(Graph Convolutional Network, . ,
正式将 用于对图结构数据建模 图算法进行了比对 本文在第 节中给出关于
GCN), CNN .GCN . 2 GNN
通过整合中心节点和邻居节点的特征和标签信息 的基本概念和定义 在第 节分门别类的给出
, ; 3 GNN
给出图中每个节点的规整表达形式 并将其输入到 的主要模型和算法 在第 节 对比和分析 与
, ; 4 , GNN
中 这样一来 就能利用多尺度的信息 网络嵌入 以及图核
CNN . GCN , (NetworkEmbedding) (Graph
组合成更高层次的表达 其有效地利用了图结构信 方法的特性和优势 在第 节中 阐述目前
. Kernel) . 5 ,
息和属性信息 为深度学习中其他神经网络迁移至 在多个领域图数据上的具体应用 在第 节归
, GNN ; 6
图上提供了标准的范式 在新的研究思路的基础上 纳和总结现有 模型缺陷和不足 并对未来发
. , GNN ,
各种 架构相继被构造出来 在多个领域的图 展方向和趋势进行展望 最后在第 节对全文所述
GNN , . 7
结构数据中发挥了独特的作用 并促进了图相关的 进行总结
, .
图 欧式结构和图结构数据比较
1
算法 并做了一定程度的改进 早期阶段的
GNN , .
2 概念与定义 主要是以 为主体框架 通过简单的特征
GNN RNN ,
映射和节点聚集为每个节点生成向量式表达 不能
,
2.1 符号与定义 很好地应对现实中复杂多变的图数据 针对此情况
. ,
是指使用神经网络来学习图结构数据 提
文献[10]提出将 应用到图上 通过对卷积算子
GNN , CNN ,
取和发掘图结构数据中的特征和模式 满足聚类 分 巧妙的转换 提出了图卷积网络
, 、 , (GraphConvolu-
类 预测 分割 生成等图学习任务需求的算法总称 并衍生了许多变体 实
、 、 、 . tionalNetwok,GCN), .GCN
GNN的历史最早可以追溯到 2005年 ,Gori等人[9] 现了 CNN在图上的平移不变 、局部感知和权值共
第一次提出 概念 用 来处理无向图 有 享[14] 为接下来其他 框架的构造和改进提供
GNN , RNN 、 , GNN
向图 标签图和循环图等 在这之后 等 思想上的指导和借鉴 下面给出 中相关符号
、 . ,Scarselli . GNN
人[12]和 等人[13]继承和发展了该模式的 的说明和定义
Micheli . 定义1 图 是由节点 和连接节
. (Graph) (Vertex)
点的边 所构成 通常记为G= VE 其中
(Edge) , ( , ).
V v v v 代表节点集合 E e e
={1,2,…,n} , ={1,2,…,
e 代表边集合 通常节点也被称为顶点或者交点 m} . .
边也被称为链接或者弧 通用的图表示是一个五
.
元组 GVEAXD 其中AN×N 代表图的邻
: ( , , , , ).
接矩阵 XN×F 代表节点的特征矩阵 DN×N 代表度
, ,
矩阵 N和F分别代表节点的数量和节点的特征
,
维度
.
定义2 组合拉普拉斯矩阵 又称标准拉普拉斯
. ,
矩阵 由对角矩阵和邻接矩阵组合而成
, :
L D A
= - (1)
该矩阵只在中心节点和一阶相连的节点上有非
零元素 其余之处均为零
, .
定义3 对称标准化拉普拉斯矩阵
. :
Lsym I D-1/2AD-1/2
= - (2)
其元素值由式 给出
(3) :
i=j且degv ■ 1 (i)≠0
Ls iy ,jm =■degv- d1
egv
i ≠j且v i与v j相连
(i) (j)
其他
■ 0
|||
|||
3 图神经网络模型
3.1 图卷积网络
图卷积网络
(GraphConvolutionalNetwork,
进行卷积操作主要有两种方法 一种是基于
GCN) :
谱分解 即谱分解图卷积 另一种是基于节点空间变
, .
换 即空间图卷积 等人[10]第一次将卷积神
, .Bruna
经网路泛化到图数据上 提出两种并列的图卷积模
,
型 谱分解图卷积和空间图卷积 等人对
——— .Bruna
比分析了一般图结构数据和网格数据共有的特点和
不同之处 综合运用了空间图卷积和谱分解处理图
,
像聚类问题 下面本文对谱分解图卷积和空间图卷
.
积进行详细的梳理和介绍
.
谱分解图卷积
3.1.1
尽管文献[10]最早提出用 分析图数据 但
CNN ,
是谱分解图卷积与图信号处理
(GraphSignalPro-
[15][16][17][18]有着密不可分的关联关系 文 cessing) .
献[19]提出处理图上离散信号方法
(DiscreteSignal
该方法把节点特征视作图信号
Processing,DSP), ,
用邻接矩阵表示图中信号的转移和扩散 利用傅里
,
叶变换扩展图信号并进行过滤 在 中 过滤
(3) . GCN ,
由于需要对邻居节点的数量进行统一并对特征 器 卷积 傅里叶变换 谱分解等理念都在该文献中
、 、 、
值求平均 ,所以一般在谱分解图卷积中多用定义
3
有涉及 .在傅里叶变换中 ,文献[20]将图上的特征向
的对称标准化拉普拉斯矩阵进行傅里叶变换和特征 量类比成拉普拉斯算子的特征函数 为傅里叶变换
,
向量分解 和卷积运算推广到图上奠定基础 拉普拉斯矩阵是
. .
2.2 图的类型 半正定对称矩阵 因此可以进行特征分解 由此傅里
, ,
不管是数学中的拓扑网络还是现实生活中的 叶变换中的特征函数可以转变为拉普拉斯矩阵的特
征向量 所以谱分解其实是利用图的拉普拉斯矩阵
网络 都可以统一抽象为图 图的形式多种多样
, . , .
按照图的边是否具有方向可以划分为有向图和无
进行特征分解 [21]提出的谱图理论
.Chung (Spectral
使得通过谱分解构造卷积核成为可
向图 边的属性称作权值 根据边是否具有权值可
. ,
GraphTheory)
能 其谱乘法器的平滑性支撑起了空间局部性 文
以将图划分为带权图和非带权图 此外还有异质
, .
.
图和同质图 同质图是指图中所有数据都为同一
献[10]通过操作图的拉普拉斯矩阵的特征向量来进
.
行卷积操作 构造了卷积函数
类型 即节点类型和边类型单一 而图中的数据类
, :
, .
型不尽相同的为异质图 ,即具有多种类型的节点 Hl=σ (UG θ(Λ )UTX
) (4)
和边 θ
. ■1 … 0
事实上 不仅仅局限于图数据处理 从广 G Λ =
,GNN . θ( ) ︙ ⋱ ︙
义上看 由于可以在赋范空间内建立拓扑关联 现实 θ
, , ■0 … n
世界的任何数据都可以被视作图结构数据 包括最
,
为常见的文字 图像 音频和视频 因此在转变为图
、 、 .
结构形式后 欧式结构的数据也可以输入到
, GNN
中进行训练和问题求解 这在下文介绍的实验数据
.
集上有所体现
.
||||
■
■
||||
计 算 机 学 报 年
38 2022
(5)
其中σ 是 激活函数 Hl是每层的输出
(·) sigmoid , ,
θ θ θ θ 是网络层参数 X 是节点特征向
=(1,2,…,n) ,
量 通过初始化权值 在数据训练中进行信息前向传
. ,
播 并对损失函数求偏导将误差进行反向传播 但是
, .
缺点在于需要进行特征分解 在大图上特征分解的
, 期 吴 博等 图神经网络前沿进展与应用
1 : 39
计算代价很高 而且每一次前向传播需要计算U 质量的局部空间滤波器 并且时间复杂度与稀疏连
. 、 ,
G θ(Λ )以及UT 三者的乘积 ,其计算复杂度与节点 通图的边数成线性相关
.
数量的平方成正比 ,即O (N2 ).由于 Bruna等人提 在节点分类任务中 ,有可能部分节点没有标签
,
出的谱分解图卷积中卷积核参数多 在网络层传播 因此有监督学习不再适用此情况 针对此问题
, . ,Kipf
过程中计算复杂度成幂指数增加 导致 提出 等人[27]提出半监督 节点分类模型 该模型在
, Bruna GCN ,
的图卷积算法主要限定于只具有低维特征的节点以 图的边数上进行线性缩放并学习隐藏层表示 这些
.
及小规模图上 因此如何对参数缩减成为一个迫切 表示既编码局部图结构 也编码节点特征 并且将图
, , ,
需要解决的问题 拉普拉斯正则项添加进损失函数上
. :
在图信号处理领域 文献[22]使用切比雪夫多项 λ λfX TLfX
, = 0+ reg= 0+ ( ) ( ) (8)
式近似拟合参数 在图拉普拉斯矩阵上进行快速小 是图中带标签节点的有监督损失函数λ是
, 0 , reg
波变换 文献[23]则使用 [24]算法将拉普拉斯 的权重参数 f 是神经网络可微函数 改进
. Lanczos , (·) .
矩阵进行正交相似变换 构造对角矩阵来生成 f 蕴含的条件从而允许模型从 中分配梯度信
, kry- (·) 0
[24]子空间的正交基 并推广到矩阵函数 这些图 息 该方法不再假定相连的节点更倾向于具有相似
lov , . .
信号快速过滤模型为谱分解图卷积加速计算提供了 类别 而是使用数据中部分有标签的节点数据对
,
理论和方法上的指导 在此基础上 等 训练 使网络模型对其余无标签的数据进行分
. ,Defferrar GCN ,
人[25]提出一种基于快速滤波递推公式的局部卷积 类 等人在卷积核上进行一阶近似生成网络层
.Kipf
算子 通常记作 卷积算子 其思想是应 间传播规则 通过稀疏密集矩阵乘法作用于信息前
, Chebyshev . ,
用切比雪夫多项式对特征矩阵求解 卷积核可以被 向传播上 式 中令K 并近似让λ 即
, . (7) =1, max ≈2,
定义成如下形式 每层卷积只考虑直接邻域 类似于 中 卷
: , CNN 3×3
K- 积核 并运用归一化技巧得到输出
1
其中θ是切比g
雪θ
夫(Λ
系)
数=
,k∑ T=
k0θ 是kT
切k(
比Λ 
) 雪夫多项式中(6 的)
,
Z
=D~ -1 2A~ D~ -1
2XΘ:
(9)
第k项 ,该项由递归定义产生 :T k(x )= 2xT
k-
1(x
)
其 参中 数矩Θ 阵∈R ZC×F R为 N简 ×F化 是后 卷的 积由 后单 的参 信数 号构 矩成 阵的滤 其波 时器
间
-T
k-
2(x ).其中T 0(x )= 1而T 1(x )=x.Λ  = 开销跟边的, 数∈
量成线性相关
计算复杂度为O.
|E|
Λλ -I是标度特征值的对角矩阵 取值在 , (
2 /max , FC 该方法只考虑一阶邻域 并通过堆叠多层增加
- 由此卷积层输出表达为 ). ,
[ 1,1]. 感受野 等人的主要贡献在于对网络的深度加
K ~ .Kipf
Hl=σ θT L X 深 减少邻域宽度 进一步提升了准确率和学习能
( k k( ) ) (7) , ,
i∑=
0 力 但是该方法仍然限定在无向图和无权图上 并且
~ . ,
中L =2L /λ max -I ,这样卷积核的参数就变成只有 要加载整个图才能进行训练 ,对于机器存储空间要
K个 每次卷积时将K 阶邻居上的特征向量进行 求较高 因此超大规模的图可能加载和运算时间比
. ,
加权求和 ,而θ k 就相当于权重系数 .计算复杂度为 较长
.
O (K|E| ),这使得训练参数的计算复杂度大幅度 在谱分解图卷积的进一步改进中 ,Li等人[28]
下降 特别是在稀疏图处理中尤其明显 文献[26]认 认为目前大部分谱分解图卷积的过滤器被设计用
, .
为 Chebyshev卷积算子的一个主要缺点是Λ  只能 来处理具有共享和固定的图结构数据 ,没有考虑
取值在 之间 只适用于特征值较小的情况 到在大小和连通性上的变化 因此 等人提出一
[-1,1] , . . Li
当拉普拉斯矩阵的特征值簇群分布在更大范围上 个概括性的动态图卷积网络
(AdaptiveGraphCon-
时 这种缺陷尤其明显 因此 等人[26]提出 为了能刻画不同的拓
, . Levie volutionNetwork,AGCN).
算法 基于参数化有理复函数 扑结构 给每组数据中的单个样本订制一
CayleyNet .CayleyNet ,AGCN
多项式 引入了谱变焦参数并 个拉普拉斯矩阵 使得过滤器能根据图的拓扑结
(CayleyPolynomial), ,
调节其大小 使其能更好地适应不同拉普拉斯矩阵 构组合邻居节点特征 将组内节点特征和组间节
, ,
特征值 等人证明了如果用雅可比置换公式 点特征联系起来 等人认为在图上工作的卷积
.Levie , .Li
卷积算子是 的一个特例 器不能 保 证 提 取 出 全 部 有 意 义 的 特 征 因 此
Chebyshev Cayley .Cayley- ,
能输出更好的平滑谱转移函数表示 并产生高 会训练一个残差图来探索图中的残差子结
Net , AGCN 计 算 机 学 报 年
40 2022
构 同时为了减少训练多个拉普拉斯矩阵的时间 规模文本分类 生物信息预测以及图像识别任务
. , 、
用马氏距离 学习矩 上验证了该方法的有效性 此外 文献[37]提出一种
AGCN (MahalanobisDistance) . ,
阵间最优距离度量参数 将原来的计算复杂度从 包含 网络层结构的深度图卷积神经网
, SortPooling
与节点个数相关变成与网络层维度相关 文献[29] 络
. (Deep Graph ConvolutionalNeuralNetwork,
提出一种图胶囊网络 先用图卷积层处理输入的图结
(GraphCapsuleNetwork, DGCNN).DGCNN
借鉴了文献[30]中局部胶囊 构数据 然后将产生的图节点排列成固定序列 借
GCAPS-CNN), (Local , .
的思想 封装复杂的隐含实体计算 鉴 [38]图核算法用来对具有同一
Capsules) ——— , Weisfeiler-Lehman
并输出具有实例化参数的信息向量 由于标准化 属性的节点进行聚类 其输出在形式上为固定维
. ,
卷积层中的局部性会导致聚合函数得到的节点特 度大小的矩阵 之后再使用 中的一维的卷积
. CNN
征有信息丢失[31] 因此 将图卷积运 层进行卷积运算 最后与全连接层相连 该体系结
, GCAPS-CNN , .
算的标量输出改成信息向量 其包含了节点特征 构允许对原始图进行端到端的梯度下降训练 无
, ,
的高阶统计信息 同时固定每层输出的节点特征 需将图转换为向量 通过置换不变量的图
. .DGCNN
维数 以 避 免维度爆炸 针对置换等变性问题 结构任务增强池化网络 从而提高 的特征缩
. , , GCN
构造基于协方差矩阵的置换不变层 减和特征抽象的性能 而文献[39]更进一步地认为
GCAPS-CNN , .
在胶囊函数中使用双射的多项式系数保存局部邻居 等代表性 学习函数在本质上是扁平
GCN GNN
特征值 从而脱离了对节点顺序的依赖 并使用图谱 的 没有学习到图的层次表示 这一限制影响了图
, , , .
距离簇 [32]学 分类任务中图标签的预测精度 因此提出一种端
(FamilyofGraphSpectralDistances) ,
习图全局拓扑结构特征 由于管理图胶囊向量维度 到端的可微分图池化方法 为
. ———DiffPool.DiffPool
的需要额外的信息 因此学习成本会有一定上升 此 每一层节点学习一个可微分的软簇分配 这种软
, . ,
外 为了同时学习到局部一致性和全局一致性 簇分配是将已经学习好的节点嵌入表示映射到一
, ,
等人[33]设计了一种双图卷积神经网络 在 组聚类集合中 然后输入到下一个神经网络层中
Zhuang . ,
双图卷积神经网络中 有两个图卷积神经网络存 去 即 下一层的输入对应上一层中的聚类集
, . GCN
在 分别代表全局知识和局部知识 通过随机游走 合 通过循环迭代多次就可以生成图的层次表示
, . , ,
构建正点互信息 相应的图表示也会越来越抽象 最终输出的节点
(PositivePointwiseMutualInfor- .
矩阵 利用邻接矩阵和 矩阵 向量可以用作 层的输入 并且使用随机梯
mation,PPMI) , PPMI Softmax ,
分别嵌入基于局部一致性和全局一致性的图知 度下降来进行端到端的训练 同时 每经过一层池
. ,
识 并引入一个无监督损失函数整合来自两个网络 化处理 图的输入规模也会相应的减小 显式地降
, , ,
的不同数据 低了计算量 不仅仅可以嵌套在 网
: .DiffPool GCN
λt 络框架上 并且可以与各种 端到端地相结
0+ ()reg(ConvA,ConvP) (10) , GNN
其中λt 是一个随时间变化的动态参数 Conv 代 合 实验结果表明 结合现有的 方法
() , A . ,DiffPool GNN
表相连的节点趋向具有相同标签的知识 Conv 代 平均提高了 到 的精度 在图分类问题上
, P 5% 10% . ,
表在相同上下文环境下出现的节点趋向具有相同标 在五个基准数据集中的四个上实现了最佳
DiffPool
签的知识 性能
. .
传统 为了降低网络层后端的训练参数 表 从模型 核心思想 图种类 学习模式 激
CNN , 1 、 、 、 、
往往会设计一个或者多个池化层 这在 中也 活函数 数据以及任务对谱分解图卷积模型进行
, GCN 、
十分有必要 在图池化处理上 等人[34]将卷 了汇总
. ,Henaff .
积算子扩展到高维数据上 使用多谱聚类在不同尺 空间图卷积
, 3.1.2
度上构造邻域 在图卷积网络架构中加入最大池化 空间图卷积从图结构数据的空间特征出发 探
, ,
层和平均池化层 逐步抽取更高级别的语义特征 并 讨邻居节点的表示形式 使得每个节点的邻居节点
, , ,
且降低了模型复杂度 等人假设图的结构没 表示变得统一和规整 方便卷积运算 空间图卷积方
.Henaff , .
有先验信息 结合高斯扩散核 法主要有三个关键问题 一是中心节点的选择 二是
, (GaussianDiffusion , ;
[35]以及自校正扩散核 感受域的大小 即邻居节点个数的选取 三是如何处
Kernel) (Self-tuningDiffusion , ;
[36]计算节点特征相似度矩阵 完成无监督 理邻居节点的特征 即构建合适的邻居节点特征聚
Kernel) , ,
和有监督的图估计 目标 在大 合函数
(GraphEstimation) . . 期 吴 博等 图神经网络前沿进展与应用
1 : 41
表1 谱分解图卷积模型
模型 文献 核心思想 图种类 学习模式 激活函数 数据 任务
/
文献[10] 傅里叶变换 同质无向 有监督 图聚类
ReLU ①
[25] 切比雪夫多项式近似拟合 同质无向 有监督 ReLU 图分类
Chebyshev ①②
Softmax
图分类
有监督
CayleyNet[26] Cayley多项式 同质无向 半监督 ReLU ①③④ 节点分类
矩阵补全
拉普拉斯正则项 同质无向
文献[27]
一阶邻域近似 同质有向
半监督 ReLU
⑤⑥⑦⑧
节点分类
Softmax
单样本拉普拉斯矩阵
 15 16 17 18 19 图分类
AGCN[28] 残差图 异质无向 有监督 -  20 21 22 图预测
马氏距离
 25
高阶统计向量
异质无向
GCAPS-CNN[29] 协方差矩阵 同质无向 半监督 Softmax ⑨⑩ 11 12 图分类
图谱距离簇  25 26 27 29
双图卷积
文献[33]
矩阵
异质无向 半监督 Sigmoid
⑤⑥⑦⑧
节点分类
PPMI Softmax
高斯扩散核 异质无向 有监督 图分类
文献[34]
自校正扩散核 同质无向 无监督 Relu  14 28 30 图预测
Softmax
DGCNN[37] SortPooling 图核 异质无向 有监督 Tanh ⑨⑩ 11 23 24 图分类
Weisfeiler-Lehman  25 27 31
Relu
微分软聚类 异质无向
DiffPool[39] 节点嵌入映射 同质无向 有监督 Softmax ⑨ 13 24 27 29 图分类
Relu
①Mnist;②20News;③Cora;④MovieLens;⑤Cora;⑥Citeseer;⑦Pubmede;⑧NELL;⑨COLLAB;⑩IMDB-BINA-
数据集 RY; 11IMDB -MULTI; 12REDDIT-BINARY; 13REDDIT-MULT; 14Reu ters; 15 Delaneysolubility; 16Az-logD; 17Hy-
dration-freeenergy; 18Tox21; 19ClinTox; 20Sider; 21Toxcast; 21SydneyUrbanObjects; 23PTC; 24PROTEIN;
 25NCI1; 26NCI109; 27D&D; 28DPP4; 29ENZYMES; 30ImageNet; 31MUTAG
针对上述三个关键问题 文献[40]首先提出在空 利用广度优先搜索扩展中心节点的邻居节点 和中心
, ,
间上的卷积操作方法 节点一起构成一个固定大小的邻域集合 若某个节点
———PATCHY-SAN.PATCHY- .
的处理流程可以分为三个步骤 节点中心度量 节 缺少邻居节点 则在其一阶邻居节点的基础上继续扩
SAN : 、 ,
点邻域集合收集以及子图规范化 节点中心度量是为 展 直到收集到足够的邻域集合节点数量 在子图规范
. , .
了确定节点次序 提供了两种可供选择 化中 对邻域集合中的节点按照一定的标号函数进行
.PATCHY-SAN ,
的方法 节点中心度或者 [41]算法 排序 形成规范化子图 每个节点属性值构成了一个输
— Weisfeiler-Lehman , , .
用于测量节点的中心性以获得节点排名 并且按照固 入通道 边的属性值也构成了一个输入通道 再用标准
, , ,
定的间隔从排序中选取节点 在节点邻域集合收集中 的 完成空间图卷积 该过程如图 所示
. , CNN . 2 .
图 一个标准的空间图卷积处理流程
2
模型有序地组织了中心节点 化使得每个子图都是固定大小的 方便参数共享 但
PATCHY-SAN , .
和邻居节点 并对它们的特征加以了利用 子图规范 是其缺点在于节点中心度量函数不够确定 中心节
, . , 计 算 机 学 报 年
42 2022
点排序的好坏直接影响模型的性能 邻居节点的数 入表示的映射函数 在中心节点的采样上 文献[45]
. . ,
目需要根据训练量和图结构进行调整 模型在较小 提出基于重要性采样 的
. (ImportanceSampling)
规模的图数据中有过拟合的情况发生 算法 它的核心思想是将图卷积解释为概
. FastGCN .
除了 构造规则欧式结构数据 率测度下嵌入函数的积分变换 即图中的节点都被
PATCHY-SAN ,
的方法 文献[42]提出扩散卷积神经网络 认定是独立同分布的样本 把损失函数和卷积层当
, (Diffusion ,
基 作是节点嵌入函数的积分 通过定义样本损失和样
ConvolutionalNeuralNetwork,DCNN).DCNN ,
于扩散核的思想 考虑节点之间链接重要性的不同 本梯度的蒙特卡罗 近似来计算积分
, , (MonteCarlo) .
将中心节点的邻居节点特征进行映射 扩散卷积核 由于对中心节点进行了选择性采样 模型训练不再
. ,
的操作使得同质图的输入会得到同一个预测结果 是对全图进行 而是部分节点批量迭代 这使得训练
, , ,
因而具有平移不变性 对于图t中每一个节点i 每 过程更加有效 相较于 可以
. , . GraphSAGE,FastGCN
跳j后的特征k 其激励函数可以概括为 在新的节点和边不断加入进来的情况下 预测精准
, ,
N 度仍旧保持较高水准
t
Z tijk=f (Wc jk· P ti*jlX tlk) (11) 尽管邻居节点随. 机采样和节点中心重要性采样
l∑
=1
其中P 为节点概率转移矩阵 X 为特征矩阵 Wc 能够在一定程度上控制感受域的规模 但是存在估
t , t , ,
为权值矩阵 的核心是概率转移矩阵 在一 计上的偏差和采样的邻居节点消失的缺陷 针对此
.DCNN , .
定程度上可以识别同构图 但是面对稠密图时 每跳 问题 文献[46]提出基于方差缩减的随机训练方法对
. , ,
内访问的节点数目会非常多 需要保存大量的张量 其进行优化 其将节点的历史激活信息h- l 作为控制
, , . v
这对于计算机内存空间有较大的需求 模型能较好 的变量 卷积层激活函数为
. ,
地获取图局部信息 但是欠缺捕获长距离节点信息 -
的能力
.针对此问题,
,文献[43]使用随机游走
(Ran-
其中P(P 是H 正l ) 则u 化=
后v∑
∈
的n(u
传)P 播uv▽ 矩h 阵l v+
Hv∑
∈
是n(
lu)P 层uvh 的l v 激活(12 矩)
对图进行预处理 在图结构已知的情况 ,
dom Walk) . 阵 在模型训练中 权重参数没有发生较大改变时
下 对于图中每个节点 根据与中心节点的邻近相关 . , ,
, ,
-
性大小排序 ,并选取p个邻居节点 .其排序值由转移 近似地用上轮的激活信息hl
v
代替hl v,而 ▽hl v=
矩 阵 计 算 完 成 这 样 时 间 复 杂 度 由 的 hl-h- l 在多个数据集上的评测表明 该方法的收
. DCNN v v. ,
N2F 下降为 Np 其中p N 而在图结构 敛性和准确率与没有使用采样方法的 不相上
O( ) O( ), ≪ . GCN
未知的情况下 用图相关矩阵作为相似矩阵来估计转 下 但大幅度减少了计算量 此后 采样策略从对节
, , . ,
移概率 之后用卷积算子的权值与邻居节点内积作为 点操作优化逐渐转变为对网络层更新函数的优化
. .
卷积输出 ,权重值根据邻居节点与中心节点的距离调 文献[47]提出一种网络层间自适应采样策略
(Adap-
整 距离越远值越低 代表相关性越小 在自顶向下分层构造网络过程中
, , . tiveSampling). ,
感受域大小一直是空间图卷积中的关键参数 对底层的采样会在一定程度上受限于顶层 其中采
, .
其涉及到邻居节点数目的选取 由于空间图卷积通 样的邻居节点对于上一层网络是可见的 由不同的
. ,
常都是递归地计算邻居节点 导致在网络层数线性 父节点共享 避免了邻域因为固定大小数值而导致
, ,
增加的同时 感受域的大小指数递增 为了减少训练 的过度扩展 自适应采样策略将层间更新函数重
, . .
的复杂程度 相应的采样方法被提了出来 这其中比 新定义为期望的形式 使得邻居节点服从一定的
, . ,
较主流的采样方法可以分为两类 一类是修改邻居 概率分布 并引入蒙特卡罗算法 采样器会根据训
: , ,
节点的采样策略 另一类是修改中心节点的采样策 练过程中方差减少而动态适应 每个节点有一个
, .
略 在邻局节点采样上 文献[44]提出一种归纳式节 自相关函数 用来确定其对采样的重要性 通过层
. , , .
点嵌入算法 间跳跃连接 的方式保存二阶近
GraphSAGE(GraphSampleandAg- (SkipConnection)
中心节点的感受域由多轮迭 似邻居节点 让信息在不同网络层间传播 从而增
gregate).GraphSAGE , ,
代产生 在每轮迭代中抽取不同标准数目的邻居节 强训练的有效性和经济性 该方法总结了
, . Graph-
点 对于邻居节点数目不足的 采取重复采样策略 和 的采样 并指出它们都是自适应
. , , SAGE FastGCN ,
并生成中心节点的特征聚集向量 相较于传统直推 采样的一个特例
. .
式节点嵌入算法 并不是为图中每个 在邻居节点数目确定后 需要考虑对邻居节点
,GraphSAGE ,
节点生成固定的表示 而是学习一个为节点产生嵌 特征进行聚合处理 在邻居节点特征聚合上 一般的
, . , 期 吴 博等 图神经网络前沿进展与应用
1 : 43
做法是对邻居节点进行线性或者非线性变换 并与 路径节点集合和不平衡路径节点集合与中心节点特
,
中心节点特征进行整合 在 中 设计了 征进行拼接并激活输出 达到在不同神经网络层之
. GraphSAGE , ,
三种不同的聚合策略 将邻 间转播正负极性连接信息的目标 在四个真实世界
:MeanAggregator——— .
居节点特征值取平均 邻居 数据集上的实验表明 能够高效地学习到节
;LSTM Aggregator——— ,SGCN
节点按随机排列输入 并取其隐层输出 点的潜在表达 并且在长路径上的聚合函数能够提
LSTM, ; ,
取邻居节点特征经过线性 升节点表达效果 等人[51]提出
PoolingAggregator——— .Such Graph-CNN.
变换后各个位置上最大值 除了对一阶邻居节点的 构建了一个具有图池化操作的异质图
. Graph-CNN
聚合 二阶及以上的邻居节点特征也不能被忽视 因 过滤器 能够同时学习图中节点和边的特征值
, . , .
此文献[48]提出 可以识别具有边缘特征的图 通过计算
CoN-GCN(CoreNeighbors-GCN). Graph-CNN ,
算法分为两个步骤 步骤一为待编码节 卷积过滤器与输入节点的内积并求和 得到节点输
CoN-GCN : ,
点选择重要的邻居节点 邻居节点由结构紧密度函 出 实际上是把节点和边的特征加入进
, .Graph-CNN
数计算得出 步骤二是从候选邻居节点中分级采样 邻接矩阵 通过线性变换得到新的节点特征值 在权
. , .
得到固定数量的核心邻居节点 经过编码后 将节点 重参数的初始化上 由于图数据的输出依赖于卷积
. , ,
及其邻域的特征矩阵送入卷积层 由于每个节点的 核的权重系数 输入节点值和邻接矩阵 高斯分布随
. 、 ,
一阶邻居节点和二阶邻居节点都被聚合 因此 机初始化方法可能会造成梯度爆炸和梯度消失 因
, CoN- .
能够学得中心节点更有效的表示 此 采用 [52]初始化和批量规范化
GCN .CoN-GCN Graph-CNN Xavier
算法核心在于结构紧密度量函数 可以使用共同邻 [53]方法避免此情况出现
, (BatchNormalization) .
居数 系数和 系数 如果出现 表 从模型 核心思想 图种类 学习模式 激
,Jaccard Adamic/Adar . 2 、 、 、 、
结构度量相同的邻居节点 则再使用欧式距离区分 活函数 数据以及任务对空间图卷积模型进行了
, , 、
从而得到邻居节点的等级排序 等人[49]提出可 汇总
.Gao .
学习 图 卷 积 层 谱分解图卷积和空间图卷积小结
(LearnableGraph Convolutional 3.1.3
提出一种子图训练方法 在 的核心原理在于利用边的连接属性对原
Layer,LGCL).LGCL . GCN
选取初始节点后 用宽度优先搜索动态随机挑选外 始节点信息进行聚合和整理 以便生成新的节点表
, ,
围节点数量 在达到规定数目后 停止扩展 在形成 示 从本质上看 谱分解图卷积和空间图卷积都是对
, , . . ,
子图后 根据原始邻居节点特征值排名构造 邻居节点特征聚合 产生一个固定维度大小的输出
,LGCL ,
新的邻居特征向量 特征向量的维数相当于通道数 表示 进而达到传播邻居节点信息的目的 基于谱
, , , .
通过一维卷积神经网络进行卷积运算 最终将中心 分解的方法在数学上给出了卷积操作的严格定义
,
节点与邻居节点聚集的多维特征压缩为一维格式 和公式证明 但是缺点在于傅里叶变换对于每一
. ,
在一定程度上减少了图卷积的内存和计算时 个图都是唯一的 所以只能在固定的图上进行卷
LGCL ,
间 适用于大规模图训练 积运算 对于图结构依赖性很强 由于拉普拉斯矩
, . , .
此外 一些学者从边的角度出发 在邻居节点特 阵中的邻接矩阵和度矩阵都是基于无向图定义
, ,
征聚合中利用特殊的边信息 能够对邻居节点特征 的 除非将有向图转换为无向图 因此谱分解的方
, , ,
聚合产生更加有效的作用 例如在社交媒体等现实 法并不能直接用于有向图和带权图 此外 谱分解
. . ,
网络中 边的符号是必须被考虑的事情 将 的 图卷积对图中所有节点同时进行变换 计算和存
, . GCN ,
模型框架从无符号图上应用到有符号图上需要面对 储空间的要求较高 难以适应大规模图数据集的
,
两个挑战 一是如何处理负链接 二是如何将负链接 分析 空间图卷积通过规定一定顺序直接对图中
: ; .
和正链接有机结合 从而学习有效的节点表示 针对 的每个节点操作 由于是在节点上进行局部卷积
, . . ,
上述问题 [50]提出基于平衡理论 因此卷积核权值可以被共享 空间图卷积使用了
,Derr (BalanceThe- .
的符号图卷积网络 一定的采样策略 可以并行批量化计算 降低了计
ory) (SignedGraphConvolu- , ,
在 中 一个平衡路 算时间和存储空间 但是其缺点在于中心节点顺
tionalNetwork,SGCN). SGCN , .
径被定义成由偶数个负链接组成 一个不平衡路径 序需要确定 因此具有位置依赖性 邻居节点数目
, , .
由奇数个负链接组成 由此 聚合函数分为两个部 的选择是一个不确定的过程 不同方法构造的感
. , ,
分 一个对应中心节点的平衡邻居节点集合 一个对 受域大小一般不尽相同 这给不同网络的参数比较
: , ,
应不平衡的邻居节点集合 将递归定义得到的平衡 带来一定的困难
. . 计 算 机 学 报 年
44 2022
表2 空间图卷积模型汇总
模型 文献 核心思想 图种类 学习模式 激活函数 数据 任务
/
节点中心度量 运行时间分析
无监督
PATCHY-SAN[40] 节点邻域集合收集 异质无向
有监督 Softmax ①②③④⑤⑥
特征可视化
子图规范化 图分类
同质无向 有监督 节点分类
DCNN[42] 扩散卷积核
异质无向 半监督 Softmax ①③④⑩ 12 20 21 图分类
随机游走 同质有向 回归
文献[43]
转移矩阵 异质无向 - Sigmoid ⑦⑨ 图分类
特征聚集向量 无监督
GraphSAGE[44]
聚合策略
同质无向
有监督 Sigmoid ⑧ 14 15
节点分类
蒙特卡罗近似 有监督 节点分类
FastGCN[45]
嵌入函数积分变换
同质无向
半监督 - ⑩ 12 15 图预测
控制变量估计器 同质无向
文献[46]
方差缩减 异质无向
半监督
- ⑧⑩ 11 12 13 15
预测
自适应采样
节点分类
文献[47] 蒙特卡罗近似 同质无向 有监督 LeakyReLU
⑩ 11 12 15 预测
跳跃连接 Softmax
邻居节点排序
CoN-GCN[48]
分级采样
同质无向 半监督
- ⑩ 11 12
节点分类
特征压缩 同质无向
LGCL[49]
宽度搜索 异质无向
有监督
Softmax ⑧⑩ 11 12
节点分类
平衡理论
SGCN[50]
平衡路径
同质无向 有监督
-  16 17 18 19
链接预测
异质图过滤器
图分类
Graph-CNN[51] Xavier初始化 异质有向 有监督 Softmax
③⑥ 22 23 24 25 节点分类
批量规范化 Relu
①MUTAG;②PCT;③NCI1;④NCI109;⑤PROTEIN;⑥D&D;⑦DPP4;⑧PPI;⑨Mnis;⑩Cora; ]gCiteseer; 12Pubmed;
数据集
 13NELL; 14WebofScience; 15Reddit; 16Bitcoin-Alpha; 17Bitcoin-OTC; 18Slashdot; 19Epinions; 20PTC; 21ENZYMES;
 22CIFAR-10; 23ImageNet; 24fMRI; 25Bosphorus3DFace
络的表示模型
(DeepNeuralNetworkforGraph
3.2 图自编码器 Representations,DNGR).DNGR 采用随机游走模
型 获取图结构信息 生成
在深度学习领域 自编码器 (RandomSurfingModel) ,
, (Auto-encoder,
概率共现矩阵 并在概率共现矩阵的基础上计算
是一类将输入信息进行表征学习的人工神经网 ,
AE)
矩阵 在图节点嵌入表示学习上 设计
络 自编码器一般包含编码器和解码器两个部分 基 PPMI . ,DNGR
. , 了一个叠加去噪自编码器
于自编码器的 GNN被称为图自编码器 (Graph Au- 输入 (Sta 矩ck 阵ed 学D 习en 图ois 节in 点g 低Au 维-
可以半监督或者无监督地学习 to-encoder,SDA), PPMI
to-encoder,GAE),
表示 并且输入的一部分会被随机置零以提高模型
图节点信息 如图 所示 ,
. 3 . 的鲁棒性 的优点在于能学习到有向图中更
.DNGR
多的结构信息 其生成的低维嵌入表示可以用于不
,
同的下游任务 但缺点是忽略了图属性信息 没有将
. ,
图属性和图结构信息一并纳入到模型框架中 因此
,
图结构的轻微变化就会影响节点表示的好坏 针对
.
节点内容信息的收集 等人[55]提出一种边缘
,Wang
图 图自编码器 图自 编 码 器
3 (Marginalized Graph Autoencoder,
算法 其在自编码器中使用基于谱分解的
MGAE) .
在图自编码器上 文献[54]提出基于深度神经网 图卷积网络层 整合节点属性特征和图结构信息 使
, , , 期 吴 博等 图神经网络前沿进展与应用
1 : 45
得它们之间能进行数据交互 堆叠多层图形 贴合地建模 基于半隐式变分推理[61]和
.MGAE .SIG-VAE
自编码器 以建立一个深层次的架构来学习有效的 正则流形 [62]理论 其整体是一
, (NormalizingFlow) ,
节点表示 等人认为在训练中随机噪声引起 个层次化的变分框架 并使用伯努利 泊松链接解
.Wang , -
的干扰可能会提供更有效的输出表示 因此会在节点 码器[63] 这可以使邻居节点共享 从而更好地对图
, . ,
内容特征中动态地加入一些干扰项 通过将某些特征 依赖结构进行生成建模 这种层次结构提供了更灵
. .
值置为零 获得在大规模图上学习的能力 构 活的图生成范式 能更好地捕获真实世界的图属性
, .MGAE , .
建了优化器以确保编码的节点属性信息和真实属性 与 相比 是一个更加强大的图生
VGAE ,SIG-VAE
信息之间的误差最小化 在得到每个节点的表示后 成模型 具有半隐式构造所支持的更可靠推理 其派
. , , ,
使用谱聚类算法得到图聚类结果 生图的隐含表示更具可解释性 不仅在图
MGAE . .SIG-VAE
在一定条件下 自编码等价于正则拉普拉斯 数据建模上扩展了 的灵活性 同时在节点分
, VAE ,
矩阵的奇异值分解 类 图聚类 图生成和链接预测任务的准确率上取得
(SingularValueDecomposition, 、 、
[56] 因此文献[57]提出一种 模型 更好的表现 文献 提出适用于生成小图的
SVD) . AutoGCN , . [64]
其模拟一阶卷积算子 使用了多个级联自编码器 算法 核心思想是用编码器
, GraphVAE .GraphVAE
替代卷积矩阵 这相当于在图上构建了一个动态 将图转为连续向量表达 通过解码器直接输出一个
, ,
谱分解图卷积 在一定程度上缓解了增加网络深 预先定义的最大概率完全连通图 而节点和边的属
, ,
度而导致的参数过平滑的现象 非线性的自编码 性被建模为独立的随机变量 此外 设
. . ,GraphVAE
器可以学习到更加复杂的局部图结构表达 同时 计了图匹配算法来计算图之间的相似性
. .
应用多任务目标函数 缓解了冷启动问 在隐含表示的分布上 为了进一步提高图嵌入
AutoGCN , ,
题 可以更有效地学习到稀疏图中节点特征的隐 生成的有效性 采用对抗化和正则化技术的图自编
, ,
含表达 码器被提了出来 等人[65]提出了一种对抗正则
. .Pan
在 中 由编码器产生的中间低维隐含向量 图嵌入生成框架 其包含两种对抗方法
AE , , :ARGA
表示必须要贴合真实样本 否则通过解码器解码出 和
, (AdversariallyRegularizedGraphAutoencoder)
来的新样本表示与真实的数据难以近似 因此变分
. ARVGA (Adversarially Regularized Variational
自编码器 [58]被提 该框架将图中的拓扑结构和
(VariationalAuto-encode,VAE) GraphAutoencoder).
了出来 变分自编码器中 编码器学到的不是样本的 节点属性编码成一个紧凑的表示 然后训练解码器
. , ,
低维向量表示 而是低维向量表示的分布 通过将编 重构图结构 为了使学习到的图节点嵌入更具有鲁
, . .
码器生成的中间隐含向量约束在一个正态分布上 棒性 等人使用 探索图的结构和节点属性
, ,Pan GCN
然后在该正态分布中采样得到中间低维向量表示 信息 将整个图编码进一个隐含空间 在解码重构图
, , .
并经过解码器还原出原始样本 基于此优点 文献 的同时 添加对抗训练模型规范隐含节点 并学习到
. , , ,
提出一种变分图自编码器 更具鲁棒性的图表达因式 对抗训练模型用来区分
[59] (VariationalGraph .
使用两层 等 隐含节点是来自于真正的先验分布还是图编码器产
Auto-encoder,VGAE).VGAE Kipf
人[27]提出的 充当编码器 输入图的邻接矩阵 生的 图编码器和对抗正则解码器被置于一个联合
GCN , .
和节点的特征矩阵 学习节点隐含向量表示的 训练框架下 这样它们能够同时被优化 文献 认
A X, , . [66]
均值和方差 并用隐含向量内积充当解码器 损失函 为假设数据服从先验的正态分布并不是一个最合理
, .
数由两部分组成 第一部分是生成图和原始图之间 的方法 因此提出基于重启随机游走
: , (Random
的距离度量差 第二部分是节点隐含向量分布和标 [67]的正则化技术 在编码器和
; WalkwithRestart) .
准正态分布的 散度 尽管 解码器中间应用随机游走和 [68]学习拓扑
Kullback-Leibler . VGAE SkipGram
能生成贴合原始图数据的表示 但是需要迭代训练 图的局部信息 从而获得节点序列 并最大化节点之
, , ,
图卷积网络来进行优化 因此训练时间会比较漫长 间的共现概率 在此基础上建立了
, . . RWR-GAE
除此之外 文献 提出了半隐式图变分自编码器 和
, [60] (RandomWalkRegularizedGraphAutoencoder)
(Semi-implicit Graph VariationalAuto-encoder, RWR-VGAE(Random Walk Regularized Varia-
由于图中可能存在重尾 多模式 偏斜 两种网络正则框架
SIG-VAE). 、 , tionalGraphAutoencoder) .
和丰富的依赖结构 引导半隐式分层变分 总体上看 对抗图自编码器使用了正则化和对
,SIG-VAE ,
推理 允许对给定图隐式数据的后验分布进行更加 抗性训练等手段 一方面这可以让编码器从不同的
, . 计 算 机 学 报 年
46 2022
角度学习原始数据特征 产生的低维隐含嵌入能更 型的鲁棒性进一步增强 表 从模型 核心思想 图
, . 3 、 、
加有效地表示原始图 并可以用于其他的下游任务 种类 学习模式 激活函数 数据以及任务对图自编
, 、 、 、
中 另一方面 解码器具有更加强大的还原能力 模 码器模型进行了汇总
. , , .
表3 图自编码器模型汇总
模型 文献 核心思想 图种类 学习模式 激活函数 数据 任务
/
随机游走 节点聚类
[54] 叠加去噪自编码器 异质无向 可视化
DNGR - Sigmoid ①②③④⑤⑥⑦
矩阵 相似度检测
PPMI
堆叠图自编码
[55] 边缘化 异质无向 无监督 Sigmoid 图聚类
MGAE ③⑧⑩
结构内容学习 Relu
[57] 级联自编码器 异质无向 半监督 Softmax 节点分类
AutoGCN ⑧⑨
Relu
散度
Kullback-Leibler
[59] 期望损失 异质无向 无监督 Sigmoid 链接预测
VGAE ⑧⑩ 11
变分编码器 Relu
节点分类
半隐式变分推理 半监督
SIG-VAE[60]
伯努利 泊松链接解码器
异质无向
无监督 - ⑧⑩ 11 12 13 14 15 16
图聚类
- 图生成
概率连通图 Sigmoid
GraphVAE[64]
图匹配
异质无向
- Relu  17 18
图生成
Softmax
链接预测
对抗训练
ARGA&ARVGA[65]
图编码
异质无向 无监督 Sigmoid
⑧⑩ 11
节点聚类
Relu 图可视化
随机游走
节点聚类
RWR-GAE& 正则节点表示 异质无向 无监督
[66] Relu ⑧⑩ 11 链接预测
RWR-VGAE
SkipGram
数据集 ①20News;②Wine;③Wikipedia;④WordSim353;⑤WordSimSimilarity;⑥WordSimRelatedness;⑦MC;⑧Cora;
⑨JDFinance;⑩Citeseer; 11PubMed; 12USAir; 13NS; 14Router; 15Power; 16Yeast; 17QM9; 18ZINC
3.3 图生成网络 用贝叶斯网络学习随机变量之间
Graphical-GAN
的依赖结构 用期望传播算法
建模和生成图是研究生物工程和社会科学网络 , (ExpectationPropa-
的 基础 .图生成网络
(Graph Generative Network,
gation
最)[70 小]联 化合 了每训 个练 局生 部成 因器 素和 的判 差别 异器
并.G 估ra 计ph 图ica 中l-
GGN)是一类用来生成图数据的 GNN,其使用一定 GAN ,
的局部分歧 以处理隐式似然性
的规则对节点和边进行重新组合 最终生成具有特
, , .Graphical-GAN
有两种实例变体 高斯混合图生成网络
定属性和要求的目标图 然而 在图上模拟复杂分
. , 和:
状态空间图生成网络
(Gau ssian
布 并从这些分布中有效地采样是比较困难的 因为
, .
MixtureGGN) (StateSpace
分别用来学习图中的离散结构和时间特
有些图数据具有非唯一性 高维性质 图中边缘之间
、 ,
GGN),
存在复杂的非局部依赖性 因此不能假设所有的图 征 结合了深度学习模型学习复杂
. .Graphical-GAN
数据都来自于同一个先验分布 尤其是对于异质图 隐含特征和概率模型学习数据先验知识的能力
, , .
模型在识别过程中必须要具有平移不变性 因此 但是在概率图模型中 模型依赖于很强的独立性
,
.
着重用来解决这类问题和克服其中的难点 假设 只能获取特定的图属性 而图语法模型
, ,
GGN .
的输入可以是节点或者边向量 也可以是给定 [71]对图的内容语义信息
GGN , (GraphGrammarsModel)
的图嵌入表示 然后对采样的数据学习后合成各种 限制严格 针对上述不足 文献 介绍了一个强
, , . [72]
任务所需要的图 大的新方法用来学习生成图 该方法聚集节点的
. .
文献 提出图形生成对抗网络 邻域并使用 [73]更新节
[69] (Graphical GRU(GatedRecurrentUnit)
点的向量表示 在线性迭代地添加节点和边的过
Generative Adversarial Network,Graphical-GAN). . 期 吴 博等 图神经网络前沿进展与应用
1 : 47
程中 结合 中每轮输出结果的概率分布 为 慢 文献[75]虽然在链接预测和节点分类上取得较好
, MLP , .
节点和边分配不同的生成和连接的决策序列 通 的效果 但是在诸如化学分子式等真实世界数据集
. ,
过学习图上的分布可以准确地得到图的结构和属 上的学习中 并没有保存其中物理或者化学意义的
,
性 从而摆脱向量和序列式知识表示的限制 节点 图范式 针对此问题 文献 提出模拟现实世界网
, . . , [76]
状态的初始化会利用图属性特征 同时加入一定 络的隐式图生成模型 从邻
, ———NetGAN.NetGAN
的条件信息使得模型能灵活模拟图中的一些关 接矩阵中生成随机游走路径 并使用有偏二阶随机
,
系 在训练和评估中 用蒙特卡罗近似估计方法和 游走[77]采样方式将学习过程从模拟图的拓扑结构
. ,
均匀随机排序处理图样本数据 使元素的生成具 转变为学习在图上的分布 构造了一个端
, .NetGAN
有合理性和有序性 但是节点和边的顺序参数在 到端的生成器和解码器 其生成器用于生成离散输
. ,
训练和测试中是固定不变的 不能很好地适应具 出样本 解码器用来区分输入目标是真实图还是合
, ,
有不同顺序关系的图 此外 在迭代生成节点和边 成图 在训练时运用随机神经网络
. , .NetGAN Wasse-
的过程中 决策序列过长 一方面使得概率估计变 [78]框架 提出 和
, . rsteinGAN , Val-criterion EO-crite-
得不准 另一方面会使得训练过程变得更加困难 两种提前终止策略 用来控制图生成过程的有
, , rion ,
可能会产生梯度消失和梯度爆炸的现象 效性 在训练完成后 新生成的图可以由一组随机游
. . ,
现有的图分析方法对于图中的缺省值过于敏感 走节点的规范化共生矩阵得到 在实验中
, . ,NetGAN
不能处理拓扑结构混杂的情况 针对此问题 文献 除了能够显式地生成真实世界存在的网络图 在链
. , ,
在 的基础上提出图拓扑插值器 接预测上也具有优良的性能表现 从侧面反应了其
[74] GAN (GraphTo- ,
重新构建了基于边权重的 较强的泛化特性 文献 提出化学分子式生成对
pologyInterpolator,GTI), . [79]
邻接矩阵 用于量度不同的边对整个图的重要程度 抗网 络
, . (MolecularGenerative AdversarialNet-
框架由六个层模块组成 分级识别层模块 分 基本框架是由一个生成
GTI ——— 、 work,MolGAN).MolGAN
割层模块 、GAN层模块 、再生成层模块 、汇集层模块 器和一个判别器组成的改进型 WGAN[80] .类似于
和阶段识别模块 其中分级识别层用于制定规则 从先验向量中采样 并传递给
. NetGAN,MolGAN ,
并决定子图是否被输入下一个模块 分割层模块 生成器 后者输出化学分子式的图结构表示 判别器
; , .
用于区分非重叠的子图 层模块由反卷积 则用来区分是来自真实数据集还是生成器产生的分
;GAN
生成器和卷积判别器组成 ,用于特征学习 ;再生 子图 ,并引入基于 ORGAN[81]的强化学习来构建一
成层模块用于构建新的子图 汇集层模块用于整 个奖励网络 使用外部软件评估化学分子式的相关
; ,
合所有层的权重邻接矩阵 块识别模块用于缩减 属性 为了保持训练的稳定性 还使用小
; . ,MolGAN
边权重矩阵大小并将图划分成包含不同边的块 批量鉴别方式[82]防止模型崩溃 避免了基
.MolGAN
集合 文献 提出 模型 于似然的方法需要图匹配或启发式节点排序的过
. [75] Graph-GAN ,Graph-
同样由生成器和判别器构成 生成器用来 程 有助于寻找具有特定属性的化学分子式 其模型
GAN . , .
生成类似于真实存在的 具有边关系的节点 并 框架如图 所示
, , 4 .
用策略梯度进行优化 在生成器中使 但是 和 不能生成带有标
.Graph-GAN ,NetGAN MolGAN
用一 种 全 新 的 激 活 函 数 签节点的图 对于图大小也过于敏感导致扩展性不
———GraphSoftmax. ,
具备规范化 图形结构感知和高
佳 此外 仅仅只是为了得到最低的判别器损失 导
GraphSoftmax 、 . , ,
效计算三个要素 因此能高效地捕获图拓扑结构
, 致生成器产生的分子式以及某些网络图等结果很单
特征 判别器用来区分输入节点是从真实的连通
. 一 在涉及图数据样本多样性方面有较大的缺陷 容
性分布图中选取的 还是在生成器中产生的模拟 . ,
, 易发生模式坍塌 为了避免这种现
节点 构建了一个最大最小化的目标 (ModeCollapse).
.Graph-GAN 象 有时候不得不提前终止训练 针对此问题 文献
函数 使得生成器和判别器经过多轮迭代循环后 , . ,
,
提出标记图生成对抗网络
达到稳定的状态 [83] (Labeled-graph
.
尽管上述模型将 GAN扩展到了图上 ,并提出 GenerativeAdversarialNetwork,LGGAN).LG-
了相应的模拟图结构和生成图数据的模型 但是仍 的生成器可以为节点生成邻接矩阵和标签
, GAN ,
然存在一定的缺陷和不足 文献 对整个邻接矩 它的判别器则使用 等人[27]提出的 结构
. [74] Kipf GCN ,
阵的操作导致计算量庞大 尤其是在大图上时间缓 并加入残差连接 这样可以抽取自适应的 结构感知
, , 、 计 算 机 学 报 年
48 2022
图 生成化学分子图
4 MolGAN
的高级图特征来识别真实图 此外 探讨了 区域其他节点对于待分类样本的干扰 提高分类的
. ,LGGAN ,
三种不同的框架 分别是标准 [6] 准确性和扩展性 在 的输入预处理上
, GAN ,Conditional- . GraphSGAN ,
[84]和 [85] 使用了 先使用网络嵌入的方法生成节点的隐含嵌入表示 之
GAN AC-GAN .Conditional-GAN ,
图标签信息判断图真假 则在使用图标签 后与节点的原始特征向量拼接成一个完整的节点输
,AC-GAN
信息的基础上 让判别器区分真假的同时判断其类 入向量 在生成器上先利用数据的高斯噪声输出假样
, .
别 这样可以产生较多种类的图 在一定程度上避免 本 并在训练过程中使用批量规范化[53]和权重规范
. , ,
了生成器产生的图类别唯一 针对图生成网络需要 化 [87]技巧 全连接层中的参
. (WeightNormalization) ,
大量带有标签样本的不足 文献 提出一种仅需 数通过权重规范化来约束 另外在输入层和全连接层
, [86] .
要少量有标签图数据的半监督图生成网络 之后加入一个随机层 以达到平滑的目的
——— , .
核心思想是在数据图中 表 从模型 核心思想 图种类 学习模式 激活
GraphSGAN.GraphSGAN 4 、 、 、 、
不同子图的低密度区域生成假样本 这能减少这块 函数 数据以及任务对图生成网络模型进行了汇总
, 、 .
表4 图生成网络模型汇总
模型 文献 核心思想 图种类 学习模式 激活函数 数据 任务
/
期望传播
Softmax
[69] 高斯混合 同质无向 无监督 图聚类
Graphical-GAN GGN Tanh  27 28 29 30 31
状态空间
GGN Relu
更新
GRU 同质无向
文献[72] 蒙特卡罗近似
异质无向 -
Sigmoid
①②③
图生成
均匀随机排序 Softmax
[74] 拓扑插值 异质无向 无监督 图生成
GTI leakyReLU③④⑤⑥⑦⑧⑨⑩
节点分类
[75] 异质有向 Sigmoid 链接预测
Graph-GAN GraphSoftmax -  11 12 13 14 15
Softmax 兴趣推荐
有偏二阶随机游走
图生成
NetGAN[76]
Wasserstein GAN
异质无向
-
Softmax
 16 17 19 20 21 链接预测
规范共生矩阵 Tanh
强化学习 Sigmoid
MolGAN[79] ORG 小A 批N
量鉴别
异质无向
- Softmax  22 23
图生成
Tanh
残差连接
图生成
LGGAN[83] Conditional-GAN 异质无向
- -  17 18 24 25 图分类
AC-GAN
CT-GAN
节点分类
GraphSGAN[86] 假样本生成 异质无向 半监督
Softmax  17 18 26 实体抽取
①Cycles;②Trees;③BA;④ER;⑤WS;⑥Kronecker;⑦Facebook;⑧Wiki-vote;⑨RoadNet;⑩P2P-Gnutella; 11arX-
数据集 iv-AstroPh; 12arXiv-GrQc; 13BlogCatalog; 14Wikipedia; 15MovieLens; 16Cora-ML; 17Cora; 18Citeseer; 19Pubmed;
 20DBLP; 21POL.BLOGS; 22QM9; 23GDB-17; 24ENZYMES; 25PROTEINS; 26DIEL; 27MNIST; 28SVHN; 29CI-
FAR10; 30CelebA; 313DChairs 期 吴 博等 图神经网络前沿进展与应用
1 : 49
3.4 图循环网络 的节点并输出一个全局图 .针对问答任务 ,GGT-
寻找输入问题序列中的隐藏状态用来构造内部
图循环网络
NN
(GraphRecurrentNetwork,GRN)
图 并构建一维细胞自动机和具有四个不同状态的
是最早出现的一种 模型 相较于其他的 ,
GNN . GNN 图灵机来寻找问题中的潜在的规则 相较于
算法 通常将图数据转换为序列 在训练的过
. GGS-
程中序,G 列RN
会不断地递归演进和变化
,
模型一般
NN,GGT-NN在对话问答任务[92]上表现出更佳的
.GRN 性能 但缺点是时间复杂度和空间复杂度比较大 随
使用双向循环神经网络 . ,
(BidirectionalRNN,Bi-
着对话问题任务复杂性加深 所需计算资源增长程
和长短期记忆网络 ,
RNN ) 作为(L 网on 络g 架Sh 构ort-Term Mem- 度也会更加剧烈 等人[93]提出了一个深度自回
.You
oryNetwork,LSTM) . 归模型 在对图的结构进行最小假
文献 [9]将 RNN用于学习图的拓扑结构和节 设的情况—— 下—GraphRNN.
将多组有代表性的图转化
点分类问题 ,每个节点的状态向量取决于参数化的 ,GraphRNN
成序列并学习 近似地描述了图的任意分布
转移函数 .该转移函数以上一轮的节点状态 、节点标 构造,
了两个学习层级
运作在图层面的.
签 、邻居节点标签作为输入 ,再将得到的当前状态向 GraphRNN :
获取图的状态信息并生成新的节点 并使用宽
量和该节点标签整合得到依赖输出向量 对于有向 RNN ,
.
度优先搜索动态扩展节点 然后对节点排序 运作在
图 则是根据边的方向决定是否将邻居节点聚集给 , ;
,
边层面的 用来给新节点生成边 并且会严格
中心节点 .Scarselli等人[12]运用信息扩展的思想
, RNN ,
通过函数 τ(G ,n )∈Rm 将图G和某个节点n映射 限定新生成边的数量 ,避免形成稠密连通图 .为了定
量地评估 的性能 等人引入度分
到m维的向量空间上 .图的一个节点对应一个分析
GraphRNN ,You
布 聚类系数分布和最大平均值差异三个指标 用于
单元 通过多组单元处理对给定的图进行分析 这些
、 ,
, .
判断合成图的质量好坏
单元整合节点特征和邻居节点特征 相互间进行信
, .
息交互并更新各自的状态直到一个稳定点 最后根 结构化序列可以表示视频中的帧 传感器网络
, 、
据单元的不同状态决定是否激活输出 在参数估计 上的时空测量值 以及自然语言词汇图上随机游走
,
.
时 对网络权重的雅可比矩阵施加惩罚项 并使用 路径 针对这种图空间结构随时间变化的问题
, , . ,Seo
[88-89]算法训练模型 等人[94]提出一种能预测结构化序列数据的深度学
Almeida-Pineda .
文献 都是迭代地激活和计算节点状态 习模型 图卷积递归网络
[9,12] , ——— (GraphConvolutional
在传播函数上反复应用压缩映射使得节点状态最终 是标准
RecurrentNetwork,GCRN).GCRN RNN
趋向于稳定 文献 在 等人[12]前期工作 对任意图结构化序列数据的应用 模型由
. [90] Scarselli .GCRN
的基础上 提出门控图序列神经网络 [25]提出的 卷积算子和 组
, (GatedGraph Defferrar Chebyshev RNN
将 成 其中 卷积算子用于提取图节点特
SequenceNeuralNetwork,GGS-NN).GGS-NN , Chebyshev
优化技术加入 等人的模型中 通过编 征 用于识别空间结构和动态模式 等人
GRU Scarselli , ,RNN .Seo
码图序列特征 产生隐含表示向量 用节 研究了两种可能的 体系结构 一种是用叠加
, .GGS-NN GCRN ,
点注释初始化网络的隐层状态 图中不同的边决定 图卷积提取特征 提取到的特征输出给 进行
, , LSTM
节点信息发送的方向和内容 在信息传播后 节点根 序列学习 另一种是将 中的矩阵乘法换成了
. , ; RNN
据邻域的变化更新自己的状态 此外 设置了一个全 图卷积操作 完成序列学习 等人用两个实际问
. , , .Seo
局状态表示 该全局状态的聚合输出值取决于所有 题测试这两种结构 一是变化的 数据预测 二
, : Mnist ;
节点的状态 使用两种训练设置 一是在 是基于 数据集的自然语言建模 实
.GGS-NN : PennTreebank .
给定所有节点注解表示后训练 二是在只给定一个 验表明 同时利用图的空间信息和时间信息可以提
; ,
节点注解表示上进行端到端的训练 相对于 高任务学习的精度和速度 在实际应用中 图的拓扑
. LSTM . ,
等纯序列模型 模型具有良好的归纳偏差 结构和节点属性都会随着时间的推移而变化 即静
,GGS-NN ,
性质 在程序验证等人工智能推理的图任务上具有 态图会变成时空属性图 时间属性图中的节点分类
. .
灵活的学习能力和泛化能力 文献 提出门控图 问题有两个方面的挑战 一是很难有效地修改时空
. [91] .
变换神经网络 语境信息 二是由于时间维度和空间维度具有互相
(GatedGraphTransformerNeural .
在 基础上 纠缠的性质 为了学习一个目标节点的特征表示 区
Network,GGT-NN).GGT-NN GGS-NN , ,
添加新的节点状态更新函数 根据节点对的状态和 分不同邻域 不同时间段等各种因素的相对重要性
, 、
外部输入更新边属性 利用注意力机制来挑选不同 过于困难 因此文献 提出了一种时空注意递归
, . [95] 计 算 机 学 报 年
50 2022
网络 法对中间隐含向量的重要性进行分析 在真实数据
(Spatio-temporalAttentiveRecurrentNet- .
模型来解决上述问题 算法通 集上的大量实验证明了 模型对于时空图语
work,STAR) .STAR STAR
过采样和聚集局部邻居节点来提取邻域向量表示 义分析的有效性
, .
之后将邻域表示和节点属性输入到时空 中 表 从模型 核心思想 图种类 学习模式 激活
GRU , 5 、 、 、 、
学习图时空上下文信息 在此基础上 用时空注意算 函数 数据以及任务对图循环网络模型进行了汇总
. , 、 .
表5 图循环网络模型汇总
模型 文献 核心思想 图种类 学习模式 激活函数 数据 任务
/
图连通性
迭代激活节点
文献[9]
压缩映射
任意
- Sigmoid -
分类
图生成
子图匹配
迭代激活节点
文献[12]
压缩映射
任意 有监督
Sigmoid -
突变检测
网页排序
文本推理
门控递归单元
GGS-NN[90]
全局状态表示
有向
-
Sigmoid
-
最短路径
Softmax 欧拉环路
全局图
Sigmoid 文本推理
GGT-NN[91] 细胞自动机 有向 有监督
Softmax - 规则挖掘
图灵机
Tanh
序列学习
GraphRNN[93]
宽度优先搜索
异质无向
-
Sigmoid
①②③④⑤
图生成
Relu
同质无向 视频预测
GCRN[94] 图时空学习
异质无向 -
Sigmoid
⑥⑦⑧ 自然语言建模
Tanh
Softmax 节点分类
STAR[95] 时空
GRU
异质无向 有监督
Tanh ⑨⑩ 11 12 可视化
LeakyRelu
数据集 ①ER;②Grid;③BA;④Protein;⑤Ego;⑥Moving-Mnist;⑦Penn;⑧Treebank;⑨Brain;⑩Reddit; 11DBLP-5;
 12DBLP-3
3.5 图注意力网络 点的不同重要性 ,可以理解为空域上的结构信息 .该
方法的好处在于不需要预先知道图的拓扑结构 并
注意力机制可以让一个神经网络只关注任务学 ,
且可以并行地计算节点 邻居对 同时也避免了诸
习所需要的信息 它能够选择特定的输入[96] 在 - ,
, . 如求逆等代价高昂的矩阵运算 但是 矩阵乘
中引入注意力机制可以让神经网络关注对任
. GAT
GNN
法的操作仅限于二阶张量 在一些具有多个图的数
务更加相关的节点和边 提升训练的有效性和测试 ,
,
的精度 由此形成图注意力网络
据集中 这无疑会限制注意力网络层的批处理能力
, ,
, (GraphAttention
导致 的处理性能会受到影响 并且某些图的
Network,GAT). GPU .
邻域可能会高度重叠 在并行化过程中会增加额外
根据注意力机制的不同 可以分为自注意力 多
,
、 、
头注意力 层次注意力等 在自注意力使用上 文献 的计算成本
、 . , .
首次提出将自注意力机制应用至 在空间 此外 文献 在 基础上引入自注意力
[97] GNN. , [98] GAE
图卷积的基础上 该方法将屏蔽的自注意力层堆叠 机制 提出了一种无监督表示学习的图注意力自编
, ,
到空间图卷积的聚合函数中 注意力互相关系数的 码 器
. (Graph Attention Auto-encoder,GATE).
计算公式如下 在编码器和解码器层同时引入自注意力 重
: GATE ,
e =aWh Wh 新构建节点属性和图结构信息 在编码器中 将节点
ij ( i, j) (13) . ,
其中a 表示注意力计算函数 这里使用单层前向 属性作为节点的初始表达 每一层都使用注意力机
(·) , .
传播神经网络 W 代表权重矩阵 该公式表达了邻 制 根据邻域中节点之间的相关性来生成新的节点
, . ,
居节点j对节点i的重要程度 其隐式地为中心节 表示 在解码器中 则反转编码重建节点属性 解码
. . , .
点的邻居节点分配权重因子 具有不同度的节点会 器的每一层逆向操作都与编码器正向操作对应 此
, .
被指定不同的权重参数 这表示邻居节点对中心节 外 对节点表示进行了正则化以重构图结构 由于
. , . 期 吴 博等 图神经网络前沿进展与应用
1 : 51
框架中不需要预先知道图的结构 因此可以 会在标签节点和数据节点之间传递子结
GATE , MPGNN
应用于归纳学习 在基准数据集的节点分类 构消息 并且采用一种分层注意力机制来探究不同
.GATE ,
任务中表现优秀 对于直推式和归纳式任务都具有 子结构消息的重要性 该分层注意力机制使用中间
, .
较强的竞争力 等人[99]提出一种比较特 注意力因素 保
.Busbridge (IntermediateAttentionalFactors)
殊的关系型图注意力网络 存计算结果 作用于标签节点 使其可以抽取最相关
(RelationalGraphAtten- , ,
以关系型图卷积网络 的子结构来更新状态 该状态随后用来预测标签节
tionNetwork,RGAT), (Rela- ,
[100] 点最合适类别 在状态更新步骤中 节点状态更新公
tionalGraphConvolutionalNetwork,RGCN) . ,
为基础 将注意力机制扩展到关系型图域中 并发展 式为
, ,
成两种变体 :内部关系图注意力机制
(Within-Rela-
xt i=gu (xt i-
1
,mt
i) (14)
和交叉关系图注 其中xt是第t轮节点i的状态向量 mt是节点的消
tionGraphAttention,WIRGAT) i , i
意力机制 息向量gu 表示网络框架 这里 等人使用了
(Across-RelationGraphAttention,AR- . (·) , Do
GAT).WIRGAT和 ARGAT使用了附加注意力机
Highway
Network[105]用来获取数据之间的长距离
制和乘性注意力机制 用来聚集节点的邻 依赖特征 更方便地表达标签和输入子图在不同尺
.WIRGAT ,
居并使用注意力系数作用于节点聚合矩阵 度上的关系 使得 具有优良的表现 更重要
.AR- , GAML .
用来阐述不同节点表示上实现单个概率分布 的是 可以提供较为直观的可视化结果 这
GAT GAML ,
和关系的重要性 并将图局部先验知识进行编码 由 有助于了解不同标签子结构关系以及解释模型的内
, .
于在实际表现中 在归纳式图分类任务上产 在原理
,RGAT .
生了边际效应 因此 等人使用完全累积 在对图注意力网络模型进一步研究中 噪声干
, Busbridge ,
分布函数 扰会使得模式分析局限在图上一小块范围 针对此
(CumulativeDistributionFunction,CDF) .
搜索合适的超参数 并做了统计假设检验 问题 文献 提出图注意力模型
, . , [106] (GraphAtten-
多个独立注意力的计算可以作为一个集成的作 使用注意力机制引导的
tionModel,GAM).GAM
用 防止过拟合 同样地 为了更好地利用邻居节点 随机游走采样节点 强迫游走区域限定在任务相关
, . , ,
信息 等人[101]使用了多头注意力 区域 并忽视无用数据节点 从而捕获图结构中关键
,Zhang (Multi- , ,
[96] 提出一种门控注意 的区域连通信息 会动态选择有效的节点序
headAttentionMechanism) , .GAM
力网络 以子网 列 在不需要对整个图进行全局分析的情况下 其计
(GatedAttentionNetwork,GaAN), , ,
卷积的方式 构建 算复杂度和存储开销也大幅度缩短 此外 为了将基
, GGRU(GraphGatedRecurrent . ,
等人认为在应用多注意力机制的同 于注意力的 推广到更大规模 更加复杂并包
Unit).Zhang GNN ,
时 滥用注意力会在子空间内聚集不够重要的关系 含噪声的图中 等人[107]研究 中节点
, ,Knyazev GNN
信息给单个节点 最终导致预测准确率的降低 因此 之间的注意力机制以及影响其有效性的因素
, . .Kn-
设计了一个软门 控制多个注意力端 探 认为在一些分类任务中 注意力的引入可以
(SoftGate) , yazev ,
究不同注意力端在子空间内生成的节点特征对于网 使得模型的表现大幅度提升 但是在实践中达到最
.
络的重要性程度 从而构造了一种关键价值关注机 优效果却不是那么容易 往往需要有监督地进行注
, ,
制 在层次注意 意力学习 受到图同构网络
(Key-valueAttentionMechanism). . (GraphIsomorphism
力机制上 等人[102]提出一种多标签学习图注意 [108]和 等人[27]研究工作的启
,Do Network,GIN) Kipf
力模型 发 等人设计了 网络 并推出两
(GraphAttention ModelforMulti-Label ,Knyazev ChebyGIN ,
在多标签分类问题中 分类的准 个简洁的图推理任务用来验证图注意力的有效性
Learning,GAML). , .
确性和可解释性是一个难点 这与标签和子图的未 第一个任务是用不同的颜色标记图中的不同节点
, ,
发掘关系之间存在某种关联 因此 将所有 第二个任务是计数图中三角形的数量 在基本事实
. GAML .
标签视作一个个的节点 称为标签节点 普通图节点 受控的环境中进行上述两个任务 这能保证不受到
, . ,
称作数据节点 然后将标签节点与数据节点一起作 其他因素影响 从而探索注意力机制在神经网络中
, ,
为神经网络的输入端 之后 运用消息传递 的深层作用 在池化层中 设定了一个阈
. GAML . ,Knyazev
算法 [100,103-104]构建了 值 只有注意力系数大于给定阈值的节点才会被保
(MessagePassingAlgorithm) ,
留 尽管在舍弃节点时 图结构发生了改变 并且可
MPGNN(Message Passing Graph Neural Net- . , ,
在 更 新 每 个 节 点 的 局 部 结 构 过 程 中 能会出现孤立的点 但是在训练中 模型为相近的节
work). , . , 计 算 机 学 报 年
52 2022
点预测了相同的系数值 因此整个局部邻域都可以 最优 那么将会使得模型的准确率有较大的提升
, , .
被合并或者丢弃 在多个数据集上的测试表明 图分 表 从模型 基准网络 注意力机制 图种类 学
. , 6 、 、 、 、
类结果的准确性和注意力系数的初始化有很大关 习模式 激活函数 数据以及任务对图注意力网络模
、 、
系 特别是在无监督学习中 如果注意力系数初始即 型进行了汇总
. , .
表6 图注意力网络模型汇总
模型 文献 基准网络 注意力机制 图种类 学习模式 激活函数 数据 任务
/
文献[97] 自注意力 异质无向 有监督 Sigmoid 节点分类
GCN ①②③④
LeakyReLU
[98] 自注意力 异质无向 无监督 Sigmoid 节点分类
GATE GAE ①②③
Softmax
附加注意力 节点分类
RGAT[99]
GCN 乘性注意力
异质无向 半监督 Sigmoid
⑤⑥⑦ 图分类
LeakyReLu
[101] 多头注意力 异质无向 Sigmoid 节点分类
GaAN GCN - ④ 19
Softmax
多标签分类
GAML[102]
MPGNN
分层注意力 异质有向 有监督 Sigmoid
⑧⑨⑩ 11 图预测
Relu
注意力引导
GAM[106]
RNN 随机游走
无向有向 有监督
Softmax  14 15 16 17 18
图分类
[107] 标准注意力 异质无向 弱监督 图分类
ChebyGIN GCN Softmax  20 21 22 23 24 25
①Cora;②Citeseer;③Pubmed;④PPI;⑤AIFB;⑥MUTAG;⑦Tox21;⑧Media_mill;⑨Bookmarks;⑩Corel5k;
数据集
 11NUS-WIDE; 12TACRED; 13Semeval-10; 14HIV; 15NCI-1; 16NCI-33; 17NCI-83; 18NCI-123; 19Reddit;
 20Triangles; 21Mnist; 22Proteins; 23D&D; 24Collab; 25Colors
利用图标签等信息通过排序函数对邻居节点排序
,
4 与网络嵌入和图核方法联系比较 并用了一维卷积网络对排序后的节点进行卷积运
算 因此 对于图拓扑结构和节点属
. PATCHY-SAN
通过前文的归纳和分析 从总体上看 图神经网 性信息的捕获依赖于排序函数 只要排序函数不发
, , .
络可以分为五类 图卷积网络 图自编码器 图生成 生变化 就具有图上的平移不变
: 、 、 ,PATCHY-SAN
网络 图循环网络和图注意力网络 每种图神经网络 性 而在 中 它利用概率转移矩阵P 对每个
、 . . DCNN , t
都有自己对图结构数据处理的一套算法和体系 其 节点的邻居特征信息求加权和 P 为度规范化邻接
, ,t
中的原理和适用的范围也有一定差别 当然它们之 矩阵的幂矩阵 随着幂指数增加 远距离连接的节点
. . ,
间不是相互孤立和排斥的 例如文献 的图自 的权重值会逐渐变小 所以在 中 节点主要
, [59,65] . DCNN ,
编码器中包含图卷积层 文献 的图循环网络 获取的是图中近距离的拓扑结构和属性 越近的邻
, [91,95] ,
为了图序列学习更有效 也会加入注意力模块 而图 居节点对中心节点影响也越大 则是
, . .GraphSAGE
注意力网络也大多以其他图神经网络框架为基础 在中心节点的每一阶邻居节点中进行采样处理 对
, ,
构建合适的节点 边以及图注意力网络层 因此在实 于第k个网络层的节点向量v 其计算函数式可以
、 . ,
际操作当中 ,需要根据图的分布和特征信息 ,以及任 简写为h vk=σ (Wk ☉h vk- 1||f (hk u- 1 ,∀u ∈N (v ))).
务的实际需求 选择合适的图神经网络 来更加有效 其中 Nv 是节点v的随机采样邻居节点集合
, , () .
地学习图结构数据 表 是 机制 优点 缺点 f 代表聚合操作 代表向量拼接操作 是
. 7 GNN 、 、 、 (·) ,|| ,☉
适用范围及实现成本汇总表 向量内积 Wk 是网络层参数矩阵σ 为激活函
. , ,(·)
从总体上看 上述 的算法和框架都利用 数 没有直接使用邻接矩阵 而是使用
, GNN .GraphSAGE ,
到了图拓扑结构信息和节点属性信息 通过卷 邻居节点采样 因此某些邻居节点会被舍弃 所以它
.GCN , ,
积操作 将节点的特征聚合起来 达到信息传播的目 每一阶的邻居不一定是完整的 在谱分解图卷积中
, , . ,
的 空间图卷积和谱分解卷积分别从两个不同的角 从最开始的利用拉普拉斯矩阵特征向量做卷积运
.
度阐述了上述过程 空间图卷积把图看作图片 节点 算 经过 等人[25]和 等人[27]的发展
. , , Defferrar Kipf ,
当作图片中的像素点 节点属性值的个数相当于像 在使用切比雪夫多项式简化后 谱分解卷积具有了
, ,
素点通道个数 通过在节点上直接定义卷积操作来 局部连接性和参数共享性 运算复杂度也大为下降
. , .
对图进行卷积 在空间图卷积中 每一次图卷积的过程相当于将更高一阶的邻居特征
. ,PATCHY-SAN 期 吴 博等 图神经网络前沿进展与应用
1 : 53
聚集起来 使得节点的属性信息通过图拓扑连接结 构由近及远地传播到全图
, .
表7 GNN机制 优点 缺点 适用范围及实现成本
、 、 、
种类 机制 优点 缺点 适用范围 实现成本
GNN
拉普拉斯矩阵唯一
, 节点数目越多 图
拉普拉斯矩阵 已训练图结构不能应 固定的小规 ,
谱分解图卷积 参数共享 规模越大 训练成
特征分解 用于其他图 训练时 模图结构 ,
; 本越高
要将全图加载进内存
GCN
中心节点 感受域 聚
在图上直接卷积 定义空间 、 、 较大规模的 空间图卷积操作
空间图卷积 , 参数共享 合函数不确定 相互
近邻节点卷积权重共享操作 , 图结构 难度低 较易实现
制约依赖 ,
提取最具有代表性
编码器将图转为低维连续表 需要手动设置隐层维
图信息 缩减输入 小规模图结 取决于编码器对
示 解码器重构图的结构和 ; 度 多为无监督学习
GAE , 量 中间隐含表示可 ; , 构 原始图降维程度
属性 , 比有监督性能差
用于下游图任务
对噪声敏感 需要精
,
对图结构和属性具 确的图标签信息 图
交替生成节点和边 或者对 ; 领域相关的 取决于相关领域
, 有强大的模拟学习 质量检查要求专家级
GGN 抗训练生成完整图表示 图生成任务 的图复杂程度
能力 知识 可能发生模式
;
坍塌
将图转为序列 用 迭代压缩节点信息
, Bi-RNN、 , 具有时空特 不能并行化 实现
等循环神经网 能学习图在时间维 具有顺序依赖性 ,
GRN LSTM、GRU 征的图 成本较高
络训练 度上的特征
增加了额外计算邻居
引入注意力机制 关注对任
, 鲁棒性和可解释性 节点信息的时间和内 归纳式图任 可并行化 适用于
务有影响的邻居节点信息 ,
GAT , 更强 无需全图信息 存消耗 注意力的作 务 较大规模的图
从而分配不同的权重 ; ,
用跟网络初始化有关
的方法比较依赖于原始的邻接矩阵 一般 在 的损失函数中 一般只利用到节点标
GCN , GNN ,
节点间的连接权重就是节点的度或者边上的权值 签信息进行计算 但由于聚集操作的存在 预测标签
. . ,
但是在 中 则是利用注意力机制对图拓扑结 也包含了其他邻居节点标签信息 因此模型隐式地
GAT , ,
构和节点属性进行学习和整合 在 中 第k个 判断了对图拓扑结构信息的利用程度 除此之外
. GAT , . ,
网络层的中心节点v 其表达式可简写为hk = 和 还重构了图邻接矩阵 通过矩阵内积
, v GAE GGN ,
的方式显式地计算了模型对于图拓扑结构的掌握程
σ 点( u 的∑ ∈N 权(v)α 重vu 参W 数k -1h 由k u- 神1 ) 经.其 网中 络α 学vu 习为 得中 来心节 一点 般和 地邻 谱居节
分
度 .GAE和 GGN也具有一定的相似性 ,其中一部
, . , 分算法的目标不是生成固定具体的节点向量或者邻
解图卷积给中心节点v的邻居节点u分配的权重
接矩阵表示 而是生成它们的概率分布 因此模型具
, ,
αvu与节点的度 deg(v )有关 ,例如在 Kipf等人[27]的
有更好的拟合和生成数据的能力
.
不难看出 对图结构数据处理的有效性来
方法中 αvu = v1 u .而对于 GAT来说 , 源于对图拓扑, 结G 构NN 和节点属信息的利用程度 因此
deg()deg()
.
每个中心节点与邻居节点的权重 应该由神经网 中或多或少 或隐或显地构造了处理上述信息
αvu
GNN 、
络计算得出 这样可以使得与任务相关的节点获得 的聚集和融合函数 简称聚合函数或者聚合方式 在
. , .
更大的权重 让模型能够捕获更多关键信息 而在 谱分解图卷积中 拉普拉斯矩阵是连接图拓扑结构
, . ,
中 节点和图都被视作序列输入到 中 和节点属性信息的 桥梁 它将两种信息融合在一
GRN , RNN . “ ”,
从节点向量生成来看 每一步的输入包括上一步的 起 并通过参数学习获得节点嵌入向量表示 而在空
, , .
状态 中心节点 邻居节点和节点标签等 由于 间图卷积中 中心节点度量和感受域大小的确定为
、 、 . RNN ,
具有 遗忘 和 记忆 的功能 因此在每一步计算中会 聚合函数的输入对象和操作范围奠定基础 在
“ ” “ ” , .
隐式地保留或者舍去部分节点信息 最终生成的节点 中 作者提出了取平均值 取最大值和
, GraphSAGE , 、
向量反映了图的局部结构和属性 变换处理三种基础聚合方法 取得了良好的
. LSTM , 计 算 机 学 报 年
54 2022
效果 之后一些学者还从其他的角度发展了聚合函 输出通过拼接整合节点特征向量后作为 的输
. GNN
数 例如 的子图训练法 的符号边组 入 以期望获得更好的训练效果
, LGCL 、SGCN , .
合法等 进一步补充了对于图中信息的利用方式 在 图核方法被描述成定义在图结构空间上的半正
, .
中 为了在降维中减少信息损失 采用 定函数 该函数将图映射到希尔伯特空间 用支持向
GAE , ,DNGR , ,
了随机游走 概率共现矩阵等聚合方式 量机 等核函数在
、 .MGAE、 (SupportVectorMachine,SVM)
等没有直接构造聚合函数 而是 映射空间内进行标准分类处理[111] 是解决图分类
AutoGCN、VGAE , ,
直接使用 编码图节点 因此这些模型的聚合 问题的传统算法 针对标签图 权重图 有向图等不
GCN , . 、 、
函数与 相同 在 中 聚合方式多种多样 同类型的图结构存在不同的图核 主要有随机游走
GCN . GGN , . ,
将节点视作变量 用贝叶斯网络计 核[112] 限制大小子图[113]和基于子树模式[114]三种
Graphical-GAN , 、
算节点依赖结构 是一种隐式的聚合 文献 使用 代表性方法 图核方法易于训练 且具有可证明的理
, . [72] . ,
进行节点特征迭代聚集 这与 有些类 论保证 但核函数往往依赖于手工组合图特征 操作
GRU , GRN , ,
似 区别在于文献 用 聚集的节点表示是 复杂且耗时长 实际表达能力受到限制 其唯一任务
, [72] GRU , .
为了模型后续能够生成新的节点和边 除此之外 在于探寻相似图结构 用于不同图之间的匹配 是一
. , , ,
使用有偏随机游走构建节点序列 该聚合 种有效的图结构相似度量方式 相较于图核方法
NetGAN , . ,
方式除了能捕获局部图结构 也能捕获一定的全局 能将提取的图表示直接用于图分类 对于节
, GNN .
图结构 文献 先通过宽度优先搜索构建节点二 点 边 图等特征提取在 中全部由神经网络端
. [75] 、 、 GNN
叉树 再使用 分配节点间的权重 这 到端地自动完成 可以完成分类 预测 图生成等更
, GraphSoftmax , , 、 、
种聚合方式有利于给生成器产生有效的概率分布 广泛的任务和目标
, .
并具有结构感知以拟合正确的节点度分布 的 表 是 主要算法的实验数据 有
.GRN 8 GNN , Cora、
聚合操作来自于 网络信息前向传播过程的计 三个引文网络数据集 以及蛋白质
RNN Citeseer、Pubmed ,
算 从多个图序列来看 会留下有用的节点信 数据集 和知识图谱数据集 横向对比了节
. ,GRN PPI NELL.
息 对于无效的节点信息则选择 遗忘 在 点分类 图聚类 链接预测和节点聚类四个基准任务
, “ ”. GAT 、 、 .
中 聚合函数来自于各种各样的注意力机制 通过在 在节点分类任务中 谱分解 空间 和
, . , GCN、 GCN、GGN
节点 边上施加不同的注意力机制 聚合后的节点表 的典型算法的准确率都能保持在 以上 在
、 , GAT 61% .
示在质量上得到了一定的提升 在保持信息完整性 数据集上 相较于 [110] [25]
. Cora , DeepWalk ,Chebyshev
的前提下对任务相关的关键节点以及边给与更大的 模型提升了 文献 模型提升了 对比
14%; [33] 16.3%.
权重 模型的可解释性更强 其他网络嵌入算法 在 数据集
, . ,GNN Citeseer、Pubmed
除了 之外 网络嵌入和图核方法也是两 上提升也比较显著 这表明在图结构数据处理上 谱
GNN , . ,
种比较重要的图学习方法 网络嵌入的中心思想是 分解 空间 等 模型要明
. GCN、 GCN、GGN、GAT GNN
通过生成映射函数将网络中的每个节点转换为低维 显优于网络嵌入算法
.
度的隐含表示 所学习到的特征表示可以用作基于
,
图的各种任务[109] 传统的网络嵌入有矩阵分解 随 5 应 用
. 、
机游走和深度学习三种方法 网络嵌入的面向对象
.
主要是图中的节点 将其转为低维表达后 图结构信 由于 能较好地学习图结构数据的特征
, , GNN ,
息有了一定程度的压缩 由于为每个节点生成单独 因此在许多图相关的领域有着广泛的应用 若按照
. .
的嵌入表示 节点之间的参数不会得到共享 参数会 应用中图的层次结构划分 则大体可以分为节点 边
, , , 、
随着节点增长而增加 框架一般较为显示地提 和图层面 在节点层面 常见的有节点分类 节点聚
.GNN . , 、
取特征表示 多个节点特征在聚合后直接被输入 较 合 节点表示学习 在边层面 则有边分类 边聚类以
, , 、 . , 、
为完整地保留了图拓扑结构信息和内容属性信息 及链接预测 在图层面 图分类 图生成 子图划分
. . , 、 、 、
在 [110]中 算法利用随机游走为每个节点 图相似度分析等应用较为广泛 按照图的种类划分
DeepWalk , . ,
生成序列 类似于深度优先搜索为节点提取上下文 可以分为引文网络 社交网络 交通网络 图像 化合
, 、 、 、 、
信息 而在 中 邻居节点采样类似于宽度优先 物分子结构 蛋白质网络等 按照应用领域划分 可
. GNN , 、 . ,
搜索 聚集起来后在形式上相当于一个子图 在文献 以分为自然语言处理 图像处理 轨迹预测 物理化
, . 、 、 、
的图分析问题中 也不乏将网络嵌入的 学和药物医学等 为了方便说明和阐述 本文从
[66,76,86] , . , 期 吴 博等 图神经网络前沿进展与应用
1 : 55
的主要应用领域这一角度出发 对近年来出现 的 应用实例进行分类归纳
GNN , GNN .
表8 GNN主要算法在不同数据集上的任务分析
数据集
任务类型 模型 类别
Cora Citeseer Pubmed PPI NELL
[110]
DeepWalk 67.2% 43.2% 65.3% - 58.1%
[115] 网络嵌入
SemiEmb 59.0% 59.6% 71.1% - 26.7%
[116]
Planetoid 75.7% 64.7% 77.2% - 61.9%
文献[27]
81.5% 70.3% 79.0% - 66.0%
Chebyshev[25]
81.2% 69.8% 74.4% - - 谱分解
[26] GCN
CayleyNets 81.9% - - - -
节点分类
文献[33]
83.5% 72.6% 80.0% - 74.2%
[44] 空间
GraphSAGE - - - 61.2% - GCN
文献[46] 空间
82.0% 70.9% 78.7% 97.8% 64.9% GCN
[49]
LGCL 83.3% 73.0% 79.5% 77.2% -
[86]
GraphSGAN 83.0% 73.1% - - - GGN
文献[97]
83.0% 72.5% 79% 97.3% -
[101]
GaAN - - - 98.7% - GAT
[98]
GATE 83.2% 71.8% 80.9% - -
图聚类 [55]
MGAE 68.1% 66.9% - - - GAE
[74]
链接预测
NetGAN 68.5% - - - - GGN
RWR-GAE& R-G 92.7% 91.5% 96.3% - -
RWR-VGAE
[66]
R-V 92.5% 92.4% 95.2% - -
GAE
节点聚类 RWR-GAE& R-G 66.9% 61.6% 72.6% - -
RWR-VGAE
[66]
R-V 68.5% 61.3% 73.6% - -
GAE
5.1 图神经网络与自然语言处理 关系抽取是自然语言处理中另外一个重要的子
领域 目的是从文本中识别实体并抽取实体之间的
在自然语言处理中 较为常见的任务有词嵌入 ,
, 、
语义关系 从而支持问答 搜索 推理等上层应用 在
实体和关系抽取 阅读理解 对话问答等 在许多情 , 、 、 .
、 、 . 传统方法中 依赖树具有丰富的结构化信息 因此通
境下 文本中的单词和句子一般可以用向量或者序 , ,
,
常会利用依赖树进行关系抽取 但是基于规则的硬
列来表示 但是信息的表达在一定程度上被压缩 面
, . 剪枝策略无法很好地选出语句依. 赖结构中的关键信
对更加复杂的文本理解和阅读问题 这种嵌入表示
,
息 并忽略依赖树中的无关信息 针对此问题 文献
无法在解释性和准确率之间达到平衡 通过对输入
, . ,
.
提出注意力引导的图卷积网络
文本中的元素重构为节点 边以及图表达 可
、 ,GNN
[118] (Attention
以构造各种语义图或者依赖图 在此基础上可以进
,
GuidedGraphConvolutionalNetwork,AGGCN).
由多个相同的块组成 每个块分成注意力
行更加有效的模式分析和推理
AGGCN ,
.
引导图卷积层 密集连接层和线性联合层 在输入神
词嵌入是自然语言处理的基础部分 词向量的
, 、 .
好坏直接影响了诸如情感分析 句法分析等下游任 经网络前 将原始依赖树转变为全连接的带权图 权
、 , ,
务的精准度 目前大部分基于神经网络的词嵌入工 重表示句子中单词之间的关系影响因子 每个块自
. .
作都是利用的词的顺序上下文 但是会忽略句子的 动学习相关的子结构 对于关系抽取任务来说 该模
, . ,
语法特征 而少部分利用词句法上下文的模型会导 型可以理解为一种软修剪的方法 在大规模跨句多
. .
致词汇量的爆炸式增长 针对此问题 文献 提 元关系抽取中的实验结果表明 能够更好
. , [117] ,AGGCN
出基于 的词嵌入生成模型 该模型分为两个 地利用依赖树的信息 提升关系抽取的准确率 另
GCN . , .
部分 和 在不增加词汇表大小 外 文献 提出了一种学习命名实体和关系抽取
,SynGCN SemGCN. , [119]
的情况下 将单词的上下文语法依赖信息 的模型 的关系抽取分为两个
,SynGCN GraphRel.GraphRel
添加进词嵌入中 框架则用于整合诸如同 阶段 在第一阶段 堆叠多个 句
.SemGCN . ,GraphRel Bi-LSTM
义 反义等不同的语义知识 用来增强所学习的词嵌 子编码器和 依赖树编码器 自动抽取句子和
、 , GCN ,
入表示 由于 同时整合单词的语法和语义知 词汇特征 标记实体中的单词并对关系三元组进行
. GCN ,
识 因此产出的词向量具有较高的质量 在词语相似 预测 第二阶段 考虑关系三元组之间的相互作用
, , . , ,
度 概念分类和词语类比三个任务上均达到最优 加入关系加权 在实体损失和关系损
、 . Graphrel GCN, 计 算 机 学 报 年
56 2022
失的双重约束下 沿着依赖链提取实体节点隐藏特 由于社交网络中存在大量的用户关系
, sentation). 、
征 同时建立一个新的具有关系加权边的全连通图 用户身份以及个人观点等信息 因此可以将文本 用
. . , 、
第二阶段的 有效地考虑了实体和关系之间的 户的社交活动以及用户之间的关系构建一个图 用
GCN ,
相互作用 其中的线性结构和依赖结构都用来提取 学习它们的表示 等人捕获了新闻事件中
, GCN .Li
文本的序列特征和区域特征 极大地提高了对重叠 媒体的政治视角 强调了将新闻文本置于情景化社
, .
关系的区分能力 由于 一般只能在预先给定 交网络的重要性 揭示了这些信息如何在社交网络
. GNN ,
的图上对关系进行抽取 这无疑限制了关系推理的 中传播
, .
深度 针对此问题 文献 提出了一种基于生成 在对话问答任务中 推理能力 可解释性和扩展
. , [120] , 、
参数的图神经网络关系抽取 性是对话问答系统面临的主要挑战 在基于
———GP-GNN.GP- . GNN
首先构建了基于文本序列输入的全连接层 用 的对话问答建模上 文献 提出 级文档多
GNN , , [124] web
来接收文本数据 之后构建了三个不同层面的模块 跳认知图 模型 为了
. : (CognitiveGraphQA,CogQA) .
能够对语句中的信息进行编码的边模块 节点关系 在给出问题答案的同时提供可解释的推理路径 该
、 ,
传播模块和使用节点表示进行预测的分类模块 通 框架以认知科学的对偶理论为基础 通过协调隐式
. ,
过对文本的编码 使得图神经网络能够从自然语言 实体抽取模块和显式语义推理模块 在迭代过程中
, ,
建模图中学习有用的参数 并进行多跳关系推理 从 逐步构建认知图 其中推理模块的功能是用
, , . GNN
而提取文本中更加复杂的关系 构建的 它的功能是抽取问题中的相关实体 并对语
, ,
.
阅读理解一直是文本分析中一项重要而富有挑 义信息进行编码 生成隐含特征表示 然后生成推理
, ,
战性的任务 文档中的实体 句子之间的复杂关系 证据路径 使得对话系统提供的答案更具有说服力
, 、 , , .
以及跨文档之间的联系无疑给机器理解文本带来很 5.2 图神经网络在物理化学和药物医学中的应用
大的困扰 在此问题上 等人[121]引入了具有不
在物理化学以及药物医学三个自然科学领域
. ,Tu
同类型节点和边的异构图 提出异构文档 实体图 中 原子 分子 药物化合物等实体数据都可以在逻
, - , 、 、
模 型 辑上被表示成图结构 由于一些分子化合物和药物
(Heterogeneous Document-Entity Graph, .
用于解决跨文档的多跳阅读理解 等有机体是异构非线性的 数据中存在大量的噪声
HDE-graph) . , .
包含了实体 上下文候选信息 文档等 在标签稀缺的情况下 将相关信息集成起来学习是
HDE-graph 、 、 ,
不同粒度级别的信息 等人用编码器对 一个挑战 如果能够对这些数据进行建模和分析 则
.Tu HDE- . ,
节点初始化 并使用了共同注意力机制和自 可以缩短研究人员探测原子结构 化学键属性 药物
graph , 、 、
注意力机制 的优点在于能不断地对文 靶分子结合机理等任务的时间 为其潜在的属性和
.HDE-graph ,
本中的证据积累 形成的证据链可以用来在多个文 分布提供一定的参考和支持
,
.
档中推理 ,从而得到问题的最终答案 .在维基文章上
Duvenaud
等人[125]用 GCN对分子指纹信息采
的对比测试表明 具有最高的准确率 文 集 设计了一种数据驱动的端到端预测模型 其中的
HDE-graph . , .
献 提出动态融合图网络 输入是任意分子的图结构 等人定义了分
[122] (DynamicallyFused
.Duvenaud
模型 将 应用在跨文 子指纹相似性度量的方法 每一层网络用哈希函数
GraphNetwork,DFGN) , GNN ,
档的阅读理解中 包含一个动态融合层 它 整合原子和原子邻居结构信息 用索引将所有节点
.DFGN , ,
会从给定查询中提到的实体开始 沿着实体链不断 特征转变成固定长度的分子指纹向量 等
, .Duvenaud
进行实体搜索 在此过程中 会构建动态文本实体 人的贡献在于将计算分子指纹向量的神经网络层替
. ,
图 并逐步从给定文档中找到支持答案的相关联实 换为可微神经网络 进而可以循环提取分子指纹特
, ,
体 在公共数据集上的评估表明 能够产生 征 忽略分子结构中非重要变化 等人的
. ,DFGN , .Duvenaud
具有可解释的推理链 除了较为常规的通用文本外 方法侧重于减少分子非结构性改变对分子指纹的影
. ,
一些特殊领域的文本还需要更加有针对性的分析和 响 而文献 希望更多地利用到原子属性信息
, [126] ,
处理 例如在新闻文本中 很多具有倾向性的观点等 因此描述了一种分子图卷积方法 通过对分子图中
. , .
信息都被隐藏在词汇和语句中 因此发掘作者的观 原子 化学键 原子间和分子间距离等项目简单编
, 、 、
点是一件比较困难的事情 针对此问题 等人[123] 码 自顶向下的提取原子特征和分子级特征 在每个
. ,Li , .
把新闻文章和社交圈嵌入到同一个空间 构建社交 网络层中对相同的原子施以相同的操作 以保持排
, ,
融合的文本表示 列不变性 在分子级特征抽取前 再对原子做一次卷
(Socially-infusedTextualRepre- . , 期 吴 博等 图神经网络前沿进展与应用
1 : 57
积来扩展深度 使得原子特征向量的每个维度包含 此外 药物相似性测量是现代生物医学的基础
, ,
的信息更多 让分子级特征化过程中丢失的信息更 任务之一 药物相似性研究可以支持很多下游的临
, ,
少 更好地利用分子图的属性信息 在分子属性信息 床任务 一方面 开发药物与现有药物之间相似性代
, . . ,
的进一步探究中 文献 提出消息传递神经网络 表了一种隐含关系 有时候需要从旧药物已知特性
, [104] ,
用于化 推断新药物的新特性 另一方面 新型药物的新特征
(MessagePassingNeuralNetwork,MPNN) . ,
学分子式的属性预测 将之前用来学习化学 给药物相似性学习带来全面性和准确性的挑战 面
.MPNN .
分子式的多个 GNN[90,125-126]整合进一个框架中 ,着 对精确的药物相似性度量问题 ,Ma等人[129]提出了
重解决两个评估基准问题 量子力学模拟的平均 一种多视图的 建模方式 该方式将每种药物
——— GAE .
错误率和化学精度 的信息函数定义了矩阵 都建模为药物关联网络中的一个节点 并扩展了
.MPNN ,
乘法 边特征编码网络和成对消息传递机制 来嵌入多视图节点特征和图边缘特征 在药物
、 .MP- GCN .
将单个节点向量转变为多个分向量 并对每个 节点学习中添加注意力机制 确定每个视图中相关
NN , ,
分向量进行信息前向传播来得到临时的嵌入表达 任务和特征的权重 保证对数据变化的动态适应
, , .
以提高 对于化学分子式属性学习的可扩展 等人将未知标签视作无特征的隐含变量 构造
MPNN Ma ,
性 此外 前文提到的 [79]也是生成化学分 了半监督和无监督两种学习方式 实验结果表明该
. , MolGAN .
子式的有效模型 与 区别在于其 方法有较好的药物预测精度 在药物节点嵌入特征
,
.MolGAN MPNN
利用生成对抗网络 模拟的是化学分子式的先验分 上具有较强的可解释性
, .
布 属于隐式学习 则利用了多种 来 5.3 图神经网络与图像处理
, .MPNN GNN
对化学键信息进行传播 属于显式学习
图像处理是计算机应用领域的一个热门方向
, . ,
在药物发现的早期阶段 预测药物分子对靶点
得益于强大的 计算能力和数据的张量表示形
,
GPU
的药效以及结合亲和力可以用两种方法 一种是基 式 基于深度学习的模型和方法能高效地进行图像
. ,
于分子力场的经验评分函数 一种是基于化学信息 处理 尽管 在图像分类等问题上达到较高的
,
. CNN
描述符的分子对接技术 但是这需要专家级知识来 精度 但面对更加复杂的语义分割 图像问答等任
. , 、
对药物进行编码 需要人工调整某些参数和特征 耗 务 还有一些不足和缺陷 针对这些问题 图神
, , ,CNN . ,
时耗力 针对此问题 文献 开发了一个通用的 经网络可以融合多种异质内容和结构信息 构建相
. , [127] ,
三维空间图卷积运算 直接用图卷积网络学习原子 应的知识图和对象图等 利用额外的信息来指导具
, ,
级蛋白质化学作用 称作原子卷积神经网络 体任务的进行
, (Atom-
.
文献 根据人体关节和骨骼之间的运动相
icConvolutionalNeuralNetwork,ACNN).ACNN [130]
首先学习了结合态的晶体结构 通过计算配体和蛋 关性 将骨骼数据表示为有向无环图 从而对图像中
, , ,
白质相关联的能量来给出结合亲和力的数值 的动作进行识别 该模型设计了一种新的有向
.AC- .
优点在于能识别蛋白质配体亚结构中缺失复合 用于提取关节 骨骼及其相互关系的信息 并
NN GNN, 、 ,
物的非共价相互作用 与以往蛋白质配体预测系统 根据提取的特征预测动作类别 为了更好地适应动
. .
不同 是端到端且完全可微的 代表了基于 作识别任务 在训练过程上对图的拓扑结构进行了
,ACNN , ,
数据驱动和物理结构探测的深度学习新范例 为基 自适应调整 在
, . TSCN(Two-streamConvolutional
于结构的药物活性预测提供了坚实的基础 而在药 [131]框架下 将骨架序列的运动信息与空
. Network) ,
物临床应用中 模拟生成的药物分子图必须能被现 间信息相结合地学习 进一步提高了模型的性能
, , .
有的化学理论分析 并与相关的病理研究相匹配 所 在图像问答上 传统方法仅仅基于图像内容来
, , ,
以模型必须要同时保证精确性和可解释性 基于此 做出相关的回答 缺乏必要的知识使得模型可能会
. ,
目的 文献 利用 对小分子药物操作 其 答非所问 针对此问题 文献 开发了一个实体
, [128] GCN , . , [132]
步骤包括节点特征提取 邻居节点聚合 图池化和图 图 把所有实体用 攘括进来 这样在问题检索
、 、 , GCN .
聚集 最终生成单个小分子的向量表达 之后结合残 中 可以避免对单个事实的依赖 在给定图像和问题
, . , .
差 网络对小分子向量进行训练 对小分子向 后 通过它们之间的相似度评分将对应的事实抽取
LSTM , ,
量之间相似距离进行度量 有效地预测小分子药物 出来 在推理正确答案时 该模型可以从候选答案列
, . ,
的活性 并与现有的临床医学病理特征建立密切的 表中综合选择最相符的答案 此外 通过对全局词向
, . ,
联系 量进行排序 选择知识库中支持事实的列表 以消除
. , , 计 算 机 学 报 年
58 2022
同义词和同形词带来的混淆影响 空间依赖关系 文献 提出了一种动态时空图卷
. , [137]
在图像语义分割中 传统的语义分割方法主要 积网络
, (DynamicGraphConvolutionalNeuralNet-
在二维平面进行处理 文献 提出了一种在三维 用于精确的交通预测 为了能够降
. [133] work,DGCNN) .
点云上建立k近邻图的三维图神经网络 低复杂度并进行实时学习 在网络框架中
(3DGraph ,DGCNN
图中的每个节点对应于 构造并预训练了张量分解层 将交通数据张量分解
NeuralNetwork,3DGNN). ,
点云中的一组点集合 与物体外观特征初始化表示 成低阶张量和稀疏张量 其中低阶张量对应稳定的
, .
向量相关联 其中物体外观特征由 从二维图 全局张量 稀疏张量对应可变的局部张量 全局张量
, CNN , .
像中提取 点云中的每个节点都有一个递归函数 该 反映道路交通中长期的时空关系网络 局部张量用
. , ,
函数会根据当前状态和邻居消息动态更新节点的隐 来捕获交通流量的日常波动和起伏 使用
.DGCNN
含表示 最终每个节点都能用来预测图像中每个像 动态图估计器来学习全局张量和局部张量的拉普拉
,
素的语义类 此外 文献 认为三维点云可以通 斯矩阵 相较于 能够随时捕捉到
. , [134] . STGCN,DGCNN
过一种超点图的结构有效地捕获 用 生成了 交通流量中一些细微因素变化的影响 因此在训练
, GCN ,
包含上下文关系的对象部件表示 解决了海量点云 误差和测试误差上都要更低一些 针对交通流中存
, .
语义分割的难题 在瞬时高峰和事故发生突然性等问题 文献 将
. , [138]
在图像分类中 传统的研究思路是只要有足够 道路传感器视作节点 用传感器之间的相近度作为
, ,
多的数据样本 那么就可以用大量的样本来训练模 边 从而构造一个有向图 通过扩散卷积运算来捕捉
, , .
型 达到非常高的准确率 但是在实际情况中 不一 空间相关性 构建了扩散卷积循环网络
, . , , (Diffusion
定有足够多的数据给模型来训练 因而催生了小样
, ConvolutionalRecurrentNeuralNetwork,DCRNN).
本学习 同样地 图神经网络可以被应用至小样本学 在图上进行双向随机游走来捕获空间依赖
. , DCRNN
习中 针对样本类别标签不足的问题 等 性 运用序列到序列的学习框架 并使用具有定时采
. ,Garcia , ,
人[135]将小样本学习作为一种有监督的消息传递任 样的图编码器 解码器架构来捕获时间依赖性
- .
务 利用 进行端到端的训练 等人将节 另外 针对道路行人轨迹预测和追踪
, GNN .Garcia , ,Kosaraju
点与数据集合中的图像相关联 用相似度函数来生 等人[139]提出了一种使用 结构的
, GAT Social-BiG-
成边 在经过 训练后对图像进行分类 此外 模型 中构建了一个具有对抗性
, GCN . AT .Social-BiGAT
等人还将该模型框架扩展到半监督学习和主 的递归图编码器 解码器体系结构 等人
Garcia - .Kosaraju
动学习上 并取得了良好的效果 使用了 [140]作为编码器训练框架 模拟
, . Bicycle-GAN ,
5.4 图神经网络在交通流量和轨迹预测中的应用 不同场景下行人的社会交互行为 通过对场景图中
.
人物之间的互动信息进行编码 得到行人的未来路
交通问题是现代城市的热点民生问题 及时准 ,
,
径预测结果 其中每一个场景与其潜在噪声向量之
确的交通预测对于城市道路交通的控制和引导至关
.
间形成可逆变换 明确解释行人轨迹预测问题的多
重要 特别是车辆速度 交通量和道路密度等统计量 ,
. 、 模态性质 提高了人物多模态轨迹预测精度
需要有较为精确估计 这对于城市交通网络中的路 , .
,
线规划和流量控制具有重要意义 由于交通流具有 5.5 其 他
.
高度的非线性和复杂性特点 传统机器学习方法难 除了上述应用外 还在诸如知识图谱与知
, ,GNN
以学习空间和时间的依赖关系 不能满足中长期交 识库 信息检索 动态网络异常检测 医保欺诈分析
, 、 、 、 、
通流预测任务的要求 针对此问题 文献 提出 网络图分析等其他领域发挥重要的作用
. , [136] .
一种时空图卷积网络 在知识图谱上 等人[141]在知识图谱中使
(Spatio-TemporalGraphCon- ,Wang
用于解决交通领域 用 完成实体对齐任务 等人将每种语言
volutionalNetwork,STGCN), GCN .Wang
的时间序列预测问题 不同于使用反复卷积和递归 的实体用 嵌入到一个统一的向量空间中 从
. GCN ,
单元 构造和堆叠了多个时空图卷积模块 实体的结构信息和属性信息中学习等价关系 此外
,STGCN , . ,
用来抽取和融合时空特征 这种多尺度可扩展网络 文献 将 应用于知识库外实体知识转移
. [142] GNN .
建模的方式 让 能够学习到交通数据中较 在传播阶段 通过邻居节点聚合和池化操作得到知
, STGCN ,
为全面的时空相关性特征 此外 交通中的空间依赖 识库外实体的嵌入 在输出阶段 在节点向量上定义
. , . ,
关系会随着时间的推移而改变 而固定的拉普拉斯 了面向任务的目标函数 使用 [143]作为预期
, , TransE
矩阵无法捕捉这种变化 为了跟踪交通数据之间的 输出模型 该模型的优势在于仅利用测试时提供的
. . 期 吴 博等 图神经网络前沿进展与应用
1 : 59
有限辅助知识 不需要复杂的再训练 在信息检索 分类医保欺诈检测模型 框
, . -OCGVAE.OCGVAE
中 文献 提出特征交互图神经网络 架由 和标准偏差向量三个模块组成
, [144] (Feature GCN、VAE .
用于 提取病人就诊记录构建了医生和病人之间的有
InteractionGraphNeuralNetwork,Fi-GNN) Yi
点击率预测 中的节点对应不同领域特征 权图 用 提取医生 患者关系网络节点特
.Fi-GNN , . GCN -
边对应特征之间的交互影响 利用图的强 征 其中的隐藏层设计了参数共享结构 用来降低
.Fi-GNN , ,
表征性 灵活 明确地对复杂的用户特征交互进行建 医患网络的数据维度 实验结果表明
, 、 . ,OCGVAE
模 为点击率预测提供良好的模型解释 在推荐系统 模型对于医保欺诈标签的预测准确率达到
, . 87%,
上 文献 把用户 推荐项关系转变为图表达 大幅度优于传统算法 有效地提高了医保欺诈筛
, [145] - , ,
用 从用户和项目中学习有意义的统计图模 查精度 在网络图分析中 等人[148]将
GCN . ,Zhang GCN
式 并用 将参数扩散应用于评分矩阵 完成对 用于现实网络的链接预测 提出 衰减理论 将大
, RNN , , γ ,
推荐系统矩阵的补全 在关于动态网络异常检测方 量启发式策略整合进一个框架之中 并且证明了
. ,
面 文献 提出一种面向动态网络的无监督学习 这些启发式策略近似等价于局部子图模式 然后
, [146] .
算法 框架分为四个部 使用 从局部子图中学习 并进行链接预测
Dynamic-DGI.Dynamic-DGI GCN , .
分 分别是图神经网络 用来对图结构和属性特征提 文献 对 性能进行理论分析 重点探讨
, , [149] GNN ,
取 动态网络表示学习 图时间变化特征提取 流数 了 框架结构和参数优化对图数据分析的有
; ; ; GNN
据异常检测 其中图神经网络使用 等人[27]的 效性 提出了最小 结构的平均场理论用于解
. Kipf , GNN
卷积核对图节点特征提取和聚合 为了将边信息直 决图分割问题
. .
接考虑进来 把原始图转为线图 再 可以看出来 在科学和生活的多个领域 凡是能
,Dynamic-DGI , , ,
次用 等人[27]的卷积核对线图进行边信息提 将数据表示成图结构的 都能用图神经网络来进行
Kipf ,
取 同时将原图和线图提取的特征进行拼接整合 作 学习 通过对图结构信息以及图属性信息的有效捕
, , .
为图节点和边的隐含向量表示 优点 捉 图神经网络在各种图任务上达到了较高的精度
.Dynamic-DGI , ,
在于能学习到图结构和属性的双重变化 捕捉到图 成为解决图相关问题的有效手段 因此在不同的领
, ,
动态变化中的异常部分 在医保欺诈分析中 等 域都有着良好的应用前景 表 是 主要应用
. ,Yi . 9 GNN
人[147]提出了一种基于图卷积和变分自编码的单 领域实例列表
.
表9 GNN主要应用领域实例列表
应用领域 种类 模型框架 输入端 任务 文献
GNN
语法嵌入 语义嵌入
SynGCN; 词汇图 词嵌入 文献[117]
GCN
SemGCN
注意力引导图卷积层 密集连接网
GCN 络层
线性联合网络层; 句子依赖树 关系抽取 AGGCN[118]
;
句子编码器 依赖
GCN
B 树i- 编LS 码T 器M
关系加权
;GCN 句子依赖树 命名实体识别 ;关系抽取 GraphRel[119]
; GCN
文本接受全连接模块 边信息编码
;
GRN
模块 ;节点关系传播模块 ;节点预 实体完全连通图 关系推理 GP-GNN[120]
测分类模块
自然语言处理
文本编码模块 异构文档图推理模
GCN 块
累计评分模;
块
异构文档实体图 阅读理解 HDE-graph[121]
;
段落选择模块 文本查询编码模
GAT 块
推理融合模;
块 答案预测模块
实体图 阅读理解 DFGN[122]
; ;
文本表示与语言偏误纠正 信息网
GCN 络图卷积学习
文本分类与;
推理
信息流图 新闻政治观点抽取 文献[123]
;
隐式实体抽取模块 显式语义推理
GCN 模块
; 认知图 对话问答 CogQA[124] 计 算 机 学 报 年
60 2022
续表
应用领域 种类 模型框架 输入端 任务 文献
GNN
原子信息哈希整合 特征索引固
GCN 定
邻居原子规范化; 分子图 分子指纹采集 文献[125]
;
编码层 原子卷积层 分子特征抽
GCN 取层
; ; 分子图 分子指纹提取 文献[126]
GCN 化学键信息传播 分子图 分子属性预测 [104]
MPNN
GRN
物理化学和药物医学
GGN
ORGAN强化学习 ;小批量鉴别 分子图 化学分子生成 MolGAN[79]
距离矩阵与邻域列表构造 原子卷
GCN 积层 径向池化层
; 蛋白质图 预测蛋白质配体 ACNN[127]
;
节点特征提取 邻居节点聚合 图
GCN 池化 图聚集
; ; 药物分子 药物活性预测 文献[128]
;
药物特征图卷积提取 半监督图自
GAE
编码器标签预测
; 药物分子图 药物相似性预测 文献[129]
GCN
人体骨骼图构建 关节 骨骼关系
GCN 提取
时空序列建;
模
、 骨骼图 人体动作预测 文献[130]
;
问题事实获取 实体关系预测 图
; ;
GCN
像实体嵌入 ;问题与图像信息提 图片和问题图 图像问答 文献[132]
取 答案预测
;
图像处理 三维图构造 像素特征提取 标签
GRN 预测
; ; 三维点云 语义分割 3DGNN[133]
点云几何分割 超点图构建 超点
GCN
与超边信息提取;
标签预测
; 三维点云 语义分割 文献[134]
;
图片上下文映射 初始节点特征构
GCN 造
标签分布学习; 图片 图像分类 文献[135]
;
GRN 时空图卷积模块 交通流图 交通流预测 [136]
STGCN
GCN
动态拉普拉斯矩阵估计 张量分解
GCN
层 时间特征抽取
空间特;
征抽取
交通流图 交通流预测 DGCNN[137]
GRN ; ;
交通流量和轨迹预测 扩散图卷积特征抽取 图自编码器
GRN
时间信息捕获
; 道路图 交通流预测 DCRNN[138]
GAE
提取社交物理特征 局部行
GAT ;
GAT
人场景识别 ;全局场景识别 ;场景 场景轨迹图 行人轨迹追踪 Social-BiGAT[139]
噪声编码器
GCN
图卷积实体嵌入 ;实体对齐预测 知识图谱 实体对齐 文献[141]
知识图谱与知识库 知识图谱信息传播模块 目标分数
GRN 评估模块
; 知识图谱 知识库推理 文献[142]
领域特征图构建 特征交互建模
信息检索
GRN
注意力传播模块; ; 领域特征图 点击率预测
Fi-GNN
[144]
图特征提取模块 基于 的矩
推荐系统
GCN 阵扩散模块
; RNN 用户 -推荐项关系图 推荐系统矩阵补全 文献[145]
图神经网络层 动态网络表示学
、
动态网络异常检测
GCN
习 、图时间变化特征提取模块 、流 动态网络图 异常图检测 Dynamic-DGI[146]
数据异常检测模块
医保欺诈分析
GCN
GCN、VAE、标准偏差向量 医患关系网络 医保欺诈标签预测 OCGVAE[147]
网络图分析 GCN
节点隐式嵌入 ;有监督启发式学习 网络图 链接预测 文献[148]
GCN
图信息随机块 ;动态平均场图分割 网络图 图分割 文献[149]
实践上都被证实是对图结构数据处理的一种有效方
6 未来研究方向 法和框架 尽管 在各个领域的图数据上取得
. GNN
了不俗的表现和较好的普适性 但是 仍然存
, GNN
的核心在于规范化表示的图结构数据并 在一定的不足和需要完善的地方 根据目前国内外
GNN .
用深度神经网络进行学习 经过近些年的不断发展 的研究现状 下面本文对 的一些制约因素和
. , , GNN
通过大量数学证明和实验分析后 在理论上和 未来发展方向进行探讨
,GNN . 期 吴 博等 图神经网络前沿进展与应用
1 : 61
6.1 网络深度 这可能会超过存储空间的上限 .此外 ,一些节点可能
只有一个邻居 而另外节点可能有多达数千个邻居
在计算机视觉 自然语言处理和音频处理中 神 , .
、 ,
邻居节点分布不均衡使得每个中心节点的感受域大
经网络的层数可以叠加多层 在一定范围内 神经网
. , 小不一致 尽管可以通过添加 哑结点 和删除邻居
络层数的增加可以更好地提取数据中的特征信息 . “ ”
. 节点的方式保持数据大小和维度的一致 但是在特
例如深层残差网络 [150]可以达到 层 但 ,
ResNet 152 . 征的聚集和融合中不可避免的会有信息损失现象发
是 的邻居节点聚合中 随着网络层数的增加
GNN , , 生 而现有的采样方法还不能完全解决该问题
邻居节点的阶数会不断扩张 导致中心节点聚合特 , .
,
征数量成指数变多 这在大规模数据集上 尤其是节 6.4 多网络的融合
. ,
点之间的边连接数量较多时表现的非常明显 随之 由于现实世界数据的复杂性 抽象出来的图结
. ,
而来的是训练过程中计算复杂度的剧增 并可能导 构也会有很多的种类和变体 有向无向 异质非异
, . 、
致过拟合的现象发生 这也就意味着随着层数的增 质 带权不带权等等 大部分的 仅能处理其中
. 、 , GNN
加 模型性能会急剧下降 如果想要加深网络 的某一种类型 而更普遍的情况是各种各样的图混
,GNN . .
层数 就必须限制每层节点数量 但是这也会使得特 杂在一起 并且希望 能满足诸如节点分类 图
, . , GNN 、
征聚集的量变少 导致节点之间信息传播受阻 如何 分类 可视化 图生成等多种任务需求 在这种复杂
, . 、 、 .
解决这一矛盾性问题是将来研究的重点之一 的高强度的任务要求下 单一的神经网络作用过于
. ,
6.2 动态性 有限 因此对于更加复杂的情况 有必要进行多网络
. ,
融合 目前比较主流的多网络融合方式是 与
就目前来看 现有的 大多处理的是静态
, GNN . GCN
其他 算法相结合 例如在节点属性和图拓扑
齐次图 一方面 框架会假定图结构是固定的
. ,GNN ; GNN .
结构信息的获取上 明显具有较高的性能和良
另一方面 框架会假设图中的节点和边来自于
,GNN
,GCN
好的适应性 在节点分类问题上会表现良好 鉴于其
单一源分布 然而 这两个假设在许多情况下并不能
. , , .
同时成立 在社交网络中 新的人可以随时进入网 优点 在 中不乏部分模型使用 作为编码
. , , GAE GCN
络 并且现有的人也可以退出网络 在推荐系统中 器 取得较好的效果 但如果还需要进行链接预测
, . , , . 、
产品可能有不同的类型 其输入可能有不同的形式 节点生成或者图生成 则有点力不从心了 此
, , ,GCN .
如文本或图像 特别是在超大规模的图中 节点的个 时可以再增设一个 输入 处理后的节点
. , GGN, GCN
数和边的个数可能有百万 千万乃至上亿 尤其是随 嵌入向量 在 内生成概率分布 完成生成式任
、 . , GGN ,
着数据的增加和改变 节点和边的个数以及节点和 务 如果图在不断地递归演进 形成了图序列 则可以
, . , .
边的类型都可能发生动态的变化 在这些任务处理 利用 来处理 以攘括多个步骤下的图信息 因此
. GRN , .
中 图的动态变化是不能忽视的 特别是在固定尺寸 在 框架中构造不同用途的深度神经网络 从不
, . GNN ,
下 因为某个节点或者边发生改变而重新学习整个 同的侧面来提取和整合数据的特征是十分有必要的
, .
图将会使得代价十分昂贵 而大多数 对于大 此外可以对诸如深度置信网络
. GNN
(DeepBeliefNet-
型图不具有很好的伸缩性 其主要原因是当堆叠 [151] [152]等神经网络进行改造 将
.
work) 、Transformer ,
的多个层时 节点的最终状态涉及大量邻居的 其泛化和应用至图结构数据学习上
GNN , .
隐藏状态 导致反向传播的高复杂性 虽然目前有一 6.5 与网络嵌入的结合
, .
定的文献[94-95,136-137]在研究图的时空动态性 ,但是面
网络嵌入可以将原始图数据的高维稀疏矩阵转
对更大规模和更加复杂的动态异质图数据时还不够
变为低维度稠密的向量 这可以大幅度压缩存储空
,
有效 因此如何对图的动态性进行有效的适应是未
间 并提取有效的图信息 一般图节点的原始特征矩
来的. 研究方向之一 , .
.
阵是高维稀疏的 ,对于一个N ×F的特征矩阵 ,当
6.3 感受域 F比较大时 所需要的存储空间也相应的增加 如果
, .
一个节点的感受域是指一组节点集合 包括中 矩阵比较稀疏 那么存储效率也会比较低下 网络嵌
, , .
心节点及其邻居节点 感受域大小是决定邻居节点 入则可以利用图结构信息 生成低维连续的节点特
. ,
数量的关键参数 在大规模图数据集中 平均每个节 征表示 避免存储空间浪费 其次 由于生成的节点
. , , . ,
点周围有多个邻居节点存在 随着网络层数的增加 嵌入表示包含了部分邻居节点信息 所以中心节点
. , ,
邻居节点会递归增加数目 感受域也随之快速扩张 的感受域也可以相应的减少 对于多层图卷积和需
, . . 计 算 机 学 报 年
62 2022
要迭代压缩的 来说 一定程度上可以减少网 综合使用 通过相互组合和融合的方式可以在特定
GNN , ,
络层数和迭代压缩次数 例如 等人[27]半监督 任务上取得不俗的性能表现
. Kipf .
复杂度为O|E|FC [110]的复杂 本文概括和提炼了目前主流的 框架和模
GCN ( ),DeepWalk GNN
度为O N 当边连接比较密集并且节点特征 型 并对不同算法进行归纳总结 分析了 在多个
(log( )). , , GNN
维度很大时 复杂度较高 如果对节点特征降维 使 领域的应用以及未来发展方向 总之 作为一种图结
, . , . ,
得降维之后的维度F' F 这样总体复杂度变为 构数据处理框架 虽然 概念的提出比较早 但是
≪ , , GNN ,
O N +O|E|F'C 尽管增加了网络嵌入 其兴起和发展的时间还不长 现有的模型算法还有进
(log( )) ( ). ,
的计算时间 但是在图卷积层可以大幅度降低计算 一步提高和改进的空间 在未来研究的道路上 还可
, . ,
开销 这样可以提高训练的有效性以及降低计算复 能有更多优秀的深度神经网络加入到 中 通过
, GNN ,
杂度 文献[66,76,86]就使用随机游走等网络嵌入方法 对图结构数据进行更加全面而细致的分析 达到在降
. ,
来为 模型构建输入序列 除此之外未来研究 低训练量的同时取得更加优异效果的目标
GNN , .
中也可以尝试诸如 [77] [153]等网络
Node2vec 、LINE
嵌入方法来对 的输入端进行改进 参 考 文 献
GNN .
7 总 结
[1] Hinton,G.E.Reducingthedimensionalityofdatawithneu-
ralnetworks.Science,2006,313(5786):504-507
从 年 等人提出 概念 到 [2] JIAOLi-Cheng,YANGShu-Yuan,LIUFangetal.Seventy-
2005 Gori GNN , GCN
的出现为非欧式结构数据提供有效的处理范式 再
yearsbeyondneuralnetworks:retrospectandprospect.Chi-
, neseJournalofComputers,2016,39(8):1697-1716(inChi-
到 等不同 框架变种
GAE、GAT、GRN、GGN GNN nese)
的提出以及 在各个领域的应用 在理论 焦李成 杨淑媛 刘芳等 神经网络七十年 回顾与展望 计算
GNN ,GNN ( , , . : .
机学报
和实践上经历一个从无到有 从有到优化的过程 ,2016,39(8):1697-1716)
、 ,
的体系族也在不断地发展和完善 从这段历程 [3] GallinariP,ThiriaS,Fogelman-SouliƧF.Multilayerpercep-
GNN .
中 可以看出许多研究人员对 算法和结构不
tronsanddataanalysis//ProceedingsoftheIEEEInternational
, GNN JointConferenceonNeuralNetworks.SanDiego,USA,
断改进和优化 从一开始 只是对节点进行简
. GRN 1988:391-399
单的特征变换和压缩 到后面 对邻居节点特
, GCN [4] LeCunY,BoserB,DenkerJS,etal.Backpropagationap-
征采样和聚合以及边信息传播路径的分析 利
pliedtohandwrittenzipcoderecognition.NeuralComputa-
,GNN
用图结构信息和属性信息的能力越来越强 在面对 tion,1989,1(4):541-551
.
不同隐含数据分布时 能够对图进行非线性变
[5] ElmanJL.Findingstructureintime.CognitiveScience,
,GAE
1990,14(2):179-211
换 进行半监督或者无监督学习 提取更具有代表性
, , [6] GoodfellowIJ,Pouget-AbadieJ,MirzaM,etal.Generative
的特征 在面对物理化学以及药物医学等需要生成
.
adversarialnets//Proceedingsofthe28thAdvancesinNeural
具有领域限定要求的图结构数据时 能够对图 InformationProcessingSystems.Montreal,Canada,2014:
,GGN
数据进行对抗性训练 获得期望的分子图 药物化合 2672-2680
, 、
物图等等 而 的出现则使得神经网络能够聚
[7] RifaiS,VincentP,MullerX,etal.Contractiveauto-en-
. GAT coders:explicitinvarianceduringfeatureextraction//Proceed-
焦在任务关注的节点 边和子图上 忽视不重要的信
、 , ingsofthe28thInternationalConferenceonMachineLearn-
息 增强训练的有效性和鲁棒性 提升测试结果的可
, , ing.Washington,USA,2011:833-840
解释性 [8] ZHOUFei-Yan,JINLin-Peng,DONGJun.Reviewofconvo-
.
在 发展的同时 面向图结构的算法还有 lutionalnetwork.ChineseJournalofComputers,2017,40
GNN ,
网络嵌入和图核方法 尽管它们也能分析和处理相
(6):1229-1251(inChinese)
周飞燕 金林鹏 董军 卷积神经网络研究综述 计算机学报
. ( , , . . ,
关的图数据和任务 但都是从某个侧面的角度出发
, 2017,40(06):1229-1251)
对图进行窥探和剖析 相较于网络嵌入和图核方法
. , [9] GoriM,MonfardiniG,ScarselliF.Anewmodelforlearning
能够直接对节点 边以及图整体进行特征聚合 ingraphdomains//ProceedingsoftheInternationalJointCon-
GNN 、
和提取 最大程度的保留了图的拓扑结构信息和内 ferenceonNeuralNetworks.Montreal,Canada,2005:729-
,
容属性信息 在分类 聚类 预测 生成等任务上表现 734
, 、 、 、
[10] BrunaJ,ZarembaW,SzlamA,etal.Spectralnetworksand
更加突出 当然 在分析图数据时 这三种方法可以
. , , locallyconnectednetworksongraphs//Proceedingsofthe 期 吴 博等 图神经网络前沿进展与应用
1 : 63
2ndInternationalConferenceonLearningRepresentations. tionProcessingSystems.Barcelona,Spain,2016:3837-3845
Banff,Canada,2014 [26] LevieR,MontiF,BressonX,etal.CayleyNets:graphcon-
[11] XuBing-Bing,CenKe-Ting,HuangJun-Jieetal.Asurvey volutionalneuralnetworkswithcomplexrationalspectralfil-
ongraphconvolutionalneuralnetwork.ChineseJournalof ters.IEEETransactionsonSignalProcessing,2019,67(1):
Computers,2020,43(5):755-780(inChinese) 97-109
徐冰冰 岑科廷 黄俊杰等 图卷积神经网络综述 计算机学
( , , . . [27] KipfTN,WellingM.Semi-supervisedclassificationwith
报
,2020,43(5):755-780) graphconvolutionalnetworks//Proceedingsof5thInterna-
[12] ScarselliF,GoriM,TsoiAC,etal.Thegraphneuralnet- tionalConferenceon Learning Representations.Toulon,
workmodel.IEEETransactionsonNeuralNetworks,2009, France,2017
20(1):61-80 [28] LiR,WangS,ZhuF,etal.Adaptivegraphconvolutional
[13] MicheliA.Neuralnetworkforgraphs:acontextualap- neuralnetworks//Proceedingsofthe32ndAAAIConference
proach.IEEETransactionsonNeuralNetworks,2009,20 onArtificialIntelligence.Louisiana,USA,2018:3546-3553
(3):498-511 [29] VermaS,ZhangZ.Graphcapsuleconvolutionalneuralnet-
[14] BronsteinMM,BrunaJ,LeCunY,etal.Geometricdeep works.arXiv:1805.08090,2018
learning:goingbeyondeuclideandata.IEEESignalProcess- [30] HintonGE,KrizhevskyA,WangSD.Transformingauto-
ingMagazine,2017,34(4):18-42 encoders//Proceedingsofthe21stInternationalConference
[15] TsitsveroM,BarbarossaS.Onthedegreesoffreedomof onArtificialNeuralNetworks.Espoo,Finland,2011:44-51
signalsongraphs//Proceedingsofthe23rdEuropeanSignal [31] SabourS,FrosstN,HintonGE.Dynamicroutingbetween
ProcessingConference(EUSIPCO).Nice,France,2015: capsules//Proceedingsofthe31stAdvancesinNeuralInfor-
1506-1510 mationProcessingSystems.LongBeach,USA,2017:3856-
[16] PasdeloupB,AlamiR,GriponV,etal.Towardanuncer- 3866
taintyprincipleforweightedgraphs//Proceedingsofthe23rd [32] VermaS,ZhangZ-L.Huntfortheunique,stable,sparse
EuropeanSignalProcessingConference(EUSIPCO).Nice, andfastfeaturelearningongraphs//Proceedingsofthe31st
France,2015:1496-1500 AdvancesinNeuralInformationProcessingSystems.Long
[17] RamI,EladM,CohenI.Generalizedtree-basedwavelet Beach,USA,2017:88-98
transform.IEEETransactionsonSignalProcessing,2011, [33] ZhuangC,MaQ.Dualgraphconvolutionalnetworksfor
59(9):4199-4209 graph-Basedsemi-supervisedclassification//Proceedingsof
[18] GavishM,NadlerB,CoifmanRR.Multiscalewaveletson the27thInternationalConferenceonWorldWideWeb.Ly-
trees,graphsandhighdimensionaldata:theoryandapplica- on,France,2018:499-508
tionstosemisupervisedlearning//Proceedingsofthe27thIn- [34] HenaffM,BrunaJ,LeCunY.Deepconvolutionalnetworks
ternationalConferenceonMachineLearning.Haifa,Israel, ongraph-structureddata.arXiv:1506.05163,2015
2010:367-374 [35] BelkinM,NiyogiP.Laplacianeigenmapsandspectraltech-
[19] SandryhailaA,MouraJMF.Discretesignalprocessingon niquesforembeddingandclustering//Proceedingsofthe15th
graphs.IEEETransactionsonSignalProcessing,2013,61 AdvancesinNeuralInformationProcessingSystems.Van-
(7):1644-1656 couver,Canada,2001:585-591
[20] ShumanDI,NarangSK,FrossardP,etal.Theemerging [36] PeronaP.Self-tuningspectralclustering//Proceedingsofthe
fieldofsignalprocessingongraphs:extendinghigh-dimen- 18thAdvancesinNeuralInformationProcessingSystems.
sionaldataanalysistonetworksandotherirregulardomains. Vancouver,Canada,2004:1601-1608
IEEESignalProcessingMagazine,2012,30(3):83-98 [37] ZhangM,CuiZ,NeumannM,etal.Anend-to-enddeep
[21] ChungFRK,GrahamFC.Spectralgraphtheory.America: learningarchitectureforgraphclassification//Proceedingsof
AmericanMathematicalSociety,1997 the32ndAAAIConferenceonArtificialIntelligence.New
[22] HammondDK,VandergheynstP,GribonvalR.Wavelets Orleans,USA,2018:4438-4445
ongraphsviaspectralgraphtheory.arXiv:0912.3848,2009 [38] ShervashidzeN,SchweitzerP,LeeuwenEJvan,etal.We-
[23] SusnjaraA,PerraudinN,KressnerD,etal.Acceleratedfil- isfeiler-lehmangraphkernels.JournalofMachineLearning
teringongraphsusingLanczosmethod.arXiv:1509.0453, Research,2010,1(3):1-48
2015 [39] YingR,YouJ,MorrisC,etal.Hierarchicalgraphrepre-
[24] Cullum,JaneK,Willoughby,etal.Lanczosalgorithmsfor sentationlearningwithdifferentiablepooling//Proceedingsof
largesymmetriceigenvaluecomputations.SocietyforIndus- the32ndAdvancesinNeuralInformationProcessingSys-
trialandAppliedMathematics,2002,I:Theory tems.Montreal,Canada,2018:4805-4815
[25] DefferrardM,BressonX,VandergheynstP.Convolutional [40] KistruckGM,SutterCJ,LountRB,etal.Learningcon-
neuralnetworksongraphswithfastlocalizedspectralfilte- volutionneuralnetworksforgraphs//Proceedingsofthe33rd
ring//Proceedingsofthe30thAdvancesinNeuralInforma- InternationalConferenceonMachineLearning.NewYork, 计 算 机 学 报 年
64 2022
USA,2016:2014-2023 ferenceon ArtificialIntelligence.Phoenix,USA,2016:
[41] DouglasBL.Theweisfeiler-lehmanmethodandgraphiso- 1145-1152
morphismtesting.arXiv:1101.5211,2011 [55] WangC,PanS,LongG,etal.MGAE:marginalizedgraph
[42] AtwoodJ,TowsleyD.Diffusion-convolutionalneuralnet- autoencoderforgraphclustering//Proceedingsofthe26th
works//Proceedingsofthe30thAdvancesinNeuralInforma- ACMInternationalConferenceonInformationandKnowl-
tionProcessingSystems.Barcelona,Spain,2016:1993-2001 edgeManagement.Singapore,2017:889-898
[43] HechtlingerY,ChakravartiP,QinJ.Ageneralizationof [56] BourlardH,KampY.Auto-associationbymultilayerper-
convolutionalneuralnetworkstograph-structureddata.arX- ceptronsandsingularvaluedecomposition.BiologicalCyber-
iv:1704.08165,2017 netics,1988,59(4-5):291-294
[44] WilliamL.H,YingZ,LeskovecJ.Inductiverepresentation [57] LvL,ChengJ,PengN,etal.Auto-encoderbasedgraph
learningonlargegraphs//Proceedingsofthe31stAdvances convolutionalnetworksforonlinefinancialanti-fraud//Pro-
inNeuralInformationProcessingSystems.LongBeach, ceedingsoftheIEEEConferenceonComputationalIntelli-
USA,2017:1024-1034 genceforFinancialEngineeringandEconomics.Shenzhen,
[45] ChenJ,MaT,XiaoC.FastGCN:fastlearningwithgraph China,2019:1-6
convolutionalnetworksviaimportancesampling//Proceed- [58] KingmaDP,WellingM.Auto-encodingvariationalBayes.
ingsofthe6thInternationalConferenceonLearningRepre- arXiv:1312.6114,2014
sentations.Vancouver,Canada,2018 [59] KipfTN,WellingM.Variationalgraphauto-encoders.arX-
[46] ChenJ,ZhuJ,SongL.Stochastictrainingofgraphconvolu- iv:1611.07308,2016
tionalnetworkswithvariancereduction//Proceedingsofthe [60] HasanzadehA,HajiramezanaliE,DuffieldN,etal.Semi-
35thInternationalConferenceonMachineLearning.Stock- implicitgraphvariationalauto-encoders//Proceedingsofthe
holm,Sweden,2018:941-949 33rdConferenceonNeuralInformationProcessingSystems.
[47] HuangW,ZhangT,RongY,etal.Adaptivesamplingto- Vancouver,Canada,2019:10711-10722
wardsfastgraphrepresentationlearning//Proceedingsofthe [61] YinM,ZhouM.Semi-implicitvariationalinference//Pro-
32ndConferenceonNeuralInformationProcessingSystems. ceedingsofthe35thInternationalConferenceon Machine
Montreal,Canada,2018:4563-4572 Learning.Stockholm,Sweden,2018:5646-5655
[48] CHENKejia,YANGZeyu,LIUZheng,etal.Graphconvo- [62] PapamakariosG,PavlakouT,MurrayI.Maskedautoregres-
lutionalnetworkmodelusingneighborhoodselectionstrate- siveflowfordensityestimation//Proceedingsofthe31stAd-
gy.JournalofComputerApplications,2019,39(12):3415- vancesin NeuralInformationProcessingSystems.Long
3419(inChinese) Beach,USA,2017:2338-2347
陈可佳 杨泽宇 刘峥等 基于邻域选择策略的图卷积网络
( , , . [63] ZhouM.Infiniteedgepartitionmodelsforoverlappingcom-
模型 计算机应用
. ,2019,39(12):3415-3419) munitydetectionandlinkprediction.JournalofMachine
[49] GaoH,WangZ,JiS.Large-scalelearnablegraphconvolu- LearningResearch,2015,38:1135-1143
tionalnetworks//Proceedingsofthe24thInternationalCon- [64] SimonovskyM,KomodakisN.GraphVAE:towardsgenera-
ferenceonKnowledgeDiscoveryandDataMining.London, tionofsmallgraphsusingvariationalautoencoders//Proceed-
UK,2018:1416-1424 ingsofthe27thInternationalConferenceonArtificialNeural
[50] DerrT,MaY,TangJ.Signedgraphconvolutionalnet- Networks.Rhodes,Greece,2018:412-422
works//Proceedingsofthe20thInternationalConferenceon [65] PanS,HuR,LongG,etal.Adversariallyregularizedgraph
DataMining.Singapore,2018:929-934 autoencoderforgraphembedding//ProceedingsoftheTwen-
[51] SuchFP,SahS,DominguezMA,etal.Robustspatialfil- ty-SeventhInternationalJointConferenceonArtificialIntelli-
teringwithgraphconvolutionalneuralnetworks.IEEEJour- gence.Stockholm,Sweden,2018:2609-2615
nalofSelectedTopicsinSignalProcessing,2017,11(6): [66] Vaibhav,HuangP-Y,FrederkingR.RWR-GAE:random
884-896 walk regularization for graph auto encoders.arXiv:
[52] GlorotX,BengioY.Understandingthedifficultyoftraining 1908.04003,2019
deepfeedforwardneuralnetworks//Proceedingsofthe30th [67] PanJY,YangHJ,FaloutsosC,etal.Automaticmultime-
InternationalConferenceonArtificialIntelligenceandStatis- diacross-modalcorrelationdiscovery//Proceedingsofthe
tics.Sardinia,Italy,2010:249-256 10thInternationalConferenceonKnowledgeDiscoveryand
[53] IoffeS,SzegedyC.Batchnormalization:acceleratingdeep DataMining.Washington,USA,2004:653-658
networktrainingbyreducinginternalcovariateshift//Pro- [68] MikolovT,ChenK,CorradoG,etal.Efficientestimation
ceedingsofthe32ndInternationalConferenceonMachine ofwordrepresentationsinvectorspace.arXiv:1301.3781,
Learning.Lille,France,2015:448-456 2013
[54] CaoS,LuW,XuQ.Deepneuralnetworksforlearning [69] LiC,WellingM,ZhuJ,etal.Graphicalgenerativeadver-
graphrepresentations//Proceedingsofthe30thAAAICon- sarialnetworks//Proceedingofthe32ndConferenceonNeu- 期 吴 博等 图神经网络前沿进展与应用
1 : 65
ralInformation ProcessingSystems.MontrƧal,Canada, nationalConferenceonMachineLearning.Sydney,Austral-
2018:6072-6083 ia,2017:2642-2651
[70] HeskesT,ZoeterO.Expectationpropagationforapproxi- [86] Ding M,TangJ,ZhangJ.Semi-supervisedlearningon
mateinferenceindynamicbayesiannetworks.ComputerSci- graphswithgenerativeadversarialnets//Proceedingsofthe
ence,2013:216-223 27thInternationalConferenceonInformationandKnowledge
[71] TaentzerG,SchweenH.Movementofobjectsinconfigura- Management.Torino,Italy,2018:913-922
tionspacesmodelledbygraphgrammars//Proceedingsofthe [87] SalimansT,KingmaDP.Weightnormalization:asimple
Graph-GrammarsandTheirApplicationtoComputerSci- reparameterizationtoacceleratetrainingofdeepneuralnet-
ence,4thInternational Workshop.Bremen,Germany, works//Proceedingsofthe30thAdvancesinNeuralInforma-
1990:660-675 tionProcessingSystems.Barcelona,Spain,2016:901-909
[72] LiY,VinyalsO,DyerC,etal.Learningdeepgenerative [88] AlmeidaLB.Learningruleforasynchronousperceptrons
modelsofgraphs.arXiv:1803.0332,2018 withfeedbackinacombinatorialenvironment.ArtificialNeu-
[73] KyunghyunCho,BartVanMerri¨enboer,CaglarGulcehreet ralNetworks,1987:102-111
al.Learningphraserepresentationsusingrnnencoder-decod- [89] PinedaFJ.Generalizationofback-propagationtorecurrent
erforstatisticalmachinetranslation//Proceedingsofthe2014 neuralnetworks.PhysicalReviewLetters,1987,59(19):
ConferenceonEmpiricalMethodsinNaturalLanguagePro- 2229-2232
cessing.Doha,Qatar,2014:1724-1734 [90] LiY,ZemelR,BrockschmidtM,etal.Gatedgraphse-
[74] LiuW,ChenPY,YuF,etal.Learninggraphtopological quenceneuralnetworks//Proceedingsofthe4thInternational
featuresviaGAN.IEEEAccess,2019,7:21834-21843 ConferenceonLearningRepresentations.SanJuan,Puerto
[75] WangH,WangJ,WangJ,etal.Graphgan:graphrepre- Rico,2016
sentationlearningwithgenerativeadversarialnets//Proceed- [91] JohnsonDD.Learninggraphicalstatetransitions//Proceed-
ingsofthe32ndAAAIConferenceonArtificialIntelligence. ingsofthe5thInternationalConferenceonLearningRepre-
NewOrleans,USA,2018:2508-2515 sentations.Toulon,France,2017
[76] BojchevskiA,ShchurO,ZügnerD,etal.NetGAN:genera- [92] WestonJ,BordesA,ChopraS,etal.TowardsAI-complete
tinggraphsviarandomwalks//Proceedingsofthe35thInter- questionanswering:asetofprerequisitetoytasks//Proceed-
nationalConferenceonMachineLearning.Stockholm,Swe- ingsofthe4thInternationalConferenceonLearningRepre-
den,2018:609-618 sentations.SanJuan,PuertoRico,2016
[77] GroverA,LeskovecJ.Node2vec:scalablefeaturelearning [93] YouJ,YingR,RenX,etal.GraphRNN:generatingrealis-
fornetworks//Proceedingsofthe22ndInternationalConfer- ticgraphswithdeepauto-regressivemodels//Proceedingsof
enceonKnowledgeDiscoveryandDataMining.SanFrancis- the35thInternationalConferenceon MachineLearning.
co,USA,2016:855-864 Stockholm,Sweden,2018:5694-5703
[78] ArjovskyM,ChintalaS,BottouL.WassersteinGAN.arX- [94] SeoY,DefferrarM,VandergheynstP,etal.Structuredse-
iv:1701.07875,2017 quencemodelingwithgraphconvolutionalrecurrentnet-
[79] DeCaoN,KipfT.MolGAN:animplicitgenerativemodel works//Proceedingofthe25thInternationalConferenceon
forsmallmoleculargraphs.arXiv:1805.11973,2018 NeuralInformation Processing.Siem Reap,Cambodia,
[80] GulrajaniI,Ahmed1F,ArjovskyM,etal.Improvedtrain- 2018:362-373
ingofWassersteinGANs//Proceedingsofthe31stAdvances [95] XuD,ChengW,LuoD,etal.Spatio-temporalattentive
inNeuralInformationProcessingSystems.LongBeach, RNNfornodeclassificationintemporalattributedgraphs//
USA,2017:5767-5777 Proceedingsofthe38thInternationalJointConferenceonAr-
[81] GuimaraesG,Sanchez-LengelingB,OuteiralC,etal.Ob- tificialIntelligence.Macao,China,2019:3947-3953
jective-reinforcedgenerativeadversarialnetworks(ORGAN) [96] VaswaniA,ShazeerN,ParmarN,etal.Attentionisallyou
forsequencegenerationmodels.arXiv:1705.10843,2018 need//Proceedingsofthe31stConferenceonNeuralInforma-
[82] SalimansT,GoodfellowI,ZarembaW,etal.Improved tionProcessingSystems.LongBeach,USA,2017:5998-
techniquesfortraininggans//Proceedingsofthe30thConfer- 6008
enceonNeuralInformationProcessingSystems.Barcelona, [97] Veli?kovi'cP,CucurullG,CasanovaA,etal.Graphatten-
Spain,2016:2226-2234 tionnetworks//Proceedingsofthe6thInternationalConfer-
[83] FanS,HuangB.Labeledgraphgenerativeadversarialnet- enceonLearningRepresentations.Vancouver,Canada,2018
works.arXiv:1906.03220,2019 [98] SalehiA,DavulcuH.Graphattentionauto-encoders.arXiv:
[84] MirzaM,OsinderoS.Conditionalgenerativeadversarial 1905.10715,2019
nets.arXiv:1411.1784,2014 [99] BusbridgeD,SherburnD,CavalloP,etal.Relationalgraph
[85] OdenaA,OlahC,ShlensJ.Conditionalimagesynthesis attentionnetworks.arXiv:1904.05811,2018
withauxiliaryclassifiergans//Proceedingsofthe34thInter- [100] SchlichtkrullM,KipfTN,BloemP,etal.Modelingrela- 计 算 机 学 报 年
66 2022
tionaldatawithgraphconvolutionalnetworks//Proceedings tiongraphkernels//ProceedingsoftheIEEEConferenceon
ofthe15thExtendedSemanticWebConference.Heraklion, ComputerVisionandPatternRecognition.Minneapolis,
Greece,2018:593-607 USA,2007:18-23
[101] ZhangJ,ShiX,XieJ,etal.GaAN:gatedattentionnet- [115] WestonJason,RatleFrƧdƧric,MobahiHossein,etal.Deep
worksforlearningonlargeandspatiotemporalgraphs//Pro- Learningviasemi-supervisedembedding//Proceedingsof
ceedingsofthe34thConferenceonUncertaintyinArtificial the25thInternationalConferenceon MachineLearning.
Intelligence.Monterey,USA,2018:339-349 Helsinki,Finland,2008:1168-1175
[102] DoK,TranT,NguyenT,etal.Attentionalmultilabel [116] YangZhilin,W.CohenWilliam,RuslanSalakhutdinov.Re-
learningovergraphs:amessagepassingapproach.Machine visitingsemi-supervisedlearningwithgraphembeddings//
Learning,2019,108(10):1757-1781 Proceedingsofthe33rdInternationalConferenceonMachine
[103] PhamT,TranT,PhungD,etal.Columnnetworksfor Learning.NewYork,USA,2016:1-9
collectiveclassification//Proceedingsofthe31stAAAICon- [117] VashishthS,BhandariM,YadavP,etal.Incorporating
ferenceon ArtificialIntelligence.SanFrancisco,USA, syntacticandsemanticinformationinwordembeddingsu-
2017:2485-2491 singgraphconvolutionalnetworks//Proceedingsofthe57th
[104] GilmerJ,SchoenholzSS,RileyPF,etal.Neuralmessage AnnualMeetingoftheAssociationforComputationalLin-
passingforquantumchemistry//Proceedingsofthe34thIn- guistics.Florence,Italy,2019:3308-3318
ternationalConferenceonMachineLearning.Sydney,Aus- [118] GuoZ,ZhangY,LuW.Attentionguidedgraphconvolu-
tralia,2017:1263-1272 tionalnetworksforrelationextraction//Proceedingsofthe
[105] SrivastavaRK,GreffK,SchmidhuberJ.Trainingvery 57thConferenceoftheAssociationforComputationalLin-
deepnetworks//Proceedingsofthe29thAdvancesinNeural guistics.Florence,Italy,2019:241-251
InformationProcessingSystems.Montreal,Canada,2015: [119] FuT-J,LiP-H,MaW-Y.GraphRel:modelingtextasre-
2377-2385 lationalgraphsforjointentityandrelationextraction//Pro-
[106] LeeJB,RossiR,KongX.Graphclassificationusingstruc- ceedingsofthe57thAnnualMeetingoftheAssociationfor
turalattention//Proceedingsofthe24thInternationalCon- ComputationalLinguistics.Florence,Italy,2019:1409-
ferenceonKnowledgeDiscoveryandDataMining.London, 1418
UK,2018:1666-1674 [120] ZhuH,LinY,LiuZ,etal.Graphneuralnetworkswith
[107] KnyazevB,TaylorGW,AmerMR.Understandingatten- generatedparametersforrelationextraction//Proceedingsof
tionandgeneralizationingraphneuralnetworks//Proceed- the57thAnnualMeetingoftheAssociationforComputa-
ingsofthe33rdConferenceonNeuralInformationProcess- tionalLinguistics.Florence,Italy,2019:1331-1339
ingSystems.Vancouver,Canada,2019:4204-4214 [121] TuM,WangG,HuangJ,etal.Multi-hopreadingcompre-
[108] XuK,HuW,LeskovecJ.Howpowerfularegraphneural hensionacrossmultipledocumentsbyreasoningoverhetero-
networks?//Proceedingsofthe7thInternationalConfer- geneousgraphs//Proceedingsofthe57thAnnualMeetingof
enceonLearningRepresentations.New Orleans,USA, theAssociationforComputationalLinguistics.Florence,It-
2019 aly,2019:2704-2713
[109] ChenH,PerozziB,Al-RfouR,etal.Atutorialonnetwork [122] QiuL,XiaoY,QuY,etal.Dynamicallyfusedgraphnet-
embeddings.arXiv:1808.02590,2018 workformulti-hopreasoning//Proceedingsofthe57thAn-
[110] PerozziB,Al-RfouR,SkienaS.DeepWalk:onlinelearning nualMeetingoftheAssociationforComputationalLinguis-
ofsocialrepresentations//Proceedingsofthe20thInterna- tics.Florence,Italy,2019:6140-6150
tionalConferenceonKnowledgeDiscoveryandDataMining. [123] LiC,GoldwasserD.Encodingsocialinformationwith
NewYork,USA,2014:701-710 graphconvolutionalnetworksforpoliticalperspectivedetec-
[111] MalleaMDG,MeltzerP,BentleyPJ.Capsuleneuralnet- tioninnewsmedia//Proceedingsofthe57thAnnualMeet-
worksforgraphclassificationusingexplicittensorialgraph ingoftheAssociationforComputationalLinguistics.Flor-
representations.arXiv:1902.08399,2019 ence,Italy,2019:2594-2604
[112] BorgwardtK M,OngCS,SchönauerS,etal.Protein [124] DingM,ZhouC,ChenQ,etal.Cognitivegraphformulti-
functionpredictionviagraphkernels//Proceedings30thIn- hopreadingcomprehensionatscale//Proceedingsofthe
ternationalConferenceonIntelligentSystemsforMolecular 57thAnnualMeetingoftheAssociationforComputational
Biology.Detroit,USA,2005:47-56 Linguistics.Florence,Italy,2019:2694-2703
[113] ShervashidzeN,BorgwardtKM.Fastsubtreekernelson [125] DuvenaudD,MaclaurinD,Aguilera-iparraguirreJ,etal.
graphs//Proceedingsofthe23rdAdvancesinNeuralInfor- Convolutionalnetworksongraphsforlearningmolecular
mationProcessingSystems.Vancouver,Canada,2009: fingerprints//Proceedingsofthe29thAdvancesinNeural
1660-1668 InformationProcessingSystems.Montreal,Canada,2015:
[114] HarchaouiZ,BachF.Imageclassificationwithsegmenta- 2224-2232 期 吴 博等 图神经网络前沿进展与应用
1 : 67
[126] KearnesS,McCloskeyK,BerndlM,etal.Moleculargraph GANandgraphattentionnetworks//Proceedingsofthe
convolutions:movingbeyondfingerprints.JournalofCom- 33rdConferenceonNeuralInformationProcessingSystems.
puter-AidedMolecularDesign,2016,30(8):595-608 Vancouver,Canada,2019:137-146
[127] GomesJ,RamsundarB,FeinbergEN,etal.Atomicconv- [140] ZhuJ-Y,ZhangR,PathakD,etal.Towardmultimodal
olutionalnetworksforpredictingprotein-ligandbindingaf- image-to-imagetranslation//Proceedingsofthe31stConfer-
finity.arXiv:1703.10603,2017 enceon NeuralInformationProcessingSystems.Long
[128] Altae-TranH,RamsundarB,PappuAS,etal.Lowdata Beach,USA,2017:465-476
drugdiscoverywithone-shotlearning.ACSCentralSci- [141] WangZ,LvQ,LanX,etal.Cross-lingualknowledge
ence,2017,3(4):283-293 graphalignmentviagraphconvolutionalnetworks//Pro-
[129] MaT,XiaoC,ZhouJ,etal.Drugsimilarityintegration ceedingsoftheConferenceonEmpiricalMethodsinNatural
throughattentivemulti-viewgraphauto-encoders//Proceed- LanguageProcessing.Brussels,Belgium,2018:349-357
ingsofthe27thInternationalJointConferenceonArtificial [142] HamaguchiT,OiwaH,Shimbo M,etal.Knowledge
Intelligence.Stockholm,Sweden,2018:3477-3483 transferforout-of-knowledge-baseentities:agraphneural
[130] ShiL,ZhangY,ChengJ,etal.Skeleton-basedactionrec- networkapproach//Proceedingsofthe26thInternational
ognitionwithdirectedgraphneuralnetworks//Proceedings JointConferenceonArtificialIntelligence.Melbourne,Aus-
oftheIEEEConferenceonComputerVisionandPattern tralia,2017:1802-1808
Recognition.LongBeach,USA,2019:7912-7921 [143] BordesA,UsunierN,García-DuršnA.Translatingembed-
[131] SimonyanK,ZissermanA.Two-streamconvolutionalnet- dingsformodelingmulti-relationaldata//Proceedingsofthe
worksforactionrecognitioninvideos//Proceedingsofthe 27thAdvancesinNeuralInformationProcessingSystems.
28thAdvancesinNeuralInformationProcessingSystems. LakeTahoe,USA,2013:2787-2795
Montreal,Canada,2014:568-576 [144] LiZ,CuiZ,WuS,etal.Fi-GNN:modelingfeatureinter-
[132] NarasimhanM,LazebnikS,SchwingAG.Outofthebox: actionsviagraphneuralnetworksforCTRprediction//Pro-
reasoningwithgraphconvolutionnetsforfactualvisual ceedingsofthe28thInternationalConferenceonInformation
questionanswering//Proceedingsofthe32ndConferenceon andKnowledgeManagement.Beijing,China,2019:539-
NeuralInformationProcessingSystems.Montreal,Canada, 548
2018:2659-2670 [145] MontiF,BronsteinM M,BressonX.Geometricmatrix
[133] QiX,LiaoR,JiaJ,etal.3Dgraphneuralnetworksfor completionwithrecurrentmulti-graphneuralnetworks//
RGBDsemanticsegmentation//ProceedingsoftheIEEEIn- Proceedingsofthe31stConferenceonNeuralInformation
ternationalConferenceonComputerVision.Venice,Italy, ProcessingSystems.LongBeach,USA,2017:3697-3707
2017:5209-5218 [146] GuoJia-Yan,LiRong-Hua,ZhangYan,etal.Graphneural
[134] LandrieuL,SimonovskyM.Large-scalepointcloudseman- networkbasedanomalydetectionindynamicnetworks.
ticsegmentationwithsuperpointgraphs//Proceedingsofthe JournalofSoftware,2020,31(03):748-762(inChinese)
郭嘉琰 李荣华 张岩等 基于图神经网络的动态网络异常
IEEEConferenceonComputerVisionandPatternRecogni- ( , , .
检测算法 软件学报
tion.SaltLakeCity,USA,2018:4558-4567 . ,2020,31(03):748-762)
[135] GarciaV,BrunaJ.Few-shotlearningwithgraphneural [147] YIDongyi,DENGGenqiang,DONGChaoxiong,etal.Medical
networks//Proceedingsofthe6thInternationalConference frauddetectionalgorithmbasedongraph.JournalofComputer
onLearningRepresentations.Vancouver,Canada,2018 Applications,2020,40(5):1272-1277(inChinese)
易东义 邓根强 董超雄等 基于图卷积神经网络的医保欺
[136] YuB,YinH,ZhuZ.Spatio-temporalgraphconvolutional ( , , .
诈检测算法 计算机应用
networks:adeeplearningframeworkfortrafficforecas- . ,2020,40(5):1272-1277)
ting//Proceedingsofthe37thInternationalJointConference [148] ZhangM,ChenY.Linkpredictionbasedongraphneural
onArtificialIntelligence.Stockholm,Sweden,2018:3634- networks//Proceedingsofthe32ndConferenceonNeural
3640 InformationProcessingSystems.Montreal,Canada,2018:
[137] DiaoZ,WangX,ZhangD,etal.Dynamicspatial-temporal 5171-5181
graphconvolutionalneuralnetworksfortrafficforecasting// [149] KawamotoT,TsubakiM,ObuchiT.Mean-fieldtheoryof
Proceedingsofthe33rdAAAIConferenceonArtificialIn- graphneuralnetworksingraphpartitioning//Proceedingsof
telligence.Honolulu,USA,2019:890-897 the32ndConferenceonNeuralInformationProcessingSys-
[138] LiY,YuR,ShahabiC,etal.Diffusionconvolutionalre- tems.Montreal,Canada,2018:4366-4376
currentneuralnetwork:data-driventrafficforecasting// [150] HeK,ZhangX,RenS,etal.Deepresiduallearningfor
Proceedingsofthe6thInternationalConferenceonLearning imagerecognition//ProceedingsoftheIEEEConferenceon
Representations.Vancouver,Canada,2018 ComputerVisionandPattern Recognition.LasVegas,
[139] KosarajuV,SadeghianA,Martín-martínR,etal.Social- USA,2016:770-778
BiGAT:multimodaltrajectoryforecastingusingbicycle- [151] RanzatoM,BoureauY-L,LeCunY.Sparsefeaturelearn- 计 算 机 学 报 年
68 2022
ingfordeepbeliefnetworks//Proceedingsofthe21stAd- 5998-6008
vancesinNeuralInformationProcessingSystems.Vancou- [153] TangJ,WangM,ZhangM,etal.LINE:large-scaleinfor-
ver,Canada,2007:1185-1192 mationnetworkembedding//Proceedingsofthe24thInter-
[152] VaswaniA,ShazeerN,ParmarN,etal.Attentionisall nationalConferenceonWorldWideWeb.Florence,Italy,
youneed//Proceedingsofthe31stAdvancesinNeuralIn- 2015:1067-1077
formationProcessingSystems.LongBeach,USA,2017:
WU Bo ZHANG Shu-Sen
,Ph.D.candidate.Hisre- ,Ph.D.candidateHisresearchinter-
searchinterestsincludegraph neural estsincludedataminingandsocialcomputing.
XU Rui
networkanddeeplearning. ,Ph.D.candidate.Hisresearchinterestsin-
LIANG Xun
,Ph.D.,professor,Ph. cludeimageprocessingandmachinelearning.
D.supervisor.Hisresearchinterestsin-
cludeneuralnetworks,socialcomputing
andnaturallanguageprocessing.
Background
Overthepastfewyears,moreandmoregraph-structure researchresultsinGNN.Theauthorsfirstlookbackonthe
dataemergeinreallife,suchasInternetnetwork,socialnet- historyofGNNanddevelopmentsinrecentyears.Thenthey
work,proteinnetwork,compoundmoleculesandothers. giveanintroductionoftherelatedconceptsanddefinitions
Duetoitscomplexityandheterogeneity,graph-structureda-
usedinGNNmathematicalreasoning.Theauthorsdiscuss
taishard to mod el .Ba sed on thisur gentnee d,GNN was andanalyzedifferentvariantsofGNNandlistcoreideas,
proposed andt rytofind ou tthegra php attern. Thro ugh joint
learningmethodsandsoonforeachtypeofGNN.Onthis
effor ts,GNNcon tinu etodeve lopa ndimpro vean dits excel- basis, the authors compare GNN with other graph learning
lentperformancehasarousedhighattentionanddeepexplo-
algorithmandpointouttheadvantagesanddisadvantagesbe-
ration.
tweenthem.Theauthorsalsoelaboratethespecificapplica-
Asakindofgraphlearningalgorithm,GNNhasstrong
tionofGNNindifferentscientificfieldsandexplainhow
abilitytolearngraph.Bymakingcertainstrategiesonthe
GNNworks.Duringtheendpartofthispaper,theauthors
nodesandedgesofthegraph,GNNtransformsthegraph-
outlinesthefuturedirectionanddevelopmenttrendofGNN
structuredataintostandardrepresentation,soastobeinput
whichmeansprobablesolutionstotheexistingproblemsand
intoavarietyofdifferentneuralnetworksfortraining,anda-
challenges.
chieveexcellentresultsintaskssuchasnodeclassification,
ThisworkissupportedbytheNationalNaturalScience
edgeinformationdisseminationandgraphclustering.GNN
FoundationofChina(No.62072463,No.71531012),the
canlearntheinternalrulesanddeepergraphrepresentationof
National Social Science Foundation of China (No.
nodeand edge feature sing raph-stru cturedataw henit is
comparedwithothergraphlearningalgorithms.Withits
18ZDA309),theNaturalScienceFoundationofBeijing(No.
strongnonlinearfittingabilitytograph-structuredata,it 4172032),theE-commerceResearchProjectofJingdong
makesGNNhavehigheraccuracyandbetterrobustnesson Mall(No.413313012),andtheOpenProjectoftheState
graph-structurerelatedproblemsindifferentfields. KeyLaboratoryofDigitalPublishingTechnologyofPeking
Thispaperprovidesacomprehensivereviewofexisting UniversityFounderGroupCo.,Ltd. --------------------------------------------------------------------------------- 计算机科学与探索 1673-9418/2023/17(10)-2278-22
JournalofFrontiersofComputerScienceandTechnology doi:10.3778/j.issn.1673-9418.2302059
图神经网络在知识图谱构建与应用中的研究进展
许鑫冉1+，王腾宇2，鲁 才3
1.电子科技大学 资源与环境学院，成都 611731
2.中国石油天然气股份有限公司塔里木油田分公司 勘探开发研究院，新疆 库尔勒 841000
3.电子科技大学 信息与通信工程学院，成都 611731
+通信作者 E-mail:xdsxxr@163.com
摘 要：作为知识的一种有效的表征方式，知识图谱网络可以用于表示不同类别之间丰富的事实信息，成为有
效的知识管理工具，并在知识工程和人工智能领域的应用和研究取得了较大的成果。知识图谱通常表现为一
种复杂的网络结构，其非结构化特点使得将图神经网络应用于知识图谱的分析和研究成为学术界的研究热
点。旨在对基于图神经网络的知识图谱构建技术提供广泛、全面的研究，以解决两类知识图谱构建的任务，包
括知识抽取（实体、关系和属性抽取）和知识合并与加工（链接预测、实体对齐和知识推理等），通过这些任务，
可以进一步完善知识图谱的结构，并能够发现新的知识和推理关系。还研究了基于高级的图神经网络方法用
于知识图谱相关的应用，如推荐系统、问答系统和计算机视觉等。最后提出了基于图神经网络的知识图谱应
用的未来研究方向。
关键词：知识图谱；图神经网络；构建技术
文献标志码：A 中图分类号：TP391
Research Progress of Graph Neural Network in Knowledge Graph Construction and
Application
XU Xinran1+,WANG Tengyu2, LU Cai3
1. College of Resources and Environment, University of Electronic Science and Technology of China, Chengdu
611731,China
2. Research Institute of Petroleum Exploration and Development of Tarim Oilfield Company of PetroChina
CompanyLimited,Korla,Xinjiang841000,China
3. School of Information and Communication Engineering, University of Electronic Science and Technology of
China,Chengdu611731,China
Abstract: As an effective representation of knowledge, knowledge graph network can be used to represent rich
factual information between different categories and become an effective knowledge management tool. It has
achieved great results in the application and research of knowledge engineering and artificial intelligence. Know-
ledge graph is usually expressed as a complex network structure. Its unstructured characteristics make the applica-
tion of graph neural network to the analysis and research of knowledge graph become a research hotspot in
academia. The purpose of this paper is to provide extensive research on knowledge graph construction technology
based on graph neural network to solve two types of knowledge graph construction tasks, including knowledge
基金项目：国家自然科学基金（41974147）。
ThisworkwassupportedbytheNationalNaturalScienceFoundationofChina(41974147).
收稿日期：2023-02-23 修回日期：2023-06-01 许鑫冉 等：图神经网络在知识图谱构建与应用中的研究进展 2279
extraction (entity, relationship and attribute extraction) and knowledge merging and processing (link prediction,
entity alignment and knowledge reasoning, etc.). Through these tasks, the structure of knowledge graph can be
further improved and new knowledge and reasoning relationships can be discovered. This paper also studies the
advanced graph neural network method for knowledge graph related applications, such as recommendation system,
question answering system and computer vision. Finally, the future research directions of knowledge graph
applicationbasedongraphneuralnetworkareproposed.
Keywords:knowledgegraph;graphneuralnetwork;constructiontechnology
知识图谱的概念最早在2012年由Google提出， 图谱在构建和推理的准确性和鲁棒性，并应用于下
随后在工业界和学术界掀起了热潮。在数据库技术 游任务中，如推荐系统[13]、自然语言处理[14]、计算机视
和Web应用的快速发展下，数据呈现了爆炸式增长， 觉[15]等，提高在下游应用场景中的效率。
并产生了大量有价值的知识，传统的数据库技术已 近几年的综述文章，侧重于对早期的知识图谱
无法满足现有市场环境中不断扩大的应用需求。大 嵌入[16]和应用[17]进行全面的总结，或者针对图神经网
量研究人员在知识工程的基础上，通过引用语义上 络[18]现有的方法进行全面论述，介绍各个图神经网络
有意义的元数据，将实例数据同上下文结构集成，从 模型，较少涉及图神经网络在知识图谱公开数据集
非结构化和半结构化数据中提取出有用的知识信
上进行广泛且深入的研究。譬如，文献[19]图神经网
息[1]，推动了知识图谱在人工智能领域的应用。近年 络应用于知识推理进行了综述，按照图神经网络模
型对知识推理研究进行了分类，并着重介绍了知识
来，开发了大量有意义的大型知识库，如YAGO（yet
推理在医学、军事等领域的应用；文献[20]对2019年
another great ontology）[2]、Freebase[3]、DBpedia[4]等，存
到2022年知识图谱的构建相关工作进行了综述，梳
储公共知识的结构化信息。
理了知识抽取、知识融合和知识推理三类知识图谱
但是，由于知识图谱系统存在数据稀疏问题，使
构建的研究工作，并进行了分析和讨论；文献[21]对
得大规模知识图谱计算和管理存在困难，为了解决
知识图谱增强的图神经网络进行了研究；文献[22]面
该问题，提出了知识图谱嵌入的思路，将知识图谱的
向图神经网络的知识图谱嵌入研究进展进行了综
实体和关系嵌入到低维连续的实体向量空间中，并
述，将模型框架分为图卷积网络、图神经网络、图注
参与知识图谱构建。知识图谱构建的关键在于信息
意力网络和图自编码器的知识图谱嵌入研究，分析了
抽取[5]和知识合并与加工[6]两部分。信息抽取是知识
图神经网络参与知识图谱嵌入研究的优势；文献[23]
图谱中基础的操作，从非结构化和半结构化数据中
开放领域知识图谱问答研究综述，将知识图谱的问
提取知识。同时，知识图谱总是不完整的，常常存在
答系统分为基于规则的知识图谱问答和基于深度学
很多缺失信息，需要对知识图谱的信息融合和加工，
习的知识图谱问答系统，对2021年以前的问答系统
在此基础上提出了链接预测[7]、实体对齐[8]、实体消
进行了深入研究。其余知识图谱相关的研究可以归
歧[9]、知识推理[10]等任务。
纳为两类（表1）：知识图谱构建研究工作（知识图谱
图神经网络（graph neuralnetwork，GNN）作为深
表示学习、实体对齐、知识推理等）[24]和知识图谱应用
度学习的热点之一，归结为其强大的数据处理能
相关研究（推荐系统、问答系统等）[25]。
力。首先，图神经网络扩展了现有的马尔可夫链路
虽然上述已有诸多文献对知识图谱相关工作进
模型和递归神经网络模型方法来处理图域中的数
行研究[26]，但仍缺乏图神经网络参与知识图谱构建广
据，保留了二者的特征，能够处理现实中大多数可用
泛而又系统的研究，深入且详细的梳理工作。与其
的数据类型，实现将一个图及其节点映射到一维的
他综述不同的是，本文主要关注图神经网络参与知
欧几里德空间[11]；其次，GNN模型能够保留图上的结
识图谱构建和应用中的研究，对近三年的文章进行
构信息，通过消息传递规则来捕获图上的依赖关系，
深入分析，并提出了一些现存的问题和未来的研究
达到聚合邻域信息迭代更新的目的[12]。近年来，很多
方向，本文脉络框架如图1所示。本文面向图神经网
研究人员尝试将图神经网络应用到知识图谱处理 络参与知识图谱构建工作进行了系统的总结，并涵
中，借助其强大的处理结构化数据的能力，提高知识 盖了近几年的最新研究。本文的贡献总结如下： 2280 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(10)
表1 近三年知识图谱相关文献
Table1 Literaturerelatedtoknowledgegraphinrecentthreeyears
分类 子分类 文献及发表年份
实体对齐
参与知识图谱构建方法类综述 知识推理 [24（] 2021）、[26](2019)、[27（] 2022）、[28（] 2022）、[29（] 2022）、[30（] 2023）、[31（] 2022）
表示学习
问答系统
[32（] 2022）、[33（] 2023）、[34（] 2023）、[35（] 2023）、[36（] 2021）、[37（] 2020）、[38（] 2023）、
知识图谱应用类综述 推荐系统
[39（] 2022）
药物预测
语义匹配模型、神经网络模型和图神经网络模型，如
表2所示，列举了常见的知识图谱表示学习模型，并
给出了各个模型的优缺点。
翻译模型将关系解释为对隐藏实体表示的简单
平移并试图找到与实体平移相关的实体的低维向量
表示。TransE[40]是最常见的翻译模型之一，TransE模
型将关系表示为实体之间的平移操作，即将头实体
与关系向量相加得到尾实体。它的目标是最小化平
移后的头实体与尾实体之间的距离，其中实体和关
系都被建模成同一空间中的向量，但是在对于一对
多和多对多关系时表现不佳，为此提出了一系列扩展
模型，如TransH[41]、TransD[42]、TransR[43]、TransM[44]等。
语义匹配模型使用张量积来捕获丰富的交互，
试图将实体的潜在语义与关系联系起来。如Compl-
图1 基于图神经网络的知识图谱构建及应用 Ex[45]和DistMult[46]等。ComplEx模型扩展了DistMult
Fig.1 Constructionandapplicationofknowledge 模型，使用复数向量表示实体和关系。它通过在实
graphbasedongraphneuralnetwork 体和关系的复数向量之间进行乘法操作来计算得
分，可以更好地捕捉实体和关系之间的多样性和对
（1）对知识图谱构建中的相关任务进行分类整
称性。上述嵌入方法通常不适用于巨大的 KG
理，类别包括知识抽取中的实体、关系和属性抽取，
（knowledge graph），因为它们需要增加KG嵌入的维
以及知识合并与加工中的链接预测、知识推理、实体
度以增强其表现力。
对齐等，探索了基于图神经网络的最新研究方法；
神经网络方法使用不同的神经网络模型从纯嵌
（2）对链接预测模型文献进行了系统的分类整
入中获得表达表示，具体来讲ConvE[47]和ComKB[48]
理，类别包括图卷积网络模型、图注意力网络模型、
是一种基于卷积神经网络的知识图谱表示学习模
子图提取模型和曲率空间模型，阐述并比较了不同
型，它将实体和关系映射到二维矩阵中，并通过卷积
链接预测方法的原理及优缺点；
操作来计算实体和关系之间的语义关系，能很好地
（3）梳理了基于图神经网络方法在知识图谱应
应对参数量大的问题。
用方面的相关文献和探索了本研究未来发展前景。
近年来，图神经网络（GNN）因其强大的特征提
取能力被广泛应用于知识图谱嵌入，大多数基于
1 知识图谱表示学习
GNN的知识图谱表示学习模型使用聚合运算从三元
知识图谱表示学习（knowledgegraphembedding, 组中提取潜在信息，通过使用KG中的拓扑结构来学
KGE）旨在将知识图谱映射到低维连续向量空间中， 习强大的嵌入[49]。GNN通常通过聚合和传播图中的
并为下游任务提供统一的底层表示。现有的知识图 节点特征来更新节点表示。与传统嵌入不同，GNN
谱表示学习模型分为四类，分别包括基于翻译模型、 能够进行端到端的监督学习，获取知识图谱的语义 许鑫冉 等：图神经网络在知识图谱构建与应用中的研究进展 2281
表2 知识图谱表示学习模型
Table2 Knowledgegraphrepresentinglearningmodel
模型 主要模型 理论 优点 缺点
翻译模型将关系解释为对隐
TransE[40]、TransH[41]、
翻译模型 藏实体表示的简单平移并将 嵌入尺寸越小，效果越好；参数 翻译和转换要求相对
TransD[42]、TransR[43]、
（2013—2015年） 测量事实的合理性利用基于 数量少 严格，无法处理噪音
TransM[44]
距离的评分函数衡量
基于相似度的评分函数用于
语义匹配模型 ComplEx[45]、 匹配向量空间中实体的潜在 参数量少，可扩展性强，泛化能 线性模型结构难以捕
（2016—2017年） DisMult[46] 语义以及实体与关系嵌入向 力强 捉非线性语义关系
量之间的相互作用
使用非线性变换来表征输入
神经网络模型 表达能力强，推理效果好，泛化 参数量大，三元组之间
ConvE[47]、ComKB[48] 数据从原始分布到另一个特
（2018年） 能力强 的语义关系被忽略
征空间
获取知识图谱的语义和结构信
R-GCN[49]、
根据消息传递规则，具有相 息；能够处理复杂的实体和关 对存储空间要求高；考
图神经网络模型 RA-GCN[50]、
似邻域信息的实体在空间上 系；能够通过引入注意力机制、 虑多跳邻域信息时，易
（2018年至今） TransE-GCN[51]、
紧密嵌入 跨层连接等方法来提高模型性 于平滑；可解释性较差
KE-GCN[52]
能，适应各种复杂场景
和结构信息，并通过模型的自由参数共享学习的知 系和属性信息的抽取等，在实体抽取和属性抽取方
识，如图2所示，为图神经网络模型及其隐藏层数据 面，图神经网络的研究相对较少，因此信息抽取方面
嵌入信息。这使它们能够获得更具表现力的表示并 主要侧重于关系抽取的研究。
降低嵌入的维数，同时减少性能下降，可以执行各种 2.1.1 实体抽取
分类及推理任务；其次图神经网络能够处理知识图 实体抽取在知识图谱中指从原始语料库中自动
谱中实体和关系之间复杂的关系结构，有效地捕捉 识别出命名实体，因为实体是知识图谱处理的最基
语义特征和结构信息；最后图神经网络适应性强，能 本的元素，所以实体抽取的准确性将直接关系到后
够通过引入注意力机制、跨层连接等方法来实现模 续知识库的质量，对学习知识图谱起到关键性的作
型性能的提升，并能够适应复杂的应用场景。 用。实体抽取的方法可以归纳为三种：（1）基于规则
的方法，该方法的特点是在限定的语义和文本邻域
的条件下进行，在定义好的规则下抽取出实体信息，
但是该方法大量依赖专家的经验，很难适应各种变
化数据的新要求；（2）基于统计学习的实体抽取方
法[54-55]，将命名实体识别问题视为序列标注问题，使
用部分标注或完全标注的语义信息进行训练；（3）基
于深度学习的方法[56-57]，深度学习对于复杂非线性问
题具有较好的拟合能力，能够学习到复杂的特征。
图2 GNN网络及隐藏层数据形式 目前在实体抽取方面，图神经网络研究较少，传
Fig.2 DataformofGNNnetworkandhiddenlayer 统的基于深度学习和机器学习的方法，在实体抽取
方面已经取得了很好的效果，图神经网络尚在发展
2 基于图神经网络的知识图谱构建 阶段，相信不久的将来图神经网络在实体抽取方面
2.1 信息抽取 也会有相应的探索。
信息抽取的关键在于从结构化和非结构化的数 2.1.2 关系抽取
据中抽取出结构化的实体及关系信息，为查询、组织 关系抽取经典的方法是基于依赖树的方法挖掘
和数据分析开辟新途径[53]，是知识图谱构建过程中重 语义信息，关系抽取从抽取类型来看，可以分为基于
要的一环，信息抽取在知识图谱中主要包含实体、关 句子级别的关系抽取和基于文档级别的关系抽取。 2282 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(10)
C-GCN[58]是一种新颖的基于上下文的图卷积网络的 识别句子中的关系并对齐到知识图谱中。上述研究
方法用于关系抽取，有效地将信息汇集在任意依赖 大多存在依赖树的噪声，特别是当依赖树自动生成
树中的关系结构上。如图3所示，使用一种新颖的以 时。A-GCN（attentive graph convolutional networks）[62]
路径为中心的剪枝技术，在最大限度保留相关内容 基于图卷积网络的注意机制考虑到单词之间的依赖
的同时，从树中删除无关的信息，提高建模的鲁棒 关系类型及重要的上下文指导，有助于关系的提取。
性，实体之间的依赖关系用粗体表示，通过使用以路 以上模型都是基于句子级别的关系抽取，实现
径为中心的剪枝技术，使用图卷积网络进行关系提 更加完备的知识理解需要多个句子实现句子间的关
取，在不忽略关键信息的基础上删除无关信息。同 系捕获，文献[63]提出了面向边缘的图神经网络模
样基于依赖树的另一种方法为 Guo等人提出的 型，实现文档级别关系的提取，实体之间的关系使用
AGGCN（attentionguidedgraphconvolutionalnetworksfor 节点之间路径形成的唯一的边来表示。GCNN
relation extraction）[59]，以完整的依赖树作为输入，采 （geneticconvolutionalneuralnetwork）[64]、GLRE（global-
用注意力机制用一种软加权策略来自动学习如何选 to-local neural networks for document-level relation
择有助于关系提取任务的句子，这种方法充分利用 extraction）[65]、dialog-HGAT（dialogue relation extraction
有用的信息，忽略无用的信息，但是破坏了原始依赖 with document-levelheterogeneous graph attention net-
树的结构信息。为解决这个问题，Sun等人提出LST- works）[66]模型侧重于模型优化和实体集上下文的细
AGGCN[60]，在不破坏原始依赖树结构的基础上，利用 粒度实现对文档的语义信息的使用，进行关系抽
注意力机制聚合分类任务中不同传播层次的最终表 取。上述方法大多不考虑对文档级别图的推理，图
示，图中的节点和边缘将得到不同的权值，同样也能 聚合推理网络（graph aggregation-and-inference net-
够实现有效信息的有效利用，忽略无用信息。Bastos work，GAIN）[67]，使用一种新的路径推理机制来推断
等人提出RECON（relation extraction using knowledge 实体之间的关系，异构的MG（mention-level graph），
graphcontext）[61]新方法，使用图神经网络学习存储在 它带有一个基于图的神经网络，用于对文档中不同
知识图谱中的句子和事实的表示，该方法可以自动 提及之间的交互进行建模，并提供文档感知提及表
示，实验表明，该增益模型具有良好的性能，不仅能
够准确识别关系抽取，还能提高知识图谱的可解释
性。同样，KRST[66]也通过引入关系路径覆盖和关系
路径置信度的概念，在模型训练前过滤不可靠路径，
以提高模型性能。
通过上述对关系抽取研究，如表3所示，可以通
过挖掘句子之间和句子之间的关系路径来实现关系
抽取，来提高知识抽取的可解释性和充分发挥图神
经网络挖掘图结构信息的优势。
2.2 知识合并及加工
2.2.1 链接预测
图3 基于上下文的图卷积网络的方法用于关系抽取 尽管在创建和维护上投入了大量努力，但大多
Fig.3 Context-basedgraphconvolutional 数现有的知识图谱还是不完整的，从而导致下游任
networksusedforrelationextraction 务执行时性能略差。为了避免这种情况，需要对知
表3 关系抽取模型
Table3 Relationalextractionmodel
模型 核心思想 代表模型及发表年份
C-GCN[58](2018)、AGGCN[59](2019)、LST-AGGCN[60](2020)、
句子级别关系提取 重点是识别或预测一个句子中的关系
RECON[61](2021)、A-GCN[62](2021)
在该任务中，整个相关信息将离散或连续地分布 GCNN[64](2019)、GLRE[65] (2020)、dialog-HGAT[66](2023)、
文档级别关系提取
在多个句子中，需要识别句间和句内的关系 GAIN[67](2020)、EoGANE[68](2020)、LSR[69](2020) 许鑫冉 等：图神经网络在知识图谱构建与应用中的研究进展 2283
识图谱进行链接预测，也称为知识库完成，根据给定 表5 链接预测模型关键信息
的事实推断缺失的事实，如图4所示，为知识图谱链 Table5 Linkpredictionmodelkeyinformation
接预测的通用流程。通过输入原始知识图谱，图神 嵌入 关系 结构 属性 额外
模型 年份
模块 注意力 信息 信息 信息
经网络作为编码器[70]，生成实体及关系级别的知识嵌
R-GCN[49] GCN 2017 × ×
入，最后使用不同的解码器实现链接预测，目前几乎 √ √
RAGAT[73] GCN 2021
√ √ √ √
所有主流的基于图神经网络的链接预测模型都遵循
SACN[71] GCN 2020 ×
√ √ √
图4所示的编码器-解码器架构。现将链接预测模型
M-GNN[72] GCN 2019 × × ×
√
大致分为四类，具体如表4和表5所示，对各个模型 GRAIL[78] GNN 2020 × ×
√ √
的特点及其优缺点进行介绍，并列举了各个模型用 RGHAT[75] GCN 2020 ×
√ √ √
到的信息。 DPMPN[79] GNN 2019 × ×
√ √
INDIGO[77] GCN 2021 × ×
√ √
Gw-Dsgm[83] GNN 2019 × ×
√ √
M2GNN[81] GNN 2022 ×
√ √ √
SEG[84] GNN 2022 × ×
√ √
HyGCE[82] GNN 2023 ×
√ √ √
LCILP[80] GNN 2023 ×
√ √ √
PAGE-link[85] GNN 2023 ×
图4 链接预测通用模型框架 √ √ √
ExpressGNN[86] GNN 2023 ×
Fig.4 Commonmodelframeworkforlinkprediction √ √ √
RPGAMQ[87] GNN 2022
√ √ √ √
（1）基于卷积神经网络模型。R-GCN（relational T-GAP[88] GNN 2021 ×
√ √ √
graph convolutionalnetworks）[49]用图神经网络实现链 CogQA[89] GNN 2022 ×
√ √ √
接预测任务的模型，如图5所示，显示的知识图谱表 Deep-IDA[90] GNN 2021
√ √ √ √
RED-GNN[91] GNN 2022 ×
示中单个节点信息更新的过程，从相邻的蓝色收集 √ √ √
信息，聚合更新到红色节点的表示中，通过下游任务 如： 平等地对待邻域中不同的实体； 表征能力
① ②
不断迭代更新，直到节点向量达到不动点，在知识图 低、叠加平直和对噪声的鲁棒性差； 不涉及向量化
③
表示学习之后使用DisMult解码器为图中每个潜在 的关系嵌入。针对第一个问题，Shang提出了SACN
的边生成可能性评分，最终挑选出最具可能性的边 （structure-aware convolutional networks）模型[71]，相较
的预测。虽然R-GCN模型有效聚合了邻域信息，实 于R-GCN在相同关系的实体聚合上引入了加权
现信息的迭代加强，但是该模型也存在一些不足，比 GCN来对相邻实体之间的关系进行定义，核心思想
表4 链接预测模型分类
Table4 Linkpredictionmodelclassification
方法 模型及发表年份 原理 优点 缺点
R-GCN[49](2018)、SACN[71] 等价聚合邻域节点信
提高了图分析的效率，实 对噪声的鲁棒性差，叠加平
图卷积网络模型 (2020)、M- GNN[72] (2019)、 息，实现邻域信息的
现起来相对简单 滑，没有向量化的关系嵌入
RAGAT[73](2021) 聚合
捕获具有不同关系路 实现向量化关系嵌入，在 需要加载完整的打分函数，
KBAT[74] (2019)、RGHAT[75]
径和不同节点的重要 图表中保留更多信息，便 可扩展性差；使用图神经网
图注意力网络模型 (2020)、HRAN[76] (2022)、
性，以捕获知识图结 于捕获知识图谱结构的异 络对模型的提升效果有限，
INDIGO[77](2021)
构的异质性 质性 需要进一步提高注意力机制
提取两个节点周围的 可解释性强，可以保留图
GraIl[78] (2020)、DPMPN[79] 时间复杂度更高，不易提取
子图提取模型 封闭子图结构，预测 中更多信息，可以建模拓
(2019)、LCILP[80](2023) 子图信息
两个节点之间的关系 扑结构信息
将知识图谱嵌入到曲
改进的多图表示，多图表
M2GNN[81](2021)、HyGGE[82] 率空间中，而不是传 需要额外的数据分析，需要
曲率空间模型 示效果很好，更好地捕获
(2023) 统的欧几里德空间 准确定义到准确的曲率空间
异构结构
中，以获取层次结构 2284 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(10)
机制，获得不同关系路径的重要性。和上述模型不
同的是，它能够捕获各种类型的语义信息，并且可以
有选择性地对特征信息进行有效的聚合，在链路预
测任务上实现了鲁棒性的效果。Liu等人提出INDIGO
（inductive knowledge graph completion）模型[77]，KG
以透明的方式完全编码为GNN，并且预测的三元组
可以直接从GNN的最后一层读出，而无需额外的组
件或评分函数。通过图注意力网络，让知识图谱的
实体通过多次迭代聚合操作，更高效地使知识图谱
上所有不同距离的实体通过边互相分享其带有的信
息，辅助完成预测推理工作。
（3）基于子图提取模型。通常三元组的预测依
赖于其常量在输入KG中的独立邻域，但没有考虑到
这些邻域的共同部分是什么，因此提出了构造局部
子图的方法。Teru等人提出GraIL（graph inductive
relation）模型[78]，通过提取两个节点周围的封闭子图
结构来预测两个节点之间的关系，并以类似于R-
GCN的方式对其进行编码，并使用评分函数对其专
用子图中所有节点的输出向量进行全局应用，从而
图5 关系图神经网络模型
对这个三元组进行预测。Xu 等人提出 DPMPN
Fig.5 Relationalgraphneuralnetworkmodel
（dynamically pruned message passing network）[79]，通
是利用节点的结构和属性信息，以及关系类型捕获 过修改给定查询的不相关实体来构造局部子图，对
知识图谱中的结构信息，最终传入解码器来进行链 GNN模型做的预测提供一些解释，而不是将GNN视
接预测任务；针对第二个问题，Wang等人提出了M- 为一个黑盒子，在这些子图中，可以对每个节点使用
GNN（multi-level structures graph neural network）模 注意力权值进行差分着色，从而可以看到哪些节点
型[72]，该模型对于不同的关系拥有不同的权重，邻域 对于预测是重要的。GraIL[78]模型不需要经过训练的
聚合时引入多层感知机（multilayer perceptron，MLP） 嵌入就可以对子图做归纳式推理，这就使得对于未
弥补R-GCN表征能力低、叠加平直和对噪声的鲁棒 知节点也可以使用图结构进行打分，但是在子图抽
性差的问题，对图上的多个GNN进行堆叠，对原始图 取和子图标签中复杂度较高，不适合在大规模图中
的多层次结构进行建模；针对第三个问题，Liu等人提 应用。针对这个问题，Zhang等人提出RED-GNN
出了RAGAT（relationawaregraphattentionnetwork）[73]， （relational digraph graph neural network）模型[91]，结合
引入了关系特定网络参数，来自适应地研究不同关 基于路径方法的可解释性和基于子图结构的保留特
系下相邻实体的消息，从而弥补了R-GCN网络可扩 性的优点，使用递归和并行计算的方法，使GNN可以
展性差的问题。 一次性建模多个关系子图，在聚合方面是基于实体
（2）基于图注意力网络模型。Luo等人提出的 之间的关系进行消息聚合。他们首先根据k跳邻域，
RGHAT（relational graph neural network）模型[75]，引入 使用图神经网络（GNN）对子图进行编码，然后学习
了实体和关系级别的注意力机制，强调了不同相邻 映射子图结构模式以链接存在的函数。尽管这些方
实体在同一关系下的重要性，即在同一关系下，不同 法取得了巨大的成功，但通常会导致邻域呈指数级
的实体也拥有不同的权重信息。分层注意力机制， 别的扩展，从而由于过度平滑而降低GNN表现力。
使得该模型更为有效地利用邻域信息，但是相应的算 基于此问题，LCILP（locality-aware subgraphs for
法复杂度也会增大。在此基础上，HRAN（hierarchical inductive link prediction）[80]模型将子图提取表述为一
recurrentattention network）模型[76]针对知识图谱中不 种局部聚类过程，旨在基于个性化PageRank方法对
同的关系拥有不同重要性，使用新颖的注意力聚合 目标链接周围紧密相关的子图进行采样。 许鑫冉 等：图神经网络在知识图谱构建与应用中的研究进展 2285
（4）基于曲率空间模型。Wang等人提出的混合 而选出最佳推理路径。由于数据标注成本过高，对
曲率多关系图神经网络（metapath and multi-interest 于监督信号的缺乏成为了重大挑战，可以通过
aggregated graph neural network，M2GNN）[81]，将知识 KGQA（knowledgegraphquestionanswer）模型[87]实现
图谱嵌入到双曲空间中，而非传统的欧几里德空间 将多条知识图谱问答转换为知识图谱中的路径生成
中，便于捕获层次结构。传统的嵌入欧几里德空间 任务。Jung等人提出了T-GAP（time-awareknowledge
的方法忽略了知识图谱的异质性，无法捕捉知识图 graph completion）模型[88]，其编码器和解码器最大限
谱的结构。M2GNN将多关系知识图谱嵌入到混合曲 度地利用时间信息和图结构。T-GAP通过关注每个
率知识空间，来模拟各种结构。缺点是混合曲率空 事件与查询时间之间的时间位移来编码TKG（time-
间曲率需手动定义固定曲率，需要邻域外的知识和 awareknowledgegraph）的特定查询子结构，并通过在
额外的数据分析，如果无法定义到准确的曲率空间 图中传播注意力来执行基于路径的推理，有效应对
就无法准确捕捉知识图谱的结构。为了解决这个问 知识图谱的动态特性和可解释性。Acheampong等人
题，将该混合曲率设置为可以训练的参数，以便更好 提出CogQA（cognitive graph QA）模型[89]，使用BERT
地捕捉知识图谱的底层结构，使用了图神经网络的 （bidirectionalencoderrepresentationfrom transformers）
更新器，可以更好地捕捉知识图谱的底层结构。 输出的若干片段构建一个知识图谱，并利用图神经
Wang等人[82]提出了双曲空间图注意力网络模型 网络的消息传播机制，实现认知图谱的多跳计算。
（hyperbolic graph attention network for reasoning over Deep-IDA（deeppredictingisoform-diseaseassociations）[90]
knowledge graphs，HyGGE），使得限制性能的复杂关 通过结合基于路径的算法支持基于嵌入的方法。首
系在该模型的基础上得到提升。一方面，对邻域结 次将传统的路径搜索算法与深度神经网络相结合进
构和关系特征的关注弥补了嵌入空间完全由三元组 行KG推理。Zhang等人提出RED-GNN[91]方法，利用
单独诱导的奇异性，从而优化了嵌入空间的表达能 动态规划的方法对多个具有共享边信息的有向图进
力；另一方面，它们配合双曲几何的作用，捕获局部 行递归编码，用查询注意力机制选择强相关的边，同
结构中包含的层次特征，从而使双曲嵌入的优势得 时学习到的权重信息可以为知识图谱的推理任务提
到更充分的发挥。 供可解释性证据。
2.2.2 知识推理 2.2.3 实体对齐
知识推理[83]在某种程度上可以看作链接预测的 实体对齐也可称为实体匹配或者实体链接，用
一种，和链接预测不同的是，它是在已有的数据的基 于发现不同知识图谱中指代的具有同一事物的实体，
础上，利用特定的方法来推断新的关系或者识别错 是知识图谱中知识融合的关键技术。传统的知识图
误的信息，以解决知识图谱不完备的问题。知识推 谱对齐技术、基于关系推理和基于相似度计算的方
理可以通过引入马尔可夫逻辑网络和路径机制来提 法等，忽略了知识图谱的结构特性，基于图神经网络
高知识推理的可解释性和鲁棒性。 的实体对齐模型，利用图神经网络来学习知识图谱不
Zhang等人提出ExpressGNN模型[86]，首次将马 同实体的低维向量表示。和传统的基于相似度的方
尔可夫逻辑网络引入到图神经网络中，将概率逻辑 法相比，基于嵌入的方法进行实体对齐任务，解决了
与图神经网络结合起来,从而实现应用少量数据实现 需要大量专家的参与或者由其他用户贡献外部资源
更高的性能，马尔可夫逻辑网络不需要对目标任务 的问题，无需人工设计相似度特征即可实现实体对
使用很多标记。而对于大规模知识图谱推理任务， 齐，表6为基于图神经网络的实体对齐模型，对它们
DPMPN[79]包含两个遵循消息传递神经网络框架的模 注意力机制对象和应用的信息进行了详细的描述。
块，其中一个基于全局的消息传播，另一个基于局部 （1）图卷积网络模型
的信息传播，能有效聚合知识图谱的邻域信息，缓解 图卷积网络模型通过递归聚合邻居节点的特征
规模问题带来的推理效果的影响。 来表征实体，优点是能获得全面、鲁棒的实体表示。
现有的知识推理可以利用关系路径增强推理效 最早使用图神经网络进行实体对齐的是Wang等人
果及可解释性。Lin等人提出基于图的关系推理模 提出的GCN-Align[92]，如图6（a）所示。通过多层GCN
型（KagNet）[26],该模型使用GCN更新知识图谱中的 将实体和属性的信息嵌入低维向量，等效实体期望
实体表示后，利用长短记忆网络为候选路径打分，从 尽可能接近，同时允许编码不同知识图谱的两个 2286 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(10)
表6 实体对齐模型关键信息 等人提出 HGCN（hierarchical graph convolution net-
Table6 Entityalignmentmodelkeyinformation works）[98]，不仅考虑到了异构关系的嵌入，还考虑到
嵌入 关系 结构 属性 额外 聚合邻居节点时可能存在的噪声问题，通过增加
模型 年份
模块 注意力 信息 信息 信息
Highway Gate控制噪声在GCN结构中的传播，使用
GCN-Align[92] GCN 2018 × × ×
√ 实体表示来近似关系表示，从而优化关系对齐的目
RDGCN[93] GNN 2019 ×
√ √ √
标。和前几个模型相似，还有两个模型也考虑到了
HMAN[94] GCN 2019
√ √ √ √
MuGNN[95] GNN 2019 × × 实体关系属性的建模，分别是 Yang 等人提出的
√ √
VR-GCN[96] GCN 2019 × × × HMAN（hybrid multi-aspectalignmentnetworks）[94]，使
√
MRAEA[97] GNN 2020 × × 用一个GCN和两个全连接网络分别对知识图的拓扑
√ √
HGCN[98] GCN 2019 × 结构、关系特征和属性特征进行编码，同时将训练前
√ √ √
SSP[99] GCN 2020 × ×
√ √ 模型BERT纳入框架，进一步提高模型效果。Wu等
NMN[100] GCN 2020 × ×
√ √ 人提出的 NMN（neighborhood matching network）模
RREA[101] GNN 2020 ×
√ √ √ 型[100]通过同时考虑拓扑结构和邻域相似性来估计两
REA[102] GNN 2020
√ √ √ √
个实体的相似性，在使用GCN嵌入的同时采用跨图
AttrGNN[103] GNN 2020 × ×
√ √
AliNet[104] GNN 2020 × × × 注意力机制设计了一个近邻匹配模块来获取邻域实
√
PEEA[105] GNN 2023 × 体之间的差异，以解决知识图谱中普遍存在的邻域
√ √ √
GALA[106] GNN 2023 × × × 异质性。
√
MetaDyGNN[107] GNN 2022 × 在聚合邻域信息的同时，会考虑到邻域多跳邻域
√ √ √
DvGNet[108] GNN 2023
√ √ √ √ 的信息可否被利用。Sun等人提出AliNe（t alignment
SFEA[109] GNN 2023 ×
√ √ √ network）模型[104]，使用一个全局结构和局部语义保持
GCN模型使用相同的参数，利用实体之间的结构传 网络，以粗到细的方式学习实体表示，通过引入远端
播实体之间的对齐关系。但是该模型只考虑节点级 邻居的注意机制来扩大其邻域结构的重叠，并限制
别的实体对齐，无法对异构数据图进行建模并利用 等效实体对的两个实体在每个GCN层中具有相同的
知识图谱中丰富的关系信息。针对这种情况，Wu等 隐藏状态，最后使用关系损失来细化实体表示。聚
人提出了RDGCN（region-enhanceddeepgraphconvo- 合信息时，AliNet[104]视一个实体的所有单跳邻居同等
lutionalnetworks）模型[93]，通过GCN来实现实体的嵌 重要，但并不是所有的单跳邻居都对目标实体的特
入，并建立知识图谱的对偶关系图，将关系视为节 征化有积极的贡献。因此如果不仔细选择，会引入
点，实体视为边，通过对偶图的约束增强对不同实体 噪声，从而降低性能。上文提出的NMN模型[100]避免
网络结构的判别，极大增加了知识图谱的效率。Wu 了该问题，使用部分预先对齐的实体作为训练数据，
图6 实体对齐模型
Fig.6 Entityalignmentmodel 许鑫冉 等：图神经网络在知识图谱构建与应用中的研究进展 2287
选择信息最丰富的邻居进行实体对齐，极大提高了 究。Zhu等人提出了NAEA（neighborhood-awareatten-
实体对齐的效果。同样的想法，如图6（b）所示，Nie tionalrepresentation）模型[110]，该模型合并了实体的邻
等人提出 SSP（global structure and local semantics- 域子图级信息，通过图注意力网络捕获邻域级信
preserved embeddings）[99]，互补地利用全局结构和局 息。上述模型中，MuGNN[95]、NAEA[110]和MRAEA[97]
部语义来学习鲁棒和准确的实体表示，全局结构和 根据实体之间的关系类型赋予不同的权重系数，使
局部语义可以为实体对齐提供互补的信息：全局结 模型能够区分不同实体之间的重要性。NAEA同时
构可以为实体表示提供全面和健壮的信息，而局部 考虑了单跳邻居对齐，并使用GAT对实体之间的结
语义可以提供细粒度的细节来细化粗粒度的实体 构信息进行编码，从而提升实体对齐的效率。
表示。 从数据集偏差的角度考虑。许多先进的KG嵌
②
在图卷积网络模型进行实体对齐时，通过考虑 入模型都有一个共同的思想，将实体嵌入转化为特定
邻域信息来聚合实体及关系的特征，同时，会考虑到 关系的嵌入。Mao等人提出RREA（relationalreflection
单跳和多跳邻域信息来实现高效的特征聚合过程， entity alignment）模型[101]，指出它们的变换矩阵很难
提高实体对齐的效率。 符合正交性质，这就是它们在实体对齐方面表现不
（2）图注意力网络模型 佳的根本原因。RREA模型采用一种称为关系反射
从注意力机制角度考虑。图注意力网络通过 的新转换操作来满足实体对齐的理想转换操作的两
①
对边缘赋予不同的权重信息，如图7所示，来实现对 个关键标准：关系分化和维度等距，提高实体对齐的
有用信息的高效处理。Ye等人提出AVR-GCN（a 准确性。Liu 等人提出 AttrGNN（attributes graph
vectorized relational graph convolutional network）模 neural network）模型[103]，集成属性和关系三元组，采
型[96]，采用不同于传统GAT的邻域特征融合方法，与 用不同的重要性，以获得更好的性能，该模型可以有
TransE模型一样，实体的不同邻居通过添加（或减去） 效地缓解严重的数据集偏差，取得显著的改进效果。
不同的关系向量来合并和表示，从而更直接地将邻 从噪声的角度考虑。Pei等人提出REA（robust
③
域关系引入模型中。Mao等人提出MRAEA（meta entity alignment）模型[102]，使用GNN嵌入，假设人工
relation aware entity alignment）[97]，采用不同于AVR- 标记的对齐实体对在真实的实体对齐任务中可能有
GCN的方法，在图神经网络的框架下考虑实体之间 噪声，噪声检测模块采用生成式对抗网络来达到降
的关系，将关系划分为若干元关系，学习彼此之间的 噪的目的。Chen等人提出SS-AGA（self-supervised
注意参数，并将其集成到实体表示中，最后对模型进 adaptive graph alignment）模型[111]，将对齐实体视为一
行半监督训练。Cao等人提出多通道图神经网络模 种新的边缘类型，引入关系感知的图注意力机制来
型MuGNN（multi-channelgraphneuralnetwork）[95]，在
控制知识传播和噪声影响，并使用新的具有自我监
GNN模型的基础上，使用多个通道稳健地编码两个
督的对齐生成机制来缓解种子对齐的稀缺性。
知识图谱，在每个通道中添加自注意力机制和图交
2.2.4 实体消歧
叉知识图谱注意力机制，采用图池化操作对二者进
实体消歧不同于实体对齐，实体消歧需要将文
行彻底集成，该模型发现了知识图谱矩阵的结构不
本内容中提及的实体链接到文本内容中所提到的实
完备性，并针对基于规则的KG矩阵完备性进行了研
体，实体对齐是将两个多结构化的知识图谱或知识
图谱中的实体进行等价对齐。知识图谱利用图神经
网络（GNN）进行实体消歧，能更好地实现对图结构
数据的特征表示。Hu等人提出GNED（graph neural
entity disambiguation）模型[112]，是一种端到端的利用
图神经网络进行实体消歧的模型，充分利用全局语
义信息通过为每个文档建立一个异构实体单词图，
来模拟同一文档中候选实体之间的全局语义关系，
将图卷积神经网络用于实体子图上来生成编码全局
图7 实体对齐模型SSP 语义的增强型实体嵌入，最终送入CRF（conditional
Fig.7 EntityalignmentmodelSSP random field）中进行实体消歧。Li等人针对现有的 2288 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(10)
实体消歧中存在信息利用不充分、准确率低等特点， 其数量从1 345个减少到237个，便于模型更好地学
提出一种基于常用实体关系图的实体消歧方法，通 习和推理。
过路径长度和个数实现连接强度和阈值的比较，最 （4）WN18：WN18是一个英语词汇数据库，包含
终实现实体消歧[113]。为应对互联网中内容模式的增 大量的单词、同义词和词汇间的语义关系。WordNet
加，提出 MMGraph（multi-modal graph convolution 中的单词被组织成一个层次结构，其中每个单词都
network）模型，使用多模态图卷积网络来聚合上下文 与其他单词之间存在不同类型的关系。WN18是一
语言信息，加上自监督的三元组网络，在多模态无标 个用于链接预测任务的基准数据集，其中包含有
签数据中学习知识表示，来进行实体消歧，为后续语 40943个实体和93003个三元组。
义网建模提供了思路。 （5）FB15K：FB15K是一个基于Freebase知识图
2.3 数据集分析 谱数据集的链接预测任务数据集。FB15K是一个用
本节将全面介绍在图神经网络参与知识图谱构 于链接预测任务的基准数据集，其中包含有14 951
建任务中使用的数据集，因为在设计关系提取模型 个实体和592213个三元组。
之前需要确定该数据集。本文总共调查了7个数据 （6）YOGO3-10[114]：YOGO3-10是一个日本语言
集，并统计了7个常用的关系提取数据集的细节，如 的知识图谱数据集，包括人物、地点和组织机构等。
表7所示。本节还介绍了数据集的局限性。 该数据集可以用于实现文本到知识图谱的实体链接
（1）WN18RR：WordNet 18（简称WN18）是一个 任务。
英语词汇数据库，包含大量的单词、同义词和词汇间 （7）DBP15K[4]：DBP15K是南京大学提出的，用
的语义关系。WN18RR是对WN18数据集的重新 于跨语言实体对齐数据集，其中包含ZH-EN、JA-EN、
划分。 FR-EN三种跨语言实体对齐的语料库。
（2）NELL-955：NELL（never-endinglanguagelearner） 这些数据集都是非常有价值的资源，它们可以
是一个自动化的知识抽取系统，旨在从互联网上自 用于支持各种类型的知识图谱构建任务，并且可以
动学习知识。NELL-955是从NELL中提取出来的一 帮助机器理解自然语言文本中的含义。现有的通用
个小型知识图谱数据集，其中实体涵盖了人、组织机 领域数据集并不适用于所有的知识图谱构建研究工
构、地点和其他类型。 作，只适用于一些方法研究。关于垂直领域知识图
（3）FB15K-237：Freebase 15（简称FB15K）是一 谱的构建需要用到领域知识图谱数据集，具有行业
个基于Freebase知识图谱数据集的链接预测任务数 特殊性，无法一一列举。下面列举了现有的图神经
据集。FB15K-237是对FB15K数据集的重新划分， 网络应用于知识图谱构建中常见的数据集会存在的
它只保留那些出现次数大于等于50次的关系，并将 问题：
表7 知识图谱常用数据集
Table7 Commondatasetsofknowledgegraph
数据集 实体 关系 训练集 验证集 测试集 应用
WN18RR 40943 11 86835 3034 3134 知识推理、链接预测
NELL-955 75592 200 149678 543 3992 知识推理、链接预测
FB15K-237 14541 237 272115 17535 20466 知识推理、链接预测
WN18 40943 18 141442 2500 2500 知识推理、链接预测
FB15K 14951 1345 483142 50000 59071 知识推理、链接预测
YOGO3-10 123182 37 1079040 5000 5000 知识推理、链接预测
DBP15K(ZH-EN) 66469 2830 8113 153929 379684 实体对齐、实体消歧
DBP15K(ZH-EN) 98125 2317 7173 237674 567755 实体对齐、实体消歧
DBP15K(JA-EN) 65744 2043 5882 164373 354619 实体对齐、实体消歧
DBP15K(JA-EN) 65680 2096 6066 233319 497230 实体对齐、实体消歧
DBP15K(FR-EN) 66858 1379 4547 192191 528665 实体对齐、实体消歧
DBP15K(FR-EN) 105889 2209 6422 278590 576543 实体对齐、实体消歧 许鑫冉 等：图神经网络在知识图谱构建与应用中的研究进展 2289
（1）数据集噪声：知识图谱数据集中可能包含错 表8 知识图谱应用相关文献
误和不一致的实体和关系标注。这些错误可能会对 Table8 Literaturerelatedtoapplicationofknowledgegraph
模型的性能产生负面影响[83,98,102,111]。 应用 文献及发表年份
（2）数据集分布：知识图谱中的实体和关系并不 KGAT[85（] 2023）、KGCN[115（] 2019）、
DSKReG[116（] 2021）、KQGC[13（] 2022）、
是平均分布的，可能存在一些关系样本非常稀少的情
推荐系统 DisenHAN[117（] 2020）、KR-GCN[118](2022)、
况，这可能导致模型对这些关系的学习效果较差[101]。
HPHS[129](2023)、AHMKR[130（] 2023）、
（3）特征选择：特征工程在知识图谱中的关系预 MI-KGNN[131（] 2023）
测任务中起着至关重要的作用。如果选择的特征不 QA-GNN[14（] 2021）、KG-FiD[122（] 2021）、
文献[123（] 2020）、MHGRN[124（] 2020）、
足或者不合适，可能会导致性能较差[77,82,94]。
Greaselm[132（] 2022）、KE-GCL[52](2021)、
问答系统
（4）算法选择：不同的算法对于不同的数据集通 GrapeQA[119（] 2023）、LMExplainer[121（] 2023）、
常具有不同的表现。可能有一些算法在某些数据集 Graph2Seq[125](2023)、BIGNN-LM-KG[120（] 2023）、
CORN[126](2022)
上表现不佳，但在其他数据集上表现良好[13]。
TS-GCN[15（] 2019）、MetaDyGNN[107](2022)、
（5）数据不平衡性：知识图谱中的实体和关系通
KGNN[127（] 2020）、SumGNN[128（] 2021）、
其他领域
常是不平衡的，即某些实体和关系比其他实体和关 DvGNet[108（] 2023）、TS-GCN[15（] 2019）、
MetaDyGNN[107](2022)
系更常见。这种不平衡性会导致图神经网络在处理
知识图谱时出现偏差或误差等问题。
化为向量；（2）注意力嵌入传播层，递归地从节点的
这些问题都会对图神经网络在知识图谱构建任
邻居传播嵌入以更新其表示，并采用知识感知注意
务中的应用产生影响，因此需要采取一些有效的方
力机制来学习传播过程中每个邻居的权重；（3）预测
法来解决这些问题，例如使用更加鲁棒的模型、采用
层，聚合来自所有传播层的用户和项目的表示，并输
更加有效的数据预处理方法等。
出预测的匹配分数。
Wang等人提出KGCN（knowledgegraphconvolu-
3 基于图神经网络的知识图谱应用 tionalnetwork）[115]是采用图神经网络聚合知识图谱中
3.1 推荐系统 的实体的开创性项目之一，通过基于感知的注意力
图神经网络和知识图谱的结合在下游有很多应 图神经网络层在知识图谱中生成实体和关系的嵌
用，具体见表8，列举了知识图谱常见的应用。推荐 入。Wang等人提出DSKReG（differentiable sampling
系统是互联网发现潜在用户兴趣的必要工具，来自 on knowledge graph for recommendation with relational
知识图谱的信息需要聚合项目之间的相关性来进行 GNN）模型[116]，使用关系图神经网络在知识图谱上进
推荐，GNN的主要特征之一是能够在生成的密集表 行推荐的可微分抽样，从知识图谱中需学习连接项
示中保留邻居之间的结构属性，通常这一操作称为 目的相关性分布，并使用该分布对合适的项目进行
平滑，在存在同质图时特别需要平滑。推荐系统中 推荐，设计可区分的抽样策略使项目在选择和模型
知识图谱的构建分为四步：（1）收集用户信息；（2）收 训练过程共同优化。以往的知识图谱嵌入忽略了图
集购买物品信息；（3）提取用户和物品属性特征； 神经网络出现的平滑性问题，基于此，Kikuta等人提
（4）构建知识图谱，将用户和物品进行相关性连接， 出基于知识查询的图卷积KQGC（knowledge query-
属性被提取为实体连接到用户和项目。输入的知识 basedgraphconvolution）[13]模型，如图8（b）所示，利用
图谱为协同知识图谱，协同知识图谱由用户和项目 图卷积网络的平滑效果增强知识图谱嵌入。Wang等
组成的二部图和项目的附加信息组成的知识图谱结 人提出 DisenHAN（disentangled heterogeneous graph
合组成。 attentionnetworkforrecommendation）模型[117]，为编码
基于图神经网络的知识图谱推荐系统不同点在 用户和项目之间的协作信号，利用嵌入传播来显式
于嵌入操作采用的方式不同。Zhang等人提出KGAT 地合并具有丰富语义结构的上下文信息。利用元关
（knowledge graph attention network）模型[85]，如图8（a） 系分解中的高阶连通性，并提出一个解纠缠的嵌入
所示，由知识图谱嵌入和图神经网络两层组成，将 传播层，分别聚合用户和项目的语义信息的不同方
GNN层应用到TransR中获得知识图谱嵌入基础上， 面，自动生成具有语义信息的元路径。Ma等人[118]设
生成节点嵌入。推荐系统具体操作流程为：（1）嵌入 计了基于图卷积网络的知识感知推理方法，使用一
层，通过保留协同知识图谱的结构将每个节点参数 种基于过渡的方法来确定三元组得分，并利用核抽 2290 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(10)
图8 推荐系统模型
Fig.8 Recommendationsystemmodel
样在每个用户-商品对之间的路径内自适应地选择三 背景知识的问题，而这些知识在问题中并没有明确
元组，为了提高推荐性能和保证解释的多样性，将用 表达出来，需要从外部知识中获取证据，并在证据基
户-物品交互和知识图谱集成到异构图中，通过图卷 础上进行预测。
积网络实现，采用路径层面的自我注意机制，区分不 知识图谱问答目的是利用知识图谱中的事实来
同选择路径的贡献，预测交互概率，提高最终解释的 回答自然语言的问题，它帮助终端用户在不了解知
相关性。 识图谱数据结构的情况下，更有效、更容易地访问
3.2 问答系统 KG中的大量和有价值的知识。
知识图谱最早在自然语言基础上构建发展起 通过结合预训练模型和 KG 实现智能问答。
来，知识图谱在自然语言处理上有着大量的应用，比 Yasunaga 等人提出 QA-GNN（question answering-
如知识问答等任务。常识性问题旨在回答哪些需要 GNN）模型[14]，如图9所示，该模型利用预训练的语言
图9 知识图谱问答系统模型
Fig.9 Knowledgegraphquestionansweringsystemmodel 许鑫冉 等：图神经网络在知识图谱构建与应用中的研究进展 2291
模型及知识图谱的端到端的问答系统模型，在给定 型还使用了节点级别的复制机制，允许将KG子图中
的问答系统上下文的条件下来计算知识图谱节点的 的节点属性直接复制到输出问题中。Guan等人[126]采
相关性，并在问答系统的上下文和知识图谱节点上 用基于Co-Attention Transformer的双向多级连接结
进行联合推理，通过图神经网络的消息传递机制公 构。该结构建立了桥梁，连接了文本编码器和图编
共更新它们的表示。同样的方法Taunk等人[119]提出 码器的每一层，可以将QA实体关系从KG引入到文
了GrapeQA模型，结合预训练模型和知识图谱的推 本编码器，并将上下文文本信息带到图编码器，以便
理能力，通过识别问答系统中的相关文本块和预训 深度交互融合这些特征以形成综合的文本和图节点
练语言模型中的相应潜在表示增强知识图谱，以及 表示，并提出了一种QA感知节点的KG子图构建方
在上下文感知节点修剪和删除与问答系统不相关的 法，QA感知节点聚合了问题实体节点和答案实体节
节点。Yang等人[120]提出了一种基于双模态图神经网 点，并进一步指导子图的扩展和构建过程，以增强连
络的外部知识推理的视觉问答方法。视觉问答是指 通性并减少噪声的引入。上述考虑子图级别的注意
通过计算机视觉和自然语言处理技术，让计算机能 力机制能够充分利用知识图谱中的子图结构信息进
够回答与图像相关的问题。通过双模态图神经网络 行特征融合。
处理图像和文本数据，根据已有的信息和规则，推出 3.3 其他领域
新的结论或答案，这种方法的目的是让计算机能够 图神经网络应用于知识图谱研究除了上述常见
利用外部知识进行推理，提高视觉问答的准确性和 的推荐系统和智能问答外，还可以在药物预测、社交
可靠性。 网络中使用。有的研究需要用到特定领域数据集实
针对大型语言模型（large lauguage models, LM） 现知识图谱的成功应用。如图10所示，通过知识图
的解释问题，虽然这些模型可以处理不同种类的自 谱进行关系预测，得到关系网络中缺失的实体及关
然语言处理（natural language processing，NLP）任务， 系信息。对药物之间的相互作用可以建模为基于知
但由于其多层非线性模型结构和数百万个参数，结 识图谱的链接预测问题，使用基于图神经网络嵌入
果的解释可能很困难。Chen等人利用注意力权重来 的方式用于知识图谱的药物发现，预测的步骤分为
提供模型预测的解释。然而纯基于注意力的解释无 以下三个步骤：（1）从数据源中提取数据，输入三元
法支持模型日益复杂的情况，并且不能推理其决策 组实体-关系数据和药物之间的相互作用矩阵；（2）在
过程，因此提出LMExplainer[121（] 知识增强的解释模 嵌入过程中，使用各种结构的模型来学习知识图谱
块），使用知识图谱（KG）和图注意力神经网络来提取 的表示，使用特定的打分函数和损失函数来进行训
LM的关键决策信号。 练；（3）通过识别三元组是否为给定的事实来实现药物
结合注意力机制实现问答系统。Yu等人提出 预测。KGNN（knowledge graph neural network）[127]、
KG-FiD（knowledge graph in fusion-in-decoder）[122]，解 MGAN（meta-path guided graph attention network）[108]
决了开放邻域问答的任务，在融合译码器框架的基础 和 SumGNN（knowledge summarization graph neural
上，应用图神经网络计算排序得分。Lv等人[123]提出 network）[128]等模型使用图神经网络挖掘药物及其潜
从异构的知识来源中自动获取证据，并提出两个模 在领域知识图谱中的关联关系，其过程本质上类似
块。首先利用图结构重新定义单词之间的距离，后续 于知识图谱的链接预测，通过捕获多跳邻域的相关
采用图卷积网络将邻居信息编码为节点的最终表示 子图，并使用图神经网络进行消息融合，有效地捕获
形式，利用图注意力机制聚合证据预测最终的答案。 药物及其潜在邻域的相关性，实现对药物性能的预
将智能问答从单个KG三元组中生成问题，转换 测，实现药物预测和药物的再利用。上述应用表明
为从一个更复杂的KG子图中生成问题。Feng等人 图神经网络同知识图谱构建相结合，挖掘领域知识
提出了一个多跳图关系网络（MHGRN）[124]，从外部知 图谱中潜在的关联关系，可以是社交网络关系、药物
识图中提取子图执行多跳、多关系推理任务，该模块 关联关系、商品关联关系、问答系统中的语义关系等。
将基于推理的方法和基于图神经网络的方法结合，
具有比较好的扩展性和可解释性。Chen等人[125]采用 4 总结与展望
了双向图到序列（Graph2Seq）模型来编码KG子图，
4.1 总结
以更好地保留KG子图的显式结构信息。同时，该模
知识图谱是一种图结构，用来建模事物之间的 2292 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(10)
图10 知识问答流程
Fig.10 Questionandanswerprocess
联系，针对知识图谱构建存在的问题，提出了使用 释性，比如文献[109]提出了减少基于文本信息的同
GNN的方法解决相应的问题，主要关注四类图神经 构-多深度联合实体对齐的需求模型，利用实体的名
网络参与知识图谱构建的问题，具体包括：链接预 称信息和属性信息，同时将实体对齐问题转化为分
测、知识图谱对齐、实体消歧和知识推理等。在了解 配问题，大大提高了模型的可解释性。还有一些文
相应的模型细节和这些策略之后，本文对基于GNN 献[79,88,129]引入路径机制或者规则，用于缓解知识图谱
的知识图谱的应用方面进行了阐述，主要包括推荐 的可解释性问题[130]，但是由于可解释性仍然是深度
系统、知识问答、计算机视觉和药物关系预测等。虽 学习的黑盒子，仍旧需要不断探索。
然图神经网络应用于知识图谱已经取得了上述发 （2）知识图谱的动态特性
展，但仍面临以下挑战，具体如表9所示。 知识图谱的构建是一个不断更新迭代的过程，
（1）图神经网络可解释性 现有的知识图谱是相对静态的，大多数知识图谱是
现有的解释大多基于实例分析和实现的效果推 动态实时变化的，动态图神经网络已经成为当前发
理得到，图神经网络尝试从基于梯度、扰动、代理和 展的主要趋势，利用图时空网络研究动态图是未来
分解等角度对黑盒问题进行解释，在知识图谱上应 的发展方向，近有研究从元学习框架新模型（dynamic
用图神经网络也有基于逻辑推理的方法尝试提高深 graph neural network，MetaDyGNN）[107]出发，用动态
度学习的可解释性，可解释性依旧是未来持续研究 网络中的少镜头进行链接预测提出了动态图神经网
的方向。现有的研究通过引入额外信息来增加可解 络模型（dynamic graph neural network，DGNN）处理
表9 知识图谱构建中存在的问题及相应的解决方案
Table9 Problemsinconstructionofknowledgegraphandcorrespondingsolutions
存在的问题 解决方案 文献及发表年份
引入路径机制（或元路径），提高可解释性； T-GAP[88（] 2021）、DPMPN[79（] 2019）、HPHS[129](2023)、SEG[84（] 2022）、
可解释性
或引入规则，对知识图谱三元组进行补充 MDJEA[109](2023)、RED-GNN[91（] 2022）、PaGE-Link[85（] 2023）
通过引入时间序列（时间位移）编码子结
动态特性 T-GAP[88（] 2021）、MetaDyGNN[107](2022)、TS-GCN[15（] 2019）
构，或采用时空图神经网络进行知识嵌入
采用无监督学习的方式或者加大知识图谱
对准确数据的依赖 PEEA[105（] 2023）、MMGraph[113](2022)
中结构信息和语义信息的利用
通过门控机制，从实体交互和关系交互的 DvGNet[108（] 2023）、MuGNN[95（] 2019）、AliNet[104（] 2020）、KDCoE[133]
结构异质性
角度全面缓解了KG的结构异质 （2018）、AttrE[134（] 2019）、SEG[84（] 2022）、DGAT[135（] 2020） 许鑫冉 等：图神经网络在知识图谱构建与应用中的研究进展 2293
动态图问题。Jung等人提出了T-GAP模型[88]，其编码 题，需要不断研究。表9总结了现如今存在的问题及
器和解码器最大限度地利用时间信息和图结构，T- 其解决方案。
GAP通过关注每个事件与查询时间之间的时间位移 4.2 展望
来编码TKG的特定查询子结构，并通过在图中传播 （1）GNN模型的可扩展性
注意力来执行基于路径的推理，有效应对知识图谱 GNN（图神经网络）模型长期存在可扩展性问
的动态特性。Gao等人通过 TS-GCN（two-stream 题，在处理大规模图数据时，虽然许多新的技术和算
graph convolutionalnetworks）[15]模式实现零镜头动作 法已被开发用于提高GNN模型的可扩展性，但是仍
识别，巧妙实现了动作识别预测。动态图神经网络 然存在一些问题导致GNN模型的可扩展性较差。首
研究将成为未来不断研究的热点之一。 先是图的规模，GNN模型需要处理大规模的节点和
（3）标记数据的依赖 边实体，会导致内存消耗和复杂度等问题；其次是许
垂直领域知识图谱对准确数据有严格的要求， 多GNN模型在设计时考虑了特定类型的图数据，可
希望能够克服对标记数据的依赖，缓解数据稀疏的 能不太适合处理其他类型的数据（例如：现有的GNN
问题，这将是未来领域知识图谱的一个发展方向。 模型主要用于处理自然语言处理数据，但对于医疗
例如：在实体对齐任务中，通过将位置信息整合到具 数据、地震解释数据，还未能挖掘到有效的处理方
有位置注意力层的表示学习中来增强远处实体与标 法），为了提高GNN的可扩展性，需要考虑这些因素，
记实体之间的联系，并提出一种弱监督学习框架来 并寻找相应的解决方案。
增强实体对齐[105]，缓解缺乏标记数据而导致的性能 （2）图神经网络的工业应用
瓶颈。MI-KGNN（multi-dimensionuser-iteminteractions 现有的图神经网络的研究大多基于理论上公开
with attentional knowledge graph neural networks）[131] 数据集，没有应用于大规模的实际应用领域，例如地
可以有效地捕获和表示知识图谱中的结构信息（即 质构造建模、航空航天、金融领域等，很少使用图神
交互的拓扑结构）和语义信息（即交互的权重），缓解 经网络进行处理，领域知识图谱对数据的准确性要
数据稀疏的问题。对数据的依赖性可以通过修改模
求很高，需要得到准确的结果，但图神经网络的泛化
型来进行，采用无监督或弱监督学习的方式，学习现
能力仍有待提升，最终实现工业落地并发挥图神经
有的有限数据信息。如何解决样本不足或缺失问
网络处理像知识图谱这样图结构的数据，仍旧需要
题，是未来一个充满前景的方向。
不断研究。
（4）知识图谱结构异质性
（3）知识图谱的工业落地
KG之间的结构异质性[132]严重阻碍了实体对齐
现如今对知识图谱的需求呈现爆炸式增长，但
的发展，现有研究主要从实体邻域异质性的角度缓
是对于领域知识图谱的构建仍然存在一些局限性。
解结构异质性，而忽略了关系异质性对其的重要作
首先是知识图谱的用处，通过各个深度学习的方法
用。基于此，可以采用基于门控机制DvGNet的双视
构建的知识图谱能否应用于垂直领域，会不会存在
图神经网络（GNN）[108]，从实体和关系交互的角度全
花费大量人力、物力构建知识图谱的问题，因为深度
面缓解KG的结构异质性。MuGNN[95]提出了一种多
学习的不可解释性和不确定性，导致无法满足实际
通道图神经网络框架，并利用规则生成三元组来补
工程的需求。以及会不会存在知识图谱交叉的问
充KG，从而缓解实体的邻域异质性，并利用邻域聚
题，构建的多个领域知识图谱在很大程度上是重合
类来应对实体邻域异质性。并将实体对齐视为最大
的，从而造成了资源浪费。由于图神经网络仍然是
二分匹配问题，由匈牙利算法解决；AliNet[104]通过使
个黑盒子，使用图神经网络构建的知识图谱仍旧无
用门控策略和注意力机制聚合多跳邻域来缓解实体
法在工业上落地。
的邻域异构性。关系异质性也是KG结构异质性的
重要原因。此外，一些研究，如KDCoE（co-training
参考文献：
embeddingsofknowledgegraphsandentitydescriptions）[133]
[1]DAIY,WANG S,XIONG N N,etal.Asurveyonknowle-
和AttrE（attribute embeddings）[134]在学习实体嵌入的
dge graph embedding: approaches, applications and bench-
过程中加入了实体的其他配置文件信息，缓解结构 marks[J].Electronics,2020,9(5):750.
异质性。但知识图谱的异质性仍然是长期存在的问 [2] SUCHANEK F M, KASNECI G, WEIKUM G. YAGO: a 2294 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(10)
core of semantic knowledge[C]//Proceedings of the 16th shot action recognition via two-stream graph convolutional
International Conference on World Wide Web, Banff, May networksandknowledgegraphs[C]//Proceedingsofthe33rd
8-12,2007.NewYork:ACM,2007:697-706. AAAIConferenceonArtificialIntelligence,the31stInnov-
[3]BOLLACKERK,EVANSC,PARITOSHP,etal.Freebase:a ativeApplications ofArtificial Intelligence Conference, the
collaboratively created graph databaseforstructuring human 9th AAAI Symposium on Educational Advances in Artifi-
knowledge[C]//Proceedings of the 2008 ACM SIGMOD cialIntelligence,Honolulu,Jan27-Feb1,2019.MenloPark:
InternationalConferenceonManagementofData,Vancouver, AAAI,2019:8303-8311.
Jun10-12,2008.NewYork:ACM,2008:1247-1250. [16] WANG Q, MAO Z, WANG B, et al. Knowledge graph
[4]AUERS,BIZERC,KOBILAROVG,etal.DBpedia:anuc- embedding: a survey of approaches and applications[J].
leus for a web of open data[C]//LNCS 4825: Proceedings IEEE Transactions on Knowledge and Data Engineering,
of the 6th International Semantic Web Conference on the 2017,29(12):2724-2743.
SemanticWeb, Busan, Nov 11-15, 2007. Berlin, Heidelberg: [17] ZOU X. A survey on application of knowledge graph[J].
Springer,2007:722-735. JournalofPhysics:ConferenceSeries,2020,1487(1):012016.
[5]ALANIH,SANGHEEK,MILLARDDE,etal.Automatic [18]WU Z,PAN S,CHEN F,et al.Acomprehensive survey on
ontology-basedknowledgeextractionfromWebdocuments graph neural networks[J]. IEEE Transactions on Neural
[J].IEEEIntelligentSystems,2003,18(1):14-21. NetworksandLearningSystems,2020,32(1):4-24.
[6]CHENX,JIAS,XIANGY.Areview:knowledgereasoning [19]孙水发,李小龙,李伟生,等.图神经网络应用于知识图谱推
overknowledgegraph[J].ExpertSystemswithApplications, 理的研究综述[J].计算机科学与探索,2023,17(1):27-52.
2020,141:112948. SUNSF,LIXL,LIWS,etal.Reviewofgraphneuralnet-
[7]LIBEN-NOWELLD,KLEINBERGJM.Thelinkprediction works applied to knowledge graph reasoning[J]. Journal of
problem for social networks[C]//Proceedings of the 2003 Frontiers of Computer Science and Technology, 2023, 17
ACM CIKM International Conference on Information and (1):27-52.
Knowledge Management, New Orleans, Nov 2-8, 2003. [20]张吉祥,张祥森,武长旭,等.知识图谱构建技术综述[J].
NewYork:ACM,2003:556-559. 计算机工程,2022,48(3):23-37.
[8]SUNZQ,HUW,ZHANGQH,etal.Bootstrappingentity ZHANG J X, ZHANG X S, WU C X, et al. Survey of
alignment with knowledge graph embedding[C]//Proceedings knowledgegraphconstructiontechniques[J].ComputerEng-
ofthe27thInternationalJointConferenceonArtificialIntel- ineering,2022,48(3):23-37.
ligence,Stockholm,Jul13-19,2018:4396-4402. [21]吴国栋,王雪妮,刘玉良.知识图谱增强的图神经网络推
[9]DREDZEM,MCNAMEEP,RAOD,etal.Entitydisambi- 荐研究进展[J].计算机工程与应用,2023,59(4):18-29.
guation for knowledge base population[C]//Proceedings of WU G D, WANG X N, LIU Y L. Research advances on
the23rdInternationalConferenceonComputationalLingui- graph neural network recommendation of knowledge graph
stics, Beijing,Aug 23-27, 2010. Beijing: Tsinghua Univer- enhancement[J]. Computer Engineering and Applications,
sityPress,2010:277-285. 2023,59(4):18-29.
[10] REN H, LESKOVEC J. Beta embeddings for multi-hop [22]延照耀,丁苍峰,马乐荣,等.面向图神经网络的知识图谱
logical reasoning in knowledge graphs[C]//Advances in 嵌入研究进展[J].计算机科学与探索,2023,17(8):1793-
NeuralInformationProcessingSystems33,Dec6-12,2020: 1813.
19716-19726. YAN ZY,DING C F,MALR,etal.Advances in knowle-
[11]SCARSELLIF,GORIM,TSOIAC,etal.Thegraphneural dge graph embedding based on graph neural networks[J].
network model[J]. IEEE Transactions on Neural Networks, Journal of Frontiers of Computer Science and Technology,
2008,20(1):61-80. 2023,17(8):1793-1813.
[12]ZHOUJ,CUIG,HUS,etal.Graphneuralnetworks:areview [23]陈子睿,王鑫,王林,等.开放领域知识图谱问答研究综述
ofmethodsandapplications[J].AIOpen,2020,1:57-81. [J].计算机科学与探索,2021，15(10):1843-1869.
[13]KIKUTAD,SUZUMURAT,RAHMANMM,etal.KQGC: CHEN Z R, WANG X, WANG L, et al. Survey of open-
knowledge graph embedding with smoothing effects ofgraph domain knowledge graph question answering[J]. Journal of
convolutionsforrecommendation[J].arXiv:2205.12102,2022. Frontiers of Computer Science and Technology, 2021, 15
[14]YASUNAGAM, REN H, BOSSELUTA, et al. QA-GNN: (10):1843-1869.
reasoning with language models and knowledge graphs for [24] ZENG K, LI C, HOU L, et al.Acomprehensive survey of
questionanswering[J].arXiv:2104.06378,2021. entity alignment for knowledge graphs[J]. AI Open, 2021,
[15]GAOJ,ZHANGTZ,XUCS.Iknowtherelationships:zero- 2:1-13. 许鑫冉 等：图神经网络在知识图谱构建与应用中的研究进展 2295
[25] JI S, PAN S, CAMBRIA E, et al.A survey on knowledge tems,2023,1(1):1-51.
graphs:representation,acquisition,andapplications[J].IEEE [39]ZENGX,TUX,LIUY,etal.Towardbetterdrugdiscovery
Transactions on Neural Networks and Learning Systems, with knowledge graph[J]. Current Opinion in Structural
2022,33(2):494-514. Biology,2022,72:114-126.
[26] LIN B Y, CHEN X, CHEN J, et al. KagNet: knowledge- [40]BORDESA,USUNIERN,GARCIA-DURANA,etal.Trans-
awaregraph networksforcommonsensereasoning[C]//Pro- lating embeddings for modeling multi-relational data[C]//
ceedings of the 2019 Conference on Empirical Methods in Advances in Neural Information Processing Systems 26,
Natural Language Processing and the 9th International LakeTahoe,Dec5-8,2013:2787-2795.
Joint Conference on Natural Language Processing, Hong [41]WANGZ,ZHANGJW,FENGJL,etal.Knowledgegraph
Kong,China.Stroudsburg:ACL,2019:2829-2839. embedding by translating on hyperplanes[C]//Proceedings
[27] FANOURAKIS N, EFTHYMIOU V, KOTZINOS D, et al. of the 28th AAAI Conference on Artificial Intelligence,
Knowledge graph embedding methods for entity alignment: Québec City, Jul 27-31, 2014. Menlo Park: AAAI, 2014:
anexperimentalreview[J].arXiv:2203.09280,2022. 1112-1119.
[28] HUANG H, LI C, PENG X, et al. Cross-knowledge-graph [42] JI G L, HE S Z, XU L H, et al. Knowledge graph embed-
entity alignmentvia relation prediction[J].Knowledge-Based ding via dynamic mapping matrix[C]//Proceedings of the
Systems,2022,240:107813. 53rdAnnual Meeting of theAssociation for Computational
[29]ZAMINIM,REZAH,RABIEIM,etal.Areviewofknow- Linguistics and the 7th International Joint Conference on
ledgegraphcompletion[J].Information,2022,13(8):396. Natural Language Processing of the Asian Federation of
[30] CHEN M, ZHANG W, GENG Y, et al. Generalizing to Natural Language Processing, Beijing, Jul 26-31, 2015.
unseen elements: a survey on knowledge extrapolation for Stroudsburg:ACL,2015:687-696.
knowledgegraphs[J].arXiv:2302.01859,2023. [43] LIN Y K, LIU Z Y, SUN M S, et al. Learning entity and
[31]YAN Q, FAN J, LI M, et al.Asurvey on knowledge graph relation embeddings for knowledge graph completion[C]//
embedding[C]//Proceedings of the 7th IEEE International Proceedings of the 29th AAAI Conference on Artificial
Conference on Data Science in Cyberspace, Guilin, Jul 11- Intelligence, Austin, Jan 25-30, 2015. Menlo Park: AAAI,
13,2022.Piscataway:IEEE,2022:576-583. 2015:2181-2187.
[32]PANGJ,ZHANGYH,DENGJX,etal.Asurveyoninfor- [44]FANM,ZHOUQ,CHANGE,etal.Transition-basedknow-
mationretrievalmethodforknowledgegraphcomplexques- ledge graph embedding with relational mapping properties
tion answering[C]//Proceedings of the 2022 China Auto- [C]//Proceedings of the 28th Pacific Asia Conference on
mation Congress, Xiamen, Nov 25-27, 2022. Piscataway: Language, Information and Computation, Phuket, Dec 12-
IEEE,2022:1059-1064. 14,2014.Stroudsburg:ACL,2014:328-337.
[33]ETEZADIR,SHAMSFARDM.Thestateoftheartinopen [45] TROUILLON T, WELBL J, RIEDEL S, et al. Complex
domain complex question answering: a survey[J].Applied embeddings for simple link prediction[C]//Proceedings of
Intelligence,2023,53(4):4124-4144. the33rdInternationalConferenceonMachineLearning,New
[34]ABDEL-NABIH,AWAJANA,ALIMZ,etal.Deeplearn- York,Jun19-24,2016:2071-2080.
ing-based question answering: a survey[J].Knowledge and [46] YANG B, YIH W T, HE X, et al. Embedding entities and
InformationSystems,2023,65(4):1399-1485. relations for learning and inference in knowledge bases[J].
[35] ZHANG L, ZHANG J, KE X, et al.A survey on complex arXiv:1412.6575,2014.
factualquestionanswering[J].AIOpen,2023,4:1-12. [47]DETTMERST,MINERVINIP,STENETORPP,etal.Con-
[36]LIUJ,DUANL.Asurveyonknowledgegraph-basedrecom- volutional 2D knowledge graph embeddings[C]//Proceedings
mendersystems[C]//Proceedingsofthe2021IEEE5thAdv- ofthe32ndAAAIConferenceonArtificialIntelligence,the
anced Information Technology, Electronic and Automation 30th Innovative Applications of Artificial Intelligence and
ControlConference,Chongqing,Mar12-14,2021.Piscata- the 8th AAAI Symposium on Educational Advances in
way:IEEE,2021:2450-2453. Artificial Intelligence, New Orleans, Feb 2-7, 2018. Menlo
[37] GAOY, LIYF, LINY, et al. Deep learning on knowledge Park:AAAI,2018:1811-1818.
graph for recommender system: a survey[J]. arXiv:2004.00387, [48] NGUYEN D Q, NGUYEN T D, NGUYEN D Q, et al. A
2020. novel embedding model for knowledge base completion
[38] GAO C, ZHENG Y, LI N, et al.A survey of graph neural based on convolutional neural network[J]. arXiv:1712.02121,
networks for recommender systems: challenges, methods, 2017.
anddirections[J].ACMTransactionsonRecommenderSys- [49] SCHLICHTKRULL M, KIPF T N, BLOEM P, et al. 2296 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(10)
Modelingrelationaldatawithgraphconvolutionalnetworks extractionusingknowledgegraphcontextinagraphneural
[C]//LNCS 10843: Proceedings of the 15th International network[C]//Proceedings of the Web Conference 2021,
Conference the Semantic Web, Heraklion, Jun 3-7, 2018. Ljubljana,Apr 19-23,2021.NewYork:ACM,2021: 1673-
Cham:Springer,2018:593-607. 1685.
[50]TIANA, ZHANG C, RANG M, et al. RA-GCN: relational [62] TIAN Y H, CHEN G M, SONG Y, et al. Dependency-
aggregation graph convolutional network for knowledge driven relation extraction with attentive graph convolutio-
graph completion[C]//Proceedings of the 12th International nal networks[C]//Proceedings of the 59th Annual Meeting
Conference on Machine Learning and Computing, Shen- of the Association for Computational Linguistics and the
zhen,Feb15-17,2020.NewYork:ACM,2020:580-586. 11th International Joint Conference on Natural Language
[51]CAIL,YANB,MAIGC,etal.TransGCN:couplingtrans- Processing,Aug1-6,2021.Stroudsburg:ACL,2021:4458-
formation assumptions with graph convolutional networks 4471.
for link prediction[C]//Proceedings of the 10th Internatio- [63]CHRISTOPOULOUF,MIWAM,ANANIADOUS.Conne-
nal Conference on Knowledge Capture, Marina Del Rey, cting the dots: document-level neural relation extraction
Nov19-21,2019.NewYork:ACM,2019:131-138. with edge-oriented graphs[J]. Pattern Recognition Letters,
[52] YU D H, YANG Y M, ZHANG R H, et al. Knowledge 2021,149:150-156.
embedding based graph convolutional network[C]//Procee- [64] SAHU S K, CHRISTOPOULOU F, MIWAM, et al. Inter-
dings of the Web Conference 2021, Ljubljana, Apr 19-23, sentencerelationextractionwithdocument-levelgraphcon-
2021.NewYork:ACM,2021:1619-1628. volutionalneuralnetwork[C]//Proceedingsofthe57thCon-
[53] COWIE J R, LEHNERT W G. Information extraction[J]. ference of the Association for Computational Linguistics,
CommunicationsoftheACM,1996,39(1):80-91. Florence, Jul 28-Aug 2, 2019. Stroudsburg: ACL, 2019:
[54] DOWNEY D, BROADHEAD M, ETZIONI O. Locating 4309-4316.
complex named entities in web text[C]//Proceedings of the [65] WANG D, HU W, CAO E, et al. Global-to-local neural
20th International Joint Conference on Artificial Intelli- networks for document-level relation extraction[J].arXiv:
gence,Hyderabad,Jan6-12,2007:2733-2739. 2009.10359,2020.
[55] MCCALLUM A, LI W. Early results for named entity [66]CHENH,HONGP,HANW,etal.Dialoguerelationextrac-
recognition with conditional random fields, feature induc- tionwithdocument-levelheterogeneousgraphattentionnet-
tion and web-enhanced lexicons[C]//Proceedings of the 7th works[J].CognitiveComputation,2023,15(2):793-802.
ConferenceonNaturalLanguageLearning,Edmonton,May [67]ZENGS,XUR,CHANGB,etal.Doublegraphbasedrea-
31-Jun1,2003.Stroudsburg:ACL,2003:188-191. soning for document- level relation extraction[J]. arXiv:
[56] COLLOBERT R, WESTON J, BOTTOU L, et al. Natural 2009.13752,2020.
language processing (almost) from scratch[J]. Journal of [68]TRANHM,NGUYENMT,NGUYENTH.Thedotshave
MachineLearningResearch,2011,12:2493-2537. theirvalues:exploitingthenode-edgeconnectionsingraph-
[57] STRUBELL E, VERGAP, BELANGER D, et al. Fast and based neural models for document-level relation extraction
accurate entity recognition with iterated dilated convolu- [C]//FindingsoftheAssociationforComputationalLinguis-
tions[J].arXiv:1702.02098,2017. tics,Nov16-20,2020.Stroudsburg:ACL,2020:4561-4567.
[58]ZHANGY,QIP,MANNINGCD.Graphconvolutionover [69] NAN G, GUO Z, SEKULIĆ I, et al. Reasoning with latent
pruned dependency trees improves relation extraction[J]. structure refinement for document-level relation extraction
arXiv:1809.10185,2018. [J].arXiv:2005.06312,2020.
[59] GUO Z, ZHANGY, LU W.Attention guided graph convo- [70] HALEDA, ELSIRAM T, SHEN Y. TFGAN: traffic fore-
lutional networks for relation extraction[J]. arXiv:1906.07510, castingusinggenerativeadversarialnetworkwithmultigraph
2019. convolutional network[J]. Knowledge-Based Systems, 2022:
[60]SUNK,ZHANGR,MAOY,etal.Relationextractionwith 108990.
convolutionalnetworkoverlearnablesyntax-transportgraph [71]SHANGC.End-to-endstructure-awareconvolutionalnetworks
[C]//Proceedingsofthe34thAAAIConferenceonArtificial ongraphs[R].UniversityofConnecticut,2020.
Intelligence, the 32nd Innovative Applications of Artificial [72] WANG Z H, REN Z C, HE C Y, et al. Robust embedding
Intelligence Conference, the 10th AAAI Symposium on with multi-level structures for link prediction[C]//Procee-
EducationalAdvances inArtificial Intelligence, New York, dingsofthe28thInternationalJointConferenceonArtificial
Feb7-12,2020.MenloPark:AAAI,2020:8928-8935. Intelligence,Macao,China,Aug10-16,2019:5240-5246.
[61]BASTOSA,NADGERIA,SINGHK,etal.RECON:relation [73] LIU X, TAN H, CHEN Q, et al. RAGAT: relation aware 许鑫冉 等：图神经网络在知识图谱构建与应用中的研究进展 2297
graph attention network for knowledge graph completion dgegraph[C]//LNCS13422：Proceedingsofthe6thInterna-
[J].IEEEAccess,2021,9:20840-20849. tional Joint Conference on Web and Big Data, Nanjing,
[74] NATHANI D, CHAUHAN J, SHARMAC, et al. Learning Nov25-27,2022.Cham:Springer,2023:195-209.
attention-basedembeddingsforrelationpredictioninknow- [88] JUNG J, JUNG J, KANG U. Learning to walk across time
ledgegraphs[J].arXiv:1906.01195,2019. forinterpretabletemporalknowledgegraphcompletion[C]//
[75] LUO Q, WANG J, ZHAO W, et al. Vasculogenic mimicry Proceedings of the 27th ACM SIGKDD Conference on
in carcinogenesis and clinical applications[J]. Journal of Knowledge Discovery and Data Mining, Singapore, Aug
HematologyOncology,2020,13(1):1-15. 14-18,2021.NewYork:ACM,2021:786-795.
[76] LI Z, LIU H, ZHANG Z, et al. Learning knowledge graph [89]ACHEAMPONGKN,TIANWH.Advancementoftextual
embedding with heterogeneous relation attention networks answer triggering: cognitive boosting[J]. IEEE Transactions
[J]. IEEE Transactions on Neural Networks and Learning onEmergingTopicsinComputing,2022,10(1):361-372.
Systems,2022,33(8):3961-3973. [90] WANG Q, HAO Y, CHEN F. Deepening the IDA* algori-
[77] LIU S, GRAU B, HORROCKS I, et al. INDIGO: GNN- thmforknowledgegraphreasoningthroughneuralnetwork
based inductive knowledge graph completion using pair- architecture[J].Neurocomputing,2021,429:101-109.
wise encoding[C]//Advances in Neural Information Proces- [91]ZHANGYQ,YAOQM.Knowledgegraphreasoningwith
singSystems34,Dec6-14,2021:2034-2045. relationaldigraph[C]//ProceedingsoftheACMWebConfe-
[78] TERU K, DENIS E, HAMILTON W. Inductive relation rence2022,Lyon,Apr25-29,2022.NewYork:ACM,2022:
prediction by subgraph reasoning[C]//Proceedings of the 912-924.
37thInternationalConferenceonMachineLearning,Jul13- [92] WANG Z, LV Q, LAN X, et al. Cross-lingual knowledge
18,2020:9448-9457. graph alignment via graph convolutional networks[C]//Pro-
[79]XUX,FENGW,JIANGY,etal.Dynamicallyprunedmes- ceedings of the 2018 Conference on Empirical Methods in
sage passing networks for large-scale knowledge graph NaturalLanguageProcessing,Brussels,Oct31-Nov4,2018.
reasoning[J].arXiv:1909.11334,2019. Stroudsburg:ACL,2018:349-357.
[80] MOHAMED HA, PILUTTI D, JAMES S, et al. Locality- [93]WUY,LIUX,FENGY,etal.Relation-awareentityalignment
awaresubgraphsforinductivelinkpredictioninknowledge for heterogeneous knowledge graphs[J]. arXiv:1908.08210,
graphs[J].PatternRecognitionLetters,2023,167:90-97. 2019.
[81]WANG S,WEIX,DOS C N,etal.Santosmixed-curvature [94]YANG HW,ZOUYY,SHIP,etal.Aligning cross-lingual
multi-relational graph neural network for knowledge graph entities with multi-aspect information[C]//Proceedings of
completion[C]//Proceedings of the Web Conference 2021, the 2019 Conference on Empirical Methods in Natural
Ljubljana,Apr 19-23,2021.NewYork:ACM,2021: 1761- LanguageProcessingandthe9thInternationalJointConfer-
1771. ence on Natural Language Processing, Hong Kong, China,
[82]WANGY,WANGH,LUW,etal.HyGGE:hyperbolicgraph Nov3-7,2019.Stroudsburg:ACL,2019:4430-4440.
attention network for reasoning over knowledge graphs[J]. [95] CAO Y X, LIU Z Y, LI C J, et al. Multi-channel graph
InformationSciences,2023,630:190-205. neural network for entity alignment[C]//Proceedings of the
[83] WU Z, PAN S, LONG G, et al. Graph wavenet for deep 57thAnnual Meeting of theAssociation for Computational
spatial-temporalgraphmodeling[J].arXiv:1906.00121,2019. Linguistics,Florence,Jul28-Aug2,2019.Stroudsburg:ACL,
[84]AIB,QINZ,SHENW,etal.Structureenhancedgraphneural 2019:1452-1461.
networksforlinkprediction[J].arXiv:2201.05293,2022. [96]YER,LIX,FANGYJ,etal.Avectorizedrelationalgraph
[85] ZHANG S C, ZHANG J N, SONG X, et al. PaGE-Link: convolutionalnetworkformulti-relationalnetworkalignment
path-based graph neural network explanation for hetero- [C]//Proceedings of the 28th International Joint Conference
geneous link prediction[C]//Proceedings of the ACM Web onArtificial Intelligence, Macao, China,Aug 10-16, 2019:
Conference 2023,Austin,Apr 30-May 4, 2023. NewYork: 4135-4141.
ACM,2023:3784-3793. [97]MAOX,WANGWT,XUHM,etal.MRAEA:anefficient
[86]ZHANGYY,CHENXS,YANGY,etal.Efficientprobabi- androbustentityalignmentapproachforcross-lingualknow-
listic logic reasoning with graph neural networks[C]//Pro- ledge graph[C]//Proceedings of the 13th International Con-
ceedings of the 8th International Conference on Learning ferenceonWebSearchandDataMining,Houston,Feb3-7,
Representations,AddisAbaba,Apr26-30,2020:1-20. 2020.NewYork:ACM,2020:420-428.
[87] XIANG Y X, WU J J, WANG T X, et al. Reasoning path [98] WU Y, LIU X, FENG Y, et al. Jointly learning entity and
generation foranswering multi-hop questionsoverknowle- relation representations for entity alignment[J]. arXiv: 1909. 2298 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(10)
09317,2019. InformationScienceandSystems,2023,11(1):5.
[99] NIE H, HAN X, SUN L, et al. Global structure and local [109] ZHANG F, LI J, CHENG J. Improving entity alignment
semantics-preserved embeddings for entity alignment[C]// via attribute and external knowledge filtering[J]. Applied
Proceedings of the 29th International Joint Conference on Intelligence,2023,53(6):6671-6681.
ArtificialIntelligence,Yokohama,Jul2020:3658-3664. [110] ZHU Q N, ZHOU X F,WU J, et al. Neighborhood-aware
[100]WUYT,LIUX,FENGYS,etal.Neighborhoodmatching attentional representation for multilingual knowledge graphs
network for entity alignment[C]//Proceedings of the 58th [C]//Proceedings of the 28th International Joint Conference
AnnualMeetingoftheAssociationforComputationalLin- onArtificialIntelligence,Macao,China,Aug10-16,2019:
guistics, Jul 5-10, 2020. Stroudsburg: ACL, 2020: 6477- 1943-1949.
6487. [111]CHENMY,ZHANGW,ZHUYS,etal.Meta-knowledge
[101] MAO X, WANG W T, XU H M, et al. Relational reflec- transfer for inductive knowledge graph embedding[C]//
tion entity alignment[C]//Proceedings of the 29th ACM Proceedingsofthe45thInternationalACMSIGIRConfer-
International Conference on Information & Knowledge ence on Research and Development in Information Retrie-
Management, Ireland, Oct 19-23, 2020. NewYork:ACM, val,Madrid,Jul11-15,2022.NewYork:ACM,2022:927-
2020:1095-1104. 937.
[102]PEISC,YU L,YU G X,etal.REA:robustcross-lingual [112]HU L,DING J,SHIC,etal.Graphneuralentitydisambi-
entity alignment between knowledge graphs[C]//Procee- guation[J].Knowledge-BasedSystems,2020,195:105620.
dingsofthe26thACMSIGKDDInternationalConference [113]LIGS,LIHM,PANY,etal.Namedisambiguationbased
on Knowledge Discovery and Data Mining, Aug 23-27, onentityrelationshipgraphinbigdata[C]//Proceedingsof
2020.NewYork:ACM,2020:2175-2184. the 7th International Conference on Data Mining and Big
[103] LIU Z Y, CAO Y X, PAN L M, et al. Exploring and Data, Beijing, Nov 21-24, 2022. Cham: Springer, 2022:
evaluatingattributes,values,andstructuresforentityalign- 319-329.
ment[C]//Proceedings of the 2020 Conference on Empi- [114] SUCHANEK F M, KASNECI G, WEIKUM G. Yago: a
rical Methods in Natural Language Processing, Nov 16- core of semantic knowledge[C]//Proceedings of the 16th
20,2020.Stroudsburg:ACL,2020:6355-6364. InternationalConferenceonWorldWideWeb,Banff,May
[104] SUN Z Q, WANG C M, HU W, et al. Knowledge graph 8-12,2007.NewYork:ACM,2007:697-706.
alignment network with gated multi-hop neighborhood [115] WANG H W, ZHAO M, XIE X, et al. Knowledge graph
aggregation[C]//Proceedings of the 34th AAAI Confere- convolutionalnetworksforrecommendersystems[C]//Pro-
nceonArtificialIntelligence,the32ndInnovativeApplica- ceedings of the 2019 World Wide Web Conference, San
tions ofArtificial Intelligence Conference, the 10thAAAI Francisco,May13-17,2019.NewYork:ACM,2019:3307-
SymposiumonEducationalAdvancesinArtificialIntellige- 3313.
nce,NewYork,Feb7-12,2020.MenloPark:AAAI,2020: [116]WANGY, LIU Z W, FAN Z W, et al. DSKReG: differen-
222-229. tiable sampling on knowledge graph for recommendation
[105] TANG W, SU F, SUN H, et al. Weakly supervised entity with relational GNN[C]//Proceedings of the 30th ACM
alignment with positional inspiration[C]//Proceedings of International Conference on Information and Knowledge
the 16th ACM International Conference on Web Search Management,Queensland,Nov1-5,2021.NewYork:ACM,
and Data Mining, Singapore, Feb 27-Mar 3, 2023. New 2021:3513-3517.
York:ACM,2023:814-822. [117] WANG Y, TANG S Y, LEI Y T, et al. DisenHAN: disen-
[106] ZHANG X, ZHANG R, CHEN J, et al. Semi-supervised tangled heterogeneous graph attention network for recom-
entity alignment with global alignment and local informa- mendation[C]//Proceedingsofthe29thACM International
tionaggregation[J].IEEETransactionsonKnowledgeand Conference on Information and Knowledge Management,
DataEngineering,2023:1-14. Ireland, Oct 19-23, 2020. New York: ACM, 2020: 1605-
[107]YANG C,WANG C,LUY,etal.Few-shotlink prediction 1614.
in dynamic networks[C]//Proceedings of the 15th ACM [118]MAT,HUANGLT,LUQQ,etal.KR-GCN:knowledge-
InternationalConferenceonWebSearchandDataMining, awarereasoningwithgraphconvolutionnetworkforexpla-
Tempe, Feb 21-25, 2022. New York: ACM, 2022: 1245- inablerecommendation[J].ACMTransactionsonInforma-
1255. tionSystems,2022,41(1):4.
[108]JINY,JIW,SHIY,etal.Meta-pathguidedgraphattention [119] TAUNK D, KHANNA L, KANDRU P, et al. GrapeQA:
network for explainable herb recommendation[J].Health Graph augmentation and pruning to enhance question- 许鑫冉 等：图神经网络在知识图谱构建与应用中的研究进展 2299
answering[J].arXiv:2303.12320,2023. task recommendation[C]//LNCS 13423: Proceedings of
[120]YANGZ,WUL,WENP,etal.Visualquestionanswering the 6th International Joint Conference on Web and Big
reasoning with external knowledge based on bimodal Data, Nanjing, Nov 25-27, 2022. Cham: Springer, 2023:
graph neural network[J]. Electronic Research Archive, 174-181.
2023,31(4):1948-1965. [131] WANG Z,WANG Z, LI X, et al. Exploring multi-dimen-
[121]CHENZ,SINGHAK,SRAM.LMExplainer:aknowledge- sionuser-iteminteractionswithattentionalknowledgegraph
enhancedexplainerforlanguagemodels[J].arXiv:2303.16537, neural networks for recommendation[J]. IEEE Transac-
2023. tionsonBigData,2023,9(1):212-226.
[122]YU D H, ZHU C G, FANGYW, et al. KG-FiD: infusing [132] ZHANG X, BOSSELUTA,YASUNAGAM, et al. Grea-
knowledge graph in fusion in decoder for open-domain seLM: graph reasoning enhanced language models for
questionanswering[J].arXiv:2110.04330,2021. questionanswering[J].arXiv:2201.08860,2022.
[123] LV SW, GUO DY, XU J J, et al. Graph-based reasoning [133] CHEN M H,TIANYT, CHANG K W, et al. Co-training
over heterogeneous external knowledge for commonsense embeddings of knowledge graphs and entity descriptions
question answering[C]//Proceedings of the 34th AAAI for cross-lingual entity alignment[C]//Proceedings of the
Conference onArtificial Intelligence, the 32nd Innovative 27th International Joint Conference onArtificial Intellige-
Applications of Artificial Intelligence Conference, the 10th nce,Jul13-19,2018:3998-4004.
AAAI Symposium on Educational Advances in Artificial [134]TRISEDYABD,QIJ,ZHANGR.Entityalignmentbetween
Intelligence,NewYork,Feb7-12,2020.MenloPark:AAAI, knowledge graphs using attribute embeddings[C]//Procee-
2020:8449-8456. dings of the 33rd AAAI Conference on Artificial Intelli-
[124]FENGYL,CHENXY,LINBY,etal.Scalablemulti-hop gence,the31stInnovativeApplicationsofArtificialIntelli-
relationalreasoningforknowledge-awarequestionanswe- genceConference,the9thAAAISymposiumonEducatio-
ring[C]//Proceedings of the 2020 Conference on Empir- nalAdvances inArtificial Intelligence, Honolulu, Jan 27-
ical Methods in Natural Language Processing, Nov 16-20, Feb1,2019.MenloPark:AAAI,2019:297-304.
2020.Stroudsburg:ACL,2020:1295-1309. [135]WANGYY,XIACH,SICX,etal.Robustreasoningover
[125] CHEN Y, WU L, ZAKI M J. Toward subgraph-guided heterogeneous textual information for fact verification[J].
knowledge graph question generation with graph neural IEEEAccess,2020,8:157140-157150.
networks[J].IEEE Transactions on Neural Networks and
LearningSystems,2023:1-12. 许鑫冉（1999—），女，湖北襄阳人，硕士研究
[126]GUANX,CAOBW,GAOQQ,etal.CORN:co-reasoning 生，主要研究方向为图神经网络、知识图谱等。
networkforcommonsensequestionanswering[C]//Procee- XU Xinran, born in 1999, M.S. candidate. Her
dings of the 29th International Conference on Computa- research interests include graph neural network,
tionalLinguistics,Gyeongju,Oct12-17,2022:1677-1686. knowledgegraph, etc.
[127] LIN X, QUAN Z, WANG Z J, et al. KGNN: knowledge
graph neural network for drug-drug interaction prediction 王腾宇（1992—），男，河南濮阳人，主要研究方
[C]//Proceedings of the 29th International Joint Confer- 向为垂直地震剖面、油气勘探、物探、地震解
enceonArtificialIntelligence,Yokohama,Jul2020:2739- 释、机器学习等。
2745. WANG Tengyu, born in 1992. His research
[128]YUY,HUANGK,ZHANGC,etal.SumGNN:multi-typed interests include vertical seismic profiling, oil
drug interaction prediction via efficient knowledge graph and gas exploration, geophysical exploration,
summarization[J].Bioinformatics,2021,37(18):2988-2995. seismicinterpretation,machinelearning,etc.
[129]CHENMK,GONGXW,JINYH,etal.Relationprefere-
nceorientedhigh-ordersamplingforrecommendation[C]// 鲁才（1975—），男，重庆人，博士，副教授，博士
Proceedingsofthe16thACMInternationalConferenceon 生导师，主要研究方向为计算机图形学、机器
Web Search and Data Mining, Singapore, Feb 27-Mar 3, 学习等。
2023.NewYork:ACM,2023:105-113. LU Cai,born in 1975,Ph.D.,associate professor,
[130] WANG Y N, ZHANG J, ZHOU X M, et al. Hierarchical Ph.D. supervisor. His research interests include
aggregation based knowledge graph embedding for multi- computergraphics,machinelearning,etc. --------------------------------------------------------------------------------- 计算机科学与探索 1673-9418/2023/17(01)-0027-26
JournalofFrontiersofComputerScienceandTechnology doi:10.3778/j.issn.1673-9418.2207060
图神经网络应用于知识图谱推理的研究综述
开放科学(OSID)
孙水发1,2，李小龙1,3，李伟生4，雷大江4，李思慧1,2，杨 柳5，吴义熔6+
1.智慧医疗宜昌市重点实验室，湖北 宜昌 443002
2.三峡大学 计算机与信息学院，湖北 宜昌 443002
3.三峡大学 经济与管理学院，湖北 宜昌 443002
4.重庆邮电大学 计算机科学与技术学院，重庆 400065
5.北京师范大学 心理学部，广东 珠海 519087
6.北京师范大学 人文和社会科学高等研究院，广东 珠海 519087
+通信作者 E-mail:yrwu@bnu.edu.cn
摘 要：知识推理（KR）作为知识图谱构建的一个重要环节，一直是该领域研究的焦点问题。随着知识图谱应
用研究的不断深入和范围的不断扩大，将图神经网络（GNN）应用于知识推理的方法能够在获取知识图谱中实
体、关系等语义信息的同时，充分考虑知识图谱的结构信息，使其具备更好的可解释性和更强的推理能力，因
此近年来受到广泛关注。首先梳理了知识图谱和知识推理的基本知识及研究现状，简要介绍了基于逻辑规
则、基于表示学习、基于神经网络和基于图神经网络的知识推理的优势与不足；其次全面总结了基于图神经网
络的知识推理最新进展，将基于图神经网络的知识推理按照基于递归图神经网络（RecGNN）、卷积图神经网络
（ConvGNN）、图自编码网络（GAE）和时空图神经网络（STGNN）的知识推理进行分类，对各类典型网络模型进
行了介绍和对比分析；然后介绍了基于图神经网络的知识推理在医学、智能制造、军事、交通等领域的应用；最
后提出了基于图神经网络的知识推理的未来研究方向，并对这个快速增长领域中的各方向研究进行了展望。
关键词：知识图谱；知识推理（KR）；图神经网络（GNN）；语义信息；结构信息
文献标志码：A 中图分类号：TP391
Review of Graph Neural NetworksApplied to Knowledge Graph Reasoning
SUN Shuifa1,2, LI Xiaolong1,3, LIWeisheng4, LEI Dajiang4, LI Sihui1,2,YANG Liu5,WUYirong6+
1.YichangKeyLaboratoryofIntelligentMedicine，Yichang,Hubei443002,China
2.CollegeofComputerandInformationTechnology,ChinaThreeGorgesUniversity,Yichang,Hubei443002,China
3.CollegeofEconomicsandManagement,ChinaThreeGorgesUniversity,Yichang,Hubei443002,China
4. College of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chong-
qing400065,China
5.FacultyofPsychology,BeijingNormalUniversity,Zhuhai,Guangdong519087,China
6. Institute ofAdvanced Studies in Humanities and Social Sciences, Beijing Normal University, Zhuhai, Guangdong
519087,China
Abstract:As an important element of knowledge graph construction, knowledge reasoning (KR) has always been a
hot topic of research. With the deepening of knowledge graph application research and the expanding of its scope,
基金项目：国家社会科学基金（20BTQ066）。
ThisworkwassupportedbytheNationalSocialScienceFoundationofChina(20BTQ066).
收稿日期：2022-07-18 修回日期：2022-09-16 28 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
graph neural network (GNN) based KR methods have received extensive attention due to their capability of
obtaining semantic information such as entities and relationships in knowledge graph, high interpretability, and
strong reasoning ability. In this paper, firstly, basic knowledge and research status of knowledge graph and KR are
summarized. The advantages and disadvantages of KR approaches based on logic rules, representation learning,
neural network and graph neural network are briefly introduced. Secondly, the latest progress in KR based on
GNN is comprehensively summarized. GNN-based KR methods are categorized into knowledge reasoning
based on recurrent graph neural networks (RecGNN), convolutional graph neural networks (ConvGNN), graph
auto-encoders (GAE) and spatial-temporal graph neural networks (STGNN). Various typical network models
are introduced and compared. Thirdly, this paper introduces the application of KR based on graph neural
network in health care, intelligent manufacturing, military, transportation, etc. Finally, the future research
directions of GNN-based KR are proposed, and related research in various directions in this rapidly growing
fieldisdiscussed.
Key words: knowledge graph; knowledge reasoning (KR); graph neural network (GNN); semantic information;
structuralinformation
知识图谱（knowledge graph，KG）最早可以追溯 术也在不断演变创新，学术界和工业界对知识推理
到Richens[1]在1956年提出的以图结构进行知识表示 领域进行了大量深入研究，也有较多关于知识推理
的语义网络（semantic net）。随后，语义网络经过了 的综述文献。相关综述文献可以归纳为三类（如
本体论（ontology）、万维网（Web）、语义网（semantic 表1）：第一类是关于知识推理任务类的综述文献，包
Web）、链接数据（linked data）等一系列发展[2]。直到 括“知识图谱补全任务[2,5-9]”“知识推理问答任务[10-11]”
2012年，谷歌正式提出知识图谱，并将知识图谱的知 和“知识图谱推荐系统任务[12-16]”等，该类综述侧重利
识定义为由实体、关系和语义描述组成的结构化三元 用知识推理方法解决某一类具体任务；第二类是关于
组事实，其中实体代表现实世界中的对象或者是抽象 知识图谱领域应用类的综述文献，包括从临床医疗[17-19]、
的概念，关系是定义的类型或者属性，用来表示实体 风险管理[20]、智能制造[21]、安全情报[22]等方面的应用
之间的关联或者实体属性。知识图谱技术已迅速成 进行综述，侧重讨论将知识推理方法应用于某一类
为数据挖掘、数据库和人工智能等领域的研究热点[3]。 领域的研究综述；第三类是知识推理方法类的综述
知识图谱推理（下述简称“知识推理”，know- 文献[3,23-29]等，该类综述侧重对知识推理原理的分析，
ledge graph reasoning）即面向知识图谱的知识推理， 以及方法的解读、分类和改进。
它是从已有的知识出发，推断出新的或未知的知识， 综上所述，关于知识推理的综述文献要么是基
从而拓展、补充和丰富知识库，最早可以追溯到1959 于知识推理某一类任务或某领域应用类的综述，要
年 Newell 等人[4]提出的一般问题解决库（general 么是基于知识图谱推理方法类的综述。这些综述主
problem solver）。随着知识图谱构建技术的不断发 要是基于传统算法、深度学习或强化学习算法的知
展、规模的不断扩大、应用场景的不断推广以及深度 识图谱综述，而基于最新相关研究方法的知识推理
学习和自然语言处理技术的不断成熟，知识推理技 类综述文章还相当缺乏。
表1 知识图谱推理综述文献分类（近三年）
Table1 Classificationofknowledgegraphreasoningsurveyarticles(thelatestthreeyears)
分类 子类 文献及发表年
知识图谱补全任务 [2](2021)、[5](2020)、[6](2020)、[7](2020)、[8](2022)、[9](2022)
推理任务类
知识图谱问答任务 [10](2021)、[11](2022)
综述
知识图谱推荐系统任务 [12](2020)、[13](2021)、[14](2021)、[15](2022)、[16](2022)
领域应用类 临床医疗、风险管理、智能制
[17](2021)、[18](2022)、[19](2022)、[20](2022)、[21](2021)、[22](2021)
综述 造、安全情报等
推理方法类综述 [3](2022)、[23](2020)、[24](2022)、[25](2022)、[26](2022)、[27](2022)、[28](2022)、[29](2022) 孙水发 等：图神经网络应用于知识图谱推理的研究综述 29
近年来，图神经网络（graphneuralnetwork，GNN） 展。因此，把提供了关于事实何时成立的时序信息
因其对图结构数据强大的编码能力，被广泛用于知识 嵌入在事实三元组中，将三元组拓展成时序四元组
图谱的构建。知识图谱以节点和边的图结构存储数 （头实体，关系，尾实体，时序），这种带有时序信息的
据，图神经网络可以有效整合知识图谱结构特征及 知识图谱被称为“时序知识图谱（temporalknowledge
属性特征[30]，通过节点的邻域信息聚合并更新节点， graph，TKG）[33]”。而现有的知识图谱研究大多数都
利用其强大的信息传播能力学习数据间的语义关系 关注的是静态知识图谱。
和潜在信息[16]，使其可以很好地学习知识图谱中的节 1.2 知识推理
点信息、节点间关系信息以及全局结构信息。由于 知识推理就是根据初步构建的知识图谱中实体
准确地学习知识图谱中有效的语义信息和结构信息 和关系所蕴含的信息，利用相关算法，推理出知识图
是开展知识推理的关键[31]，图神经网络在知识图谱数 谱中缺失的实体或者缺失的关系。本质上就是利用
据加载、数据处理，特别是在知识推理上都具有明显 已经存在的知识推出未知的或者新知识的过程[26]，其
的优势。尽管已有诸多的知识推理方法类综述文 核心都是针对三元组中的实体和关系进行预测，具
献，但仍缺乏对将知识推理和图神经网络相结合的 体可分为实体预测和关系预测。实体预测是指利用
研究进行系统梳理和总结的文献。与现有综述类工 已有事实的关系及一个实体，推理出另一个实体并
作相比，本文的创新主要体现在以下三方面： 由此构成完整三元组；关系预测是推理给定的头尾
（1）对知识推理文献进行了系统的分类整理，类 实体之间的关系[34]。无论实体预测还是关系预测，最
别包括基于逻辑规则、基于表示学习、基于神经网络 后都转化为选择与给定元素更有可能形成有效三元
和基于图神经网络的推理，阐述并比较了不同知识 组的实体或关系，并将其作为推理预测结果，这种有
推理方法的原理及优缺点。 效性可以通过规则的方式推理或通过基于特定假设
（2）调研了基于图神经网络的知识推理相关文 的得分函数计算得到[35]。从结构上讲，知识推理工作
献，总结了基于图神经网络的知识推理的最新研究 主要包括局部任务和全局任务。局部任务即节点分
进展，首次将基于图自编码网络和基于时空图神经 类、链接预测、知识补全等任务；全局任务即子图匹
网络的知识推理进行了综述分析。 配、子图分类、图趋势预测等[36]。子图匹配简单来说
（3）总结了基于图神经网络的知识推理方法在理 就是给定一个查询图Q，在数据图G中找到与图Q结
论、算法和应用方面的现状、问题和未来发展前景。 构相同的图；子图分类是指给定多张图以及每张图
对应的标签，通过学习得出一个由图到相应标签的
1 知识推理研究进展 图分类模型；图趋势预测是通过现有图谱，有效挖
1.1 知识图谱 掘、预测数据中的规律和知识[37]。
知识图谱是一种比较通用的语义知识的形式化 目前，关于知识推理方法类的综述较多（如表
描述框架，用节点表示语义符号，用边表示符号之间 1），但大多都只包括了部分推理方法和有限的文献
的语义关系，形式化的表述用事实三元组（头实体， 调研，尤其是对于近年兴起的基于图神经网络的知
关系，尾实体）来记录[32]。相比传统的语义网络，知识 识推理内容缺少梳理，还没有专门基于图神经网络
图谱因为简易的数据表征方式、多样化的知识表示 的知识推理的综述。因此，本文总结了当前与知识
和多层次的语义表达等优点，使得其能够在数据量 图谱和图神经网络相关的研究，在Chen等人[23]提出
大、场景复杂的情况下有效运用于挖掘关联知识和 的框架和基础上，将知识推理方法分为基于逻辑规
复杂关系。 则、基于表示学习、基于神经网络和基于图神经网络
然而，由于结构化的知识仅仅在特定的时间段 四大类（如表2），并对各类知识推理方法进行简明阐
内成立，时序信息是非常重要的，而事实的演化也会 述和对比，在此基础上重点总结了基于图神经网络
遵循一个时间序列。时序知识图谱除了描述语义关 的知识推理的最新研究进展。
系外，还需要考虑与时间关系的描述。它不单单是 （1）基于逻辑规则的推理。早期的知识推理主
一个“增强型”的开放域知识图谱，而是需要结合业 要是基于逻辑规则的推理，其基本思想是借鉴传统
务场景和领域知识，并针对时序知识自身的特点，对 知识推理中的规则推理方法，在知识图谱上运用简
知识的概念、实体和关系进行语义化和时空化拓 单规则或统计特征进行推理。主要包括基于一阶谓 30 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
表2 知识推理方法分类和典型算法
Table2 ClassificationofKGreasoningmethodsandtheirtypicalalgorithms
分类 子类 典型算法
基于一阶谓词逻辑 DL(descriptionlogic)[38]、FOIL[39]、AMIE[40]
基于逻辑规 基于规则 NELLs[41]、ProPPR[42]、MLNs[43]、ProbKB[44]、PSL[45]、HL-MRFs[46]
则的推理 基于本体 OWL-EL[47]、OP[48]、KGRL[49]
基于随机游走 PRA[50]、SFE[51]、CPRA[52]
基于张量分解 RESCAL[53]、RESCAL-Logit[54]、PRESCAL[55]、MF-TF[56]
TransE[57]、TransH[58]、TransR[59]、PTransE[60]、TransD[61]、TranSparse[62]、TransG[63]、Know-Evolve[64]、HyTE[65]、
基于表示学 基于距离模型
UGKE[66]
习的推理
基于语义匹配 SME[67]、DistMult[68]、HolE[69]、ComplEx[70]
基于多源信息 KALE[71]、TEKE[72]、pLogicNet[73]、IterE[74]
基于卷积神经网络 DKRL[75]、ConMask[76]、MT-KGNN[77]、ConvE[78]、ConvKG[79]
基于神经网
基于循环神经网络 Path-RNN[80]、IRNs[81]、DSKG[82]
络的推理
基于强化学习 DeepPath[83]、MINERVA[84]、MARLPaR[85]、GRL[86]、DAPath[87]
递归图神经网络 GNN[88]、GraphESN[89]、GGNN[90]、SSE[91]
基于图神经 卷积图神经网络 GCN[92]、GraphSAGE[93]、RGCN[94]、SACN[95]、CompGCN[96]、GAT[97]、GaAN[98]、GENI[99]、NAKGR[100]
网络的推理 图自编码网络 DNGR[101]、SDNE[102]、GAE[103]、ARGA[104]、DGMG[105]、NetGAN[106]、M2GNN[107]
时空图神经网络 DCRNN[108]、ST-GCN[109]、GWN[110]、GMAN[111]、TFGAN[112]
词逻辑[38-40]、基于规则[41-46]、基于本体[47-49]和基于随机 外，基于表示学习的推理只考虑满足知识图谱事实
游走算法[50-52]。基于逻辑规则的推理算法优点是：有 的约束，没有考虑更深层次的成分信息，限制了其推
坚实的数学基础，可解释性强；当结合大规模解析语 理能力（表3）。
料库和背景知识时，可模拟人类的推理能力，捕捉知 （3）基于神经网络的推理。深度学习模型的构
识图谱中隐藏的语义信息，这使得结合先验知识来 建一定程度上参考了人类大脑多层生物神经网络的
辅助推理成为可能。然而，知识图谱中的节点往往 结构，模拟人脑通过对低层特征进行组合以形成更
服从长尾分布，即只有少数实体和关系的出现频率 加抽象的高层特征。基于神经网络的推理具备更强
较高，而大多数实体和关系出现的频率较低，故基于 的泛化能力和学习能力，将前文所述的表示学习方
逻辑规则的推理无法解决数据稀疏性问题，无法很 法通过多个非线性表示层组合起来，再对其深度特
好处理多跳推理问题，也严重影响推理性能；加之基 征进行表示，进而开展知识推理。主要包括基于卷
于逻辑规则的推理对逻辑背景知识和规则定义的依 积神经网络[75-79]、基于循环神经网络[80-82]和基于强化
赖度较高，因此泛化能力十分有限，并不适用于包含 学习[83-87]的神经网络。基于神经网络的知识图谱推
大量潜在推理模式的大规模知识图谱（表3）。 理可以把已有的知识图谱中存在的关系保存到神经
（2）基于表示学习的推理。基于表示学习推理 网络中。因此，基于神经网络的方法具备更高的学
算法的中心思想是找到一种映射函数，将语义网络 习能力、推理能力和泛化能力，不仅能够学习海量的
中的实体、关系和属性映射到低维实值向量空间以 文本语料，缓解大规模知识图谱带来的数据爆炸问
获得分布式表示，进而捕获实体和关系之间的隐式 题，并且可以直接建模知识图谱事实元组，降低了计
关联。研究人员提出了大量基于表示学习的推理方 算难度，甚至还能通过合理设计和使用辅助存储单
法，包括基于张量分解[53-56]、距离模型[57-66]、语义匹配[67-70] 元，在一定程度上模拟人脑推理和思考问题的过
和多元信息模型[71-74]。表示学习发展迅速，在大规模 程。但随着模型复杂度相对较高，也导致了可解释
知识图的知识表示和推理中显示出巨大的潜力。该 性较差的问题（表3）。
算法可以解决基于逻辑规则算法无法解决的数据稀 （4）基于图神经网络的推理。随着知识图谱规
疏性问题，具有较强的泛化能力，且能在大规模知识 模的不断扩大和应用场景的不断深化，传统的基于
图谱上取得一定的效果。但也存在实体和关系向量 逻辑规则、基于表示学习的模型始终存在效率低下、
值缺乏明确的物理意义及可解释性较差的问题。另 规则覆盖率低的问题，无法满足对大规模知识图谱 孙水发 等：图神经网络应用于知识图谱推理的研究综述 31
表3 各类知识图谱推理方法的原理、优势及不足
Table3 Principles,advantagesanddisadvantagesofKGreasoningmethods
知识图谱推理分类 原理 优势 不足
无法解决数据稀疏性问题，无法
基于逻辑规则的推 可解释性强，可以捕捉知识
运用简单规则或统计特征进行推理 很好处理多跳推理问题，泛化能
理[38-52] 图谱中隐藏的语义信息
力有限
将语义网络中的实体、关系和属性映射到低维
基于表示学习的推 解决了数据稀疏性问题，具 可解释性较差，没有考虑更深层次
实值向量空间以获得分布式表示，进而捕获实
理[53-74] 有较强的泛化能力 的成分信息，推理能力有限
体和关系之间的隐式关联进行推理
具备更高的学习能力、推理 严重依赖文本的数量及质量；存在
基于神经网络的推 利用多个非线性表示层组合起来，提取知识图 能力和泛化能力，缓解大规 稀疏奖励、难以适应动态增长的知
理[75-87] 谱的深度特征进行表示，进而开展知识推理 模知识图谱带来的数据爆炸 识图谱；模型复杂度相对较高，可
问题，降低了计算难度 解释性较差
通过图卷积的方式来聚合相邻节点的信息（包
基于图神经网络的 可以同时学习语义信息和结
括语义信息和结构信息），得到节点表示进行 模型的复杂度高
推理[88-112] 构信息，推理能力强
推理
进行推理的要求；基于传统神经网络的推理技术则 经网络的知识推理，可以较好地将知识图谱语义信
欠缺解释性。以上大多数模型的核心都在提高图谱 息和结构信息同时考虑，尤其是能够捕捉知识图谱
语义信息获取能力，较少考虑图谱的结构信息。 的结构信息，已逐渐成为知识推理热门研究方法。
图神经网络的优势在于：一是图神经网络采用 在输入上，基于图神经网络的知识推理模型将图形
图数据的表征方式，这与知识图谱图数据结构相契 结构和节点内容信息作为输入。在训练框架上，可
合；二是图神经网络在信息传播和计算过程中是在 以在端到端学习框架内以（半）监督或无监督的方式
已有图的节点和关系上进行优化计算，不再添加新 训练，具体取决于学习任务和可用的标签信息。在
的信息节点；三是虽然图上的计算量也较大，但是相 输出上，可以根据不同推理任务来制定输出机制，通
比线性神经网络中的计算传导，这使得计算的传播 过激活函数将知识图谱节点的表示作为输出，可以
更具针对性；四是节点上的信息计算方式考虑了该 执行知识推理的节点分类、节点标签预测等节点级
节点的隐层信息和邻节点信息及图数据所携带的结 任务（如图1）。同理，将GNN中两个节点的隐藏表
构信息，在预测过程中也更具解释性（表3）。因此， 示作为输出，可利用相似性函数或神经网络来预测
基于图神经网络的知识推理，可以较好地将知识图 边的标签或连接强度等，执行边分类和链接预测等
谱语义信息和结构信息同时考虑，尤其是能够捕捉 任务（如图2）。通过在模型中加入多层感知器和
知识图谱的结构信息，已逐渐成为当下主流的研究 Softmax层，可处理图分类、子图匹配、图趋势预测等
方法。 知识推理全局任务（如图3）。
2 基于图神经网络的知识推理研究
近年来，人们对深度学习方法在图上的扩展越来
越感兴趣。在多方因素的成功推动下，研究人员借鉴
了卷积网络、循环网络和深度自动编码器的思想，定
义和设计了用于处理图数据的神经网络结构——图
神经网络（GNN）。图神经网络是一组复杂的神经网
络模型，可用于多类任务[37]。图1为图神经网络基本
模型，主要包括输入层、图卷积层、激活函数层和输
图1 图神经网络模型
出层。图卷积层通过聚合相邻节点的特征信息得到
Fig.1 Graphneuralnetworkmodel
每个节点的隐藏表示，然后通过激活函数层进行非
线性变换，得到新的图的表示，通过多次图卷积层和 现有的基于图神经网络的知识推理文献较少，
激活函数层，得到每个节点的最终表示。基于图神 且一般只概述了递归图神经网络（recurrent graph 32 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
图2 基于图神经网络的知识推理模型（边级任务） 图3 基于图神经网络的知识推理模型（全局任务）
Fig.2 GNNbasedKGreasoning Fig.3 GNNbasedKGreasoningmodel(globaltask)
model(side-leveltask)
对图神经网络分类的基础上，将基于图神经网络的知
neural networks，RecGNN）和卷积图神经网络（con- 识推理分为基于递归图神经网络[88-91]、卷积图神经网
volutional graph neural networks，ConvGNN）相关内 络[92-100]、图自编码网络[101-107]和时空图神经网络[108-112]的
容，缺少对图自编码网络（graph auto-encoders，GAE） 知识推理，全面总结了基于图神经网络的知识推理
和时空图神经网络（spatial-temporal graph neural net- 最新进展。表4为各类基于图神经网络的知识图谱
work，STGNN）在知识推理中应用的归纳。图自编码 推理方法的原理、优势及不足。本文也是首次尝试
网络和时空图神经网络已广泛用于知识推理任务中， 将基于图自编码网络和基于时空图神经网络纳入知
故本文结合最新的算法更新和领域应用，在Wu等人[37] 识推理中进行综述。
表4 各类基于图神经网络的知识推理方法对比
Table4 ComparisonofGNNbasedKGreasoningmethods
推理方法 原理 典型算法 年份 优势 不足
用相邻节点信息来表示节点， GNN[88] 2008 由于在每个时间步
基于 相比传统算法，模型同时考虑知识
通过不断地迭代传播邻接节点 GraphESN[89] 2010 都需要展开图中所
RecGNN 图谱的语义信息和结构信息，具备
信息，得到图谱中节点的最终 GGNN[90] 2015 有的节点，模型的收
的知识推理 更好的可解释性和更强的推理能力
表示，进而开展知识推理 SSE[91] 2018 敛速度和效率较差
GCN[92] 2013
GraphSAGE[93] 2017
将传统的卷积算子转移到图结
RGCN[94] 2018 模型直接对图域的邻接节点进行聚
构数据上,有效地聚集了邻接， 网络层数决定了网
基于 SACN[95] 2019 合，可以处理大型图；还可以通过节
通过计算中心单一节点与邻节 络处理效率，对于不
ConvGNN的 CompGCN[96] 2019 点采样技术提高效率；通过注意力
点之间的卷积来表示邻节点间 同的图结构泛化能
知识推理 GAT[97] 2017 机制可实现邻域对中心贡献程度的
信息的传递和聚合，用于知识 力较差
GaAN[98] 2018 自适应调节
推理任务
GENI[99] 2019
NAKGR[100] 2021
DNGR[101] 2016
SDNE[102] 2016
利用多层感知机作为编码器，
GAE[103] 2016 受限于无监督学习
基于GAE 获得节点的低维表示，然后解 无监督学习框架，既适用于无属性
ARGA[104] 2018 的应用场景，整体性
的知识推理 码器重构节点的邻域统计信 信息的普通图，还适用于有属性图
DGMG[105] 2018 能有待提升
息，进而开展知识推理任务
NetGAN[106] 2018
M2GNN[107] 2021
DCRNN[108] 2017
引入了时间序列特征，同时提 ST-GCN[109] 2017 同时考虑空间依赖性和时间依赖 模型复杂程度高，在
基于STGNN
取时域和空间域信息，可用于 GWN[110] 2019 性，可以处理高度非线性和复杂性 时间序列中的应用
的知识推理
开展时序知识图谱推理任务 GMAN[111] 2020 问题 效果有待提升
TFGAN[112] 2022 孙水发 等：图神经网络应用于知识图谱推理的研究综述 33
表5 基于递归图神经网络的知识推理算法归纳
Table5 RecGNNbasedKGreasoningalgorithms
典型算法 知识推理任务 涉及数据集 年份 优势 不足
随机图数据/诱变数 可以将图数据映射为向量表示，进 计算成本高，迭代效率低；要保证迭代
GNN[88] 子图匹配、节点分类 2008
据集 而开展应用 收敛，会限制模型的处理能力
消除了必须迭代收敛的约束，模型
计算量较大，不适合处理大规模图数
GGNN[90] 关系预测、节点分类 FacebookbAbI 2015 泛化能力更强；解决过深层的图神
据；对较远路径的信息会有所丢失
经网络导致过度平滑的问题
Amazonproduct 随机采样，学习效率高；可以处理大
SSE[91] 节点分类 2018 不能保证一定收敛
dataset/PPI 规模图数据
注：表中“知识推理任务”栏只罗列了算法涉及知识推理的任务。如GNN算法[88]中包括子图匹配、化合物诱变活性分析和网
页排序3个任务，但图中只列出了与知识推理相关的子图匹配任务以及对应数据库。
2.1 基于递归图神经网络 RecGNN 的知识 域所包含的信息。RecGNN的目标是通过不断迭代
推理 传播邻接节点信息 f ，直到模型达到稳定状态，进而
w
递归图神经网络（RecGNN）是图神经网络的先 得到节点的最终表示 g [114]。
w
驱（如表5）。RecGNN的目标是学习递归神经架构的 Scarselli等人[88]提到GNN可以直接处理大多数
节点表示，通过图中节点不断地与其邻接交换信息， 现实世界中的图问题，包括有向、无向、循环和非循
直到达到稳定的平衡。递归图神经网络的概念最早 环的图，且成功实现了将图数据映射到几何空间，并
由Gori等人[113]于2005年提出，Scarselli等人[88]对此模 开展了子图匹配、化合物诱变活性分析和网页排序
型进行了更详细的阐述，每个节点的定义是由该节 等任务，这是首次利用图神经网络处理图数据推理
点的属性特征（或标签特征）以及邻接节点来共同表 任务——子图匹配。其实验结果表明GNN对于结构
示（如图4），参数函数 f 称为局部变换函数，描述了 化数据的建模十分有效，但也存在着数据计算量大、
w
顶点n和其邻域顶点的依赖性。 g 称为局部输出函 迭代效率低等诸多的不足。Li等人[90]提出了GGNN
w
数，刻画了输出值的生成过程。 （gated graph neural network），GGNN 是基于 GRU
x f l l x l （1） （gatedrecurrentunit）的经典空间域模型，可以理解为
n= w( n, con, nen, nen)
[] [] []
GNN+Gate。相比GNN，GGNN的特点在于使用了
o g x l （2）
n= w( n, n)
GRU单元更新节点状态，解决了过深层的图神经网
其中，l 、l 、x 、l 分别表示顶点 n的属性、关
n con nen nen
[] [] [] 络导致过度平滑的问题。但由于在每个时间步都需
联边的属性、所有邻接节点的状态和属性，因此，每
要展开图中所有的节点，每个节点还需要使用向量
个节点 n 的状态 x R ，该状态 x 包含节点 n 的邻
n∈ s n
进行表示，当图很大且向量表示维度很高时，模型的
效率会出现较大问题。GGNN实际上是以损失图中
较长路径信息的代价换取了模型可建模的问题空间。
在此基础上，Dai等人[91]提出了SSE（stochastic
steady-state embedding）算法。SSE算法提出了一种
随机学习框架，可有效利用学习算法中的模型参数，
其主要思想是随机采样一批节点用于状态更新，随
机采样一批节点用于梯度计算，以随机和异步的方
式周期性更新节点隐藏状态。由于算法是随机训练
的，在收敛速度和执行时间方面对于大规模图是非
常有效的，且在多个知识推理任务中得到了验证。
综上所述，RecGNN旨在学习具有递归神经架构
图4 图和节点的邻域 的节点表示。它们假设图中的节点不断与其邻接
Fig.4 Domainsofgraphsandnodes （包括邻接节点和关联边）交换信息，直到达到稳 34 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
态。RecGNN在理论上很重要，它启发了后来学者们 用局部连接来减少学习参数，将卷积图神经网络扩
对卷积图神经网络的研究，基于空间的卷积图神经 展到大规模图数据分类问题上。Defferrard等人[116]设
网络继承了信息传递的思想。 计了图的快速局部卷积滤波器，其大大降低了计算
2.2 基于卷积图神经网络ConvGNN的知识 复杂度和学习复杂度，可以被运用到任何图结构数
据，可以理解为第二代卷积图神经网络。在此基础
推理
上，Levie等人[117]设计了更高效的卷积滤波器。为了
卷积图神经网络（ConvGNN）将卷积运算从网格
减少计算量并提高性能，研究者们探索出了不同的邻
数据（欧几里德数据，如图像数据）推广到了图形数
域聚合方法，如均匀邻接采样[93]、顶点重要性采样[118]
据（非欧几里德数据，如知识图谱）。2013年，Bruna
和基于随机行走的重要性采样[119]。Kipf和Welling[120]
等人[92]提出了基于谱域的图卷积网络（spectral-based
提出的GCN（graph convolutional network）利用Che-
GCN）和基于空间域的图卷积网络（spatial-based
byshev多项式拟合卷积核，可以学习图上局部结构特
GCN）两种模型，开创性地引入傅里叶变换，将图结
征并进行编码，较好地解决半监督任务，可理解为第
构信息由拉普拉斯矩阵特征向量表示，可以理解为
三代卷积图神经网络（如图5）。图5（a）是用于半监
第一代卷积图神经网络。表6对上述两类卷积神经
督学习的多层卷积图神经网络（GCN）示意图，输入
图网络进行了比较分析。基于空间域的图卷积网络
通道为C ，输出层为 F 特征图。图结构（边显示为黑
直接对图的邻接节点进行聚合，可以较好反映图数
线）在层上共享，标签用 Y 表示。图5（b）为两层
据的结构关系，更适合处理有向图和大型图数据。 i
GCN在Cora数据集上训练的隐藏层激活的可视化，
因此，目前利用卷积图神经网络的知识推理方法都
不同颜色表示不同标签类型。
是基于空间域方法进行研究。
卷积图神经网络传播规则可表示为：
与RecGNN不同，基于空间的ConvGNN通过多
层卷积来得到高阶节点表示，进而通过这些表示特 H(L +1) σ D  - 21 A  D  - 21 H(l )W(l ) （3）
= ( )
征对图数据进行节点分类、链接预测、图分类等任 其中，A   =A +I N 为图G 的带自环邻接矩阵；I N 为单
务。Henaff等人[115]在文献[92]的基础上定义了核，利 位矩阵；W(l ) 为可训练权重向量；σ 为激活函数；
(·)
表6 基于谱域的和空间域的卷积图神经网络比较
Table6 ComparisonofspectraldomainandspatialdomainbasedConvGNN
比较分析 基于谱域的卷积图神经网络方法 基于空间域的卷积图神经网络方法
模型在前向传播过程中，需要用到所有节点的拉普拉斯矩 直接对图的邻接节点进行聚合，可以处理大型图数据；还可以
效率
阵，计算开销大，难以处理大型图 通过节点采样技术提高效率
因需利用拉普拉斯矩阵的对称性实现，故只能处理无向图 可直接处理各种图（包括有向、无向、有环、无环、异构图等），
灵活性
（有向图只能转换为无向图来处理） 更加灵活
只能处理固定的图，不能处理动态图，不能对图进行修改， 在每个节点执行局部图卷积，可以在不同位置和结构之间共
通用性
泛化能力差 享权值，泛化能力强
图5 卷积图神经网络（ConvGNN）
Fig.5 Convolutionalgraphneuralnetworks(ConvGNN) 孙水发 等：图神经网络应用于知识图谱推理的研究综述 35
H(l ) RN ×D 为第 lth 层的激活矩阵，H(0) X 。其核心 全部数据且训练出来的表示唯一的短板。Graph-
∈ =
思想是学习一个函数映射，通过该映射图中的节点 SAGE实现了在大型图数据上的归纳表示学习，可扩
可以聚合自身的信息、邻接节点信息和结构信息来 展性更强，对于节点分类和链接预测问题的表现也
生成节点的表示[121]。ConvGNN在建立许多其他复 比较突出。
杂的GNN模型中起着核心作用。 在知识图谱实体分类或链接预测任务中，许多
2.2.1 基于空间域的卷积图神经网络 丢失的信息都可能存在于邻域结构编码的图中，即
基于空间域的ConvGNN的知识推理，将知识图 可以通过三元组中的任意两个推测出第三个元素。
谱视作无向图，利用ConvGNN分析拓扑结构，实现 据此，Schlichtkrull等[94]提出了R-GCN，R-GCN为图
邻域向中心实体的语义聚合，典型方法包括Graph- 谱中的实体生成隐性特征表示，可理解为知识图谱
SAGE（graph sample and aggregate）[93]、R-GCN（rela- 中的实体属性标签，并将其应用于两个任务中。对
tional graph convolutional network）[94]、SACN（structure- 于实体分类任务，R-GCN参考GCN[120]算法，对图中
aware convolutional networks）[96]、RGHAT（relational 的每个节点使用Softmax分类器进行节点分类；对于
graph neural network with hierarchical attention）[15]、H- 关系预测任务，R-GCN提取每个节点的表示，通过两
GCN（hierarchical graph convolutional network）[122]等 个节点的表示来预测节点间关系。R-GCN的主要贡
（如表7）。 献在于：显示了GCN的框架可以应用于关系数据建
GCN[120]的基本思想是把图数据中节点的高维邻 模，特别是关系预测和实体分类任务；引入了参数共
接信息降维到低维的向量表示，其本质是“直推式 享和实现稀疏约束的技术，并将其应用于具有大量
（transductivelearning）”，即需要知道图数据的全部信 关系的多图分析中。
息进行训练，且模型无法快速得到新节点的表示。 Vashishth等人[95]设计了一种针对多关系有向图
GraphSAGE[93]提出了一种新的方法，相比GCN捕捉 的图神经网络CompGCN（composition-based multi-
图的全局信息、保存映射结果的方法，该算法属于 relationalgraphconvolutionalnetworks）来同时学习节
“归纳式（inductive learning）”，即聚合邻接信息得到 点和关系的表示。另外，为了降低大量不同类型关
图数据表示的映射函数，因此也可以对图谱中新增 系带来的大量参数的影响，设计了一种分解操作，将
的节点进行表示（如图6）。因此，GraphSAGE更具有 所有关系都用一组基的加权组合来表示。模型在多
泛化能力，也解决了GCN模型训练节点时必须知道 个数据集上进行了链路预测、节点分类、子图分类等
表7 基于空间域的卷积图神经网络的知识推理算法
Table7 SpatialdomainbasedGCNnetworkKGreasoningalgorithms
典型算法 知识推理任务 涉及数据集 年份 优势 不足
生成节点表示的映射函数，泛化能 存在过采样或欠采样；不能对
任务1：Citation
力强；批量训练，节省内存，可应用 多边关系信息进行学习；训练
GraphSAGE[93] 节点分类 任务2：Reddit 2017
于大规模的图结构数据；可用于新 时间较长，内存占用大，效率
任务3：PPI
增节点的表示 不高
任务1：AIFB/MUTAG/BGS/
聚合了节点间的关系信息；节点的 实体的权重矩阵固定，灵活性
节点分类、链 AM
R-GCN[94] 2018 更新用共享参数并行计算，效率更 不够；参数与关系的数量有关，
接预测 任务2：WN18/FB15K/
高；可以运用到异构图 可能出现过拟合现象
FB15K-237
节点预测、分 复杂度低，效率更高；使用重要性 固定采样节点个数，灵活性不
FastGCN[118] Cora/Pubmed/Reddit 2018
类 采样减少了对数据的过度依赖 够；会引入估计偏差
模型深度更深，可以捕获更多全局
H-GCN[122] 节点分类 Cora/Citeseer/Pubmed/NELL 2019 信息；避免了重复邻域聚合中过度 对少样本节点识别性能更好
平滑问题
节点分类、链接 同时学习节点和关系编码；解决了
CompGCN[95] FB15K-237/WN18RR 2019 计算量增加
预测、图分类 多关系图表示参数过载问题
利用权重信息增加同类型节点间
WN18/FB15K/FB15K-237- 模型更复杂；不适用开放式的
SACN[96] 链接预测 2019 强度；同时学习三元组结构信息和
Attr 知识图谱
实体属性信息；准确率高 36 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
图6 GraphSAGE核心思想
Fig.6 CoreideaofGraphSAGE
实验，验证了CompGCN的有效性。为解决知识图谱 示，进而开展知识图谱补全任务（如图7）。
中三元组不完整问题，Shang等人[96]结合加权卷积图 2.2.2 基于图注意力机制的卷积图神经网络
神经网络（weighted graph convolutional neural net- 2017 年，Veličković等人[97]提出了 GAT（graph
work，WGCN）和Conv-TransE两个模块，提出了SACN attention network），GAT是一种基于空间结构的图神
（structure-aware convolutional network）模型。模型 经网络，在聚合邻域特征信息时，通过注意力机制确
使用WGCN作为编码器，将节点结构、节点属性、关 定采样节点权重信息，比GCN多了一个自适应的边权
系类型作为输入，WGCN中的可学习权值有助于从 重系数[123]，从而实现邻域对中心贡献程度的自适应调
相邻图节点中收集自适应量的信息；将Conv-TransE 节。GAT无需提前知道整个网络的结构，即可通过局
作为解码器，在Conv-TransE的节点嵌入表示保留了 部信息获取到网络的整体信息，避免了大量矩阵运
实体和关系之间属性信息，并可以较好用于知识图 算。本质上，GAT是将原本GCN的标准化函数替换
谱补全任务。SACN通过WGCN来建模KG中的实 为使用注意力权重的邻接节点特征聚合函数。因此
体和关系，提取实体特征，然后输入至Conv-TransE 模型可以直接应用到归纳推理的问题中，包括知识
中使实体满足KG三元组约束，得到实体的嵌入表 图谱的节点分类、链接预测等任务。典型方法包括
图7 知识推理局部任务（SACN）
Fig.7 Knowledgereasoninglocaltask(SACN) 孙水发 等：图神经网络应用于知识图谱推理的研究综述 37
MGAT（multi-view graph attention network）[124]、TGAT 层注意的关系图神经网络Encoder-Decoder框架。
（temporal graph attention）[125]、NAKGR（neighborhood Xu等人[127]提出DPMPN（dynamically pruned message
attention knowledge graph reasoning）[100]等，图8为利 passing networks）模型，以同时编码完整的图数据表
用MGAT算法开展链接预测和节点分类模型框架图。 示和由注意力模块学习的局部图数据表示，实现推
2019年Nathani等人[126]提出了基于图注意力网 理过程中子图的动态构建。Xie等人[128]提出ReIncep-
络（GAT）的知识图谱关系推理模型KBGAT（know- tionE（relation-aware inception network with joint local-
ledge bases GAT），该模型使用多头注意力机制来进 global structural information for knowledge graph em-
行目标节点周围信息的收集，以解决隐藏信息获取困 bedding）模型，结合ConvE和KBGAT[127]，利用关系感
难的问题，提升了关系预测的准确率。Zhang等人[98] 知注意力（relation-aware attention，RAATT）机制实现
提出了基于门控注意力机制的GaAN（gated atten- 对图谱结构信息的深入理解。康世泽等人[129]提出
tion networks）模型，不同于传统的多头注意机制（均 HE-GAN（heterogeneous information network embed-
衡地消耗所有的注意头），门控注意机制可以通过引 ding framework via graph attention network）模型，通
入的门控单元来调节参与内容的数量，使用一个卷 过堆叠图注意力网络，有效学习实体的高阶邻接特
积子网络来控制每个注意头的重要性。由于在门控 征，实现对知识图谱语义的完整表达[130]。已有较多
单元的构造中只引入了一个简单的、轻量级的子网， 的模型较好地将基于GAT的图神经网络引入到知
计算开销可以忽略不计，而且模型易于训练。Zhang 识图谱领域，并开展节点分类、关系预测等推理任
等人[7]提出了一个用于知识图谱补全任务的具有分 务[131-133（] 表8）。
图8 MGAT模型框架图
Fig.8 FrameworkofMGATmodel
表8 基于GAT的卷积图神经网络的知识推理算法
Table8 GraphattentionmechanismbasedGCNreasoningalgorithms
典型算法 知识推理任务 涉及数据集 年份 优势 不足
多个注意头的贡献相等，
GAT[97] 节点分类 Cora/Citeseer/Pubmed/PPI 2017 利用注意力机制分配节点权重，表达能力更强
忽略了边的特征信息
利用门控注意力机制调节各头的聚合范围和
GaAN[98] 节点分类 PPI/Reddit 2018 模型复杂度更高
重要性权重，表示更准确；可扩展至时空预测
WN18RR/FB15K-237/ 考虑了边的信息特征，可捕获实体的多跳邻 无法处理实体间多边
KBGAT[126] 关系预测 2019
NELL-995 域的实体和关系 关系嵌入表达
链接预测、节点 CKM/LAZEGA/Citeseer/ 能够捕获隐藏的更复杂的关系模式，有较好 无法处理开放式知识
MGAT[124] 2020
分类 Cora/DBLP/Twitter 的泛化能力 图谱
WN18RR/FB15K-237/ 嵌入维度较高时效果
ATTH[133] 链接预测 2020 利用双曲模型同时捕获层次信息和逻辑关系
YAGO3-10 较差
WN11/FB13/WN18/ 同时获取实体和关系特征，同样适用开放式 不能较好学习多跳邻
NAKGR[100] 知识推理 2021
FB15K 的知识图谱 接信息
链接预测：WN18RR/
HE- 链接预测、节点 融合知识图谱高阶邻居信息，可较好处理节
FB15K-237 2021 模型的通用性不够
GAN[129] 分类 点间多关系知识图谱
节点分类：DBLP/IMDB 38 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
2.3 基于图自动编码GAE的知识推理 神经网络结构将图的节点映射到潜在空间特征表示
图自动编码神经网络是一种无监督的学习框架， 为低维向量，并从潜在的表示中解码图形信息，进而
它将节点/图编码到潜在向量空间中，并从编码的信 开展节点分类、链接预测等任务。在网络嵌入方法
息中重建图数据。GAE[103]用于学习网络嵌入和生成 中，GAE通过重构邻接矩阵等图结构信息来学习潜
新的图形（如图9）。编码器使用图卷积层来获得每个 在节点表示，它保留了节点的结构信息。图自编码
节点的网络嵌入表示，解码器计算给定网络嵌入的成 器的挑战是邻接矩阵的稀疏性，这使得解码器的正
对距离。在应用非线性激活函数后，解码器重建图邻 条目数远远小于负条目数。典型的解决方案是利用
接矩阵。网络通过真实邻接矩阵与重构邻接矩阵之 多层感知机作为编码器来获取节点嵌入，利用解码
间的最小化差异来训练。图自动编码网络又分为基 器重建节点的邻域统计信息[134-135]。利用网络嵌入的
于网络嵌入的图自动编码方法和基于图生成的图自 图自编码方法开展知识推理的典型方法包括DNGR
动编码方法。基于网络嵌入的图自编码方法利用神 （deep neural networks for learning graph representa-
经网络结构将图的顶点表示为低维向量，可以用于知 tion）[101]、SDNE（structural deep network embedding）[102] 、
识图谱节点分类或链接预测任务[104]；基于图生成的图 VGAE（variational graph auto-encoder）[103]和ARVGA
自动编码方法是在给定一组观察到的图的情况下生 （adversarially regularized variational graph autoenco-
成新的图，可以很好地应用到知识推理的知识补全任 der）[104]等（表9）。
务中。 DNGR 用深度神经网络的随机冲浪（random
2.3.1 基于网络嵌入的图自编码方法 surfing model）替代采样（conventional sampling）的方
基于网络嵌入的图自动编码方法的目的是利用 式为每个顶点生成一个低维向量表示，方便更准确、
图9 GAE模型
Fig.9 GAEmodel
表9 基于网络嵌入的图自编码网络知识推理算法
Table9 Networkembeddingbasedgraphauto-encodersnetworkKGreasoningalgorithms
典型算法 知识推理任务 涉及数据集 年份 优势 不足
解决了采样序列长度有限的问题，更直接捕获 未考虑节点特征信息；使用固定
20-NewsGroup/
DNGR[101] 节点分类 2016 图的结构信息；可处理数据稀疏性问题，有效 步长传播信息，可伸缩性不强；训
Wine/Wikipedia
地降低噪声并增强鲁棒性；时间复杂度更低 练不稳定，耗时较长
未考虑节点特征信息；只考虑了
BlogCatalog/ 分别用一阶、二阶相似性，有效捕获高度非线
节点分类、链接 节点的一阶、二阶相似性，网络表
SDNE[102] Flickr/Youtube/ 2016 性网络局部特征和全局特征；通过带权重采
预测 现不够好；对新添加孤立点无法
20-NewsGroup 样，可有效挖掘非一阶节点间的关系
很好表示
可同时学习图的结构信息和节点内容特征；学 浅层模型，无法捕捉高度非线
GAE、 Cora/Citeseer/
链接预测 2016 习到的隐表示的维数可以远远小于输入数据 性的网络结构，导致网络表现
VGAE[103] Pubmed
的维数，实现降维的目的 不够好
学习具有规则等价节点的网络嵌入；重建一些
DRNE[135] 节点分类 Jazz/BlogCatalog 2018 顶点的隐藏状态，而不是整个图形；可以更好 通过反复迭代更新，效率较慢
捕捉图的结构信息
ARGA、 节点分类、链接 Cora/Citeseer/ 可同时学习图的结构信息和节点内容特征，模
2018 复杂度更高
ARVGA[104] 预测 Pubmed 型鲁棒性更好 孙水发 等：图神经网络应用于知识图谱推理的研究综述 39
快速获取图的结构信息，进而开展下游任务。SDNE GraphRNN（graph recurrent neural network）[137]、
用一阶、二阶相似度有效捕获高度非线性网络局部 NetGAN（generating graphs via random walk）[106]和
特征和全局特征，实验表明，所得到的表示可以有效 M2GNN（mixed-curvature multi-relational graph neu-
地作用于节点分类等下游任务。但DNGR和SDNE ralnetwork）[107]等（表10）。
只考虑节点结构信息，即节点之间的连通性，忽略了 Li等人[105]提出了DGMG，利用基于空间的卷积
节点可能包含描述节点本身属性的特征信息。Kipf 图神经网络来实现对现有图的隐藏表示。DGMG生
等人[103]结合图数据结构的特点，参考自编码器（auto- 成节点和边的决策过程是以整个图的表示为基础
encoders，AE）和变分自动编码器（variational auto- 的，具体取决于由RecGNN更新的生长图的节点状态
encoders，VAE），提出了图自动编码器（GAE）和变分图 和图状态。DGMG递归地在一个图中产生一个节
自动编码器VGAE。VGAE是基于VAE的无监督学 点，在添加新节点后的每一步，DGMG通过做出一系
习图结构数据的框架，该模型利用了潜在变量学习 列决策来生成图，即是否添加节点、添加哪个节点、
无向图的潜在表示，在链接预测任务上取得了较好 是否添加边以及哪个节点连接到新节点，因此，可以
的效果。Pan等人[104]提出的ARGA（adversariallyregu- 利用DGMG模型开展知识图谱的节点分类和链接预
larized graph autoencoder）和ARVGA算法将生成对 测任务。You等人[137]提出的GraphRNN是两级（图级
抗网络（generative adversarial network，GAN）加入到 和边级）循环神经网络的深度图生成模型。图级的
GAT中。网络主要分为三部分：编码器（生成）、解码 RNN每次向节点序列添加一个新节点，而边级的
器和判定器。判定器的任务就是训练一个二分类 RNN生成一个二进制序列，为新添加的节点生成
器，使它能够判别模型的输入到底是真实分布还是 边。Bojchevski等人[106]提出的NetGAN将LSTM（long
虚假分布。而编码部分则作为生成，其目的是要骗 short-term memory network）与Wasserstein-GAN结合
过判定器，由此循环迭代，就使得编码器的输出能够 在一起，使用基于随机行走的方法来捕获图的拓扑
尽可能地接近真实分布。 结构（如图10）。GAN框架由两个模块组成，一个生
2.3.2 基于图生成的图自编码方法 成器和一个鉴别器。生成器尽最大努力在LSTM网
基于图生成的图自动编码方法是在给定一组观 络中生成合理的随机行走序列，而鉴别器则试图区
察到的图的情况下，使用图神经网络来表示图的节 分伪造的随机行走序列和真实的随机行走序列。训
点和边之间的依赖关系生成新的图，构建图生成模 练完成后，对一组随机行走中节点的共现矩阵进行
型。在自然语言处理中，生成语义图或知识图谱通 正则化，可以得到一个新的图，可以用于知识图谱的
常以给定的句子为条件，生成新的图。通过将给定 链接预测任务。
条件下的新生成图与原图进行对比，即可开展知识 2.4 基于时空图神经网络STGNN的知识推理
推理的知识补全任务，如实体分类、关系预测等。通 一般的GCN方法可以较好地捕捉知识图谱中节
过设计合理的推荐条件或问答条件，新生成的图可 点之间的连接关系，保留网络中的空间关系的信息，
用于开展知识推理的知识推荐和知识问答任务[136]。 但缺乏捕捉时间关系的能力。时空图神经网络
利用网络嵌入的图自编码方法开展知识推理的典型 （STGNN）[109]将卷积图神经网络扩展到时空图模型，
方法包括DGMG（deepgenerativemodelsofgraphs）[105]、 旨在从时空图中学习隐藏模式，其基本假设是节点
表10 基于图生成的图自编码网络的知识推理算法
Table10 Graphgenerationbasedgraphauto-encodersnetworksKGreasoningalgorithms
典型算法 知识推理任务 涉及数据集 年份 优势 不足
图生成模型、节点分类、
DGMG[105] Cycles/Trees/B-AGraphs 2018 考虑了图的全局信息 时间复杂度高，效率较低
链接预测
图形较大时耗时长，无法
图生成模型、节点分类 Community/Grid/B-A/
GraphRNN[137] 2018 具有可扩展性和对噪声的鲁棒性 有效处理条件限制的图
（聚合） Protein/Ego
生成模型
Cora/DBLP/Citeseer/POL/ 保留了重要的拓扑信息，链接预 可解释性差；耗时长，效
NetGAN[106] 图生成模型、链接预测 2018
Pubmed/Polblogs 测能力较好 率偏低
WN18RR/FB15K-237/ 更好地保留图的复杂的异构信 对于多空间曲率权重的
M2GNN[107] 知识图谱补全、链接预测 2021
YAGO3-10 息，扩展性更强 分配，缺乏可解释性 40 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
图10 NetGAN模型
Fig.10 NetGANmodel
的未来信息取决于其历史信息及其邻接的历史信 图11描述了一种时空图神经网络模型，图卷积
息，其核心思想是同时考虑空间依赖和时间依赖。 层后是一维CNN层。图卷积层对时序知识图谱 A进
时空图神经网络中的空间依赖关系即对应知识图谱 行运算捕捉知识的空间相关性（图数据的拓扑结构
的拓扑结构信息，时间依赖即对应知识图谱的时序 关系），一维CNN层沿着时间轴变化来捕捉知识的时
信息，节点的信息即为实体属性信息。例如，在交通 间相关性。输出层通过多层感知机的线性变换，为
网络中，每个传感器连续记录道路的交通速度作为 每一个节点生成预测，比如下个时间步长内的节点
顶点，传感器对之间的距离作为交通网络的边。将 值，进而可以有效开展时序知识图谱的知识推理任
交通网络看作一个时序知识图谱，节点的属性即为 务。目前，利用时空图神经网络主要集中在开展知
路口的交通速度，边即表示不同路口的距离信息，节 识发现相关任务，较多的时序知识图谱推理任务主
点的属性随时间的变化而变化，也会受其他节点和 要集中在基于时空图神经网络的交通流预测以及军
边的影响。 事领域，未来也一定会扩展到更多领域。
传统时序知识图谱推理往往是对一般知识推理 基于时空图神经网络开展知识推理的典型方法
模型的扩展，将时间信息嵌入到关系信息中，这些方 包括DCRNN（diffusion convolutional recurrent neural
法往往很难捕获远距离依赖关系，对潜在实体和关 network）[108]、ST-GCN（spatio-temporal graph convolu-
系的表现较差，也难以有效编码时序知识图谱复杂 tional network）[109]、GWN（graph wavenet）[110]、T-GCN
的时空关系。基于时空图神经网络的时空预测方 （temporal graph convolutional network）[138]、GCRN
法，通过将节点在图结构上进行时空关系的模拟，较 （graph convolutional recurrent network）[139]、ASTGCN
好地保留了图数据的空间关系（拓扑结构）和时间关 （attention based spatial-temporal graph convolutional
系，与时序知识图谱的知识推理任务不谋而合，在 network）[140]、MTGNN（multivariatetimeseriesforecas-
复杂的空间关系中，能取得比传统方法更好的预测 ting with graph neural network）[141]和 TFGAN（traffic
效果。 forecasting using generative adversarial network）[112]等
图11 时空图神经网络模型
Fig.11 Spatial-temporalgraphneuralnetworksmodel 孙水发 等：图神经网络应用于知识图谱推理的研究综述 41
表11 基于时空图神经网络的知识推理算法
Table11 Spatial-temporalgraphneuralnetworksbasedKGreasoningalgorithms
典型算法 知识推理任务 涉及数据集 年份 优势 不足
效率较低，不能很好地
DCRNN[108] 时空预测：交通预测 METR-LA/PeMS-BAY 2017 可同时捕获空间特征和时间依赖性
捕获长时间依赖
首次提出了GCN和TCN分别捕获空间依 无法捕获动态事件在
ST-GCN[109] 时空预测：交通预测 BJER4/PeMSD7 2017 赖和时间依赖信息，可捕获长期的时间依 多时间、多关系上的依
赖关系 赖性
忽略了不同节点在不
可以精确地捕捉数据中隐藏的空间依赖，
GWN[110] 时空预测：交通预测 METR-LA/PEMS-BAY 2019 同时间间隔之间的依
可捕获长期的时间依赖关系
赖关系
无法处理复杂关系；节
自制交通数据集（SZ- 图卷积网络用于捕获道路网络的拓扑结
T-GCN[138] 时空预测：交通预测 2019 点只包括单一信息，缺
taxi）、Los环路数据集 构，门控递归单元捕获时间相关性
少更多属性信息融合
Traveltimedatasets/ 不仅可以学习历史数据的局部复杂空间相
TFGAN[112] 时空预测：交通预测 Trafficspeeddatasets/ 2022 关性和动态时间依赖性，还可以学习不同 模型复杂度高
Trafficflowdatasets 时间步长与网络中其他节点的全局相关性
（表11）。Wu等人[110]提出了一种新的用于时空图建 3 基于图神经网络知识推理的应用
模的图神经网络结构GWN。它可以自适应依赖矩 描述常识和事实的知识图谱是学术界和工业界
阵并通过节点嵌入进行学习，故可以捕获数据中隐 广泛使用的知识表示方式，采用图构建知识和数据
藏的空间依赖。GWN具有一个堆叠的可扩展的一 之间的关联，是一种直接且有效的将知识和数据结
维卷积组件，整个框架以端到端的方式学习，其感受 合的方式。受益于图神经网络技术在信息传播和推
野随着层数的增加呈指数增长，能够有效处理大型 理上的优势，知识图谱中的先验知识被有效地引入
时序知识图谱。T-GCN图形卷积网络除了能够捕获 到应用任务中。知识图谱是互联网世界的数据基
交通信息和属性之间的知识结构和语义关系之外， 石，其高效的数据整合能力和数据关联能力使其在
还能够捕获交通的时空特征。 众多领域展示出越来越丰富的实际应用价值。目
图卷积网络用于捕获道路网络的拓扑结构，以 前，基于图神经网络的知识推理技术主要集中在常
对空间依赖性进行建模。门控递归单元用于捕获道 用的FB15K、YAGO、WN18、NELL-995、Cora、Cite-
路上交通数据的动态变化，以模拟时间相关性。受 seer、Pubmed、BlogCatalog等知识图谱数据集上开
最近生成对抗网络（GAN）和图卷积网络（GCN）在处 展，但也逐渐应用于医疗、智能制造、军事、交通、金
理非欧数据方面发展的启发，Khaled等人[112]提出了 融风险等众多生产生活实际领域中。
一种对抗多卷积图神经网络模型，命名为TFGAN（如 3.1 医学领域
图12）。图12（a）为TFGAN生成器结构，图12（b）为
在医学领域，随着医学信息系统和医学大数据
TFGAN判别器结构，图12（c）为TFGAN模型框架。
的发展，医院积累了海量的医疗数据，如何从这些异
TFGAN模型将非监督模型的弹性优势与监督训练提
构数据中筛选提炼信息，并加以整合、共享及应用，
供的监督优势相结合，以帮助GAN生成器模型生成 是推进智能医疗的关键问题。Vretinaris等人[142]对图
准确的流量预测。为了改进表示并有效地对隐式相 神经网络（GNN）模型进行了改进，将来自医学知识
关性建模，在生成器内构建多个GCN。同时，在每个
库的领域知识引入到查询图中，并在负采样过程引
图之后应用GRU和自我注意力机制来捕获跨节点的 入了生成对抗网络（GAN），以避免梯度消失的问题，
动态时间依赖性。该算法对六个真实世界的交通数 从而获得更好的性能，有效解决了医学领域的实体分
据集的三个交通变量（交通流量、速度和旅行时间） 类和实体消岐问题；Agrawal等人[143]利用R-GCN[94]模
进行实验，结果表明，TFGAN优于相关的最新模型，
型作为编码器，并使用张量分解作为解码器，使用知识
并取得了显著的推理效果。 图谱推理的方法来推断药物-蛋白质、蛋白质-蛋白质、 42 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
图12 TFGAN网络模型
Fig.12 TFGANnetworkmodel
药物-药物、药物-副作用等方面的相互作用；Ioannidis 达和相关性搜索推理问题的解决带来了可能性[9]。
等人[144]将蛋白质函数预测看作多关系图上的半监督学 由于知识图谱具有强大的知识表示和推理能力，知
习任务，并采用图神经网络（GNN）方法进行求解，利 识推理作为流程工业知识处理的重要环节一直备受
用图神经网络实现了蛋白质功能预测任务。 关注[146]。黄超[147]利用Graph SAGE结合多头注意力
目前，基于图神经网络的知识图谱推理在医学领 机制方法开展知识推理任务，完成了石墨烯知识图
域的探索和工作还不够深入。文献[7]总结了医学知 谱补全和关系预测等任务。Ma等人[148]探索了电子自
识推理目前面对的一些挑战和重要问题，并展望了其 动化设计（electronic design automation，EDA）中应用
发展前景和研究趋势，推进知识图谱、知识推理在医 R-GCN[94]的场景，利用知识图谱推理技术提升智能化
疗领域尤其是临床决策支持[5]、医疗智能语义检索[6]、 管理水平。基于图时空神经网络的知识推理对于智
医疗推荐[145]等方面的应用已成为了人们迫切的需求。 能制造的人机协同交互、物流配送、在线监控等方面
3.2 智能制造领域 也有较好的契合，未来定将在智能制造中扮演着越
在智能制造领域，数据和知识是实现制造业与 来越重要的角色。
新一代信息技术融合的基础，是实现智能制造的保 3.3 军事领域
障。知识图谱本质上是基于语义网络的思想，可以 构建基于军事信息库的知识图谱，可以为作战
实现对现实世界的事物及其相互关系的形式化描 指挥人员提供更加精确的情报，极大地提高部队作
述。该技术为智能制造领域数据及知识的关联性表 战效率。基于军事知识图谱，建立军事武器问答系 孙水发 等：图神经网络应用于知识图谱推理的研究综述 43
统和联合作战信息服务系统，可以实现军事辅助决 题。该方法训练了一个图推理模型（graph reasoning
策[149]。张清辉等人[150]定义了模型中概念之间的语义 model，GRM），该模型结合GGNN[90]可以对照片中人
关系和时序关系，提出了军事信息服务知识推理方 物的社会关系进行推理。另外，一种新的模型SR-
法，为任务驱动的军事信息服务领域知识的推理提 GNN（session-based recommendation with graph neural
供了理论基础。随着信息化战争加速向智能化战争 networks）[157]将会话序列建模为有向会话图，通过门
演化，如何系统规范地存储和表示作战知识，使无人 控图神经网络获得每个图中所有节点的潜在向量。
系统能够根据高层任务指令自主完成任务规划，并 接着，每个会话用一个注意力网络表示为全局偏好和
基于不断更新的战场知识进行重规划和智能决策， 当前兴趣的组合，最后预测每个项目在一次会话中成
也是一个新的研究领域[151]。未来，军事知识图谱以 为下次点击的概率。从知识图谱应用发展趋势来看，
及高效能的知识推理技术能够提供大规模自主知识 当前正值通用知识图谱应用转向领域知识图谱应用
约束空间内的解决方案及智慧指挥决策解决方案， 的阶段。目前，大规模知识图谱在智能语义搜索、知
在虚拟情报参谋、隐含知识发现、情报智能关联等场 识问答、演化分析、对话理解等方面的应用处于初级
景中发挥重要作用，提升部队作战能力。 阶段，潜在应用领域广泛，推广前景广阔[130]。
3.4 交通领域
随着时空图神经网络（STGNN）的快速发展，将 4 总结与展望
图卷积网络扩展到时空图模型，能从时空图中学习 4.1 总结
隐藏模式[109-110,141]。交通知识图谱可以实现交通流量 知识图谱推理的核心是针对三元组中的实体和
分析建模、航空交通管理以及公共场景挖掘等。交 关系进行预测，因此，需要对图数据的结构信息以及
通知识图谱可以实现同乘人员识别提取、公交站点 实体的属性信息进行表示，进而开展推理任务。
群出行量和运力挖掘、最大公交客流提取识别、线路 GNN依靠其强大的点和边来对非欧几里德数据建
站点上下车客流提取等，为公共交通领域提供了有 模，高效地解决了在实际应用中遇到的图结构数据
效的决策和参考。基于时序知识图谱和时空模型， 问题。图神经网络可以很好地学习知识图谱中的节
有学者提出了动态时空图神经网络的知识推理。例 点信息、节点间关系信息以及全局结构信息，本文分
如，文献[152]设计了一个动态图递归卷积神经网络 别从递归图神经网络、卷积图神经网络、图自编码网
（dynamicgraphrecurrentconvolutionalneuralnetwork， 络和时空图神经网络等方面对基于图神经网络的知
Dynamic-GRCNN）用于城市交通客流量的预测任 识推理的研究进行了综述，介绍了各类图神经网络
务。动态自我注意力网络（dynamicself-attentionnetwork， 的原理、特点及优势，并就基于图神经网络的知识推
DySAT）[153]在结构邻域和时间动力学两个维度联合 理在医学、智能制造、军事、交通等领域的应用进行
自我注意力来生成动态节点表示，实现了链路预测的 了归纳。
功能。基于动态时空图神经演化的图卷积网络 基于RecGNN的知识推理通过不断地迭代传播
（evolving graph convolutionalnetwork，EvolveGCN）[154] 邻接节点信息，得到图谱中节点的最终表示，进而开
模型，使用RNN演化GNN参数来捕获图序列的动态 展知识推理。相比传统算法，模型同时考虑知识图
性。其将时间信息引入交通领域知识图谱[111-112,142]，并 谱的语义信息和结构信息，具备更好的可解释性和
融合深度学习技术，整合多源数据的语义相关性，实 更强的推理能力；但由于在每个时间步都需要展开
现更贴合需求的智能化知识服务模型，在交通预测 图中所有的节点，使得模型的收敛速度和效率较
时空知识推理上将大有可为。 差。基于ConvGNN的知识推理通过中心节点与邻
3.5 其他领域 接节点之间的卷积来表示节点间信息。模型可以通
除此以外，知识图谱在教育、通信等领域也有广 过节点采样技术提高效率；通过注意力机制可实现
泛应用，比如学科问答机器人、通信故障定位分析、 邻域对中心贡献程度的自适应调节，实现了在大型
网络安全监测等。赵振兵等人[155]运用基于门控图神 知识图谱上开展推理任务；但浅层的网络结构往往
经网络（GGNN）[90]的知识图谱推理，完成了输电线路 使得推理的能力受到限制，不同模型的泛化能力也
螺栓缺陷分类任务。Wang等人[156]将知识推理与图 相对较差。基于GAE的知识推理利用多层感知机作
像识别相结合，探讨了一个有趣的社交关系推理问 为编码器，以获得节点的低维表示，然后利用解码器 44 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
重构节点的邻域信息，进而开展知识推理任务；但受 捉语义和结构信息的优势，优化推理模型，提高推理
限于无监督学习的应用场景，整体性能有待提升。 速度，扩展到大规模知识图谱，保证推理的时效性，
基于STGNN的知识推理引入了时间序列特征，同时 将成为未来需要致力解决的问题。针对将图神经网
考虑知识图谱的空间信息（结构信息）和时序信息， 络应用到大规模图上的研究同样是将来研究的热点
可用于开展时序知识图谱推理任务。但模型复杂程 问题，在这方面，引入摘要数据结构，构造局部图数
度较高，且在时间序列中的应用效果有待提升。 据，并能适当地融合局部图结构，形成整体图神经网
总体而言，基于图神经网络的知识推理可以较 络的表示是可能的途径之一。
好地将知识图谱语义信息和结构信息同时考虑，尤 四是开发有效的深度图神经网络。GNN的本质
其是能够捕捉知识图谱的结构信息。图神经网络的 是通过聚合邻接节点信息来表征中心节点，现有的
信息传播机制相较传统深度学习模型更具有可解释 图神经网络模型大多还是只限于浅层的结构。一般
性，利用图神经网络模型在知识图谱中实现知识推 来讲，深度图神经网络能更加捕获知识图谱的全局
理，从而显式地生成基于知识图谱的推理路径，或许 信息和结构信息，但当构造多层的神经网络之后，中
可以期待打开深度学习的黑盒。 心节点和邻接节点的差异就会变得微乎其微，实验
4.2 展望 结果反而变差，这是由过平滑现象造成的。如何解
未来面向图神经网络的知识推理方法仍将以各 决深度图神经网络过平滑现象，使图神经网络能够
类知识图谱下游任务作为依托，可应用到众多场景 应用于更多层的结构，从而发挥出深度学习与图神
中。与此同时，知识推理需要向自动化、智能化发 经网络的强大优势，构建更深的图神经网络模型仍
展，需要关注大规模（时序）知识图谱中知识推理的 是值得深入研究的问题。
可扩展性，大数据流处理中的推理效率、自动或半自 五是挖掘和探索知识图谱中更多有用的信息。
动的推理实现。最后从以下几个重点技术展望未来 在当前对于图神经网络模型的研究中，诸多学者将
基于图神经网络的知识推理的发展前景。 较多的精力放在了图数据中节点之间有无连接这一
一是融合多源信息和多种方法的知识推理技 拓扑结构信息（即知识图谱关系信息）。但知识图谱
术。随着文本、视频、音频数据的大量出现，众多知 除了节点间关系信息，里面还涉及较多的实体信息、
识以不同的形式被表达，因此基于多模态的知识推 实体属性信息，以及距离中心节点的远近不同的关
理技术将应运而生。从不同类型的数据中推理获得 系信息对中心节点的影响程度等。如果能够探索出
关联更符合客观世界规律的模型，也更容易被各类 知识图谱中更多有用信息的表示和利用，必会将基
工业任务所应用。融合基于图神经网络的知识推理 于图神经网络的知识推理性能提升一个层次。
与其他方法的知识推理，通过在更深层次混合，实现 六是图神经网络的工业落地。当前基于图神经
优势互补，提升推理性能将成为未来研究的热点。 网络的知识图谱研究大多还只停留在理论层面，亦
二是动态知识推理技术。目前，GNN处理的图 或者在实验数据集、公开知识图谱数据等进行测试
结构基本上都是静态图，基于时空图神经网络模型 验证，实际应用还非常有限。虽然基于图神经网络
虽然能处理时序知识图谱，目前针对GNN处理动态 的知识推理在部分领域（如医学领域、智能制造领
图结构的研究还比较少。传统基于静态图谱的推理 域、军事领域、交通领域等）已有一小部分的实际应
技术不能很好地表达时序信息，在众多工业应用场 用，但远没有达到大规模应用的程度。任何研究只
景中无法进行动态建模，也无法对时序信息进行处 有真正地在工业界落地，才能发挥它的应用价值，反
理。随着算力水平的提升，利用图时空神经网络，将 之也会促进其进一步的研究发展。尽快将图神经网络
时序信息加入知识推理技术将逐渐成为未来研究方 应用到实际的工业场景中是一个亟需解决的问题。
向之一。
三是面向大规模知识图谱的快速推理。信息时 参考文献：
代，随着数据的增长，知识图谱的规模越来越大将成 [1]RICHENSRH.Preprogrammingformechanicaltranslation
为未来的发展趋势，致使图中的节点数量变得巨大， [J].MechanicalTranslation,1956,3(1):20-25.
这就给图神经网络的计算带来了不小的挑战。因 [2] JIS,PANS,CAMBRIAE,etal.Asurveyonknowledgegraphs:
此，如何充分发挥图神经网络在知识推理中快速捕 representation, acquisition, and applications[J]. IEEE Tran- 孙水发 等：图神经网络应用于知识图谱推理的研究综述 45
sactions on Neural Networks and Learning Systems, 2021, ZHU D L,WENY,WAN Z C.Review ofrecommendation
33(2):494-514. systems based on knowledge graph[J]. Data Analysis and
[3]马昂,于艳华,杨胜利,等.基于强化学习的知识图谱研究 KnowledgeDiscovery,2021,5(12):1-13.
综述[J].计算机研究与发展,2022,59(8):1694-1722. [14] LIU J, DUAN L.Asurvey on knowledge graph-based re-
MAA, YU Y H, YANG S L, et al. Survey of knowledge commender systems[C]//Proceedings of the 2021 IEEE 5th
graph based on reinforcement learning[J]. Journal of Com- Advanced Information Technology, Electronic and Auto-
puterResearchandDevelopment,2022,59(8):1694-1722. mation Control Conference, Xi an, Oct 15-17, 2021. Pis-
'
[4]NEWELLA,SHAWJC,SIMONHA.Reportonageneral cataway:IEEE,2021:2450-2453.
problem solving program[C]//Proceedings of the 1st Inter- [15]程章桃,钟婷,张晟铭,等.基于图学习的推荐系统研究综
national Conference on Information Processing, Jun 15-20, 述[J].计算机科学,2022,49(9):1-13.
1959.Paris:UNESCO,1959:256-264. CHENGZT,ZHONGT,ZHANGSM,etal.Surveyofre-
[5]CHENZ,WANGY,ZHAOB,etal.Knowledgegraphcom- commendationsystemsbasedongraphlearning[J].Compu-
pletion:areview[J].IEEEAccess,2020,8:192435-192456. terScience,2022,49(9):1-13.
[6] ARORA S. A survey on graph neural networks for know- [16]田萱,陈杭雪.推荐任务中知识图谱嵌入应用研究综述
ledgegraphcompletion[J].arXiv:2007.12374,2020. [J].计算机科学与探索,2022,16(8):1681-1705.
[7]ZHANGZ,ZHUANGFZ,ZHUHS,etal.Relationalgraph TIANX,CHENHX.Surveyonapplicationsofknowledge
neural network with hierarchical attention for knowledge graph embedding in recommendation tasks[J]. Journal of
graphcompletion[C]//Proceedingsofthe34thAAAIConfe- Frontiers of Computer Science and Technology, 2022, 16
rence onArtificial Intelligence, the 32nd InnovativeAppli- (8):1681-1705.
cations ofArtificial Intelligence Conference, the 10thAAAI [17]乔凯,陈可佳,陈景强.基于知识图谱与关键词注意机制
Symposium on Educational Advances in Artificial Intelli- 的中文医疗问答匹配方法[J]. 模式识别与人工智能,
gence,NewYork,Feb7-12,2020.MenloPark:AAAI,2020: 2021,34(8):733-741.
9612-9619. QIAOK,CHENKJ,CHENJQ.Chinesemedicalquestion
[8]CAIB,XIANGY,GAOL,etal.Temporalknowledgegraph answeringmatchingmethodbasedonknowledgegraphand
completion:asurvey[J].arXiv:2201.08236,2022. keyword attention mechanism[J]. Pattern Recognition and
[9] ZEB A, SAIF S, CHEN J, et al. Complex graph convolu- ArtificialIntelligence,2021,34(8):733-741.
tional network for link prediction in knowledge graphs[J]. [18]范媛媛,李忠民.中文医学知识图谱研究及应用进展[J].
ExpertSystemswithApplications,2022,200:116796. 计算机科学与探索,2022,16(10):2219-2233.
[10]陈子睿,王鑫,王林,等.开放领域知识图谱问答研究综述 FAN Y Y, LI Z M. Research and application progress of
[J].计算机科学与探索,2021,15(10):1843-1869. Chinese medical knowledge graph[J]. Journal of Frontiers
CHEN Z R, WANG X, WANG L, et al. Survey of open- of Computer Science and Technology, 2022, 16(10): 2219-
domain knowledge graph question answering[J]. Journal of 2233.
Frontiers of Computer Science and Technology, 2021, 15 [19]董文波,孙仕亮,殷敏智.医学知识推理研究现状与发展
(10):1843-1869. [J].计算机科学与探索,2022,16(6):1193-1213.
[11]萨日娜,李艳玲,林民.知识图谱推理问答研究综述[J].计 DONG W B, SUN S L, YIN M Z. Research and develop-
算机科学与探索,2022,16(8):1727-1741. ment of medical knowledge graph reasoning[J]. Journal of
SA R N, LI Y L, LIN M. Survey of question answering Frontiers of Computer Science and Technology, 2022, 16
based on knowledge graph reasoning[J]. Journal of Fron- (6):1193-1213.
tiersofComputerScienceandTechnology,2022,16(8):1727- [20]袁俊,刘国柱,梁宏涛,等.知识图谱在商业银行风控领域
1741. 的研究与应用综述[J].计算机工程与应用,2022,58(19):
[12]GUOQ,ZHUANGF,QINC,etal.Asurveyonknowledge 37-52.
graph-based recommender systems[J]. IEEE Transactions YUAN J, LIU G Z, LIANG H T, et al. Summary of resea-
on Knowledge and Data Engineering, 2022, 34(8): 3549- rch and application of knowledge graphs in risk manage-
3568. ment field of commercial banks[J]. Computer Engineering
[13]朱冬亮,文奕,万子琛.基于知识图谱的推荐系统研究综 andApplications,2022,58(19):37-52.
述[J].数据分析与知识发现,2021,5(12):1-13. [21]张栋豪,刘振宇,郏维强,等.知识图谱在智能制造领域的 46 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
研究现状及其应用前景综述[J].机械工程学报,2021,57 23,2015.NewYork:ACM,2015:891-900.
(5):90-113. [32]赵军.知识图谱[M].北京:高等教育出版社,2018.
ZHANGDH,LIUZY,JIAWQ,etal.Areviewonknow- ZHAO J. Knowledge graph[M]. Beijing: Higher Education
ledgegraphanditsapplicationprospectstointelligentmanu- Press,2018.
facturing[J]. Journal of Mechanical Engineering, 2021, 57 [33] ZHU C C, CHEN M H, FAN C J, et al. Learning from
(5):90-113. history:modeling temporalknowledge graphswith sequen-
[22]丁兆云,刘凯,刘斌,等.网络安全知识图谱研究综述[J]. tialcopy-generation networks[C]//Proceedings of the 35th
华中科技大学学报(自然科学版),2021,49(7):79-91. AAAI Conference onArtificial Intelligence, the 33rd Con-
DING Z Y, LIU K, LIU B, et al. Survey of cyber security ference on Innovative Applications of Artificial Intelli-
knowledge graph[J]. Journal of Huazhong University of gence, the 11th Symposium on Educational Advances in
ScienceandTechnology(NaturalScienceEdition),2021,49 ArtificialIntelligence.MenloPark:AAAI,2021:4732-4740.
(7):79-91. [34]张仲伟,曹雷,陈希亮,等.基于神经网络的知识推理研究
[23]CHENX,JIAS,XIANGY.Areview:knowledgereasoning 综述[J].计算机工程与应用,2019,55(12):8-19.
over knowledge graph[J]. Expert Systems with Applica- ZHANG ZW,CAO L,CHEN X L,etal.Survey of know-
tions,2020,141:112948. ledge reasoning based on neural network[J]. Computer
[24] TIAN L, ZHOU X, WU Y P, et al. Knowledge graph and EngineeringandApplications,2019,55(12):8-19.
knowledge reasoning: a systematic review[J]. Journal of [35]官赛萍,靳小龙,贾岩涛,等.面向知识图谱的知识推理研
ElectronicScienceandTechnology,2022:100159. 究进展[J].软件学报,2018,29(10):2966-2994.
[25] YE Z, KUMAR Y J, SING G O, et al. A comprehensive GUAN S P, JIN X L, JIAYT, et al. Knowledge reasoning
survey of graph neural networks for knowledge graphs[J]. over knowledge graph: a survey[J]. Journal of Software,
IEEEAccess,2022,10:75729-75741. 2018,29(10):2966-2994.
[26]宋浩楠,赵刚,孙若莹.基于深度强化学习的知识推理研 [36]翁金塔,仇晶,张光华.面向推理的知识图谱表示学习方
究进展综述[J].计算机工程与应用,2022,58(1):12-25. 法综述[J].广州大学学报(自然科学版),2021,20(3):80-89.
SONG H N, ZHAO G, SUN RY. Developments of know- WENG J T, QIU J, ZHANG G H. The representation lear-
ledge reasoning based on deep reinforcement learning[J]. ning method of a knowledge graph for reasoning: a review
ComputerEngineeringandApplications,2022,58(1):12-25. [J].JournalofGuangzhouUniversity(NaturalScienceEdi-
[27]张宇,郭文忠,林森,等.深度学习与知识推理相结合的研 tion),2021,20(3):80-89.
究综述[J].计算机工程与应用,2022,58(1):56-69. [37]WU Z,PAN S,CHEN F,et al.Acomprehensive survey on
ZHANG Y, GUO W Z, LIN S, et al. Review on combina- graph neural networks[J]. IEEE Transactions on Neural
tion of deep learning and knowledge reasoning[J]. Compu- NetworksandLearningSystems,2020,32(1):4-24.
terEngineeringandApplications,2022,58(1):56-69. [38]LEETW,LEWICKIMS,GIROLAMIM,etal.Blindsou-
[28] ZHANG W, CHEN J, LI J, et al. Knowledge graph reaso- rce separation of more sources than mixtures using over-
ning with logics and embeddings: survey and perspective complete representations[J]. IEEE Signal Processing Let-
[J].arXiv:2202.07412,2022. ters,1999,6(4):87-90.
[29]马瑞新,李泽阳,陈志奎,等.知识图谱推理研究综述[J]. [39]SCHOENMACKERSS,DAVISJ,ETZIONIO,etal.Lear-
计算机科学,2022,49(S1):74-85. ningfirst-orderhornclausesfromwebtext[C]//Proceedings
MARX,LIZY,CHENZK,etal.Reviewofreasoningon of the 2010 Conference on Empirical Methods in Natural
knowledgegraph[J].ComputerScience,2022,49(S1):74-85. Language Processing,Cambridge,Oct 9-11,2010.Strouds-
[30] CAI H, ZHENG V W, CHANG K C C. A comprehensive burg:ACL,2010:1088-1098.
surveyofgraphembedding:problems,techniques,andapp- [40]GALÁRRAGALA,TEFLIOUDIC,HOSEK,etal.AMIE:
lications[J]. IEEE Transactions on Knowledge and Data association rule mining underincomplete evidence in onto-
Engineering,2018,30(9):1616-1637. logicalknowledge bases[C]//Proceedings of the 22nd Inter-
[31] CAO S S, LU W, XU Q K. GraRep: learning graph repre- national Conference on World Wide Web, Rio de Janeiro,
sentations with global structural information[C]//Procee- May13-17,2013.NewYork:ACM,2013:413-422.
dings of the 24th ACM International Conference on Infor- [41] MITCHELL T, COHEN W, HRUSCHKA E, et al. Never-
mation and Knowledge Management, Melbourne, Oct 19- ending learning[J]. Communications of theACM, 2018, 61 孙水发 等：图神经网络应用于知识图谱推理的研究综述 47
(5):103-115. 54thAnnual Meeting of theAssociation for Computational
[42] WANG W Y, MAZAITIS K, COHEN W W. Programming Linguistics,Berlin,Aug7-12,2016.Stroudsburg:ACL,2016:
with personalized pagerank: a locally groundable first- 1308-1318.
order probabilistic logic[C]//Proceedings of the 22ndACM [53]NICKELM,TRESPV,KRIEGELH P.Athree-way model
International Conference on Information and Knowledge for collective learning on multi-relational data[C]//Procee-
Management, San Francisco, Oct 27-Nov 1, 2013. New dings of the 28th International Conference on Machine
York:ACM,2013:2129-2138. Learning,Bellevue,Jun28-Jul2,2011.Madison:Omni-
[43]RICHARDSONM,DOMINGOSP.Markovlogicnetworks press,2011:809-816.
[J].MachineLearning,2006,62(1):107-136. [54]NICKELM,TRESPV,KRIEGELH P.FactorizingYAGO:
[44]CHENY,WANGDZ.Knowledgeexpansionoverprobabi- scalable machine learning for linked data[C]//Proceedings
listic knowledge bases[C]//Proceedings of the 2014 ACM of the 21st International Conference on World Wide Web,
SIGMOD International Conference on Management of Lyon,Apr16-20,2012.NewYork:ACM,2012:271-280.
Data, Snowbird Utah, Jun 22-27, 2014. New York:ACM, [55]WUY,ZHUD,LIAOX,etal.Knowledgegraphreasoning
2014:649-660. based on paths of tensor factorization[J]. Pattern Recogni-
[45] KIMMIG A, BACH S, BROECHELER M, et al. A short tionandArtificialIntelligence,2017,30(5):473-480.
introduction to probabilistic soft logic[C]//Proceedings of [56]JAIN P,MURTYS,CHAKRABARTIS.Jointmatrix-tensor
the 2012 NIPS Workshop on Probabilistic Programming: factorization for knowledge base inference[J]. arXiv:1706.
Foundations and Applications, Lake Tahoe, Dec 8, 2012. 00637,2017.
Cambridge:MITPress,2012:1-4. [57] BORDES A, USUNIER N, GARCÍA-DURÁN A, et al.
[46] BACH S H, BROECHELER M, HUANG B, et al. Hinge- Translating embeddings for modeling multi-relational data
loss Markov random fields and probabilistic soft logic[J]. [C]//Proceedings of the 27thAnnual Conference on Neural
JournalofMachineLearningResearch,2017,18:1-67. Information Processing Systems 2013, Dec 5-8, 2013. Red
[47] PUJARA J, MIAO H, GETOOR L, et al. Ontology-aware Hook:CurranAssociates,2013:2787-2795.
partitioning for knowledge graph identification[C]//Procee- [58]WANGZ,ZHANGJW,FENGJL,etal.Knowledgegraph
dings of the 2013 Workshop on Automated Knowledge embedding by translating on hyperplanes[C]//Proceedings
Base Construction, San Francisco, Oct 27-28, 2013. New of the 14th AAAI Conference on Artificial Intelligence
York:ACM,2013:19-24. Québec,Jul27-31,2014.MenloPark:AAAI,2014:1112-1119.
[48] CHEN Y, GOLDBERG S, WANG D Z, et al. Ontological [59] LIN Y, LIU Z, SUN M, et al. Learning entity and relation
pathfinding[C]//Proceedings of the 2016 International Con- embeddings for knowledge graph completion[C]//Procee-
ferenceon ManagementofData,San Francisco,Jun 26-Jul dings of the 15th AAAI Conference on Artificial Intel-
1,2016.NewYork:ACM,2016:835-846. ligence,Austin,Jan25-30,2015.MenloPark:AAAI,2015:
[49] WEI Y Z, LUO J, XIE H Y. KGRL: an OWL2 RL reaso- 2181-2187.
ning system for large scale knowledge graph[C]//Procee- [60] LINY, LIU Z, LUAN H, et al. Modeling relation paths for
dings of the 12th International Conference on Semantics, representation learning of knowledge bases[J]. arXiv:1506.
KnowledgeandGrids,Beijing,Aug15-17,2016.Washing- 00379,2015.
ton:IEEEComputerSociety,2016:83-89. [61] JI G, HE S, XU L, et al. Knowledge graph embedding via
[50] LAO N, COHEN W W. Relational retrieval using a com- dynamic mapping matrix[C]//Proceedings of the 53rd
binationofpath-constrainedrandomwalks[J].MachineLear- Annual Meeting of the Association for Computational
ning,2010,81(1):53-67. Linguistics and the 7th International Joint Conference on
[51]GARDNERM,MITCHELLT.Efficientandexpressiveknow- NaturalLanguageProcessing,Beijing,Jul26-31,2015.Stroud-
ledge base completion using subgraph feature extraction sburg:ACL,2015:687-696.
[C]//Proceedings of the 2015 Conference on Empirical [62]JIGL,LIUK,HESZ,etal.Knowledgegraphcompletion
Methods in Natural Language Processing, Lisbon, Sep 17- with adaptive sparse transfer matrix[C]//Proceedings of the
21,2015.Stroudsburg:ACL,2015:1488-1498. 30th AAAI Conference on Artificial Intelligence, Phoenix,
[52] WANG Q, LIU J, LUO Y F, et al. Knowledge base com- Feb12-17,2016.MenloPark:AAAI,2016:985-991.
pletion via coupled path ranking[C]//Proceedings of the [63] XIAO H, HUANG M, HAO Y, et al. TransG: a generative 48 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
mixturemodelforknowledgegraphembedding[C]//Procee- 2377.
dings of the 54th Annual Meeting of the Association for [75]XIER,LIUZ,JIAJ,etal.Representationlearningofknow-
ComputationalLinguistics,Berlin,Aug 7-12,2016.Strouds- ledge graphs with entity descriptions[C]//Proceedings of
burg:ACL,2016:2316-2325. the 30thAAAI Conference onArtificial Intelligence, Phoe-
[64] TRIVEDI R, DAI H J, WANG Y C, et al. Know-evolve: nix,Feb12-17,2016.MenloPark:AAAI,2016:2659-2665.
deep temporal reasoning for dynamic knowledge graphs [76]SHIB,WENINGERT.Open-worldknowledgegraphcom-
[C]//Proceedings of the 34th International Conference on pletion[C]//Proceedings of the 32nd AAAI Conference on
MachineLearning,Sydney,Aug6-11,2017:3462-3471. Artificial Intelligence, New Orleans, Feb 2-7, 2018. Menlo
[65]DASGUPTASS,RAYSN,TALUKDAR P.HyTE:hyper- Park:AAAI,2018:1957-1964.
plane-based temporally awareknowledgegraph embedding [77] TAY Y, TUAN LA, PHAN M C, et al. Multi-task neural
[C]//Proceedingsofthe2018ConferenceonEmpiricalMe- network for non-discrete attribute prediction in knowledge
thods in Natural Language Processing, Brussels, Oct 31- graphs[C]//Proceedings of the 2017 ACM Conference on
Nov4,2018.Stroudsburg:ACL,2018:2001-2011. Information and Knowledge Management, Singapore, Nov
[66] CHEN X, CHEN M, SHI W, et al. Embedding uncertain 6-10,2017.NewYork:ACM,2017:1029-1038.
knowledge graphs[C]//Proceedings of the 33rdAAAI Con- [78]DETTMERST,MINERVINIP,STENETORPP,etal.Con-
ference on Artificial Intelligence, Honolulu, Jan 27-Feb 1, volutional 2D knowledge graph embeddings[C]//Procee-
2019.MenloPark:AAAI,2019:3363-3370. dings of the 32nd AAAI Conference on Artificial Intelli-
[67] BORDES A, GLOROT X, WESTON J, et al. A semantic gence, New Orleans, Feb 2-7, 2018. Menlo Park: AAAI,
matching energy function for learning with multi-relational 2018:1811-1818.
data[J].MachineLearning,2014,94(2):233-259. [79]LISJ,CHENSD,OUYANGXY,etal.Jointlearningbased
[68] YANG B, YIH W, HE X, et al. Embedding entities and on multi-shaped filters for knowledge graph completion[J].
relations for learning and inference in knowledge bases[J]. HighTechnologyLetters,2021,27(1):43-52.
arXiv:1412.6575,2014. [80] NEELAKANTAN A, ROTH B, MCCALLUM A. Compo-
[69] NICKEL M, ROSASCO L, POGGIO T. Holographic em- sitional vector space models for knowledge base inference
beddings of knowledge graphs[C]//Proceedings of the 30th [C]//Proceedings of the 29th AAAI Conference on Artifi-
AAAI Conference on Artificial Intelligence, Phoenix, Feb cialIntelligence,Austin,Jan25-30,2015.MenloPark:AAAI,
12-17,2016.MenloPark:AAAI,2016:1955-1961. 2015:31-34.
[70] TROUILLON T, DANCE C R, WELBL J, et al. Knowle- [81] SHEN Y, HUANG P S, CHANG M W, et al. Traversing
dge graph completion via complex tensor factorization[J]. knowledge graph in vector space without symbolic space
JournalofMachineLearningResearch,2017,8:1-38. guidance[J].arXiv:1611.04642,2016.
[71] GUO S, WANG Q, WANG L, et al. Jointly embedding [82]GUOLB,ZHANGQH,GEWY,etal.DSKG:adeepse-
knowledge graphs and logical rules[C]//Proceedings of the quential model for knowledge graph completion[C]//Pro-
2016 Conference on Empirical Methods in Natural Lan- ceedings of the 3rd China Conference on Knowledge
guageProcessing,Austin,Nov1-4,2016.Stroudsburg:ACL, Graph and Semantic Computing,Tianjin,Aug 14-17,2018.
2016:192-202. Cham:Springer,2018:65-77.
[72]WANG Z, LI J, LIU Z, et al.Text-enhanced representation [83] XIONG W, HOANG T, WANG W Y. DeepPath: a reinfor-
learning for knowledge graph[C]//Proceedings of the 25th cement learning method for knowledge graph reasoning[J].
International Joint Conference on Artificial Intelligence, arXiv:1707.06690,2017.
NewYork,Jul9-15,2016.PaloAlto:AAAI,2016:4-17. [84] DAS R, DHULIAWALA S, ZAHEER M, et al. Go for a
[73] QU M, TANG J. Probabilistic logic neural networks for walk and arrive at the answer: reasoning over paths in
reasoning[C]//Advances in Neural Information Processing knowledge bases using reinforcement learning[J]. arXiv:
Systems32,Vancouver,Dec8-14,2019:7710-7720. 1711.05851,2017.
[74] ZHANG W, PAUDEL B, WANG L, et al. Iteratively lear- [85] LI Z, JIN X, GUAN S, et al. Path reasoning over know-
ning embeddings and rules for knowledge graph reasoning ledge graph: a multi-agent and reinforcement learning based
[C]//Proceedings of the World Wide Web Conference, San method[C]//Proceedings of the 2018 IEEE International
Francisco,May13-17,2019.NewYork:ACM,2019:2366- Conference on Data Mining, Singapore, Nov 17-20, 2018. 孙水发 等：图神经网络应用于知识图谱推理的研究综述 49
Piscataway:IEEE,2018:929-936. networks for learning on large and spatio-temporal graphs
[86]WANGQ,JIY,HAOY,etal.GRL:knowledgegraphcom- [J].arXiv:1803.07294,2018.
pletion with GAN-based reinforcement learning[J]. Know- [99] PARK N, KANA, DONG X L, et al. Estimating node im-
ledge-BasedSystems,2020,209:106421. portance in knowledge graphs using graph neural networks
[87] TIWARI P, ZHU H, PANDEY H M. DAPath: distance- [C]//Proceedings of the 25th ACM SIGKDD International
aware knowledge graph reasoning based on deep reinfor- Conference on Knowledge Discovery and Data Mining,
cementlearning[J].NeuralNetworks,2021,135:1-12. Anchorage,Aug4-8,2019.NewYork:ACM,2019:596-606.
[88]SCARSELLIF,GORIM,TSOIAC,etal.Thegraphneural [100]CHEN X,DING L,XIANGY.Neighborhoodaggregation
network model[J]. IEEE Transactions on Neural Networks, basedgraphattentionnetworksforopen-worldknowledge
2008,20(1):61-80. graph reasoning[J]. Journal of Intelligent & Fuzzy Sys-
[89] GALLICCHIO C,MICHELIA.Graph echo state networks tems,2021,41(2):3797-3808.
[C]//Proceedings of the 2010 International Joint Confe- [101] CAO S, LU W, XU Q. Deep neural networks for learning
renceonNeuralNetworks,Barcelona,Jul18-23,2010.Pis- graph representations[C]//Proceedings of the 30th AAAI
cataway:IEEE,2010:1-8. Conference onArtificial Intelligence, Phoenix, Feb 12-17,
[90]LIY,TARLOWD,BROCKSCHMIDTM,etal.Gatedgraph 2016.MenloPark:AAAI,2016:1145-1152.
sequenceneuralnetworks[J].arXiv:1511.05493,2015. [102] WANG D, CUI P, ZHU W. Structural deep network
[91]DAIHJ,KOZAREVAZ,DAIB,etal.Learningsteady-states embedding[C]//Proceedings of the 22nd ACM SIGKDD
of iterative algorithms over graphs[C]//Proceedings of the International Conference on Knowledge Discovery and
35thInternationalConferenceonMachineLearning,Stock- DataMining,SanFrancisco,Aug13-17,2016.NewYork:
holmsmässan,Jul10-15,2018:1114-1122. ACM,2016:1225-1234.
[92] BRUNA J, ZAREMBAW, SZLAM A, et al. Spectral net- [103]KIPFTN,WELLINGM.Variationalgraphauto-encoders
works and locally connected networks on graphs[J]. arXiv: [J].arXiv:1611.07308,2016.
1312.6203,2013. [104] PAN S, HU R, LONG G, et al.Adversarially regularized
[93] HAMILTON W L, YING Z T, LESKOVEC J. Inductive graph autoencoder for graph embedding[J]. arXiv:1802.
representation learning on large graphs[C]//Advances in 04407,2018.
Neural Information Processing Systems 30, Long Beach, [105]LIY,VINYALSO,DYERC,etal.Learningdeepgenera-
Dec4-9,2017.RedHook:CurranAssociates,2017:1024-1034. tivemodelsofgraphs[J].arXiv:1803.03324,2018.
[94]SCHLICHTKRULLM S,KIPFTN,BLOEM P,etal.Mo- [106] BOJCHEVSKI A, SHCHUR O, ZÜGNER D, et al. Net-
deling relational data with graph convolutional networks GAN: generating graphs via random walks[C]//Procee-
[C]//LNCS 10843: Proceedings of the 15th European Se- dings of the 35th International Conference on Machine
mantic Web Conference, Heraklion, Jun 3-7, 2018. Cham: Learning,Stockholm,Jul10-15,2018:610-619.
Springer,2018:593-607. [107]WANGS,WEIX,NOGUEIRADOSSANTOSCN,etal.
[95]VASHISHTH S, SANYALS, NITIN V, et al. Composi- Mixed-curvaturemulti-relationalgraphneuralnetworkfor
tion based multi-relational graph convolutional networks[J]. knowledge graph completion[C]//Proceedings of the 30th
arXiv:1911.03082,2019. Web Conference 2021, Ljubljana,Apr 19-23, 2021. New
[96]SHANGC,TANGY,HUANGJ,etal.End-to-endstructure- York:ACM,2021:1761-1771.
aware convolutional networks for knowledge base com- [108] LI Y, YU R, SHAHABI C, et al. Diffusion convolutional
pletion[C]//Proceedings of the 33rd AAAI Conference on recurrent neural network: data-driven traffic forecasting
Artificial Intelligence, the 31st Innovative Applications of [J].arXiv:1707.01926,2017.
Artificial Intelligence Conference, the 9th AAAI Sympo- [109] YU B, YIN H, ZHU Z. Spatio-temporal graph convolu-
sium on Educational Advances in Artificial Intelligence, tional networks: a deep learning framework for traffic
Honolulu, Jan 27-Feb 1, 2019. Menlo Park: AAAI, 2019: forecasting[J].arXiv:1709.04875,2017.
3060-3067. [110] WU Z, PAN S, LONG G, et al. Graph wavenet for deep
[97] VELIČKOVIĆ P, CUCURULL G, CASANOVA A, et al. spatial-temporalgraphmodeling[J].arXiv:1906.00121,2019.
Graphattentionnetworks[J].arXiv:1710.10903,2017. [111] ZHENG C P, FAN X L,WANG C, et al. GMAN: a graph
[98] ZHANG J, SHI X, XIE J, et al. GaAN: gated attention multi-attention network for traffic prediction[C]//Procee- 50 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
dings of the 34th AAAI Conference on Artificial Intelli- with graph convolutional networks[J]. arXiv:1609.02907,
gence, the 32nd Innovative Applications of Artificial 2016.
Intelligence Conference, the 10th AAAI Symposium on [121] DAI H, DAI B, SONG L. Discriminative embeddings of
EducationalAdvances inArtificial Intelligence, New York, latent variable models for structured data[C]//Proceedings
Feb7-12,2020.MenloPark:AAAI,2020:1234-1241. of the 33rd International Conference on Machine Lear-
[112]KHALEDA,ELSIRAMT,SHENY.TFGAN:trafficfore- ning,NewYork,Jun19-24,2016:2702-2711.
casting using generative adversarial network with multi- [122] HU F, ZHU Y, WU S, et al. Hierarchical graph convolu-
graph convolutionalnetwork[J].Knowledge-BasedSys- tionalnetworksforsemi-supervisednodeclassification[J].
tems,2022:108990. arXiv:1902.06667,2019.
[113]GORIM,MONFARDINIG,SCARSELLIF.Anewmodel [123]VASWANIA,SHAZEERN,PARMARN,etal.Attention
forlearningingraphdomains[C]//Proceedingsofthe2005 isallyouneed[C]//AdvancesinNeuralInformationProces-
IEEE International Joint Conference on Neural Networks, sing Systems 30, Long Beach, Dec 4-9, 2017. Red Hook:
Montreal, Jul 31-Aug 4, 2005. Piscataway: IEEE, 2005: CurranAssociates,2017:5998-6008.
729-734. [124] XIE Y, ZHANG Y, GONG M, et al. MGAT: multi-view
[114]LIJH,XUWB,JINYW,etal.Applyingofgraphneural graph attention networks[J]. Neural Networks, 2020, 132:
network in relationship prediction in knowledge graph 180-189.
reasoning[C]//Proceedings of the 2021 IEEE 23rd Inter- [125]XU D,RUAN C,KORPEOGLU E,etal.Inductiverepre-
national Conference on High Performance Computing & sentation learning on temporal graphs[J]. arXiv:2002.
Communications; the 7th International Conference on 07962,2020.
Data Science & Systems; the 19th International Con- [126]NATHANID,CHAUHANJ,SHARMAC,etal.Learning
ference on Smart City; the 7th International Conference attention-basedembeddingsforrelationpredictioninknow-
onDependabilityinSensor,Cloud&BigDataSystems& ledgegraphs[J].arXiv:1906.01195,2019.
Application,Haikou,Dec20-22,2021.Piscataway:IEEE, [127] XU X, FENG W, JIANG Y, et al. Dynamically pruned
2021:2206-2210. message passing networks for large-scale knowledge graph
[115] HENAFF M, BRUNA J, LECUN Y. Deep convolutional reasoning[J].arXiv:1909.11334,2019.
networks on graph-structured data[J]. arXiv:1506.05163, [128] XIE Z, ZHOU G, LIU J, et al. ReInceptionE: relation-
2015. aware inception network with joint local-global structural
[116] DEFFERRARD M, BRESSON X, VANDERGHEYNST information for knowledge graph embedding[C]//Procee-
P.Convolutionalneuralnetworksongraphswithfastloca- dings of the 58th Annual Meeting of the Association for
lized spectral filtering[C]//Advances in Neural Informa- Computational Linguistics. Stroudsburg:ACL, 2020: 5929-
tion Processing Systems 29, Barcelona, Dec 5-10, 2016. 5939.
RedHook:CurranAssociates,2016:3837-3845. [129]康世泽,吉立新,张建朋.一种基于图注意力网络的异质
[117] LEVIE R, MONTI F, BRESSON X, et al. CayleyNets: 信息网络表示学习框架[J].电子与信息学报,2021,43
graph convolutional neural networks with complex ratio- (4):915-922.
nalspectralfilters[J].IEEETransactionsonSignalProces- KANG SZ,JILX,ZHANG JP.Heterogeneousinforma-
sing,2018,67(1):97-109. tion network representation learning framework based on
[118] CHEN J, MA T, XIAO C. FastGCN: fast learning with graphattentionnetwork[J].JournalofElectronics&Infor-
graph convolutionalnetworks via importance sampling[J]. mationTechnology,2021,43(4):915-922.
arXiv:1801.10247,2018. [130]田玲,张谨川,张晋豪,等.知识图谱综述——表示、构
[119]HURA,JANJUAN,AHMEDM.Asurveyonstate-of-the- 建、推理与知识超图理论[J].计算机应用,2021,41(8):
arttechniquesforknowledgegraphsconstructionandchal- 2161-2186.
lenges ahead[C]//Proceedings of the IEEE 4th Interna- TIAN L, ZHANG J C, ZHANG J H, et al. Knowledge
tional Conference on Artificial Intelligence and Know- graph survey：representation，construction, reasoning and
ledge Engineering, Laguna Hills, Dec 1-3, 2021. Pisca- knowledgehypergraphtheory[J].JournalofComputerApp-
taway:IEEE,2021:99-103. lications,2021,41(8):2161-2186.
[120] KIPF T N, WELLING M. Semi-supervised classification [131]SHANGC,LIUQ,CHENKS,etal.Edgeattention-based 孙水发 等：图神经网络应用于知识图谱推理的研究综述 51
multi-relational graph convolutional networks[J]. arXiv: International Conference on Knowledge Discovery and
1802.04944,2018. DataMining.NewYork:ACM,2020:753-763.
[132] ZHANG Y, CHEN X, YANG Y, et al. Efficient proba- [142] VRETINARISA, LEI C, EFTHYMIOU V, et al. Medical
bilistic logic reasoning with graph neural networks[J]. entity disambiguation using graph neural networks[C]//
arXiv:2001.11850,2020. Proceedings of the 2021 International Conference on
[133] CHAMI I,WOLFA, JUAN D C, et al. Low-dimensional ManagementofData.NewYork:ACM,2021:2310-2318.
hyperbolic knowledge graph embeddings[J]. arXiv:2005. [143] ZITNIK M, AGRAWAL M, LESKOVEC J. Modeling
00545,2020. polypharmacy side effects with graph convolutional net-
[134]YUW,ZHENGC,CHENGW,etal.Learningdeepnetwork works[J].Bioinformatics,2018,34(13):i457-i466.
representations with adversarially regularized autoenco- [144] IOANNIDIS V N, MARQUES A G, GIANNAKIS G B.
ders[C]//Proceedings of the 24th ACM SIGKDD Inter- Graph neural networks for predicting protein functions
national Conference on Knowledge Discovery and Data [C]//Proceedingsofthe2019IEEE8thInternationalWork-
Mining,London,Aug19-23,2018.NewYork:ACM,2018: shop on Computational Advances in Multi-Sensor Adap-
2663-2671. tive Processing, Le Gosier, Dec 15-18, 2019. Piscataway:
[135]TUK,CUIP,WANGX,etal.Deeprecursivenetworkem- IEEE,2019:221-225.
bedding with regular equivalence[C]//Proceedings of the [145] LI L, WANG P, YAN J, et al. Real-world data medical
24th ACM SIGKDD International Conference on Know- knowledge graph: construction and applications[J].Artifi-
ledgeDiscovery and Data Mining, London,Aug 19-23, cialIntelligenceinMedicine,2020,103:101817.
2018.NewYork:ACM,2018:2357-2366. [146] ZHANG Y. Knowledge reasoning with graph neural net-
[136]DECAON,KIPFT.MolGAN:animplicitgenerativemodel works[D].Atlanta:GeorgiaInstituteofTechnology,2021.
forsmallmoleculargraphs[J].arXiv:1805.11973,2018. [147]黄超.基于图神经网络的知识推理研究与应用[D].成
[137] YOU J, YING R, REN X, et al. GraphRNN: generating 都:电子科技大学,2021.
realisticgraphswithdeepauto-regressivemodels[C]//Pro- HUANG C. Research and application of knowledge rea-
ceedings of the 35th International Conference on Ma- soning based on graph neural network[D]. Chengdu: Uni-
chineLearning,Stockholm,Jul10-15,2018:5708-5717. versityofElectronicScienceandTechnologyofChina,2021.
[138] ZHAO L, SONG Y, ZHANG, et al. T-GCN: a temporal [148] MAY, HE Z, LI W, et al. Understanding graphs in EDA:
graph convolutional network for traffic prediction[J]. from shallow to deep learning[C]//Proceedings of the
IEEE Transactions on Intelligent Transportation Systems, 2020 International Symposium on Physical Design, Taipei,
2019,21(9):3848-3858. China,Sep20-23,2020.NewYork:ACM,2020:119-126.
[139] SEOY, DEFFERRARD M,VANDERGHEYNST P, et al. [149]林旺群,汪淼,王伟,等.知识图谱研究现状及军事应用
Structured sequence modeling with graph convolutional [J].中文信息学报,2020,34(12):9-16.
recurrent networks[C]//LNCS 11301: Proceedings of the LINWQ,WANG M,WANGW,etal.Asurveytoknow-
25th International Conference on Neural Information Pro- ledge graph and its military application[J]. Journal of
cessing,SiemReap,Dec13-16,2018.Cham:Springer,2018: ChineseInformationProcessing,2020,34(12):9-16.
362-373. [150]张清辉,杨楠,梁政.任务驱动的军事信息服务知识推理
[140] GUO S, LIN Y, FENG N, et al. Attention based spatial- 研究[J].火力与指挥控制,2021,46(5):64-70.
temporal graph convolutional networks for traffic flow ZHANG Q H,YANG N, LIANG Z. Study on knowledge
forecasting[C]//Proceedingsofthe 33rdAAAIConference reasoning of task driven military information service[J].
onArtificialIntelligence,the 31stInnovativeApplications FireControl&CommandControl,2021,46(5):64-70.
ofArtificial Intelligence Conference, the 9th AAAI Sym- [151]庞维建,李辉,黄谦,等.基于本体的无人系统任务规划研
posiumonEducationalAdvancesinArtificialIntelligence, 究综述[J].系统工程与电子技术,2022,44(3):908-920.
Honolulu, Jan 27-Feb 1, 2019. Menlo Park:AAAI, 2019: PANGWJ,LIH,HUANG Q,etal.Review onontology-
922-929. based task planning for unmanned systems[J]. System
[141] WU Z, PAN S, LONG G, et al. Connecting the dots: EngineeringandElectronics,2022,44(3):908-920.
multivariate time series forecasting with graph neural [152] PENG H, WANG H, DU B, et al. Spatial temporal inci-
networks[C]//Proceedings of the 26th ACM SIGKDD dence dynamic graph neural networks for traffic flow 52 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(1)
forecasting[J].InformationSciences,2020,521:277-290. 李小龙（1989—），男，湖北公安人，博士研究
[153]SANKARA,WUY,GOUL,etal.DySAT:deepneuralrep- 生，讲师，主要研究方向为自然语言处理、知识
resentation learning on dynamic graphs via self-attention 图谱、知识推理等。
networks[C]//Proceedingsofthe 13th InternationalConfe- LI Xiaolong, born in 1989, Ph.D. candidate,
renceonWebSearchandDataMining,Houston,Feb3-7, lecturer. His research interests include natural
language processing, knowledge graph, know-
2020.NewYork:ACM,2020:519-527.
ledgereasoning,etc.
[154] PAREJA A, DOMENICONI G, CHEN J, et al. Evolve-
GCN:evolvinggraphconvolutionalnetworksfordynamic
李伟生（1975—），男，四川安岳人，博士，教授，
graphs[C]//Proceedings of the 34th AAAI Conference on
主要研究方向为智能信息处理、模式识别等。
Artificial Intelligence, the 32nd Innovative Applications
LI Weisheng, born in 1975, Ph.D., professor.
ofArtificialIntelligenceConference,the10thAAAISym-
Hisresearchinterestsincludeintelligentinforma-
posium on Educational Advances in Artificial Intelligence,
tionprocessing,patternrecognition,etc.
NewYork,Feb7-12,2020.MenloPark:AAAI,2020:5363-
5370.
雷大江（1979—），男，湖北汉川人，博士，教授，
[155]赵振兵,段记坤,孔英会,等.基于门控图神经网络的栓母
主要研究方向为数据挖掘、机器学习等。
对知识图谱构建与应用[J].电网技术,2021,45(1):98-106.
LEIDajiang,bornin1979,Ph.D.,professor.His
ZHAO Z B, DUAN J K, KONG Y H, et al. Construction
research interests include data mining, machine
and application of bolt and nut pair knowledge graph
learning,etc.
based on GGNN[J]. Power System Technology, 2021, 45
(1):98-106.
李思慧（1999—），女，河北石家庄人，硕士研究
[156] WANG Z, CHEN T, REN J, et al. Deep reasoning with
生，主要研究方向为知识图谱推理。
knowledge graph for social relationship understanding[J].
LI Sihui, born in 1999, M.S. candidate. Her
arXiv:1807.00504,2018.
researchinterestisknowledgegraphreasoning.
[157]WU S,TANGY, ZHUY, et al. Session-based recommen-
dation with graph neural networks[C]//Proceedings of the
33rdAAAI Conference onArtificial Intelligence, the 31st
杨柳（1981—），女，陕西咸阳人,硕士研究生，主
Innovative Applications of Artificial Intelligence Confe-
要研究方向为数据质量、心理与行为大数据等。
rence, the 9th AAAI Symposium on Educational Advan-
YANG Liu, born in 1981, M.S. candidate. Her
ces in Artificial Intelligence, Honolulu, Jan 27-Feb 1,
research interests include data quality, psycho-
2019.MenloPark:AAAI,2019:346-353. logicalandbehavioralbigdata,etc.
孙水发（1977—），男，江西黎川人，博士，教授， 吴义熔（1970—），男，湖北荆州人，博士，教授，
博士生导师，主要研究方向为智能信息处理、 博士生导师，主要研究方向为自然语言处理、
图像处理等。
图像处理、信息管理系统等。
SUN Shuifa,bornin1977,Ph.D.,professor,Ph.D.
WUYirong,bornin1970,Ph.D.,professor,Ph.D.
supervisor. His research interests include intel-
supervisor. His research interests include natu-
ligent information processing, image proces-
rallanguage processing,image processing,infor-
sing,etc.
mationmanagementsystem,etc. --------------------------------------------------------------------------------- 第 15 卷第 1 期 智 能 系 统 学 报 Vol.15 No.1
2020 年 1 月 CAAI Transactions on Intelligent Systems Jan. 2020
DOI: 10.11992/tis.201908034
图神经网络推荐研究进展
吴国栋1,2，查志康2，涂立静2，陶鸿2，宋福根1
（1. 东华大学 管理学院，上海 200051; 2. 安徽农业大学 信息与计算机学院，安徽 合肥 230036）
摘 要：图神经网络(graph neural network, GNN)具有从图的领域对数据进行特征提取和表示的优势，近年来成
为人工智能研究的热点，图神经网络推荐也是推荐系统研究的一个新方向。本文对GNN模型进行深入研究的
基础上，分析了GNN推荐过程，并从无向单元图推荐、无向二元图推荐、无向多元图推荐3个方面详细讨论了
现有GNN推荐研究取得的主要进展及不足，阐明了现有GNN推荐研究中存在的主要难点，最后提出了
GNN上下文推荐、GNN跨领域推荐、GNN群组推荐、GNN推荐的可解释性等未来GNN推荐的研究方向。
关键词：图神经网络；推荐系统；深度学习；实体联系；社交关系；协同过滤；无向图；有向图
中图分类号：TP301 文献标志码：A 文章编号：1673−4785(2020)01−0014−11
中文引用格式：吴国栋, 查志康, 涂立静, 等. 图神经网络推荐研究进展[J]. 智能系统学报, 2020, 15(1): 14–24.
英文引用格式：WU Guodong, ZHA Zhikang, TU Lijing, et al. Research advances in graph neural network recommendation[J].
CAAI transactions on intelligent systems, 2020, 15(1): 14–24.
Research advances in graph neural network recommendation
WU Guodong1,2，ZHA Zhikang2，TU Lijing2，TAO Hong2，SONG Fugeng1
(1. School of Business and Management, Donghua University, Shanghai 200051, China; 2. School of Information and Computer, An-
hui Agricultural University, Hefei 230036, China)
Abstract: Graph neural network (GNN) has the advantage of feature extraction and representation of data from the field
of Graph. In recent years, it has become a hotspot of artificial intelligence research, and the recommendation of Graph
Neural Network is also a new direction of recommendation system research. Based on the in-depth study of GNN mod-
el, this paper analyzes the GNN recommendation process, and discusses in detail the main progress and deficiencies of
GNN recommendation studies from three aspects: undirected unit graph recommendation, undirected binary graph re-
commendation and undirected multivariate graph recommendation. The main difficulties in existing GNN recommenda-
tion studies are clarified, and the research directions of GNN recommendation in the future, including GNN contextual
recommendation, GNN cross-domain recommendation, GNN group recommendation, and GNN recommendation’s in-
terpretability, and so on, are pointed out in the end.
Keywords: graph neural network; recommendation system; deep learning; entity relations; society relation; collaborat-
ive filtering; undirected graph; directed graph
图神经网络(graph neural network, GNN)作为 和表示，是一种高效、易扩展的新型的神经网络
一种从卷积神经网络(convolutional neural net- 结构，在学习图数据方面表现出了强大的功能。
works, CNN)和图嵌入思想启发而来的新型拓展 与传统的深度学习方法相比，GNN可以通过构建
神经网络[1]，可以在图领域对数据进行特征提取 的图模型来反映实体及其之间的联系。目前，国
内外对GNN的研究都取得了一定的进展，如自
然语言处理[2]、文本分类[3]、特征关系提取[4]、图片
收稿日期：2019−08−30.
基金项目：国家自然科学基金资助项目(31671589)；安徽省自 分类[5]、疾病预测[6]等。在推荐系统中，实体间的
然科学研究重点项目(KJ2017A152，KJ2019A0211).
通信作者：吴国栋. E-mail：gdwu1120@qq.com. 关系有用户与用户、用户与物品、物品与物品之 第 1 期 吴国栋，等：图神经网络推荐研究进展 ·15·
间关系，传统的推荐方法主要关注用户与物品间 1)有向图GNN
的关系，很少关注用户相互间及物品相互间的关 实际上有向图比无向图可以反映更多的信
系。图神经网络GNN的发展，为人们进一步分 息，比如某种次序或者逻辑关系，在文献[17]中，
析推荐系统实体及其相互间的关系提供了更好的 Kampffmeyer等通过使用两个权值矩阵W，W
p c
表示方式，近年来，基于GNN推荐的相关研究越 来进行协同获得更加精确的处理结果，如式(6)：
来越受到广大学者关注，并取得了一定的成果。 Ht=(cid:27)(D(cid:0) p1A p(cid:1)(cid:27)(D(cid:0) c1A cHt(cid:0)1W c)W p) (6)
本文分析了GNN推荐的主要过程及其研究进 式中：p代表父节点(指向它的节点)；c代表子节
展，提出了GNN推荐当前存在的难点，并指出未 点(它指向的节点)；D−1A 、D−1A分别代表对父
p p c c
来GNN推荐的主要研究方向。 节点和子节点邻接矩阵的标准化矩阵；(cid:27) 是非线
性激活函数。
1 图神经网络
2)无向图GNN
没有次序关系的节点就构成无向图，图神经
图神经网络是利用一定的方法对节点进行描
网络GNN对于无向图的处理只需要将其视为两
述，并经过不断的节点状态更新，得到具有包含
邻居节点信息和图形拓扑结构特点的状态[7]，最 个有向图的叠加即可。实际上，无向图的计算相
比有向图更为简单，对其进行更新时，只需一个
终将这些节点通过特定方法进行输出，得到需要
权重矩阵W正常经过加权，通过激活函数更新
的结果。式(1)表示节点状态的更新方式，式
即可。
(2)表示对更新完的节点状态进行输出：
( )
h = f X ;X ;h ;X (1)
本文将图神经网络GNN按照构成它的节点
v v CO[v] ne[v] ne[v]
o =g(h ;X ) (2) 是否表示相同的实体，分为单元图GNN，二元图
v v v
式中：f 是局部转换函数；g 为局部输出函数；o表
GNN与多元图GNN。单元图GNN中节点仅表
示输出结果；h表示节点当前的嵌入化结果；
示1种实体类型，即节点的类型唯一，在推荐系统
v
X代表节点v的特征；X 表示对应节点v的边 中常常体现在用户社交关系图，如根据用户的朋
v CO[v]
友关系构建对应的GNN模型；二元图GNN中的
的属性；h 表示节点v更新前的状态；X 表示
ne[v] ne[v]
节点所表示的实体类型为2种，诸如用户−物品购
节点v的邻居节点的特征。
买关系图，用户−项目标签图等；图中节点所表示
式(1)、(2)均表示以一个节点为单位进行操
实体类型超过2种的为多元图GNN，在实体种类
作，当对所有的节点进行上述运算的时候，可以
及其关系较复杂的时候可以使用这种类型的GNN
更加简洁的用式(3)、式(4)进行描述：
H=F(H;X) (3) 模型。
O=G(H;X ) (4)
N 2 推荐系统
式中：H表示所有节点的状态；O表示对所有的节
点进行输出之后的结果；X表示边的特征； X N 分 推荐系统就是通过分析用户的历史行为对用
别表示所有节点的特征；F((cid:1))、G((cid:1)) 分别表示全局 户的兴趣建模，从而主动给用户推荐能够满足其
转换函数与全局输出函数。由此可知，当对所有 兴趣和需求的物品(或信息)。常见的推荐模型有
节点的状态进行从t至t+1轮更新时，可以表示为 基于用户行为的推荐，如协同过滤(collaborative
式(5)： filtering, CF)[18]，隐语义模型(latent factor model,
( )
Ht+1=F Ht;X (5) LFM)[19]；基于内容的推荐，如标签推荐[20]；混合推
GNN有多种变体，如根据训练方法的差异有 荐[21]，即通过多种不同的推荐模型相互协作，如在
GraphSAGE[8]、FastGCN[9]、ControlVariate[10]、Co- 推荐系统的不同时期分别使用不同的模型或者使
training GCN[11]和Self-training GCN[11]等；根据信 用多个模型的推荐结果再进行决策。协同过滤分
息传播计算方式的不同有Spectral Network[12]、 为基于用户的协同过滤[22]和基于物品的协同过
MoNet[13]、DCNN[14]、Gate Graph Neural Networks[15]、 滤[23]，基于用户行为的推荐算法往往存在着冷启
Sentence LSTM[16]等。 动问题[24]和数据稀疏性问题[25]。
图神经网络GNN按照其构成拓扑结构边的 随着深度学习的发展，基于深度学习的推荐
类型，分为有向图GNN和无向图GNN，对于不同 研究也很多，Elkahky等[26]提出了一种多视图深
的边类型，对应的局部转换函数f的计算方法也 度神经网络模型(Multi-View deep neural network,
有所差异。 Multi-ViewDNN)，通过用户和物品(项目)两种信 ·16· 智 能 系 统 学 报 第 15 卷
息实体的语义匹配来实现用户的物品推荐； 好的推荐效果。3)提取出更新后的节点(边、子
Zheng等[27]提出了一种深度协作神经网络模型 图)特征，并用相关算法实现推荐。将GNN模型
(deep cooperative neural network, DeepCoNN)，利用 完成更新之后的节点取出，作为该节点对应的实
两个并行的神经网络模型学习用户和项目的隐特 体特征，采用相关算法进行推荐。如文献[30]
征，然后在两个神经网络上构建一个交互层来预 中，使用协同过滤推荐的方法；文献[31]中，将
测用户对项目的评分；Liu等[28]研究了位置社交 GNN提取的物品特征和节点特征，通过MLP进
网络中的行为预测问题，通过利用循环神经网络 行评分预测推荐；文献[32]中，通过两种不同的
抓住序列行为之间的依赖关系，从而基于用户的 神经网络，进行试验结果预测与推荐。
历史行为序列，帮助预测下一时刻的行为。
4 GNN推荐相关研究
3 GNN推荐主要过程
由于有向图GNN推荐时，需要两个权值矩阵
一般说来，GNN推荐主要过程分为3个步 来实现聚集与更新操作，相对无向图GNN推荐，
骤：1)根据推荐系统实体及其相互关系构建对应 只需一个权重矩阵来说，就变得更为复杂。因
的GNN模型。主要考虑如何将推荐系统中不同 此，在现有图神经网络GNN推荐的相关研究中，
实体映射为GNN中图节点，不同实体间的联系 主要集中在无向图GNN推荐方面。以下重点从
映射为GNN图中对应的边，如何用的神经网络 无向单元图GNN推荐、无向二元图GNN推荐以
函数去拟合GNN中不同的节点。在GNN推荐模 及无向多元图GNN推荐3个方面探讨GNN推荐
型中，不论是用户节点还是物品节点，都可以根 相关研究。
据相关信息做嵌入化处理，得到对应节点的向量 4.1 无向单元图GNN推荐
化描述。如对一个物品节点，可以根据不同用户 这种GNN推荐模型节点类型单一，操作比较
对其评论或评分信息做嵌入化处理；对一个用户 简单。主要是将推荐系统中的实体映射到一个无
节点，可以根据其社交关系或物品购买记录做嵌 向单元图GNN，图中所有节点都表示为一种实体
入化处理。边作为反映GNN推荐模型中实体之 类型。如Cui[33]等将GNN用于服装推荐，服装的
间的联系，通常有两种处理方式：一是根据联系 类别作为节点，各个类别之间的关系作为边，各
的类型及强弱程度不同，进行嵌入化操作；二是 类服装放入对应的节点之中形成子图，构成了一
对边不进行任何处理，仅仅当成GNN推荐模型 个无向单元图GNN推荐模型，推荐与指定服装
中，用于信息传播算法作用的媒介。2)决定 匹配度较高的目标服装实现套装搭配，取得了较
GNN模型的信息传播与更新方法。GNN模型的 好的效果。
变体很多，不同变体之间，信息的聚集和更新方 文献[30]中，考虑到用户的行为往往受到自
式也不同。文献[29]指出了在不同的GNN变体 己当前兴趣、朋友兴趣等多种因素影响，通过构
中，出现的相关聚集过程。如GCN模型，通常选 建用户—朋友的无向单元图GNN，分别对用户节
择mean聚集函数；GraphSAGE模型，通常采用 点、朋友节点进行描述，并使用相关传播算法更
max函数；GIN模型，通常使用的sum函数等。不 新用户信息节点，最后和物品嵌入化得到的结果
同的聚集函数适合于不同的图结构，mean函数可 进行运算，输出用户对物品可能的喜爱程度，如
以反映图中节点的分布情况，max函数可以反映 图1所示。具体步骤如下：
主要特征，sum可以考虑到比较全面的图形结构 1)将用户近期的浏览内容，通过循环神经网
特征等。信息更新过程，主要是将信息聚集之后 络(RNN)得到表示用户兴趣的h，并用h描述用
n n
的结果，与中心节点进行特定的运算，并作为下 户的节点信息；
一层节点的初始状态。这方面，不同的模型差异 2)将朋友的近期行为记录，通过RNN得到
也很大，如GCN模型进行信息更新时，不会考虑 ss，用来表示该朋友的短期兴趣；
k
中心节点的信息；GraphSAGE则会将聚集结果和 3)将朋友长期行为向量化，得sl，见式(7)：
k
中心节点的向量进行连接操作；GIN模型会将两 sl =W [k;:] (7)
k u
者进行直接相加等。充分考虑推荐系统实体间关 式中：W [k;:] 表示对用户u从第k次记录一直取
u
系，及对应GNN模型的结构特征，选择最合适的 到最新的记录，进行向量化处理。
信息传播算法，进行信息更新，往往可以取得更 4)将上述两个向量联合起来，构成代表目标 节点用户的嵌入化向量 s ，见式(8)： 节点与他的第k个邻居的相似度计算结果。
(k [ ])
s =ReLU W ss;sl (8) 6)将所有的邻居节点信息通过注意力系数相
k 1 k k [ ]
式中：ReLU为非线性激活函数， W ss;sl 表示对 加后，得到表示目标节点所有邻居节点的信息向
1 k k
向量ss、sl进行连接处理后使用W进行偏置。 量 hˆ u，见式(10)，再将 hˆ
u
经过偏置加权之后作为
k k 1
5)目标节点的初始状态选取为 h n，邻居节点 节点的下一轮状态进 ∑行更新，见式(11)：
的初始状态选取为 s ，利用构建完成的用户与好 hˆ = (cid:11)(l)h(l) (10)
k u k2N(u)[(fug uk k )
友之间关系的拓扑图，通过计算每层的目标节点 h(l+1)=ReLU W(l)hˆ(l) (11)
u u
和邻居节点的相似度关系，提取出注意力系数
式中：W是可训练的权值矩阵，l、l+1表示当前更
a ，见式(9)：
uk ( ( )) 新的次数。
exp f h(l);h(l)
(cid:11)(l)= ∑ u k (9) 7)将节点的特征与嵌入化得到的物品特征进
uk (cid:11)(l)h(l)
j2N(u)[fug uk k 行相似度运算，通过softmax进行输出，此时输出
式中：l表示当前的更新次数，f(hl，hl)表示目标 的结果就是某用户对物品可能的感兴趣程度。
u k
层数0
…
GNN节点更新
… 用户u的
…
近期行为
短期兴趣
… 长期兴趣
近期行为+RNN
朋友1 朋友2 朋友3 … 朋友
|N(u)| 长期行为向量化
层数 L
…
h(0)
1
h(0)
u
h(0)
2
h(0) h(0)
3 |N(u)|
s s s s 1 2 3 |N(u)|
ss ss ss sS
1 2 3 |N(u)|
s1 s1 s1 s1 1 2 3 |N(u)|
物品嵌入化处理
输
出 物品1
概 h(L)
物品2 1
率 h(L)
分 u
物品3
布
物品4 h(L)
2
h(L)
3
相
进 似 物品|I|
行 度
推 层
荐
层xam-tfoS
第 1 期 吴国栋，等：图神经网络推荐研究进展 ·17·
h(L)
|N(u)|
h(L)
u
图 1 无向单元图GNN推荐模型
Fig. 1 Single-unit undirected graph GNN model
该模型充分考虑到社会关系与用户本人的当 有加以区分。
前兴趣，但对物品特征的提取比较粗糙，没有考 4.2 无向二元图GNN推荐
虑到用户与物品之间的互动关系，同时不同的朋 在实际推荐中，最常见的关系就是用户与项
友对用户的影响程度也是不一样的，此模型也没 目(物品)的交互记录，这两种实体关系就可以构 成一个完整的二元拓扑图。Fan等[31]通过构建用户− 用于对物品进行评分预测。同样考虑到对用户可
物品关系二元图(用户购买的所有物品)、用户− 能的行为，不仅与他自己曾经购买的物品有关，
朋友关系单元图(用户的社交关系)、物品−用户关 也和他的社交关系有关，该文献提出了一种新型
系二元图(物品被用户购买的记录)这3个无向图 图神经网络GNN推荐系统框架GraphRec，如图2。
朋友1 朋友2
用户基于物品购买 构建用户社交图
记录的特征向量
朋友3
GNN
算法 朋友4
用户 i - 物品图
已购
用户2
已购 用户1
已购
用户4
…
…
用户社交图
用户模块
用户i已 对应 注意力机制
购物品1 评分 MLP x
i1
购用 物户 品i已 2 评对 分应 x i2 用户i
用户i已 对应
用户i h iI
购物品3 评分
用户i已 对应 x i3
购物品4 评分 用户基于
x
i4 社交关系
用户 i−物品图 的特征向
h 3I 量 注意力机制
hs
用户 3−物品图
i h 1s
用户2−物品图 h 2I
hs
用户1−物品图 2
hI
GNN算法聚合 h is
1
物品模块 并 h 3s
合 hs
3
注意力机制 h 2I h 4s
用 特户 征 h 1 h 2 h 3 … h i h 1I
物品j
GNN
算
法
用已 户购 3 聚 合 物品j z MLP
特征 j 评分预测
物品j−用户图
推荐模块
…
·18· 智 能 系 统 学 报 第 15 卷
图 2 基于社交关系的GraphRec模型
Fig. 2 Social-based recommendation model-GraphRec
该框架主要由3个模块组成，分别是用户− e向量连接处理，通过一个多层感知器得到x 向
r ia
物品关系和用户—朋友关系构成用户模块，物品− 量(其中a表示用户购买的相关物品，i表示某一
用户关系构成物品模块和由一个多层感知器 个用户)，见式(12)：
([ ])
(MLP)所构成的推荐模块。通过信息传播更新算 x =g q (cid:8)e (12)
ia v a r
法，对这3个图中的节点进行计算，根据结果进行 2)将计算出的x 和用户p通过一个两层的
ia i
评分预测。具体过程如下： 神经网络得到该用户对物品的注意力系数α*，见
首先根据用户购买不同物品行为以及用户之 式(13)：
( [ ] )
间的社交关系构建相应的户—物品关系图和用户− (cid:11)(cid:3) =WT(cid:1)(cid:27) W (cid:1) x (cid:8)p +b +b (13)
ia 2 1 ia i 1 2
朋友关系图，再在图上分别对用户i 和物品j进行 其中，w 、w 是可训练的参数，b 、b 是偏置项，
1 2 1 2
嵌入化处理，得到代表用户信息的p向量，代表 σ(∙)是非线性函数。
i
物品信息的q向量。同时每一个特定的用户对 3)对 (cid:11)(cid:3) 进行 softmax 处理，得到 (cid:11) 作为最终
j ia
于他所购买的物品对应的评分，用独热编码向量 的注意力系数，见式(14)：
( )
化成e r。
(cid:11) =
∑exp (cid:11)(cid:3)
ia( ) (14)
用户模块分为两部分，第1部分是对某用户 ia exp (cid:11)(cid:3)
a2C(i) ia
的购买行为进行特征刻画，第2部分是对该用户
4)用α 对之前得到的x 向量进行加权，并
ia ia
的社交关系进行刻画，将两个特征结合起来通过
且通过一个多层感知器(GNN的简单聚合函
一个多层感知器，就得到代表该用户的特征。用
数)得到用户−物品特征h，见式(15)：
{∑i }
户模块的实现方法如下：
hI=(cid:27)(w(cid:1) a x +b) (15)
1)对所提取的物品q向量和对应的评分 i a2c(i) ia ia
a 第 1 期 吴国栋，等：图神经网络推荐研究进展 ·19·
5)用同样的方法对该用户的好友进行处理， 4.3 无向多元图GNN推荐
得到对应h (o表示用户好友集i的一个好友)； 多元图GNN会大大增加模型的复杂度，同时
io
6)使用2)中的方法对 h 和用户向量 p 通过 计算复杂性和刻画节点的难度也随之增加，但多
io i
一个两层神经网络提取注意力系数β*，见式 元图GNN往往更加贴近现实，可以得到更加客
(16)，并且通过softmax进行处理可以得到β，见 观的结果。文献[36]中，考虑到在一家医院的病
式(17)： 患进行就诊时，需要进行项目测试以及根据其具
( [ ] )
(cid:12)(cid:3) =WT(cid:1)(cid:27) W (cid:1) hI(cid:8)p +b +b (16) 体情况开出不同的药方，一般基于经验进行诊
io 2 1 o( )i 1 2
exp (cid:12)(cid:3) 断，可能会出现误差，而且数据难以全面收集。
(cid:12) = ∑ i0( ) (17)
io exp (cid:12)(cid:3) Mao将图神经网络GNN推荐运用在诊疗研究中，
o2N(i) io
如图3所示。通过一个无向多元图GNN构建病
7)将得到的β对h进行加权并通过一个多层
i 患、医疗科室、药方以及测试结果之间的关系，其
感知器，最后得到具有刻画用户i社交关系的向
中医院的各个科室作为核心节点，进行几轮信息
量 hS，见式(18)：
i {∑ } 的迭代计算之后，根据计算出的节点信息通过两
hS =(cid:27)(w(cid:1) (cid:12) hI +b) (18)
i o2N(i) io o 种不同的神经网络，推荐可能的药方，以及某项
其中，b是偏置项，σ(∙)是非线性函数。将h和 诊疗测试的可能结果。
s
h连接起来通过多层感知器得到代表用户的向
i 病人1 病人2 病人3 方1 方2 方3
量h。 药 药 药
物品模块使用类似的方法对用户向量p和评
t
分向量e进行连接，获得z 向量(j表示物品，t表
r jt
示某用户)，然后对z向量使用上述步骤2)中的方
医疗科室1 医疗科室2 医疗科室3 医疗科室4
法提取出注意力系数，并且对周围的用户向量使
用该系数加权后，结果通过一个多层感知器就得
到代表物品j特征的向量z。
j
预测模块是将上述两个模块得到的h向量，
通过一个多层感知器，最终输出预测评分。
医疗 医疗 医疗 医疗 医疗 医疗
损失函数定义为均方 ∑误差，见式(19)： 测试1 测试2 测试3 测试4 测试5 测试6
1 ( )
Loss= 2jOj r′ ij(cid:0)r ij 2 (19) 图 3 患者医疗诊断关系和医疗测试结果
i;j2O Fig. 3 The graph of patients’ consults relation and
其中i 、j表示用户i、物品j，r表示实际评分，r'表 laboratory testing results
示预测评分，jOj 表示所有评分记录的个数。 该研究中，节点之间的关系通过3个邻接矩
该方法将用户的社交关系融入神经网络，同 阵进行表示，如图4，分别是A 、A 、A ，其中
E×P E×M E×L
时对于用户和物品的特征刻画都相互关联起来， E为医疗科室，P为患者，M为药方，L为医疗测
并且引入了注意力机制，取得了不错的效果，但 试结果；A 表示医疗科室与病人之间的关系，如
E×P
是在用户模块中两个GNN模型无法并行计算， 果病人在该医疗科室进行过就诊，则为1，否则为
增加了模型的时间复杂度。 0。假设一个病人可以对应多个医疗科室，但是一
在文献[32]中，Rex构建了用户−标签无向二 个医疗科室只能对应一个病人，也就是说，一行
元图，通过PinSage算法(随机游走和图卷积结 最多只有一个1。A 表示医疗科室与药方之间
E×M
合)成功应用于超大规模的网页内容推荐。Wang 的关系，如果该科室可以开出对应的药方，则该
等[34]构建用户—物品图，不同之处在于GNN算 值为1，反之为0。A 表示医疗科室和医疗测试
E×L
法中使用目标节点及其邻居节点的点积进行更 结果之间的关系，如果某个医疗科室有该实验测
新，并且通过协同过滤的方法进行推荐。文献[35] 试则该两点之间有权重，选择的值是平时测试的
为了解决推荐系统的冷启动问题，利用知识图谱 平均值，为了对一些测试结果是0的项目进行区
为推荐提供更多的辅助信息，针对不同用户将知 别，作者额外增加了一个M 矩阵，对于存在的
E×L
识图谱转换为多个用户的个性加权图，并且通过 项目则对应数字为1，否则为0。最后一个矩阵表
GCN学习出每个物品的表示向量，然后根据用户 示医疗科室和药方之间的关系，如果该医疗科室
特征向量计算出用户与物品有交互的概率。 有对应的药方则该点为1，否则为0。 ·20· 智 能 系 统 学 报 第 15 卷
P P P M M M L L L L L L L L L L L L
1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3
E 1 0 0 E 1 0 0 E 0.3 0.0 0.1 0 0 0 E 1 1 1 0 0 0
1 1 1 1
E 0 1 0 E 0 1 1 E 0 0.1 0 0 0.5 0 E 0 1 0 0 1 0
2 2 2 2
E 0 1 0 E 0 0 0 E 0 0 0.1 0.8 0 0 E 0 0 1 1 0 0
3 3 3 3
E 0 0 1 E 0 0 0 E 0 0 0.0 0 0 0.6 E 0 0 1 0 0 1
4 4 4 4
A A A M
E×P E×M E×L E×L
图 4 病患、医疗科室、药方以及医疗测试结果关系矩阵
Fig. 4 Relation matrix between patients encounters medications and laboratory test data
在式(20)中，f、f分别表示两种激活函数， 有商家提供的商品描述与分类信息，消费者与系
1 2
N 表示v节点的所有邻居，k表示第k轮运算。 统交互的点击、浏览、收藏、交易信息，消费者的
(v) ( ({ }))
H(k+1)(v)= fW 1(k) H(k)(v);fW 2(k) H(k)(w)jw2N(v) 评分及评论信息等；数据形式有文本信息，图像
1 2
信息、数值评分与标签信息等，甚至还有语音及
(20)
Mao对激活函数ϕ使用了最简单的求和函数[36]， 视频信息等。现有推荐模型对于这些多源多模
态数据很难同时进行有效处理，导致数据利用不
如式(21)所示，对节点类型为i的节点的第k轮
充分或数据对象之间的关系表示不明显。同样
计算，其中h表示他的连接节点。
j 0 1
H
i(k+1)=ϕBBBBBB@∑ n
A ij(cid:1)H( jk)(cid:1)W(
jk)CCCCCCA
(21)
的 较， 单现 一有 ，G 如N 一N推 般荐 只模 能型 对， 用对 户节 留点 下向 的量 评化 论的 数方 据式 或比
者
j=0
评分加以处理，难以将多源多模态信息进行融合
经过k轮计算之后，将计算的节点结果输入
表示以达到最佳效果。如何充分集成使用多源
两种神经网络，分别进行药方和医疗测试结果的
多模态数据信息是GNN推荐有待解决的一个
推荐。
问题。
在式(22)中，损失函数表示为两项之和，第
5.2 GNN的有向图推荐问题
1项L 为药方预测的误差，见式(23)，第2项
m 目前GNN推荐模型主要是无向图GNN推
L 表示使用交叉熵的方式表示医疗测试结果的
L 荐，其中无向图的边用来反映节点之间的互动关
预测误差，见式(24)，λ是系数通过这种引入的混
系。但是有向图比无向图可以反映更多的信息，
合误差，很有效地避免了过拟合问题。
比如某种次序或者逻辑关系，有向图的推荐结果
L=L (P;A )+(cid:21)L (V;A ) (22)
m E(cid:2)M L E(cid:2)L
往往可以取得更好的效果。推荐系统中也存在着
∑∑
1 NE NM N ( ) ( )
L (P;A)=(cid:0) na logp + 1(cid:0)a log 1(cid:0)p 对应的有向关系，如信任关系、关注关系等。与
M N N ij ij ij ij
E i j p 无向图GNN推荐相比，基于有向图GNN的推荐
(23)
∑∑ 更具有挑战性，也更为复杂。
1 NE NL ( )
L (V;A)=(cid:0) m v (cid:0)a 2 (24) 5.3 GNN的动态推荐问题
L N ij ij ij
E i j 对于数据规模往往很大的图形结构，很难进
该模型较单元图与二元图神经网络，结构更
行实时的图模型更新，而且图神经网络GNN迭
加复杂，但能更有效地对不同类型的数据信息
代过程中往往需要根据整个图的信息向量化才能
进行充分使用。同时，通过将模型中的对象进
完成计算，对于不断更新的数据每次进行重新计
行节点再划分，成功处理了一些实验过程中的
算，需要花费很高的成本，如何在较低成本下完
数据缺失值问题；使用新的正则化规则，避免了
成动态的GNN更新，现有GNN推荐研究并没有
过拟合情况，取得了不错效果。不足之处在于
考虑。如文献[30]中，用户的社交情况可能会实
实验相关数据仅采用一家医院，对于规模更大
时发生变化，新朋友可能会对用户的兴趣造成很
的数据集，GNN图形结构将更复杂，实际应用有
大影响，如果可以实时更新用户的社交图谱，就
一定困难。
可以完成对GNN动态推荐。
5.4 GNN网络更新层数问题
5 现有GNN推荐研究难点
标准的深度神经网络推荐研究中，网络层数
5.1 多源多模态信息的GNN推荐问题 可以达到成百上千层，由于更深的结构，可以显
在一个系统中，数据来源与数据结构往往呈 著提高网络的表达能力。在GNN推荐过程中，
现多源异构性。以电子商务系统为例，数据来源 一般层数仅仅为个位数。因为堆叠多个GNN层 第 1 期 吴国栋，等：图神经网络推荐研究进展 ·21·
将会导致过度平滑，所有顶点将收敛到相同的 推荐[41]等。现有GNN推荐研究中，往往只是对
值。如何选择GNN更新的层数以及其他相关的 “一张”图进行“加工”，停留在一个单一的层面上，
参数，以缓解堆叠多层GNN推荐造成的平滑问 如何从一张图过渡到另一张图，实现不同GNN
题，是GNN推荐难点所在。 图模型间信息的有效迁移，是一个值得研究的课
5.5 数据稀疏问题 题。如文献[36]中，作者仅仅考虑到病人在一家
GNN推荐中，通过构建节点和边，将各个对 医院的就诊情况，如果考虑到病人的更多信息，
象用边“连接”起来，在缓解数据稀疏性方面相 如生活习惯、职业、年龄等将这些作为辅助域
比传统的推荐模型会有提升。但GNN推荐模型 的信息充分利用，就可以获得更加精确的推荐
在面临数据稀疏的时候，往往会出现两个问题： 效果。
1)如果节点对应的对象没有任何相关记录时， 3)基于GNN的群组推荐
相关推荐算法将难以实现，如文献[36]中，如果 推荐系统的应用越来越广泛，推荐的对象从
有新来的病人或者病人的就诊记录很少，如仅 单个用户的个性化推荐发展为面向多个用户的群
为一条记录，GNN推荐模型会难以得到可以代 组推荐。现有GNN推荐研究中，主要是个性化
表用户特征的最终结果；2)节点属性维度缺失 推荐，很少涉及GNN群组推荐，如何通过GNN
问题。一个向量化的多维节点，每一个维度都 进行群组推荐未来值得研究的问题。
反映一个对应的属性，如果该属性的值是未知 4)基于GNN的套餐推荐
的，在向量化的过程中就无法写入相应的数值， 当前的推荐系统大多推荐内容单一，仅能满
将会影响到推荐的效果。在文献[36]中就出现 足用户的部分需求，现实生活中，用户需求往往
了病人未参加部分医疗测试的情况，作者通过 是多方面的。如对旅游的用户进行推荐时，如果
重新构建测试结果，解决这个问题，但模型的复 能通过GNN的高度归纳性将路线规划、住宿环
杂度也随之增加。 境、交通方式、特产商铺、消费价格等多个因素进
行综合考虑，为用户推荐最适合的套餐服务，这
6 GNN推荐未来研究方向
将会给用户带来更好的旅游体验。
1)基于上下文的GNN推荐
5) GNN推荐与其他推荐方法融合
深度学习发展迅猛，在不同领域的研究都取
用户的兴趣和行为往往是随着时间、空间等
得了突破性进展，而 GNN推荐实质上只是获取
因素动态发生变化的，在目前的推荐系统中，很
多学者对基于时间上下文的个性化推荐[37]，基于 节点的状态之后再用函数进行输出，可以考虑融
情景上下文的推荐[38]都有一定的研究，通过联 合其他推荐算法或者传统深度学习技术，减少模
型的时间复杂度，同时提高推荐的效果。
系上下文往往会获得更加精确的推荐效果。现
有GNN推荐研究不论是构建用户−用户关系图
6) GNN推荐的可解释性研究
还是用户−物品(项目)关系图，都只是单纯的将
GNN的应用范围很广泛，比如文献[42]利用
用户(物品)相关信息进行处理。时间与空间上
GNN模拟各个物理系统间的关系，进行演绎来预
下文信息，都没有考虑在内。如在文献[31]中，
测整个系统的下一个状态，这说明GNN具有一
定的因果推理能力。现有GNN推荐研究中，尽
作者没有考虑到用户兴趣会随着时间变化对浏
览的记录产生的影响，文献[36]中，没有考虑到 管取得了不错的推荐效果，但是推荐结果往往很
难给出一个令用户信服的科学解释。如在文
患者就诊记录的时间问题，但在不同时期同一个
患者情况会存在很大差异。如何在GNN推荐模
献[31]中，作者使用多个GNN模型得出特征后，
通过MLP进行评分预测，仍然缺乏一定的可解
型中引入时间、内容以及位置等不同的上下文信
释性。
息，以提高推荐性能是值得研究的重要课题
之一。
7 结束语
2)基于GNN的跨领域推荐
跨领域推荐[39]对解决推荐系统的冷启动和数 图神经网络(GNN)推荐方法可以通过节点、
据稀疏性问题有很大的帮助，通过从辅助域到目 边及对应的拓扑结构直接反映推荐系统中实体及
标域的推荐可以取得良好的推荐效果。在传统的 其相互间关系，直接在图上对相关信息进行不断
推荐研究中，跨领域推荐取得了一定成效，如基 更新计算，具有很强的归纳性，有效避免了传统
于标签的跨领域推荐[40]，基于共享知识的跨领域 推荐方法中信息利用不完全带来诸多问题，越来 ·22· 智 能 系 统 学 报 第 15 卷
越受到学术界和产业界的关注。本文深入分析 graph convolutional networks with variance reduction[C]//
了GNN推荐及其过程，对现有GNN推荐相关研 Proceedings of the 35th International Conference on Ma-
究从无向单元图推荐、无向二元图推荐、无向多 chine Learning. Stockholm, Sweden, 2018: 941−949.
元图推荐3个方面进行详细探讨，对各自的优点 [11]LI Q, HAN Z, WU X M. Deeper insights into graph con-
与不足进行了分析，指出了GNN推荐面临的难 volutional networks for semi-supervised learning[C]//
点及未来的研究方向，对基于图的深度推荐系统 Thirty-Second AAAI Conference on Artificial Intelli-
进一步研究具有一定的借鉴意义。 gence. New Orleans, USA,2018.
[12]BRUNA J, ZAREMBA W, SZLAM A, et al. Spectral net-
参考文献：
works and locally connected networks on graphs[C]//In-
[1]ZHOU J, CUI G, ZHANG Z, et al. Graph neural networks: ternational Conference on Learning Representations
a review of methods and applications[J]. arXiv: 1812. (ICLR2014). Banff, Canada, 2014: 1−14.
08434, 2018. [13]MONTI F, BOSCAINI D, MASCI J, et al. Geometric
[2]BASTINGS J, TITOV I, AZIZ W, et al. Graph convolu- deep learning on graphs and manifolds using mixture
tional encoders for syntax-aware neural machine transla- model CNNs[C]//Proceedings of 2017 IEEE Conference
tion[C]//Proceedings of the 2017 Conference on Empirical on Computer Vision and Pattern Recognition. Honolulu,
Methods in Natural Language Processing. Copenhagen, USA, 2017: 5115−5124.
Denmark, 2017: 1957−1967. [14]ATWOOD J, TOWSLEY D. Diffusion-convolutional
[3]HENAFF M, BRUNA J, LECUN Y. Deep convolutional neural networks[C]//Advances in Neural Information Pro-
networks on graph-structured data[J]. arXiv:1506.05163, cessing Systems. Barcelona, Spain, 2016: 1993−2001.
2015. [15]LI Y, ZEMEL R, BROCKSCHMIDT M, et al. Gated
[4]ZHANG Yuhao, QI Peng, MANNING C D. Graph convo- graph sequence neural networks [J]. arXiv:1511.05493,
lution over pruned dependency trees improves relation ex- 2015.
traction[C]//Proceedings of the 2018 Conference on Empir- [16]ZHANG Yue, LIU Qi, SONG Linfeng. Sentence-state
ical Methods in Natural Language Processing. Brussels, LSTM for text representation[C]//Proceedings of the 56th
Belgium, 2018: 2205−2215. Annual Meeting of the Association for Computational
[5]WANG Xiaolong, YE Yufei, GUPTA A. Zero-shot recog- Linguistics. Melbourne, Australia, 2018: 317−327.
nition via semantic embeddings and knowledge [17]KAMPFFMEYER M, CHEN Yinbo, LIANG Xiaodan, et
graphs[C]//Proceedings of 2018 IEEE/CVF Conference on al. Rethinking knowledge graph propagation for zero-shot
Computer Vision and Pattern Recognition. Salt Lake City, learning[C]//Proceedings of 2019 IEEE/CVF Conference
USA, 2018: 6857−6866. on Computer Vision and Pattern Recognition. Long
[6]RHEE S,SEO S, KIM S.Hybrid approach of relation net- Beach, USA, 2019: 11487−11496.
work and localized graph convolutional filtering for breast [18]黄璐, 林川杰, 何军, 等. 融合主题模型和协同过滤的多
cancer subtype classification[J].arXiv: 1711.05859,2017. 样化移动应用推荐[J]. 软件学报, 2017, 28(3): 708–720.
[7]KAWAMOTO T, TSUBAKI M, OBUCHI T. Mean-field HUANG Lu, LIN Chuanjie, HE Jun, et al. Diversified
theory of graph neural networks in graph partitioning[C]// mobile app recommendation combining topic model and
Proceedings of the 32nd International Conference on Neur- collaborative filtering[J]. Journal of software, 2017, 28(3):
al Information Processing Systems. Red Hook, USA, 2018: 708–720.
4361−4371. [19]胡堰, 彭启民, 胡晓惠. 一种基于隐语义概率模型的个
[8]HAMILTON W, YING Zhotao, LESKOVEC J. Inductive 性化Web服务推荐方法[J]. 计算机研究与发展, 2014,
representation learning on large graphs[C]//Advances in 51(8): 1781–1793.
Neural Information Processing Systems. Long Beach, US, HU Yan, PENG Qimin, HU Xiaohui. A personalized Web
2017: 1024−1034. service recommendation method based on latent semantic
[9]CHEN J, MA T, XIAO C. Fastgcn: fast learning with probabilistic model[J]. Journal of computer research and
graph convolutional networks via importance sampling[J]. development, 2014, 51(8): 1781–1793.
arXiv:1801.10247, 2018. [20]刘建勋, 石敏, 周栋, 等. 基于主题模型的Mashup标签
[10]CHEN Jianfei, ZHU Jun, SONG Le. Stochastic training of 推荐方法[J]. 计算机学报, 2017, 40(2): 520–534. 第 1 期 吴国栋，等：图神经网络推荐研究进展 ·23·
LIU Jianxun, SHI Min, ZHOU Dong, et al. Topic model tion: a recurrent model with spatial and temporal contexts[C]//
based tag recommendation method for Mashups[J]. Proceedings of the Thirtieth AAAI Conference on Artifi-
Chinese journal of computers, 2017, 40(2): 520–534. cial Intelligence. Arizona, USA ,2016: 194−200.
[21]曹俊豪, 李泽河, 江龙, 等. 一种融合协同过滤和用户属 [29]XU,KEYULU,et al.How powerful are graph neural net-
性过滤的混合推荐算法[J]. 电子设计工程, 2018, 26(9): works [J]. arXiv:1810.00826, 2018.
60–63. [30]SONG Weiping, XIAO Zhiping, WANG Yifan, et al. Ses-
CAO Junhao, LI Zehe, JIANG Long, et al. A hybrid re- sion-based social recommendation via dynamic graph at-
commendation algorithm based on collaborative filtering tention networks[C]//Proceedings of the Twelfth ACM In-
and user attribute filtering[J]. Electronic design engineer- ternational Conference on Web Search and Data Mining.
ing, 2018, 26(9): 60–63. New York, United States, 2019: 555−563.
[22]张双庆. 一种基于用户的协同过滤推荐算法[J]. 电脑知 [31]FAN Wenqi, MA Yao, LI Qing, et al. Graph neural net-
识与技术, 2019, 15(1): 19–21. works for social recommendation[C]//The World Wide
ZHANG Shuangqing. User-based collaborative filtering Web Conference. New York, USA, 2019: 417−426.
recommendation algorithm[J]. Computer knowledge and [32]YING R, HE Ruining, CHEN Kaifeng, et al. Graph con-
technology, 2019, 15(1): 19–21. volutional neural networks for web-scale recommender
[23]邓园园, 吴美香, 潘家辉. 基于物品的改进协同过滤算 systems[C]//Proceedings of the 24th ACM SIGKDD In-
法及应用[J]. 计算机系统应用, 2019, 28(1): 182–187. ternational Conference on Knowledge Discovery & Data
DENG Yuanyuan, WU Meixiang, PAN Jiahui. Improved Mining. New York, USA, 2018: 974−983.
item-based collaborative filtering algorithm and its applic- [33]CUI Zeyu, LI Zekun, WU Shu, et al. Dressing as a whole:
ation[J]. Computer systems & applications, 2019, 28(1): outfit compatibility learning based on node-wise graph
182–187. neural networks[C]//The World Wide Web Conference.
[24]高玉凯, 王新华, 郭磊, 等. 一种基于协同矩阵分解的用 New York, USA, 2019: 307−317.
户冷启动推荐算法[J]. 计算机研究与发展, 2017, 54(8): [34]WANG X, HE X, WANG M, et al. Neural graph collab-
1813–1823. orative filtering[J]. arXiv:1905.08108, 2019.
GAO Yukai, WANG Xinhua, GUO Lei, et al. Learning to [35]WANG Hongwei, ZHAO Miao, XIE Xing, et al. Know-
recommend with collaborative matrix factorization for ledge graph convolutional networks for recommender sys-
new users[J]. Journal of computer research and develop- tems[C]//The World Wide Web Conference. San Fran-
ment, 2017, 54(8): 1813–1823. cisco, USA, 2019: 3307−3313.
[25]王伟, 陈伟, 祝效国, 等. 众筹项目的个性化推荐: 面向 [36]MAO C, YAO L, LUO Y. MedGCN: Graph convolution-
稀疏数据的二分图模型[J]. 系统工程理论与实践, al networks for multiple medical tasks[J]. arXiv:
2017, 37(4): 1011–1023. 1904.00326, 2019.
WANG Wei, CHEN Wei, ZHU K, et al. Personalized re- [37]刘云, 王颖, 亓国涛, 等. 时间上下文的协同过滤Top-
commendation of crowd-funding campaigns: a bipartite N推荐算法[J]. 计算机技术与发展, 2017, 27(7): 79–82.
graph approach for sparse data[J]. Systems engineering– LIU Yun, WANG Ying, QI Guotao, et al. Collaborative
theory & practice, 2017, 37(4): 1011–1023. filtering top-N recommendation algorithm based on time
[26]ELKAHKY A M, SONG Yang, HE Xiaodong. A multi- context[J]. Computer technology and development, 2017,
view deep learning approach for cross domain user mod- 27(7): 79–82.
eling in recommendation systems[C]//Proceedings of the [38]沈记全, 王磊, 侯占伟, 等. 基于情景上下文与信任关系
24th International Conference on World Wide Web. 的旅游景点推荐算法[J]. 计算机应用研究, 2018,
Florence, Italy, 2015: 278−288. 35(12): 3640–3643.
[27]ZHENG Lei, NOROOZI V, YU P S. Joint deep modeling SHEN Jiquan, WANG Lei, HOU Zhanwei, et al. Attrac-
of users and items using reviews for recommendation[C]// tions recommendation algorithm based on situational con-
Proceedings of the Tenth ACM International Conference text and trust relationship[J]. Application research of
on Web Search and Data Mining. New York, USA, 2017: computers, 2018, 35(12): 3640–3643.
425−434. [39]李林峰, 刘真, 魏港明, 等. 基于共享知识模型的跨领域
[28]LIU Q, WU S, WANG L, et al. Predicting the next loca- 推荐算法[J]. 电子学报, 2018, 46(8): 1947–1953. ·24· 智 能 系 统 学 报 第 15 卷
LI Linfeng, LIU Zhen, WEI Gangming, et al. Cross-do- 作者简介：
main recommendation algorithm based on sharing know- 吴国栋，副教授，中国计算机学会
ledge pattern[J]. Acta electronica sinica, 2018, 46(8): 会员，主要研究方向为深度学习、推荐
1947–1953. 系统。主持安徽省自然科学研究重点
项目1项、一般项目1项、安徽省科技
[40]邢长征, 杨晓婷. 基于SVD++与标签的跨域推荐模
攻关重点项目1项。发表学术论文
型[J]. 计算机工程, 2018, 44(4): 225–230.
30余篇。
XING Changzheng, YANG Xiaoting. Cross-domain re-
commendation model based on SVD++ and tag[J]. Com-
查志康，硕士研究生，主要研究方
puter engineering, 2018, 44(4): 225–230.
向为推荐系统。
[41]李林峰, 刘真, 魏港明, 等. 基于共享知识模型的跨领域
推荐算法[J]. 电子学报, 2018, 46(8): 1947–1953.
LI Linfeng, LIU Zhen, WEI Gangming, et al. Cross-do-
main recommendation algorithm based on sharing know-
ledge pattern[J]. Acta electronica sinica, 2018, 46(8):
1947–1953. 涂立静，讲师，主要研究方向为人
[42]BATTAGLIA P, PASCANU R, LAI M, et al. Interaction 工智能、机器学习。主持安徽省自然
科学研究一般项目1项、安徽农业大
networks for learning about objects, relations and physics[C]//
学青年基金项目1项。发表学术论文
Proceedings of the 30th International Conference on
10余篇。
Neural Information Processing Systems. Red Hook, USA,
2016: 4502−4510.
第四届亚洲人工智能技术大会
The 4th Asian Conference on Artificial Intelligence Technology
由中国人工智能学会、重庆市大数据应用发展管理局、重庆理工大学、重庆市巴南区人民政府联合主
办，重庆理工大学期刊社、重庆市巴南区科学技术局、重庆市巴南区大数据应用发展管理局、重庆两江人工
智能学院联合承办，重庆市人工智能学会协办，重庆市科学技术协会指导的“第四届亚洲人工智能技术大会
（ACAIT 2020）”将作为2020年中国智能产业博览会期间的唯一国际学术会议在重庆召开。
征稿范围（但不局限于）：
1）人工智能理论基础； 2）人工智能应用；3）模式识别； 4）机器感知与虚拟现实；5）自然语言处理和机器
翻译；6）图像和语音处理；7）计算机视觉；8）神经网络与计算智能；9）知识科学与知识工程；10）生物信息学
与人工生命；11）机器学习；12）深度学习及其应用；13）数据挖掘；14）面向大数据的人工智能技术；15）智能
控制与智能管理；16）粗糙集与软计算；17）智能搜索；18）智能推理；19）智能规划；20）智能信息处理；21）智
能制造；22）智能机器人；23）物联网；24）工业互联网；25）智能通信与网络；26）人机交互/普适计算；27）智慧
能源；28）自动程序设计。
联系方式:
联系人：贺柳、徐佳忆
电话：023-62561406
邮箱：cqznjs@126.com；xb@cqut.edu.cn --------------------------------------------------------------------------------- 计算机科学与探索 1673-9418/2022/16(10)-2249-15
JournalofFrontiersofComputerScienceandTechnology doi:10.3778/j.issn.1673-9418.2203004
图神经网络推荐系统综述
吴 静，谢 辉+，姜火文
江西科技师范大学 数学与计算机科学学院，南昌 330038
+通信作者 E-mail:huixie@aliyun.com
摘 要：推荐系统（RS）因信息冗杂繁多而诞生。由于数据形式的多样化、复杂化以及数据信息量稀疏性，传统
的推荐系统已经不能很好地解决目前的问题。图神经网络（GNN）能从图中对边和节点数据进行特征提取和
表示，对处理图结构数据具有先天优势，因此在推荐系统中蓬勃发展。将近年的主要研究成果进行了梳理并
加以总结，着重从方法、问题两个角度出发，系统性地综述了图神经网络推荐系统。首先，从方法层面阐述了
图卷积网络推荐系统、图注意力网络推荐系统、图自动编码器推荐系统、图生成网络推荐系统、图时空网络推
荐系统等五大类的图神经网络推荐系统；接着，从问题相似性出发，归纳出序列推荐问题、社交推荐问题、跨域
推荐问题、多行为推荐问题、捆绑推荐问题以及基于会话推荐问题等六大类问题；最后，在对已有方法分析和
总结的基础上，指出了目前图神经网络推荐系统研究面临的难点，提出相应的研究问题以及未来研究的方向。
关键词：图神经网络（GNN）；推荐系统（RS）；图卷积网络（GCN）
文献标志码：A 中图分类号：TP391
Survey of Graph Neural Network in Recommendation System
WU Jing, XIE Hui+, JIANG Huowen
School of Mathematics and Computer Science, Jiangxi Science and Technology Normal University, Nanchang
330038,China
Abstract: Recommendation system (RS) was introduced because of a lot of information. Due to the diversity,
complexity, and sparseness of data, traditional recommendation system can not solve the current problem well.
Graph neuralnetwork (GNN)can extractand representthe features from edges and nodes data in the graphs and has
inherent advantages in processing the graphs structure data, so it flourishes in recommendation system. This paper
sorts out the main references of graph neural network in recommendation system in recent years, focuses on the two
perspectives of method and problem, and systematically reviews graph neural network in recommendation system.
Firstly, from the method level, five graph neural networks of the recommendation system are elaborated, including
the graph convolutional network in the recommendation system, graph attention network in the recommendation
system, graph autoencoder in the recommendation system, graph generation network in the recommendation system
and graph spatial-temporal network in the recommendation system. Secondly, from the perspective of problem
similarity, six major problem types are summarized: sequence recommendation, social recommendation, cross-
domain recommendation, multi-behavior recommendation, bundle recommendation, and session-based recommen-
基金项目：国家自然科学基金（71561013，61762044）；江西省社会科学研究规划项目（20TQ04）；江西省高校人文社会科学研究项
目（JC17221，JD18083，JC18109）；江西省教育厅科技计划项目（GJJ211116，GJJ170661）。
This work was supported by the National Natural Science Foundation of China (71561013, 61762044), the Social Science Planning
Projects in Jiangxi Province (20TQ04), the Fund of Humanities and Social Sciences in Universities of Jiangxi Province (JC17221,
JD18083,JC18109),andtheProjectofScienceandTechnologyPlanbyEducationDepartmentofJiangxiProvince(GJJ211116,GJJ170661).
收稿日期：2022-03-01 修回日期：2022-06-07 2250 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(10)
dation. Finally, based on the analysis and summary of the existing methods, this paper points out the main difficu-
lties in the current research on graph neural network in recommendation system, proposes the corresponding issues
thatcanbeinvestigated,andlooksforwardtothefutureresearchdirectionsonthistopic.
Keywords:graphneuralnetwork(GNN);recommendationsystem(RS);graphconvolutionnetwork(GCN)
随着大数据时代的到来，数据结构更加复杂，图 用户信任度和粘性，为商家增加营收。根据推荐算
神经网络推荐系统是用来处理非欧式数据并以此来 法[2]所用数据的不同分为基于内容的推荐、协同过滤
提升推荐系统准确度的方法。现实生活中形成的社 的推荐以及混合的推荐。如图1所示为推荐系统基
交网络、知识图谱等都存在大量的非欧式数据，图神 本分类。
经网络（graph neural network，GNN）推荐系统（re-
commendation system，RS）[1]能达到传统推荐系统所
无法达到的效果。尤其在项目与项目、用户与用户、
用户与项目以及显性或隐性信息之间的处理上，
GNN推荐系统能够借助非欧式数据，使得推荐结果
高质量化。推荐系统目前的主要挑战是如何从用户-
物品交互以及辅助信息中学习有效的嵌入信息。其
大部分的信息本质上都是图结构，而GNN在表示学
图1 推荐系统分类
习方面具有先天优势。随着深度学习的发展，作为
Fig.1 Recommendationsystemclassification
常见的深度学习模型GNN，其应用于推荐系统方向
的研究与日俱增，在推荐方向的应用将成为发展的 基于协同过滤的推荐系统是基于用户-项目的历
必然趋势。基于GNN推荐系统问题的相关研究正受 史交互记录产生推荐，可以是显性反馈（评分、喜欢/
到人们的广泛关注和研究。以往的GNN推荐方向的 不喜欢），也可以是隐性反馈（浏览、点击）；基于内容
综述从GNN模型的图结构、个人或群体等角度上进 的推荐主要是根据用户和项目的特征信息来进行推
行总结归纳，本文最大的创新点在于从方法、问题两 荐；混合方法推荐则结合了以上两种不同的推荐方
个角度切入分析，在近些年来图神经网络的相关研 法，即可同时建模静态特征与动态交互。在基于协同
究进行整理的基础上，对图神经网络推荐系统进行 过滤的推荐系统上，图神经网络属于基于图的模型。
深入研究，从两个角度来分析总结基于GNN推荐系
统的最新研究进展，提出GNN推荐系统当前存在的 2 图神经网络推荐系统方法
问题并讨论未来的主要研究方向。 图神经网络[3]借鉴了卷积神经网络、循环网络和
深度自编码器的思想，目的是为了扩展现有神经网
1 推荐系统 络，定义和设计用于处理图形结构数据的神经网络
推荐系统[1]的核心是通过用户的历史行为、兴趣 结构。尽管在提取欧氏空间数据的特征方面，传统
偏好或者人口统计学特征来得到某种推荐算法，该 方法取得了巨大的成功，但图神经网络既可以利用
算法能产生用户感兴趣的项目列表，而该项目列表 图来反映对象之间的复杂关系，还可以对非欧氏空
使得排在前面的物品展示给用户。正因为互联网的 间生成的数据进行特征提取和表示。它在学习图形
发展，推荐系统已经成为互联网产品的标配，而推荐 结构数据方面表现出了更强大的功能。正因为GNN
系统的主要目标是发现并建立用户与信息之间的通 在图学习上的优越性能，它被广泛运用于推荐系统。
道。从用户角度来看，推荐系统就是帮助用户找到 除此之外，它也被应用到许多领域，如文本分类[4]、自
他们所需要的信息，例如喜欢的物品或服务，还会帮 然语言处理[5]、疾病预测[6]、特征关系提取[7]等。
助用户做出决策，并且发现用户可能感兴趣的潜在 对于推荐系统来说[8]，一般推荐系统包括三个阶
信息；从信息角度来看，推荐系统可以将特定的信息 段，分别是匹配、排序和再排序。图神经网络[9]的原
提供给特定的用户，以此来提供个性化的服务，提高 理主要是：首先构建图结构模型来反映实体和实体 吴 静 等：图神经网络推荐系统综述 2251
之间的关系；再利用特定的方法对节点进行描述并 事实上，GCN与其他四类也进行了融合，创造了许多
得到包含最终的邻居节点信息和拓扑结构特点状态 成果。在最近的文献研究里，更多的是处理大规模
的节点，该节点已经进行了不断的更新迭代；最后将 的数据。文献[11]提出了一种基于高效的随机游走
通过某种特定的方式输出这些节点的表示形式，并 方法来构建卷积模型，并设计了一个新颖的训练策
获得所需要的信息。而对于GNN推荐系统来说，其 略来改善模型的鲁棒性和收敛性。其在基于图卷积
主要阶段和图神经网络过程接近，一般只分为四步： 架构的推荐系统上，能解决数亿级别用户的Web推
（1）根据实体相互关系建立GNN模型；（2）决定GNN 荐任务，但不足之处在于不能解决其他大规模的图
模型的信息传播与更新方法；（3）提取出更新后的节 表示学习问题。对于处理大规模数据的计算和内存
点特征；（4）选取算法实现推荐。本文基于图神经网 问题上，Chen等[12]提出了一种基于混合内存计算
络推荐系统的方法主要分成了五大类。图2表示了 （computation-in-memory，CIM）结构的图卷积网络的
GNN推荐系统主要的五大分类。 有效分配方法。该方法还解决了图卷积网络在应用
中的不规则数据的访问问题。CIM结构上优化了
GCN的任务分配，为GCN推荐系统上数据处理提供
了一个解决方案。同样地，对于处理和训练复杂的
大规模异构图数据上，Tran等[13]则开发了一个基于
GCN原理的新的框架——HeteGraph（graph learning
in recommender systems via graph convolutional net-
works）。其通过一种抽样技术和一个图卷积运算来
学习高质量图的节点嵌入。这个与传统的GCN不
图2 GNN推荐系统分类 同，后者需要一个完整的图邻接矩阵来进行嵌入学
Fig.2 Taxonomyofgraphneuralnetwork-based 习，而该框架是设计了两个模型来评估推荐系统任
recommendationsystem 务，即项目评级预测和多样化项目推荐。该方法主
要是应用于大规模异构图数据的推荐问题，但仅适
2.1 图卷积网络推荐系统
用于两个实体，即用户和项目。进一步来说，Shafqat
图卷积网络（graphconvolutionnetworks，GCN）[10]
等[14]将用户-项目点击交互作为概率分布，并使用该
是将卷积运算从传统数据推广到了图数据，如图3
值度量节点之间的相似度。该方法采用了两个不同
所示。
节点之间的相似性度量来事先对邻居进行采样。这
种方法简化了GCN模型的邻居抽样任务，提高了训
练效率，降低了复杂度和计算时间，但需要形成会话
图，并不适应于所有推荐系统场景。对于异构图数
据，不同于Tran等[13]方法，Yin等[15]提出的基于异构信
息网络的高效推荐算法是利用图卷积神经网络自动
学习节点信息的特点，提取异构信息，并融合异构信
息的计算策略和评分信息融合策略解决节点评分问
图3 图卷积原理图
题，通过更新节点，减小了训练规模，提高了计算效
Fig.3 Principlediagramofgraphconvolutionnetworks
率。除了数据量的问题，关于可解释性上，同样地利
该图是使用深度为2的卷积模型。左边是一个 用了用户和项目两个实体，Chen 等[16]将知识图
小的输入图示例，右边为两层神经网络。该网络使 （knowledge graph，KG）引入到推荐系统来提高可解
用节点 A及其邻域 N A（节点 B、C、D）来计算节 释性。他们提出了一种基于KG的交互式规则引导
( )
点 A的值。 推荐（interactive rules-guided recommender，IR-Rec）
在基于图卷积神经网络推荐系统的算法中，一 框架，主要是从增强的KG中提取用户-项目之间交
部分算法并不会直接使用GCN方法，而是将GCN与 互的多条路径，再从潜在动机角度将这些路径归纳
图嵌入融合在一起，从而提升了整个模型的效率。 出一些公共行为规则，通过这些规则来确定推荐的 2252 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(10)
潜在原因。根据用户、项目和规则设计了图卷积网 献[19]仅仅利用了其他信息来关联一些隐性信息。
络等不同神经网络来学习嵌入表示。Bonet等[17]给出 实际上，许多社会研究和实践案例表明，人们的消费
了一种时间协同过滤（temporal collaborative fil- 行为和社会行为不是孤立的，而是相互关联的。一
tering，TCF）方法，利用GNN学习用户和项目表示， 些隐性信息也值得挖掘。Xiao等[21]基于图神经网络、
并利用递归神经网络建模。该方法为了解决数据稀 注意机制和互补模型，创造出了一种新的框架——
疏性，使用每段时间累积的数据来训练GNN，提高了 MutualRec（joint friend and item recommendations with
推荐系统的性能，但其侧重于提高推荐的准确度，忽 mutualistic attentional graph neural networks），用于联
视了推荐系统的可解释性，且无法应对数据样本量 合建模社交网络中的用户偏好和社交交互。这种框
稀少的情况。 架使用了空间和频谱注意力神经网络层来获取用户
2.2 图注意力网络推荐系统 的偏好特征和社交特征，再通过互补模型中的关注
图注意力网络（graph attention network，GAT）[10] 层将两个特征融合在一起，同时解决了社交推荐和
是一种基于空间的图卷积网络，它在聚合特征信息 链路预测任务。该模型具有一定局限性，可以结合
时，将注意力机制用于确定节点邻域权重。它能够 知识图来推荐，进而更好地使前两层缓解数据稀疏
放大数据中最重要部分的影响并且能够自适应地学 性。而Dang等[22]首次提出了一种将知识图和知识表
习邻居节点权重。但是，计算成本和内存消耗会随 示引入到Web服务推荐中的深层知识感知方法，并提
着每对邻居之间的注意权重的计算而迅速增加。这 出了一种深度知识感知的Web服务推荐框架（deep
也是基于GAT推荐系统的难题。 knowledge-awareapproach forWeb servicerecommen-
基于GAT推荐系统的研究比较丰富。社交关系 dation，DKWSR）。该框架还加入了注意力机制来模
是GAT应用的主要因素。Song等[18]提出了用于在线 拟当前候选项目的标签对组合项目表示的影响。这
社区基于会话的社交推荐的动态图注意力神经网络 解决了因用户调用有限数量的服务而导致的数据稀
（dynamic-graph-attention neural network）模型。同样 疏性和冷启动问题，并提高了推荐结果的可解释
地，Jiang等人[19]也认为社会关系能优化推荐系统，由 性。Li等[23]为解决数据稀疏和冷启动的问题，利用图
此将社会信息融入到图卷积网络中的嵌入邻域聚类 的边信息创造出了一个名为GSIRec（graphsideinfor-
中，利用用户-项目交互图和社会关系图来捕捉用户 mation for recommendation）的深层端到端推荐框
的项目品味和用户朋友之间的关系。他们设计了一 架。其利用了图注意力神经网络来增强推荐。
种新的框架——注意力社会推荐系统（attentional Salamat等[24]通过将社会网络建模为一个异质图，利
social recommendation system，ASR），通过两个注意 用带注意力机制的GNN智能聚合来自所有来源的信
力机制分别研究节点的邻居权重以及交互图和社交 息，并提出了一种新的基于图的推荐系统Hetero-
图之间的语义贡献，并利用分层图注意力卷积网络 GraphRe（heterogeneous graph-based neural networks
使SAR能自适应地探索更高阶的交互和社会邻居， for social recommendations）。该系统提高了模型的
以构建更好的嵌入表示。但是，ASR设置了两个注 可解释性，但未考虑社交网络的动态行为。以上的
意力机制而使模型更加复杂，往后需要有效、合理地 文献方法都能有效解决数据稀疏和冷启动问题，但
简化GAT。在社会关系的另一方面，对于利用社会 由于文献[24]需要获取了大量的信息，那么如何进行
信息解决传统协同过滤中的数据稀疏性和冷启动问 高效的数据筛选从而捕获有用的信息也是一个大的
题，Wu等[20]提出了能够学习二重社交影响的对偶图 挑战。众所周知，KG能有效地缓解数据稀疏性，但
注意力网络（dual graph attention networks for mode- 基于KG的推荐系统不能自动捕获实体对推荐的长
ling multifaceted social effects in recommender sys- 期依赖关系，Sang等[25]提出了一种双通道神经交互方
tems，DANSER），它包括两个对偶的图注意力网络， 法——知识图增强神经协同过滤残差递归网络
以学习推荐系统中社会效应的深层表征，利用了特 （knowledge graph enhanced neural collaborative fil-
定用户的注意力权重和通过动态并能够感知上下文 tering with residual recurrent network，KGNCF-RRN）。
的注意力权重来建模。不同于大多数的模型，它并 该方法能捕捉丰富的语义信息，还能捕捉用户与项
没有假设好友的社会影响是固定静态的。而在上述 目之间复杂的隐含关系，用于推荐。这也为捕获隐
文献中，文献[18，20]都有考虑到用户的动态性，而文 性信息提供了方法。 吴 静 等：图神经网络推荐系统综述 2253
2.3 图自动编码器推荐系统 GV100和32GBRAM的计算机，所有用户训练SMVAE
图自动编码器（graphautoencoders）[7]是一类图嵌 （supervised multi-variationalauto-encoder）的总时间
入方法，典型的用法是利用多层感知机作为编码器 为33.5 h。如何更高效、更简洁地处理大数据，从而
来获取节点嵌入。其目的是利用神经网络结构将图 挖掘隐式关系，是需要考虑的问题。
的顶点表示为低维向量。Kipf与Welling在2016年 2.4 图生成网络推荐系统
提出了基于图的（变分）自编码器——VGAE（varia- 图生成网络（graph generative networks）[7]是给定
tionalgraphauto-encoder）。自此开始，图自编码器在 一组观察到的图的情况下生成新的图。图生成网络
很多领域都派上了用场，例如脑电路图[26]、多视图[27]、 的方法都是基于特定领域，例如：分子图生成、自然
社交网络[28]等。 语言处理等。一些方法是将生成过程看作交替生成
在隐式关系上，文献[29-32]各自提出了模型，但 节点和边，另一些方法是利用生成对抗训练。在最
区别在于一个是捕捉图结构下的隐式信任关系，另 近的研究中，图生成网络正在被深度学习彻底改变，
一个是捕获隐式数据之间的关系。Zheng等[29]提出 其应用广泛，尤其是药物中的分子生成等[33]方面。而
了一种基于变分自动编码器（variationalauto-encoder， 在推荐系统的生成图上，新节点连通性与现有图的
VAE）的隐式信任关系感知社交推荐模型（implicit 冷启动问题一直存在。例如用户属性，如性别、教育
trustrelation-awaremodel，ITRA）。ITRA采用注意模 等存在着大部分缺失信息，使得个性化推荐任务遇
块将加权信任嵌入信息反馈到继承的非线性VAE结 到一定问题。Zhou等[34]提出一种基于对抗性VAE的
构中。模型可以通过重建一个包含间接关键意见领 属性推断模型（infer-AVAE）。该模型将多层感知器
袖和邻居显性联系的隐式高阶交互的非二进制邻接 和GNN结合，学习正负潜在表示，还将引入互信息约
社交矩阵进行推荐。而典型的模型通常将用户信任 束作为解码器的正则化器，以更好地利用表示中的
关系描述为从社交图中导出的二进制邻接矩阵，基 辅助信息并生成不受观察限制的输出表示，但其还
本上只包含邻域交互，然后用相同的值对不同个体 是会出现过拟合和过度平滑问题。对稀疏性数据，
的信任值进行编码。这种方法无法捕捉隐藏在图结 很容易产生过拟合现象。尽管在学习图表示和图生
构下的隐式高阶关系，因此忽略了间接因素的影 成方面出现了一些新的文献，但是由于学习过程严
响。而Yao等[30]提出了相关瓦瑟斯坦自动编码器 重依赖于拓扑特征，从而导致大多数的图表示和图
（correlated Wasserstein autoencoders，CWAEs）模型， 生成方法大都不能处理孤立的新节点。在这方面，
通过无向无环图来表示数据，利用现实世界数据通 Xu等[35]提出了一个统一的生成图卷积网络模型，该
常相互关联的特点，以提高推荐性能。更进一步地， 模型通过对观察到的图形数据构造的图生成序列进
Deng等[31]提出了一种混合的HybridGNN-SR（combi- 行采样，自适应地学习生成模型框架中所有节点的
ning unsupervised and supervised graph learning for 节点表示。此模型是将图表示学习和图卷积网络结
session-basedrecommendation）模型，将无监督图学习 合到一个顺序生成模型，该方法在增长图的链接预
和有监督图学习相结合，从图的角度来表示会话中 测上优于其他方法。然而，因为计算复杂性取决于
的项目转换模式以此捕捉节点特征的图形结构数 完整图的大小，可伸缩性仍然是一个主要问题。大
据。具体说，在无监督学习部分，提出将变分图自动 多数研究还会结合对抗神经网络、卷积神经网络构
编码器和互信息相结合来表示会话图中的节点；在 成图生成对抗神经网络。例如，Wu等[36]提出了一种
监督学习部分，使用一种路由算法来提取会话中较 新的基于图卷积的生成先令攻击（graph convolution-
高概念特征进行推荐。这种算法考虑了会话中的项 basedgenerativeshillingattack，GOAT），部署了一个生
目之间依赖关系。文献[32]则是开发了一种考虑用 成性对抗网络（generativeadversarialnetwork，GAN），
户偏好的监督多变量自动编码器（supervised multi- 其生成器还结合了一种图卷积结构。该方法是为了
variational autoencoder considering user preference， 探索推荐系统的稳定性，进而提出了先令攻击模
SMVAE-UP），可以提取内容特征之间的关系，从而获 型。此推荐方法只适用于对基于评论等内容的推
得偏好感知的多通道特征。这样可以从大量帖子中 荐。同样是结合对抗神经网络，Zhang等[37]提出了一
为每个用户个性化推荐帖子，但是该训练时间具有 种新的全局仿射和局部特定生成对抗网络（global-
局限性，使用了Intel Core i77800X，NVIDIA Quadro a ne and local-specific generative adversarial network，
ffi 2254 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(10)
GALS-GAN），用于显式构造全局语义布局和学习不 在空间上现有作品只考虑了用户和POI的距离或者
同的实例级特征，解决了合成细粒度纹理和小规模 POI-POI距离，不能发现用户区域周期偏好；另一方
实例的困难。可见，图生成网络推荐系统开始和卷 面，在时间上大多数文献将用户和时间视为两个独
积神经网络或对抗神经网络进行了一定程度的融 立的因素，没有发现不同用户可能在不同的时间偏
合。受到深度学习和强化学习最新进展的启发，有 爱相同的POI。Han等[42]对此提出了多个利用用户区
些人[38]开始利用图的深度生成模型结合注意力机制 域周期模型和用户POI周期模型的评分函数，还开发
来生成模型。不过，这些推荐系统仅仅是想生成有 了一个时间平滑策略来缓解数据稀疏性问题，但未
用且有效的信息，并没有考虑到兴趣会随时间变化， 能考虑到时空序列节点之间的上下文信息。
当图变大时，对长序列建模就变得困难了，而且这些 总体而言，在以上五类基于图神经网络推荐系
方法都不能扩展到大的图，其性能还有待提升。 统研究中，如表1所示，图卷积与图注意力神经网络
2.5 图时空网络推荐系统 依旧是热点，GCN能够和其他四类进行嵌入获得新
图时空网络（graph spatial-temporal networks）[7] 的方法。而图自动编码器很适合发现并处理隐式数
同时捕捉时空图的时空相关性，它利用时空图来建 据，图生成神经网络会利用对抗神经网络成为对抗
模。时空图具有全局图结构，每个节点的输入随时 生成网络，还会结合知识图谱增强数据，减少节点数
间变化。图时空网络的目标可以是预测未来的节点 据稀疏。而图时空网络推荐系统场景基本上是POI
值或标签，或者预测时空图标签。它常用于交通流 任务推荐，由于数据量大，会结合注意力网络和卷积
量预测方面。最近的研究常结合深度学习使用时空 神经网络建模。单独采用图生成网络推荐系统和图
图卷积网络（spatial-temporal graph convolution net- 时空网络推荐系统文献较少。一方面是计算内存和
works，ST-GCN）来提取空间和时间维度上的特征。 速度限制了该方向的研究进展；另一方面是图生成
例如Park等[39]设计的生成性对抗网络框架，它从一组 网络对于新节点只有节点属性可用，图时空网络中
带有样式标签但未配对的运动剪辑中学习风格特 的时空图涉及到空间和时间问题。不过，这也表示
征，以支持多个样式域之间的映射，而以往多采用单 了该研究处于研究阶段初期。图生成网络推荐系统
一维度，例如利用时间轴来提取数据风格特征，无法 和图时空网络推荐系统存在巨大继续研究的空间。
表现空间动态的运动。虽然该文献中的框架能提取
空间和时间两个维度的特征，但其对随机噪音十分 3 GNN推荐系统问题
敏感，适合少量已经标好明确样式标签的数据。对 由于存在该领域的研究成果不单单属于以上分
于涉及时间动态和属性交互上，一般算法通过时间 类，而且从图神经网络角度来看，图卷积神经网络常
线分割不同的时间窗口，但不适用于有交互行为的 与其他四类结合来促进推荐系统领域发展，另一方
数据，还不能完全处理异构节点数据。Zhang等[40]提 面，推荐系统中的图神经网络[43]开始融合社交网络和
出了一个新的框架TigeCMN（temporalinteractiongraph 知识图谱。虽然Xiang等在文献[44]已经归纳出了问
embedding via coupled memory neural networks），从 题类别，但基于图神经网络的推荐系统的范围非常
一个序列的时间相互作用中学习节点表示。该框架 庞大，有些算法和应用很难明确归纳到某一类。而
也可以结合机器学习任务，适用性广，但仅仅考虑了 对于有些分类来说，同一分类的问题可以针对不同
二部图，未扩展到多部异构图而且训练过程中提取 类型的算法和应用。这里，按照推荐系统一般的场
数据是均匀抽样，其实用性较差，具有很大的改进空 景[8]来划分，把问题分为六类：序列推荐问题、社交推
间。杨珍等[41]提出了该方向的专利，通过建模时序信 荐问题、跨域推荐问题、多行为推荐问题、捆绑推荐
息的GCN，再分配给周围邻居的时序注意力权重来 问题以及基于会话的推荐问题。
探索时序信息，提高了推荐系统的性能。但该方法 3.1 序列推荐问题
只能用于购物商品推荐，具有一定的局限性。与传 在真实场景中，通常会使用所有数据来训练模
统推荐任务不同，由于POI（point-of-interest）推荐具 型，但这样会遗漏用户表示中的用户序列行为信
有个性化、空间感知和时间依赖性，图时空网络推荐 息。在最近的研究中，Yang等[45]通过添加一个标签
系统常应用于POI推荐。已有文献尝试对空间和时 推荐函数建立一个顺序推荐模型。Gu等[46]将项目图
间特征建模，但大多存在以下两大局限性：一方面， 嵌入和上下文建模结合到推荐系统任务中去。而 吴 静 等：图神经网络推荐系统综述 2255
表1 GNN推荐系统各类别的对比
Table1 Classescomparisonofgraphneuralnetworkinrecommendationsystem
分类 作者 关键技术 问题场景 优点 局限性
不能解决其他大规模的图表示学
Ying等[11] GCN、随机游走 Web推荐任务 提高模型的鲁棒性
习问题
Chen等[12] GCN 所有推荐任务 减少处理延迟 内存访问模型复杂
应用于大规模异构
Tran等[13] GCN 处理异构图数据 仅适用于两个实体，即用户和项目
图数据的推荐任务
简化了GCN模型的邻居抽样任
需要形成会话图，并不适应于所有
图卷积网络 Shafqat等[14] GCN 在线产品推荐任务 务，提高了训练效率，降低了复
推荐系统场景
推荐系统 杂度和计算时间
提取和组合异构图中的结构特
异构信息网络的推
Yin等[15] GCN 征，减小了训练规模，提高了计 算法复杂
荐任务
算效率
Chen等[16] GCN、KG TOP-K推荐 提高可解释性 学习效率低，未利用更多的辅助信息
提高推荐系统的性能和推荐的 处理不了冷启动和数据稀疏性问
Bonet等[17] GCN、递归神经网络 大数据推荐任务
准确度 题，忽略了推荐系统的可解释性
Song等[18] 图注意力神经网络 在线社区社交推荐 能进行用户的动态的兴趣推荐 只能对大规模数据有效
图注意力神经网络、 模型复杂，无法区分社交的正面和
Jiang等[19] 社交推荐 能发现潜在的社会传播效应
GCN 负面影响
能学习社会深层次表征，提高推
Wu等[20] 图注意力神经网络 社交推荐 需要提取足够多的高层联系信息
荐准确度
Xiao等[21] 图注意力神经网络 社交推荐 融合用户偏好和社交交互信息 不能完全利用辅助信息
充分挖掘文本特征，解决数据稀
图注意力网 图注意力神经网络、
Dang等[22] Web服务 疏性问题，优化特征表示，提高 模型需与其他开放知识库相结合
络推荐系统 知识图谱
推荐的可解释性
图注意力神经网络、评级预测任务、
Li等[23] 解决数据稀疏和冷启动的问题 运行时间较长
知识图谱 TOP-K推荐任务
Salamat等[24] 图注意力神经网络 社交推荐 提高了模型的可解释性 未考虑社交网络的动态行为
图注意力神经网络、
能自动捕捉丰富的语义信息和用
Sang等[25] 知识图谱、残差递归 所有推荐 未考虑用户之间交互的顺序性
户与项目之间复杂的隐含关系
神经网络
捕捉隐藏在图结构下的隐式高
Zheng等[29] 图自动编码器、GCN 社交推荐 未考虑用户之间交互的顺序性
阶关系，提高推荐系统性能
Yao等[30] 图自动编码器、GCN 隐式数据的推荐系统 捕获数据相关性以提高推荐性能 未考虑时间顺序因素
图自动编码
图自动编码器、无监 考虑了会话中的项目之间依赖 对模型中各组件和超参数的影响
器推荐系统 Deng等[31] 会话推荐
督学习、有监督学习 关系 未知
从大量帖子中为每个用户个性
Ohtomo等[32] 图自动编码器 个性化推荐 训练时间长
化推荐帖子
图生成神经网络、 更好地利用辅助信息并生成不
Zhou等[34] 个性化推荐 对稀疏性数据很容易产生过拟合
GCN 受限制的输出表示
图生成神经网络、
Xu等[35] 社交推荐 解决冷启动问题 大图的计算复杂度高
GCN
图生成网络 图生成神经网络、生
Wu等[36] 在线推荐 增强推荐系统的稳定性 只能对评论等基于内容的推荐有用
推荐系统 成对抗网络
图生成神经网络、 解决了合成细粒度纹理和小规
Zhang等[37] 图像推荐 严重依赖于推断的语义
GCN 模实例的困难
图生成神经网络、 大图长序列建模困难，信息质量要
Xu等[38] 在线视频推荐 提高推荐的准确度
GCN 求高
图时空神经网络、 能提取空间和时间两个维度的 对随机噪音十分敏感，适合少量已
Park等[39] 运动风格推荐
GCN 特征 经标好明确样式标签的数据
仅仅考虑了二部图，未扩展到多部
图时空神经网络、图
Zhang等[40] 所有推荐任务 适用性广 异构图而且训练过程中提取数据
图时空网络 嵌入、GCN
是均匀抽样，其实用性较差
推荐系统
图时空神经网络、
杨珍等[41] 用户商品推荐 提高了推荐系统的性能 只能用于购物商品推荐
GCN
图时空神经网络、 未能考虑到时空序列节点之间的
Han等[42] POI推荐 缓解数据稀疏性问题
GCN 上下文信息 2256 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(10)
Tao等[47]提出了一种新的序贯推荐方法，从隐式用户 式出现时，它能解释与图相关的边信息。Ouyang等[57]
交互历史中学习项目趋势信息，并将项目趋势信息 利用相关域的互补信息来缓解稀疏性，实现了基于
合并到后续的项目推荐任务中，利用了门控图神经 学习应用嵌入的跨域应用推荐，可以为用户找到符
网络对项目趋势表征建模来提高项目的表征能 合自己兴趣的应用程序。对于个性化新闻推荐，
力。这些提出的方法都提高了推荐系统的性能，但 Sheu等[58]提出了一种基于上下文感知的图嵌入方法，
文献[46-47]都是利用历史信息且都采用了注意力 用于新闻的推荐。为了充分利用结构和特征信息，
机制，只是前者使用的是会话序列信息，后者使用的 Liang等[59]提出了一种新的异构图神经网络框架——
是用户交互历史。对于隐式信息，Wang等[48]引入知 HGNRec（heterogeneous graph neural network frame-
识图，利用用户的隐式偏好表示，整合了递归神经网 work）。Ma等[60]提出了一个基于图的行为感知网
络和注意力机制，以捕捉用户兴趣的演变和序列中 络。由于应用场景不一样，所需信息的量也不同，而
不同项目之间的关系。 知识图谱所捕获的信息量巨大，故文献[55]的推荐模
3.2 社交推荐问题 型的运行也较其他场景更复杂。其中文献[58-60]都
社交推荐主要是利用信任或亲密的人所感兴趣 是适用于新闻推荐应用，但目标不一样，文献[58]强
的东西，即用户关系链中的推荐内容，进而对用户进 调新闻个性化，而文献[60]则重在多样化。Wang等[61]
行推荐。近些年，在提高社交推荐的精确度上，Guo 将标准的图卷积网络引入推荐中，它利用用户-物品
等[49]关注到了项目特征之间的相关性，将用户特征空 交互图来传播嵌入特征表示：
间和项目特征空间抽象为两个图形网络。Liu等[50]提 e(k +1) σW e(k ) 1 W e(k ) W e(k ) e(k ) （1）
出了项目关系图神经网络，用于同时发现多个复杂 u = ( 1 u +∑ i ∈N
u
|N u||N i|( 1 i + 2( i ⊙± u )))
关系，而且对于不能直接获取的项目或者用户信息 e(k +1) σW e(k ) 1 W e(k ) W e(k ) e(k ) （2）
提供了解决方案。而Salamat等[51]通过将社会网络建 i = ( 1 i +∑ u ∈N
i
|N u||N i|( 1 u + 2( u ⊙± i )))
模为一个异质图，利用带注意力机制的GNN智能聚 He等[62]则简化了该公式：
合来自所有来源的信息，建立用户与用户、项目与项 e(k +1) 1 e(k ) （3）
u =∑ |N | |N| i
目、用户与项目之间的关系。在关系方面，实体之间 i ∈N u u i
还存在着高阶的关系，为了捕获这些高阶的关系，很 e(k +1) 1 e(k ) （4）
i =∑ |N| |N | u
多文献考虑将知识图谱和用户-项目图进行融合。又 u ∈N i i u
上述研究表明模型的简单性带来了更高的性
因为知识图谱有多重类型的边，所以需要使用注意
能。Amar[63]针对推荐系统问题提出了一种基于SVD
力机制来聚集来自邻居的信息。在用户信息整合
上，一些工作[52]假设用户具有静态的表示，再利用 （singular value decomposition）的简单方法的基准测
GNN来学习项目表示；另外的一些工作[53]则将用户 试，以理解进一步简化建模方法是否可以改善性能
作为知识图谱中一种输入数据来学习。例如Wang
指标。Liu等[64]采用两个GNN来处理每个用户/物品
等[54]对融合后的知识图谱进行嵌入表示，使用注意力 的Embedding，其中一个处理偏好，另一个处理相似
机制和递归神经传播邻居节点的嵌入表示来更新当 性。这个带有两个图的模型将GNN和协同过滤方法
前节点的表示。这些关系在一定程度上解决了图神 进行了融合，使推荐系统达到了更高的精确度。
经网络推荐系统数据的稀疏性问题。 3.4 多行为推荐问题
3.3 跨域推荐问题 在现实中，用户行为不仅仅是单个类型的用户
跨域推荐一般利用原本的数据集来对单个目标 与商品的行为数据，还有复杂的交互关系类型数据，
进行推荐，有的还考虑到用户与物品之间的双向潜 例如：加购、点击、购买、收藏等。Xia等[65]提出了一种
在关系和潜在信息。Yang等[55]将知识图与排序学 基于图形神经网络的多行为增强推荐框架，该框架
习、神经网络相结合来构建模型，提出了基于知识图 在基于图形的消息传递体系结构下，显式地建模不
的贝叶斯个性化推荐模型和基于知识图的神经网络 同类型的用户-项目交互之间的依赖关系。它还设计
推荐模型，可以通过捕获高阶关系来解决个性化问 了一个关系聚合网络来模拟交互异构性，并递归地
题。文献[56]引入了一种新的耦合图张量分解模 在相邻节点之间通过用户-项目交互图进行嵌入传
型。当单边的信息以项目-项目相关矩阵或图形的形 播。它采用了异构图来构建依赖关系，而在交互的 吴 静 等：图神经网络推荐系统综述 2257
时间序列上，Yu等[66]用一种基于图神经网络的混合 导，目前研究的会话推荐系统正解决这方面的问
模型对多行为交互序列进行特征层次的深层表示， 题。在基于匿名会话预测用户操作上，Zheng等[76]提
从而实现基于会话的推荐。在具体的互动式新闻推 出了一种双通道图转换网络的方法，用于模拟目标
荐上，Ma等[60]同时考虑了六种不同类型的行为以及 会话和邻居会话之间的项转换。基于多行为的会话
用户对新闻多样性的需求。他们分别从不同角度来 推荐预测下一个项目上，Yu等[66]提出了一种基于图
解决用户的多行为问题，但方法各有千秋，用户的多 神经网络的混合模型GNNH。与其他模型相比，该
行为问题依旧是一个挑战。 模型通过特征级别表征学习发现多行为转换模式的
3.5 捆绑推荐问题 潜力，能够对多行为交互序列进行特征层次的深层
捆绑推荐经常使用在场景推荐中，由于用户不 表示，从而实现基于会话的推荐。对于会话兴趣动
仅仅与单个物品进行交互，他们希望一次性得到自 态问题上，Gu等[46]提出了一种将项目图嵌入和上下
己想要的产品。那么，怎样才能使用户获得所需的 文建模结合到推荐任务中的方法。它是基于所有历
一系列物品，这是一个问题。在法律推荐方面，Yang 史会话序列构造的有向图，利用图神经网络捕捉项
等[67]构造了一个HLIN（heterogeneous legal informa- 目之间丰富的局部依赖关系。并采用会话级注意机
tion network）网络，它包含了文本信息和各种节点。 制，根据目标用户的当前兴趣获得每个好友的表
其基本思想是融合来自多个异构图的交互特征以改 示。它还对目标用户的历史会话兴趣应用最大池，
进图节点的表示学习，例如user-item二部图和social 了解其长期兴趣的动态性。基于会话推荐的技术
关系网络图。Zhang等[68]认为这是第一次将meta- 上，Huang等[77]提出了一个具有多级转换动力学
path与social relation表征结合起来的工作。草药推 （multi-level transition dynamics，MTD）的多任务学习
荐方面，Yuan等[69]将注意机制引入综合症状诱导过 框架，该框架能够以自动和分层的方式联合学习会
程模型。此外，它还引入了中医知识图谱，以丰富输 话内和会话间的项目转换动力学，从而捕捉了复杂
入语料库，提高表示学习的质量。在减轻客户服务 的过渡动态信息，这种过渡动态表现为时序和多级
压力方面：Liu等[70]通过图形神经网络对一组灵活的 相互依赖的关系结构。
服装项目进行建模；Chen等[71]采用时空图进行了动 这六种分类方法是从问题角度出发的分类。如
态预测，动态地提供最优的自行车站布局；Yang等[45] 表2所示，在这六大分类中不难发现，信息质量与数
添加了一个标签推荐函数，通过点击标签快速捕获 量是一个很大的影响因素，为了得到更多的有用信
用户的问题意图。在舞蹈音乐推荐方面：Gong等[72] 息，会采用隐式信息或者高阶信息。序列推荐方面
提出了一种基于舞蹈运动分析的深度音乐推荐算 也可以适量结合该方面的其他信息来提升推荐准确
法，实现了一种新的音乐推荐方法，可以学习动作和 性。而跨域推荐中模型改进上的简化也值得探究。
音乐之间的对应关系。针对开发人员所需的API 那么数据是否也需要简化呢？随着个性化和用户多
（application programming interface）问题，Ling等[73]提 行为化，个性化推荐和多样化推荐的平衡如何维
出了一种新的API使用推荐方法GAPI（graph neural 持？这也有待研究。
network based collaborative filtering for API usage
recommendation）；Zhang等[74]提出了基于图卷积网络 4 GNN推荐系统研究难点及未来研究方向
的语义变分图自动编码器，这是一种端到端的方 随着在线信息的爆炸式增长，人们提出了众多
法。对于课程推荐，Zhu等[75]将网络结构化特征与图 推荐方法，推荐系统取得了一定的研究进展。尤其
形神经网络和用户交互活动相结合，采用张量分解 是图神经网络，已有的研究进展和现今计算内存和
技术，提出了一种混合推荐模型。可见，图神经网络 速度的提升为图数据分析铺平了道路，对基于图神
推荐系统的实用场景丰富。场景动态性是考虑的重 经网络的推荐系统研究提供了强有力的帮助。图神
点，时空图和动态图将是研究的主要问题。 经网络作为一种有效的图数据深度表示学习技术，
3.6 会话推荐问题 其研究已经成功地探索了推荐系统方面的多种任
在会话推荐系统中，系统通过自然语言和用户 务，并证明了其有效性。以往图神经网络对推荐的
进行动态交互，识别出用户的偏好，进而进行物品推 研究角度是GNN模型的图结构、个人或群体等，大多
荐。一般的静态模型缺乏用户的实时反馈和显式指 集中在无向图的结构或用户数量分类上，忽略了 2258 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(10)
表2 问题相似性归纳分析
Table2 Inductiveanalysisofproblemsimilarity
问题分类 方法分类 作者 难点
图注意力网络、图卷积网络 Yang等[45] 数据稀疏和冷启动问题，异构图
图卷积网络、图注意力网络 Gu等[46] 动态兴趣建模问题
序列推荐问题
图注意力网络 Tao等[47] 项目趋势信息，动态图构建问题
图注意力网络 Wang等[48] 高阶关系建模，可解释性
图自动编码器 Guo等[49] 大数据与个性化信息
图神经网络 Liu等[50] 大数据，关系动态变化问题
图注意力网络 Salamat等[51] 大数据，异构图，可解释性，动态行为
社交推荐问题
图注意力网络 Liu等[52] 动态表示问题，知识图
图注意力网络 Tu等[53] 数据稀疏，个性化问题，知识图
图卷积网络 Wang等[54] 大数据，隐含兴趣，动态兴趣
图神经网络 Yang等[55] 大数据，数据稀疏和冷启动，动态问题
图神经网络 Loannidis等[56] 可解释性
图神经网络 Ouyang等[57] 数据稀疏
图注意力网络 Sheu等[58] 缺乏用户交互记录
图神经网络 Liang等[59] 信息高效性，异构图
跨域推荐问题
图卷积网络、图注意力网络 Ma等[60] 异构图，多样性和准确性
图卷积网络 Wang等[61] 交互图嵌入特征表示
图卷积网络 He等[62] 邻域聚合
图神经网络 Amar[63] 算法简洁性，信息高效性
图神经网络 Liu等[64] 模型精确性
图神经网络 Xia等[65] 提取多类型下的异构关系
多行为推荐问题 图神经网络 Yu等[66] 有效捕获信息
图卷积网络、图注意力网络 Ma等[60] 异构图，多样性和准确性
图神经网络 Yang等[67] 信息增强问题
图神经网络 Zhang等[68] 异构图
图注意力网络 Yuan等[69] 异构图
图神经网络 Liu等[70] 个性多样化
图神经网络 Chen等[71] 动态化，准确性
捆绑推荐问题
图注意力网络、图卷积网络 Yang等[45] 数据稀疏和冷启动问题，异构图
图卷积网络 Gong等[72] 结合深度学习从舞蹈动作中推荐音乐
图神经网络 Ling等[73] 信息的高阶连通性
图卷积网络、图自动编码器 Zhang等[74] 大数据，数据稀疏
图神经网络 Zhu等[75] 数据稀疏和冷启动问题
图神经网络 Zheng等[76] 异构图，潜在信息
图神经网络 Yu等[66] 有效捕获信息
会话推荐问题
图卷积网络、图注意力网络 Gu等[46] 动态兴趣建模问题
图神经网络 Huang等[77] 动态信息及信息增强
GNN本身模型分类和问题本身。本文由方法、问题 冷启动问题，跨领域推荐方法及辅助信息的嵌入等
两个角度对图神经网络推荐系统进行了研究、分析， 方法应运而生。而对于图神经网络方面，随着知识
对比了方法中每小类的优点和局限性，概括了问题中 表示学习和知识路径推理等[78]关键知识图技术的出
的难点。以下是一些存在研究难点的未来研究方向。 现，利用知识图谱辅助推荐将面临诸多挑战，也是一
4.1 数据稀疏性和冷启动 个重要的研究热点。文献[79]提出了协同知识增强
推荐系统应用中，用户行为数据稀少与用户或 的推荐方法，通过构建的交互图中项目之间的联系
者项目的数量不足导致推荐系统长期存在稀疏性和 和知识图中实体之间的连通性来学习用户和项目的 吴 静 等：图神经网络推荐系统综述 2259
表示。除了将知识图谱与推荐系统结合起来，现实 方法使得训练一个深度大的 GCNN 模型更具挑战
世界中还有许多其他外部结构信息可以帮助推荐， 性。由于处理复杂的计算和训练大规模数据集，再
例如社交网络中的社会关系信息等。Guo等[80]就提 加上模型边界的过度测量，这在很大程度上阻碍了
出了一种基于异构多关系图融合的信任推荐方法。 推荐系统框架的应用，还需要进行深入的研究。
它同时考虑用户的社会信任关系和项目相关知识， 4.4 大数据与数据噪音
这为解决数据稀疏性和冷启动问题提供了更多的可 在推荐系统中，随着时间累计，数据越来越多，
能。特别是图卷积网络，其与其他方法的结合使得 数据量过大将会带来更多的数据噪音。目前的主要
这一研究方向得到了进一步的发展。但是，单独运 挑战是从用户-物品交互以及辅助信息中学习有用的
用图生成网络和图时空网络在推荐系统上比较少， 信息。而处理复杂的计算和训练大规模数据集也是
最近这方面的研究渐渐多起来了，这将是未来尤其 一个挑战。现有的基于图神经网络的方法利用用户
注意的方向，而图生成网络推荐系统方面的独立节 与项目之间的高阶连通性来获得满意的性能，但是
点和其数据稀疏性导致模型易过拟合问题将是研究 这些方法的训练效率较低，容易引入信息传播的偏
的重难点。 差。此外，由于观测的交互信息极其稀疏，应用的贝
4.2 用户动态兴趣 叶斯个性化排序损失不足以为训练提供监督信号。
知识图谱不仅包含各种数据类型（例如，像用户 为了解决上述问题，Pan等[83]提出了有效图协同过滤
和项目这样的节点类型，以及像不同的行为类型这 方法。但不同的领域包含各种不同的图数据，节点
样的边类型），通常还有不同的和不确定的兴趣[81]。 和连边关系也各有不同，如何结合领域中有用的知
在多行为用户和个性化推荐上，许多文献对用户动 识对给定的图数据利用图卷积神经网络进行建模是
态兴趣问题提供了一些模型以及方法。Isufi等[82]发 图卷积神经网络应用的关键问题。如果数据全部运
展了一个从最近邻和最远邻图学习联合卷积表示的 用上，随之而来的是过平滑问题，而且推荐的准确度
模型，以建立一个新的准确性-多样性权衡推荐系 会降低。因此，如何在基于GNN的推荐中为每个用
统。但大多数都是基于用户数据的补充上，如何解 户或项目自适应地选择合适的接收信息的范围也是
决与用户意图相关的嵌入问题，如何自适应地为每 一个值得研究的问题。数据作为推荐系统最重要的
个用户设置不同的兴趣数，如何为多向量表示设计 部分，如何解决推荐的多样性和个性化的问题。这
一个有效的传播模式等，需要进一步研究。因此，如 也将是未来研究的主要问题。
何表现用户的多重和不确定的兴趣是一个值得探索 总而言之，在现有研究的基础上，GNN推荐系统
的方向。 的难点大致上与数据、动态问题有关。从数据量来
4.3 动态图与异构图 看，存在由于数据过少而导致的数据稀疏性和冷启
在现实世界的推荐系统中，不仅用户兴趣是动 动问题，也存在数据过多时的数据筛选和数据噪音
态的，而且用户和项目之间的关系也随着时间的推 问题。从动态性来看，存在着用户的动态兴趣嵌入
移而发生变化。为了确保推荐的精确度，系统需要 问题和动态、异构图的模型构建问题。这些难点也
时常更新信息。从图的角度来看，不断更新的信息 是未来研究的方向。
带来的是动态图而不是静态图。而动态图形则带来
了变化的结构。在实际应用中，如何针对动态图设 参考文献：
计相应的GNN框架是一个有趣的前瞻性研究课题。 [1]于蒙,何文涛,周绪川,等.推荐系统综述[J].计算机应用,
现有的推荐研究很少关注动态图，而且基于时空图 2022,42(6):1898-1913.
YU M, HE W T, ZHOU X C, et al. Review of recommen-
神经网络的研究也很少，动态图在推荐中是一个很
dation system[J]. Journal of Computer Applications, 2022,
大程度上未被探索的领域，值得进一步研究。在推
42(6):1898-1913.
荐系统处理复杂、属性丰富、基于上下文的交互信息
[2]陈江美,张文德.基于位置社交网络的兴趣点推荐系统研
的性能上，现有的基于GCN的方法大多集中于同构
究综述[J].计算机科学与探索,2022,16(7):1462-1478.
图环境下的任务求解，没有考虑异构图环境。传统
CHEN J M, ZHANG W D. Review of point of interest
的GCN方法需要一个完整的图邻接矩阵来进行嵌入
recommendation systems based on location-based social
学习，这种为图中的每个节点生成邻居节点的递归 networks[J]. Journal of Frontiers of Computer Science and 2260 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(10)
Technology,2022,16(7):1462-1478. 11(4):1366.
[3] LIU Z Y, ZHOU J. Introduction to graph neural networks [15]YINY,ZHENGW.Anefficientrecommendationalgorithm
[M].SanRafael:Morgan&ClaypoolPublishers,2020. basedonheterogeneousinformationnetwork[J].Complexity,
[4]HENAFFM,BRUNAJ,LECUNY.Deepconvolutionalnet- 2021(17):1-18.
worksongraph-structureddata[J].arXiv:1506.05163,2015. [16] CHEN J Y, YU J, LU W J, et al. IR-Rec: an interpretive
[5] BASTINGS J, TITOV I, AZIZ W, et al. Graph convolu- rules-guidedrecommendationoverknowledgegraph[J].In-
tionalencodersforsyntax-awareneuralmachinetranslation formationSciences,2021,563:326-341.
[C]//Proceedingsofthe2017ConferenceonEmpiricalMe- [17] BONET E R, NGUYEN D M, DELIGIANNIS N, et al.
thodsinNaturalLanguageProcessing,Copenhagen,Sep7- Temporal collaborative filtering with graph convolutional
11,2017.Stroudsburg:ACL,2017:1957-1967. neural networks[C]//Proceedings of the 25th International
[6] RHEE S, SEO S, KIM S. Hybridapproach of relation net- ConferenceonPatternRecognition,Milan,Jan10-15,2021.
work and localized graph convolutional filtering for breast Piscataway:IEEE,2021:4736-4742.
cancersubtypeclassification[J].arXiv:1711.05859,2017. [18] SONG W P, XIAO Z P, WANG Y F, et al. Session-based
[7] ZHANG Y H, QI P, MANNING C D. Graph convolution social recommendation via dynamic graph attention net-
over pruned dependency trees improves relation extraction works[C]//Proceedingsofthe12thACM InternationalCon-
[C]//Proceedingsofthe2018ConferenceonEmpiricalMe- ference on Web Search and Data Mining , Melbourne, Feb
thods in Natural Language Processing, Brussels, Oct 31- 11-15,2019.NewYork:ACM,2019:555-563.
Nov4,2018.Stroudsburg:ACL,2018:2205-2215. [19] JIANG Y B, MA H F, LIU Y H, et al. Enhancing social
[8]GAO C,ZHENGY,LIN,etal.Graph neuralnetworksfor recommendationviatwo-levelgraphattentionalnetworks
recommender systems: challenges, methods, and directions [J].Neurocomputing,2021,449:71-84.
[J].arXiv:2109.12843,2021. [20]WU QT,ZHANG H R,GAO X F,etal.Dualgraph atten-
[9]吴国栋,查志康,涂立静,等.图神经网络推荐研究进展[J]. tion networks for deep latentrepresentation of multifaceted
智能系统学报,2020,15(1):14-24. social effects in recommender systems[C]//Proceedings of
WU G D, ZHA Z K, TU L J, et al. Research advances in the Web Conference 2019: Proceedings of the World Wide
graphneuralnetworkrecommendation[J].JournalofIntelli- WebConference,SanFrancisco,May13-17,2019.NewYork:
gentSystems,2020,15(1):14-24. ACM,2019:2091-2102.
[10]徐冰冰,岑科廷,黄俊杰,等.图卷积神经网络综述[J].计 [21]XIAOY,PEIQQ,XIAOTT,etal.MutualRec:jointfriend
算机学报,2020,43(5):755-780. and item recommendations with mutualistic attentional
XU B B, CEN K T, HUANG J J, et al.Asurvey on graph graph neural networks[J]. Journal of Network and Com-
convolutional neural network[J]. Chinese Journal of Com- puterApplications,2021,177:102954.
puters,2020,43(5):755-780. [22] DANG D P, CHEN C X, LI H C, et al. Deep knowledge-
[11] YING R, HE R N, CHEN K F, et al. Graph convolutional aware framework for web service recommendation[J]. The
neuralnetworksforweb-scalerecommendersystems[C]// JournalofSupercomputing,2021,77:14280-14304.
Proceedings of the 24thACM SIGKDD International Con- [23] LIAC,YANG B. GSIRec: learning with graph side infor-
ferenceonKnowledgeDiscoveryandDataMining,London, mation for recommendation[J]. World Wide Web-Internet
Aug19-23,2018.NewYork:ACM,2018:974-983. andWebInformationSystems,2021,24(5):1411-1437.
[12] CHEN J X, LIN G Q, CHEN J X, et al. Towards efficient [24] SALAMAT A, LUO X, JAFARI A. HeteroGraphRec: a
allocation of graph convolutional networks on hybrid com- heterogeneousgraph-basedneuralnetworksforsocialrecom-
putation-in-memoryarchitecture[J].ScienceChinaInforma- mendations[J].Knowledge-BasedSystems,2021,217:106817.
tionSciences,2021,64(6):108-121. [25] SANG L, XU M, QIAN S S, et al. Knowledge graph en-
[13]TRANDH,SHENGQZ,ZHANGWE,etal.HeteGraph: hanced neuralcollaborative filtering with residualrecurrent
graphlearninginrecommendersystemsviagraphconvolu- network[J].Neurocomputing,2021,454:417-429.
tional networks[J]. Neural Computing and Applications, [26] BEHROUZI T, HATZINAKOS D. Graph variational auto-
2021.DOI:10.1007/s00521-020-05667-z. encoder for deriving EEG-based graph embedding[J]. Pat-
[14] SHAFQAT W, BYUN Y C. Incorporating similarity mea- ternRecognition,2022,121:108202.
sures to optimize graph convolutional neural networks for [27] ZHANG X B, YANG Y, ZHAI D H, et al. Local2Global:
product recommendation[J].Applied Sciences-Basel, 2021, unsupervisedmulti-viewdeepgraphrepresentationlear- 吴 静 等：图神经网络推荐系统综述 2261
ning with nearestneighborconstraint[J].Knowledge-Based dation: from relevance to reasoning[C]//Proceedings of the
Systems,2021,231:107439. 12thACM Conference on RecommenderSystems,Vancou-
[28] TRAN Q M, NGUYEN H D, HUYNH T, et al. Measuring ver,Oct2-7,2018.NewYork:ACM,2018:482.
the influence and amplification of users on social network [39]PARK S,JANG D K,LEE S H.Diversemotion stylization
withunsupervisedbehaviorslearningandefficientinteraction- formultiplestyledomainsviaspatial-temporalgraph-based
based knowledge graph[J]. Journal of CombinatorialOpti- generative model[J]. Proceedings of the ACM on Compu-
mization,2021.DOI:10.1007/s10878-021-00815-0. terGraphicsandInteractiveTechniques,2021,4(3):36.
[29]ZHENGQQ,LIUGF,LIUA,etal.Implicitrelation-aware [40] ZHANG Z, BU J J, LI Z, et al.Tige CMN: on exploration
social recommendation with variational auto-encoder[J]. of temporal interaction graph embedding via coupled me-
WorldWideWeb-Internet andWeb Information Systems, moryneuralnetworks[J].NeuralNetworks,2021,140:13-26.
2021,24(5):1395-1410. [41]杨珍,丁铭,唐杰,等.面向推荐系统的时空图卷积方法和
[30] YAO L Y, ZHONG J B, ZHANG X F, et al. Correlated 系统:CN113269603A[P].2021-08-17.
Wasserstein autoencoder for implicit data recommendation YANG Z, DING M, TANG J, et al. Temporal and spatial
[C]//Proceedings of the 2020 IEEE/WIC/ACM International graph convolution method and system for recommendation
JointConference onWeb Intelligence and IntelligentAgent system:CN113269603A[P].2021-08-17.
Technology,Melbourne,Dec14-17,2020.Piscataway:IEEE, [42]HANHY,ZHANGMD,HOUM,etal.STGCN:aspatial-
2020:417-422. temporal aware graph learning method for POI recommen-
[31]DENG K, HUANG J J, QIN J. Hybrid GNN-SR: combi- dation[C]//Proceedingsofthe20thIEEEInternationalCon-
ning unsupervised and supervised graph learning for ses- ferenceonDataMining,Sorrento,Nov17-20,2020.Pisca-
sion-based recommendation[C]//Proceedings of the 20th taway:IEEE,2020:1052-1057.
IEEEInternationalConferenceonDataMiningWorkshops, [43]WU S,SUN F,ZHANGW,etal.Graphneuralnetworksin
Sorrento,Nov17-20,2020.Piscataway:IEEE,2020:136-143. recommendersystems:asurvey[J].arXiv:2011.02260,2020.
[32] OHTOMO K, HARAKAWAR, QGAWAT, et al. Persona- [44] XIANG N H, ZHAO C R, EMINEY, et al. Graph techno-
lized recommendation of Tumblr posts using graph convo- logies for user modeling and recommendation: introduc-
lutional networks with preference-aware multimodal fea- tiontothespecialissue-part1[J].ACMTransactionsonIn-
tures[J]. Item Transactions on Media Technology andApp- formationSystems,2021,40(2):1-5.
lications,2021,9(1):54-61. [45]YANG M H, CAO S S, HU B B, et al. IntelliTag: an intel-
[33] BONGINI P, BIANCHINI M, SCARSELLI F. Molecular ligent cloud customer service system based on tag recom-
generative graph neural networks for drug discovery[J]. mendation[C]//Proceedings of the 2021 IEEE 37th Interna-
Neurocomputing,2021,450:242-252. tionalConferenceonDataEngineering,Chania,Apr19-22,
[34] ZHOU Y D, DING Z H, LIU X M, et al. Infer-AVAE: an 2021.Piscataway:IEEE,2021:2559-2570.
attribute inference model based on adversarial variational [46] GU P, HAN Y Q, GAO W, et al. Enhancing session-based
autoencoder[J].Neurocomputing,2022,483:105-115. social recommendation through item graph embedding and
[35]XU D,RUAN CW,MOTWANIK,etal.Generativegraph contextual friendship modeling[J]. Neurocomputing, 2021,
convolutional network for growing graphs[C]//Proceedings 419:190-202.
of the 2019 IEEE International Conference on Acoustics, [47]TAOY,WANG C,YAO LN, et al. Item trend learning for
Speech and SignalProcessing,Brighton,May 12-17,2019. sequential recommendation system using gated graph neu-
Piscataway:IEEE,2019:3167-3171. ral network[J]. Neural Computing & Applications, 2021.
[36]WU F, GAO M,YU J L, et al. Ready for emerging threats DOI:10.1007/S00521-021-05723-2.
torecommendersystems?Agraphconvolution-basedgene- [48] WANG X, HE X, CAO Y, et al. KGAT: knowledge graph
rative shilling attack[J]. Information Sciences, 2021, 578: attention network for recommendation[C]//Proceedings of
683-701. the25thACM SIGKDD InternationalConferenceonKnow-
[37]ZHANG S S, NI J C, HOU L J, et al. Global-affine and ledge Discovery and Data Mining,Anchorage,Aug 4-8,
local-specific generative adversarial network for semantic- 2019.NewYork:ACM,2019:950-958.
guided image generation[J]. Mathematical Foundations of [49] GUO Z W, WANG H.Adeep graph neural network-based
Computing,2021,4(3):145-165. mechanism for social recommendations[J]. IEEE Transac-
[38]XUXR,CHENLM,ZUSP,etal.Huluvideorecommen- tionsonIndustrialInformatics,2021,17(4):2776-2783. 2262 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(10)
[50] LIU W W, ZHANG Y, WANG J L, et al. Item relationship [62] HE X, DENG K,WANG X, et al. Light GCN: simplifying
graphneuralnetworksfore-commerce[J].IEEETransac- and powering graph convolution network for recommen-
tions on Neural Networks and Learning Systems, 2021. dation[C]//Proceedings of the 43rd International ACM
DOI:10.1109/TNNLS.2021.3060872. SIGIR Conference on Research and Development in Infor-
[51] SALAMAT A, LUO X, JAFARI A. Hetero Graph Rec: a mationRetrieval.NewYork:ACM,2020:639-648.
heterogeneousgraph-basedneuralnetworksforsocialre- [63]AMAR B. Revisiting SVD to generate powerful node em-
commendations[J].Knowledge-basedSystems,2021,217: beddings for recommendation systems[J]. arXiv:2110.03665,
106817. 2021.
[52] LIU Y, YANG S, XU Y, et al. Contextualized graph atten- [64] LIU H D, YANG B, LI D S. Graph collaborative filtering
tion network for recommendation with item knowledge based on dual-message propagation mechanism[J]. IEEE
graph[J]. IEEE Transactions on Knowledge and Data En- Transactions on Cybernetics, 2021. DOI: 10.1109/TCYB.2021.
gineering,2021.DOI:10.1109/TKDE.2021.3082948. 3100521.
[53] TU K, CUI P,WANG D, et al. Conditional graph attention [65]XIALH,HUANGC,XUY,etal.Multi-behaviorenhanced
networks for distilling and refining knowledge graphs in recommendation with cross-interaction collaborative rela-
recommendation[C]//Proceedingsofthe30thACM Interna- tionmodeling[C]//Proceedingsofthe2021IEEE37thInter-
tional Conference on Information & Knowledge Manage- national Conference on Data Engineering, Chania,Apr 19-
ment.NewYork:ACM,2021:1834-1843. 22,2021.Piscataway:IEEE,2021:1931-1936.
[54] WANG H Y, YAO K M, LUO J, et al. An implicit prefe- [66]YUB,ZHANGRQ,CHENW,etal.Graphneuralnetwork
rence-aware sequential recommendation method based on basedmodelformulti-behaviorsession-basedrecommen-
knowledge graph[J]. Wireless Communications & Mobile dation[J].Geoinformatica,2022,26(2):429-447.
Computing,2021:5206228. [67]YANGJ,MAW,ZHANGM,etal.LegalGNN:legalinfor-
[55] YANG X, HUAN Z Y, ZHAI Y S, et al. Research of per- mationenhancedgraphneuralnetworkforrecommendation
sonalized recommendation technology based on knowledge [J]. ACM Transactions on Information Systems, 2021, 40
graphs[J].AppliedSciences-Basel,2021,11(15):7104. (2):1-29.
[56] LOANNIDIS V N, ZAMZAM A S, GIANNAKIS G B, et [68] ZHANG C, WANG Y, ZHU L, et al. Multi-graph hetero-
al. Coupled graphs and tensor factorization for recommen- geneous interaction fusion for social recommendation[J].
der systems and community detection[J]. IEEE Transactions ACMTransactionsonInformationSystems,2021,40(2):1-26.
onKnowledgeandDataEngineering,2021,33(3):909-920. [69]YUANYJ,WEN D J,WEIZ,etal.Akg-enhanced multi-
[57] OUYANG Y, GUO B, TANG X, et al. Mobile App cross- graphneuralnetworkforattentiveherbrecommendation[J].
domainrecommendationwithmulti-graphneuralnetwork[J]. IEEE/ACM Transactions on Computational Biology and
ACM Transactions on Knowledge Discovery from Data, Bioinformatics,2021.DOI:10.1109/TCBB.2021.3115489.
2021,15(4):55. [70]LIUX,SUNYB,LIUZW,etal.Learningdiversefashion
[58] SHEU H S, CHU Z X, QI D Q, et al. Knowledge-guided collocation by neural graph filtering[J]. IEEE Transactions
articleembeddingrefinementforsession-basednewsre- onMultimedia,2021,23:2894-2901.
commendation[J]. IEEE Transactions on Neural Networks [71] CHEN J G, LI K L, LI K Q, et al. Dynamic planning of
and Learning Systems, 2021. DOI: 10.1109/TNNLS.2021. bicyclestationsindocklesspublicbicycle-sharingsystem
3084958. using gated graph neural network[J].ACM Transactions on
[59]LIANGTT,SHENGX,ZHOUL,etal.Mobileapprecom- IntelligentSystemsandTechnology,2021,12(2):25.
mendation via heterogeneous graph neural network in edge [72]GONGWJ,YUQS.Adeepmusicrecommendationmethod
computing[J].AppliedSoftComputing,2021,103:107162. based on human motion analysis[J]. IEEEAccess, 2021, 9:
[60] MAMY,NAS,WANG HY,et al.The graph-based beha- 26290-26300.
vior-aware recommendation for interactive news[J]. arXiv: [73] LING CY, ZONYZ, XIE B. Graph neural network based
1812.00002V2,2018. collaborative filtering for API usage recommendation[C]//
[61] WANG X, HE X, WANG M, et al. Neural graph colla- Proceedings of the 2021 IEEE International Conference on
borative filtering[C]//Proceedings of the 42nd International Software Analysis, Evolution and Reengineering, Honolulu,
ACM SIGIR Conference,Paris,Jul21-25,2019.NewYork: Mar9-12,2021.Piscataway:IEEE,2021:36-47.
ACM,2019:165-174. [74] ZHANGYQ,YANG HY, KUANG L.AwebAPI recom- 吴 静 等：图神经网络推荐系统综述 2263
mendation method with composition relationship based on quentialrecommendations with intent-aware diversification
GCN[C]//Proceedings of the 2020 IEEE International Con- [C]//Proceedings of the 29thACM International Conference
ference on Parallel & Distributed Processing with Appli- onInformation&KnowledgeManagement.NewYork:ACM,
cations, Big Data & Cloud Computing, Sustainable Com- 2020:175-184.
puting & Communications, Social Computing & Networking, [82] ISUFIE,POCCHIARIM,HANJALICA.Accuracy-diversity
Exeter,Dec17-19,2020.Piscataway:IEEE,2020:601-608. trade-off in recommender systems via graph convolutions
[75]ZHUYF,LUH,QIUP,etal.Heterogeneousteachingeva- [J]. Information Processing & Management, 2021, 58(2):
luation network based offline course recommendation with 102459.
graph learning and tensor factorization[J]. Neurocomputing, [83] PAN Z Q, CHEN H H. Efficient graph collaborative filte-
2021,415:84-95. ringviacontrastivelearning[J].Sensors,2021,21(14):4666.
[76] ZHENGYJ, LIU SY, LI Z K, et al. DGTN: dual-channel
graphtransitionnetworkforsession-basedrecommendation
吴静（1997—），女，江西九江人，硕士研究生，
[C]//Proceedings of the 20th IEEE International Conferen-
CCF学生会员，主要研究方向为推荐系统、图
ceon Data Mining, Sorrento, Nov 17-20, 2020. Piscata-
神经网络。
way:IEEE,2020:236-242.
WUJing,bornin1997,M.S.candidate,student
[77] HUANG C, CHEN J, XIAL, et al. Graph-enhanced multi-
memberofCCF.Herresearchinterestsincludere-
tasklearningofmulti-leveltransitiondynamicsforsession-
commendationsystemandgraphneuralnetworks.
based recommendation[C]//Proceedings of the 2021 AAAI
Conference on Artificial Intelligence. Menlo Park: AAAI,
谢辉（1978—），男，河南信阳人，博士，副教授，
2021:4123-4130.
CCF会员，主要研究方向为数据挖掘、智能推荐。
[78]WUZT,SONGCY,CHENYQ,etal.Areviewofrecom-
XIEHui,bornin1978,Ph.D.,associateprofes-
mendation system research based on bipartite graph[C]//
sor, member of CCF. His research interests in-
Proceedings of the 2020 2nd International Conference on
clude data mining and intelligent recommen-
Computer Science Communication and Network Security,
dation.
Sanya,Dec22-23,2020:336.
[79] PAN Z Q, CHEN H H. Collaborative knowledge-enhanced
recommendationwithself-supervisions[J].Mathematics,2021, 姜火文（1974—），男，江西进贤人，博士，教授，
9(17):2129. CCF会员，主要研究方向为隐私保护、计算机
[80]GUOJ,ZHOUY,ZHANGP,etal.Trust-awarerecommen- 教育。
dation based on heterogeneous multi-relational graphs fu- JIANG Huowen, born in 1974, Ph.D., profes-
sion[J].InformationFusion,2021,74:87-95. sor,memberofCCF.Hisresearchinterestsinclu-
[81] CHEN W, REN P, CAI F, et al. Improving end-to-end se- deprivacypreservationandcomputereducation. --------------------------------------------------------------------------------- 第46卷 第5期 山 东 大 学 学 报 (工 学 版) 2016年10月
Vol．46 No．5 JOUＲNAL OF SHANDONG UNIVEＲSITY (ENGINEEＲING SCIENCE) Oct． 2016
文章编号:1672-3961(2016)05-0007-06 DOI:10.6040/j．issn．1672-3961.1.2016.257
基于 HITS 算法的微博用户可信度评估
吴树芳1，2，徐建民3*
(1． 天津大学管理与经济学部，天津300072; 2．河北大学管理学院，河北 保定071000;
3． 河北大学计算机科学与技术学院，河北 保定071000)
摘要:以新浪微博为研究平台，在HITS(hyperlink-induced topic search)算法的基础上，提出融合用户交互行为和博
文内容的微博用户可信度评估算法。分别构建基于交互行为和基于博文内容的微博用户有向链接图，图中节点
表示用户，有向边体现用户基于交互行为或基于内容的指向关系;依据HITS 算法计算两种拓扑结构下微博用户
的权威度和中心度;以融合的权威度作为度量评估用户可信度。试验采用从新浪微博采集的数据作为测试集合，
通过反复训练法获得可信度阈值，绘制不同可信度算法的用户可信度曲线，验证了算法的可行性和有效性。
关键词:HITS算法;微博用户;可信度;交互行为; 博文
中图分类号:TP391 文献标志码:A
Evaluation of microblog users' credibility based on HITS algorithm
WU Shufang1，2，XU Jianmin3*
(1． College of Management and Economics，Tianjin University，Tianjin300072，China;
2． College of Management，Hebei University，Baoding 071000，Hebei，China;
3．School of Computer Science and Technology，Hebei University，Baoding 071000，Hebei，China)
Abstract: Based on Sina-Microblog and HITS (hyperlink-induced topic search) algorithm，a new user's credibility al-
gorithm that merged user interactions and blog contents was putted forward． The new algorithm firstly constructed two
directed connection graphs based on user interactions and blog contents respectively，where nodes represented users and
arcsembodied the direction relationship between users． Authority and hub of these two connected graphs was computed．
Thefusionauthority wasadoptedasmeasurementto evaluateuser'scredibility． Thedatacollectedfrom Sina-Microblog as
test set was used to conduct experiments． Threshold of credibility was obtained by repeated training，and then credibility
curves of different algorithms were drawn to verify the feasibility and effectiveness of the new algorithm．
Key words: HITS algorithm; microblog users; credibility; interaction; blog
09－30，微博月活跃用户数为2．12 亿人，有超过62%
0 引言 的微博用户处于非活跃状态，如何辨别其中的虚假用
户，是搭建一个诚信、公平、健康的社交平台亟需解决
随着互联网的发展，出现了各种社交网络平台， 的问题之一［1-2］。尽管新浪微博社区管理中心发布了
如英文的Twitter、Facebook，中文的新浪微博和腾讯 一系列微博用户信誉约束规则，但这些规则仍然存在
微博等。这些社交平台已经渗透到人们生活的各个 一些缺陷，导致微博用户可信度排名不合理［3］。解决
方面，成为人们获取信息的主要渠道之一。据统计， 微博用户的可信度问题不仅可以帮助人们找到
2015年6月我国微博用户已达6．68 亿，截止2015 － 真实可靠的微博信息，也有利于发现领域专家，某个
收稿日期:2016-03-31; 网络出版时间:2016-09-1822∶48∶39
网络出版地址:http: //www．cnki．net/kcms/detail/37．1391．T．20160918．2248．002．html
基金项目:河北省社会科学基金资助项目( HB15TQ013)
作者简介:吴树芳(1979—)，女，河北邯郸人，副教授，博士，主要研究方向为信息检索与不确定信息处理．E-mail: shufang_44@126．com
* 通讯作者:徐建民(1966—)，男，河北邯郸人，教授，博士，主要研究方向为信息检索与不确定信息处理．E-mail: hbuxjm@hbu．edu．cn 8 山 东 大 学 学 报 (工 学 版) 第46卷
领域的专家一般是微博用户中的高可信度用户［4-5］。 页，例如与“搜索引擎”主题相关的网页中，谷歌和
现有的微博用户可信度多依据微博注册用户信息的 百度属于权威度高的网页。一个网页的中心度高，
完整性和社会地位来评估［6］，事实上，注册信息完整 说明该网页包含了很多指向高权威度网页的链接，
或社会地位高的微博用户其可信度不一定高，故仅以 例如中文语言资源联盟( Chinese Linguistic Data
此来判断用户的可信度存在不足。 Consortium，CLDC) 页面中包含一些具有权威性的
目前对微博用户可信度的研究尚处于起步阶 开源软件和中文语料库，并通过链接的方式指向了
段，研究内容较少。CASTILLO C 等人提出了话题 这些资源，则这个页面可以认为是“自然语言处理”
可信度评估方法，首先提取和话题相关的 Tweets 用 主题下的一个高中心度网页。HITS 算法中隐含有
户信息、Tweets 传播的特征和 Tweets 内容的特征， 以下两个假设: ( 1) 一个高权威度网页会被很多高
然后采用决策树估计话题的可信度，该项研究针对 中心度的网页指向; ( 2) 一个高中心度的网页会指
的是内容可信度，并没对微博用户的可信度进行深 向很多高权威度的网页。
入研究［7］。闫光辉等人在 PageＲank 算法的基础 依据上述假设，可知中心度和权威度两个指标
上，参考网络群体结构平衡理论，结合微博用户本身 是相互增强的关系［16］，一个页面的重要性通过权威
的属性因素，提出了基于链接的微博用户可信度评 度和中心度两个值进行度量。假设A( i) 表示网页 i
估模型，该模型忽略了微博用户所发博文对其可信 的权威值，H( i) 代表网页i的中心度，图1 所示的网
度的影响［8］。GUPTA M 等人提出一个用户可信度 页集合中，有1 个网页有链接指向页面1，同时页面
评估算法，该算法依据用户所发博文的可信度均值 1 通过3 个链接指向其它3 个页面，则页面1 的权
获得用户的可信度，忽略了微博用户本身属性及用 威度依据指向其节点的网页的中心度计算，即:
户行为对其可信度的影响［9］。MUKHEＲJEE A 等 A(1) =H(1) +H(2) +H(3) ，页面1 的中心度通过
人提出GS-Ｒank算法用于检查欺骗群，即一群用户 它指向的节点的权威度计算，即 H( 1) = A( 1) +
互相协作，进行系列虚假评论［10］。CHU Z 等人将 A(2) +A( 3) 。综上可知，节点中心度和权威度的
信息熵与机器学习方法结合，提出了微博虚假用户 计算公式为:
识别算法，取得了一定成效［11］。徐建民等人通过对 n
A( i) = ∑H( j) ， (1)
微博用户行为进行分析，运用逻辑回归算法，提出了
j=1
一个基于逻辑回归的用户可信度评估模型［12］。 m
H( i) = ∑A( k) ， (2)
上述研究内容在对微博用户可信度进行评估 k=1
式中，H( j) 为指向节点 i 的节点的中心度; A( k) 为
时，或者基于微博用户本身属性、行为，或者基于用
节点i指向的节点的权威度。式( 1) 、( 2) 可看出:
户所发博文内容。事实上，二者对微博用户可信度
中心度和权威度是相互增强、不断迭代的关系。
的评估贡献度不分上下，如果能将二者有效融合，则
将对微博用户可信度的评估更为合理。本文在
HITS 算法［13］的基础上分别获得基于用户交互行
为［14］和基于内容的微博用户权威度和中心度，并通
过线性调和的方法将二者融合，获得每个微博用户
的最终权威度/中心度对，实现对微博用户的可信度
评估。试验采用从新浪微博获取的用户信息验证文
章提出的评估方法的可行性和有效性。
图1 网页中心度、权威度
1 HITS 算法 Fig．1 Hub and authority of web pages
在微博中，一个虚假的微博用户常常通过人为
HITS 算法是文献［15］提出的一个网页重要性 增加自己的关注量来提高影响力［17］。结合HITS 算
评判算法，是链接分析中非常基础且重要的算法，目 法，从微博用户关注行为的角度看，人为增加关注量
前已广泛应用于自然语言处理相关领域。该算法采 仅可能增加虚假用户的权威度，无法增加其中心度，
用中心度( Hub) 和权威度( Authority) 这两个重要的 故依据中心度和权威度两个指标来评估微博用户的
指标来计算检索到的网页的重要性。一个网页的权 可信度具有可行性。此外，对微博用户可信度的评
威度高，说明该网页是与某个主题相关的高质量网 估，除依据微博用户本身的特性外，还可依据微博用 第5期 吴树芳，等:基于HITS算法的微博用户可信度评估 9
户所发博文。虚假微博用户所发博文内容一般是机 互比较微弱，可忽略。
械式的，固定格式且没有实质内容，故其他微博用户 Idegree( User( i) →User( j) ) =
对该博文几乎没有交互行为( 关注、转发、评论、 α ω +α ( ω +ω +ω ) ， (3)
1 Follow 2 Ｒetweet Comment Praise
赞) 。反之，如果微博用户 User( i) 所发博文 式中，ω 、ω 、ω 、ω 分别为 User( i) 对
Follow Ｒetweet Comment Praise
Blog( i) 被多个高中心度的博文引用，或者该博文引 User( j) 关注、转发、评论、赞的权重。为了将交互度
用过一些高权威度的博文，则博文 Blog( i) 的中心 Idegree的值限定在0 ～1，假定α +α =1，参数α ，
1 2 1
度和权威度就高，相应地User( i) 的可信度就高。 α 用于调节关注和其余3 种( 评论、转发、赞) 交互
2
本研究在 HITS 算法的基础上，从微博用户的 行为对Idegree( User( i) →User( j) ) 的贡献度。在
交互行为和其所发博文两个角度出发，对微博用户 微博中，用户评论、转发、赞的微博一般来自于其关
的可信度进行评估，提出一个新的微博用户可信度 注的微博用户，经验上，关注和其余3 种行为影响的
评估算法HITS-UC。 和对最终交互度的影响相当，故假定α =α =0．5，
1 2
在未来的研究中将对不同交互行为对交互度的影响
2 微博用户可信度评估 程度做进一步的深入研究。关注行为的权重ω
Follow
只有2 个取值，要么关注，要么不关注，故:
{
2．1 基于交互行为的用户权威度/中心度 1， 如果User( i) 关注User( j) ;
ω = (4)
在微博网络中，若不涉及博文内容，微博用户的 Follow 0， 否则。
交互行为主要包括关注、收藏、转发、评论、赞，由于 观察、分析新浪微博可以发现，其余3 种交互行
收藏数无法获得，所以本研究在计算交互度时不考 为的难易程度为赞＜转发 ＜评论，从而导致微博中
虑收藏行为。HITS 算法的核心原理是依据网页的 赞的个数大于其余2 种，转发数大于评论数。理论
链入和链出单向边体现网页间的引用关系，并以此 上，三者对交互度的贡献程度为评论最大，转发次
计算每个网页的中心度和权威度，得出网页重要性 之，赞最小。如果直接依据交互行为的交互次数计
排序。在微博网络中，如果任意2 个微博用户间有 算各自的权重，则赞的权重会远远大于其余两种，这
某种交互行为，则认为二者存在单向的指向关系，如 显然与实际不符。此外，为了保证ω 、ω 、
Ｒetweet Comment
图2 所示。从图2 中可以看出，存在自 User( a) 指 ω 的和不超过1，故将分母固定为2N，最终给出
Praise
向User( f) 的边，则二者之间存在交互行为。依据 下述的交互行为权重计算方法:
HITS 算法，则可计算出图中所示环境下 User( a) 的 N－Num
ω = retweet， (5)
权威度A 和中心度H 。 Ｒetweet 2N
User(a) User(a)
N－Num
ω = comment， (6)
Comment 2N
N－Num
ω = praise， (7)
Praise 2N
式中，N=Num + Num + Num ，其中
Ｒetweet Comment Praise
Num 为对应交互行为的交互次数。
i
综上，依据微博用户间的有向交互度，可以得到
微博用户基于交互行为的有向交互图( 如图 2 所
示) ，并依据式( 1) 、( 2) 可计算出微博用户 User( i)
图2基于交互行为的微博用户链接图
Fig．2 Micro-blog users link graph based on interactions 基于交互行为的权威度A ( User( i) ) 和中心度
I
上述思想存在以下缺点: 若任何2 个微博用户 H ( User( i) ) 。
I
User( i) 和User( j) 之间有任何一种交互行为，就绘 2．2 基于博文内容的用户权威度/中心度
制一条有向边，导致最终绘制的拓扑图中有很多无 微博属于非结构化的短文本，长度不可以超过
效边，从而使得用户权威度和中心度不合理，故论文 140 字。微博中除了有文本、图片、视频外，还有 2
做出如下限制:首先计算 User( i) 对 User( j) 的交互 个很特殊的符号“#”和“@”。“#”表示微博所属的
度Idegree( User( i) →User( j) ) ，其计算方法如公式 话题，“@”是在博文内容中体现的用户交互关系。
(3) 所示，如果其值大于指定的阈值 ε，则绘制二者 如在新浪微博中，用户“微相册”( U ) 发表了一篇博
1
之间的有向边，否则，认为 User( i) 对 User( j) 的交 文，博文中“#helo 一月#”表示该博文属于话题“hel- 10 山 东 大 学 学 报 (工 学 版) 第46卷
lo 一月”“@ 微博相机”( U ) 、“@ 微笑的阿榕” 过向S中加入被S中节点指向的微博用户和指向 S
3
( U ) ，表明该微博用户和用户“微博相机”和“微笑 中节点的微博用户来拓展集合 S，将 S 拓展成一个
4
的阿榕”有交互关系。本节将基于博文内容中这2 更大的集合T ，节点间以有向边相连，形成边集E ;
1 1
个典型特征，绘制微博用户间的有向链接关系图，进 (3) 初始化 T 中节点的权威度、中心度为:
1
而计算基于内容的用户权威度和中心度。详细规则 A ( User( i) ) =H ( User( i) ) =1(1≤i≤n) ;
I I
为:如果用户 User( i) 和 User( j) 在博文的“#”里提 (4) 重复执行下面的操作，直至集合 T 中的所
1
到了相同的标题，则同时存在 User( i) →User( j) 和 有微博用户User( i) (1≤i≤n) 的权威度值、中心度
User( j) →User( i) 的有向边，如果User( i) 在博文里 值趋于稳定:
“@”了 User( j) ，则仅存在有向边 User( i) → A I( User( i) ) =∑H I( User( k) ) 规范化为
User( j) 。依据该规则，针对新浪微博中用户“微相
A ( User( i) ) =A ( User( i) ) /(
∑A I( s)
) ;
I I 2
册”( U ) 和“Limm”( U ) 发表的2 篇博文，可以绘
1 2
制出图3 基于博文内容的用户链接关系图。在图3 H I( User( i) ) = ∑A I ( User( v) ) 规范化为
H( s)
所示拓扑结构的基础上，依据式(1) 、(2) 可以得到 H ( User( i) ) =H ( User( i) ) /( ∑ ) ;
I I 2
微博用户 User( i) 的基于博文内容的权威度
(5) 依据用户所发博文内容，通过向 S 中加入
A ( User( i) ) 和中心度H ( User( i) ) 。
C C 被S中节点指向的微博用户和指向S中节点的微博
用户来拓展集合S，将S拓展成一个更大的集合 T ，
2
节点间以有向边相连，形成边集E ;
2
(6) 针对T ，重复步骤( 3) ( 4) ，得到微博用户
2
基于博文内容的权威度A ( User( i) ) ，中心度
C
H ( User( i) ) 。
C
图3 基于内容的用户链接图 (7) 将步骤(4) (6) 得到的结果线性调和，得到用
Fig．3 Users link graph based on blog
户最终的权威度A( User( i) ) ，中心度H( User( i) ) 。
2．3 微博用户可信度评估算法HITS-UC
(8) 依据权威度评估微博用户的可信度，对其
在上文中，依据用户交互关系和博文内容绘制
进行降序排序;
了两类有向链接关系图，最终计算可信度时将二者
(9) 如果微博用户的权威度小于阈值 δ，则将其
融合，即对于任意2 个微博用户User( i) 和User( j) ，
视为虚假用户。
如果二者存在满足阈值的交互关系和内容关系中的
一种，则二者之间存在有向边。融合微博用户交互
3 试验
行为和博文内容的用户权威度、中心度
A ( User( i) ) +A ( User( i) )
A( User( i) ) = I C ，(8) 3．1 测试集合
2
由于目前没有统一的、权威的微博数据集供使
H ( User( i) ) +H ( User( i) )
H( User( i) ) = I C ，(9) 用，因此本文通过新浪微博提供的 API 接口和爬虫
2
工具，随机爬取了16487 名用户、165859 条微博，以
依据式(8) ( 9) 计算出待评微博用户的中心度和权
及他们之间关注、评论、转发、赞的数据，经人工辨别
威度后，按照权威度降序对微博用户进行排序，若权
后发现其中有9 652 个真实用户和6 835 个虚假用
威度小于阈值 δ，则认为该微博用户的可信度比较
户，最终将这些数据作为试验测试集合。
低，属于虚假用户。基于 HITS 的用户可信度评估
3．2 评测标准
算法( HITS-UC) 实现过程为:
评估一个微博用户是否为可信用户，实际是二
输入:热门榜单中的微博用户;
分类问题，其性能可采用查全率P 、查准率P
recal precision
输出:拓展后的可信微博用户;
和F 来衡量，计算公式为:
measure
实现过程:
a
(1) 运用随机函数random( ) ，从微博热门榜单 P recall = a+b， (10)
中随机选出几个权威度较大的微博用户节点作为根 a
P = ， (11)
集合S; precision a+c
(2) 依据用户间的交互行为和交互度阈值 ε，通 式中，a表示命中的正样本数; b 表示遗漏的正样本 第5期 吴树芳，等:基于HITS算法的微博用户可信度评估 11
数;c 表示计算出为正样本实际上是负样本的数量。 观察图4 可以发现，融合交互行为和博文内容的
查全率P 和查准率P 有时候会出现矛盾，这 HITS-UC 算法性能较优，产生该结果的原因是因为
recall precision
样就需要将二者归一化，最常见的方法就是将P 该算法有效考虑了虚假用户的两个典型特征: 缺少
recall
和P 加权调和平均，得到F ( 又称为F ) 用户间的交互行为和缺少博文内容中的交互。
precision measure score
评测指标，F 值越高性能越好，计算方法如下:
measure
(1 +β2) P P
F = recall precision， (12)
measure β2( P +P )
recall precision
当参数β=1 时，就是最常见的F ，即
1
2 P P
F = recall precision。 (13)
1 P +P 图4 不同查全率下的查准率曲线
recall precision
Fig．4 Precision curves under different recall
3．3 试验结果
第二项试验首先采用较为经典的算法 Basic-
对于交互度阈值 ε，观察式( 3) 与( 4) 可以发
CA 算法［9］、User-Ｒank［18］算法和本研究提出的算法
现，只要微博用户 User( i) 关注了 User( j) ，则 Ide-
HITS-UC 计算上述100 个微博用户的可信度值，然
gree( User( i) →User( j) ) 0．5，故将 ε 设置为0．5。
后绘制三者对应的可信度曲线，其结果如图5 所示。
对于微博用户可信度阈值 δ，采用反复训练的方法
图中横轴为用户编号( 共 100 个用户，编号为 1 ～
获得其较优值。将试验数据中的9652 个真实用户
100) ，纵轴为用户对应的可信度。观察图5 可以发
和6835 个虚假用户无规律混合，然后运用本文章
现，虽然同一个微博用户采用3 种算法计算的信任
提出的算法计算δ=0．1、0．2、0．3、…、0．9、1．0 时的
度不同，但是3 种算法下，100 个微博用户的信任度
性能指标，结果如表1 所示。观察表1 可以发现，当
曲线走势基本相同( 即信任度排序基本相同) ，从而
δ=0．6 时，F 最高，故将0．6 作为算法中的可信度
1 验证了基于HITS 的微博用户可信度评估算法的可
阈值δ的较优取值，如果想得到更为合理的 δ 值，可
行性。从图5 看出，HITS-UC 算法计算出的用户信
以进一步细化训练0．55 ～0．65 范围内的 F 值。当
1 任度大致上介于 Basic-CA 算法和 User-Ｒank 算法
δ=0．6 时，依据 HITS-UC 算法，正确判定了测试集
之间，产生这种结果的原因是因为 Basic-CA 算法主
合中14962 名微博用户，准确率为0．9075，后续实
要是基于博文内容计算用户的可信度，User-Ｒank
验中将采用0．6 作为微博用户的可信度阈值。
算法主要是基于用户本身计算用户的可信度，而
表1 不同阈值δ下的F 值比较
1 HITS-UC 算法采用了等比例调和的方法同时考虑
Table1 The comparison of F value based on
1
different threshold δ 了用户和博文内容，故理论上其计算出的可信度值
δ Ｒecall Precision F 也应基于二者之间。
1
0．1 1．0000 0．5854 0．7385
0．2 0．9357 0．5982 0．7298
0．3 0．9053 0．6894 0．7827
0．4 0．7832 0．8556 0．8178
0．5 0．7961 0．8639 0．8286
0．6 0．7945 0．9075 0．8472
0．7 0．7561 0．9135 0．8273
图5 不同算法下100个用户的信任度曲线
0．8 0．7021 0．9174 0．7954
Fig．5 Credibility curves of 100 users based on
0．9 0．6531 0．9581 0．7767
different algorithms
1．0 0．5181 0．9624 0．6736
为了验证本研究提出的微博用户可信度评估算 4 结语
法的可行性，从测试集合中随机抽取100 名微博用
户，做了2 项实验。第一项试验用于比较本研究提 本研究参考了 HITS 算法的基本原理，并将其
出的单独依据基于交互行为( HITS-U) 、基于博文内 应用到微博用户可信度评估，提出了融合微博用户
容( HITS-C) 和二者融合的 HITS-UC 算法的性能， 交互行为和博文内容的用户可信度评估算法 HITS-
图4 为该项试验的结果，即三者在不同查全率下的 UC。试验采用从新浪微博采集的数据作为测试集，
查准率曲线，曲线距离坐标原点越远，其性能越优。 首先获得了交互度阈值ε和信任度阈值δ的较优取 12 山 东 大 学 学 报 (工 学 版) 第46卷
值，然后通过和 Basic-CA 算法、Page-Ｒank 算法比 SIAM Press，2012:153-164．
较，验证了本文提出算法的可行性。在未来的研究 ［10］MUKHEＲJEE A，LIU B，GLANCE N． Spotting fake
reviewer groups in consumer reviewer［C］//Proceedings
中，将进一步改进现有工作，使得现有算法更加完
of the 21st International Conference on World Wide
善、合理。
Web． New York，USA: ACM Press，2012:191-200．
参考文献: ［11］CHU Z，GIANVECCHIO S，WANG H，et al． Detec-
ting automation of twitter accounts: are you a human，
［1］SONG J，LEE S，KIM J． Spam filtering inTwitterusing
bot，orcyborg? ［J］． IEEETransactionsonDependable
sender-receiver relationship ［M］． Berlin， German:
and Secure Computing，2012，9(6):811-824．
Springer，2006:301-317．
［12］徐建民，粟武林，吴树芳，等． 基于逻辑回归的微博用
［2］王越，张剑金，刘芳芳． 一种多特征微博僵尸粉检测方
户可信度建模［J］．计算机工程与设计，2015，36(3):
法与实现［J］． 中国科技论文，2014，9(1):81-86．
772-777．
WANG Yue，ZHANG Jianjin，LIU Fangfang． Detection
XU Jianmin，SU Wulin，WU Shufang，et al． Modeling
of micro-blog zombie fans based on multi-features［J］．
user reliability based on logistic regression in Micro-blog
China Science Paper，2014，9(1):81-86．
［J］． ComputerEngineerinlg andDesign，2015，36(3):
［3］刘晓飞． 基于链接分析的微博用户可信度研究［D］． 兰
772-777．
州:兰州交通大学，2015．
［13］苗家，马军，陈竹敏． 一种基于HITS 算法的Blog 文
LIU Xiaofei． Ｒesearch on credibility of microblog users
摘方法［J］．中文信息学报，2011，25(1):104-109．
based on link analysis［D］． Lanzhou: Lanzhou Jiaotong
MIAO Jia，MA Jun，CHEN Zhumin． A new HITS-
University，2015．
based summarization approach for Blog［J］． Journal of
［4］蒋盛益，陈东沂，庞观松，等． 微博信息可信度分析研
Chinese InformationProcessing，2011，25(1):104-109．
究综述［J］． 图书情报工作，2013，57(12):136-142．
［14］周小平，梁循，张海燕． 基于Ｒ-C模型的微博用户社区
JIANG Shengyi，CHEN Dongyi，PANG Guansong，et
发现［J］． 软件学报，2014，25(12):2808-2823．
al． A review of micro-blog informationreliability analysis
ZHOU Xiaoping，LIANG Xun，ZHANG Haiyan． User
［J］． Library and Information Service，2013，57( 12):
community detection Micro-blog using Ｒ-C model［J］．
136-142．
Journal of Software，2014，25(12):2808-2823．
［5］毛佳昕，刘奕群，张敏，等． 基于用户交互行为的微博
［15］KLEINBEＲG J M． Authoritative sources in a hyper-
用户社会影响力分析［J］． 计算机学报，2014，37(4):
linked environment［C］//Proceedings of the9th Annual
791-880．
ACM-SIAM Symposium on Discrete Algorithms． New
MAO Jiaxin，LIU Yiqun，ZHANG Min，etal． Socialin-
York，USA: ACM Press，1998:668-677．
fluence analysis for micro-blog user based on user behav-
［16］田中生． 基于影响力的社会网络关键用户识别方法研
ior［J］． Chinese Journal of Computers，2014，37( 4):
究［D］． 长春:吉林大学，2015．
791-880．
TIAN Zhongsheng． Ｒesearch on key user identification
［6］ Wikipedia Inc． Credibility［EB/OL］． ( 2013-01-20)
method based on influence in social networks［D］．
［2015-01-20］．http: //en．wikipedia．org/wiki/Credibili-
Changchun:Jinlin University，2014．
ty．
［17］李赫元，俞晓明，刘悦，等． 中文微博客的垃圾用户检
［7］CASTILLO C，MENDOZA M，POBLTETEB． Informa-
测［J］． 中文信息学报，2014，28(3):62-67．
tioncredibility onTwitter［C］//Proceedingsof Informa-
LIHeyuan，YU Xiaoming，LIU Yue，etal． Ｒesearchon
tion International Conference on World Wide Web． New
detecting spammer in Micro-blogs［J］． Journal of Chi-
York，USA: ACM Press，2011:675-684．
nese Information Processing，2014，28(3):62-67．
［8］闫光辉，刘晓飞，王梦阳． 基于链接的微博用户可信度
［18］王峰，余伟，李石君． 新浪微博平台上的用户可信度
研究［J］．计算机应用研究，2015，32(10):2910-2917．
评估［J］． 计算机科学与探索，2013，7( 12): 1125-
YAN Guanghui，LIU Xiaofei，WANG Mengyang． Ｒe-
1134．
searchoncredibility of microblog usersbasedonlink［J］．
WANG Feng，YU Wei，LI Shijun． Evaluation of user
ApplicationＲesearchof Computers，2015，32(10):2910-
credibility based on Sina weibo platform［J］． Journal of
2917．
Frontiers of Computer Science and Technology，2013，
［9］GUPTA M，ZHAO P，ZHAO J． Evaluation event credi-
7(12):1125-1134．
bility on Twitter［C］//Proceedings of the2012 SIAM In-
( 编辑:胡春霞)
ternationalConferenceonDataMining． California，USA: --------------------------------------------------------------------------------- 软件学报ISSN 1000-9825, CODEN RUXUEW E-mail: jos@iscas.ac.cn
Journal of Software,2021,32(2):519−550 [doi: 10.13328/j.cnki.jos.006104] http://www.jos.org.cn
©中国科学院软件研究所版权所有. Tel: +86-10-62562563
∗
基于 U-Net 结构改进的医学影像分割技术综述
殷晓航, 王永才, 李德英
(中国人民大学 信息学院,北京 100872)
通讯作者: 王永才, E-mail: ycw@ruc.edu.cn
摘 要: 深度学习在医学影像分割领域得到广泛应用,其中,2015年提出的U-Net因其分割小目标效果较好、结构
具有可扩展性,自提出以来受到广泛关注.近年来,随着医学图像割性能要求的提升,众多学者针对U-Net结构也在不
断地改进和扩展,比如编解码器的改进、外接特征金字塔等.通过对基于U-Net结构改进的医学影像分割技术,从面
向性能优化和面向结构改进两个方面进行总结,对相关方法进行了综述、分类和总结,并介绍图像分割中常用的损
失函数、评价参数和模块,进而总结了针对不同目标改进U-Net结构的思路和方法,为相关研究提供了参考.
关键词: U-Net;医学影像分割;结构改进;深度神经网络;技术综述
中图法分类号: TP391
中文引用格式: 殷晓航,王永才,李德英.基于 U-Net 结构改进的医学影像分割技术综述.软件学报,2021,32(2):519−550.
http://www.jos.org.cn/1000-9825/6104.htm
英文引用格式: Yin XH, Wang YC, Li DY. Suvery of medical image segmentation technology based on U-Net structure
improvement. Ruan Jian Xue Bao/Journal of Software, 2021,32(2):519−550 (in Chinese). http://www.jos.org.cn/1000-9825/6104.
htm
Suvery of Medical Image Segmentation Technology Based on U-Net Structure Improvement
YIN Xiao-Hang, WANG Yong-Cai, LI De-Ying
(School of Information, Renmin University of China, Beijing 100872, China)
Abstract: The application of deep learning in the field of medical image segmentation has attracted great attentions, among which the
U-Net proposed in 2015 has been widely concerned because of its good segmentation effect and scalable structure. In recent years, with
the improvement of the performance requirements of medical image segmentation, many scholars are improving and expanding the U-Net
structure, such as the improvement of encoder-decoder, or the external feature pyramid, and so on. In this study, the medical image
segmentation technology based on U-Net structure improvement is summarized from the aspects of performance-oriented optimization
and structure-oriented improvement. Related methods are reviewed, classified and summarized. The paper evaluates the parameters and
modules, and then summarizes the ideas and methods for improving the U-Net structure for different goals, which provides references for
related research.
Key words: U-Net; medical image segmentation; structural improvement; deep neural network; technology survey
随着深度学习技术的快速发展,深度学习在医学影像领域的应用吸引了广泛的研究和关注.其中,如何自动
识别和分割医学影像中的病灶是最受关注的问题之一.为解决这一问题,2015 年,Ronneberger 等人在 MICCAI
会议发表 U-Net[1],是深度学习在医学影像分割中的突破性的进展.U-Net 是基于 FCN(fully convolutional
network)改进而成,包括编码器、瓶颈(bottleneck)模块、解码器几部分组成,由于其U型结构结合上下文信息和
训练速度快、使用数据量小,满足医学影像分割的诉求,而在医学影像分割中广泛应用.U-Net 的结构如图 1 所
∗ 基金项目: 国家自然科学基金(61972404, 61672524, 11671400)
Foundation item: National Natural Science Foundation of China (61972404, 61672524, 11671400)
收稿时间: 2020-05-09; 修改时间: 2020-06-02; 采用时间: 2020-06-20; jos在线出版时间: 2020-07-27 520 Journal of Software 软件学报 Vol.32, No.2, February 2021
示.由于病灶的形状的多样性和不同器官结构的差异性,仅使用 U-Net 结构分割病灶无法满足对于精准度、速
度等的需求.
Fig.1 U-Net network structure diagram[1]
图1 U-Net网络结构图[1]
U-Net 自发表以来,其编码器-解码器-跳连的网络结构启发了大量基于 U-Net 结构改进的医学影像分割方
法.随着深度学习技术的发展,包括注意力机制、稠密模块、特征增强、评价函数改进等基于 U-Net 的基础结
构,将这些深度神经网络发展的最新技术引入到医学影像分割应用中,成为被广泛采取的改进方法.这些相关工
作或者面向不同的优化目标,或者通过结构改进、添加新模块等手段,提高医学影像分割的准确性、运算效率、
适用范围等.由于相关工作众多,而且大多数工作是结合实际问题,不断地加入新的思想,现有文献中对U-Net结
构改进的相关工作尚缺少较好的综述和总结的工作.本文拟从改进目的和改进手段两个方面对近几年基于
U-Net结构改进的医学影像分割的工作进行综述.
• 面向性能优化的改进工作主要包括:(1) 将 U-Net 扩展到 3D 图像[2,3];(2) 增强相关特征,抑制无关特
征[4−13];(3) 改进计算速度、内存占用[14−22];(4) 改进特征融合方法[19,23−30];(5) 针对小样本训练数据集
的改进[31−34];(6) 提高泛化能力的改进[35,36].
• 针对 U-Net 模块结构的改进主要包括:(1) 针对编码器、解码器结构的改进[37−45];(2) 针对损失函数
的改进[2,7,32,41,46−49];(3) 对瓶颈(bottleneck)模块结构的改进[9,31,50];(4) 增加数据流路径的改
进[49,51];(5) 采用自动结构搜索的改进[52]等方面.
图 2 给出了本文对 U-Net 相关研究工作的分类方法.虽然有的相关工作同时被两个层面包含,但这种分类
总结能使得我们更清晰地了解该工作的改进目的和实现目的的改进手段.针对每类改进的具体方法,本文较详
细的介绍了方法的主要设计思想、改进效果、所使用的数据集、评价指标等,并最后给出对相关方法的整体的
总结和比较.此外,本文还提炼出 U-Net 结构改进中一些常见的基础结构模块,这些基础结构模块对深度学习网
络结构的改进具有较为普遍的借鉴意义.
本文第1节介绍医学影像分割深度神经网络中的一些常见的损失函数和评价参数.第2节、第3节从两个
方面、11个子类总结和介绍基于U-Net结构改进的医学影像分割的相关研究工作.第4节提炼医学影像分割研
究中常见的一些特殊结构.第5节对文中所提的算法进行总结、对比和展望. 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 521
Fig.2 Medical image segmentation method based on U-Net structure improvement
图2 基于U-Net结构改进的医学影像分割方法
1 医学影像分割中神经网络常采用的评价参数和损失函数
损失函数和评价参数是训练网络是必不可少的部分:损失函数表示预测和目标之间的差异,常用交叉熵、
Dice loss等判断训练模型与真值之间的差异;分割评价参数是评价图像分割好坏的重要参数,常用Dice等评价
网络模型的优劣.本节主要列举几个图像分割神经网络中常用的评价参数和损失函数.
1.1 评价参数
在评价参数之前,先要介绍一下机器学习中的混淆矩阵.混淆矩阵主要是解决二分类问题[53].其中,TP=True
Positive=真阳性,FP=False Positive=假阳性,FN=False Negative=假阴性,TN=True Negative=真阴性.
1.1.1 精确率(precision)
精确率表示的是预测为正的样本中有多少被预测正确.
TP
P= (1)
TP+FP
1.1.2 召回率(recall)
召回率就是召回目标类别,即表示样本中的正样本有多少被预测正确.
TP
R= (2)
TP+FN
1.1.3 准确率(accuracy)
准确率是评估获得所有成果中目标成果所占的比率.
TP+TN
ACC= (3)
TP+TN+FP+FN
1.1.4 综合评价指标(F-measure)
F-Measure是综合精确率和召回率的评估指标,用于反映整体的情况.
(α2+1)PR
F = (4)
α2(P+R)
当α=1时,
2PR
F1= (5)
P+R
1.1.5 IoU(intersection over union)/Jaccard Index
IoU 又称为 Jaccard Index[54],是目标检测常用到的评价参数,通过预测边框和真实边框的比值计算两个样
本的相似度或者重叠度.我们分别用 Vseg,Vgt 表示两个轮廓区域所包含的点集(Vseg 为预测,Vgt 为真实标签),
范围[0,1],则 522 Journal of Software 软件学报 Vol.32, No.2, February 2021
|V ∩V | |V ∩V | TP
J = seg gt = seg gt = (6)
|V ∪V | |V |+|V |−|V ∩V | FP+TP+FN
seg gt seg gt seg gt
1.1.6 mIoU(mean intersection over union)
mIoU为语义分割的标准度量,在每个类上计算IoU之后进行平均.由于其简洁、代表性强,大多数研究人员
都采用该标准报告结果.假设共有 k+1个类(从 L 到 L,其中包含一个空类或背景),p 表示本属于类 i但被预测
0 k ij
为类j的像素数量.即p 表示真正的数量,而p ,p 表示假正、假负,则MIoU定义为
ii ij ji
1 k p
MIoU = ∑ ij (7)
k+1 k k
i=0∑p +∑p −p
ij ij ij
j=o j=0
1.1.7 Dice coefficient
Dice是一种评估两个轮廓区域相似度的函数,通常用于计算两个样本的相似度或者重叠度,其范围为[0,1].
|V ∩V | 2TP
Dice=2 seg gt = (8)
|V |+|V | FP+2TP+FN
seg gt
Jaccard Index和Dice coefficient之间的换算公式为
D 2J
J = , D= (9)
2−D 1+J
1.1.8 SSIM
SSIM是图像质量评价结构相似性指标,是基于样本x和y之间对于亮度、对比度、结构这 3个方面进行
比较,其范围为[0,1],值越大,两图像之间的差异越小[55].
SSIM(x,y)=[l(x,y)]α⋅[c(x,y)]β⋅[s(x,y)]γ (10)
2μμ +c 2σσ +c
其中,图像照明度比较部分为l(x,y)= x y 1 ,图像对比度比较部分为c(x,y)= x y 2 ,图像结构比较
μ2+μ2+c σ2+σ2+c
x y 1 x y 2
σ +c
部分为s(x,y)= xy 3 .其中,μ为x的均值,μ为y的均值;σ2为x的方差,σ2为y的方差,σ 为x和y的协方
σσ +c x y x y xy
x y 3
差;c ~c 为常数,避免除0.
1 3
1.2 损失函数
损失函数的设计常要考虑数据集的特点,比方说,Focal loss就是用来处理数据集中的难分样本.Dice系数可
以用来处理数据分类不均衡的情况,其中,不均衡很多情况下是由于背景和待分割区域之间的面积对比不均衡
导致的.对于二分类,可以只考虑待分割区域,即是本文中的 Dice loss 函数;那么当对于多种类的分割时,同样可
以只计算待分割区域的Dice系数,这样就可以避免背景占比太大,造成的数据集分类不均的情况.
1.2.1 交叉熵损失函数
设 y′是模型的输出,在 0-1 之间.对于正样本而言,输出越大,意味着损失越小;对于负样本而言,越小,则损失
越小.所以,交叉熵的定义为
⎧−ylogy′, y=1
H =−ylogy′−(1−y)log(1−y′)=⎨ (11)
⎩−(1−y)log(1−y′), y=0
1.2.2 Focal loss
Focal loss[56]是在交叉熵损失函数基础上进行的修改,主要是为了解决one-stage目标检测中正负样本比例
严重失衡的问题.该损失函数降低了大量简单负样本在训练中所占的权重,也可理解为一种困难样本挖掘.
⎪⎧−α(1−y′)γlogy′, y=1
L =⎨ (12)
ft ⎪⎩−(1−α)y′γlog(1−y′), y=0
γ>0 减少易分类样本的损失,使得更关注于困难的、错分的样本.平衡因子α用来平衡正负样本.实验证明,
γ=2最优. 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 523
1.2.3 Dice loss
Dice loss[2]在感兴趣的解剖结构仅占据扫描的非常小的区域,从而使学习过程陷入损失函数的局部最小
值.所以,要加大前景区域的权重.
L =1−Dice (13)
Dice
1.2.4 Tversky loss
Tversky[57]系数是Dice系数和Jaccard系数的一种广义系数,V 为预测标签,V 为真实标签,公式定义为
seg gt
|V ∩V |
T(V ,V )= seg gt (14)
seg gt |V ∩V |+α|V −V |+β|V −V |
seg gt seg gt gt seg
L =1−(V ,V ) (15)
Tversky seg gt
当α=β=0.5时,Tversky loss为Dice loss;当α=β=1时,Tversky系数就是Jaccard系数.A−B则意味着是FP(假
阳性),而B−A则意味着是FN(假阴性);α和β分别控制假阴性和假阳性.通过调整α和β,可以控制假阳性和假阴性
之间的权衡[58].
2 基于U-Net面向性能优化的改进方法
本节和第 3 节将重点介绍基于 U-Net 改进的各类的图像分割方法,本节介绍面向性能优化的改进方法.现
有的工作主要在应用范围、特征增强、训练速度优化、训练精度、特征融合、小样本训练集以及泛化能力提
升几方面对 U-Net 提出各种改进进行研究,这些工作对网络结构进行了不同的变体,或是针对不同的问题加入
了不同的结构.
2.1 将U-Net扩展到3D图像
生物医学影像是不同位置的切片构成的一组三维图,所以传统的 2D 图像处理模型处理 3D 的医学影像时
会存在问题:一是效率不高,二是会丢失大量的上下文.针对这一问题,Ozgun Cicek 等人基于 U-Net 提出了 3D
U-net[3],其网络结构如图3所示.3D U-net输入输出是三维图像,提升了U-Net模型对三维图像的分割准确性.
Fig.3 3D U-Net structure diagram[3]
图3 3D U-Net结构图[3]
另一个代表性工作是Fausto Millemari等人提出的V-net[2],结构如图4所示.在输入3D图像按照通道拆分
的同时,在每一层加入残差结构,以确保短时间收敛.降采样采用卷积操作替换最大池化操作,有利于在接下来
的网络层中减小输入信号的尺寸的同时扩大特征感受野范围,并提出Dice-based loss这个新的损失函数. 524 Journal of Software 软件学报 Vol.32, No.2, February 2021
Fig.4 V-Net structure diagram[2]
图4 V-Net结构图[2]
2.2 针对增强相关特征,抑制无关特征的改进方
医学影像中,由于病变区的位置较其他无关特征更多,那么在分割过程中,聚焦目标特征、抑制无关特征就
极为重要.一般在编解码器和瓶颈处加入SE或者attention模块,这两个模块都可以从空间和通道两个方面进行
激励,以达到增强特征的效果.
2.2.1 加入SE模块
SE(squeeze-and-excitation)是在 2018 年 CVPR 上提出通过学习的方式来自动获取到每个特征通道的重要
程度,然后依照这个重要程度去提升有用的特征,并抑制对当前任务用处不大的特征[59].Roy等人[4]引入3个SE
模型扩展结构分,别串联在U-Net的编码和解码结构中.
(1) 第1种是信道SE(cSE),通过全局池化提取最能表现特征的通道,再将信息融合到原有的tensor中.
(2) 第2种是空间SE(sSE),提取一张特征图划分特征区域,再将特征区域信息融合到原有的tensor中.
(3) 第3种同时进行空间和信道SE(scSE),是cSE与sSE的合并输出.
实验结果表明:空间激励要比通道激励产生更高的对分割更为重要的增益;与标准的网络相比,scSE虽然增
加了一些计算复杂度,但是分割性能更好.
2.2.2 加入attention块
Attention 可以解释为将计算资源偏向信号最具信息性的部分的方法.一般在图像分割中,由于病灶较小且
形状变化较大,常在encoder和decoder对应特征拼接之前,或是在U-Net的瓶颈处增加attention模块来减少假
阳性预测. 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 525
(1) 在encoder和decoder之间加入attention模块
Oktay O等人在2018年提出的Attention U-net[5]在U-Net在encoder和decoder中对应的特征进行拼接之
前加入了一个集成注意力门(AGs),重新调整了 encoder 的输出特征.该模块将生成一个门控信号 g,用以消除不
相关和嘈杂的歧义在跳过连接中的响应,以突出通过跳过连接传递的显着特征.attention模块的内部结构如图5
所示.
ReLU Sigmoid Resampler
x x x
x x x
x x x
Fig.5 Internal structure of Attention module in Attention U-net[5]
图5 Attention U-net中Attention模块内部结构[5]
Li 等人在 2019年提出了敏感连接注意力 U-net(CASU)[6],用于视网膜血管的精细分割.CASU 的网络结构
与Attention U-net的网络结构相同,但是在Attention模块的结构上,CASU采用不同的设计方式,如图6所示.G
是并行编码模块的输出,X是前一个解码模块的输出.G和X经过Attention门的处理后,再同G拼接.由于注意门
的参数更新不仅取决于解码层传递的梯度,而且还取决于编码器层传递的梯度,其 AGs 最终采用的是可以提高
训练过程中细节特征的质量和影响的Up-link.实验结果表明,该方法能够有效地提高分割模型的注意权重.
Fig.6 Structure diagram of Attention module in CASU[6]
图6 CASU中Attention模块的结构图[6]
Ni 等人在 2019 年提出的 RAUNet[7]加入了增强注意力模块(AAM)用于融合多层次特征和捕获上下文信
息,来解决白内障手术器械分割中的镜面反射问题.RAUNet的增强注意力模块(AAM)结构如图7所示.
Low-level
Conv C2×1×1
1×1
Channel-attention vector Conv C2×1×1 Output
C1×H×W GAP C1×1×1 1×1
+ C 1o ×n 1v Softmax × +
Channel-attention vector Conv
High-level GAP C2×1×1 1×1 C2×1×1 C2×H×W
C2×H×W
Fig.7 Structure diagram of AAM in RAUNet[7]
图7 RAUNet中AAM的结构图[7] 526 Journal of Software 软件学报 Vol.32, No.2, February 2021
AAM对语意依赖进行建模,以强调目标通道.其主要通过全局平均池化分别提取高层和低层的全局上下文
信息和语义特征,并分别压缩成一个attention向量后对语意依赖项进行编码,突出关键特征并过滤背景信息.
Zhou 等人提出了轮廓感知信息聚合网络 CIA-Net[8],用于解决细胞核簇和不同器官形状的差异性的问题.
CIA-Net在编解码器之间建立多层次的横向连接,分层地充分利用金字塔特征,通过encoder早期层的纹理信息,
可以帮助Nuclei decoder中分辨率低但具有强语义的层来细化细节,如图8(a)所示.
Fig.8 Structure diagram of IAM in CIA-Net[8]
图8 CIA-Net中IAM结构图[8]
CIA-Net将decoder分为Nuclei decoder和Contour decoder,两者之间加入信息聚合模块(IAM),将核信息和
轮廓信息双向融合(如图 8(b)所示).此外,为了防止网络依赖于单一层次的区分特征,在每个阶段引入深度监控
机制[60],加强对多层次上下文信息的学习,这也有利于通过缩短反向传播路径来训练更深层次的网络体系结构.
(2) 在bottleneck处加入Attention模块
bottleneck 是 U 型网络收缩路径和扩张路径中间的部分.Wang 等人提出的巩膜分割模型——
ScleraSegNet[9]采用丢弃了全联接层的VGG16作为encoder,瓶颈处增加了bottleneck模块用以编码最有区别的
语义特征,其信息特征按照空间和信道进行分解,采用4个attention模块:(1) Channel attention module(CAM),由
SEnet[59]引出,结构图如图9(b)所示;(2) Spatial attention module(SAM)[61],结构如图9(c)所示;(3) Parallel channel
attention and spatial attention module[61],将CAM和SAM并联后相加,结构如图9(d)所示;(4) Sequential channel
attention and spatial attention module[62]在平均池化层增加了最大池化层,然后将CAM和SAM模型顺序串联起
来所得到,结构图如图 9(e)所示.经过在不同数据集上验证,作者提出了的这个方法在准确性上和泛化能力上都
取得了显著的效果.
Fig.9 Internal structure diagram of Bottleneck in ScleraSegNet[9]
图9 ScleraSegNet的bottleneck内部结构图[9] 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 527
(3) 在decoder中加入attention模块
DA 3D-UNet[10]在3D Unet的基础上将上采样替换成DUpsampling[63],以提高解码器中图像的质量.在解码
器的最后两层加入由空间attention和通道attention组合而成的双注意力模块,将大范围的、多通道的特征集中
在关键位置、通道中.
(4) 在跳连中加入attention模块
Li等人提出的ANU-Net[11]在Unet++的跳连中加入了Attention Gate,以提升网络对于形状多样性病灶的分
割效果.Attention Gate 的输入分为两个部分:解码器的上采样特征(g)和编码器中相应的特征(f),其上采样特征
(g)作为门信号来增强编码器中相应的深度特征,从而增强相关特征、抑制无关特征,结构图如图10所示.
Fig.10 ANU-Net structure diagram[11]
图10 ANU-Net的结构图[11]
(5) 在编解码器单元中加入attention模块
徐宏伟等人提出的RDA-Unet[12]采用残差双注意力(RAD)模块作为编解码器单元,RAD将通道注意力机制
和空间注意力机制相结合,保证特征提取的准确性,并加入残差结构以防止梯度消失,更好地定位肾脏的边界.
2.2.3 其他方法
Liu等人在U-Net的基础上加深网络层数至7层,并将编码器的池化层直接与解码器对应的层级联,以减少
信息的损失,并称此网络为 IU-Net[64].由于分割复杂的肝脏切片容易产生低质量的分割,其采用图割算法[65],在
前景和背景选取种子点,建立一个图,利用最大流算法找到加权图的最小割集,最终得到分割较好的图像.他们
将 IU-Net 和图割相结合的网络最终命名为 GIU-Net[64].Mu-net[13]将经过下采样后不同尺度的特征图分别输入
U-Net,再将不同尺度的U-Net的输出经过上采样到上一层U-net的输入,帮助上一层减少对于低频信息的计算,
从而更加聚焦于病灶的分割.
2.3 针对内存占用、计算速度的改进方法
由于2D卷积容易丢失上下文信息,而3D卷积占用CPU量过大,为了减少内存,一种方法是扩大patch中的
volume,另一种方法是用较小的 batch size 训练.这些方法毕竟是有局限性的,因而以下几个工作改进网络中部
分模块,减少内存,提升运算速度.
2.3.1 加入稠密卷积块
Li等人于2018年提出由有效提取切片的2D Dense Net和提取肝脏病灶分割中上下文信息的3D Dense Net
组成 H-DenseUNet[14],即稠密融合 U 型网络.该网络先采用 ResNet 粗略的分割肝脏图像,然后在感兴趣区域
(ROI)中,利用2D Dense Net和3D Dense Net[66,67]有效探测切片内和切片间的特征.在H-DenseUNet的结构上,
MMMDF[15]将2D/3D DenseNet替换成多模态2D-ResUNet和3D-ResUNet,以2D网络的快速分割结果来指导
3D模型的学习并实施分割.
另一方面,光声成像(PAT)测量用的声波经过稀疏采样后可以用于图像重建,但会导致较为严重的图像信息
缺失[68].Steven Guan针对这一问题提出一种全密集连接的FD-UNet[16],用于重建稀疏采样的2D PAT图像,其基 528 Journal of Software 软件学报 Vol.32, No.2, February 2021
于U-Net,在编解码器引入Dense connectivity密集连接,避免了冗余特征的学习,增强了信息流动,在性能接近的
前提下进一步减少了网络参数,降低了计算成本,进行图像重建时可更加快捷(如图11所示).
Fig.11 2D dense connection in FD-Net[16]
图11 FD-Net中2D稠密连接[16]
2.3.2 加入可逆结构
Robin等人提出了Partially Reversible U-Net[17],将U-Net的编解码器每个单元采用可逆序列[69],同时使用传
统的不可逆操作来进行下采样和上采样以及跳跃连接.这种完全可逆的体系结构比传统的 U-Net 节省了大量
的内存,因为激活只需要在每个可逆序列的末尾和不可逆的组件上保存.
2.3.3 加入SE残差块
Zhu等人提出的AnatomyNet[46](如图12所示)以端到端的方式联合分割所有organs-at-risks(OARs),接收一
个原始的全容积 CT 图像作为输入,并将所有 OARs 的掩模与图像一起返回.该结构与 U-Net 的不同在于:只在
第1个编码块中采样了下采样层,使得下一层中的特征映射和梯度比其他网络结构占用更少的GPU内存.移除
第2~第4个编码器块中的下采样层,采用了SE残差块[59]学习有效特征,以提升分割小解剖结构的性能.
Fig.12 Anatomynet structure diagram. The first layer is down sampling,
and the rest is replaced by SE residual block[46]
图12 AnatomyNet结构图.第1层是下采样,其余由SE residual block代替[46]
2.3.4 通道分组
Chen等人在2019年为弥补三维MRI脑肿瘤分割模型效率和准确性不可共存的问题,提出一种新的三维扩
张多纤维网络(DMFNet)[18].DMFNet 建立在多光纤单元(MF)[70]的基础上,利用有效的群卷积,引入加权的三维
扩展卷积运算,获得多尺度的图像分割表示,从而减少参数以提升运算效率.
图 13(a)、图 13(b)采用通道分组思想,将循环通道分成多个组,这样可以减少特征映射和核心之间的连接,
从而显著地节省参数.而图13(c)中的Multiplexer主要是用于不同的fiber之间交换信息.在图13(d)中增加了扩
张卷积,这种加权求和策略可以从不同视角自动选择有价值的信息. 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 529
Fig.13 MF unit of dilated multi-fiber net (DMFnet)[18]
图13 DMFnet多纤维网络的MF单元[18]
2.3.5 加入Inception块
Nabil等人在MultiResUNet[19]中提出了MultiRes模块代替U-Net的每一层解决多分辨率分析同时又节省
内存、提高速度,其将U-Net编解码器的每个单元替换为MultiRes模块.受inception[71]启发,作者先将大小为3×3,
5×5,7×7的卷积层并联,以实现多层分辨率的分析(如图14(a)所示),然后采用更小、更轻量级的3×3卷积块近似
代替5×5,7×7的卷积操作以减少存储(如图14(b)所示),再将filter的个数从1逐渐增加3来减少前一层滤波器
数量带来的二次效应[72],并且增加1×1卷积层的残差连接以更好地保证空间信息,最后构成MultiRes模块.
(a) (b) (c)
Fig.14 MultiRes model of MultiResUnet[19]
图14 MultiResUnet中MultiRes模块[19]
DENSE-Inception U-net[20]将inception和残差模块以及稠密模块相结合,如图15所示,其中,采用Inception-
Res 取代标准的卷积来增加网络宽度;采用 Dense-Inception 模块,在增加网络深度的同时,又不会增加参数的数
量;上下采样采用Inception模块,保证图像分割的准确性.其在肺部图像分割和血管图像分割、脑肿瘤图像分割
方面都有很好的性能.
Fig.15 DENSE-INception U-net structure diagram[20]
图15 DENSE-INception U-net结构图[20] 530 Journal of Software 软件学报 Vol.32, No.2, February 2021
2.3.6 其他方法
Li等人提出了PBR-Unet[21],主要包括提取像素级概率图的功能提取模块和用于精细分割的双向递归模块,
如图16所示.用2D Unet提取概率图,用于指导精细分割;双向递归模块将上下文信息集成到整个网络中,避免了
传播过程中空间信息的丢失,从而节省内存.徐等人提出了基于级联 Vnet-S[22]的单一器官分割法,在 V-net 的基
础上减少V-net的编解码器的卷积单元,减小卷积核的大小,在跳连中加入Dropout缓解过拟合,以减少3D卷积
带来内存占用问题,提升运算速度.
Fig.16 PBR-Unet structure diagram[21]
图16 PBR-Unet结构图[21]
2.4 针对特征融合的改进方法
特征融合其实更多意义上讲的是网络的上下文特征的融合、不同模态特征的融合.上下文特征的融合可以
从编解码器中加入新的模块DAC和RMP帮助融合信息,如CE-Net[73];也可以在跳连阶段增加编解码器信息的
流动,如MultiResUNet[19]、Unet++[23]或者去掉跳连、增加信息聚合的DFA-Net[24];或者外接特征金字塔从不同
分辨率角度保证分割的准确性,如 MFP-Unet[25].对于不同模态的融合,可将编码器分别提取各模态之间的信息
再进行融合,如深度级联脑肿瘤分割方法[26]、Dense Multi-path U-Net[27]、IVD-Net[28].
2.4.1 上下文特征的融合
(1) 编解码器加入新的模块
为了获取更高层次的信息,并保留 2D 医学影像分割中的医学信息,Gu 等人在编解码器的基础上加入上下
文提取模块,从而构成新的网络CE-Net[73],整体框架如图17所示.
Fig.17 CE-Unet network structure diagram[73]
图17 CE-Unet网络结构图[73] 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 531
上下文提取模块主要包括 DAC(dense atrous convolution module)模块和 RMP 模块(residual multi-kernel
pooling).作者受 inception-ResNet-V2[74]模块和扩张卷积启发提出了 DAC 模块,以编码高层级的语义特征图.
RMP 模块采用残差多核池化方法,主要依靠多核有效视场来检测不同大小的目标,解决医学影像中物体尺寸的
巨大变化.
(2) 在跳连处改进
U-Net的跳连结构主要是融合上下文的语义特征,以更好地分割病灶。但是简单的级联使得高层级和低层
级的语义信息融合容易造成重要语意丢失,因而针对这一问题,相关工作提出了多种改进特征融合的方法.Nabil
等人在MultiResUNet[19]中提出:由一系列带有残差连接的卷积层构成的Res path取代U-Net的级联,使低级特
征经过进一步处理再与高级特征级联,以消除编码器的低级特征和解码器的高级特征融合时造成的语义差异
(如图 18 所示).Zhou 等人从另一方面对跳连进行改进,提出带有深度监控的嵌套的密集跳连路径的 Unet++[23],
结构如图19所示.
Fig.18 Skip connection of MultiResUnet[19]
图18 MultiResUnet的跳连[19]
Fig.19 UNet++ network structure diagram[23]
图19 UNet++的网络结构图[23]
Jin等人在跳连处加入attention机制,提出了三维混合残差注意感知分割网络RA-UNet[29],用于精确提取肝
脏兴趣体积(VOI),并从肝脏VOI中分割肿瘤.该网络在3D U-net的基础上,除了第1层和最后一层外,其他都由
残差结构堆叠,以实现增加深度而不会产生梯度爆炸,并在跳连处加入 Wang 等人提出的残差注意力模型[75],分
为用于处理原始特征的主干分支、用于增强特征抑制噪声的软掩膜分支.
杨兵等人所提出的深度特征聚合网络 DFA-Net[24](如图 20 所示)直接去掉 U-Net 跳连并称其为基础层,加
入中间层、聚合层以及特征聚合模块 FAM,帮助更好地融合上下文信息.Nikhil 等人提出的 U-Det[30]将 U-Net
的跳连替换为 Bi-FPN[76],如图 21 所示.其拥有自顶向下和自底向上的路径的同时,每个节点为不同的输入加入
不同权重,以强调不同输入的重要性.而Li所提出的DPSN[77]在跳连处采用特征金子塔,高度提取抽象编码器的
特征之后,再通过跳连和解码器进行级联,将高层语义特征和低层语义特征更好的融合. 532 Journal of Software 软件学报 Vol.32, No.2, February 2021
Fig.20 DFA-Net network structure diagram[24]
图20 DFA-Net网络结构图[24]
Fig.21 U-Det network structure diagram[30]
图21 U-Det网络结构图[30]
(3) 外接特征金字塔
Moradi 等人提出了 MFP-Unet[25],该网络在 U-Net 基础上外接特征金字塔网络 FPN[78],从扩展路径的各个
层次提取特征,最后将提取的特征串联,形成 64 通道的最终特征映射,并传给用于特征分类滤波器中,以提升语
义对分割的贡献.
2.4.2 不同模态的特征融合
传统的 U-Net 网络对于多模态图像输入,采用先混合处理再输入的方式,这样操作容易丢失不同模态的部
分信息.Lachinov等人[26]为解决这一问题,提出一种深度级联脑肿瘤分割方法,主要是将编码器并行分出几个路
径分别学习不同模态的特征表示,在跳连和 bottleneck 处采用像素最大化操作再与解码器级联,网络结构如图
22所示.
而Dolz等人提出的Dense Multi-path U-Net[27]在编码器多路径的基础上加入Dense Net的思想,以解决缺
血性中风病灶的位置和形状的高度变异性.此方法首先将输入端图像混合的方式,变成在不同路径中对每个模
式进行处理,以更好地利用其独特的信息,如图 23 所示;然后在不同模态之间建立稠密连接,改善数据流,减轻梯
度消失;并且扩展了非对称 inception 卷积块,代替最大池化操作,其多扩张率的卷积操作,从不同尺度上提取特
征,更好的捕获上下文信息.同年,Jose Dolz等人在Dense Multi-path U-Net[27]的基础上提升编码器的多路径稠密
性,提出了IVD-Unet[28],主要对椎间盘(IVD)图像进行分割. 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 533
Fig.22 Gliomas segmentation and cascaded U-Net network structure diagram[26]
图22 Glioma分割与级联U-Net网络结构图[26]
Fig.23 Dense Multi-path U-Net network structure diagram[27]
图23 Dense Multi-path U-Net网络结构图[27]
2.5 针对提高泛化能力的改进方法
在临床实践中,医学影像是从不同的供应商处获取,从特定的源域训练的 U-Net 再传输到不同的目标域时,
性能会急剧下降.泛化能力是指网络可以混合训练来自不同提供商的图像,具体方法有两种:从内部结构提出适
应不同提供商图像的域适配器,如3D U2-net[35]采用在编解码器单元内采用Adapter找到合适网络训练的卷积,
从而适应不同提供商提供的图像;从外部接入Cycle-GAN网络,如Yan等人提出的Unet-GAN[36],包括一个用于
适应供应商的非配对生成对抗网络(CycleGAN)[79],一个用于对象分割的LV-Unet.在图24中,LV-Unet是由数据
集S训练的满足LV(左心房)分割的分割网络;CycleGAN是一个为未配对的图像到图像转换而设计的既定架构,
包括两个生成器G 和G ,代表源域和目标域;两个辨别器D 和D ,辨别是原始图像还是转换图像.
S T S T
Fig.24 U-netGAN network structure diagram[36]
图24 U-netGAN网络结构图[36] 534 Journal of Software 软件学报 Vol.32, No.2, February 2021
2.6 针对小样本训练数据集的改进
医学影像由于涉及隐私问题和标注成本高的问题,其数据集数量极少.针对小样本训练数据集的问题,一般
从重复的网络结构和数据集标签两个方面进行.
• 重复网络结构可以在 bottleneck 重复使用 SRU 门控单元[31],也可以重复使用整个 U-Net 如 Bridged
U-net[32].
• 从数据本身标签入手,可以结合贝叶斯训练给定数据标签再进行网络训练,提升分割准确性;或者将一
幅图像仅使用一个单一全局标签,以降低对数据量的要求.
2.6.1 重复网络结构
Wang 等人[31]提出在 U-Net 的瓶颈处加入重复单元结构:双门控递归单元(DRU)或单门控递归单元(SRU),
可以在数据集和计算能力有限的情况下进行训练.DRU 在 GRU[80]上进行改进,能有效地细化迭代分割,但浪费
内存,因而提出简化成单门控的SRU代替DRU,其精度并未变化.
Chen等人提出了Bridged U-net[32],采用U-Net桥连接的方法,在多个层次上充分利用不同的特征,加速神经
网络的收敛.网络结构如图25所示.两个U-Net之间的桥连接采用级联,U-Net的跳连采用加法,可以达到网络的
最好表现形式.激活函数采用ELU和ReLU相结合,解决了单纯使用ELU的随着网络不断深入的饱和问题.
Fig.25 Bridged U-net network structure diagram[32]
图25 Bridged U-net的网络结构图[32]
2.6.2 计算数据标签
U2-NET[33]提出一个具有认知不确定性反馈的BAYESIAN U-NET模型,用于病理OCT扫描中光感受器层
的分割.通过贝叶斯对于给定数据和标签进行后验概率计算,再通过U-Net进行训练.
Florian Dubost提出了GP-Unet[34],用弱标签来检测病灶的卷积神经网络,也就是每幅图像只需要一个单一
的全局标签“病变计数”就可以训练,网络结构如图26所示.GP-Unet是一个具有完全卷积结构的回归网络,结合
一个全局池层,将 3D 输出聚合成一个指示病变数量的标量.在测试时,GP-Unet 首先运行网络来估计病变的数
量,再移除全局池层来计算输入图像大小的定位图. 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 535
Fig.26 GP-Unet network structure diagram[34]
图26 GP-Unet网络结构图[34]
3 基于U-Net面向结构模块的改进
本节对于 U-Net 面向结构模块的改进作出总结,现有工作主要在编解码器、bottleneck 和损失函数改进、
数据流增强以及自动搜索结构几方面对 U-Net 提出各种改进型研究.这些工作对网络结构进行了不同的变体,
或是针对不同的问题加入了不同的结构.
3.1 针对编码器解码器结构的改进方法
编、解码器的改进可分为 3 部分:一是卷积操作的改进,如加入协调引导卷积、长短残差结构;二是编解码
器单元的改进,如可以可形变卷积块、循环残差卷积和概率模块;三是上、下采样的改进,如可以采用长短残差
结构和最近邻插值的方法.
3.1.1 卷积操作改进
肺叶的鉴别和诊断对疾病的诊断和治疗具有重要意义,少数肺病在肺叶有区域性的病变,准确分割肺叶极
为重要,Wang等人[37]提出一种基于利用协调引导卷积的深度神经网络,从胸部CT图像中自动分割肺叶的方法.
其首先采用自动肺分割方法提取CT图像中的肺面积,然后利用V-net对肺叶进行分割.协调卷积部分结构图如
图27所示.
Conv3D
or Deconv3D
……
[c, d, w, h]
……
[c’, d ’, w’ , h’]
…… Channels
concatenate
[c+3, d, w, h]
y y y
000000
1 21 21 21 21 21 2 x x x
333333
z44444 z4 coordinate z y coordinate z x coordinate
Fig.27 Coordination-guided convolution proposed by Wang, et al.[37]
图27 Wang等人提出的协调卷积[37] 536 Journal of Software 软件学报 Vol.32, No.2, February 2021
为了减少不同肺叶的错误分类,文中采用协调引导卷积(CoordConvs)[81]来生成肺叶位置信息的附加特征
图.CoordConv是对经典卷积层的简单扩展,通过添加额外的坐标通道来集成位置信息.
对于模态的急性亚急性脑中风病灶 MRI 图像分割,Albert 等人[38]提出在采样过程中平衡患者和健康的人
的 MRI 图像采样,并且在 U-Net 的网络结构中加入长短残差结构代替卷积操作和下采样操作在保证精度的同
时减少参数,改进结构如图28所示.
Fig.28 Network structure diagram proposed by Albert, et al.[38]
图28 Albert等人提出的网络结构图[38]
3.1.2 编、解码器单元改进
Jin等人提出DUNet[39],其是在U-Net的框架的基础上,用可变形卷积块[82]作为编码器、解码器的每一个单
元.可变形卷积块通过学习局部、密集和自适应的感受野来模拟不同形状和尺度的视网膜血管,以达到准确分
割.具体是在标准卷积使用的网格采样位置上添加偏移量,而偏移量是从附加卷积层生成的先前特征映射中学
习的.因此,变形能够适应不同的尺度、形状、方向等.图29给出可变形卷积与普通卷积方法差异的示意图.
Fig.29 Comparison of deformable convolution and normal convolution in DUNet[39]
图29 DUNet中可变形卷积和正常卷积对比[39]
蒋等人提出的 I-Unet[40]在 U-Net 的基础上改进编解码器单元,编码器采用由扩张卷积、inception 和 RCL
层组成的Conv-Block,解码器采用反卷积、RCL层组成的Deconv-Block,通过扩大感受野进行多尺度特征融合.
何承恩等人基于 3D-Unet 提出了 3D-HDC-Unet[41],在编码器的每个单元中加入混合膨胀卷积残差块,以不
断变化的膨胀率改变棋盘效应[83]给分割带来的负面影响.
Alom 等人提出了 R2U-Net[42],该方法将残差连接和循环卷积结合起来,用于替换 U-Net 中原来的子模块,
其改进结构如图 30 所示,图中环形箭头表示循环连接.图 31 展示了几种不同的子模块内部结构图.该方法保证
网络深度的同时,减轻梯度消失的影响,在提取低级特征有显著效果,多应用于视网膜血管分割.
Kohl等人提出HPU-net[43],一个结合U-Net和条件变分自动编码器(cVAE)的能够考虑多尺度变化的层次概
率分割网络,网络结构如图 32 所示.该网络分为采样过程和训练过程,在采样过程中,解码器额外对延迟的空间
网格采样.在训练过程中,采用条件概率分布对网络进行训练. 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 537
Fig.30 R2U-Net network structure diagram[68]
图30 R2U-Net网络结构图[68]
(a) 常规的U-Net中使用的方法;(b) 在(a)的基础上使用循环卷积代替原有卷积;
(c) 使用残差连接的方式;(d) 该文章提出的结合(b)和(c)的循环残差卷积模块
Fig.31 Structure diagram of Recurrent convolution in R2U-Net[42]
图31 R2U-Net中循环卷积结构图[42]
(a) Sampling (b) Training
Fig.32 HPU-net network structure diagram[43]
图32 HPU-net网络结构图[43]
3.1.3 上、下采样改进
在微创手术中,准确地追踪到手术器械的位置是十分重要的.针对内窥镜图像中的分割和识别外科器械问
题,Hasan等人[44]为缓解转置卷积导致“不均匀重叠”也就是棋盘格形状的伪影问题,提出了U-NetPlus网络结构,
将 VGG-11 和 VGG-16[84]作为编码器这种预先训练的编码器[85],通过规避与目标数据相关联的优化挑战,加快 538 Journal of Software 软件学报 Vol.32, No.2, February 2021
了收敛速度[86].
Wang等人提出了Non-local U-Nets[45],在U-Net的基础上,对于输入输出模块采用残差结构,对于上下采样
采用外部嵌套残差结构的全局聚合模块,从而减弱单一卷积操作所带来的信息丢失问题.
3.2 基于损失函数的改进方法
神经网络训练过程中,使用损失函数计算每次迭代的结果与真实值之间的差距,从而指导下一步训练向正
确的方向进行.损失函数改进主要解决的是类不平衡的问题,主要是从函数自身和两个损失函数相结合两个方
面进行改进.
3.2.1 函数自身改进
Dice loss函数的一个局限性在于FP与FN的检测权重相等,这将导致分割图有较高的准确率和较低的召
回率.像在皮肤病变者众数据极不平衡,感兴趣区域极小,FN需要比FP高很多才能提高召回率.V-net[2]中提出了
一个基于 dice coefficient 的损失函数,也就是对分割求偏导数,从而不需要为不同类别分配权重,就可以建立前
景、背景平衡.
2∑Npg
D= i i i (16)
∑Np2+∑Ng2
i i i i
∂D =2⎢⎡ g j( ∑ iNp i2+∑ iNg i2) −2p j( ∑ iNp ig i) ⎥⎤
(17)
∂p j ⎢ ⎢⎣ ( ∑ iNp i2+∑ iNg i2)2 ⎥ ⎥⎦
对于 Dice loss 的预测接近真实情况时效果不佳引起震荡的问题,Chen WL 等人提出一个新的损失函数
Cos-Dice[32]损失函数,来加速学习进程.
⎛π ⎞
L CosDice =cosQ ⎜ ⎝2⋅DSC⎟ ⎠, Q>1 (18)
3.2.2 两个函数的混合
针对医学数据类不平衡的问题,Abraham等人基于Tversky index提出了一个广义的损失函数Focal Tversky
Loss(FTL)[47].与 Dice loss 函数相比,这个函数在训练较小结构可以更好地权衡准确率与召回率之间的关系(其
中,c为类别,TI 为Tversky index).
c
1
FTL =∑(1−TL )γ (19)
c c
c
而AnatomyNet[46]和3D-HDC-Unet[41]采用Dice系数和Focal loss相结合的方式解决这一问题.
L=L +λL (20)
Dice Focal
实验结果表明,λ=0.5时效果最好.
RAUNet[7]提出的Cross Entropy Log Dice(CEL-Dice)结合了交叉熵的稳定性和类不平衡不影响Dice loss
的特性,因此,它有比Dice loss更好的稳定性,比交叉熵更好地解决类不平衡的问题(H为交叉熵,D为Dice loss).
L=(1−α)H−αlog(D) (21)
Zhong等人[48]提出了交叉熵和Dice loss损失组合新的形式:
L=(1−α)H+αD (22)
3.3 针对增加数据流路径的改进方法
针对于数据流的改进主要是从两个方面:一是采用 DenseNet 的思想,增加网络中不同模块之间的连接;二
是将U-Net网络串行使用两次,也就是桥连接,从而达到信息成倍数流通的目的.
U-Net 的各种变体都包含编码器和解码器,但是对于数据流路径数量是有限的,Zhang 等人提出的 MDU-
Net[51]将 DenseNet 的思想应用于编、解码器、跳连中,直接融合高层和低层相邻的不同比例尺的特征映射,增
强当前层的特征传播.这在很大程度上提高了信息流的编解码能力(如图33所示). 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 539
Fig.33 MDU-Net network structure diagram[51]
图33 MDU-Net的网络结构图[51]
Zhuang 等人提出的 LadderNet[49],其结构类似于桥连接,与之最大区别在于两点:其一,LadderNet 用加法取
代U-Net中跳连采用的级联,两个并行U-Net对应层也采用加法;其二,LadderNet采用了一个新的共享权重残差
块(如图 34 所示),解决了多编码器解码器分支来的参数增多、训练难度增加的问题.这个共享权重残差块由 3
个部分组成:跳连、递归卷积以及 dropout 正则化.其在同一块中的两个卷积层共享参数可以看作一个递归层,
两个卷积层之间加入dropout避免过拟合.
1 2 3 4
A
B
C
D
E
Fig.34 LadderNet network structure diagram[49]
图34 LadderNet网络结构图[49]
3.4 基于自动搜索最优网络结构的改进方法
Ken等人借鉴了网络结构搜索(NAS),提出了SegNAS3D[52]三维图像分割网络结构搜索,以解决三维图像分
割中大量手动调参和网络体系结构优化的问题,如图 35 所示.文中提出了在每一层加入一个新的块结构
Mg-Blk,该块结构是由可学习块Block[87]、空间dropout和可选择残差连接组成.文中最重要的是这个可学习块
block的学习训练,文中将一个块结构表示成一个有向无环图,如图36所示,每一个节点代表一个特征图,每一条
边代表一次操作.矩阵的行和列为输入节点和输出节点,矩阵中的数值为扩张卷积的扩张率,通过学习节点数以
及扩张率来训练整个网络的准确性. 540 Journal of Software 软件学报 Vol.32, No.2, February 2021
Fig.35 SegNAS3D network structure diagram[52]
图35 SegNAS3D网络结构图[52]
Fig.36 SegNAS3D expansion coefficient selection[52]
图36 SegNAS3D扩张系数选择[52]
3.5 基于瓶颈(bottleneck)的改进方法
Bottleneck 是 U 型网络收缩路径和扩张路径中间的部分,其主要接受了所有来自编码器提取的特征信息,
并将分割好的的图像通过解码器恢复到原有分辨率,因而其重要性可想而知.一般对于 bottleneck 的改进,多采
用attention机制,以更好地关注分割细节.Wang等人提出的巩膜分割模型ScleraSegNet[9]在bottleneck中采用4
种 attention 机制,将通道注意力和空间注意力相结合,以更好地分割.而 Wang 等人[31]受 GRU 的启发,在
bottleneck处重复使用SRU模型,在保证分割精度的同时,又减轻参数过多带来的影响.
而 Li 等人提出了新的改进方法 BSU-Net[50],其先将 U-Net 的编解码器以及 bottleneck 进行改进,加入了
Inception、Dense 模块和扩张卷积,并称该网络为 Base U-Net.然后将 Base U-Net 按照是否去掉跳连分为
Encoding U-Net和Segmentation U-Net,再将两者的bottleneck部分连接.大多数的网络金队输入输出有监督,而
BSU-Net通过将U-Net改进,称自动编码器,弥补了bottleneck的监督空白,并且可以进一步提取bottleneck处的
信息,对于图像进行更好的分割.网络结构如图37所示.
Fig.37 BS U-Net network structure diagram[50]
图37 BS U-Net网络结构图[50] 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 541
4 U-Net结构改进中常用结构模块
由于图像分割任务的目标不同,其网络结构也不尽相同.通过对解决问题的分类,我们总结归纳出如下适用
于不同问题的网络结构模块,从而帮助大家针对不同问题,快速找到适用的模块以组成网络结构.
4.1 残差结构
一般来说,增加神经网络的宽度和深度可以提高网络的表达性能.但如果简单地增加网络的层数,就会面对
梯度消失或是梯度爆炸的问题.何凯明等人为此提出了残差网络[88],将每两层网络中增加一个跳连,以保证增加
层数后不会削弱网络的表达性能.残差结构如图 38 所示.在 V-net[2]、MultiResUNet[19]、RDA-Unet[12]等结构中
都有采用,可以放置于编码解码器单元,也可在下采样中使用.
Fig.38 Residual structure[88]
图38 残差结构[88]
4.2 Attention模块
Attention 的主要思想是强化特征,在医学影像里常用于分割细节较多的血管、肺叶,其内部结构不固定,可
根据强调的内容自行设计,例如强调特征图称为 Spatial Attention、强调通道为 Channel Attention.Attention
U-net[5]、CASU[6]、RAUNet[7]、CIA-Net[8]都是在解码器中加入attention模块,Attention U-net的AGs是加入门
控信号以消除噪声,CASU的AGs采用Up-link以聚焦特征,IAM是将核、轮廓两个解码器分支的信息聚合.这
三者都是空间信息方面的特征聚焦,而 AAM 主要是通过强调目标通道从而聚焦特征;ScleraSegNet[9]是在瓶颈
处加入CAM和SAM块,从空间和通道两个方面进行特征的聚焦.表1给出了不同的Attention模块的总结.
Table 1 Network model with attention mechanism
表1 加入attention机制的网络模型
网络简称 改进结构 模块图号 Attention机制 功能
Attention U-net[5] 解码器 图5 AGs 门控g消除噪声
CASU[6] 解码器 图6 AGs Uplink聚焦特征
RAUNet[7] 解码器 图7 AAM 强调目标通道
CIA-Net[8] 解码器 图8 IAM 核和轮廓信息聚合
ScleraSegNet[9] 瓶颈处 图9 CAM+SAM 通道+空间 attention
4.3 SE模块
通道的压缩和激励,通过找到特征较好的通道,强调这一通道,压缩不相关的通道,以减少参数,强化分割精
度.无论 AnatomyNet[46],还是 Roy 等人[4]提出的通道和空间挤压激励,都是运用了这一思想.SKNet[89]在 SENet
的基础上结合了Merge-and-RunMappings以及attention on inception block,用多尺度特征汇总信息,来按照通道
指导侧重使用哪个核的表征,从而减少了参数增加路径和动态选择.因而在之后的图像分割中,可以考虑采用
SKNet所提出的方法代替SE结构.
4.4 DenseNet模块
DenseNet 主要是将每一层的网络复制到下一层的全连接结构,增强数据流动的同时减少计算量.医学影像
分割中,常将 Dense 的应用于编码器与解码器的全连接、编解码器的单元,从而达到减少参数提升计算精度.
H-DenseUNet[14]和 FD-UNet[16]都是在编解码器的单元中引用 Dense模块,不同在于:前者是将 2D和3D Dense
的模块相结合,用 2D 网络指导 3D 网络分割;而后者仅仅在编解码器每个单元中使用 Dense 模块以减少参 542 Journal of Software 软件学报 Vol.32, No.2, February 2021
数.Dense Multi-path U-Net[27]和IVD-Unet[28]的网路结构大部分相同,后者在前者的基础上将编码器的稠密性提
升到了一个新的高度,将不同模态之间的信息更好地交互.MDU-Net[51]将稠密的思想应用在编码器的每个单元
之间、解码器的每个单元之间,并且跳连也不再单单是编解码器对应层的连接,采用全连接的方式将高级信息
和低级信息充分融合利用,表2给出了稠密模块的总结.
Table 2 Application of DenseNet thought in network
表2 应用DenseNet思想的网络
网络简称 改进结构 Dense形式 作用
H-DenseUNet[14] 编解码器 2D+3D Dense模块 保证信息流
FD-UNet[16] 编解码器 Dense block 减少参数
Dense Multi-path U-Net[27] 编码器 不同模态稠密连接 增强不同模态之间的信息流
IVD-Unet[28] 编码器 不同模态超级稠密连接 增强不同模态的信息流
MDU-Net[51] 编解码器、跳连 全网络稠密连接 增强信息流动
4.5 Inception模块
在医学影像中,病灶所占区域在不同的图像中变化极大,因而卷积核的选择非常重要.然而较小的卷积核适
合局部信息,较大的内核更适合捕获全局分布的信息.Inception 将扩张率不同、大小不同的卷积都囊括在内,通
过不同尺度提取特征,从而达到精确提取特征的目的,例如 CE-Net[73]中的 DAC 模块就是为了更好地提取特征
而设计.但由于 Inception 中包含不同大小的卷积核,大卷积核相比于小卷积核计算量要多很多,因而
MultiResUNet[19]选择用 3×3 代替 5×5,7×7 的卷积核,而 Dense Multi-path U-Net[27]和 IVD-Unet[28]采用非对称
inception模块,也就是将n×n的卷积拆解成n×1,1×n的卷积,从而降低计算量.
4.6 CycleGAN模块
生成对抗性网络(GAN)将图像从一个领域转换成另外一领域,例如将斑马转换成马.在医学影像中,由于不
同源域的图像放在一起训练将导致极大的问题,通过将图像先经过 CycleGAN 再进行训练,从而达到更好的训
练效果,例如Unet-GAN(如图39所示)[36].
Fig.39 U-net extended structure technology development flow chart
图39 U-Net扩展结构技术发展流程图 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 543
5 总结与建议
对于上文介绍的基于 U-Net 扩展结构的技术脉络总结如图 39 所示,按照面向性能优化和面向结构改进总
结成表3和表4.主要从网络维度、改进结构、亮点、数据集、评价参数这5个方面进行总结.
1) 网络的维度主要是2D、3D、2D和3D的混合:2D网络为基本网络;3D网络因为其具有2D网络没有
的上下文信息;2D 和 3D 网络的融合以 2D 网络的快速分割结果来指导 3D 模型的学习并实施分割,
主要在减少内存、提升计算速度中使用.
2) 对于改进的结构,包括编解码器、bottleneck、跳连、卷积操作、上下采样、损失函数、外接其他结
构以及数据标签.编解码器的改进包括编解码器单元的改进、上下采样、卷积操作的改进,在大部分
问题中都有应用,而像跳连、数据标签这类改进主要是为解决特征融合、小样本数据集问题.
3) 在数据集方面,相关方法采用了几乎各不相同的数据集,主要包括脑肿瘤(BraTS)、视网膜血管、肝脏、
胰脏、腰间盘、乳腺癌、前列腺等.由于各种方法采用的数据集不尽相同,本文列举数据集以提供一
个数据集名称索引.由于不同方法评价所采用的数据集不尽相同,所以不同方法难以进行横向比较.
4) 从指标函数方面,可见主要评价指标是Dice scores,IOU次之.表中总结了各个方法采取的评价指标以
及指标数值,帮助大家在选择网络模型时有一个参考和比较.
Table 3 Based on U-Net, it classifies the performance optimization and compared from
the aspects of improved structure and highlights
表3 基于U-Net面向性能优化进行分类,并从改进结构、亮点等方向进行对比
分类 网络简称 时间 维度 改进结构 亮点 数据集 评价参数 数值
基于3D 3D U-Net[3] 2016 3D 编解码器 卷积2D Enopus kidney IoU 0.732
图像 变3D embryos
分割的 V-net[2] 2016 3D 编解码器 加入残差 PROMISE Avg. Hausdorff 5.71±
改进 结构 2012 distance 1.20mm
Concurrent global Dice 0.843±
Spatial...[4] 2018 3D 编解码器 scSE MALC scores 0.062
Attention Gastric 0.767±
U-net[5] 2018 2D 解码器 AGs cancer Dice scores 0.132
CASU[6] 2019 3D 解码器 AGs DRIVE ROC AUC 0.915 7
RAUNet[7] 2019 3D 解码器 AAM Cata7 Avg.Dice 0.977 1
CIA-Net[8] 2019 3D 解码器 信息聚合 MoNuSeg F1-score 0.845 8
模块(IAM) 2018 MICCAI
增强 4个Attention UBIRIS,
相关 ScleraSegNet[9] 2019 2D bottleneck 模块替换 MICHE-I Precision 0.921 1
特征, bottleneck块 and MASD
抑制
DA 3D-UNet[10] 2019 3D
解码器、 双注意力模块、
LIDC MIoU 0.894
无关 上采样 DUpsampling
特征 残差 从医院共采集
编解码器
RDA-Unet[12] 2019 2D 双注意力 79位肾囊肿 DSC 0.965
单元
模块 患者的CT图像
GIU-Net[64] 2020 2D 解码器 池化层级连,分割后 codalab DSC 0.9505±
使用图割算法 0.0132
ANU-Net[11] 2020 2D 跳连 Attention LiTS/ Dice 0.9815/
gate CHAO 0.9479
Mu-net[13] 2020 3D 重复 多尺度 2PM image PSNR 26.41
U型网 U-Net datasets (N1-B1)
FD-Unet[16] 2018 2D 卷积操作 全密集模块 Circles AVERAGE 0.82±
SSIM 0.07
针对内存 MICCAI
占用、 H-DenseUNet[14] 2018 2/3D U-Net放入 2D+3D 2017 LiTS和 Dice scores 0.937±
其他结构 Dense Net 0.02
计算 3DIRCADb
速度的 MICCAI head
改进方法 AnatomyNet[46] 2018 3D 编解码器 SE残差 and neck Avg. Dice 0.792 5
模块 segmentation
2015 544 Journal of Software 软件学报 Vol.32, No.2, February 2021
Table 3 Based on U-Net, it classifies the performance optimization and compared from
the aspects of improved structure and highlights (Continued 1)
表3 基于U-Net面向性能优化进行分类,并从改进结构、亮点等方向进行对比(续1)
分类 网络简称 时间 维度 改进结构 亮点 数据集 评价参数 数值
DMFNet[18] 2019 3D 编解码器 DMF BraTS-2018 Dice scores 0.850 9
Partially
部分可逆
Reversible 2019 3D 编解码器 BraTS 2018 Dice scores 0.856 2
U-Net[17] 结构
功能提取 NIH
PBR-Unet[21] 2019 3D U-Net放入 模块和双向 Pancreatic Avg. Dice 83.35±
其他结构 5.02
递归模块 segmentation
针对 MultiResUNet[19] 2019 2D/ 跳连 MultiRes BraTS17 5-Fold Cross 78.1936±
内存 3D block Validation 0.7868
占 计用 算、
Vnet-S[22] 2019 3D 编解 跳码 连器 、
和减 卷少 积卷 核积 ,单 跳元
连 2M 01I 7C C LiA TI
S
Dice 0.96
速度的 加入Dropout
改进 卷积采用Dense-
卷积操作、
方法 DENSE-Ince 2D/ Inception模块, MICCAI Average
ption U-net[20] 2020 3D 下采样和 上下采样使用 BraTS 2017 Dice score 0.958 2
上采样操作
inception模块
421名NPC
患者T1W,
MMMDF[15] 2020 2D/ 编解码器 2D ResUnet+ T2W,T1C Dice 0.805
3D 3D ResUet
3种脑结构
MR图像
每幅图像只需 subset of the
GP-Unet[34] 2017 3D 数据标签 要一个单一 Rotterdam Sensitivity 0.62
的全局标签 Scan Study
针对 Bridged 重复 Mean
小样本 U-net[32] 2018 2D U型网 U-net桥连接 PROMISE12 vDSC 89.56
训练 U2-NET[33] 2019 2D 数据标签 贝叶斯训练给 Vienna Dice scores 0.8943±
数据集 定数据标签 Reading 0.04
的改进 双门控递归
Recurrent 单元(DRU)和
U-net…[31] 2019 2D bottleneck 单门控递归 DRIVE mIOU 0.849
单元(SRU)
在跳连阶段
UNet++[23] 2018 2D 跳连 采用密集块 cell nuclei Jaccard/IOU 92.63
和深度监控
Glioma
Segmentation 分别学习各
2018 3D 编码器 BraTS 2018 Avg. Dice 0.908
with Cascaded 模态再组合
Unet[26]
Dense Multi- 3D 0.635±
path U-Net[27] 2018 编码器 密集多路径 ISLES DSC 0.186
超密集
IVD-Net[28] 2018 3D 编码器 LITS Avg. Dice 0.961
多路径
针对
特征 CE-Net[73] 2019 2D 编解码器 DAC和RMP ORIGA Accuracy 0.955±
0.003
融合
MultiResUNet[19] 2019 3D 跳连 Res path BraTS17 5-Fold Cross 78.1936±
Validation 0.7868
Augmented MICCAI 2017
RA-UNet[29] 2019 3D 跳连 Attention LiTS and the mDice 0.977 1
Module 3DIRCADb
MFP-Unet[25] 2019 2D 外接 外接特征 validation Dice scores 0.97±
金字塔网络 0.13
DFA-Net[24] 2020 3D 跳连 特征聚合 brainweb Dice (WM 95.84,94.91,
模块FAM GM CSF) 94.68
跳连、 Bi-FPN,Mish
U-DET[30] 2020 2D LUNA-16 DSC 0.828 2
激活函数 激活函数 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 545
Table 3 Based on U-Net, it classifies the performance optimization and compared from
the aspects of improved structure and highlights (Continued 2)
表3 基于U-Net面向性能优化进行分类,并从改进结构、亮点等方向进行对比(续2)
分类 网络简称 时间 维度 改进结构 亮点 数据集 评价参数 数值
针对提高 Unet-GAN[36] 2019 2D U-Net放入其他结构 CycleGAN GE Dice scores 0.867±0.035
泛化能力 3DU2-net[35] 2019 3D 单元内 Adapter Base01 Heart Dice scores 93.26
Table 4 Based on U-Net, it classifies the structural module improvement,
and compares the improved structure and highlights
表4 基于U-Net面向结构模块改进进行分类,并从改进结构、亮点等方向进行对比
分类 网络简称 时间 维度 改进结构 亮点 数据集 评价参数 数值
卷积操作、
Acute and sub- 长短残差 0.59±
acute...[38] 2018 3D 下采样和 网络结构 ISLES 2015 Avg. Dice 0.31
上采样操作
DUNet[39] 2018 3D 编解码器 可形变卷积 DRIVE Accuracy 0.969 7
R2U-Net[42] 2018 2D 编码解码器 循环残差 Retina mIOU (%) 0.821
单元 卷积 Vessels
HPU-net[43] 2019 2D 解码器 cVAE LIDC IoUrec 0.97±0.00
Automated 协调引导 Dice 0.947
针对 segmentation...[37] 2019 3D 卷积操作 卷积 LUNA16 coefficient (0.044)
编码器
Nearest-
解码器 U-NetPlus[44] 2019 2D 上采样 Neighbor MICCAI Dice 0.902
的改进 interpolation 2017EndoVis scores
加入Incep-
I Unet[40] 2019 2D 编解码器 ISIC Archive Dice 0.871
tion和RCL
3D-HDC-Unet[41] 2020 3D 编码器 混合膨胀卷积 BraTS2017 DSC(WT, 0.90,0.80,
TC,ET) 0.70
全局聚合 3D
Non-local 模块(global multimodality
U-Nets[45] 2020 2D 上下采样 aggregation isointense infant Dice 0.923 9
block) brain MR image
V-Net[2] 2016 3D 损失函数 Dice-based loss PROMISE 2012 Avg. Dice 0.869±0.033
Focal Tversky Focal Tversky 0.804±
loss...[47] 2018 2D 损失函数 Loss(FTL) BUS 2017 Dice scores 0.024
Bridged cos-Dice loss
基于 U-Net[32] 2018 2D 损失函数 Func-tion PROMISE12 Dice scores 89.96
损失 RAUNet[7] 2019 3D 损失函数 CEL-Dice Cata7 mIOU (%) 0.956 2
函数
混合损失
MICCAI head
改进的 AnatomyNet[46] 2019 3D 损失函数
函数
and neck seg- Avg. Dice 0.792 5
方法 mentation2015
3D-HDC- 混合损失 DSC(WT, 0.90,0.80,
Unet[41] 2020 3D 损失函数 函数HLF BraTS2017 TC,ET) 0.70
改进 二值交叉熵和
2020 2D 损失函数 LIDC-IDRI DSC 84.48
U-Net…[48] Dice loss函数
针对
LadderNet[49] 2018 2D
重复U型网、 桥连接、共享
DRIVE F1-score 0.820 2
数据流 编解码器 权重残差块
路径的 MDU-Net[51] 2018 2D 编解码器、 多尺度密集 MICCAI2015 Dice scores 0.928
改进 交叉连接 交叉连接 GlaS
自动搜索
最优网络 SegNAS3D[52] 2019 3D 编解码器 MgBlk块 MP-RAGE Dice 0.817±
0.003
结构
双门控递归
Recurrent 单元(DRU)和
U-net...[31] 2019 2D bottleneck 单门控递归 DRIVE mIOU 0.849
针对
单元(SRU)
Bottle
neck的
4个attention
改进 ScleraSegNet[9] 2019 2D bottleneck 模块替换 UBIRIS.v2 Precision 0.921 1
bottleneck块
BSU-Net[50] 2020 2D bottleneck Encoding LiTS 2017 DPC 0.961 0
U-Net 546 Journal of Software 软件学报 Vol.32, No.2, February 2021
随着器官结构差异化、病灶形状多样化,U-Net已经无法满足所有病灶高精准性的分割.随着attention机制、
Dense模块、Inception模块以及残差结构、图割等模块的发展和完善,近期一些工作在U-Net的基础上加入不
同的模块,以实现对于不同病灶的精准分割.基于 U-Net 扩展结构多种多样,因而我们进一步总结了针对不同的
目的的网络结构改进方法,总结出几个方案供参考,见表5.
1) 对于分割微小细节,例如视网膜血管、肺叶等,可在残差的基础上使用可变形卷积或者扩张卷积,根据
空间、通道激励,在解码器或bottleneck中选择加入attention模块或者SE模块.
2) 针对提升计算速度的问题,可以采用的基本结构包括扩张卷积、残差结构、SE残差块等;主要改进的
特殊结构包括从编解码器单元加入稠密模块或者可逆结构,对于损失函数可选择Dice-based loss.
3) 对于特征融合问题,可以将网络编码器按照不同模态分别提取特征再进行总体融合,不同模态之间加
入稠密卷积,增加信息流减少参数,或者解码器外接特征金子塔辅助特征融合.
Table 5 Suggestions on using structure for different problems
表5 针对不同问题的使用结构建议
解决问题 基本结构 特殊结构 放置位置 损失函数
分割 扩张卷积、可形变 attention decoder或者
−
微小细节 卷积、残差结构 机制、SE块 bottleneck
提升 扩张卷积、残差 稠密卷积、 编解码器单元、 Dice-based loss
计算速度 结构、SE残差块 可逆结构 上采样、下采样 or Dice loss
Inception、金字塔 编解码器、
特征融合 残差结构 −
特征图、稠密卷积 跳连、外接
综上所述,本文分类总结和分析了基于 U-Net 结构改进的医学图像分割方法,从改进的性能指标目的和改
进的主要结构特点,对主要的相关工作进行了总结和介绍.基于对现有工作的综述,提炼出基于 U-Net 进行结构
改进的一些常用改进模块和常用改进方法,可以作为未来这个领域研究工作的参考.对于 U-Net 的未来应用,U-
Net 不仅应用于医学影像分割,在其他领域也有较好的应用效果,例如应用于人群识别的 W-net[90],应用于航空
图像的ResUNet-a[91]、TernausNet[85]、FlowS-Unet[92]、ST-Unet[93]等多种改进方法.将U-Net扩展到更多的应用
领域,并进一步提升U-Net的特征提取和识别准确性,提高计算效率,是未来可行的研究方向.
References:
[1] Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation. In: Proc. of the Int’l Conf.
on Medical Image Computing and Computer-assisted Intervention (MICCAI 2015). 2015. 234−241.
[2] Milletari F, Navab N, Ahmadi S, et al. V-net: Fully convolutional neural networks for volumetric medical image segmentation. In:
Proc. of the Int’l Conf. on 3D Vision. 2016. 565−571.
[3] Cicek O, Abdulkadir A, Abdulkadir A, et al. 3D U-net: Learning dense volumetric segmentation from sparse annotation. In: Proc.
of the Medical Image Computing and Computer-assisted Intervention. 2016. 424−432.
[4] Roy AG, Navab N, Navab N, et al. Concurrent spatial and channel ‘squeeze & excitation’ in fully convolutional networks. In: Proc.
of the Medical Image Computing and Computer-assisted Intervention. 2018. 421−429.
[5] Oktay O, Schlemper J, Folgoc LL, et al. Attention U-net: Learning where to look for the pancreas. arXiv:1804.03999, 2018.
[6] Li R, Li M, Li J, et al. Connection sensitive attention U-net for accurate retinal vessel segmentation. arXiv:1903.05558, 2019.
[7] Ni ZL, Bian GB, Zhou XH, et al. RAUNet: Residual attention U-net for semantic segmentation of cataract surgical instruments.
arXiv:1909.10360, 2019.
[8] Zhou Y, Onder OF, Dou Q, et al. CIA-net: Robust nuclei instance segmentation with contour-aware information aggregation. In:
Proc. of the Int’l Conf. on Information Processing in Medical Imaging (IPMI 2019). 2019. 682−693.
[9] Wang C, He Y, Liu Y, et al. ScleraSegNet: An improved U-net model with attention for accurate sclera segmentation. In: Proc. of
the Int’l Conf. on Biometrics. 2019. 1−8.
[10] Wang P, Qiang Y, Yang XT, Hou TX. Double attention 3D-UNet for lung nodule segmentation. Computer Engineering, 2020 (in
Chinese with English abstract). https://doi.org/10.19678/j.issn.1000-3428.0057019 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 547
[11] Li C, Tan Y, Chen W, et al. ANU-Net: Attention-based nested U-Net to exploit full resolution features for medical image
segmentation. Computers and Graphics, 2020,90:11−20.
[12] Xu HW, Yan PX, Wu M, Xu ZY, Sun YB. Automated segmentation of cystic kidney in CT images using residual double attention
motivated U-Net model. Application Research of Computers, 2020,37(7):2237−2240 (in Chinese with English abstract).
[13] Lee S, Negishi M, Urakubo H, et al. Mu-Net: Multi-scale U-net for two-photon microscopy image denoising and restoration.
Neural Networks, 2020,125:92−103.
[14] Li X, Chen H, Qi X, et al. H-DenseUNet: Hybrid densely connected UNet for liver and tumor segmentation from CT volumes.
IEEE Trans. on Medical Imaging, 2018,37(12):2663−2674.
[15] Hong YJ, Meng TB, Li HJ, Liu LZ, Xu SY, Guo SW. Deep segmentation method of tumor boundaries from MR images of patients
with nasopharyngeal carcinoma using multi-modality and multi-dimension fusion. Journal of Zhejiang University (Engineering
Science), 2020,54(3):566−573 (in Chinese with English abstract).
[16] Guan S, Khan AA, Sikdar S, et al. Fully dense UNet for 2D sparse photoacoustic tomography artifact removal. IEEE Journal of
Biomedical and Health Informatics, 2020,24(2):568−576.
[17] Brügger R, Baumgartner CF, Konukoglu E. A partially reversible U-net for memory-efficient volumetric image segmentation. In:
Shen D, et al., eds. Proc. of the Int’l Conf. on Medical Image Computing and Computer Assisted Intervention (MICCAI 2019).
Springer-Verlag, 2019.
[18] Chen C, Liu X, Ding M, et al. 3D dilated multi-fiber network for real-time brain tumor segmentation in MRI. In: Proc. of the Int’l
Conf. on MICCAI 2019. 2019. 184−192.
[19] Ibtehaz N, Rahman MS. MultiResUNet: Rethinking the U-net architecture for multimodal biomedical image segmentation. arXiv:
1902.04049v1, 2019.
[20] Zhang Z, Wu C, Coleman S, et al. DENSE-INception U-net for medical image segmentation. Computer Methods and Programs in
Biomedicine, 2020,192:Article No.105395.
[21] Li J, Lin X, Che H, et al. Probability map guided bi-directional recurrent UNet for pancreas segmentation. arXiv:1903.00923, 2019.
[22] Xu BQ, Ling TH. Automatic segmentation algorithm for single organ of CT images based on cascaded Vnet-S network. Journal of
Computer Applications, 2019,39(8):2420−2425 (in Chinese with English abstract).
[23] Zhou Z, Siddiquee MR, Tajbakhsh N, et al. UNet++: A nested U-net architecture for medical image segmentation. arXiv:1807.
10165, 2018.
[24] Yang B, Liu XF, Zhang J. Medical image segmentation based on deep feature aggregation network. Computer Engineering, 2020
(in Chinese with English abstract). http://kns.cnki.net/kcms/detail/31.1289.TP.20200407.0948.001.html
[25] Moradi S, Oghli MG, Alizadehasl A, et al. MFP-Unet: A novel deep learning based approach for left ventricle segmentation in
echocardiography. Physica Medica, 2019,67:58−69.
[26] Lachinov D, Vasiliev E, Turlapov V, et al. Glioma segmentation with cascaded UNet. arXiv:1810.04008, 2018.
[27] Dolz J, Ayed IB, Desrosiers C, et al. Dense multi-path U-net for ischemic stroke lesion segmentation in multiple image modalities.
arXiv:1810.07003, 2018.
[28] Dolz J, Desrosiers C, Ayed IB, et al. IVD-Net: Intervertebral disc localization and segmentation in MRI with a multi-modal UNet.
arXiv:1811.08305, 2018.
[29] Jin Q, Meng Z, Sun C, et al. RA-UNet: A hybrid deep attention-aware network to extract liver and tumor in CT scans. arXiv:1811.
01328, 2018.
[30] Keetha NV, Babu PSA, Annavarapu CSR. U-Det: A modified U-Net architecture with bidirectional feature network for lung nodule
segmentation. arXiv:2003.09293, 2020.
[31] Wang W, Yu K, Hugonot J, et al. Recurrent U-net for resource-constrained segmentation. arXiv preprint arXiv:1906.04913, 2019.
[32] Chen W, Zhang Y, He J, et al. Prostate segmentation using 2D bridged U-net. In: Proc. of the Int’l Joint Conf. on Neural Network.
2019. 1−7.
[33] Orlando JI, Seebock P, Bogunovic H, et al. U2-Net: A Bayesian U-net model with epistemic uncertainty feedback for photoreceptor
layer segmentation in pathological oct scans. In: Proc. of the Int’l Symp. on Biomedical Imaging. 2019. 1441−1445. 548 Journal of Software 软件学报 Vol.32, No.2, February 2021
[34] Dubost F, Bortsova G, Adams HH, et al. GP-Unet: Lesion detection from weak labels with a 3D regression network. In: Proc. of
the Medical Image Computing and Computer-assisted Intervention. 2017. 214−221.
[35] Huang C, Huang C, Han H, et al. 3D U2-net: A 3D universal U-net for multi-domain medical image segmentation. In: Proc. of the
Medical Image Computing and Computer-assisted Intervention. 2019. 291−299.
[36] Yan W, Wang Y, Gu S, et al. The domain shift problem of medical image segmentation and vendor-adaptation by Unet-GAN. In:
Proc. of the Medical Image Computing and Computer-assisted Intervention. 2019. 623−631.
[37] Wang W, Chen J, Zhao J, et al. Automated segmentation of pulmonary lobes using coordination-guided deep neural networks. In:
Proc. of the Int’l Symp. on Biomedical Imaging. 2019. 1353−1357.
[38] Clerigues A, Valverde S, Bernal J, et al. Acute and sub-acute stroke lesion segmentation from multimodal MRI. arXiv:1810.13304,
2018.
[39] Jin Q, Meng Z, Meng Z, et al. DUNet: A deformable network for retinal vessel segmentation. arXiv:1811.01206v1, 2018.
[40] Jiang HD, Ye XN. An improved skin disease image segmentation algorithm based on I-Unet network, Modern Electronics
Technique, 2019,42(12):52−56 (in Chinese with English abstract).
[41] He CE, Xu HJ, Wang Z, et al. Automatic segmentation algorithm for multimodal magnetic resonance-based brain tumor images.
Acta Optica Sinica, 2020,40(6):66−75 (in Chinese with English abstract).
[42] Alom MZ, Hasan M, Yakopcic C, et al. Recurrent residual convolutional neural network based on U-net (R2U-net) for medical
image segmentation. arXiv:1802.06955, 2018.
[43] Kohl SA, Romeraparedes B, Maierhein KH, et al. A hierarchical probabilistic U-net for modeling multi-scale ambiguities.
arXiv:1905.13077, 2019.
[44] Hasan SM, Linte CA. U-NetPlus: A modified encoder-decoder U-net architecture for semantic and instance segmentation of
surgical instrument. arXiv:1902.08994, 2019.
[45] Wang Z, Zou N, Shen D, et al. Non-local U-Nets for biomedical image segmentation. In: Proc. of the AAAI Conf. on Artificial
Intelligence. 2020. 6315−6322.
[46] Zhu W, Huang Y, Zeng L, et al. AnatomyNet: Deep learning for fast and fully automated whole‐volume segmentation of head and
neck anatomy. arXiv:1808.05238v2, 2019.
[47] Abraham N, Khan NM. A novel focal Tversky loss function with improved attention U-net for lesion segmentation. In: Proc. of the
Int’l Symp. on Biomedical Imaging. 2019. 683−687.
[48] Zhong SH, Guo XM, Zheng YN. Improved U-Net network for lung nodule segmentation. Computer Engineering and Applications,
2020,56(17):203−209 (in Chinese with English abstract).
[49] Zhuang J. LadderNet: Multi-path networks based on U-net for medical image segmentation. arXiv:1810.07810, 2018.
[50] Song LI, Tso GK, Kaijian HE, et al. Bottleneck feature supervised U-net for pixel-wise liver and tumor segmentation. arXiv:1810.
10331, 2020.
[51] Zhang J, Jin Y, Xu J, et al. MDU-Net: Multi-scale densely connected U-net for biomedical image segmentation. arXiv:1812.00352,
2018.
[52] Wong KC, Moradi M. SegNAS3D: Network architecture search with derivative-free global optimization for 3D image
segmentation. arXiv:1909.05962, 2019.
[53] Foody GM. Status of land cover classification accuracy assessment. Remote Sensing of Environment, 2002,80(1):185−201.
[54] Jaccard P. The distribution of the flora in the alpine zone. New Phytologist, 1912,11(2):37−50.
[55] Horé A, Ziou D. Image quality metrics: PSNR vs. SSIM. In: Proc. of the 20th Int’l Conf. on Pattern Recognition (ICPR 2010).
Istanbul: IEEE Computer Society, 2010. 2366−2369. [doi: 10.1109/ICPR.2010.579]
[56] Lin TY, Goyal P, Girshick R, et al. Focal loss for dense object detection. arXiv:1708.02002, 2017.
[57] Physica A, Boris Podobnik A, Jia Shao C, et al. Features of similarity. Psychological Review,1977,84(4):327−352.
[58] Salehi SS, Salehi SS, Erdogmus D, et al. Tversky loss function for image segmentation using 3D fully convolutional deep networks.
arXiv:1706.05721, 2017.
[59] Hu J, Shen L, Albanie S, et al. Squeeze-and-excitation networks. IEEE Trans. on Pattern Analysis and Machine Intelligence, 2020,
42(8):2011−2023. [doi: 10.1109/TPAMI.2019.2913372] 殷晓航 等:基于U-Net结构改进的医学影像分割技术综述 549
[60] Dou Q, Yu L, Chen H, et al. 3D deeply supervised network for automated segmentation of volumetric medical images. Medical
Image Analysis, 2017,41(41):40−54.
[61] Park J, Woo S, Lee J, et al. BAM: Bottleneck attention module. arXiv:1807.06514, 2018.
[62] Woo S, Park J, Lee J, et al. CBAM: Convolutional block attention module. In: Proc. of the European Conf. on Computer Vision.
2018. 3−19.
[63] Tian Z, He T, Shen C, et al. Decoders matter for semantic segmentation: Data-dependent decoding enables flexible feature
aggregation. In: Proc. of the Computer Vision and Pattern Recognition. 2019. 3126−3135.
[64] Liu Z, Song Y, Sheng VS, et al. Liver CT sequence segmentation based with improved U-Net and graph cut. Expert Systems with
Applications, 2019,126:54−63.
[65] Boykov Y, Veksler O. Graph Cuts in Vision and Graphics: Theories and Applications. Springer-Verlag, 2006. 79−96.
[66] Huang G, Liu Z, Laurens VDM, et al. Densely connected convolutional networks. In: Proc. of the IEEE Conf. on Computer Vision
and Pattern Recognition (CVPR). 2017. 2261−2269.
[67] Tu Z. Auto-context and its application to high-level vision tasks. In: Proc. of the Computer Vision and Pattern Recognition. 2008.
1−8.
[68] Ntziachristos V, Ripoll J, Wang LV, et al. Looking and listening to light: The evolution of whole-body photonic imaging. Nature
Biotechnology, 2005,23(3):313−320.
[69] Gomez AN, Ren M, Urtasun R, et al. The reversible residual network: Backpropagation without storing activations. In: Proc. of the
Neural Information Processing Systems. 2017. 2214−2224.
[70] Chen Y, Kalantidis Y, Li J, et al. Multi-fiber networks for video recognition. In: Proc. of the European Conf. on Computer Vision.
2018. 364−380.
[71] Szegedy C, Vanhoucke V, Ioffe S, et al. Rethinking the inception architecture for computer vision. In: Proc. of the Computer
Vision and Pattern Recognition. 2016. 2818−2826.
[72] Szegedy C, Liu W, Jia Y, et al. Going deeper with convolutions. In: Proc. of the Computer Vision and Pattern Recognition. 2015.
1−9.
[73] Gu Z, Cheng J, Fu H, et al. CE-Net: Context encoder network for 2D medical image segmentation. IEEE Trans. on Medical
Imaging, 2019,38(10):2281−2292.
[74] Szegedy C, Ioffe S, Vanhoucke V, et al. Inception-v4, inception-ResNet and the impact of residual connections on learning. In:
Proc. of the National Conf. on Artificial Intelligence. 2016. 4278−4284.
[75] Wang F, Jiang M, Qian C, et al. Residual attention network for image classification. In: Proc. of the Computer Vision and Pattern
Recognition. 2017. 6450−6458.
[76] Tan M, Pang R, Le QV, et al. EfficientDet: Scalable and efficient object detection. arXiv:1911.09070, 2019.
[77] Li M, Dong S, Gao Z, et al. Unified model for interpreting multi-view echocardiographic sequences without temporal information.
Applied Soft Computing, 2020,88:Article No.106049.
[78] Lin T, Dollar P, Girshick R, et al. Feature pyramid networks for object detection. In: Proc. of the Computer Vision and Pattern
Recognition. 2017. 936−944.
[79] Wang Z, Bovik AC, Sheikh HR, et al. Image quality assessment: from error visibility to structural similarity. IEEE Trans. on Image
Processing, 2004,13(4):600−612.
[80] Cho K, Van Merrienboer B, Bahdanau D, et al. On the properties of neural machine translation: Encoder-decoder approaches. In:
Proc. of the Empirical Methods in Natural Language Processing. 2014. 103−111.
[81] Liu R, Lehman J, Molino P, et al. An intriguing failing of convolutional neural networks and the CoordConv solution. In: Proc. of
the Neural Information Processing Systems. 2018. 9605−9616.
[82] Dai J, Qi H, Xiong Y, et al. Deformable convolutional networks. In: Proc. of the Int’l Conf. on Computer Vision. 2017. 764−773.
[83] Yu F, Koltun V, Funkhouser T, et al. Dilated residual networks. In: Proc. of the Computer Vision and Pattern Recognition. 2017.
636−644.
[84] Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition. arXiv:1409.1556, 2015. 550 Journal of Software 软件学报 Vol.32, No.2, February 2021
[85] Iglovikov V, Shvets AA. TernausNet: U-net with VGG11 encoder pre-trained on ImageNet for image segmentation. arXiv:1801.
05746, 2018.
[86] He K, Girshick R, Dollar P, et al. Rethinking ImageNet pre-training. In: Proc. of the 2019 IEEE/CVF Int’l Conf. on Computer
Vision (ICCV). 2019. 4917−4926. [doi: 10.1109/ICCV.2019.00502]
[87] Liu H, Simonyan K, Yang Y, et al. DARTS: Differentiable architecture search. In: Proc. of the Int’l Conf. on Learning
Representations. 2019.
[88] He K, Zhang X, Ren S, et al. Deep residual learning for image recognition. In: Proc. of the Computer Vision and Pattern
Recognition. 2016. 770−778.
[89] Li X, Wang W, Hu X, et al. Selective kernel networks. In: Proc. of the Computer Vision and Pattern Recognition. 2019. 510−519.
[90] Valloli VK, Mehta K. W-Net: Reinforced U-net for density map estimation. arXiv:1903.11249, 2019.
[91] Diakogiannis FI, Waldner F, Caccetta P, et al. ResUNet-a: A deep learning framework for semantic segmentation of remotely
sensed data. arXiv:1904.00592, 2019.
[92] Gu L, Xu SQ, Zhu LQ. Detection of building changes in remote sensing images via FlowS-Unet. Acta Automatica Sinica, 2020,
46(6):1291−1300 (in Chinese with English abstract).
[93] Yu B, Yin H, Zhu Z, et al. ST-UNet: A spatio-temporal U-network for graph-structured time series modeling. arXiv:1903.05631,
2019.
附中文参考文献:
[10] 王磐,强彦,杨晓棠,侯腾璇.双注意力 3D-UNet 肺结节分割网络.计算机工程,2020. https://doi.org/10.19678/j.issn.1000-3428.005
7019
[12] 徐宏伟,闫培新,吴敏,徐振宇,孙玉宝.基于残差双注意力U-Net模型的CT图像囊肿肾脏自动分割.计算机应用研究,2020,37(7):
2237−2240.
[15] 洪炎佳,孟铁豹,黎浩江,刘立志,徐硕瑀,郭圣文.多模态多维信息融合的鼻咽癌 MR 图像肿瘤深度分割方法.浙江大学学报(工学
版),2020,54(3):566−573.
[22] 徐宝泉,凌彤辉.基于级联Vnet-S网络的CT影像单一器官自动分割算法.计算机应用,2019,39(8):2420−2425.
[24] 杨兵,刘晓芳,张纠.基于深度特征聚合网络的医学图像分割.计算机工程,2020. http://kns.cnki.net/kcms/detail/31.1289.TP.202004
07.0948.001.html
[40] 蒋宏达,叶西宁.一种改进的I-Unet网络的皮肤病图像分割算法.现代电子技术,2019,42(12):52−56.
[41] 何承恩,徐慧君,王忠,等.多模态磁共振脑肿瘤图像自动分割算法研究.光学学报,2020,40(6):66−75.
[48] 钟思华,郭兴明,郑伊能.改进U-Net网络的肺结节分割方法.计算机工程与应用,2020,56(17):203−209.
[92] 顾炼,许诗起,竺乐庆.基于flows-UNet的遥感图像建筑物变化检测.自动化学报,2020,46(6):1291−1300.
殷晓航(1995－),女,硕士生,主要研究领域 李德英(1965－),女,博士,教授,博士生导
为深度学习,医学图像分割. 师,CCF高级会员,主要研究领域为传感器
网络,社会网络,图优化理论与算法,算法
设计与分析.
王永才(1978－),男,博士,副教授,博士生
导师,CCF专业会员,主要研究领域为物联
网,智能感知,网络定位,视觉感知,惯导融
合定位. --------------------------------------------------------------------------------- 第４０卷 第４期 计 算 机 学 报 Ｖｏｌ．４０ Ｎｏ．４
２０１７年４月 ＣＨＩＮＥＳＥ ＪＯＵＲＮＡＬ ＯＦ ＣＯＭＰＵＴＥＲＳ Ａｐｒ．２０１７
基于位置社交网络的上下文感知的兴趣点推荐
任星怡 宋美娜 宋俊德
（北京邮电大学计算机学院信息网络工程研究中心教育部重点实验室 北京 １００８７６）
摘 要 随着基于位置社交网络（Ｌｏｃａｔｉｏｎ－Ｂａｓｅｄ Ｓｏｃｉａｌ Ｎｅｔｗｏｒｋｓ，ＬＢＳＮ）的快速发展，兴趣点（Ｐｏｉｎｔ－ｏｆ－Ｉｎｔｅｒｅｓｔ，
ＰＯＩ）推荐为基于位置的服务提供了前所未有的机会．兴趣点推荐是一种基于上下文信息的位置感知的个性化推
荐．然而用户－兴趣点矩阵的极端稀疏给兴趣点推荐的研究带来严峻挑战．为处理数据稀疏问题，文中利用兴趣点的
地理、文本、社会、分类与流行度信息，并将这些因素进行有效地融合，提出一种上下文感知的概率矩阵分解兴趣点推
荐算法，称为ＴＧＳＣ－ＰＭＦ．首先利用潜在狄利克雷分配（Ｌａｔｅｎｔ Ｄｉｒｉｃｈｌｅｔ Ａｌｌｏｃａｔｉｏｎ，ＬＤＡ）模型挖掘兴趣点相关的文
本信息学习用户的兴趣话题生成兴趣相关分数；其次提出一种自适应带宽核评估方法构建地理相关性生成地理相
关分数；然后通过用户社会关系的幂律分布构建社会相关性生成社会相关分数；另外结合用户的分类偏好与兴趣
点的流行度构建分类相关性生成分类相关分数，最后利用概率矩阵分解模型（Ｐｒｏｂａｂｉｌｉｓｔｉｃ Ｍａｔｒｉｘ Ｆａｃｔｏｒｉｚａｔｉｏｎ，
ＰＭＦ），将兴趣、地理、社会、分类的相关分数进行有效地融合，从而生成推荐列表推荐给用户感兴趣的兴趣点．该文
在一个真实ＬＢＳＮ签到数据集上进行实验，结果表明该算法相比其他先进的兴趣点推荐算法具有更好的推荐效果．
关键词 基于位置的社交网络；兴趣点推荐；话题模型；地理相关性；社会相关性；分类相关性；社会媒体
中图法分类号 ＴＰ３１１ ＤＯＩ号 １０．１１８９７／ＳＰ．Ｊ．１０１６．２０１７．００８２４
Ｃｏｎｔｅｘｔ－Ａｗａｒｅ Ｐｏｉｎｔ－ｏｆ－Ｉｎｔｅｒｅｓｔ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ
ｉｎ Ｌｏｃａｔｉｏｎ－Ｂａｓｅｄ Ｓｏｃｉａｌ Ｎｅｔｗｏｒｋｓ
ＲＥＮ Ｘｉｎｇ－Ｙｉ ＳＯＮＧ Ｍｅｉ－Ｎａ ＳＯＮＧ Ｊｕｎ－Ｄｅ
（Ｅｎｇｉｎｅｅｒｉｎｇ Ｒｅｓｅａｒｃｈ Ｃｅｎｔｅｒ ｏｆ Ｉｎｆｏｒｍａｔｉｏｎ Ｎｅｔｗｏｒｋｓ，Ｍｉｎｉｓｔｒｙ ｏｆ Ｅｄｕｃａｔｉｏｎ，Ｓｃｈｏｏｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ，
Ｂｅｉｊｉｎｇ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｐｏｓｔｓ ａｎｄ Ｔｅｌｅｃｏｍｍｕｎｉｃａｔｉｏｎｓ，Ｂｅｉｊｉｎｇ １００８７６）
Ａｂｓｔｒａｃｔ Ｔｈｅ ｒａｐｉｄ ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ ｌｏｃａｔｉｏｎ－ｂａｓｅｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ（ＬＢＳＮｓ）ｈａｓ ｐｒｏｖｉｄｅｄ ａｎ
ｕｎｐｒｅｃｅｄｅｎｔｅｄ ｏｐｐｏｒｔｕｎｉｔｙ ｆｏｒ ｂｅｔｔｅｒ ｌｏｃａｔｉｏｎ－ｂａｓｅｄ ｓｅｒｖｉｃｅｓ ｔｈｒｏｕｇｈ Ｐｏｉｎｔ－ｏｆ－Ｉｎｔｅｒｅｓｔ（ＰＯＩ）
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．ＰＯＩ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｉｓ ａ ｐｅｒｓｏｎａｌｉｚｅｄ，ｌｏｃａｔｉｏｎ－ａｗａｒｅ，ａｎｄ ｃｏｎｔｅｘｔ ｄｅｐｅｎｄｅｄ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．Ｈｏｗｅｖｅｒ，ｅｘｔｒｅｍｅ ｓｐａｒｓｉｔｙ ｏｆ ｕｓｅｒ－ＰＯＩ ｍａｔｒｉｘ ｃｒｅａｔｅｓ ａ ｓｅｖｅｒｅ ｃｈａｌｌｅｎｇｅ．Ｉｎ
ｔｈｉｓ ｐａｐｅｒ，ｗｅ ｐｒｏｐｏｓｅ ａ ｃｏｎｔｅｘｔ－ａｗａｒｅ ｐｒｏｂａｂｉｌｉｓｔｉｃ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ ｍｅｔｈｏｄ ｃａｌｌｅｄ ＴＧＳＣ－
ＰＭＦ ｆｏｒ ＰＯＩ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ，ｅｘｐｌｏｉｔｉｎｇ ｇｅｏｇｒａｐｈｉｃａｌ ｉｎｆｏｒｍａｔｉｏｎ，ｔｅｘｔ ｉｎｆｏｒｍａｔｉｏｎ，ｓｏｃｉａｌ
ｉｎｆｏｒｍａｔｉｏｎ，ｃａｔｅｇｏｒｉｃａｌ ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ ｐｏｐｕｌａｒｉｔｙ ｉｎｆｏｒｍａｔｉｏｎ，ｉｎｃｏｒｐｏｒａｔｉｎｇ ｔｈｅｓｅ ｆａｃｔｏｒｓ
ｅｆｆｅｃｔｉｖｅｌｙ．Ｆｉｒｓｔ，ｗｅ ｅｘｐｌｏｉｔ ａｎ ａｇｇｒｅｇａｔｅｄ Ｌａｔｅｎｔ Ｄｉｒｉｃｈｌｅｔ Ａｌｌｏｃａｔｉｏｎ（ＬＤＡ）ｍｏｄｅｌ ｔｏ ｌｅａｒｎ ｔｈｅ
ｉｎｔｅｒｅｓｔ ｔｏｐｉｃｓ ｏｆ ｕｓｅｒｓ ａｎｄ ｉｎｆｅｒ ｔｈｅ ｉｎｔｅｒｅｓｔ ＰＯＩｓ ｂｙ ｍｉｎｉｎｇ ｔｅｘｔｕａｌ ｉｎｆｏｒｍａｔｉｏｎ ａｓｓｏｃｉａｔｅｄ ｗｉｔｈ
ＰＯＩｓ ａｎｄ ｇｅｎｅｒａｔｅ ｉｎｔｅｒｅｓｔ ｒｅｌｅｖａｎｃｅ ｓｃｏｒｅ．Ｓｅｃｏｎｄ，ｗｅ ｐｒｏｐｏｓｅ ａ ｋｅｒｎｅｌ ｅｓｔｉｍａｔｉｏｎ ｍｅｔｈｏｄ ｗｉｔｈ
ａｎ ａｄａｐｔｉｖｅ ｂａｎｄｗｉｄｔｈ ｔｏ ｍｏｄｅｌ ｔｈｅ ｇｅｏｇｒａｐｈｉｃａｌ ｃｏｒｒｅｌａｔｉｏｎｓ ａｎｄ ｇｅｎｅｒａｔｅ ｇｅｏｇｒａｐｈｉｃａｌ ｒｅｌｅｖａｎｃｅ
ｓｃｏｒｅ．Ｔｈｉｒｄ，ｗｅ ｂｕｉｌｄ ｓｏｃｉａｌ ｒｅｌｅｖａｎｃｅ ｔｈｒｏｕｇｈ ｔｈｅ ｐｏｗｅｒ－ｌａｗ ｄｉｓｔｒｉｂｕｔｉｏｎ ｏｆ ｕｓｅｒ ｓｏｃｉａｌ ｒｅｌａｔｉｏｎｓ
ｔｏ ｇｅｎｅｒａｔｅ ｓｏｃｉａｌ ｒｅｌｅｖａｎｃｅ ｓｃｏｒｅ．Ｔｈｅｎ，ｗｅ ｍｏｄｅｌ ｔｈｅ ｃａｔｅｇｏｒｉｃａｌ ｃｏｒｒｅｌａｔｉｏｎｓ ｗｈｉｃｈ ｃｏｍｂｉｎｅ ｔｈｅ
ｃａｔｅｇｏｒｙ ｂｉａｓ ｏｆ ｕｓｅｒｓ ａｎｄ ｔｈｅ ｐｏｐｕｌａｒｉｔｙ ｏｆ ＰＯＩｓ ｉｎｔｏ ｃａｔｅｇｏｒｉｃａｌ ｒｅｌｅｖａｎｃｅ ｓｃｏｒｅ．Ｆｕｒｔｈｅｒ，ｗｅ
收稿日期：２０１６－０５－１８；在线出版日期：２０１６－０９－２８．本课题得到国家科技重点支撑项目（２０１４ＢＡＫ１５Ｂ０１）资助．任星怡，女，１９８３年生，博
士研究生，主要研究方向为推荐系统、数据挖掘、大数据．Ｅ－ｍａｉｌ：ｘｙｒｅｎ＠ｂｕｐｔ．ｅｄｕ．ｃｎ．宋美娜，女，１９７４年生，博士，教授，主要研究领域
为服务计算、云计算、超大规模信息服务系统．宋俊德，男，１９３８年生，博士，教授，主要研究领域为服务科学与工程、云计算、大数据、物联
网、ＩＣＴ关键技术．
书书书 ４期 任星怡等：基于位置社交网络的上下文感知的兴趣点推荐 ８２５
ｅｘｐｌｏｉｔ ｐｒｏｂａｂｉｌｉｓｔｉｃ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ ｍｏｄｅｌ（ＰＭＦ）ｔｏ ｉｎｔｅｇｒａｔｅ ｔｈｅ ｉｎｔｅｒｅｓｔ，ｇｅｏｇｒａｐｈｉｃａｌ，
ｓｏｃｉａｌ ａｎｄ ｃａｔｅｇｏｒｉｃａｌ ｒｅｌｅｖａｎｃｅ ｓｃｏｒｅｓ ｆｏｒ ＰＯＩ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．Ｆｉｎａｌｌｙ，ｗｅ ｉｍｐｌｅｍｅｎｔ ｅｘｐｅｒｉｍｅｎｔｓ
ｏｎ ａ ｒｅａｌ ＬＢＳＮ ｃｈｅｃｋ－ｉｎ ｄａｔａｓｅｔ．Ｅｘｐｅｒｉｍｅｎｔａｌ ｒｅｓｕｌｔｓ ｓｈｏｗ ｔｈａｔ ＴＧＳＣ－ＰＭＦ ａｃｈｉｅｖｅｓ ｓｉｇｎｉｆｉｃａｎｔｌｙ
ｓｕｐｅｒｉｏｒ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｑｕａｌｉｔｙ ｃｏｍｐａｒｅ ｔｏ ｏｔｈｅｒ ｓｔａｔｅ－ｏｆ－ｔｈｅ－ａｒｔ ＰＯＩ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｔｅｃｈｎｉｑｕｅｓ．
Ｋｅｙｗｏｒｄｓ ｌｏｃａｔｉｏｎ－ｂａｓｅｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋ；ｐｏｉｎｔ－ｏｆ－ｉｎｔｅｒｅｓｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ；ｔｏｐｉｃ ｍｏｄｅｌ；
ｇｅｏｇｒａｐｈｉｃａｌ ｃｏｒｒｅｌａｔｉｏｎｓ；ｓｏｃｉａｌ ｃｏｒｒｅｌａｔｉｏｎｓ；ｃａｔｅｇｏｒｉｃａｌ ｃｏｒｒｅｌａｔｉｏｎｓ；ｓｏｃｉａｌ ｍｅｄｉａ
相比传统推荐系统的发展，兴趣点推荐系统的
１ 引 言 发展更加复杂．兴趣点推荐面临一些新的挑战．首
先，用户－兴趣点的签到矩阵是高稀疏的，因为在基
随着城市的快速发展，兴趣点（如商场、餐厅、博 于位置的社交网络中用户访问兴趣点只占有非常小
物馆、娱乐场所、酒店、旅游景点等）的数量也随之增 的比例，因此兴趣点推荐面临数据稀疏性问题［５］．其
长，它为人们提供了更多体验生活的机会．在日常生 次，随着不同的时间与不同的地理位置，用户的兴趣
活中，人们通常喜欢探索居住城市与邻近的地方，根 是动态变化的．然后，兴趣点推荐包含不同类型的上
据自己的个人兴趣选择与自己偏好相关的兴趣点． 下文信息，如兴趣点的文本信息、兴趣点的地理坐
由于兴趣点与用户偏好的数据中包含大量有价值的 标、用户的签到时间、用户的社会关系、兴趣点的分
信息，可以用于兴趣点推荐中［１］．同时在大量的兴趣 类信息、兴趣点的流行度等，与传统推荐不同的是兴
点中如何有效地帮用户做出满意的决策是一个困难 趣点相关的文本信息是不完整的且模糊的．
的问题，通常被认为“选择麻痹”．为了解决这个问 依据上述挑战，本文提出一种上下文感知的概
题，兴趣点推荐任务将帮助用户过滤掉不感兴趣的 率矩阵分解兴趣点推荐算法，并结合兴趣话题、地理
位置并减少决策时间［２］． 相关性、社会相关性与分类相关性．
基于位置服务应用的日益流行，关于空间、时间、 本文中我们的贡献总结如下：
社会和内容等方面的兴趣点推荐，基于位置的社交网 （１）本文利用兴趣点的地理、文本、社会、分类
络为研究人们移动行为提供了前所未有的机会［３］．典 与流行度信息，并有效地融合这些因素，提出一种上
型的基于位置的社交网站，如国外的Ｆｏｕｒｓｑｕａｒｅ、 下文感知的兴趣点推荐算法，称为ＴＧＳＣ－ＰＭＦ．
Ｙｅｌｐ、Ｇｏｗａｌｌａ，国内的街旁、嘀咕等，人们可以使用 （２）本文利用主题模型挖掘兴趣点相关的文本
智能手机、平板电脑等移动设备对当前访问的兴趣 信息，学习用户的兴趣话题；提出一种自适应带宽核
点签到，并与好友分享自己的签到信息和体验，导致 评估方法确定用户的个性化兴趣点签到分布，构建
“Ｗ４”的信息布局（即什么人、什么地点、什么时间、 兴趣点之间的地理相关性；通过用户社会关系的幂
什么事件），对应４个不同层次的信息［４］．的确，兴趣 律分布构建用户之间的社会相关性；结合用户的分
点推荐服务旨在为用户推荐一些新的感兴趣的位 类偏好与兴趣点的流行度构建分类相关性．
置，基于位置社交网络的兴趣点推荐为人们提供更 （３）本文提出一种分数匹配方法，将兴趣相关
好的定位服务起着重要的作用． 分数、地理相关分数、社会相关分数以及分类相关分
不同于传统推荐任务，兴趣点推荐是一个基于 数进行有效地匹配，然后将匹配后的偏好分数融合
上下文信息的位置感知的个性化推荐．通过下面的 到概率矩阵分解模型中，从而提出一种新的上下文
场景进行详细描述．例如，星怡居住在中国北京，早 感知的概率矩阵分解算法进行兴趣点推荐．
晨她通常会去她家附近的庆丰包子铺吃早餐，中午 （４）本文使用一个真实的ＬＢＳＮ签到数据集进
她通常会去她工作地点附近的东北风味餐馆吃午 行大量的实验评估 ＴＧＳＣ－ＰＭＦ的推荐效果，实验
餐，晚上在回家之前她通常会约她的朋友去酒吧娱 结果证明ＴＧＳＣ－ＰＭＦ优于其他先进的兴趣点推荐
乐，周末她有时会与家人去朝阳公园散步或者去西单 技术．
购物．现在，如果星怡想去杭州度假，那么在旅行中什 本文第２节介绍ＬＢＳＮ中兴趣点推荐技术的相
么样的兴趣点她会感兴趣呢？这样的兴趣点推荐一 关工作；第３节提出ＴＧＳＣ－ＰＭＦ兴趣点推荐算法；
定是基于上下文信息的位置感知的个性化推荐． 第４节介绍实验的方案设计与性能对比，验证该算 ８２６ 计 算 机 学 报 ２０１７年
法的有效性；第５节总结并探讨将来的研究工作． 人［１９］利用话题模型研究社会媒体用户的兴趣并推
荐给与用户兴趣相似的新朋友．由于兴趣点相关的
２ 相关工作 文本信息通常是不完整的且模糊的，本文利用文本
信息并采用话题模型来处理这个问题．
２．１ 兴趣点推荐 ２．３ 基于地理信息的兴趣点推荐
随着基于位置社交网络的快速发展，兴趣点推 事实上地理邻近性显著地影响用户在兴趣点上
荐可为人们提供更好的基于位置的服务，受到学术 的签到行为，地理信息被集中用于兴趣点推荐．一种
界和工业界的广泛关注．基于记忆的协同过滤技术， 方法是简单地考虑用户当前的位置，过滤离用户较
如基于用户的协同过滤和基于项目的协同过滤被应 远的ＰＯＩｓ［２０－２３］．另一种方法是应用地理潜在特征
用到兴趣点推荐中．Ｙｅ等人［２］关于兴趣点推荐采用 或者主题模型 推断 区域或者 ＰＯＩｓ 的潜在特
线性插值的方法结合地理与社会影响应用到基于用 征［８，１０－２４］．更复杂的方法是评估签到过的ＰＯＩｓ的地
户的协同过滤框架中．Ｌｅｖａｎｄｏｓｋｉ等人［６］考虑旅行 理相关性作为所有用户共同的距离分布，即一种多
的距离并扩展基于项目的协同过滤方法．用户－用户 中心高斯分布［２５］、一种幂律分布［２，１４，２６－３０］或者一种
和项目－项目之间的相似度需要共享的签到数据来 关于每个用户的个性化非参数分布［３１］．特别是，关
计算，并且兴趣点推荐的签到数据具有高稀疏性，基 于每个用户的地理经纬度坐标，当前工作［３２－３３］采用
于记忆的协同过滤方法很容易遭受数据稀疏问题． 固定带宽核密度评估方法建模兴趣点的地理签到分
因此，应用基于记忆的协同过滤技术不能有效地进 布．更进一步，本文提出一种自适应带宽核评估方法
行兴趣点推荐．基于模型的协同过滤技术同样被应 加强已获取的签到分布的能力，预测一个用户与一
用到兴趣点推荐中．Ｌｉｕ等人［７］基于贝叶斯非负矩 个未签到的ＰＯＩ之间的相关分数．
阵分解结合地理影响与文本信息提出一种地理概率 ２．４ 基于社会信息的兴趣点推荐
因素分析框架．但是在他们的工作中，只考虑了显示 利用用户之间的社会关系可以提高基于位置社
反馈．最近，考虑关于签到数据的隐式反馈，Ｌｉａｎ等 交网络的兴趣点推荐系统的质量．因为在ＰＯＩｓ上
人［８］提出一种结合地理影响的加权矩阵分解方法． 社会朋友比陌生人更有可能分享共同的偏好．当前
另外，Ｃａｏ等人［９］通过随机游走方法计算元路径特 大部分研究是从用户之间的社会关系中获取相似
征值，以度量实例路径中的首尾节点间关联度，利用 度，并将其与传统的基于记忆或者基于模型的协同
监督学习方法获得各个特征的权值，计算特定用户 过滤技术相结合．例如，一些文献［２１－２２，３１－３４］将
在兴趣点的签到概率． 用户的相似性无缝连接到基于用户的协同过滤技术
２．２ 基于文本信息的兴趣点推荐 中，然而其他一些研究［２５，３５－３６］利用潜在因素模型的
为了更好地理解ＬＢＳＮ的模式并改善其服务， 权重或者用户之间的相似性作为正则化项．本文利
当前更多的研究开始探索文本信息．一些研究采用 用用户之间的社会相关性，聚集ＰＯＩｓ上用户朋友
话题模型或者地理潜在因素获取区域或者ＰＯＩｓ的 的签到频率或者评价，基于所有用户历史签到数据
潜在特征［１０－１３］．Ｆａｒｒａｈｉ等人［１４］应用话题模型挖掘 来评估社会签到频率或者评价的分布，并将其转换
移动手机的文本数据来识别人们日常位置驱动的行 成社会相关分数．
程．关于基于位置的社交网络，Ｙｅ等人［１５］利用个体 ２．５ 基于分类信息的兴趣点推荐
位置的显示模式和相似位置间的隐式相关性，提出 用户访问过的ＰＯＩｓ的分类信息隐式地显现了
一种用分类标签标注位置的语义注释研究．Ｙｉｎ等 ＰＯＩｓ上的用户行为．利用ＰＯＩｓ的分类信息构建用
人［１６］利用位置与位置相关的文本提出一种潜在地 户的特别偏好是有用的．然而，关于兴趣点推荐只有
理话题分析方法有利于发现有意义的地理话题 ． 少量研究利用分类信息．Ｈｕ等人［２４］利用矩阵分解
Ｆｅｒｒａｒｉ等人［１７］分析Ｔｗｉｔｔｅｒ上的帖子并利用话题 技术结合每个分类的潜在向量，基于ＰＯＩ的分类潜
模型提取城市模式，例如热点地区和人群行为．这些 在向量推算用户对ＰＯＩ的相关分数．Ｌｉｕ等人［２７］将
关于探索文本信息的兴趣点推荐研究，一种直接的 ＰＯＩｓ的分类聚类成组，从用户历史签到数据中构建
方法是结合话题模型的协同过滤技术．Ａｇａｒｗａｌ等 用户－分类转换矩阵替代用户－ＰＯＩ签到矩阵，应用
人［１８］利用每个项目相关的词语和用户特征来正则 矩阵分解技术发现下一个用户可能签到的ｔｏｐ－ｋ分
化项目因素和用户间的相关评分．Ｐｅｎｎａｃｃｈｉｏｔｔｉ等 类．Ｙｉｎｇ等人［３４］通过ＰＯＩｓ上标注的标签获取ＰＯＩｓ ４期 任星怡等：基于位置社交网络的上下文感知的兴趣点推荐 ８２７
的分类权重，基于分类的偏好与权重的内积评估用 为了便于说明，Ｕ＝｛ｕ，ｕ，…，ｕ ｝为用户的集合，
１ ２ Ｍ
户与ＰＯＩｓ间的相关分数．Ｒａｈｉｍｉ等人［３７］通过ＰＯＩ Ｍ代表用户的数量．Ｌ＝｛ｌ，ｌ，…，ｌ｝为ＰＯＩｓ的集
１ ２ Ｎ
的分类信息获取用户的偏好，以此简单识别用户对 合，Ｎ代表ＰＯＩｓ的数量．Ｃ＝｛ｃ，ｃ，…，ｃ｝为分类
１ ２ Ｂ
ＰＯＩ的喜好．Ｚｈａｏ等人［３８］聚类用户到各个社区中， 的集合，Ｂ代表分类的数量．Ｗ＝｛ｗ，ｗ，…，ｗ ｝为
１ ２ Ｖ
每个社区作为加权的分类向量，通过社区中的用户， 文本信息相关的所有唯一词的集合，Ｖ是唯一词的
每个维度代表一个特定的ＰＯＩ分类的签到数量，应 数量．ｒ
ｕｉ，ｌ
ｊ为用户ｕ ｉ在ＰＯＩ ｌ ｊ上的签到频率或者评
用基于用户的协同过滤方法并利用用户所在社区的 价．ｄ 为与ＰＯＩ ｌ相关的文本项目．ｄ 为与用户ｕ
ｌ ｊ ｊ ｕｉ ｉ
分类向量进一步计算用户间的相似性． 签到过的ＰＯＩｓ相关的文本项目．
２．６ 基于流行度信息的兴趣点推荐
ＰＯＩｓ的流行度反映了ＰＯＩｓ所提供的服务和产
品的质量．在兴趣点推荐中利用ＰＯＩｓ的流行度是
有用的．当前大多数研究认为ＰＯＩｓ的流行度为用
户对ＰＯＩｓ的普遍先验喜好．Ｙｉｎｇ等人［３４］对于未签
到的ＰＯＩｓ，在完全二部图中，利用用户的先验喜好
作为用户与ＰＯＩｓ之间的加权边．其它一些研究工
作［５，７，２４，２９］利用地理信息获取先验喜好调整后验喜
好．然而，一方面，在这些研究中，先验喜好不是个性
化的用户偏好．因此，在实践中得益于ＰＯＩｓ的流行
度是有限的．另一方面，当前一些研究［２０，２４，２７，３４，３７］分
开地构建分类的影响和ＰＯＩｓ的流行度，因此，在这
种情况下，关于兴趣点推荐的分类和流行度信息可
能不会被充分利用．本文提出一种融合用户的分类
偏好和ＰＯＩｓ的流行度，并将其转换成用户与ＰＯＩ
间的分类相关分数．
图１ 模型框架
３ 上下文感知的兴趣点推荐
定义１． 签到矩阵．给定一个ＬＢＳＮ上的ＰＯＩｓ
的用户历史签到数据，构建一个签到矩阵Ｒ ，
｜Ｕ｜×｜Ｌ｜
３．１ 问题陈述与模型框架 矩阵中的每个元素ｒ ｕｉ，ｌ ｊ代表用户ｕ ｉ∈Ｕ在位置ｌ ｊ∈
Ｌ上的签到频率或者评价，Ｕ和Ｌ分别是ＬＢＳＮ上
本节定义数据结构、阐述研究问题并展示模型
的用户和ＰＯＩｓ的集合．
框架．从ＬＢＳＮ的丰富信息中提取数据结构即ＰＯＩｓ
定义２． 社会关系矩阵．给定一个ＬＢＳＮ上的
上的用户历史签到数据，包括ＰＯＩｓ的文本信息、
用户之间的社会关系，构建一个社会关系矩阵
ＰＯＩｓ的地理信息、用户的社会信息、ＰＯＩｓ的分类信
Ｓ ，如果在两个不同的用户ｕ，ｕ′∈Ｕ之间存
息以及ＰＯＩｓ的流行度．表１列出本文的关键符号． ｜Ｕ｜×｜Ｕ｜ ｉ ｉ
在社会关系，则ｓ ＝１；否则，ｓ ＝０．
ｕｉ，ｕ′ｉ ｕｉ，ｕ′ｉ
表１ 本文中的关键符号 定义３． 分类偏好矩阵．给定一个ＬＢＳＮ上
符号 意义 的ＰＯＩｓ的用户历史签到数据与ＰＯＩｓ的分类信息，
Ｕ 在ＬＢＳＮ上所有用户的集合
构建一个分类偏好矩阵Ｃ ，矩阵中的每个元素
ｕｉ 某用户：ｕｉ∈Ｕ ｜Ｕ｜×｜Ｃ｜
Ｌ 在ＬＢＳＮ上所有ＰＯＩｓ的集合 ｃ 代表用户ｕ 访问属于分类ｃ∈Ｃ的ＰＯＩｓ的频
ｌｊ 某ＰＯＩ：ｌｊ∈Ｌ具有一对经纬度地理坐标（ｘｊ，ｙｊ）
率ｕｉ， ，ｃ
Ｃｇ
是ＰＯＩｓ的ｉ 分类集合，通常ｇ
在ＬＢＳＮ上是预先
Ｃ 在ＬＢＳＮ上所有ＰＯＩｓ的分类的集合
ｃｇ 某分类：ｃｇ∈Ｃ 定义的．请注意一个ＰＯＩ可以属于多个分类．
Ｗ 文本相关的唯一词的集合 定义４． 流行度矩阵．给定一个 ＬＢＳＮ上的
ｗｉ 某唯一词：ｗｉ∈Ｗ
ＰＯＩｓ的用户历史签到数据，构建一个流行度矩阵
Ｒ｜Ｕ｜×｜Ｌ｜ 签到矩阵
Ｓ｜Ｕ｜×｜Ｕ｜ 社会关系矩阵 Ｐ ｜Ｃ｜×｜Ｌ｜，矩阵中的每个元素ｐ ｃ，ｌ代表签到频率或者
Ｃ｜Ｕ｜×｜Ｃ｜ 分类偏好矩阵
所有用户在ＰＯＩ
ｌ上的总评价ｇｊ
，即在分类ｃ∈Ｃ上
Ｐ｜Ｃ｜×｜Ｌ｜ 流行度矩阵 ｊ ｇ ８２８ 计 算 机 学 报 ２０１７年
的ＰＯＩ ｌ的流行度． 本评论到一个ＰＯＩ文档即ｄ，同样我们聚集同一用户
ｊ ｌ ｊ
定义５． 地理坐标．一个ＰＯＩ ｌ∈Ｌ是与一对 签到过的ＰＯＩｓ的所有文本评论到一个用户文档即
ｊ
地理经纬度坐标（ｘ，ｙ）相关的． ｄ ．这样我们获得一个大量的文档集合，每一个文档对
ｊ ｊ ｕｉ
本文模型框架如图１所示．（１）用户与ＰＯＩ的 应一个ＰＯＩ或者一个用户．此模型有两个潜在变量：
话题配置．该方法有效地利用ＰＯＩ相关的文本信息 （１）文档－话题分布Θ；（２）话题－词语分布Φ．我们可以
及上下文信息，更好地配置用户与ＰＯＩ之间的话题 从用户感兴趣的话题以及与这些话题相关的ＰＯＩｓ的
模型；（２）地理相关性模型．给定一个用户访问过的 文本评论中获取信息．
ＰＯＩｓ，首先评估用户所在位置经纬度坐标的个性化
签到分布，然后构建用户已访问的ＰＯＩｓ和未签到
的ＰＯＩｓ之间的地理相关性，最后计算用户对任一
未签到的ＰＯＩ的地理相关分数；（３）社会相关性模
型．给定一个未签到的ＰＯＩ，首先聚集用户朋友的社
会签到频率或者评价，然后基于所有用户历史签到
数据评估社会签到频率或者评价的分布，最后将其转
化成用户对未签到的ＰＯＩ的社会相关分数；（４）分类
相关性模型．首先从用户访问过的ＰＯＩｓ的分类标
签中获取用户的偏好，其次利用用户的偏好在相对
应的分类标签中对未签到的ＰＯＩ的流行度进行加 图２ 聚合ＬＤＡ模型
权，基于所有用户历史签到数据评估流行度的分布，
本质上每一个用户或者ＰＯＩ是由话题的多项
然后将用户对未签到的ＰＯＩ的加权流行度映射成
分布所代表，在统一的话题模型框架中，每一个话题
分类相关分数，因此分类相关性即考虑所有ＰＯＩｓ
与文本词语的多项分布相关．因此，ｄ 的话题代表
的流行度又考虑所有ＰＯＩｓ的分类信息从而有利于
ｕｉ
用户ｕ 的兴趣话题．用户ｕ 的兴趣话题多项分布表
兴趣点推荐，其表示ＰＯＩｓ的质量；（５）分数匹配．首 ｉ ｉ
示为θ．每个兴趣话题的文本项目多项分布表示为．
先兴趣相关分数是关于话题的ＰＯＩ的兴趣匹配用户
聚合ＬＤＡ的生成过程如下：
的个性化兴趣话题；其次，根据用户签到的所有ＰＯＩｓ
１．针对每个话题ｚ∈｛１，…，Ｋ｝，提取一个文本项目多
的地理坐标，构建ＰＯＩｓ之间的地理相关性，利用地
项分布，ｚ∈Ｄｉｒ（ β）．
理相关性生成某用户对某未签到的ＰＯＩ的地理相
２．针对用户ｕ的文档ｄ
ｉ ｕｉ
关分数；然后在用户朋友已访问的ＰＯＩｓ之间，利用
（１）提取一个兴趣话题分布θｄｕｉ∈Ｄｉｒ（α）
社会相关性生成某用户对某未签到的ＰＯＩ的社会
（２）针对文档ｄ ｕｉ的每个词语ｗ ｄ，ｎ：
相 的关 ＰＯ分 Ｉ数 之； 间进 的一 分步 类在 与用 流户 行已 度访 中问 ，利的 用Ｐ 分ＯＩｓ 类与 相未 关签 性到
生
① 提取一个话题ｚ ｄ，ｎ～Ｍｕｌｔ（θｄｕｉ）
② 提取一个词语ｗ ｄ，ｎ～Ｍｕｌｔ（ｚｄ，ｎ）
成某用户对某未签到的ＰＯＩ的分类相关分数；最后
于是构成了矩阵Θ 和矩阵Φ ．基于学习
Ｍ×Ｋ Ｋ×Ｖ
对兴趣相关分数、地理相关分数、社会相关分数与分
后的矩阵Θ 和矩阵Φ ，进一步推断用户ｕ 的
Ｍ×Ｋ Ｋ×Ｖ ｉ
类相关分数进行匹配生成偏好分数；（６）ＴＧＳＣ－
兴趣话题分布θ和ＰＯＩ ｌ 的话题分布π．因此，我
ｉ ｊ ｊ
ＰＭＦ模型．将匹配后的偏好分数融合到概率矩阵分
们可以计算话题的相似性．
解模型中，从而提出一种新的上下文感知的概率矩
３．２．２ 模型参数学习
阵分解算法进行兴趣点推荐生成推荐列表．
在聚合ＬＤＡ模型中，有两个未知的兴趣参数集
３．２ 配置用户与ＰＯＩ的话题模型
合：文档－话题分布Θ和话题－词语分布Φ．潜在变量ｚ
３．２．１ 话题提取
对应唯一词到话题中的配置．如图２所示，给定两个超
本文话题提取的目的是基于用户签到的ＰＯＩｓ的
参数α和β，所有用户文档的完全似然模型如下：
文本信息，基于ＬＤＡ算法［３９］．关于兴趣点推荐，我们提
Ｍ Ｎｍ
出一种聚合ＬＤＡ模型学习用户的兴趣．通过话题分布 ｐ（Ｗ，Ｚ，Θ，Φ｜α， β）＝∏∏ｐ（ｗ ｍ，ｎ｜ ｚｍ，ｎ）·
ｍ＝１ｎ＝１
提取用户和ＰＯＩ的配置文件．我们构建一个聚合ＬＤＡ
ｐ（ｚ ｍ，ｎ｜θ ｍ）·ｐ（θ ｍ｜α）·ｐ（Φ｜β）（１）
模型如图２所示．我们聚集与同一ＰＯＩ有关的所有文 ４期 任星怡等：基于位置社交网络的上下文感知的兴趣点推荐 ８２９
请注意如式（１）所示，在聚合ＬＤＡ的完全似然 的过程，获取用户对ＰＯＩｓ的兴趣偏好生成兴趣相
模型中，直接评估Θ和Φ是很难计算的．在参数评 关分数，为了能够更好地与本文接下来所提的地理
估的过程中，我们只需要对矩阵Θ 和矩阵Φ 相关分数、社会相关分数与分类相关分数进行分数
Ｍ×Ｋ Ｋ×Ｖ
保持跟踪．对于这些矩阵，我们使用吉布斯采样［４０］ 匹配生成偏好分数，从而更加有效地融合兴趣点推
来评估话题－词语分布与用户－话题分布．首先需要
荐的文本、地理、社会、分类与流行度信息．
采样潜在变量ｚ的条件分布如下： ３．３ 兴趣点推荐的地理相关性模型
ｐ（ｚ ｉ＝ｋ｜ｗ ｉ＝ｗ ｉ，ｚ －ｉ，ｗ）∝ ｎｎ ｋ（ｋ
·
，（ｗ －），ｉ ｉ－ｉ） ＋＋ Ｖβ β· ｎｎ
ｄ（ｋ
ｉｄ（ｋ ｉ
）
，－） ， ｉ－ｉ ＋＋ Ｋα
α
地要的 理Ｐ 作 相Ｏ 用Ｉ 关ｓ ． 性的 换地 要言理 强之邻 ．，邻 因近 近 此性 的 ，在 我Ｐ用 们Ｏ户 Ｉｓ 利签 比 用到 偏 用行 远 户为 的 已中 Ｐ 签起 ＯＩ 到着 ｓ重 的的
（２）
计数ｎ（·） 表明排除项目ｉ对应的话题或者文档．
ＰＯＩｓ和用户未签到的ＰＯＩｓ之间的地理相关性来评
·，－ｉ
估用户对未签到的ＰＯＩ的地理相关分数．为构建
ｎ（ｋ）
＋α
伴随着采样结果，我们使用θ ｉｋ＝
Ｋ
ｉ ＰＯＩｓ之间的地理相关性，基于每个用户签到过的
∑ｎ ｉ（ｋ） ＋Ｋα ＰＯＩｓ，我们在地理坐标上评估个性化签到分布．我
ｋ＝１
和 ＝
ｎ ｋ（ｗ） ＋β
来评估θ和，ｎ（ｗ）是关于话
们采用核带宽到每个签到数据点，并且从底层的签
ｋｗ Ｖ ｋ 到数据中可以学习出自适应带宽．自适应核评估方
∑ｎ ｋ（ｗ） ＋Ｖβ
法包括３个步骤：试点估计、当地带宽决策、自适应
ｗ＝１
题ｋ的词配置频率，ｎ（ｋ）是关于用户ｕ 的文档ｄ 的 核评估地理相关分数．
ｉ ｉ ｕｉ
话题观察计数．Ｖ是唯一词的数量，Ｋ是话题的数 ３．３．１ 试点估计
量．这里我们设置α和β是两个对称的先验． 首先，我们基于固定带宽核密度估计发现一个
接下来，给定训练模型Ｍ：｛Θ，Φ｝和超参数α 试点估计．让Ｌ ｕ＝｛ｌ １，ｌ ２，…，ｌ ｎ｝为用户ｕ ｉ签到过的
和β，根据一个ＰＯＩ的文档ｄ
ｌ
ｊ推导话题分布ｐ（π ｊ｜ ＰＯＩｓ的集合．Ｌ ｕ中的每个ＰＯＩ ｌ ｊ都与一对经纬度
ｄ ｌ，Ｍ）．类似上述的聚合ＬＤＡ模型的参数评估，我 坐标（ｘ ｉ，ｙ ｉ）相关．特别是，我们利用用户ｕ ｉ在ＰＯＩ ｌ ｉ
ｊ
们同样使用吉布斯采样方法提取每个ＰＯＩ的话题
上的签到频率或者评价（即ｒ ｕｉ，ｌｉ），作为ｌ ｊ的权重，因
分布．吉布斯采样的完全条件分布如下： 为一个ＰＯＩ的签到频率或者评价高就暗示着此
ｐ（ｚ ｄｌｊ＝ｋ｜ｗ ｉ＝ｗ ｉ，ｚ －ｉ，ｗ －ｉ，Ｍ）∝（ｎ ｄ（ｋ ｌｊ） ，－ｉ＋α）（３） Ｐ 上Ｏ 的Ｉ对 签用 到户 分更 布重 的要 试． 点用 估户 计ｕ 给ｉ在 定一 如个 下未 ：签到的ＰＯＩ ｌ ｊ
然后，ＰＯＩ ｌ 的文档ｄ 的话题分布是π ＝
ｊ ｌ ｊ ｊｋ ｎ
１
ｎ ｊ（ｋ）＋α
，ｎ（ｋ）是文档ｄ 的话题观察计数．
ｆ Ｇｅｏ（ｌ ｊ｜ｕ ｉ）＝ ２∑（ｒ ｕｉ，ｌｉ·Ｑ Ｈ（ｌ ｊ－ｌ ｉ）） （６）
Ｋ ｊ ｌ ｊ ｉ＝１
∑ｎ（ｋ）＋Ｋα ｎ
ｊ Ａ＝∑ｒ （７）
ｋ＝１ ｕｉ，ｌｉ
３．２．３ 兴趣相关分数
ｉ＝１
我们定义用户ｕ ｉ和ＰＯＩ ｌ ｊ之间的兴趣相关分 Ｑ Ｈ（ｌ ｊ－ｌ ｉ）＝ ２πＨ１
１Ｈ
２ｅｘｐ（ －（ｘ ２ｊ － Ｈｘ
２
１ｉ）２ －（ｙ ２ｊ－ Ｈｙ
２
２ｉ）２ ）
数作为用户话题分布θ 和ＰＯＩ话题分布π 的相似
ｉ ｊ （８）
性．通过兴趣相关分数计算ＰＯＩ的兴趣与用户的个
Ｑ （ｌ－ｌ）是包含两个全局带宽（Ｈ ，Ｈ ）的固定带
Ｈ ｊ ｉ １ ２
性化兴趣的匹配程度．我们使用Ｊｅｎｓｅｎ－Ｓｈａｎｎｏｎ散
宽Ｈ的标准内核函数，两个全局带宽（Ｈ ，Ｈ ）给定
１ ２
度测量上述两个多项话题分布之间的相似性．用户
如下：
ｕ 和ＰＯＩ ｌ之间的对称Ｊｅｎｓｅｎ－Ｓｈａｎｎｏｎ散度如下：
ｉ
Ｄ
（ｕｊ ，ｌ）＝１ Ｄ（θ‖Ｍ）＋１
Ｄ（π‖Ｍ） （４）
Ｈ １＝１．０８ｎ－１ ５槡 Ａ１ ∑ｎ （ ｒ ｕｉ，ｌｉ·ｘ ｉ－ Ａ１ ∑ｎ ｒ ｕｉ，ｌｋ·ｘ ｋ）２
ＪＳ ｉ ｊ ２ ｉ ２ ｊ ｉ＝１ ｋ＝１
（９）
１
Ｍ＝ （θ＋π）和Ｄ（·‖·）是 Ｋｕｌｌｂａｃｋ－Ｌｅｉｂｌｅｒ距
离．兴２ 趣相ｉ 关分ｊ 数定义如下： Ｈ ２＝１．０８ｎ－１ ５槡 Ａ１ ∑ｎ （ ｒ ｕｉ，ｌｉ·ｙ ｉ－ Ａ１ ∑ｎ ｒ ｕｉ，ｌｋ·ｙ ｋ）２
ｉ＝１ ｋ＝１
Ｓ（ｕ，ｌ）＝１－Ｄ （ｕ，ｌ） （５） （１０）
ｉ ｊ ＪＳ ｉ ｊ
我们在配置用户与ＰＯＩ的话题模型中采用兴 （Ｈ ，Ｈ ）从用户ｕ 的签到数据中被分别计算成经
１ ２ ｉ
趣相关分数模型的目的是通过话题提取与参数学习 度值与纬度值的标准偏差． ８３０ 计 算 机 学 报 ２０１７年
３．３．２ 当地带宽决策 或者评价ｘ
ｕｉ，ｌ
ｊ（即如果在两个不同的用户ｕ ｉ，ｕ′ ｉ∈Ｕ
进一步，不是直接使用式（６）中的试点估计 之间存在社会联系，则ｓ ＝１；否则，ｓ ＝０）
ｕｉ，ｕ′ｉ ｕｉ，ｕ′ｉ
ｆ ｌ（｜ｕ）来预测用户ｕ 到ＰＯＩ ｌ 的相关分数，而 如下：
Ｇｅｏ ｊ ｉ ｉ ｊ
是我们利用试点估计来决策每个签到的ＰＯＩ ｌ ｉ的 ｘ
ｕｉ，ｌ
ｊ＝∑ｓ ｕｉ，ｕ′ｉ·ｒ
ｕ′ｉ，ｌ
ｊ
（１５）
自适应当地带宽ｈ ｉ给定如下： ｕ′ｉ∈Ｕ
ｈ ｉ＝（ｄ－１·ｆ Ｇｅｏ（ｌ ｉ｜ｕ ｉ））－τ （１１）
ｒ ｕ′ｉ，ｌ是用户ｕ′ ｉ在ＰＯＩ ｌ ｊ上的签到频率或者评价．ｓ
ｕｉ，ｕ′ｉ
τ是敏感参数０τ１，即参数τ越大，自适应 是用户ｕ ｉ和ｕ′ ｉ之间的社会联系．
当地带宽ｈ 对试点估计ｆ （ｌ｜ｕ）越敏感，ｄ是几 依据上述可以简单地认为社会签到频率或者评
ｉ Ｇｅｏ ｉ ｉ
何平均值如下： 价ｘ ｕｉ，ｌ ｊ是用户ｕ ｉ和ＰＯＩ ｌ ｊ之间的相关分数．在传
ｎ ｎ 统协同过滤技术中，通过用户ｕ ｉ的朋友数量可以简
ｄ＝槡 ｉ∏ ＝１ｆ Ｇｅｏ（ｌ ｉ｜ｕ ｉ） （１２） 单划分ｘ
ｕｉ，ｌ
ｊ．但更复杂的是，本文基于社会签到频
强制约束ｈ（ｉ＝１，２，…，ｎ）的几何平均值为１． 率或者评价的分布，对所有用户历史签到数据进行
ｉ
３．３．３ 自适应核评估地理相关分数 学习后，将社会签到频率或者评价转换成正则化的
最后，根据式（９）和式（１０）的全局带宽 Ｈ＝ 相关分数．
（Ｈ ，Ｈ ）和式（１１）的自适应当地带宽ｈ，则用户ｕ ３．４．２ 社会签到频率或者评价的分布估计
１ ２ ｉ ｉ
在一个未签到的ＰＯＩ ｌ 上的签到分布的自适应核 在真实世界的数据集中，社会签到频率或者评
ｊ
评估Ｆ （ｌ｜ｕ）的计算如下： 价的随机变量ｘ遵循幂律分布，概率密度函数定义
Ｇｅｏ ｊ ｉ
ｎ 如下：
１
Ｆ Ｇｅｏ（ｌ ｊ｜ｕ ｉ）＝ Ａ∑（ｒ ｕｉ，ｌｉ·Ｑ Ｈｈｉ（ｌ ｊ－ｌ ｉ））（１３）
ｆ （ｘ）＝（γ－１）（１＋ｘ）－γ （１６）
ｉ＝１ Ｓｏ
Ｑ Ｈｈｉ（ｌ ｊ－ｌ ｉ）＝ γ由签到矩阵Ｒ ｜Ｕ｜×｜Ｌ｜和社会关系矩阵Ｓ
｜Ｕ｜×｜Ｕ｜
１ ｅｘｐ（ －（ｘ ｊ－ｘ ｉ）２ －（ｙ ｊ－ｙ ｉ）２ ）
（１４）
所评估：
２π 请Ｈ 注１Ｈ 意２ 的ｈ ｉ２ 是：当一个２
签
Ｈ 到２ １ｈ ｉ２
的ＰＯＩ
ｌ２ ｉＨ 在２ ２ｈ 一ｉ２
个高签
γ＝１＋｜Ｕ‖Ｌ｜［ ｕ∑ ′ｉ∈Ｕｌ′∑ ｊ∈Ｌｌｎ （１＋ ｕ∑ ″ｉ∈Ｕｓ ｕ′ｉ，ｕ″ｉ·ｒ
ｕ″ｉ，ｌ′
ｊ） （］ １－ ７１
）
到密度区域时，则试点估计ｆ （ｌ｜ｕ）越大，自适应
Ｇｅｏ ｊ ｉ
∑ｓ ·ｒ 是用户ｕ′的朋友ｕ″在ＰＯＩ ｌ′上的社
当地带宽ｈ ｉ越小，生成ｌ ｉ附近的一个峰值自适应核 ｕ″ｉ∈Ｕｕ′ｉ，ｕ″ｉ ｕ″ｉ，ｌ′ ｊ ｉ ｉ ｊ
评估Ｆ Ｇｅｏ（ｌ ｊ｜ｕ ｉ）；当一个签到的ＰＯＩ ｌ ｉ在一个低签 会签到频率或者评价．
到密度区域时，则试点估计ｆ Ｇｅｏ（ｌ ｊ｜ｕ ｉ）越小，自适应 ３．４．３ 社会相关分数
当地带宽ｈ ｉ越大，生成ｌ ｉ附近的一个平滑自适应核 估计概率密度函数ｆ Ｓｏ相对于社会签到频率或
评估Ｆ Ｇｅｏ（ｌ ｊ｜ｕ ｉ）．因此，关于用户ｕ ｉ在一个未签到 者评价ｘ是单调递减的，但是社会相关分数相对于
ＰＯＩ ｌ ｊ上的地理相关分数，我们的自适应核评估方 社会签到频率或者评价应该是单调递增的，因为在
法可以提高评估签到分布的预测能力． ＰＯＩｓ上朋友之间会分享更多的共同兴趣．因此，基
３．４ 兴趣点推荐的社会相关性模型 于ｆ Ｓｏ的累积分布函数，我们定义ｘ
ｕｉ，ｌ
ｊ的社会相关
在真实的基于位置的社交网络中，用户之间的
分数如下：
在社会 ＬＢ关 ＳＮ系 ｓ很 上大 用程 户度 创影 建响 社用 会户 联对 系Ｐ 意Ｏ 味Ｉｓ 他的 们签 之到 间行 存为 在．
Ｆ Ｓｏ（ｘ ｕｉ，ｌ
ｊ）＝∫ｘ ０ｕｉ，ｌｊ
ｆ Ｓｏ（ａ）ｄａ＝１－（１＋ｘ ｕｉ，ｌ ｊ）１－γ（１８）
着社会关系．因此，利用用户和用户朋友之间的社会 由于１－γ＜０，则Ｆ Ｓｏ相对于社会签到频率或者
关系，根据用户朋友签到过的ＰＯＩ来推算用户与未 评价ｘ
ｕｉ，ｌ
ｊ是一个递增函数．另外，基于累积分布函
签到的ＰＯＩ间的相关分数．这个过程包括３个步 数Ｆ Ｓｏ，社会签到频率或者评价ｘ
ｕｉ，ｌ
ｊ转换成社会相
骤：社会聚合、社会签到频率或评价的分布估计，社 关分数反映了用户在ＰＯＩｓ上的所有社会签到频率
会相关分数． 或者评价ｘ 的相对位置．
ｕｉ，ｌ
ｊ
３．４．１ 社会聚合 ３．５ 兴趣点推荐的分类相关性模型
形式上，给定一个用户ｕ 和一个未签到的ＰＯＩ 在基于位置的社交网络中，每个ＰＯＩ被附加一
ｉ
ｌ，我们聚集用户ｕ 的朋友在ＰＯＩ ｌ 上的签到频率 些分类．ＰＯＩ的分类明显地表示了在ＰＯＩ上发生什
ｊ ｉ ｊ ４期 任星怡等：基于位置社交网络的上下文感知的兴趣点推荐 ８３１
么活动或者提供什么服务和产品．因此，利用用户签 由于１－δ＜０，Ｆ Ｃａ相对于分类流行度ｙ
ｕｉ，ｌ
ｊ是一个递
到的ＰＯＩｓ和未签到的ＰＯＩ之间的分类相关性推算 增函数．另外，基于累积分布函数Ｆ ，分类流行度
Ｃａ
一个用户对一个未签到的ＰＯＩ的相关分数．另外， ｙ ｕｉ，ｌ ｊ正则化成分类相关分数反映了相比于用户在
ＰＯＩ的流行度反映了ＰＯＩ所提供的产品和服务的 ＰＯＩｓ上的其他分类流行度ｙ
ｕｉ，ｌ
ｊ的相对位置．
质量．因此，在兴趣点推荐中利用流行度是有用的． ３．６ 上下文感知的概率矩阵分解模型
特别是，我们提出一种结合用户的分类偏好和ＰＯＩ 因为兴趣点推荐是一个与文本、地理、社会、分
的流行度的新方法．这个过程包括３个步骤：分类偏 类、流行度相关的上下文感知的个性化推荐．因此我
好的加权流行度、分类流行度的分布估计和分类相 们提出一个上下文感知的概率矩阵分解兴趣点推荐
关分数计算． 算法．
３．５．１ 利用分类偏好加权流行度 ３．６．１ 分数匹配
首先，我们定义ｃ ｕｉ，ｃ ｇ为用户ｕ ｉ对分类ｃ ｇ 的偏 本文认为用户历史签到矩阵Ｒ ｜Ｕ｜×｜Ｌ｜中的ｙ ｕｉ，ｌ ｊ
好，即用户ｕ ｉ签到属于分类ｃ
ｇ
的ＰＯＩｓ的频率．然 为用户ｕ ｉ在ＰＯＩ ｌ ｊ上的签到频率或者评价（如果用
后，使用偏好ｃ
ｕｉ，ｃ
ｇ加权分类ｃ
ｇ
上未签到的ＰＯＩ ｌ
ｊ
户ｕ ｉ对ＰＯＩ ｌ ｊ感兴趣，则ｙ ｕｉ，ｌ ｊ＝１；否则ｙ ｕｉ，ｌ ｊ＝０）．
此外，关于兴趣点推荐我们利用了文本信息、地理信
的流行度，即ｐ ．相应地，我们获取了用户ｕ 在
ｃ，ｌ ｉ
ｇｊ 息、社会信息、分类信息与流行度信息．
ＰＯＩ ｌ ｊ上的分类流行度ｙ
ｕｉ，ｌ
ｊ如下：
关于分数匹配，我们需要考虑４个部分：（１）ＰＯＩ
ｙ ｕｉ，ｌ ｊ＝∑ｃ ｕｉ，ｃ ｇ·ｐ ｃ ｇ，ｌ ｊ （１９） 的兴趣话题匹配用户的个性化兴趣话题，从而推导
ｃ ｇ∈Ｃ
Ｃ是在ＬＢＳＮ上预先定义的分类的集合．ｙ
ｕｉ，ｌ
ｊ的值 兴趣相关分数；（２）评估用户所在位置经纬度坐标
越大意味着ＰＯＩ ｌ的分类越满足用户ｕ 的偏好并 的个性化签到分布，基于地理相关性，推导用户对未
ｊ ｉ
且意味着ＰＯＩ ｌ越受公众的欢迎． 签到的ＰＯＩ的地理相关分数；（３）根据用户朋友已
ｊ
依据上述可以简单地认为分类流行度ｙ
ｕｉ，ｌ
ｊ是 签到的ＰＯＩ，利用用户与朋友之间的社会关系，推导
用户ｕ 和ＰＯＩ ｌ之间的相关分数．但更复杂的是， 用户对未签到的ＰＯＩ的社会相关分数；（４）根据用
ｉ ｊ
本文基于分类流行度的分布，对所有用户历史签到 户已签到的ＰＯＩｓ与未签到的ＰＯＩ的分类与流行
数据进行学习后，将某用户对某未签到的ＰＯＩ的分 度，基于分类相关性，推导用户对未签到的ＰＯＩ的
类流行度映射成正则化的相关分数． 分类相关分数．用户ｕ ｉ在ＰＯＩ ｌ ｊ上的签到频率或者
３．５．２ 分类流行度的分布估计
评价由用户和ＰＯＩ这两种因素所决定．一方面，评
形式上，分类流行度随机变量ｙ遵循幂律分 价ｒ ｕｉ，ｌ ｊ反映用户的兴趣话题和ＰＯＩ的话题之间的
布，概率密度函数定义如下： 匹配程度．两个话题分布匹配得越好，则评价ｒ ｕｉ，ｌ
ｊ
ｆ Ｃａ（ｙ）＝（δ－１）（１＋ｙ）－δ，ｙ０，δ＞１ （２０） 越高．另一方面，评价ｒ ｕｉ，ｌ ｊ反映用户与ＰＯＩｓ之间的
地理、社会与分类相关性．地理、社会与分类相关分
δ由分类偏好矩阵Ｃ 和流行度矩阵Ｐ 所
｜Ｕ｜×｜Ｃ｜ ｜Ｃ｜×｜Ｌ｜
评估： 数越高，则评价ｒ ｕｉ，ｌ ｊ越高．
我们融合兴趣、地理、社会与分类相关分数，由
δ＝１＋｜Ｕ‖Ｌ｜［∑ ∑ｌｎ （１＋∑ｃ ·ｐ ）］－１
ｕ′ｉ∈Ｕｌ′ ｊ∈Ｌ ｃ
ｇ∈Ｃｕ′ｉ，ｃ ｇ ｃ ｇ，ｌ′ ｊ
（２１）
式（５）、式（１３）、式（１８）和式（２２）给定的相关分数，关
于用户ｕ 对ＰＯＩ ｌ的偏好，基于乘法法则，我们把
∑ｃ ·ｐ 是ＰＯＩ ｌ′上的用户ｕ′的分类流行度． ｉ ｊ
ｃ
ｇ∈Ｃｕ′ｉ，ｃ
ｇ
ｃ ｇ，ｌ′
ｊ
ｊ ｉ
这些相关分数整合到一个统一的偏好分数ＴＧＳＣ ｉｊ
３．５．３ 分类相关分数 中，定义如下：
估计概率密度函数ｆ Ｃａ相对于分类流行度ｙ是 ＴＧＳＣ ｉｊ＝Ｓ（ｕ ｉ，ｌ ｊ）Ｆ Ｇｅｏ（ｌ ｊ｜ｕ ｉ）Ｆ Ｓｏ（ｘ
ｕｉ，ｌ
ｊ）Ｆ Ｃａ（ｙ
ｕｉ，ｌ
ｊ）
单调递减的，但是分类相关分数相对于分类流行度 （２３）
应该是单调递增的，因为人们偏好的流行ＰＯＩｓ也 Ｓ（ｕ ｉ，ｌ ｊ）是用户ｕ ｉ和ＰＯＩ ｌ ｊ之间的用户兴趣
满足人们的分类偏好．因此，基于ｆ Ｃａ的累积分布函 话题分布θ ｉ与ＰＯＩ话题分布π ｊ的兴趣相关分数．
数，我们定义ｙ ｕｉ，ｌ ｊ的分类相关分数如下： Ｆ Ｇｅｏ（ｌ ｊ｜ｕ ｉ）是自适应核评估地理相关分数，Ｆ Ｓｏ（ｘ ｕｉ，ｌ ｊ）
Ｆ Ｃａ（ｙ ｕｉ，ｌ ｊ）＝∫ｙ ０ｕｉ，ｌｊ ｆ Ｃａ（ａ）ｄａ＝１－（１＋ｙ ｕｉ，ｌ ｊ）１－δ（２２） 是 一社 提会 的相 是关 ，关分 于数， 兴Ｆ Ｃ 趣ａ（ 点ｙ ｕｉ 推，ｌ ｊ 荐）是 ，在分类 之相 前关 的分 研数 究． 工值 作得 ８３２ 计 算 机 学 报 ２０１７年
中［７，２５，３１］，乘法法则被广泛应用于融合不同的因素， 题、地理、社会和分类指数ＴＧＳＣ 相乘从而能改进
ｉｊ
并显示了高鲁棒性．因此，本文采用乘法法则融合兴 ＰＭＦ模型．
趣、地理、社会与分类相关分数，从而有效地进行分 并且我们在用户和ＰＯＩ的潜在特征向量中设
数匹配． 置零均值高斯球面先验如下：
３．６．２ ＴＧＳＣ－ＰＭＦ模型 Ｍ
Ｐ（Ｕ｜σ２）＝∏Ｎ（Ｕ｜０，σ２Ｉ） （２６）
利用兴趣话题、地理相关性、社会相关性与分类 Ｕ ｉ Ｕ
ｉ＝１
相关性，我们将这些因素融合到概率矩阵分解模型 Ｎ
Ｐ（Ｌ｜σ２）＝∏Ｎ（Ｌ｜０，σ２Ｉ） （２７）
Ｌ ｊ Ｌ
中．所提的ＴＧＳＣ－ＰＭＦ模型的图解如图３所示． ｊ＝１
因此，通过一个简单的贝叶斯推理，式（２４）的后
验分布给定如下：
Ｐ（Ｕ，Ｌ｜Ｒ，σ２，ＴＧＳＣ，σ２，σ２）∝
Ｕ Ｌ
Ｐ（Ｒ｜Ｕ，Ｌ，σ２，ＴＧＳＣ，σ２，σ２）Ｐ（Ｕ｜σ２）Ｐ（Ｌ｜σ２）＝
Ｕ Ｌ Ｕ Ｌ
Ｍ Ｎ
∏∏［Ｎ（ｒ
ｕｉ，ｌ
ｊ｜ｆ（Ｕ ｉ，Ｌ ｊ，ＴＧＳＣ ｉｊ），σ２）］Ｉｉｊ×
ｉ＝１ｊ＝１
Ｍ Ｎ
∏Ｎ（Ｕ｜０，σ２Ｉ）×∏Ｎ（Ｌ｜０，σ２Ｉ） （２８）
ｉ Ｕ ｊ Ｌ
ｉ＝１ ｊ＝１
用户和ＰＯＩ的潜在特征的后验分布的对数函
数如下：
ｌｎＰ（Ｕ，Ｌ｜Ｒ，σ２，ＴＧＳＣ，σ２，σ２）＝
Ｕ Ｌ
Ｍ Ｎ
１
－ ２σ２∑∑Ｉ ｉｊ（ｒ
ｕｉ，ｌ
ｊ－ｆ（Ｕ ｉ，Ｌ ｊ，ＴＧＳＣ ｉｊ））２－
ｉ＝１ｊ＝１
Ｍ Ｎ
１ １
∑ＵＴＵ－ ∑ＬＴＬ－
２σ２ ｉ ｉ ２σ２ ｊ ｊ
图３ ＴＧＳＣ－ＰＭＦ模型 Ｕｉ＝１ Ｌｊ＝１
Ｍ Ｎ
１
用户－ＰＯＩ的签到矩阵Ｒ ｜Ｕ｜×｜Ｌ｜，在签到矩阵里 ２［（∑∑Ｉ ｉｊ）ｌｎσ２＋ＭＤｌｎσ Ｕ２＋ＮＤｌｎσ Ｌ２］＋Ｐ（２９）
ｉ＝１ｊ＝１
的每个元素ｒ ｕｉ，ｌ ｊ代表某用户ｕ ｉ对某ＰＯＩ ｌ ｊ的签到 Ｄ是潜在因素的维数，Ｐ是一个不依赖于参数的常
频率或者评价．总共有Ｍ个用户和Ｎ个ＰＯＩ．Ｕ ｉ和 量．与用户和ＰＯＩ的潜在向量的超参数保持固定的
Ｌ 是用户和ＰＯＩ的潜在特征向量．我们定义了被观 最大化对数后验，等同于最小化平方误差和目标函
ｊ
察的签到频率或者评价的条件分布如下： 数的二次正则化项：
Ｐ（Ｒ｜Ｕ，Ｌ，ＴＧＳＣ，σ２）＝ １ Ｍ Ｎ
Ｅ＝ ∑∑Ｉ （ｒ －ＴＧＳＣ ·ＵＴＬ）２＋
Ｍ Ｎ ２ ｉ＝１ｊ＝１ ｉｊ ｕｉ，ｌ ｊ ｉｊ ｉ ｊ
ｉ∏ ＝１ｊ∏ ＝１［Ｎ（ｒ ｕｉ，ｌ ｊ｜ｆ（Ｕ ｉ，Ｌ ｊ，ＴＧＳＣ ｉｊ），σ２）］Ｉｉｊ （２４） λ Ｕ∑Ｍ
Ｕ
２＋λ Ｌ∑Ｎ
Ｌ ２ （３０）
２ ｉ Ｆ ２ ｊ Ｆ
Ｎ（·｜μ，σ２）是具有均值μ和方差σ２的高斯分布概 ｉ＝１ ｊ＝１
率密度函数，Ｉ 是指示函数（如果用户ｕ 访问ＰＯＩ λ Ｕ＝σ２／σ Ｕ２，λ Ｌ＝σ２／σ Ｌ２，· ２ Ｆ是Ｆｒｏｂｅｎｉｕｓ范数．针
ｉｊ ｉ
对式（２１）的目标函数的局部最小化，对Ｕ和Ｌ进行
ｌ则Ｉ ＝１，否则，Ｉ ＝０）．我们使用函数ｆ（Ｕ，Ｌ，
ｊ ｉｊ ｉｊ ｉ ｊ
梯度下降算法如下：
ＴＧＳＣ ）近似表示用户ｕ 到ＰＯＩ ｌ的签到频率．
ｉｊ ｉ ｊ Ｎ
Ｅ
关于用户ｕ ｉ对ＰＯＩ ｌ ｊ的偏好，我们考虑了将兴 Ｕ ｉ＝－ ｊ∑ ＝１Ｉ ｉｊ（ｒ ｕｉ，ｌ ｊ－ＴＧＳＣ ｉｊ·Ｕ ｉＴＬ ｊ）·
趣话题、地理相关性、社会相关性与分类相关性进行
ＴＧＳＣＬ＋λＵ （３１）
ｉｊ ｊ Ｕ ｉ
有效地融合，融合函数定义如下：
Ｍ
Ｅ
ｆ（Ｕ ｉ，Ｌ ｊ，ＴＧＳＣ ｉｊ）＝ＴＧＳＣ ｉｊ·Ｕ ｉＴＬ ｊ （２５） Ｌ ｊ＝－ ｉ∑ ＝１Ｉ ｉｊ（ｒ ｕｉ，ｌ ｊ－ＴＧＳＣ ｉｊ·Ｕ ｉＴＬ ｊ）·
ＴＧＳＣ ｉｊ由式（２３）所计算．Ｕ ｉ和Ｌ ｊ分别是用户ｕ ｉ和 ＴＧＳＣ ｉｊＵ ｉ＋λ ＬＬ
ｊ
（３２）
ＰＯＩ ｌ ｊ的Ｄ维潜在因素，ＴＧＳＣ ｉｊ是用户ｕ ｉ对ＰＯＩ ｌ ｊ ３．６．３ 预测和推荐
的话题、地理、社会与分类指数，我们利用用户潜 对用户与ＰＯＩ之间的兴趣话题、地理相关性、
在因素Ｕ 与ＰＯＩ潜在因素Ｌ 的加权内积并与话 社会相关性、分类相关性以及参数Ｕ和Ｌ研究之
ｉ ｊ ４期 任星怡等：基于位置社交网络的上下文感知的兴趣点推荐 ８３３
后，对于一个给定的ＰＯＩ，ＴＧＳＣ－ＰＭＦ模型预测用
户对其评价被Ｅ（ｒ
ｕｉ，ｌ
ｊ｜ｕ ｉ，ｌ ｊ）＝ＴＧＳＣ ｉｊ·Ｕ ｉＴＬ ｊ所评 ４ 实 验
估．由于基于位置社交网络的兴趣点推荐是高位置
感知的，所以推荐列表推荐的ＰＯＩｓ应该接近用户 ４．１ 实验设置
的当前区域，因此推荐用户所在地理位置附近的 ４．１．１ 数据集描述
ＰＯＩｓ给用户是可取的．ＴＧＳＣ－ＰＭＦ模型可以预测 Ｆｏｕｒｓｑｕａｒｅ是一个大规模的基于位置的社交
用户偏好分数．在真实的世界里，我们需要考虑文 网站．允许用户在不同的位置进行签到，通过分析空
本、位置、社会、分类与流行度信息做出合理的个性 间、时间、社会与文本等方面的签到数据，定量评估
化兴趣点推荐．给定用户当前的地理位置，可能的方 人们的移动模式．我们使用文献［４１］所提供的数据
法是在一定范围内对应Ｔｏｐ－Ｋ的预测分数推荐给 集的一部分．数据集的统计如表２所示．
用户Ｋ个ＰＯＩｓ．
表２ 数据集的统计
数据集 用户的数量 ＰＯＩｓ的数量 分类的数量 社会关系的数量 签到或者评价的数量 用户－ＰＯＩ矩阵密度／％
Ｆｏｕｒｓｑｕａｒｅ ５４６８ ７２８６ ６０ ３５２１６ ５１２６４３ １．２８７
为了清洗并移除较少发生的异常数据，我们过 ∑｜Ｒ（ｕ）∩Ｔ（ｕ）｜
滤掉少于１０次签到的用户，并要求每个ＰＯＩ应该 Ｒｅｃａｌｌ＠Ｋ＝ ｕ （３６）
Ｔ（ｕ）
被至少访问过１０次．此外，我们要求一个用户应该
Ｋ是推荐给用户的ＰＯＩｓ的数量，Ｒ（ｕ）是推荐给用
至少访问５个不同的ＰＯＩｓ．在我们的实验中，随机
户ＰＯＩｓ的 Ｔｏｐ－Ｋ列表，Ｔ（ｕ）是用户实际访问的
选择数据集的２０％作为测试数据集，其余８０％的数
ＰＯＩｓ的数量．
据集作为训练数据集．在我们实验数据集中，有
４．１．３ 参数调整
５４６８个用户总共访问７２８６个ＰＯＩｓ．
关于ＴＧＳＣ－ＰＭＦ模型，融合了话题、地理、社
４．１．２ 评价指标
会与分类相关性．在聚合 ＬＤＡ 模型中，我们设置
我们使用隐式评分，即一个ＰＯＩ的签到频率作
α＝５０／Ｔ和β＝０．１．在地理相关性模型中，我们发
为ＰＯＩ的评分．传统的电影推荐评分范围是从
现地理相关性对参数τ是敏感的，当τ＝０．５时，地
１～５．不同于电影推荐评分，我们需要通过函数
理相关分数达到最佳的效果．在社会相关性模型中，
ｆ（ｘ）＝（ｘ－１）／（Ｋ－１）将离散的评分转化到［０，１］
参数γ不是自由参数，是从签到数据中学习后，由
范围内，Ｋ是最大的评分值［４２］．
式（１７）所计算得出的．在分类相关性模型中，参数δ
在我们的性能对比实验中，采用两种预测指标来
不是自由参数，是从签到数据中学习后，由式（２１）所
评估兴趣点推荐系统的性能：均方根误差（ＲＭＳＥ）
计算得出的．在ＴＧＳＣ－ＰＭＦ模型中，我们设置λ＝
和平均绝对误差（ＭＡＥ）．定义如下： Ｕ
０．０１和λ＝０．０１．
Ｌ
Ｂ
１ ＾
ＲＭＳＥ＝槡 Ｂ∑［（Ｒ ｒ－Ｒ ｒ）／Ｒ ｒ］２ （３３） ４．１．４ 对比方法
ｒ＝１ 我们所提的方法，即与 ＴＧＳＣ－ＰＭＦ比较的其
Ｂ
＾
∑ （Ｒ －Ｒ）／Ｒ 它先进的兴趣点推荐技术如下：
ｒ ｒ ｒ
ＭＡＥ＝ｒ＝１ （３４） （１）ＬＣＡＲＳ．此方法基于话题模型构建位置 －内
Ｂ
容感知的推荐系统推断用户个性化兴趣和位置偏
Ｂ是预测的总数，Ｒ 是用户ｕ 对一个ＰＯＩ ｌ 的真
ｒ ｉ ｊ
＾
好［１２－１３］．
实评价，Ｒ 是预测评分．ＲＭＳＥ和ＭＡＥ的值越低，
ｒ （２）ＴＬ－ＰＭＦ．此方法通过采用文本信息和流行
则对应的预测分析精度越高．
度提出话题－位置感知的兴趣点推荐系统［２３］．
根据预测值的排序我们给用户推荐Ｋ个ＰＯＩｓ
（３）ＵＳＧ．此方法是一个统一的位置推荐框架
并且基于这些被用户签到的ＰＯＩｓ进行评估．在我
结合用户偏好、社会和地理信息［２］．
们的方法对比试验中，采用两种 Ｔｏｐ－Ｋ 指标来评
（４）ＮＣＰＤ．此方法应用矩阵分解结合邻域的影
估兴趣点推荐的质量：Ｐｒｅｃｉｓｉｏｎ＠Ｋ和Ｒｅｃａｌｌ＠Ｋ．
响、分类、流行度和ＰＯＩｓ的地理距离［２４］．
定义如下：
我们设计４种基线方法进一步验证分别利用兴
∑｜Ｒ（ｕ）∩Ｔ（ｕ）｜
趣话题、地理相关性、社会相关性和分类相关性所带
Ｐｒｅｃｉｓｉｏｎ＠Ｋ＝ ｕ （３５）
Ｋ 来的好处．ＧＳＣ－ＰＭＦ是第１个ＴＧＳＣ－ＰＭＦ模型的 ８３４ 计 算 机 学 报 ２０１７年
简化版即没有考虑兴趣话题因素．ＴＳＣ－ＰＭＦ是第２ 过结合兴趣话题、地理相关性、社会相关性、分类相
个ＴＧＳＣ－ＰＭＦ模型的简化版即移除了地理相关性． 关性与流行度信息，我们可以看到 ＴＧＳＣ－ＰＭＦ很
ＴＧＣ－ＰＭＦ是第３个ＴＧＳＣ－ＰＭＦ模型的简化版即 大程度地改善了推荐性能．
没有考虑社会相关性．ＴＧＳ－ＰＭＦ是第４个ＴＧＳＣ－ ４．２．２ 方法对比
ＰＭＦ模型的简化版即移除了分类相关性． 在训练集中，关于推荐给用户的ｋ个ＰＯＩｓ和
４．２ 实验结果 被用户访问的ｎ个ＰＯＩｓ，如图４和图５所示描述了
４．２．１ 性能对比 我们所提的ＴＧＳＣ－ＰＭＦ方法对比其他先进的兴趣
对于ＲＭＳＥ和ＭＡＥ这两种预测指标，我们设 点推荐技术的推荐精确度．在所有评估的方法中，准
置不同的维数数量与话题数量，对比ＴＧＳＣ－ＰＭＦ、 确率和召回率的趋势是直观的．例如，ｋ值增加，则准
ＴＬ－ＰＭＦ和 ＰＭＦ．首先，我们分别设置话题数量 确率变低，召回率变高．因为推荐给用户越多的ＰＯＩｓ
Ｔ＝３０和Ｔ＝５０与维数数量Ｄ＝１０和Ｄ＝３０．从用 时，用户就会发现越多他们可能愿意签到的ＰＯＩｓ，
户历史签到数据中学习，获取兴趣相关分数、地理 但是一些被推荐的ＰＯＩｓ被用户访问的机会就会随
相关分数、社会相关分数和分类相关分数，并对这些 之减少．随着ｎ值的增加，准确率和召回率都逐渐上
相关分数进行匹配获得偏好分数ＴＧＳＣ ．然而我们 升．因为使用越多的被用户访问的ＰＯＩｓ的签到数
ｉｊ
不能直接使用Ｅ（ｒ
ｕｉ，ｌ
ｊ｜ｕ ｉ，ｌ ｊ）＝ｇ（ＴＧＳＣ ｉｊ·Ｕ ｉＴＬ ｊ） 据，ＴＧＳＣ－ＰＭＦ推荐模型就会更好地进行学习．
来进行预测，但是我们可以通过逻辑函数ｇ（ｘ）＝ 因为用户－ＰＯＩ签到矩阵的密度很低，所以兴趣
１／（１＋ｅ－ｘ）预测结果，限制预测分值在［０，１］范围 点推荐技术的绝对精度通常不高，然而随着签到数
内．进一步，在每个话题数量Ｔ＝３０和Ｔ＝５０的情 据收集得越多，则兴趣点推荐技术将表现得越好．在
况下，我们设置不同的用户因素和ＰＯＩ因素的维数 前人的工作中［３０，３２］，这种现象已经被反复观察．相
Ｄ＝１０和Ｄ＝３０，对ＴＧＳＣ－ＰＭＦ、ＴＬ－ＰＭＦ和ＰＭＦ 反，我们专注于对比被评估的兴趣点推荐技术的相
进行对比实验． 对准确性．
如表３和表４所示，ＴＧＳＣ－ＰＭＦ和ＴＬ－ＰＭＦ的 ＬＣＡＲＳ．此方法利用话题模型（ＬＤＡ）推断用户
性能都超过ＰＭＦ的性能．因为ＰＭＦ是最简单的模 的个性化兴趣和区域的当地偏好［１２－１３］．当地偏好或
型没有融合任何因素；ＴＬ－ＰＭＦ的性能居中是因为 者个性化兴趣表现为话题的混合物，每个话题是
其在ＰＭＦ模型的基础上融合兴趣话题和流行度信 ＰＯＩｓ上的分布，并从ＰＯＩｓ的签到数据和分类信息
息；然而我们所提的 ＴＧＳＣ－ＰＭＦ的性能最好是因 中学习到．但是，ＬＣＡＲＳ与 ＴＧＳＣ－ＰＭＦ相比忽略
为其在ＰＭＦ模型的基础上融合兴趣话题、地理相 了ＰＯＩｓ上的用户签到行为的地理特征、社会特征
关性、社会相关性、分类相关性和流行度信息．例如， 与流行度信息．因此，如图４和图５所示，ＬＣＡＲＳ的
当话题数量Ｔ＝３０和因素维数Ｄ＝１０时，ＴＧＳＣ－ 推荐精确度最低．
ＰＭＦ相比于ＰＭＦ的ＲＭＳＥ值和ＭＡＥ值分别提 ＴＬ－ＰＭＦ．此方法利用文本信息和流行度提出
高１３．５％和１１．２％；ＴＧＳＣ－ＰＭＦ相比于ＴＬ－ＰＭＦ 话题和位置感知的推荐系统［２３］．ＴＬ－ＰＭＦ利用一个
的ＲＭＳＥ值和ＭＡＥ值分别提高７．９％和５．７％．通 ＬＤＡ模型，通过挖掘ＰＯＩｓ相关的文本信息，学习用
户的兴趣话题并推断用户感兴趣的 ＰＯＩｓ．然后，
表３ 在两个不同的因素维数与两个不同的话题数量的设置
下对比ＴＧＳＣ－ＰＭＦ、ＴＬ－ＰＭＦ、ＰＭＦ的ＲＭＳＥ值 ＴＬ－ＰＭＦ提出一个话题－位置感知的概率矩阵分解
ＲＭＳＥ Ｄ＝１０ Ｄ＝３０
方法．然而，ＴＬ－ＰＭＦ与我们所提的ＴＧＳＣ－ＰＭＦ相
模型 Ｔ＝３０ Ｔ＝５０ Ｔ＝３０ Ｔ＝５０ 比忽略了ＰＯＩｓ上用户签到行为的地理、社会和分
ＰＭＦ ０．６６７９ ０．６６６８
类相关性特征．（１）我们所提的ＴＧＳＣ－ＰＭＦ融合了
ＴＬ－ＰＭＦ ０．６２７２ ０．６０６５ ０．６３８８ ０．６２９８
ＴＧＳＣ－ＰＭＦ ０．５７７６ ０．５６５８ ０．５９７２ ０．５９２３ ５个上下文因素信息即ＰＯＩｓ的文本信息、ＰＯＩｓ的
地理信息、用户的社会信息、ＰＯＩｓ的分类信息与
表４ 在两个不同的因素维数与两个不同的话题数量的
设置下对比ＴＧＳＣ－ＰＭＦ、ＴＬ－ＰＭＦ、ＰＭＦ的ＭＡＥ值
ＰＯＩｓ的流行度信息；而ＴＬ－ＰＭＦ只考虑了ＰＯＩｓ的
ＭＡＥ Ｄ＝１０ Ｄ＝３０ 文本信息与流行度信息，并没有考虑地理、社会、分
模型 Ｔ＝３０ Ｔ＝５０ Ｔ＝３０ Ｔ＝５０ 类信息；（２）我们所提的ＴＧＳＣ－ＰＭＦ模型，先利用
ＰＭＦ ０．４９４９ ０．４９０８
ＬＤＡ算法提出一种聚合ＬＤＡ模型提取用户兴趣生
ＴＬ－ＰＭＦ ０．４６６２ ０．４６１７ ０．４７０８ ０．４６８９
ＴＧＳＣ－ＰＭＦ ０．４３９５ ０．４２９６ ０．４５５５ ０．４５０５ 成兴趣相关分数，然后我们提出一种自适应带宽核 ４期 任星怡等：基于位置社交网络的上下文感知的兴趣点推荐 ８３５
相关分数，由于基于位置社交网络的兴趣点推荐一
定程度依赖社会因素，而ＴＬ－ＰＭＦ并没有考虑社会
因素，ＴＧＳＣ－ＰＭＦ与 ＴＬ－ＰＭＦ相比较增加了社会
因素，这一定程度提高了推荐精确度；（４）我们所提
的ＴＧＳＣ－ＰＭＦ不仅同时考虑分类与流行度信息，
并且对这两个因素进行融合，从而对ＰＯＩｓ的流行
度进行加权，基于ＰＯＩｓ的分类的幂律分布评估用
户对ＰＯＩｓ的分类相关性生成分类相关分数，由于
基于位置社交网络的兴趣点推荐一定程度依赖分类
与流行度因素，而ＴＬ－ＰＭＦ并没有考虑分类因素又
只简单地考虑流行度因素，ＴＧＳＣ－ＰＭＦ与ＴＬ－ＰＭＦ
相比较增加了分类因素并考虑分类与流行度之间
的有效加权融合，这一定程度提高了推荐精确度；
（５）ＴＬ－ＰＭＦ只是简单地利用话题模型与ＰＯＩｓ的
流行度融合到概率矩阵分解模型中，ＴＬ－ＰＭＦ利用
ＰＯＩｓ的流行度信息时并没有构建流行度分布；而我
们所提的ＴＧＳＣ－ＰＭＦ利用话题模型、地理相关性、
社会相关性、分类相关性推导出兴趣相关分数、地理
相关分数、社会相关分数，然后对这些分数进行有效
匹配生成偏好分数融合到概率矩阵分解模型中．我
们所提的上下文感知的概率矩阵分解模型 ＴＧＳＣ－
ＰＭＦ相比ＴＬ－ＰＭＦ推荐精确度有了显著地提高．
因此，如图４和图５所示，ＴＬ－ＰＭＦ的推荐精确度仅
略高于ＬＣＡＲＳ，远远不及ＴＧＳＣ－ＰＭＦ．
ＵＳＧ．此方法基于用户的协同过滤与基于社会
的协同过滤线性整合用户偏好、社会影响和所有用
户距离分布的地理影响［２］，但 ＵＳＧ与ＴＧＳＣ－ＰＭＦ
相比没有考虑ＰＯＩｓ的分类和流行度信息．另外，
ＵＳＧ对于用户偏好、社会影响和地理影响，采用通
用线性加权是不明智的，因为有些用户可能受社会
的朋友影响更多，有些用户可能受地理影响更多．然
而ＴＧＳＣ－ＰＭＦ采用乘法法则整合兴趣、地理、社会
与分类相关分数能够更有效地进行融合．因此，如
图４和图５所示，ＵＳＧ的推荐精度排第３．
ＮＣＰＤ．此方法利用矩阵分解方法推导每个用
户、ＰＯＩ和分类的潜在因素向量，推断每个用户的地
评估方法评估用户对ＰＯＩｓ的地理相关分数，由于
理偏好和每个ＰＯＩ的流行度偏好［２４］．然后，基于用
基于位置社交网络的兴趣点推荐很大程度依赖地理
户的潜在因素向量、ＰＯＩ的分类、ＰＯＩ的邻域、用户
因素，而ＴＬ－ＰＭＦ只考虑兴趣话题并没有考虑最重
的地理偏好和ＰＯＩ的流行度偏好，计算某用户对某
要的地理因素，ＴＧＳＣ－ＰＭＦ与 ＴＬ－ＰＭＦ相比较很
ＰＯＩ的偏好分数．ＮＣＰＤ相比 ＵＳＧ增加了分类与
大程度提高了推荐精确度；（３）我们所提的ＴＧＳＣ－
流行度信息所以精确度有所提高．但是 ＮＣＰＤ与
ＰＭＦ增加了用户的社会相关性因素，我们不是简单
ＴＧＳＣ－ＰＭＦ相比只是简单地把地理和流行度影响
地利用用户的社会关系，而是通过用户朋友关系的
作为用户的偏好，没有把它们建模成地理或者流行
幂律分布评估用户对ＰＯＩｓ的社会相关性生成社会
度分布，并且忽略了社会因素．因此，如图４和图５ ８３６ 计 算 机 学 报 ２０１７年
所示，ＮＣＰＤ的推荐精确度排第２． 协同过滤技术；（４）从用户历史签到数据中学习，基
ＴＧＳＣ－ＰＭＦ．如图４和图５所示，关于准确率 于分类流行度的幂律分布，利用分类与流行度信息，
和召回率，我们所提的 ＴＧＳＣ－ＰＭＦ模型表现出最 无缝整合用户的分类偏好与 ＰＯＩｓ的流行度，有效
好的推荐精确度．特别是，我们所提的方法相比精确 地将其转换为合理的分类相关分数；（５）ＴＧＳＣ－
度第２高的ＮＣＰＤ推荐技术有了明显的改善．主要 ＰＭＦ整合兴趣相关分数、地理相关分数、社会相关
有以下几个原因：（１）ＴＧＳＣ－ＰＭＦ利用一个聚合 分数与分类相关分数到概率矩阵分解模型中，有效
ＬＤＡ模型学习用户的兴趣话题并挖掘ＰＯＩｓ相关的 地融合了文本、地理、社会、分类与流行度信息．总结
文本信息推断用户感兴趣的ＰＯＩｓ；（２）从用户历史 以上这些原因，所以我们所提的 ＴＧＳＣ－ＰＭＦ的准
签到数据中学习，构建ＰＯＩｓ之间的地理相关性，在 确率和召回率最高．
地理坐标上评估个性化签到分布，采用自适应带宽核 ４．２．３ 不同因素影响
评估计算某用户对某ＰＯＩ的地理相关分数；（３）从 为了分别研究 ＴＧＳＣ－ＰＭＦ模型融合话题分
用户历史签到数据中学习，基于社会关系的幂律分 布、地理相关性、社会相关性、分类相关性所带来的
布，ＴＧＳＣ－ＰＭＦ利用用户朋友的社会签到频率或者 好处，我们对比了我们所提的 ＴＧＳＣ－ＰＭＦ模型的
评价，有效地将社会签到频率或者评价转换为合理 ４个基线方法，ＧＳＣ－ＰＭＦ、ＴＳＣ－ＰＭＦ、ＴＧＣ－ＰＭＦ和
的社会相关分数．这种方法优于传统的基于社会的 ＴＧＳ－ＰＭＦ．对比的结果如图６和图７所示．从结果
图６ 不同因素影响推荐给用户ｋ个ＰＯＩｓ的精确度
图７ 不同因素影响被用户访问ｎ个ＰＯＩｓ的精确度 ４期 任星怡等：基于位置社交网络的上下文感知的兴趣点推荐 ８３７
中，我们首先观察到在推荐给用户ｋ个ＰＯＩｓ和被 Ｔ的值超过阈值时，模型的复杂度足以处理数据．在
用户访问ｎ个ＰＯＩｓ的两种评估方法中ＴＧＳＣ－ＰＭＦ 这一点上，增加Ｄ和Ｔ的值对提高模型性能的帮助
始终优于４个基线方法，并表明在两种评估方法中 就不明显了．
ＴＧＳＣ－ＰＭＦ受益于４个因素来提高推荐精确度．此
外，另一个观察是同一个因素在两种不同的评估方
法中的影响程度是不同的．
特别是，在推荐给用户ｋ个ＰＯＩｓ的评估方法
中，根据４个因素的重要性，它们的影响程度排列如
下：兴趣话题＞地理相关性＞社会相关性＞分类相
关性；然而在被用户访问ｎ个ＰＯＩｓ的评估方法中，
它们的影响程度排列如下：兴趣话题＞社会相关性＞
地理相关性＞分类相关性．观察结果如下：（１）兴
图８ 参数Ｔ和Ｄ的不同值时ＲＭＳＥ值
趣话题在两种评估方法中都起着最重要的作用；
（２）关于兴趣点推荐，４个因素在ＴＧＳＣ－ＰＭＦ算法
从图９的结果中，首先我们观察到ＴＧＳＣ－ＰＭＦ的
中都起着重要的作用而且又是彼此竞争的．例如，在 推荐平均绝对误差ＭＡＥ值相比图８中ＴＧＳＣ－ＰＭＦ的
推荐给用户ｋ个ＰＯＩｓ的评估方法中，地理相关性 推荐均方根误差ＲＭＳＥ值都有所减小．其次我们观察
相比社会相关性更重要一些，然而在被用户访问ｎ 到ＴＧＳＣ－ＰＭＦ的推荐平均绝对误差ＭＡＥ值随着维度
个ＰＯＩｓ的评估方法中，社会相关性比地理相关性
数量Ｄ的增加而增加，由于平均绝对误差值越小精确
更重要一些；（３）４个因素的集成有助于提高推荐质
度越高，因此随着维度的数量增加，精确度有所下降；
量，因为 ＴＧＳＣ－ＰＭＦ的推荐精确度明显优于每个
然后当维度的数量大于５０时，推荐平均绝对误差值的
因素，原因是在实践中人们不同程度地受兴趣、地
变化就不明显了．类似的观察，随着话题数量Ｔ的增
理、社会和分类相关性的影响，只考虑一种类型的相
加，ＴＧＳＣ－ＰＭＦ的推荐平均绝对误差值减小，随着话题
数量的增加，精确度有所上升，然后当话题的数量大于
关性无法建模所有用户的签到行为．
４．２．４ 参数影响
５０时推荐平均绝对误差值的变化也不明显．原因是Ｄ
调整模型参数，即话题的数量Ｔ和维度的数量
和Ｔ代表模型的复杂度．因此，一方面，当Ｄ和Ｔ的值
Ｄ对于ＴＧＳＣ－ＰＭＦ模型的性能是重要的．因此，在
太小时，模型描述数据的能力受限；另一方面，当Ｄ和
这一部分我们在Ｆｏｕｒｓｑｕａｒｅ数据集上研究模型参
Ｔ的值超过阈值时，模型的复杂度足以处理数据．在这
数的影响．关于超参数α和β，我们设置固定值α＝
一点上，增加Ｄ和Ｔ的值对提高模型性能的帮助就不
５０／Ｔ和β＝０．１．我们尝试不同的设置，发现ＧＴＳＣ－ 明显了．
ＰＭＦ模型的性能对这些超参数是不敏感的，但是
ＴＧＳＣ－ＰＭＦ模型的性能对主题和维数的数量是敏
感的．因此我们通过设置主题和维数的数量来测试
ＴＧＳＣ－ＰＭＦ模型的性能，结果如图８和图９所示．
从图８的结果中，首先我们观察到ＴＧＳＣ－ＰＭＦ
的推荐均方根误差ＲＭＳＥ值随着维度的数量Ｄ增
加而增加，由于均方根误差值越小精确度越高，因此
随着维度的数量增加，精确度有所下降；然后当维度
的数量大于５０时，推荐均方根误差值的变化就不明
图９ 参数Ｔ和Ｄ的不同值时ＭＡＥ值
显了．类似的观察，随着话题的数量Ｔ增加，ＴＧＳＣ－
图１０描述了基于位置社交网络数据集中式（１１）
ＰＭＦ的推荐均方根误差值减小，随着话题的数量增
的敏感参数τ对ＴＧＳＣ－ＰＭＦ的准确率与召回率的
加，精确度有所上升，然后当话题的数量大于５０时
影响．请注意参数γ和δ可以从签到数据中学习，不
推荐均方根误差值的变化也不明显．原因是Ｄ和Ｔ
是自由参数．观察结果如下：（１）τ的最优值在０．４～
代表模型的复杂度．因此，一方面，当Ｄ和Ｔ的值太
０．６之间，此时可生成最高的推荐精确度；（２）τ值在
小时，模型描述数据的能力受限；另一方面，当Ｄ和 ８３８ 计 算 机 学 报 ２０１７年
０～０．４之间变化时，当地带宽对式（６）的试点估计 提的ＴＧＳＣ－ＰＭＦ兴趣点推荐能有效地匹配兴趣相
不那么敏感，即当地带宽与签到数据不太相关．特别 关分数、地理相关分数、社会相关分数与分类相关分
是，当τ＝０时，自适应带宽退化成固定带宽，这样就 数生成偏好分数，将偏好分数整合到概率矩阵分解
与签到数据无关了．结果，精确率和召回率降低； 模型中，从而有效地融合兴趣、地理、社会与分类相
（３）相反，当τ值升高至０．６～１．０之间，当地带宽对 关性．最终，在真实的ＬＢＳＮｓ的数据集中，实验结果
式（６）的试点估计就更加敏感，关于签到数据当地带 有效验证该方法的推荐效果，并显示 ＴＧＳＣ－ＰＭＦ
宽容易过度拟合．因此，推荐质量也退化了． 的精确度相比其他当前先进的兴趣点推荐技术有了
明显提高．
在未来工作中我们将计划结合用户对ＰＯＩｓ评
价的文本信息中提取出的情感因素，或者结合时间
因素，进一步提高兴趣点推荐的性能．
致 谢 本文工作是在北京邮电大学信息网络工程
研究中心完成的．该中心为教育部重点实验室．本文
审稿专家和编辑提出了宝贵意见和建议，在此致谢！
参 考 文 献
［１］ Ｂａｏ Ｊ，Ｚｈｅｎｇ Ｙ，Ｗｉｌｋｉｅ Ｄ，Ｍｏｋｂｅｌ Ｍ．Ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ ｉｎ
ｌｏｃａｔｉｏｎ－ｂａｓｅｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ：Ａ ｓｕｒｖｅｙ．ＧｅｏＩｎｆｏｒｍａｔｉｃａ，
２０１５，１９（３）：５２５－５６５
［２］ Ｙｅ Ｍ，Ｙｉｎ Ｐ Ｆ，Ｌｅｅ Ｗ Ｃ，Ｌｅｅ Ｄ Ｌ．Ｅｘｐｌｏｉｔｉｎｇ ｇｅｏｇｒａｐｈｉｃａｌ
ｉｎｆｌｕｅｎｃｅ ｆｏｒ ｃｏｌｌａｂｏｒａｔｉｖｅ ｐｏｉｎｔ－ｏｆ－ｉｎｔｅｒｅｓｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３４ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ
ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．
Ｂｅｉｊｉｎｇ，Ｃｈｉｎａ，２０１１：３２５－３３４
［３］ Ｇａｏ Ｈ Ｊ，Ｌｉｕ Ｈ．Ｍｏｂｉｌｅ Ｓｏｃｉａｌ Ｎｅｔｗｏｒｋｉｎｇ：Ｄａｔａ Ａｎａｌｙｓｉｓ
图１０ 敏感参数τ对ＴＧＳＣ－ＰＭＦ推荐精确度的影响 ｏｎ Ｌｏｃａｔｉｏｎ－Ｂａｓｅｄ Ｓｏｃｉａｌ Ｎｅｔｗｏｒｋｓ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ：
Ｓｐｒｉｎｇｅｒ，２０１４
［４］ Ｇａｏ Ｈ Ｊ，Ｔａｎｇ Ｊ Ｌ，Ｈｕ Ｘ，Ｌｉｕ Ｈ．Ｃｏｎｔｅｎｔ－ａｗａｒｅ ｐｏｉｎｔ ｏｆ
５ 总结与未来工作
ｉｎｔｅｒｅｓｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｏｎ ｌｏｃａｔｉｏｎ－ｂａｓｅｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２９ｔｈ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ
针对兴趣点推荐本文提出一个上下文感知的概 Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ａｓｔｉｎ，ＵＳＡ，２０１５：１７２１－１７２７
率矩阵分解模型，称为ＴＧＳＣ－ＰＭＦ，并利用文本信 ［５］ Ｌｉ Ｘ Ｔ，Ｃｏｎｇ Ｇ，Ｌｉ Ｘ Ｌ，ｅｔ ａｌ．Ｒａｎｋ－ｇｅｏｆｍ：Ａ ｒａｎｋｉｎｇ
息、地理信息、社会信息、分类信息与流行度信息，有 ｂａｓｅｄ ｇｅｏｇｒａｐｈｉｃａｌ ｆａｃｔｏｒｉｚａｔｉｏｎ ｍｅｔｈｏｄ ｆｏｒ ｐｏｉｎｔ ｏｆ ｉｎｔｅｒｅｓｔ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３８ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ
效地融合了兴趣话题、地理相关性、社会相关性与分
ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ
类相关性．首先，我们利用一个聚合ＬＤＡ模型学习
Ｒｅｔｒｉｅｖａｌ．Ｓａｎｔｉａｇｏ，Ｃｈｉｌｅ，２０１５：４３３－４４２
用户的兴趣话题，挖掘ＰＯＩｓ相关的文本信息推断
［６］ Ｌｅｖａｎｄｏｓｋｉ Ｊ Ｊ，Ｓａｒｗａｔ Ｍ，Ｅｌｄａｗｙ Ａ，Ｍｏｋｂｅｌ Ｍ Ｆ．ＬＡＲＳ：
用户感兴趣的ＰＯＩｓ．其次，构建地理相关性，提出一 Ａ ｌｏｃａｔｉｏｎ－ａｗａｒｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
种自适应带宽核评估方法，评估用户对ＰＯＩｓ的地 ２８ｔｈ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｄａｔａ Ｅｎｇｉｎｅｅｒｉｎｇ．
理相关分数．然后，构建社会相关性，通过用户的朋 Ｗａｓｈｉｎｇｔｏｎ，ＵＳＡ，２０１２：４５０－４６１
友到ＰＯＩｓ的幂律分布，评估社会签到频率或者评
［７］ Ｌｉｕ Ｂ，Ｆｕ Ｙ Ｊ，Ｙａｏ Ｚ Ｊ，Ｘｉｏｎｇ Ｈ．Ｌｅａｒｎｉｎｇ ｇｅｏｇｒａｐｈｉｃａｌ
ｐｒｅｆｅｒｅｎｃｅｓ ｆｏｒ ｐｏｉｎｔ－ｏｆ－ｉｎｔｅｒｅｓｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ
价将社会相关性转换成社会相关分数．再次，构建分
ｏｆ ｔｈｅ １９ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
类相关性，结合用户的分类偏好与ＰＯＩｓ的流行度
Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｃｈｉｃａｇｏ，ＵＳＡ，２０１３：
将其转换为用户对ＰＯＩｓ的分类相关分数．我们所 １０４３－１０５１ ４期 任星怡等：基于位置社交网络的上下文感知的兴趣点推荐 ８３９
［８］ Ｌｉａｎ Ｄ Ｆ，Ｚｈａｏ Ｃ，Ｘｉｅ Ｘ，ｅｔ ａｌ．ＧｅｏＭＦ：Ｊｏｉｎｔ ｇｅｏｇｒａｐｈｉｃａｌ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｈｙｄｅｒａｂａｄ，
ｍｏｄｅｌｉｎｇ ａｎｄ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ ｆｏｒ ｐｏｉｎｔ－ｏｆ－ｉｎｔｅｒｅｓｔ Ｉｎｄｉａ，２０１１：１０１－１０２
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０ｔｈ ＡＣＭ ＳＩＧＫＤＤ ［２０］ Ｂａｏ Ｊ，Ｚｈｅｎｇ Ｙ，Ｍｏｋｂｅｌ Ｍ Ｆ．Ｌｏｃａｔｉｏｎ－ｂａｓｅｄ ａｎｄ ｐｒｅｆｅｒｅｎｃｅ－
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ ａｗａｒｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｕｓｉｎｇ ｓｐａｒｓｅ ｇｅｏ－ｓｏｃｉａｌ ｎｅｔｗｏｒｋｉｎｇ
Ｍｉｎｉｎｇ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１４：８３１－８４０ ｄａｔａ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
［９］ Ｃａｏ Ｊｉｕ－Ｘｉｎ，Ｄｏｎｇ Ｙｉ，Ｙａｎｇ Ｐｅｎｇ－Ｗｅｉ，ｅｔ ａｌ．ＰＯＩ ｒｅｃｏｍ－ Ａｄｖａｎｃｅｓ ｉｎ Ｇｅｏｇｒａｐｈｉｃ Ｉｎｆｏｒｍａｔｉｏｎ Ｓｙｓｔｅｍｓ．Ｒｅｄｏｎｄｏ
ｍｅｎｄａｔｉｏｎ ｂａｓｅｄ ｏｎ ｍｅｔａ－ｐａｔｈ ｉｎ ＬＢＳＮ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｂｅａｃｈ，Ｃａｌｉｆｏｒｎｉａ，ＵＳＡ，２０１２：１９９－２０８
Ｃｏｍｐｕｔｅｒｓ，２０１６，３９（４）：６７５－６８４（ｉｎ Ｃｈｉｎｅｓｅ） ［２１］ Ｆｅｒｅｎｃｅ Ｇ，Ｙｅ Ｍ，Ｌｅｅ Ｗ Ｃ．Ｌｏｃａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｆｏｒ ｏｕｔ－
（曹玖新，董羿，杨鹏伟等．ＬＢＳＮ中基于元路径的兴趣点推 ｏｆ－ｔｏｗｎ ｕｓｅｒｓ ｉｎ ｌｏｃａｔｉｏｎ－ｂａｓｅｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
荐．计算机学报，２０１６，３９（４）：６７５－６８４） ｏｆ ｔｈｅ ２２ｎｄ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ
［１０］ Ｌｉｕ Ｙ，Ｗｅｉ Ｗ，Ｓｕｎ Ａ Ｘ，Ｍｉａｏ Ｃ Ｙ．Ｅｘｐｌｏｉｔｉｎｇ ｇｅｏｇｒａｐｈｉｃａｌ ａｎｄ Ｋｎｏｗｌｅｄｇｅ Ｍａｎａｇｅｍｅｎｔ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１３：
ｎｅｉｇｈｂｏｒｈｏｏｄ ｃｈａｒａｃｔｅｒｉｓｔｉｃｓ ｆｏｒ ｌｏｃａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／ ７２１－７２６
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２３ｒｄ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ［２２］ Ｗａｎｇ Ｈ，Ｔｅｒｒｏｖｉｔｉｓ Ｍ，Ｍａｍｏｕｌｉｓ Ｎ．Ｌｏｃａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ Ｋｎｏｗｌｅｄｇｅ Ｍａｎａｇｅｍｅｎｔ． ｉｎ ｌｏｃａｔｉｏｎ－ｂａｓｅｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ ｕｓｉｎｇ ｕｓｅｒ ｃｈｅｃｋ－ｉｎ ｄａｔａ／／
Ｓｈａｎｇｈａｉ，Ｃｈｉｎａ，２０１４：７３９－７４８ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２１ｓｔ ＡＣＭ ＳＩＧＳＰＡＴＩＡＬ Ｉｎｔｅｒｎａｔｉｏｎａｌ
［１１］ Ｈｕ Ｂ，Ｅｓｔｅｒ Ｍ．Ｓｐａｔｉａｌ ｔｏｐｉｃ ｍｏｄｅｌｉｎｇ ｉｎ ｏｎｌｉｎｅ ｓｏｃｉａｌ ｍｅｄｉａ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｄｖａｎｃｅｓ ｉｎ Ｇｅｏｇｒａｐｈｉｃ Ｉｎｆｏｒｍａｔｉｏｎ Ｓｙｓｔｅｍｓ．
ｆｏｒ ｌｏｃａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ７ｔｈ ＡＣＭ Ｏｒｌａｎｄｏ，ＵＳＡ，２０１３：３７４－３８３
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｈｏｎｇ Ｋｏｎｇ，Ｃｈｉｎａ， ［２３］ Ｌｉｕ Ｂ，Ｘｉｏｎｇ Ｈ．Ｐｏｉｎｔ－ｏｆ－ｉｎｔｅｒｅｓｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｉｎ ｌｏｃａｔｉｏｎ
２０１３：２５－３２ ｂａｓｅｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ ｗｉｔｈ ｔｏｐｉｃ ａｎｄ ｌｏｃａｔｉｏｎ ａｗａｒｅｎｅｓｓ／／
［１２］ Ｙｉｎ Ｈ Ｚ，Ｃｕｉ Ｂ，Ｓｕｎ Ｙ Ｚ，ｅｔ ａｌ．ＬＣＡＲＳ：Ａ ｓｐａｔｉａｌ ｉｔｅｍ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＳＩＡＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｄａｔａ
ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ．ＡＣＭ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｍｉｎｉｎｇ．Ａｕｓｔｉｎ，ＵＳＡ，２０１３：３９６－４０４
Ｓｙｓｔｅｍｓ，２０１４，３２（３）：１１．１－１１．３７ ［２４］ Ｈｕ Ｌ Ｋ，Ｓｕｎ Ａ Ｘ，Ｌｉｕ Ｙ．Ｙｏｕｒ ｎｅｉｇｈｂｏｒｓ ａｆｆｅｃｔ ｙｏｕｒ
［１３］ Ｙｉｎ Ｈ Ｚ，Ｓｕｎ Ｙ Ｚ，Ｃｕｉ Ｂ，ｅｔ ａｌ．ＬＣＡＲＳ：Ａ ｌｏｃａｔｉｏｎ－ｃｏｎｔｅｎｔ－ ｒａｔｉｎｇｓ：Ｏｎ ｇｅｏｇｒａｐｈｉｃａｌ ｎｅｉｇｈｂｏｒｈｏｏｄ ｉｎｆｌｕｅｎｃｅ ｔｏ ｒａｔｉｎｇ
ａｗａｒｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １９ｔｈ ＡＣＭ ｐｒｅｄｉｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３７ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ
ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ
ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｃｈｉｃａｇｏ，ＵＳＡ，２０１３：２２１－２２９ Ｒｅｔｒｉｅｖａｌ．Ｇｏｌｄ Ｃｏａｓｔ，Ａｕｓｔｒａｌｉａ，２０１４：３４５－３５４
［１４］ Ｆａｒｒａｈｉ Ｋ，Ｇａｔｉｃａ－Ｐｅｒｅｚ Ｄ．Ｄｉｓｃｏｖｅｒｉｎｇ ｒｏｕｔｉｎｅｓ ｆｒｏｍ ｌａｒｇｅ－ ［２５］ Ｃｈｅｎｇ Ｃ，Ｙａｎｇ Ｈ Ｑ，Ｋｉｎｇ Ｉ，Ｌｙｕ Ｍ Ｒ．Ｆｕｓｅｄ ｍａｔｒｉｘ
ｓｃａｌｅ ｈｕｍａｎ ｌｏｃａｔｉｏｎｓ ｕｓｉｎｇ ｐｒｏｂａｂｉｌｉｓｔｉｃ ｔｏｐｉｃ ｍｏｄｅｌｓ．ＡＣＭ ｆａｃｔｏｒｉｚａｔｉｏｎ ｗｉｔｈ ｇｅｏｇｒａｐｈｉｃａｌ ａｎｄ ｓｏｃｉａｌ ｉｎｆｌｕｅｎｃｅ ｉｎ ｌｏｃａｔｉｏｎ－
Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｉｎｔｅｌｌｉｇｅｎｔ Ｓｙｓｔｅｍｓ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，２０１１， ｂａｓｅｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２６ｔｈ ＡＡＡＩ
２（１）：３．１－３．２７ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｔｏｒｏｎｔｏ，Ｃａｎａｄａ，
［１５］ Ｙｅ Ｍ，Ｓｈｏｕ Ｄ，Ｌｅｅ Ｗ Ｃ，ｅｔ ａｌ．Ｏｎ ｔｈｅ ｓｅｍａｎｔｉｃ ａｎｎｏｔａｔｉｏｎ ２０１２：１７－２３
ｏｆ ｐｌａｃｅｓ ｉｎ ｌｏｃａｔｉｏｎ－ｂａｓｅｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ［２６］ Ｋｕｒａｓｈｉｍａ Ｔ，Ｉｗａｔａ Ｔ，Ｈｏｓｈｉｄｅ Ｔ，ｅｔ ａｌ．Ｇｅｏ ｔｏｐｉｃ ｍｏｄｅｌ：
１７ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｊｏｉｎｔ ｍｏｄｅｌｉｎｇ ｏｆ ｕｓｅｒ’ｓ ａｃｔｉｖｉｔｙ ａｒｅａ ａｎｄ ｉｎｔｅｒｅｓｔｓ ｆｏｒ
Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓａｎ Ｄｉｅｇｏ，ＵＳＡ，２０１１：５２０－ ｌｏｃａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ６ｔｈ ＡＣＭ
５２８ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．
［１６］ Ｙｉｎ Ｚ Ｊ，Ｃａｏ Ｌ Ｌ，Ｈａｎ Ｊ Ｗ，Ｈｕａｎｇ Ｔ．Ｇｅｏｇｒａｐｈｉｃａｌ ｔｏｐｉｃ Ｒｏｍｅ，Ｉｔａｌｙ，２０１３：３７５－３８４
ｄｉｓｃｏｖｅｒｙ ａｎｄ ｃｏｍｐａｒｉｓｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０ｔｈ Ｉｎｔｅｒｎａ－ ［２７］ Ｌｉｕ Ｘ，Ｌｉｕ Ｙ，Ａｂｅｒｅｒ Ｋ，Ｍｉａｏ Ｃ Ｙ．Ｐｅｒｓｏｎａｌｉｚｅｄ ｐｏｉｎｔ－ｏｆ－
ｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｈｙｄｅｒａｂａｄ，Ｉｎｄｉａ， ｉｎｔｅｒｅｓｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｂｙ ｍｉｎｉｎｇ ｕｓｅｒｓ’ｐｒｅｆｅｒｅｎｃｅ ｔｒａｎｓｉｔｉｏｎ
２０１１：２４７－２５６ ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２２ｎｄ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
［１７］ Ｆｅｒｒａｒｉ Ｌ，Ｒｏｓｉ Ａ，Ｍａｍｅｉ Ｍ，Ｚａｍｂｏｎｅｌｌｉ Ｆ．Ｅｘｔｒａｃｔｉｎｇ ｕｒｂａｎ Ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ Ｋｎｏｗｌｅｄｇｅ Ｍａｎａｇｅｍｅｎｔ．Ｂｕｒｌｉｎｇａｍｅ，
ｐａｔｔｅｒｎｓ ｆｒｏｍ ｌｏｃａｔｉｏｎ－ｂａｓｅｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ＵＳＡ，２０１３：７３３－７３８
ｔｈｅ ３ｒｄ ＡＣＭ ＳＩＧＳＰＡＴＩＡＬ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｗｏｒｋｓｈｏｐ ｏｎ ［２８］ Ｙａｏ Ｚ，Ｌｉｕ Ｂ，Ｆｕ Ｙ，ｅｔ ａｌ．Ｕｓｅｒ ｐｒｅｆｅｒｅｎｃｅｌｅａｒｎｉｎｇ ｗｉｔｈ
Ｌｏｃａｔｉｏｎ－Ｂａｓｅｄ Ｓｏｃｉａｌ Ｎｅｔｗｏｒｋｓ．Ｃｈｉｃａｇｏ，ＵＳＡ，２０１１：９－１６ ｍｕｌｔｉｐｌｅ ｉｎｆｏｒｍａｔｉｏｎ ｆｕｓｉｏｎ ｆｏｒ ｒｅｓｔａｕｒａｎｔｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／
［１８］ Ａｇａｒｗａｌ Ｄ，Ｃｈｅｎ Ｂ Ｃ．Ｆｌｄａ：Ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ ｔｈｒｏｕｇｈ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１４ＳＩＡＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
ｌａｔｅｎｔ ｄｉｒｉｃｈｌｅｔ ａｌｌｏｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３ｒｄ ＡＣＭ Ｄａｔａ Ｍｉｎｉｎｇ．Ｐｈｉｌａｄｅｌｐｈｉａ，ＵＳＡ，２０１４：４７０－４７８
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ． ［２９］ Ｙｕａｎ Ｑ，Ｃｏｎｇ Ｇ，Ｍａ Ｚ Ｙ，ｅｔ ａｌ．Ｔｉｍｅ－ａｗａｒｅ ｐｏｉｎｔ－ｏｆ－ｉｎｔｅｒｅｓｔ
Ｈｏｎｇ Ｋｏｎｇ，Ｃｈｉｎａ，２０１０：９１－１００ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３６ｔｈ ＡＣＭ ＳＩＧＩＲ
［１９］ Ｐｅｎｎａｃｃｈｉｏｔｔｉ Ｍ，Ｇｕｒｕｍｕｒｔｈｙ Ｓ．Ｉｎｖｅｓｔｉｇａｔｉｎｇ ｔｏｐｉｃ ｍｏｄｅｌｓ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ
ｆｏｒ ｓｏｃｉａｌ ｍｅｄｉａ ｕｓｅｒ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０ｔｈ Ｒｅｔｒｉｅｖａｌ．Ｄｕｂｌｉｎ，Ｉｒｅｌａｎｄ，２０１３：３６３－３７２ ８４０ 计 算 机 学 报 ２０１７年
［３０］ Ｙｕａｎ Ｑ，Ｃｏｎｇ Ｇ，Ｓｕｎ Ａ Ｘ．Ｇｒａｐｈ－ｂａｓｅｄ ｐｏｉｎｔ－ｏｆ－ｉｎｔｅｒｅｓｔ ［３６］ Ｌｉｕ Ｘ，Ｗｕ Ｗ．Ｌｅａｒｎｉｎｇ ｃｏｎｔｅｘｔ－ａｗａｒｅ ｌａｔｅｎｔ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｗｉｔｈ ｇｅｏｇｒａｐｈｉｃａｌ ａｎｄ ｔｅｍｐｏｒａｌ ｉｎｆｌｕｅｎｃｅｓ／／ ｆｏｒ ｃｏｎｔｅｘｔ－ａｗａｒｅ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２３ｒｄ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ３８ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ Ｋｎｏｗｌｅｄｇｅ Ｍａｎａｇｅｍｅｎｔ． Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ｓａｎｔｉａｇｏ，Ｃｈｉｌｅ，
Ｓｈａｎｇｈａｉ，Ｃｈｉｎａ，２０１４：６５９－６６８ ２０１５：８８７－８９０
［３１］ Ｚｈａｎｇ Ｊ Ｄ，Ｃｈｏｗ Ｃ Ｙ．ｉＧＳＬＲ：Ｐｅｒｓｏｎａｌｉｚｅｄ ｇｅｏ－ｓｏｃｉａｌ ｌｏｃａｔｉｏｎ ［３７］ Ｒａｈｉｍｉ Ｓ Ｍ，Ｗａｎｇ Ｘ．Ｌｏｃａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｂａｓｅｄ ｏｎ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ—Ａ ｋｅｒｎｅｌ ｄｅｎｓｉｔｙ ｅｓｔｉｍａｔｉｏｎ ａｐｐｒｏａｃｈ／／ ｐｅｒｉｏｄｉｃｉｔｙ ｏｆ ｈｕｍａｎ ａｃｔｉｖｉｔｉｅｓ ａｎｄ ｌｏｃａｔｉｏｎ ｃａｔｅｇｏｒｉｅｓ／／
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２１ｓｔ ＡＣＭ ＳＩＧＳＰＡＴＩＡＬ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １７ｔｈ Ｐａｃｉｆｉｃ－Ａｓｉａ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｄｖａｎｃｅｓ ｉｎ Ｇｅｏｇｒａｐｈｉｃ Ｉｎｆｏｒｍａｔｉｏｎ Ｓｙｓｔｅｍｓ． Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｇｏｌｄ Ｃｏａｓｔ，Ａｕｓｔｒａｌｉａ，２０１３：
Ｏｒｌａｎｄｏ，ＵＳＡ，２０１３：３３４－３４３ ３７７－３８９
［３２］ Ｚｈａｎｇ Ｊ Ｄ，Ｃｈｏｗ Ｃ Ｙ．ＣｏＲｅ：Ｅｘｐｌｏｉｔｉｎｇ ｔｈｅ ｐｅｒｓｏｎａｌｉｚｅｄ ［３８］ Ｚｈａｏ Ｙ Ｌ，Ｎｉｅ Ｌ Ｑ，Ｗａｎｇ Ｘ Ｙ，Ｃｈｕａ Ｔ Ｓ．Ｐｅｒｓｏｎａｌｉｚｅｄ
ｉｎｆｌｕｅｎｃｅ ｏｆ ｔｗｏ－ｄｉｍｅｎｓｉｏｎａｌ ｇｅｏｇｒａｐｈｉｃ ｃｏｏｒｄｉｎａｔｅｓ ｆｏｒ ｌｏｃａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ ｏｆ ｌｏｃａｌｌｙ ｉｎｔｅｒｅｓｔｉｎｇ ｖｅｎｕｅｓ ｔｏ ｔｏｕｒｉｓｔｓ ｖｉａ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ．Ｊｏｕｒｎａｌ ｏｆ Ｉｎｆｏｒｍａｔｉｏｎ Ｓｃｉｅｎｃｅｓ，２０１５， ｃｒｏｓｓ－ｒｅｇｉｏｎ ｃｏｍｍｕｎｉｔｙ ｍａｔｃｈｉｎｇ．ＡＣＭ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ
２９３（１）：１６３－１８１ Ｉｎｔｅｌｌｉｇｅｎｔ Ｓｙｓｔｅｍｓ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，２０１４，５（３）：５０．１－
［３３］ Ｚｈａｎｇ Ｊ Ｄ，Ｃｈｏｗ Ｃ Ｙ，Ｌｉ Ｙ Ｈ．Ｌｏｒｅ：Ｅｘｐｌｏｉｔｉｎｇ ｓｅｑｕｅｎｔｉａｌ ５０．２６
ｉｎｆｌｕｅｎｃｅ ｆｏｒ ｌｏｃａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ［３９］ Ｂｌｅｉ Ｄ Ｍ，Ｎｇ Ａ Ｙ，Ｊｏｒｄａｎ Ｍ Ｉ．Ｌａｔｅｎｔ ｄｉｒｉｃｈｌｅｔ ａｌｌｏｃａｔｉｏｎ．
２２ｎｄ ＡＣＭ ＳＩＧＳＰＡＴＩＡＬ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，２００３，３：９９３－１０２２
Ａｄｖａｎｃｅｓ ｉｎ Ｇｅｏｇｒａｐｈｉｃ Ｉｎｆｏｒｍａｔｉｏｎ Ｓｙｓｔｅｍｓ．Ｄａｌｌａｓ，ＵＳＡ， ［４０］ Ｇｒｉｆｆｉｔｈｓ Ｔ Ｌ，Ｓｔｅｙｖｅｒｓ Ｍ．Ｆｉｎｄｉｎｇ ｓｃｉｅｎｔｉｆｉｃ ｔｏｐｉｃｓ．Ｐｒｏｃｅｅｄｉｎｇｓ
２０１４：１０３－１１２ ｏｆ ｔｈｅ Ｎａｔｉｏｎａｌ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ ｏｆ ｔｈｅ Ｕｎｉｔｅｄ Ｓｔａｔｅｓ ｏｆ
［３４］ Ｙｉｎｇ Ｊ Ｊ Ｃ，Ｋｕｏ Ｗ Ｎ，Ｔｓｅｎｇ Ｖ Ｓ，Ｌｕ Ｅ Ｈ Ｃ．Ｍｉｎｉｎｇ ｕｓｅｒ Ａｍｅｒｉｃａ，２００４，１０１（Ｓｕｐｐｌｅｍｅｎｔ １）：５２２８－５２３５
ｃｈｅｃｋ－ｉｎ ｂｅｈａｖｉｏｒ ｗｉｔｈ ａ ｒａｎｄｏｍ ｗａｌｋ ｆｏｒ ｕｒｂａｎ ｐｏｉｎｔ－ｏｆ－ ［４１］ Ｃｈｅｎｇ Ｚ Ｙ，Ｃａｖｅｒｌｅｅ Ｊ，Ｌｅｅ Ｋ，Ｓｕｉ Ｄ Ｚ．Ｅｘｐｌｏｒｉｎｇ ｍｉｌｌｉｏｎｓ
ｉｎｔｅｒｅｓｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ．ＡＣＭ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｉｎｔｅｌｌｉｇｅｎｔ ｏｆ ｆｏｏｔｐｒｉｎｔｓ ｉｎ ｌｏｃａｔｉｏｎ ｓｈａｒｉｎｇ ｓｅｒｖｉｃｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｓｙｓｔｅｍｓ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，２０１４，５（３）：４０．１－４０．２６ ５ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂｌｏｇｓ ａｎｄ Ｓｏｃｉａｌ
［３５］ Ｙａｎｇ Ｄ Ｑ，Ｚｈａｎｇ Ｄ Ｑ，Ｙｕ Ｚ Ｙ，Ｗａｎｇ Ｚ．Ａ ｓｅｎｔｉｍｅｎｔ Ｍｅｄｉａ．Ｂａｒｃｅｌｏｎａ，Ｓｐａｉｎ，２０１１：８１－８８
ｅｎｈａｎｃｅｄ ｐｅｒｓｏｎａｌｉｚｅｄ ｌｏｃａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ／／ ［４２］ Ｓａｌａｋｈｕｔｄｉｎｏｖ Ｒ，Ｍｎｉｈ Ａ．Ｐｒｏｂａｂｉｌｉｓｔｉｃ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ／／
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｈｙｐｅｒｔｅｘｔ ａｎｄ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ
Ｓｏｃｉａｌ Ｍｅｄｉａ．Ｐａｒｉｓ，Ｆｒａｎｃｅ，２０１３：１１９－１２８ Ｓｙｓｔｅｍｓ．Ｖａｎｃｏｕｖｅｒ，Ｃａｎａｄａ，２００７：１２５７－１２６４
ＲＥＮ Ｘｉｎｇ－Ｙｉ，ｂｏｒｎ ｉｎ １９８３，Ｐｈ．Ｄ． ＳＯＮＧ Ｍｅｉ－Ｎａ，ｂｏｒｎ ｉｎ １９７４，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ．Ｈｅｒ
ｃａｎｄｉｄａｔｅ．Ｈｅｒ ｃｕｒｒｅｎｔ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｃｕｒｒｅｎｔ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｓｅｒｖｉｃｅ ｃｏｍｐｕｔｉｎｇ，ｃｌｏｕｄ
ｉｎｃｌｕｄｅ ｄａｔａ ｍｉｎｉｎｇ，ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｃｏｍｐｕｔｉｎｇ，ｖｅｒｙ ｌａｒｇｅ ｓｃａｌｅ ｉｎｆｏｒｍａｔｉｏｎ ｓｅｒｖｉｃｅ ｓｙｓｔｅｍ．
ｓｙｓｔｅｍ，ａｎｄ ｂｉｇ ｄａｔａ． ＳＯＮＧ Ｊｕｎ－Ｄｅ，ｂｏｒｎ ｉｎ １９３８，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ．Ｈｉｓ
ｃｕｒｒｅｎｔ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｓｅｒｖｉｃｅ ｓｃｉｅｎｃｅ ａｎｄ
ｅｎｇｉｎｅｅｒｉｎｇ，ｃｌｏｕｄ ｃｏｍｐｕｔｉｎｇ，ｂｉｇ ｄａｔａ，ｔｈｅ Ｉｎｔｅｒｎｅｔ ｏｆ
Ｔｈｉｎｇｓ ａｎｄ ＩＣＴ ｋｅｙ ｔｅｃｈｎｏｌｏｇｉｅｓ．
Ｂａｃｋｇｒｏｕｎｄ
Ｔｈｉｓ ｐａｐｅｒ ｂｅｌｏｎｇｓ ｔｏ ｓｏｃｉａｌ ｎｅｔｗｏｒｋ ａｎｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｄｖｅｒｔｉｓｅｍｅｎｔｓ ｆｏｒ Ｐｏｉｎｔ－ｏｆ－Ｉｎｔｅｒｅｓｔ． Ｍｅｍｏｒｙ－ｂａｓｅｄ ａｎｄ
ｓｙｓｔｅｍ ａｒｅａ．Ｗｉｔｈ ｔｈｅ ｒａｐｉｄ ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ ｍｏｂｉｌｅ ｄｅｖｉｃｅｓ， ｍｏｄｅｌ－ｂａｓｅｄ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ａｌｇｏｒｉｔｈｍｓ ａｒｅ ｎｏｒｍａｌｌｙ
ｇｌｏｂａｌ ｐｏｓｉｔｉｏｎ ｓｙｓｔｅｍ （ＧＰＳ）ａｎｄ Ｗｅｂ ２．０ｔｅｃｈｎｏｌｏｇｉｅｓ， ｖｅｒｙ ｅｆｆｅｃｔｉｖｅ ｉｎ ｔｒａｄｉｔｉｏｎａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍｓ，ｓｕｃｈ ａｓ
ｌｏｃａｔｉｏｎ－ｂａｓｅｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ （ＬＢＳＮｓ）ｈａｖｅ ａｔｔｒａｃｔｅｄ ｍｏｖｉｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｎｄ ｇｏｏｄｓ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．Ｈｏｗｅｖｅｒ，
ｍｉｌｌｉｏｎｓ ｏｆ ｕｓｅｒｓ ｔｏ ｓｈａｒｅ ｒｉｃｈ ｉｎｆｏｒｍａｔｉｏｎ，ｓｕｃｈ ａｓ ｇｅｏｇｒａｐｈｉｃａｌ ａｓ ａ ｕｓｅｒ ｃａｎ ｏｎｌｙ ｖｉｓｉｔ ａ ｆｅｗ ＰＯＩｓ ｉｎ ＬＢＳＮ，ｔｈｅ ｃｈｅｃｋ－ｉｎｓ ｏｆ
ｌｏｃａｔｉｏｎ，ｅｘｐｅｒｉｅｎｃｅｓ ａｎｄ ｔｉｐｓ．Ｐｏｉｎｔ－ｏｆ－Ｉｎｔｅｒｅｓｔ （ＰＯＩ） ＰＯＩ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｒｅ ｓｃａｒｃｅ，ｔｒａｄｉｔｉｏｎａｌ ｃｏｌｌａｂｏｒａｔｉｖｅ
ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ ｐｌａｙｓ ａｎ ｉｍｐｏｒｔａｎｔ ｒｏｌｅ ｉｎ ＬＢＳＮｓ ｓｉｎｃｅ ｆｉｌｔｅｒｉｎｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄｓ ｅａｓｉｌｙ ｓｕｆｆｅｒ ｆｒｏｍ ｔｈｅ ｄａｔａ
ｉｔ ｃａｎ ｈｅｌｐ ｕｓｅｒｓ ｅｘｐｌｏｒｅ ａｔｔｒａｃｔｉｖｅ ｌｏｃａｔｉｏｎｓ ａｓ ｗｅｌｌ ａｓ ｈｅｌｐ ｓｐａｒｓｉｔｙ ｐｒｏｂｌｅｍ．Ｔｈｕｓ，ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ（ＣＦ）ｔｅｃｈｎｉｑｕｅｓ
ｓｏｃｉａｌ ｎｅｔｗｏｒｋ ｓｅｒｖｉｃｅ ｐｒｏｖｉｄｅｒｓ ｄｅｓｉｇｎ ｌｏｃａｔｉｏｎ－ａｗａｒｅ ａｒｅ ｕｎｒｅｌｉａｂｌｅ ｆｏｒ ｍａｋｉｎｇ ｅｆｆｅｃｔｉｖｅ ＰＯＩ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ． ４期 任星怡等：基于位置社交网络的上下文感知的兴趣点推荐 ８４１
ＰＯＩ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｉｓ ａ ｐｅｒｓｏｎａｌｉｚｅｄ，ｌｏｃａｔｉｏｎ－ａｗａｒｅ， ｃｏｒｒｅｌａｔｉｏｎｓ ｗｈｉｃｈ ｃｏｍｂｉｎｅ ｔｈｅ ｃａｔｅｇｏｒｙ ｂｉａｓ ｏｆ ｕｓｅｒｓ ａｎｄ ｔｈｅ
ａｎｄ ｃｏｎｔｅｘｔ ｄｅｐｅｎｄｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．Ｔｈｅｒｅｆｏｒｅ，ｗｅ ｐｒｏｐｏｓｅ ｐｏｐｕｌａｒｉｔｙ ｏｆ ＰＯＩｓ ｉｎｔｏ ｃａｔｅｇｏｒｉｃａｌ ｒｅｌｅｖａｎｃｅ ｓｃｏｒｅ．Ｆｕｒｔｈｅｒ，
ａ ｃｏｎｔｅｘｔ－ａｗａｒｅ ｐｒｏｂａｂｉｌｉｓｔｉｃ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ ｍｅｔｈｏｄ ｏｕｒ ｅｘｐｌｏｉｔ ｐｒｏｂａｂｉｌｉｓｔｉｃ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ ｍｏｄｅｌ（ＰＭＦ）ｔｏ
ｃａｌｌｅｄ ＴＧＳＣ－ＰＭＦ ｆｏｒ ＰＯＩ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ，ｅｘｐｌｏｉｔｉｎｇ ｉｎｔｅｇｒａｔｅ ｔｈｅ ｉｎｔｅｒｅｓｔ，ｇｅｏｇｒａｐｈｉｃａｌ，ｓｏｃｉａｌ ａｎｄ ｃａｔｅｇｏｒｉｃａｌ
ｇｅｏｇｒａｐｈｉｃａｌ ｉｎｆｏｒｍａｔｉｏｎ，ｔｅｘｔ ｉｎｆｏｒｍａｔｉｏｎ，ｓｏｃｉａｌ ｉｎｆｏｒｍａｔｉｏｎ， ｒｅｌｅｖａｎｃｅ ｓｃｏｒｅｓ ｆｏｒ ＰＯＩ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．Ｆｉｎａｌｌｙ，ｗｅ
ｃａｔｅｇｏｒｉｃａｌ ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ ｐｏｐｕｌａｒｉｔｙ ｉｎｆｏｒｍａｔｉｏｎ，ｉｎｃｏｒｐｏｒａｔｉｎｇ ｉｍｐｌｅｍｅｎｔ ｅｘｐｅｒｉｍｅｎｔｓ ｏｎ ａ ｒｅａｌ ＬＢＳＮ ｃｈｅｃｋ－ｉｎ ｄａｔａｓｅｔ．
ｔｈｅｓｅ ｆａｃｔｏｒｓ ｅｆｆｅｃｔｉｖｅｌｙ． Ｅｘｐｅｒｉｍｅｎｔａｌ ｒｅｓｕｌｔｓ ｓｈｏｗ ｔｈａｔ ＴＧＳＣ－ＰＭＦ ａｃｈｉｅｖｅｓ
Ｆｉｒｓｔ，ｗｅ ｅｘｐｌｏｉｔ ａｎ ａｇｇｒｅｇａｔｅｄ Ｌａｔｅｎｔ Ｄｉｒｉｃｈｌｅｔ Ａｌｌｏｃａｔｉｏｎ ｓｉｇｎｉｆｉｃａｎｔｌｙ ｓｕｐｅｒｉｏｒ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｑｕａｌｉｔｙ ｃｏｍｐａｒｅ ｔｏ
（ＬＤＡ）ｍｏｄｅｌ ｔｏ ｌｅａｒｎ ｔｈｅ ｉｎｔｅｒｅｓｔ ｔｏｐｉｃｓ ｏｆ ｕｓｅｒｓ ａｎｄ ｉｎｆｅｒ ｏｔｈｅｒ ｓｔａｔｅ－ｏｆ－ｔｈｅ－ａｒｔ ＰＯＩ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｔｅｃｈｎｉｑｕｅｓ．
ｔｈｅ ｉｎｔｅｒｅｓｔ ＰＯＩｓ ｂｙ ｍｉｎｉｎｇ ｔｅｘｔｕａｌ ｉｎｆｏｒｍａｔｉｏｎ ａｓｓｏｃｉａｔｅｄ Ｔｈｅ ｗｏｒｋ ｄｅｓｃｒｉｂｅｄ ｉｎ ｔｈｉｓ ｐａｐｅｒ ｉｓ ｓｕｐｐｏｒｔｅｄ ｂｙ ｔｈｅ
ｗｉｔｈ ＰＯＩｓ ａｎｄ ｇｅｎｅｒａｔｅ ｉｎｔｅｒｅｓｔ ｒｅｌｅｖａｎｃｅ ｓｃｏｒｅ．Ｓｅｃｏｎｄ，ｗｅ Ｎａｔｉｏｎａｌ Ｋｅｙ Ｐｒｏｊｅｃｔ ｏｆ Ｓｃｉｅｎｔｉｆｉｃ ａｎｄ Ｔｅｃｈｎｉｃａｌ Ｓｕｐｐｏｒｔｉｎｇ
ｐｒｏｐｏｓｅ ａ ｋｅｒｎｅｌ ｅｓｔｉｍａｔｉｏｎ ｍｅｔｈｏｄ ｗｉｔｈ ａｎ ａｄａｐｔｉｖｅ ｂａｎｄ－ Ｐｒｏｇｒａｍｓ ｏｆ Ｃｈｉｎａ （Ｇｒａｎｔ Ｎｏ．２０１４ＢＡＫ１５Ｂ０１）；ｔｈｅ
ｗｉｄｔｈ ｔｏ ｍｏｄｅｌ ｔｈｅ ｇｅｏｇｒａｐｈｉｃａｌ ｃｏｒｒｅｌａｔｉｏｎｓ ａｎｄ ｇｅｎｅｒａｔｅ Ｃｏｓｐｏｎｓｏｒｅｄ Ｐｒｏｊｅｃｔ ｏｆ Ｂｅｉｊｉｎｇ Ｃｏｍｍｉｔｔｅｅ ｏｆ Ｅｄｕｃａｔｉｏｎ；
ｇｅｏｇｒａｐｈｉｃａｌ ｒｅｌｅｖａｎｃｅ ｓｃｏｒｅ．Ｔｈｉｒｄ，ｗｅ ｂｕｉｌｄ ｓｏｃｉａｌ ｒｅｌｅｖａｎｃｅ Ｅｎｇｉｎｅｅｒｉｎｇ Ｒｅｓｅａｒｃｈ Ｃｅｎｔｅｒ ｏｆ Ｉｎｆｏｒｍａｔｉｏｎ Ｎｅｔｗｏｒｋｓ，
ｔｈｒｏｕｇｈ ｔｈｅ ｐｏｗｅｒ－ｌａｗ ｄｉｓｔｒｉｂｕｔｉｏｎ ｏｆ ｕｓｅｒ ｓｏｃｉａｌ ｒｅｌａｔｉｏｎｓ ｔｏ Ｍｉｎｉｓｔｒｙ ｏｆ Ｅｄｕｃａｔｉｏｎ．
ｇｅｎｅｒａｔｅ ｓｏｃｉａｌ ｒｅｌｅｖａｎｃｅ ｓｃｏｒｅ．Ｔｈｅｎ，ｗｅ ｍｏｄｅｌ ｔｈｅ ｃａｔｅｇｏｒｉｃａｌ --------------------------------------------------------------------------------- 计算机科学与探索 1673-9418/2022/16(07)-1462-17
JournalofFrontiersofComputerScienceandTechnology doi:10.3778/j.issn.1673-9418.2112037
基于位置社交网络的兴趣点推荐系统研究综述
陈江美1，张文德2+
1.福州大学 经济与管理学院，福州 350108
2.福州大学 信息管理研究所，福州 350108
+通信作者 E-mail:zhangwd@fzu.edu.cn
摘 要：兴趣点推荐是近年来位置社交网络和推荐系统领域研究的热点之一，了解兴趣点推荐在位置社交网
络方面的发展现状，有利于为下一步的研究提供方向。对国内外兴趣点推荐系统的相关文献进行梳理，首先
介绍了兴趣点推荐系统的概念，并从影响推荐的因素、推荐方法和推荐存在的问题三方面探讨其与传统推荐
的区别。然后提出了兴趣点推荐系统的基本框架，该框架包含了数据来源、推荐方法和算法评价三个核心部
分。以该框架为基础，介绍了影响兴趣点推荐的多种因素，归纳了现有的兴趣点推荐算法，总结了算法的评价
指标。同时对代表性工作进行了分析介绍，详细总结了各种方法的研究内容与特点，并评价了其优势与不
足。最后对该领域所面临的挑战和潜在的研究方向进行了总结与展望，给出了未来的研究趋势和发展方向。
关键词：位置社交网络；推荐系统；兴趣点推荐；影响因素
文献标志码：A 中图分类号：TP391
Review of Point of Interest Recommendation Systems in Location-Based Social
Networks
CHEN Jiangmei1, ZHANG Wende2+
1.SchoolofEconomyandManagement,FuzhouUniversity,Fuzhou350108,China
2.InstituteofInformationManagement,FuzhouUniversity,Fuzhou350108,China
Abstract: Point of interest recommendation is recently one of the hotspots in the field of location-based social
networks and recommendation systems. Understanding the research status of the point of interest recommendation
in location-based social networks can provide a direction for the next step of work. The recent literatures of the
point of interest recommendation systems are analyzed. Firstly, the definition is introduced, and the difference from
traditional recommendation is discussed from three aspects: influencing factors, recommendation approaches and
existing problems. Secondly, the general framework of the point of interest recommendation is proposed, which
includes data sources, recommendation approaches and evaluation. Based on this framework, the various influencing
factors are introduced, the current recommendation algorithms are generalized, and the evaluation metrics are
summarized. Meanwhile, the representative works are analyzed, the research contents and characteristics of each
type of methods are summarized in detail, and their advantages and limitations are evaluated. Finally, the challenges
and potential directions for possible extensions in this filed are summarized and prospected, and the future research
trendsanddevelopmentdirectionsareconcluded.
Keywords:location-basedsocialnetworks;recommendationsystems;pointofinterestrecommendation;influencingfactor
基金项目：国家自然科学基金青年项目（61300104）；中国高校产学研创新基金新一代信息技术创新项目（2019ITA0103）。
ThisworkwassupportedbytheNationalNaturalScienceFoundationforYouthofChina(61300104)andtheNewGenerationInforma-
tionTechnologyInnovationProjectofIndustry-University-ResearchInnovationFundinChineseUniversities(2019ITA0103).
收稿日期：2021-12-09 修回日期：2022-02-14 陈江美 等：基于位置社交网络的兴趣点推荐系统研究综述 1463
继在线社交网络发展和应用之后，移动社交网络 为了更系统地了解兴趣点推荐的研究理论、现
成为新的发展方向，尤其是多样化的移动位置签到与 状、挑战和发展趋势，本文基于上述三个核心问题对
共享等功能的不断普及。在此背景下，社交网络与位 国内外近年来相关的研究成果进行了梳理与解读。
置服务不断融合，助推了基于位置社交网络（location- 首先对兴趣点推荐系统的概念、与传统推荐的区别
based social network，LBSN）的兴起[1]，如Foursquare 及基本框架进行了概述；其次在了解理论背景的基
和Yelp。LBSN利用用户的签到功能，有机地将线上 础上，总结归纳了影响兴趣点推荐的常见因素，从各
和线下世界结合起来，提供用户位置定位功能的同 个影响因素的角度分析兴趣点推荐的现状；然后阐
时，还实现了位置信息在社交网络平台的共享，进而 述对比了现有的兴趣点推荐算法，并对代表性的工
衍生出多样化的位置服务。推荐系统作为有效处理 作进行了深入分析；根据兴趣点推荐的现状，重点对
“信息过载”问题的重要工具[2]，旨在依据用户的个性 面临的问题和潜在的方向进行了概述；最后进行总
化需求为用户推荐可能感兴趣的商品，其在位置服 结与展望，为兴趣点推荐系统后续的相关研究提供
务领域的应用受到广泛关注。 借鉴与参考，从而推动我国个性化推荐服务行业的
近年来，将推荐系统应用到位置社交网络中，出 进一步发展。
现了诸多基于位置的推荐服务。其中，兴趣点（point
of interest，POI）推荐受到了众多学者的关注。兴趣 1 兴趣点推荐系统概述
点是指用户签到的地点，如商场、学校等。兴趣点推 移动社交网络的广泛普及，涌现了大量的位置
荐能有效缓解位置信息过载问题，进而提升用户的 服务功能，将推荐系统应用到位置服务，促进了基于
个性化体验，同时有助于商家挖掘潜在的客户，提高 位置社交网络的兴趣点推荐系统的发展。兴趣点推
商家的商业效益。为此，兴趣点推荐成为基于位置 荐系统一般包含了用户集合U u u u 和兴趣
={ 1, 2,…, m}
社交网络中的一项重要服务，是位置社交网络和推 点集合 L l l l ，m 和 n 分别表示用户和兴趣
={1, 2,…, n}
荐系统领域核心的研究方向之一。 点的个数。其中，每个兴趣点附带坐标属性，可用<经
LBSN中蕴含着海量信息，兴趣点推荐主要利用 度，纬度>表示兴趣点的坐标位置。用户u对兴趣点
用户历史签到记录及辅助信息从大量地点中为用户 的签到记录表示为 L ，将用户的签到记录转换为用
u
推荐心仪的地点。然而，兴趣点推荐是一项颇有挑 户-兴趣点交互矩阵 R ，R 中的每个元素 R 表示了
ui
战性的内容，用户的偏好受到多种因素的影响，这些 用户u对兴趣点i的签到次数，签到次数反映了用户
影响推荐的因素类型繁多且复杂，传统的推荐方法 的偏好。据此，基于位置的社交网络图可描绘如图1
难以有效构建用户的偏好模型，因此有必要充分发 所示。
掘新的推荐方法，以适应兴趣点推荐服务的发展。
同时，为了评估推荐算法的有效性，对推荐效果的评
估与跟踪也是兴趣点推荐的重要研究内容。
根据以上的目标，本文在了解兴趣点推荐的基
本概念与框架的基础上，从兴趣点推荐系统的研究
中总结了三个核心问题：首先是分析影响兴趣点推
荐的因素，即明确影响用户对兴趣点偏好的因素有
哪些。本文归纳为用户自身的偏好、地理位置、社交
关系、时间信息、内容信息与流行度。其次是探索现
有的兴趣点推荐算法，即兴趣点推荐采用何种方法
1
来建模用户对兴趣点的偏好，以构建合理高效的推
Fig.1 Location-basedsocialnetwork
荐模型。本文总结分析了基于矩阵分解算法的推
荐、基于图嵌入的推荐与基于深度学习的推荐这三 兴趣点推荐作为传统在线推荐（如电影、图书和
种方法的应用与发展。最后是算法的评价模块，即 新闻推荐系统等）在社交网络领域的延伸，不仅能帮
评估算法的性能与有效性。本文归纳了目前流行的 助用户维系现实世界中的社交关系，还能为用户提
几种预测指标及排序指标，并分析其应用情况。 供个性化的服务。为了进一步理解兴趣点推荐系统， 1464 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(7)
以下将对其与传统推荐系统的区别及基本框架进行 （1）协同过滤推荐
分析与总结。 协同过滤算法作为推荐系统领域中最基础的方
1.1 传统推荐系统 法[4-6]，主要利用用户-项目的历史评分数据来找出相
传统推荐系统主要通过分析用户与项目间的 似用户或项目。该算法主要分为基于内存的方法[4-5]
二元关系[3]，利用评分信息构建用户对项目的偏好 和基于模型的方法[6]。基于内存的方法可进一步分为
模型，以挖掘用户感兴趣的项目。通常利用U u 基于用户的协同过滤[4]和基于项目的协同过滤[5]，如
={ 1,
u u 表示用户集，m 表示用户的个数，利用 I 图3所示。其中，基于用户的协同过滤认为具有相似
2,…, m} =
i i i 表示项目集，n表示项目的个数。用户与 偏好的用户具有相同的兴趣，基于项目的协同过滤
{1, 2,…, n}
项目的关系如图2（a）所示，若用户对项目进行评分， 则认为用户倾向于喜欢其之前感兴趣项目的相似项
则以连线的方式表示它们之间的交互。同时，将图2 目，两者都是基于评分数据的推荐。另外，基于模型
（a）的交互关系转化为图2（b）的用户-项目评分矩阵， 的方法主要采用机器学习（如矩阵分解算法、深度学
矩阵中的元素为用户u对项目i的评分，空值表示用 习技术等）和数据挖掘技术（如聚类及分类算法等），
户未对此项目进行评分。在现实生活中，实际存在 通过评分矩阵数据不断训练得到模型参数，并建立
着海量的用户和项目数，而用户评分的项目个数较 相关的推荐模型，以预测用户的兴趣偏好。
有限，因此用户-项目评分矩阵极其稀疏，面临严重的 在最早的推荐工作中，协同过滤算法常用来做
数据稀疏问题，如何缓解稀疏问题以提高推荐性能 评分预测。在兴趣点推荐领域，已有的研究[7-8]主要
是传统推荐系统的挑战之一。 将情景信息融入协同过滤算法中。文献[7]将地理和
社会信息嵌入基于用户的协同过滤框架中，预测用
户的潜在偏好。文献[8]考虑实时推荐问题，将时间
纳入协同过滤算法中，描述用户的时间偏好。因此，
协同过滤算法由于模型的构建相对简单且易实现而
得到了广泛应用。但算法本身极易遭受数据稀疏的
影响，同时还存在冷启动问题，若单纯采用协同过滤
算法，可能导致较低的推荐准确率。
2 （2）基于内容的推荐
Fig.2 Usersinteractiondata 基于内容的推荐方法的基本思想主要是推荐用
户与之前喜欢项目的类似项目[9]。首先分析用户的显
在推荐系统中，推荐算法作为核心的技术，其性
隐性特征及相关文本信息，挖掘出与用户偏好有关
能的高低决定了推荐的效果。传统的推荐方法主要
的标签及项目的属性，接着度量项目间的相似性，将
分为协同过滤推荐（collaborative filtering，CF）、基于
用户偏好的项目与其他项目的相似性排序，向用户
内容的推荐（content-based）和混合推荐（hybrid），具
推荐其潜在感兴趣的项目。该方法不需要评分记录，
体分类如图3所示。以下对三种推荐方法的内容及
可有效解决协同过滤算法的冷启动问题，但推荐系
应用进行介绍。
统中可用的属性信息极为有限，具有一定的局限性。
（3）混合推荐
为了克服上述两种方法的不足，出现了混合推荐
策略。该方法主要将多种推荐算法融合，通过引入
辅助信息来缓解数据稀疏和冷启动问题，进而改善
推荐的准确率。文献[10-11]融合了基于协同过滤和
基于内容的方法进行推荐。Guo等人[12]将协同过滤
方法结合其他技术实现位置的推荐。Yuan等人[8]将
时间分别融入协同过滤和矩阵分解框架中，采用混
3 合推荐的方式实现兴趣点的动态推荐。因此，混合
Fig.3 Categoryofrecommendationalgorithms 推荐方法被广泛应用，但算法的复杂性较高，且运行 陈江美 等：基于位置社交网络的兴趣点推荐系统研究综述 1465
时间较长，目前还需探索新的方法与技术应用到兴 面临更多样化的决策问题。
趣点推荐工作中。 具体地，本文将传统推荐系统与兴趣点推荐系
1.2 兴趣点推荐与传统推荐的区别 统的区别进行总结，如表1所示。
兴趣点推荐指在传统的社交网络中增加位置信
1
息，以便社交网络中的用户能直接共享兴趣点信
Table1 Differencebetweentraditionalrecommendation
息。与传统的推荐系统相比，由于LBSN中用户与兴
andPOIrecommendation
趣点存在的相依性及兴趣点本身的独有属性（如时
比较类型 兴趣点推荐系统 传统的推荐系统
序性、粒度属性等）[13]，使得兴趣点推荐系统存在诸多
位置维度 有 无
异于传统推荐系统的特点。本文从影响推荐的因素、
信息来源 签到数据、情景信息 评分信息
推荐方法及推荐存在的问题三方面进行分析比较。 数据类型 隐式数据 显式数据
（1）从影响推荐的因素考虑，传统的推荐系统主 推荐结果展示 基于评价的方式、列表方式 基于评价的方式
要利用评分数据进行预测和推荐。兴趣点推荐系统 数据稀疏、冷启动、序列推
解决问题 荐、动态推荐、个性化推荐、数据稀疏、冷启动
的影响因素主要包含用户签到数据和多类型的情景
异地推荐
信息，如地理、时间、社交和兴趣点流行度等，并采用
有效的算法构建模型以模拟用户的决策行为。另 1.3 基本框架
外，LBSN中多层级的网络结构使得用户的社交关系 近年来，学者们主要利用LBSN中用户的签到记
相较于传统推荐系统更为复杂，从而影响推荐因素 录及情景信息模拟用户的决策行为，从而为用户推
的多样性。 荐其可能感兴趣的地点。为了进一步了解兴趣点推
（2）从推荐方法来看，传统的推荐只需根据用户 荐的工作流程，总结得到一个通用的推荐框架如图4
的历史记录构建偏好模型，由2.1节可知，其主要采 所示。该框架由三部分构成，即数据来源、推荐算法
用协同过滤算法、基于内容的算法和混合推荐算法 和算法评价。数据来源主要包括LBSN中用户和兴
进行项目的推荐。由于兴趣点推荐相较于传统的推 趣点的基本属性数据及相关的情景信息（即影响推
荐新增了位置信息及其附带的标签信息，采用传统 荐的因素）。为此，本文将主要对影响兴趣点推荐的
的推荐算法可能无法满足复杂的推荐任务与精准推 因素进行总结与阐述；推荐算法是推荐工作的核心，
荐的需求，需要运用新技术解决更复杂的任务。例 算法的性能决定了最终推荐的效果。本文将当前主
如，考虑兴趣点的标签信息，需采用深度学习等相关 流的兴趣点推荐算法分为矩阵分解算法、基于图嵌
技术来挖掘兴趣点更深层次的隐特征，从而为用户 入的方法及基于深度学习的方法；算法评价是推荐
推荐适合其偏好特征的兴趣点。因此，兴趣点推荐 的最后一步，利用相关的评价指标可有效评估算法
相较于传统的推荐需要更多技术支撑，才能更有效 的性能和效率，从而完成推荐任务。
地完成推荐任务。
（3）从推荐工作存在问题的角度考虑，传统的推
荐主要存在数据稀疏和冷启动两大问题。数据稀疏
是指用户-项目评分矩阵多数为空值；冷启动是指系
统如何给新用户进行推荐的问题。在兴趣点推荐工
作中，还面临着序列推荐、动态推荐、个性化推荐和
异地推荐等问题。序列推荐的任务是根据当前所在
的位置，为用户推荐下一个可能签到的地点。在动
态推荐问题上，Gao等人[14]最早将时间纳入兴趣点推
荐，利用时间间隙划分用户-兴趣点签到矩阵。为了
4
实现个性化推荐，文献[15-16]采用核密度估计方法描
Fig.4 FrameworkofPOIrecommendationsystem
述用户的地理偏好，进而捕捉用户的移动行为。在
异地推荐上，任星怡等人[17]采用了多种上下文信息建 为此，围绕兴趣点推荐系统的基本框架，本文接
模用户偏好，从而实现异地推荐。因此，兴趣点推荐 下来将对影响兴趣点推荐的因素、推荐算法及算法 1466 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(7)
评价指标这三方面的内容展开介绍，并对其代表性 函数捕捉用户的地理偏好，但每个用户应当具有独
工作进行概述与对比。 一无二的签到分布。据此，Zhang等人[15]采用核密度
估计方法为每个用户分配唯一的概率密度函数。文
2 影响兴趣点推荐的因素 献[16]对核密度估计方法进一步扩展，采用二维的坐
兴趣点推荐通常受到多种因素的影响，其中用户 标改进一维的距离来建模地理偏好，度量用户u对未
对兴趣点的签到信息反映了用户的行为偏好，对于研 签到兴趣点l的概率：
究兴趣点推荐任务具有重大的应用价值。此外，位 n
f l|u 1 r K l l （1）
置社交网络中的情景信息影响着用户的决策和推荐
( u)= A∑
j
( uj· H( - j))
=1
的准确率。为此，本文将影响兴趣点工作的因素归 ■ x x2 y y2■
纳为以下六方面：用户偏好[18-23]、地理信息[7,15-16,20-21,24-29]、 K H(l -l j)= 2πH1 1H 2exp ■| | -( 2j H- 12) - ( 2j H- 22) ■| | （2）
社交关系[7,15,17,30-36]、时间信息[8,14,37-43]、内容信息[44-48]和流
其中，A表示用户签到兴趣点的总次数；K l l 表
H( - j)
行度[8,17,29,49-51]。在此基础上，对探究各影响因素的相
示两个固定带宽 H H 的标准核函数。
关工作进行分析与归纳。 ( 1, 2)
为了实现用户个性化推荐，文献[20]对文献[16]
2.1 用户偏好
的固定带宽加以改进，提出自适应带宽h ：
用户的决策行为受自身偏好的影响极为显著， u
β
在兴趣点推荐工作中，用户的偏好可表现为用户签 ■ ■n n ■-1 ■-
| |
h | f l|u | f l|u （3）
到兴趣点的次数与评论等。通常将用户的签到次数 u=|| ∏ ( u)| · ( u)|
■■ j =1 ■ ■
量化为偏好程度，若用户经常访问此地点，表明用户
■ x x2 y y2■
对 签兴 到趣 数点 据的 并偏 融好 合程 地度 理越 信高 息。 ，采So 用ng 基等 于人 用[18] 户提 的取 协用 同户的
过
K Hh u(l -l j)= 2πH1 1H 2h2 uexp ■| | -( 2Hj- 12h) 2
u
- ( 2Hj- 22h) 2
u
■| |（4）
其中，β 是敏感参数。最终，利用文献[20]的自适应
滤算法为用户推荐兴趣点。Zhou等人[19]利用协同过
核密度估计模拟用户的行为，获取用户的预测偏好：
滤算法对用户偏好进行个性化建模，并综合考虑了
n
好友重要性与签到相关性的影响。但上述算法遭受 pG F l|u 1 r K l l （5）
数据稀疏的影响，性能有待进一步地改进。在此基
ul= Geo( u)= A∑
j
( ij· Hh i( - j))
=1
上述研究主要对用户的地理行为建立统一的模
础上，文献[20-21]利用矩阵分解算法学习用户偏好，
型。近年来，将地理信息与其他影响推荐的因素融
通过用户的签到信息推测出用户和兴趣点的隐特征
合成为趋势。文献[21,25-26]将地理与社交信息融
向量。另外，用户的评论内容反映了用户的偏好，若
合，利用矩阵分解算法求解用户与兴趣点的偏好特
用户的评论内容为积极态度，如附带“喜欢”或“满
意”等词，体现了用户对此兴趣点感兴趣。文献[20] 征。文献[27]提出地理-时间交互网络模型，探索兴
利用聚合LDA（latentDirichletallocation）算法学习用 趣点对之间的联系，实现下一个兴趣点的推荐。因
户的评论信息，并将提取到的偏好与兴趣点的特征 此，探索地理信息的模型已较为成熟，如何进一步融
进行匹配。Xiong等人[22]提出概率生成模型实现用户 合LBSN中的异构信息是下一步研究的重点。
特征偏好的提取。Xing等人[23]利用深度学习技术挖 2.3 社交关系
掘用户的评论信息，以学习用户的偏好。因此，充分 在位置推荐中，最初是利用协同过滤算法建模
利用用户的签到次数及评论信息可有效构建偏好模 社交关系来实现用户偏好的预测[7,14,24]，但利用协同过
型，但由于用户决策的复杂性，需要进一步考虑情景 滤方法时，用户相似度的度量易受局部异常点影响，
信息对用户行为的影响，以更精准地推荐。 且算法极易遭受稀疏问题，为此，矩阵分解方法受到
2.2 地理位置 关注。Qian等人[30]利用概率矩阵分解模型建模三种
地理位置是兴趣点推荐区别于传统推荐的根本 社交关系。Zhang等人[31]将用户的标签、社交和地理
特征。考虑用户倾向于签到距离较近的地点，Ye等 信息融入矩阵分解框架中，改善推荐性能。上述算
人[7]提出幂律分布模型描述用户签到特征。Cheng等 法实质是利用LBSN中的好友关系预测用户对兴趣
人[24]考虑用户偏向在多个中心点范围内签到，提出多 点的偏好分数。近年来，信任理论不断应用于推荐
中心的高斯分布模型。上述的模型采用相同的分布 领域，基于信任的推荐已拓展到兴趣点推荐中。Zhu 陈江美 等：基于位置社交网络的兴趣点推荐系统研究综述 1467
等人[32]提出一种信任预测方法，综合考虑用户间的信 到时间，利用注意力机制捕捉用户的长期偏好，并基
任度与相似度向目标用户推荐好友，并融合用户偏 于兴趣点序列和类别序列建立两个LSTM模型来模
好与地理影响。Xu等人[33]将用户偏好、社交关系与 拟用户的短期偏好。为此，现有的序列推荐工作主
时空信息融入矩阵分解算法中，通过挖掘用户的直 要融合时空信息，并应用神经网络及其拓展技术来
接信任和间接信任关系捕捉用户的社交影响。文献 实现。
[34-36]利用图模型来表示用户的社交关系，图中相 综上，用户在时间信息上展现出的周期性与序
关节点的关系反映了用户间的交互，该方法取得了较 列性的签到行为影响着用户的行为偏好，时间因素
显著的效果。由此可见，目前的研究主要是利用好友 对兴趣点推荐的研究具有重要作用。
间的相似度和信任度来度量用户的社交影响，根据 2.5 内容信息
好友的喜好预测目标用户的偏好，未来的工作将需 兴趣点的内容信息影响着用户的决策，相关学
要探索更多高效的方法来捕获用户间的社交关系。 者逐渐利用兴趣点的内容信息来挖掘其附带的属性
2.4 时间信息 特征，从而更有效率地实现用户的个性化推荐。Chen
用户对兴趣点的签到时间反映了用户的时间偏 等人[44]将兴趣点的文本内容嵌入深度学习模型，更深
好，考虑用户的签到行为受时间信息的影响，会根据 层次地捕捉兴趣点的标签信息。Zhao等人[45]融合了
时间的变化呈现出周期性和序列性的行为。为了描 兴趣点的情感属性和地理属性，利用概率矩阵分解
述用户的周期性行为，Gao等人[14]考虑时间的差异性 技术挖掘用户与兴趣点的潜在特征。为了充分利用
和连续性特征，并将此属性融入矩阵分解框架中，以 上下文信息，Zhang等人[46]运用社交网络中的图像内
刻画用户的时间特征。文献[8]将时间信息融入协同 容和地理信息捕捉用户的偏好，采用加权矩阵分解
过滤算法中，并结合兴趣点的时间流行度进行推荐。 算法学习用户及兴趣点的深层特征。上述的工作主
上述算法主要采用时间间隙将用户-兴趣点签到矩阵 要利用矩阵分解和深度学习来提取相关特征，以预
划分为若干个签到矩阵，加剧了数据稀疏问题。基 测用户偏好。然而，LBSN中存在的多是异构数据，
于此，Ying等人[37]提出非对称投影的时间感知嵌入方 这些数据复杂且难以建模，探索更多的特征提取技
法刻画时间特征。文献[38]利用神经网络方法提取 术来处理异构数据是未来研究的重点。
时间特征向量，能较好应对数据稀疏问题，进而改善 2.6 流行度
推荐性能。在最新的一项研究中，Yin等人[39]考虑用 流行度是指兴趣点受用户欢迎的程度，体现了兴
户的时空偏好行为，将协同过滤算法与模糊聚类算 趣点推荐系统提供的服务与质量。目前相关的研究
法结合，有效地实现了兴趣点的动态推荐。 普遍将兴趣点的流行度作为用户的先验知识。Yang
序列性签到行为在兴趣点推荐中主要表现为用 等人[49]利用用户生成的文本和图像内容预测兴趣点
户在当前时间签到对下一个时间签到地点产生的影 的流行度，以缓解兴趣点信息的稀疏影响。兴趣点
响，即衍生出序列推荐问题。序列推荐侧重于为目 流行度具备时间属性，即实时性问题。Yao等人[50]考
标用户在一段时间内（如几个小时）推荐某些地点， 虑兴趣点的流行度受时间影响，提出将用户与兴趣
是一项重要的推荐任务。文献[40]整合了时间和地 点间的时间匹配度融入推荐框架中。Yuan等人[8]采
理特征，构建了一个基于图的潜在表示模型，并结合 用流行度信息衡量兴趣点被签到的先验概率，并将
LSTM（longshort-termmemory）神经网络来模拟用户 其与地理、时间信息融合，实现动态推荐。另外，Si等
复杂的移动行为，实现兴趣点的动态序列推荐。文献 人[51]深入探索了流行度的影响，将连续签到时间段的
[41]提出将时空上下文信息输入到LSTM框架中，融 流行度结合地理影响来完成推荐。该模型提出了两
合基于注意力机制模型来提取签到序列中的签到记 种推荐策略，对待活跃用户运用二维核密度估计建
录，以实现下一个兴趣点推荐。为了实现实时推荐， 模地理偏好，对待非活跃用户运用一维幂律分布模
Wang等人[42]考虑了兴趣点的类型与签到时间，利用 拟地理影响，再分别融合时间流行度特征实现兴趣
基于注意力机制的循环神经网络学习上下文信息， 点推荐。上述研究主要将流行度和其他情景信息相
更好地预测用户下一个签到的兴趣点。基于此，Wu 结合，说明了流行度信息在推荐工作中的重要地位。
等人[43]丰富了上下文信息，采用线性组合的方式对用 上述对影响兴趣点推荐的因素进行了阐述，并
户的长短期偏好建模。该模型融合了类别信息和签 总结了相关代表性工作。表2分析了几种重要模型 1468 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(7)
考虑的影响因素，并归纳了算法的优点与局限性。 3 兴趣点推荐算法
文献[14,28]只考虑了单一信息的影响，因此推荐准确 兴趣点推荐的影响因素类型多且复杂，利用传统
率较低。文献[17]融合了多种信息到矩阵分解算法 的推荐方法（如协同过滤推荐方法等）无法进一步建模，
中，可有效缓解数据稀疏性，但该算法未能充分挖掘 因此衍生出不同类型的推荐算法与技术。目前的兴趣
兴趣点的特征。同时，为了探究不同因素的影响，文 点推荐方法主要朝着矩阵分解算法[14,20-21,24-26,30-31,33,46,52-57]、
献[7]通过消融实验获得地理信息在推荐中的影响高 基于图的方法[34-36,58-60]与基于深度学习[23,61-72]的方向发
于其他因素。文献[17]提出了本地和异地推荐两种 展。以下将重点对兴趣点推荐的核心算法及其相关
情景，实验得出在异地场景中内容信息影响最大，在 代表工作进行详细阐述与对比总结。
本地推荐场景中时间信息影响最大。以上说明了各 3.1 矩阵分解算法
影响因素在推荐工作中发挥的不同作用。此外，从 矩阵分解算法（matrix factorization，MF）能有效
表2可知，除了常见的几种情景信息外，文献[48]考虑 缓解数据稀疏问题，且能够挖掘用户和兴趣点的特
了社交网络中的图像内容，利用矩阵分解和深度学 征，因此被广泛应用到推荐工作中。该方法采用降
习技术挖掘用户与兴趣点的特征，从而改善推荐性 维的方式将用户-兴趣点矩阵 R分解为低维空间上的
能。因此，现有研究还存在一定的局限性，仍有一些
用户隐特征矩阵U ={U 1,U 2,…,U m}∈Rk ×n 和兴趣点隐
影响用户决策的因素未加以考虑，如天气、交通等， 特征矩阵V ={V 1,V 2,…,V n}∈Rk ×m，k为隐特征个数，并
如何建模这些因素对推荐工作的影响是未来研究的 通过训练使两者乘积 R  ij 尽可能接近 R ，其对应的优
重点。 化问题如式（6）所示：
2
Table2 ComparisonoftypicalalgorithmsininfluencingfactorsofPOIrecommendation
代表算法 影响推荐因素 说明 优点 局限性 代码链接
将用户偏好融合到具
用户偏好、地理、 整合了多种情景 无法解决数据稀疏 http://spatialkeyword.sce.ntu.edu.sg/
USG[7] 有社会和地理影响的
社交 信息 问题 eval-vldb17/code/USG.zip
推荐框架
融合地理信息到加权 捕捉了用户的空 只考虑了地理位置 http://spatialkeyword.sce.ntu.edu.sg/
GeoMF[28] 地理
矩阵分解算法模型 间聚类现象 影响 eval-vldb17/code/GeoMF.zip
将社会影响和个性化 https://github.com/camcochet/iGSLR-
实现了个性化的 无法解决冷启动问
iGSLR[15] 地理、社交 地理影响整合到统一 Personalized-Geo-Social-Location-
推荐 题和数据稀疏问题
的推荐框架 Recommendation
提出时间的连续性和 模拟了时间特征
推荐准确率较低；只 http://spatialkeyword.sce.ntu.edu.sg/
LRT[14] 时间 差异性特征，融入矩 影响；实现了动
考虑了时间影响 eval-vldb17/code/LRT.zip
阵分解框架中 态推荐
适用于异地推荐
地理、社交、时间、 将所有情景信息融入 未解决兴趣点特征
GTSCP[17] 场景；缓解数据 N/A
内容、流行度 联合概率生成模型 缺失的不足
稀疏问题
考虑用户的主要活动 https://paperswithcode.com/paper/
可缓解数据稀疏 未充分考虑其他情
LGLMF[29] 地理、流行度 区域及该区域内每个 lglmf-local-geographical-based-
性问题 景信息的影响
位置的相关性 logistic#code
融合社交和局部地理 可缓解数据稀疏 融合的情景信息较
SLGMF[26] 地理、社交 N/A
因素影响 性问题 有限
https://paperswithcode.com/paper/
将空间和地理信息融 可扩展到其他领 只考虑了空间和文
CRQA[47] 地理、内容 joint-spatio-textual-reasoning-for-
合到联合推理模型中 域的推荐任务 本推理
answering#code
从各模态中提取相关
MM-Gated- 有效捕获多模态 未充分利用兴趣点 https://github.com/danaesavi/poi-type-
内容、图像 信息来获取文本和图
XAtt[48] 间的交互 与用户信息 prediction
像间的交互
注：N/A表示相关文献未提及。 陈江美 等：基于位置社交网络的兴趣点推荐系统研究综述 1469
|U| |V| 表示时间相关项；Trust 表示信任关系值。
1 ||R UTV||2 （6） uv
mU ,iVn 2∑ i ∑ j ij- i j F 另外，Davtalab等人[53]融合了地理信息、射箭关系
=1 =1
与传统推荐工作相比，兴趣点推荐不仅采用矩 和时间信息到概率矩阵分解框架中。文献[54-55]采
阵分解算法求解用户及项目的隐特征，还能进一步 用联合矩阵分解的方法捕获用户的偏好，从而解决隐
地将情景信息嵌入矩阵分解框架中，以预测用户的 式反馈问题。上述算法利用不同类型的矩阵分解方
偏好。文献[33]将社交关系融入矩阵分解算法，采用 法求解用户的偏好矩阵，适用于预测稀疏数据集的
添加正则项的方式求解用户偏好矩阵 R ，通过优化 用户偏好，但缺点是这类方法往往训练时间较长。
式（7）模型来实现。其次，将用户关系兴趣矩阵 H 分 3.2 基于图嵌入方法
解为用户关系隐特征矩阵W 和兴趣点隐特征矩阵 基于图嵌入方法（graph embedding，GE）能够形
V ，求解 H 的优化函数如式（8）所示。最后，将式（7） 象地将数据及其对应的关系刻画到图上，其兴起为
与（8）联合求解，并采用随机梯度下降法优化式（9） 社交网络的研究拓宽了新的思路。在LBSN中，兴趣
的目标函数。 点推荐往往包含着用户对兴趣点的偏好关系与用户
|U| |V| |U| |V|
社交关系。为此，可利用图模型将这两种关系描绘
1 ||R UTV||2 λ ||U||2 λ ||V||2（7）
mU ,iVn 2∑ i ∑ j ij- i j F+ u∑ i F+ v∑ j F 成图5所示的二分图网络[73]。在二分图网络中，用户
=1 =1 =1 =1
|W| |V|
若签到过兴趣点，则将两节点相连，若两个用户是好
1 ||H WTV||2
mW ,iVn 2∑ if ∑ j if ,j- if j F+ 友关系，则利用边连接两个用户。近年来，图嵌入的
=1 =1
|W| |V| 方法得到了广泛的应用，接下来将对基于图的兴趣
λ ||W||2 λ ||V||2 （8）
w∑ if F+ v∑ j F 点推荐方法进行概括。
=1 =1
α |U| |V|
ΩU W V 1 ||R UTV||2
min ( , , )= 2∑
i
∑
j
ij- i j F+
=1 =1
α |W| |V| |U|
2 ||H WTV||2 λ ||U||2
2∑
if
∑
j
if ,j- if j F+ u∑
i
F+
=1 =1 =1
|V| |W|
λ ||V||2 λ ||W||2 （9）
v∑
j
F+ w∑
if F
=1 =1
其中，λ 、λ 与 λ 为正则化参数；矩阵元素 H 为用
u v w ifj
, 5
户与好友对兴趣点的偏好度；α 与α 为调整因子。
Fig.5 Bipartitegraphnetwork
1 2
在最新的推荐工作中，为了深度挖掘用户的潜
Zhu等人[34]提出了一种融合社交与地理信息的
在偏好，文献[52]将用户偏好、信任关系和时空信息
图嵌入表示方法。该方法将用户嵌入与社交图嵌入
融入到一个改进后的SVD矩阵分解框架中。该方法
结合获得用户的特征表示，将兴趣点嵌入与地理图
在原有模型的基础上提高了准确率，同时考虑了信
嵌入结合获得兴趣点的特征表示。最终，在神经网
任关系。对应的优化函数如下：
络框架下捕获用户与兴趣点的潜在交互，从而得到
m n
argmin
f (P ,Q
)=
1 ∑∑a ui(R ui-P uTQ i)2
+
用户的偏好。此模型可有效缓解协同过滤推荐算法
2u i
m=1 m=1 无法解决的数据稀疏问题，并提高推荐质量。
1 2∑
u
∑
u
vS (u ,v )||Q u-Q v||2 F+ Lu等人[58]将图模型的方法应用到下一个兴趣点
=1 ≠
λ λ 推荐的场景中，建立了一个改进的基于图的潜在表
u||P||2 v||Q||2 （10）
F+ F 示模型，利用历史签到记录捕获时间序列影响与用
2 2
在式（10）的目标函数中，第一项表示基本的用户偏
户的时间偏好。在此基础上，使用LSTM神经网络模
好。此方法的创新之处在于第二项，Su v 表示用户
型扩展原有框架，以模拟用户复杂的移动行为。最
( , )
相似度，结合了信任与时空信息，具体如式（11）所示： 终，利用学习到的潜在表示完成推荐任务，获得了较
SZ Z n a a Trust
Su v ( u, v) ( ui′+1)( vi′+1) uv （11） 好的准确率。但此方法对社交网络中情景信息的挖
( , )= ku ku ∑ ko
( u) ( v) i =1 ( i) 掘不够充分，仍有待改善。
其中，SZ Z 定义为空间距离相关项；a a 为了丰富情景信息，Qiao等人[35]提出了一种健壮
( u, v) ( ui′+1)( vi′+1) 1470 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(7)
的基于图嵌入的算法，能够有效解决社交网络中的 网络、循环神经网络和图神经网络技术的推荐方法。
异构性问题。该方法利用异构图融合了用户社交关 卷积神经网络（convolutionalneuralnetwork，CNN）
系、地理和时间信息，生成了一个联合的表示学习框 的基本结构如图6所示，包括输入层、卷积层、池化
架。具体地，通过综合考虑情景信息的影响，得到异 层、连接层与输出层。Xing等人[61]考虑了地理位置、
构图中节点间的转移概率，并利用异构图中的拓扑 社交关系和评论信息，并将这些因素融合到一个基
结构来学习用户与兴趣点的潜在表示。实验结果表 于卷积神经网络和概率矩阵分解模型的框架中，从
明，该方法提升了推荐的性能，且能够处理兴趣点推 而挖掘用户与兴趣点的特征。随着研究的深入，该
荐中的冷启动问题。 团队将兴趣点的属性、用户偏好和情感信息融入卷
Chen等人[36]提出了一种多任务嵌入的个性化推 积神经网络框架，利用神经网络捕捉评论内容中的
荐方法，分别采用了序列嵌入和图嵌入的方式对用 语义信息，从而解决用户偏好的不可解释性问题和
户的签到行为建模。该模型融合了序列数据、社交 数据稀疏问题，生成了效果更优的潜在模型[23]。冯浩
关系、语义信息和时空信息，利用序列嵌入方法捕获 等人[62]利用卷积神经网络学习用户评论信息的特征，
签到数据中的序列信息，再利用图嵌入的方式在用 最终通过学习到的特征表示进行位置推荐，以改善
户-用户、用户-兴趣点和用户-时间等关系图中捕获 算法的性能。
情景信息的影响。该研究通过不同的嵌入方式探究
各类信息的影响，有效地提高了推荐的性能。
在最新的一项研究中，Hu等人[59]建立了一种模
拟用户动态偏好的方法，目的在于有效地捕捉用户
的细粒度偏好。该方法嵌入了地理和时间信息，旨
在探究其对兴趣点级与项目级的影响，并融入到基
6
于图嵌入的模型中，从而解决数据稀疏和冷启动问
Fig.6 Structureofconvolutionalneuralnetwork
题，但不足之处在于可解释性较低。
上述对图嵌入方法在兴趣点推荐中的相关应用 循环神经网络（recurrentneuralnetwork，RNN）主
进行了介绍，借助图嵌入方法，能够利用图对LBSN 要用于处理时间序列数据，大多数兴趣点推荐的研
中存在的用户、兴趣点和用户社交等节点关系进行 究主要应用该技术来完成序列推荐任务。Xia等人[63]
建模，从而深层地挖掘社交网络间的关系，有效地将 提出了一种基于注意力机制的循环神经网络，能根
推荐问题转化为图中相关节点的交互问题，缓解了 据相应用户的序列签到数据来模拟用户的生活模
数据稀疏和冷启动问题。虽然基于图的方法为兴趣 式。相较于传统的推荐方法，利用神经网络模型提
点推荐工作提供了新的方向，但其可解释性较低。 高了算法的可解释性。Chen等人[64]提出了一个有监
随着深度学习的兴起，学者们逐渐将深度学习迁移 督的循环神经网络学习预测模型，该模型考虑了用
到图上来，形成了图神经网络等重要的方法，来进一 户的兴趣、地理位置和时间信息，最终形成了用户兴
步弥补上述方法的不足。 趣和上下文信息的综合特征表示。然而，上述的研
3.3 基于深度学习方法 究在对用户的短期偏好建模时忽略了用户的长期偏
鉴于传统的推荐方法在构建复杂模型时训练效 好，导致推荐结果不可靠。为此，Sun等人[65]提出了
果不佳，且利用矩阵分解算法易出现过拟合问题，深 一种新的适用于下一个兴趣点推荐的方法，该方法分
度学习技术受到了学者们的关注与青睐。深度学习 别对用户的长短期偏好建模，并融合地理信息与用
（deep learning，DL）通过构建多层神经网络结构，对 户的短期偏好到循环神经网络中。Huang等人[66]考
原始数据中的简单特征进行组合，从而能够获取更 虑了相似用户的历史数据，利用循环神经网络与基于
加抽象的语义特征表示。近年来，深度学习借由其 协同过滤算法建模用户的行为，从而捕捉用户的偏
强大的学习能力，以及能够深层次地表征用户与项 好。该模型克服了当前多层感知机与LSTM推荐方
目的潜在特征的特点，已被广泛地应用到推荐系统 法的不足，在兴趣点推荐场景下得到了有效的应用。
中。以下将对深度学习中各种神经网络在兴趣点推 基于图推荐方法的兴起为社交网络的研究拓宽
荐中的工作现状进行总结，主要包括针对卷积神经 了思路，学者们开始关注将深度学习模型运用到图数 陈江美 等：基于位置社交网络的兴趣点推荐系统研究综述 1471
据上，而图神经网络（graphneuralnetwork，GNN）成为 兴趣点推荐中的应用进行了对比与归纳，介绍了CNN
其中最活跃的方法。Zhong等人[67]提出混合图卷积 技术在表征潜在特征方面的优势，总结了RNN在序
网络模型，利用兴趣点对之间的地理距离构建空间 列推荐上的应用以及GNN结合各情景信息来解决异
图，采用图卷积网络表示兴趣点间的连通性，该模型 构性问题，说明了深度学习是该领域应用的重要技
为缓解数据稀疏问题提供了有效途径。为了建立更 术。为此，相关领域的学者应准确把握深度学习的最
强大的推荐模型，Zhang等人[68]利用图神经网络构建 新发展趋势，为兴趣点推荐的发展寻求新的突破点。
出一个包含用户节点和兴趣点节点的社交网络图，分 综上，本文在传统推荐方法的基础上不断延伸，
别从节点信息和拓扑结构中学习节点的特征表示。 概括了基于矩阵分解的算法、基于图嵌入的方法和
用户节点利用了相邻社交节点和具有签到行为的兴 基于深度学习的方法的应用，分析了不同推荐方法
趣点的表示来学习，并采用注意力机制来学习社交 目前已解决的问题。为了系统地了解各推荐方法的
网络关系的异质结构。兴趣点节点融合了地理和时 应用，表3对比归纳了各方法中代表性工作的特点、
间信息特征，利用双向的长短期记忆模型来模拟用 优缺点及相应的代码链接。
户的序列签到行为。该模型有效提高了推荐的效果， 由表3可知，矩阵分解算法主要通过融合各情景
能普遍运用到各类推荐任务中。在实际应用中，Kang 信息，采用降维的方式求解用户与兴趣点的隐特征，
等人[69]将监测站的位置制定为包含时间空间的图节 进而预测用户偏好。该算法能够缓解数据稀疏问题，
点推荐问题，设计了一个有效的基于空气质量推断 但训练时间较长，且会出现过拟合问题。基于图嵌
的高阶图卷积模型，进而捕捉空气质量分布的时空 入的方法通过构建关系图来反映用户与兴趣点的关
特征。该模型利用节点增量学习方法来判断节点的 系，并将各情景信息描述到图上，能缓解数据稀疏性，
优先级顺序，最终依据优先级顺序完成推荐任务。 但存在可解释性较低等问题。深度学习技术与矩阵
上述将深度学习中的CNN、RNN与GNN方法在 分解方法都具备挖掘用户与兴趣点特征的能力，相
3
Table3 ComparisonoftypicalalgorithmsinPOIrecommendationmethods
推荐算法类别 代表算法 说明 优点 局限性 代码链接
考虑三类朋友来寻找每个用户 考虑了朋友的影 https://paperswithcode.com/paper/
融合的情景
ASMF[56] 的潜在兴趣点，并将地理和分 响，同时可缓解 point-of-interest-recommendations-
信息较有限
类信息融入矩阵分解框架中 数据稀疏问题 learning#code
基于矩阵分解 利用加权矩阵分解算法融合地 捕捉了用户的空 考虑的情景 http://spatialkeyword.sce.ntu.edu.sg/
GeoMF[28]
的兴趣点推荐 理信息 间聚类现象 信息单一 eval-vldb17/code/GeoMF.zip
可缓解数据稀疏 https://paperswithcode.com/paper/
将时空信息合并到矩阵分解模 无法解决冷
STACP[57] 问题；实现动态 joint-geographical-and-temporal-
型中 启动问题
推荐 modeling#code
利用异构图融合用户的社交、 解决社交网络的 模型的复杂
UP2VEC[35] N/A
地理和时间信息 异构性问题 度较高
利用基于图的方法从各信息关 https://paperswithcode.com/paper/
基于图嵌入的 未考虑节点
RELINE[60] 系图中学习用户和兴趣点表 解决冷启动问题 reline-point-of-interest-
兴趣点推荐 属性
示，并嵌入到潜在空间中 recommendations#code
利用基于图嵌入的方法捕获时 可有效模拟用户 可解释性较
GLR[58] N/A
间序列和用户时间偏好信息 复杂的移动行为 低
https://paperswithcode.com/paper/
利用自注意力机制建模序列信 可有效表征用户 模型的复杂
DAN-SNR[70] dan-snr-a-deep-attentive-network-
息和社交影响 与兴趣点的特征 度较高
for-social#code
基于深度学习 利用图神经网络构建用户-兴 适用于各类推荐 模型的复杂
GNN-POI[68] N/A
的兴趣点推荐 趣点节点的网络图 任务 度较高
考虑了非相邻位 https://paperswithcode.com/paper/
一种时空双向注意模型，充分 融合的情景
STAN[71] 置和非连续签到 stan-spatio-temporal-attention-
考虑了相关位置的时空效应 信息较有限
位置的相关性 network-for-1#code
注：N/A表示相关文献未提及。 1472 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(7)
较于矩阵分解方法，深度学习技术能够更深层次地 及其优缺点。接下来，为了更综合、更全面地了解兴
挖掘潜在特征，且具有强大的学习能力，主要缺点是 趣点推荐的发展现状，本文依据研究成果提出的时
模型的复杂度较高。为此，系统地了解各种方法的优 间顺序，以影响推荐的因素、解决的推荐问题及对应
劣势与适用场景，将有利于兴趣点推荐工作的开展。 的推荐算法三方面为核心，探讨与总结各相关工作
以上对影响兴趣点推荐的因素进行了分析，对 的推荐策略，进而充分地了解兴趣点推荐的研究现
各推荐算法的应用进行了描述，并详细介绍了相关 状。相关总结如表4所示。
代表性的工作，有利于理解现有兴趣点推荐的成果 由表4可知，兴趣点推荐已融合了各种影响因素
4
Table4 AnalysisofresearchstatusinPOIrecommendation
影响因素和问题 推荐策略 推荐算法
考虑用户签到兴趣点的概率与物理距离相关，提出幂律分布模型（Ye等[7]，2011） Hybrid
考虑用户在多个中心点范围内签到，提出多中心的高斯分布模型（Cheng等[24]，2012） MF
地理信息 提出核密度估计方法建模用户的地理偏好（Zhang等[15]，2013） Hybrid
提出固定带宽核密度估计方法构建地理偏好模型（Zhang等[16]，2015） —
利用自适应核密度估计方法捕捉用户的地理偏好（任星怡等[20]，2017；Si等[51]，2019） MF等
将情景信息融入矩阵分解框架（任星怡等[20]，2017；彭宏伟等[21]，2019） MF
采用基于用户的协同过滤方法建模签到信息和地理信息（Song等[18]，2019） CF
用户偏好
将好友重要性与签到相关性融入协同过滤方法（Zhou等[19]，2019） CF
利用卷积神经网络挖掘用户评论中的语义信息（Xing等[23]，2019） CNN
利用概率矩阵分解模型建模社交关系（Qian等[30]，2014） MF
提出基于朋友的协同过滤方法（彭宏伟等[21]，2019） CF
影响 社交 将改进后的直接信任与间接信任融入矩阵分解算法（Xu等[33]，2021） MF
因素 利用图嵌入的方法表示用户间的社交关系（Zhu等[34]，2019；Chen等[36]，2021） GE
利用图神经网络构建社交网络图（Zhang等[68]，2021） GNN
提出基于时间感知的兴趣点推荐模型（Yuan等[8]，2013） Hybrid
提出时间的差异性和连续性特征（Gao等[14]，2013） MF
时间 提出基于非对称投影的时间感知嵌入方法（Ying等[37]，2019） —
利用时间信息捕捉用户的动态偏好（Ma等[38]，2020；Yin等[39]，2021） RNN、Hybrid
利用时间序列数据实现下一个兴趣点推荐（Chen等[64]，2020；Huang等[66]，2021） RNN、Hybrid
考虑兴趣点流行度影响用户的决策行为（Yuan等[8]，2013；任星怡等[20]，2017） Hybrid、MF
流行度 利用文本和图像信息预测兴趣点流行度（Yang等[49]，2019） —
将流行度特征结合二维的核密度估计与一维的幂律分布（Si等[51]，2019） —
将兴趣点的文本内容嵌入深度学习模型（Chen等[44]，2020） Hybrid
内容
采用加权矩阵分解算法融合图像内容和地理信息（Zhang等[46]，2019） MF
利用矩阵分解技术缓解稀疏问题（Gao等[14]，2013；温彦等[25]，2019） MF
数据稀疏性 利用图嵌入表示方法缓解稀疏性（Zhu等[34]，2019） GE
采用混合图卷积网络应对稀疏性问题（Zhong等[67]，2020） GNN
利用元路径挖掘用户行为间复杂的语义关系以表征新用户的属性（Yu等[52]，2019） MF
冷启动
提出混合图神经网络模型改善冷启动问题（Zhong等[67]，2020） GNN
提出一种基于注意力机制的循环神经网络实现序列推荐（Xia等[63]，2017） RNN
推荐 序列推荐 提出改进的基于图的潜在表示模型来捕获时间序列影响（Lu等[58]，2020） Hybrid
问题 利用循环神经网络学习情景信息来预测用户下一个签到的兴趣点（Wang等[42]，2021） RNN
提出兴趣点的受欢迎程度受时间影响（Yuan等[8]，2013） Hybrid
动态推荐 考虑用户偏好的动态变化特征（Gao等[14]，2013；Ying等[37]，2019；Ma等[38]，2020） MF、RNN等
利用协同过滤算法与模糊聚类算法捕捉用户的时空偏好（Yin等[39]，2021） Hybrid
提出核密度估计方法描述用户的地理行为（Zhang等[16]，2015；任星怡等[20]，2017） MF等
个性化推荐
融合流行度与二维的核密度估计方法捕捉活跃用户的偏好（Si等[51]，2019） —
异地推荐 提出概率生成模型模拟用户在异地的决策行为（任星怡等[17]，2017） — 陈江美 等：基于位置社交网络的兴趣点推荐系统研究综述 1473
来构建模型，且取得了显著的成效。在解决推荐问 其中，k表示推荐列表的个数；Ru 表示对应算法计
( )
题方面，对数据稀疏、冷启动、个性化、序列与动态推 算训练集后生成的推荐列表；Lu 表示用户u在测试
( )
荐问题的研究颇为丰富，未来研究应将重点放在异 集上真实的签到列表；r 表示真实的评分；r 表示
ui  ui
, ,
地推荐问题上。在推荐算法上，可看出早年主要以
预测评分。
协同过滤算法为基础，接着逐渐利用矩阵分解算法 另外，每个用户推荐生成列表具有有序性，理想
来融合各情景信息，以缓解数据稀疏性。近年来，为 状态是准确率越高的兴趣点排序越靠前越好。因
了更深层次地挖掘用户偏好，相关工作主要利用图 此，针对排序的结果，需通过度量其排序指标来评估
嵌入方法与深度学习来构建模型，从而提高推荐性 算法的性能，常用的指标包括平均精度均值（mean
能。以上的研究总结可为相关领域的研究者提供更 average precision，MAP）和归一化折损累计增益
好的借鉴，同时将前沿的技术应用到兴趣点推荐工 （normalized discounted cumulative gain，NDCG）。两
作中值得探索。 者的区别主要在于MAP考虑对象是二元相关性，即
对象要么喜欢要么不喜欢，而NDCG主要通过实数
4 算法评价指标 的形式进行相关性比较。定义分别如下：
兴趣点推荐系统利用各种推荐算法为用户生成 k
p j rel j
最终的推荐列表，系统通过度量相关的评价指标来 MAP k 1 M ∑ j =1( ( )× ( )) （16）
对构建的算法进行评价，评价的结果反映了算法的
@ = M∑
i
N
=1
k relj
有效性。与传统推荐使用的指标相似，在兴趣点推 DCG 2 () -1 （17）
k=∑ j
荐中，目前常用的预测指标包括准确率（precision）、 j =1lb( +1)
M DCG
召回率（recall）、F1值、平均绝对误差（mean absolute NDCG k 1 k （18）
@ = M∑iDCG
error，MAE）。定义分别如下： i =1 k
其中，j表示排名；p j 表示推荐生成列表中截止到 j
|Ru Lu| ( )
∑ ( )⋂ ( ) 的准确率；rel j 的值取决于用户是否有签到排名 j
precision k u ∈U （12） ( )
@ = |Ru| 的兴趣点，若有签到则值为1，否则为0。
∑ ( )
u U
∈ 推荐的效果取决于评价指标值的高低，对算法
|Ru Lu|
∑ ( )⋂ ( ) 进行评估测量是推荐工作的最后流程。为了了解兴
recall k u ∈U （13）
@ = |Lu| 趣点推荐工作中各指标的应用情况，本文列举了几
∑ ( )
u U
∈ 种重要算法采用的指标。同时为了综合了解算法的
recall precision
F 2× × （14）
1= recall precision 整体性能，将其对应文献所涉及的时间与空间复杂
+
度进行了归纳，如表5所示。
MAE 1 |r r | （15）
= N∑
ui
u ,i-  u ,i
由表5可知，precision和recall是应用最广的预
,
5
Table5 Summaryofevaluationmetricsofseveralalgorithms
代表算法 precision recall F1 MAE MAP NDCG 时间复杂度 空间复杂度
LRT[14] Omnd N/A
√ √ ( )
ASMF[56] Omnd2 N/A
√ √ √ ( )
UCGSMF[21] O m nd2 Md N/A
√ √ (( + ) + )
GSBPR[74] OTmd N/A
√ √ √ √ ( )
APRA-SA[51] Omd n2 N/A
√ √ √ √ ( + )
SPR[45] OTn3d Omn n2
√ ( ) ( + )
MANC[75] N/A N/A
√ √ √ √
ATST-LSTM[41] Omnd2 N/A
√ √ √ ( )
Loc-Interest-LSTM[64] OTKn OKn
√ √ √ ( ) ( )
注：m表示用户的数量；n表示兴趣点的数量；d表示维度；M表示数据集大小；T表示迭代的数量；K表示兴趣主题的数量；N/A表
示相关文献未提及。 1474 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(7)
测指标，因为它们能够最直接反映出预测的推荐列 特征，进而根据每个用户自身特征进行个性化推荐，
表是否符合用户的喜好，所以获得广泛的应用。F1 提高目标领域推荐的多样性与准确性。在兴趣点
作为precision和recall的调和平均值，通常用于评估 推荐工作中，存在数据稀疏问题与冷启动问题，若
算法的整体性能。MAE能够反映预测评分与真实评 融合多个辅助领域的数据来为目标领域进行推荐，
分的差距，在文献[48,52]中，该指标主要用于对推荐 可有效解决兴趣点推荐中的冷启动问题。例如，已
结果进行误差评估，以更有效地评价推荐的准确性。 有工作在对图神经网络的应用中，对用户与兴趣点
MAP与NDCG是经典的排序指标，在文献[74-75]中， 关系图的构建主要停留在单一的层面上，考虑如何
为了综合评估排序的性能，结合了两种指标进一步说 从一个关系图过渡到其他的关系图，进而实现不同
明算法的有效性。因此，在算法评价流程中，采用越 图神经网络框架间的数据迁移，是一个值得关注的
多的预测和排序指标，以及结合适当的复杂度分析 问题。
会增加算法的说服力。同时，进一步发掘更多的评 （4）推荐结果的可解释性
估指标来验证算法的性能，是未来研究的重点内容。 推荐的可解释性指的是向推荐对象提供解释，
使其理解推荐该项目的原因，为了使兴趣点推荐系
5 面临的挑战及研究趋势 统成为一个用户参与的交互系统，必须提高推荐结
兴趣点推荐系统作为一个新兴的研究领域，近 果的可解释性，从而提高推荐系统的有效性及用户
年来取得了较为丰硕的成果，但由于不同场景下推 的满意度。在对兴趣点推荐结果的解释过程中，不
荐的差异性与多样性，导致推荐的难度增加，仍存在 仅要考虑兴趣点的属性，还要关注属性可能随时间
一些挑战和难点亟待解决。本文总结了未来可进一 动态变化的特征。深度学习依靠其强大的表征能力
步探究的内容，概括来讲包括以下这些潜在的方向。 被广泛应用到推荐系统，然而其深层神经网络被普
（1）数据来源问题 遍认为是不可解释的。近年来备受关注的知识图谱
在基于位置社会网络的兴趣点推荐系统中，用户 方法为该问题带来了契机，它通过建立<实体，关系，
采用“签到”的方式与社交网络中的好友共享位置，从 属性>三元组来提高可解释性，然而知识图谱的大数
而产生签到数据。作为推荐工作的基础，对数据的 据规模无法依据用户反馈进行实时更新，只能略微
挖掘与认知至关重要，然而用户的签到数据往往采用 改善推荐的可解释性。目前对兴趣点推荐中可解释
隐式的方式表达[76]。比如用户对地点的签到次数越 性问题的研究还比较少，探索一类能够实时交互更
高，可理解为用户偏好此地点，但用户签到的频率无 新的可解释性推荐方法值得研究。
固定的数据范围，增加了量化偏好值的难度，这与传 （5）用户的隐私保护
统推荐系统显式打分的方法有所区别。另外，兴趣 为了提高推荐的性能，当前的兴趣点推荐工作
点推荐工作的数据集主要来源于一些公开网站[77-79]， 需要从用户签到的历史记录与交互行为中充分挖掘
但用户可能仅在海量的位置中留下稀疏的签到记 用户的潜在偏好信息，包括对用户信息的收集、处
录，增加了数据获取的难度，这是推荐工作面临的首 理、存储和挖掘等，这在一定程度上威胁到用户的隐
要问题。 私信息。为此，现有的兴趣点推荐系统面临着较高
（2）融合多种影响因素的推荐 的隐私风险，提高兴趣点推荐的性能与保护用户的
目前的兴趣点推荐工作主要针对用户及兴趣点 隐私问题可能相悖。目前用来解决隐私保护问题的
两个维度的属性进行研究，如用户的社交关系、签到 一类方法是向原始数据中添加噪音，该方法简单高
时间、兴趣点的内容及流行度等。如何进一步拓展 效且易实现，然而过多的噪音会影响算法的有效性；
影响用户决策的其他行为信息，从而辅助用户决策 另一类方法是采用加密技术，但效率较低且实用性
至关重要。比如，兴趣点推荐还可能受到用户自身 不强；最近出现的联合学习是一种新的隐私保护学
的情感以及外界因素（如天气、交通）的影响，探究用 习方法，它不需要用户共享实时的签到信息，可通过
户的情感行为及引入外界因素构建模型成为一项富 离线的方式训练模型，适用性较强，但需要有足够的
有挑战的研究内容。 数据量。因此，如何应用相关技术在推荐的高精度
（3）跨领域推荐 要求与隐私保护间找到适当的平衡点，成为了兴趣
跨领域推荐可融合来自不同领域的用户偏好 点推荐系统研究的难点。 陈江美 等：基于位置社交网络的兴趣点推荐系统研究综述 1475
6 结束语 trieval, Beijing, Jul 25-29, 2011. New York: ACM, 2011:
325-334.
移动社交网络与推荐系统的融合，助推了基于
[8]YUAN Q, CONG G, MAZY, et al.Time-aware point-of-
位置社交网络的兴趣点推荐系统的发展。兴趣点推
interest recommendation[C]//Proceedings of the 36th Inter-
荐利用用户的签到数据及相关的情景信息模拟用户
national ACM SIGIR Conference on Research and Deve-
的决策行为，以挖掘用户潜在感兴趣的地点，成为当
lopment in Information Retrieval, Dublin, Jul 28-Aug 1,
前推荐系统领域较为活跃的方向之一。本文首先对
2013.NewYork:ACM,2013:363-372.
现有的兴趣点推荐的研究现状进行了梳理、分类与
[9]ADOMAVICIUSG,TUZHILINA.Towardthenextgenera-
归纳，介绍了兴趣点推荐系统的相关理论与基本框 tion of recommender systems: a survey of the state-of-the-
架。接着围绕基本框架对影响兴趣点推荐的因素、 artandpossibleextensions[J].IEEETransactionsonKnow-
推荐算法和算法评价三大核心内容进行概述，并详 ledgeandDataEngineering,2005,17(6):734-749.
细分析对比了各种代表性工作的研究内容和优缺 [10] SHIH D H,YEN D C, LIN H C, et al.An implementation
andevaluationofrecommendersystemsfortravelingabroad
点。最后对该领域难点问题和研究方向进行总结和
[J].ExpertSystemswithApplications,2011,38(12):15344-
展望，提出一些潜在的发展方向与趋势，希望能为兴
15355.
趣点推荐领域的学者提供借鉴与帮助。
[11]KARDANAA,EBRAHIMIM.Anovelapproachtohybrid
recommendationsystemsbasedonassociationrulesmining
参考文献：
for content recommendation in asynchronous discussion
[1]BARALR,ZHU X L,IYENGAR SS,etal.ReEL:review groups[J].InformationSciences，2013,219:93-110.
aware explanation of location recommendation[C]//Procee- [12]GUOB,LIJ,ZHENGVW,etal.CityTransfer:transferring
dings of the 26th Conference on User Modeling, Adapta- inter-and intra-city knowledge for chain store site recom-
tion and Personalization, Singapore, Jul 8-11, 2018. New mendation based on multi-source urban data[J]. Proceedings
York:ACM,2018:23-32. oftheACMonInteractive,Mobile,WearableandUbiquitous
[2]RAVIL,SUBRAMANIYASWAMYV,VARADHARAJANV, Technologies,2018,1(4):1-23.
et al. Efficient user profiling based intelligent travel reco- [13]焦旭,肖迎元,郑文广,等.基于位置的社交网络推荐技术
mmender system for individual and group of users[J]. Mobile 研究进展[J].计算机研究与发展,2018,55(10):2291-2306.
NetworksandApplications,2019,24(3):1018-1033. JIAOX,XIAOYY,ZHENGWG,etal.Researchprogress
[3] KOREN Y, BELL R, VOLINSKY C. Matrix factorization ofrecommendationtechnologyinlocation-basedsocialnet-
techniques for recommender systems[J]. Computer, 2009, works[J]. Journal of Computer Research and Development,
42(8):30-37. 2018,55(10):2291-2306.
[4]ZHANGZP,ZHANGY,RENYG.Employingneighborhood [14] GAO H J, TANG J L, HU X, et al. Exploring temporal
reduction for alleviating sparsity and cold startproblems in effectsforlocationrecommendationonlocation-basedsocial
user-based collaborative filtering[J]. Information Retrieval networks[C]//Proceedings of the 7th ACM Conference on
Journal,2020,23(4):449-472. RecommenderSystems,HongKong,China,Oct12-16,2013.
[5]XUEF,HEXN,WANGX,etal.Deepitem-basedcollabo- NewYork:ACM,2013:93-100.
rativefilteringfortop-nrecommendation[J].ACMTransac- [15]ZHANG JD,CHOW CY.iGSLR:personalized geo-social
tionsonInformationSystems,2019,37(3):1-25. locationrecommendation—akerneldensityestimationapp-
[6]郭宁宁,王宝亮,侯永宏,等.融合社交网络特征的协同过 roach[C]//Proceedingsofthe21stSIGSPATIALInternational
滤推荐算法[J].计算机科学与探索,2018,12(2):208-217. Conference onAdvances in Geographic Information Systems,
GUO N N, WANG B L, HOU Y H, et al. Collaborative Orlando,Nov5-8,2013.NewYork:ACM,2013:324-333.
filtering recommendation algorithm based on characteristics [16]ZHANGJD,CHOWCY.CoRe:exploitingthepersonalized
ofsocialnetwork[J].JournalofFrontiersofComputerScience influence of two-dimensional geographic coordinates for
andTechnology,2018,12(2):208-217. location recommendation[J]. Journal of Information Sciences,
[7]YE M,YIN PF, LEE W C, et a1. Exploiting geographical 2015,293(1):163-181.
influence for collaborative point-of-interest recommendation [17]任星怡,宋美娜,宋俊德.基于用户签到行为的兴趣点推
[C]//Proceedingsofthe34thInternationalACM SIGIR Con- 荐[J].计算机学报,2017,40(1):28-51.
ference on Research and Development in Information Re- REN XY, SONG M N, SONG J D. Point-of-interest reco- 1476 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(7)
mmendationbasedontheusercheck-inbehavior[J].Chinese [28] LIAN D F, ZHAO C, XIE X, et al. GeoMF: joint geogra-
JournalofComputers,2017,40(1):28-51. phicalmodelingandmatrixfactorizationforpoint-of-interest
[18] SONG C,WEN J H, LI S. Personalized POI recommenda- recommendation[C]//Proceedings of the 20th ACM SIGKDD
tionbasedoncheck-indataandgeographicalregionalinflu- International Conference on Knowledge Discovery and Data
ence[C]//Proceedings of the 3rd International Conference Mining, New York, Aug 24-27, 2014. New York: ACM,
on Machine Learning and SoftComputing,Da Lat,Jan 25- 2014:831-840.
28,2019.NewYork:ACM,2019:128-133. [29] RAHMANI H A, ALIANNEJADI M, AHMADIAN S, et
[19] ZHOU J J, LIU B, CHEN Y F, et al. UFC: a unified POI al. LGLMF: local geographical based logistic matrix facto-
recommendation framework[J]. Arabian Journal for Science rization model for POI recommendation[C]//LNCS 12004:
andEngineering,2019,44(11):9321-9332. Proceedingsofthe 15thAsia Information RetrievalSocieties
[20]任星怡,宋美娜,宋俊德.基于位置社交网络的上下文感 Conference on Information Retrieval Technology, Hong
知的兴趣点推荐[J].计算机学报,2017,40(4):824-841. Kong,China,Nov7-9,2019.Cham:Springer,2020:66-78.
RENXY,SONGMN,SONGJD.Context-awarepoint-of- [30]QIANXM,FENGH,ZHAOGS,etal.Personalizedreco-
interest recommendation in location-based social networks mmendation combining user interest and social circle[J].
[J].ChineseJournalofComputers,2017,40(4):824-841. IEEE Transactions on Knowledge and Data Engineering,
[21]彭宏伟,靳远远,吕晓强,等.一种基于矩阵分解的上下文 2014,26(7):1763-1777.
感知POI推荐算法[J]. 计算机学报, 2019, 42(8): 1797- [31]ZHANGZY,LIUY,ZHANGZJ,etal.Fusedmatrixfacto-
1811. rization with multi-tag, social and geographical influences
PENG H W, JIN Y Y, LV X Q, et al. Context-aware POI forPOIrecommendation[J].WorldWideWeb,2019,22(3):
recommendation based on matrix factorization[J]. Chinese 1135-1150.
JournalofComputers,2019,42(8):1797-1811. [32] ZHU J H, WANG C, GUO X, et al. Friend and POI reco-
[22] XIONG X, QIAO S J, HAN N, et al. Where to go: an mmendation based on social trust cluster in location-based
effective point-of-interest recommendation framework for socialnetworks[J].EURASIPJournalonWirelessCommu-
heterogeneous social networks[J]. Neurocomputing, 2020, nicationsandNetworking,2019(1):89.
373:56-69. [33] XU C H, DINGAS, ZHAO K D.Anovel POI recomme-
[23] XING S N, LIU F A, WANG Q Q, et al. Content-aware ndation method based on trust relationship and spatial-
point-of-interest recommendation based on convolutional temporal factors[J]. Electronic Commerce Research and
neuralnetwork[J].AppliedIntelligence,2019,49(3):858-871. Applications,2021,48:101060.
[24]CHENG C,YANG H Q,KING I,etal.Fusedmatrixfacto- [34]ZHU JH,GUO X.Deepneuralmodelforpoint-of-interest
rization with geographical and social influence in location- recommendation fused with graph embedding representation
based social networks[C]//Proceedings of the 26th AAAI [C]//LNCS 11604: Proceedings of the 14th International
Conference on Artificial Intelligence, Toronto, Jul 22-26, Conference onWirelessAlgorithms, Systems, andApplica-
2012.MenloPark:AAAI,2012:17-23. tions, Honolulu, Jun 24-26, 2019. Cham: Springer, 2019:
[25]温彦,马立健,曾庆田,等.基于地理信息偏好修正和社交 495-506.
关系偏好隐式分析的POI推荐[J].数据分析与知识发现, [35] QIAO Y, LUO X, LI C, et al. Heterogeneous graph-based
2019,3(8):30-40. jointrepresentationlearningforusersandPOIsinlocation-
WEN Y, MA L J, ZENG Q T, et al. POI recommendation based social network[J]. Information Processing & Mana-
based on geographic and social relationship preferences[J]. gement,2020,57(2):102151.
DataAnalysisandKnowledgeDiscovery,2019,3(8):30-40. [36]CHENL,YINGYK,LYUD,etal.Amulti-taskembedding
[26]夏英,张金凤.融合社交关系和局部地理因素的兴趣点推 based personalized POI recommendation method[J]. CCF
荐[J].计算机工程与应用,2021,57(15):133-139. Transactions on Pervasive Computing and Interaction, 2021,
XIA Y, ZHANG J F. POI recommendation fusing social 3(3):253-269.
relationsandlocalgeographicfactors[J].ComputerEnginee- [37]YING H C,WU J, XU G D, et al.Time-aware metric em-
ringandApplications,2021,57(15):133-139. beddingwithasymmetricprojectionforsuccessivePOIreco-
[27]LIUTC,LIAOJX,WUZG,etal.Exploitinggeographical- mmendation[J].WorldWideWeb,2019,22(5):2209-2224.
temporalawarenessattentionfornextpoint-of-interestreco- [38] MA Y X, GAN M X. Exploring multiple spatio-temporal
mmendation[J].Neurocomputing,2020,400:227-237. information for point-of-interest recommendation[J]. Soft 陈江美 等：基于位置社交网络的兴趣点推荐系统研究综述 1477
Computing,2020,24:18733-18747. interest recommendation method for location-based social
[39] YIN M, LIU Y, ZHOU X, et al. A fuzzy clustering based networks based on user activity and spatial features[J].
collaborativefilteringalgorithmfortime-awarePOIrecom- Knowledge-BasedSystems,2019,163:267-282.
mendation[J]. Journal of Physics: Conference Series, 2021, [52] YU D J, XU K H, WANG D J, et al. Point-of-interest
1746(1):012037. recommendationbasedonusercontextualbehaviorsemantics
[40]LUYS,HUANGJL.GLR:agraph-basedlatentrepresenta- [J].InternationalJournalofSoftwareEngineeringandKnow-
tion model for successive POI recommendation[J]. Future ledgeEngineering,2019,29(11/12):1781-1799.
GenerationComputerSystems,2020,102:230-244. [53] DAVTALAB M,ALESHEIKHAA.APOIrecommendation
[41] HUANG L W, MA Y T, WANG S B, et al. An attention- approach integrating social spatio-temporal information into
based spatiotemporal LSTM network for next POI recom- probabilistic matrix factorization[J]. Knowledge and Infor-
mendation[J]. IEEE Transactions on Services Computing, mationSystems,2021,63(1):65-85.
2021,14(6):1585-1597. [54]YUDJ,WANYANWB,WANGDJ.Leveragingcontextual
[42]WANGHL,LIPY,LIUY,etal.Towardsreal-timedemand- influence and user preferences for point-of-interest recom-
awaresequentialPOIrecommendation[J].InformationSciences, mendation[J].MultimediaToolsandApplications,2021,80
2021,547:482-497. (1):1487-1501.
[43]WUY,LIK,ZHAO G,etal.Personalizedlong-andshort- [55]YUAN H,XU J,ZHENG N,et al.PRPOIR: exploiting the
term preference learning for next POI recommendation[J]. region-level interest for POI recommendation[C]//Procee-
IEEE Transactions on Knowledge and Data Engineering, dings of the 32nd IEEE International Conference on Tools
2022,34(4):1944-1957. withArtificialIntelligence,Baltimore,Nov9-11,2020.Pis-
[44]CHEN L,ZHANG L,CAO SS,etal.Personalizeditinerary cataway:IEEE,2020:59-66.
recommendation: deep and collaborative learning with textual [56] LI H, GE Y, HONG R C, et al. Point-of-interest recom-
information[J]. Expert Systems with Applications, 2020, 144: mendations: learning potential check-ins from friends[C]//
113070. Proceedingsofthe22ndACM SIGKDD InternationalCon-
[45] ZHAO G, LOU P, QIAN X, et al. Personalized location ference on Knowledge Discovery and Data Mining, San
recommendation by fusing sentimental and spatial context Francisco,Aug13-17,2016.NewYork:ACM,2016:975-984.
[J].Knowledge-BasedSystems,2020,196:105849. [57]RAHMANIHA,ALIANNEJADIM,BARATCHIM,etal.
[46] ZHANG Z B, ZOU C, DING R F, et al. VCG: exploiting Joint geographical and temporal modeling based on matrix
visual contents and geographical influence for point-of- factorizationforpoint-of-interestrecommendation[J].Advan-
interest recommendation[J]. Neurocomputing, 2019, 357: cesinInformationRetrieval,2020,12035:205-219.
53-65. [58]LUYS,HUANGJL.GLR:agraph-basedlatentrepresenta-
[47] CONTRACTOR D, GOEL S, SINGLA P. Joint spatio- tion model for successive POI recommendation[J]. Future
textual reasoning for answering tourism questions[C]//Pro- GenerationComputerSystems,2020,102:230-244.
ceedings of the 2021 Web Conference, Ljubljana, Apr 19- [59] HU X J, XU J J, WANG W Q, et al. A graph embedding
23,2021.NewYork:ACM,2021:1978-1989. basedmodelforfine-grainedPOIrecommendation[J].Neuro-
[48] SÁNCHEZ VILLEGAS D,ALETRAS N. Point-of-interest computing,2021,428:376-384.
type prediction using text and images[J]. arXiv:2109.00602, [60] CHRISTOFORIDIS G,KEFALAS P,PAPADOPOULOSAN,
2021. et al. RELINE: point-of-interest recommendations using
[49]YANGY,DUANYQ,WANGXZ,etal.Hierarchicalmulti- multiple network embeddings[J]. Knowledge and Information
clue modelling for POI popularity prediction with hetero- Systems,2021,63(4):791-817.
geneoustouristinformation[J].IEEETransactionson Know- [61] XING S, LIU F, ZHAO X, et al. Points-of-interest recom-
ledgeandDataEngineering,2019,31(4):757-768. mendation based on convolution matrix factorization[J].
[50] YAO Z J, FU Y J, LIU B, et al. POI recommendation: a Appliedintelligence,2018,48(8):2458-2469.
temporal matching between POI popularity and user regu- [62]冯浩,黄坤,李晶,等.基于深度学习的混合兴趣点推荐算
larity[C]//ProceedingsoftheIEEE16thInternationalConfer- 法[J].电子与信息学报,2019,41(4):880-887.
enceonDataMining,Barcelona,Dec12-15,2016.Washing- FENG H, HUANG K, LI J, et al. Hybrid point of interest
ton:IEEEComputerSociety,2016:549-558. recommendation algorithm based on deep learning[J]. Journal
[51] SI Y L, ZHANG F Z, LIU W Y. An adaptive point-of- of Electronics & Information Technology, 2019, 41(4): 1478 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2022, 16(7)
880-887. tion algorithm based on Poisson factorization and neural
[63]XIAB,LIY,LIQM,etal.Attention-basedrecurrentneural network[J]. Computer Engineering andApplications, 2020,
network for location recommendation[C]//Proceedings of 56(21):176-186.
the 12th International Conference on Intelligent Systems [73] XIE M, YIN H Z, WANG H, et al. Learning graph-based
and Knowledge Engineering, Nanjing, Nov 24-26, 2017. POI embedding for location-based recommendation[C]//
Piscataway:IEEE,2017:1-6. Proceedings of the 25thACM International Conference on
[64] CHEN M, LIW Z, QIAN L, et al. Next POI recommenda- Information and Knowledge Management, Indianapolis,
tion based on location interestmining with recurrentneural Oct24-28,2016.NewYork:ACM,2016:15-24.
networks[J]. Journal of Computer Science and Technology, [74]GAOR,LIJ,DUB,etal.Exploitinggeo-socialcorrelations
2020,35(3):603-616. to improve pairwise ranking for point-of-interest recom-
[65]SUNK,QIANT,CHENT,etal.Wheretogonext:modeling mendation[J].ChinaCommunications,2018,15(7):180-201.
long- and short-term user preferences for point-of-interest [75]CHANGL,CHENW,HUANGJB,etal.Exploitingmulti-
recommendation[C]//Proceedingsofthe34thAAAIConfer- attention network with contextual influence for point-of-
ence on Artificial Intelligence, the 32nd Innovative Appli- interest recommendation[J].Applied Intelligence, 2021, 51
cations ofArtificial Intelligence Conference, the 10thAAAI (4):1904-1917.
Symposium on EducationalAdvances inArtificial Intellig- [76]ZHU JH,GUO X.Deepneuralmodelforpoint-of-interest
ence,NewYork,Feb7-12,2020.MenloPark:AAAI,2020: recommendation fused with graph embedding representa-
214-221. tion[C]//LNCS 11604: Proceedings of the 14th International
[66]HUANGCM,WUCY.Thepointofinterest(POI)recom- Conference onWirelessAlgorithms, Systems, andApplica-
mendation formobiledigitalcultureheritage(M-DCH)based tions, Honolulu, Jun 24-26, 2019. Cham: Springer, 2019:
on the behavior analysis using the recurrent neural networks 495-506.
(RNN)and user-collaborative filtering[J].JournalofInternet [77]GAO H J,TANG J L,HU X,etal.Content-aware pointof
Technology,2021,22(4):821-833. interest recommendation on location-based social networks
[67]ZHONGT,ZHANGS,ZHOUF,etal.Hybridgraphconvo- [C]//Proceedings of the 29thAAAI Conference onArtificial
lutional networks with multi-head attention for location Intelligence, Austin, Jan 25-30, 2015. Menlo Park: AAAI,
recommendation[J]. World Wide Web, 2020, 23(6): 3125- 2015:1721-1727.
3151. [78]CHOE,MYERSSA,LESKOVECJ.Friendshipandmobility:
[68]ZHANGJ,LIUX,ZHOUX,etal.Leveraginggraphneural user movement in location-based social networks[C]//Pro-
networks for point-of-interest recommendations[J]. Neuro- ceedingsofthe17thACM SIGKDD InternationalConference
computing,2021,462:1-13. on Knowledge Discovery and Data Mining, San Diego,
[69] KANG Y, CHEN J, CAO Y, et al. A higher-order graph Aug21-24,2011.NewYork:ACM,2011:1082-1090.
convolutional network for location recommendation of an [79]YELP. Challenge data set[EB/OL]. (2014-04-25)[2021-10-
air-quality-monitoringstation[J].RemoteSensing,2021,13 25].http://www.yelp.com/dataset_challenge.
(8):1600.
[70]HUANGL,MAY,LIUY,etal.DAN-SNR:adeepattentive 陈江美（1995—），女，福建南平人，博士研究
network for social-aware next point-of-interest recommen- 生，主要研究方向为商务智能、数据挖掘等。
dation[J].ACM Transactions on InternetTechnology,2020, CHEN Jiangmei, born in 1995, Ph.D. candi-
21(1):1-27. date. Her research interests include business in-
[71]LUOYT,LIUQ,LIUZC.STAN:spatio-temporalattention telligence,datamining,etc.
network for next location recommendation[C]//Proceedings
of the 2021 Web Conference, Ljubljana,Apr 19-23, 2021. 张文德（1962—），男，福建福州人，博士，教授，
NewYork:ACM,2021:2177-2185. 主要研究方向为信息化管理、知识产权等。
[72]张松慧,熊汉江.融合神经网络和泊松分解的兴趣点推荐 ZHANGWende,born in 1962,Ph.D.,professor.
算法[J].计算机工程与应用,2020,56(21):176-186. His research interests include information man-
ZHANG S H, XIONG H J. Point-of-interest recommenda- agement,intellectualproperty,etc. --------------------------------------------------------------------------------- 计算机应用
Journal of Computer Applications
ISSN 1001-9081,CN 51-1307/TP
《计算机应用》网络首发论文
题目： 基于全局状态预测与公平经验重放的交通信号控制算法
作者： 缪孜珺，罗飞，丁炜超，董文波
收稿日期： 2024-01-19
网络首发日期： 2024-04-09
引用格式： 缪孜珺，罗飞，丁炜超，董文波．基于全局状态预测与公平经验重放的交通
信号控制算法[J/OL]．计算机应用.
https://link.cnki.net/urlid/51.1307.TP.20240407.1337.006
网络首发：在编辑部工作流程中，稿件从录用到出版要经历录用定稿、排版定稿、整期汇编定稿等阶
段。录用定稿指内容已经确定，且通过同行评议、主编终审同意刊用的稿件。排版定稿指录用定稿按照期
刊特定版式（包括网络呈现版式）排版后的稿件，可暂不确定出版年、卷、期和页码。整期汇编定稿指出
版年、卷、期、页码均已确定的印刷或数字出版的整期汇编稿件。录用定稿网络首发稿件内容必须符合《出
版管理条例》和《期刊出版管理规定》的有关规定；学术研究成果具有创新性、科学性和先进性，符合编
辑部对刊文的录用要求，不存在学术不端行为及其他侵权行为；稿件内容应基本符合国家有关书刊编辑、
出版的技术标准，正确使用和统一规范语言文字、符号、数字、外文字母、法定计量单位及地图标注等。
为确保录用定稿网络首发的严肃性，录用定稿一经发布，不得修改论文题目、作者、机构名称和学术内容，
只可基于编辑规范进行少量文字的修改。
出版确认：纸质期刊编辑部通过与《中国学术期刊（光盘版）》电子杂志社有限公司签约，在《中国
学术期刊（网络版）》出版传播平台上创办与纸质期刊内容一致的网络版，以单篇或整期出版形式，在印刷
出版之前刊发论文的录用定稿、排版定稿、整期汇编定稿。因为《中国学术期刊（网络版）》是国家新闻出
版广电总局批准的网络连续型出版物（ISSN 2096-4188，CN 11-6037/Z），所以签约期刊的网络版上网络首
发论文视为正式出版。 网络首发时间：2024-04-09 19:55:37
网络首发地址：https://link.cnki.net/urlid/51.1307.TP.20240407.1337.006
Journal of Computer Applications ISSN 1001-9081
计算机应用 CODEN JYIIDU http://www.joca.cn
DOI:10.11772/j.issn.1001-9081.2024010066
基于全局状态预测与公平经验重放的交通信号控制算法
缪孜珺，罗飞*，丁炜超，董文波
(华东理工大学 信息科学与工程学院，上海 200237)
(*通信作者电子邮箱 luof@ecust.edu.cn)
摘 要: 为了应对交通拥堵，设计高效的交通信号控制算法能够显著增强现有交通网络下的车辆通行效率。尽管深度强化
学习算法在单路口交通信号控制问题上已展现出卓越的性能，然而其在多路口环境下的应用仍然面临着重大的挑战——即因
多智能体强化学习算法产生时间和空间部分可观测性而引发算法出现非平稳性问题，这会导致算法无法保证稳定地收敛。为
此，提出一种基于全局状态预测与公平经验重放的多路口交通信号控制算法(IS-DQN)。一方面，基于不同车道的车流历史信息
预测多交通路口的全局状态，扩展IS-DQN的状态空间，以避免算法产生空间部分可观测性而带来非平稳性问题。另一方面，
为了应对传统经验重放策略的时间部分可观测性，IS-DQN采用了蓄水池算法以保证经验重放池的公正性，进而避免其中的非
平稳性问题。在复杂的多路口环境下应用IS-DQN进行三种不同的交通压力仿真实验，实验结果表明：在不同交通流情况下，
尤其是在中低交通流量下，相对独立深度强化学习算法，IS-DQN算法能够得到更低的车辆平均行驶时间，并表现出了更优的
收敛性能与收敛稳定性。
关键词: 深度强化学习；交通信号控制；时序预测；蓄水池算法；长短期记忆网络
中图分类号:TP181 文献标志码： A
Traffic signal control algorithm based on overall state
prediction and fair experience replay
MIAO Zijun, LUO Fei*, DING Weichao, DONG Wenbo
(School of Information Science and Engineering, East China University of Science and Technology, Shanghai 200237, China)
Abstract: In order to cope with traffic congestion, designing efficient traffic signal control algorithms can significantly enhance the
traffic efficiency of vehicle. Although deep reinforcement learning algorithms have shown excellent performance in single intersection
traffic signal control problems, their application in multi-intersection environments still faces significant challenges - the non-stationarity
problem caused by the spatiotemporal partial observability of multi-agent reinforcement learning cannot guarantee stable convergence.
To this end, a multi-intersection traffic signal control algorithm based on overall state prediction and fair experience replay (IS-DQN)
was proposed. On the one hand, to avoid the problem of non-stationarity caused by spatial observability in algorithm, the state space of
IS-DQN was expanded by predicting the overall state of multiple traffic intersections based on historical traffic flow information from
different lanes. On the other hand, in order to cope with the time partial observability brought about by traditional experience replay
strategies, IS-DQN adopted a reservoir sampling algorithm to ensure the fairness of experience replay pool and avoid non-stationary
problems it brings. Three different traffic pressure experiments were conducted using IS-DQN in complex multi-intersection
environments. Simulation experiments under three different traffic pressure were conducted in complex multi-intersection environments.
Results shows that under different traffic pressure conditions, especially in low and medium traffic pressure, IS-DQN algorithm showed
lower average vehicle travel time, better convergence performance and stability compared to independent deep reinforcement learning
algorithms.
Keywords: deep reinforcement learning; traffic signal control; time series prediction; reservoir sampling algorithm; Long Short-
Term Memory (LSTM) network
收稿日期：2024-01-19； 修回日期：2024-03-15； 录用日期：2024-03-25。
基金项目：国家自然科学基金面上项目(62276097)；上海市自然科学基金资助项目（22ZR1416500，23ZR1414900）；上海市基
础研究特区计划（22TQ1400100-16）。
作者简介： 缪孜珺(1999—)，男，浙江宁波人，硕士研究生，主要研究方向：强化学习； 罗飞(1978—)，男，湖北武汉人，副
教授，博士，CCF会员，主要研究方向：认知计算、强化学习； 丁炜超(1989—)，男，山东青岛人，副教授，博士，CCF会
员，主要研究方向：云计算、群智计算、联邦学习； 董文波（1992—），男，河南新乡人，讲师，博士研究生，CCF 会员，
主要研究方向：机器学习、人工智能。 2 计算机应用
号控制的基于全局状态预测与公平经验重放的独立稳态深度
0 引言 强化学习算法(IS-DQN)，以提升算法的性能与稳定性。本文
的主要贡献如下：
随着市民汽车保有量的增加和城市化进程的加剧，交通
一方面，提出了一种基于自注意力机制和长短期记忆神
拥堵问题日益突出，严重影响了市民的生活质量和城市的可
经网络(LSTM)的全局交通状态预测网络，利用该网络预测多
持续发展。因此，优化交通信号控制方法，实现智能化、精
交通路口的全局状态，从而为IS-DQN设计了基于全局状态
细化的交通管理，进而提高道路通行效率，对解决城市交通
预测的增广状态空间，以解决多智能体强化学习算法因其空
拥堵、减少公路运输尾气排放具有重要的意义[1]。
间部分可观测性而导致的非平稳性问题。
交通信号控制方法从固定配时控制(Fixed-time Control)、
另一方面，提出了一种基于蓄水池算法的经验池重放机
感应式控制(Vehicle Actuated)发展到实时自适应控制(Real-
制，避免了多路口交通控制算法因其时间部分可观测性而导
time Adaptive Traffic Control)[2]。其中，固定配时控制方法有 致的非平稳问题，从而提升算法的鲁棒性与收敛稳定性。
固定的信号变换周期。感应式控制方法通过使用道路检测器
在真实路网的低中高三种不同交通流量条件下进行了实
的实时测量结果来优化信号计时[3]，因其实现了较优的交通
验。实验结果表明：IS-DQN算法相较于独立深度强化学习算
流量控制效果，该方法已被纳入一些商业交通信号控制系统。
法，车辆平均行驶时间减少了8.15%、9.59%、0.85%都，并
然而，该方法受到其模型预先定义参数的限制，在波动的交
表现出了更优的收敛稳定性，有效提升了车辆通行效率。
通需求中，以强化学习算法为代表的自适应控制系统是一种
更有效的解决方案[2]。最新的研究表明：将深度强化学习算 1 交通信号控制问题中的非平稳性
法--深度Q学习(Deep Q-Network, DQN)算法应用于交通信号
控制问题，在解决交通拥堵方面，DQN的性能显著优于感应 多路口交通信号控制问题一般会被描述为一个马尔可夫
式控制方法[4-8]。 决策过程(Markov Decision Process, MDP)，定义为元组
尽管单智能体的强化学习算法在单路口的交通信号控制
问题上已经有所建树，但如果想要在现实中的复杂多路口交
通环境下应用，则需要使用多智能体强化学习算法(MARL)。
MARL基于已经熟悉的单智能体算法来进行学习，这主要分
为两种思路：完全中心化方法和去中心化方法[9]。完全中心
化方法将多个智能体的决策视为一个超级智能体的决策；然
而，随着交通网络的复杂度增加，联合Q函数策略的复杂度
也呈指数级增长。去中心化方法则不考虑其他智能体的变化，
每个智能体都有独立的Q函数，并且只根据自己观察到的环
境进行独立学习；在大规模城市交通网络下，去中心化的独
立强化学习算法表现出更好的适应性，这也是本文关注的重
点。
然而，去中心化的独立强化学习算法在交通信号控制问
题上的应用会引入一个非平稳性问题：独立智能体观测到的
环境包含其他正在学习的智能体，因此其所假设的收敛目标
会不断变化，从而导致算法无法平稳收敛。为了解决这个问
题，一部分研究人员通过图卷积网络或注意力机制学习智能
体之间的依赖性[10-12]，但他们忽略了状态信息的时空相关性；
另一部分则侧重于聚合来自其他智能体的状态信息[13-15]，但
不幸的是在实际应用中畅通的通信环境难以实现。Fang等[16]
则利用注意力机制捕捉交叉口的时空依赖性，改进了算法的
收敛性与可解释性。该算法采用集中式训练，在大规模交通
网络中难以应用，但复杂多交叉口之间的时空依赖性值得本
文进行进一步探讨。
因此，针对独立强化学习在多路口交通信号控制中所带
来的非平稳性问题，同时从算法的状态信息获取与经验重放
两方面对 DQN 进行改进，从而提出一种面向多路口交通信
,   S , A , P , R  。在多交通路口环境下(Environment)将每
个路口设定为一个智能体(IS-DQN agent)。在该条件下，S代
表各个路口所观测到的交通流状态(State)集合； A 代表各个
路口所作出的动作(Action)集合； P 代表不同状态动作下的
状态转移概率； R 代表奖励函数(Reward)。当环境处于时间
步长 t 下时，每个智能体会通过构建的策略与观测所得的
当前交通状态 s
t
对当前时间步的信号灯变换动作进行选择
与执行，然后系统转换到下一个状态 s
t+ 1
。在时间步t+1，
智能体再次观测环境根据定义的奖励函数获取奖励 r ，并根
据该奖励对策略进行更新。图1描绘了交通信号控制问题
的MDP过程。
图1 交通信号控制问题MDP过程示意图
Fig. 1 Picture of MDP process for traffic signal
control problem
为了进一步分析多智能体环境中的非平稳性，首先假设
一个完全可观察的多智能体环境。在m个智能体中选取一个
智能体n(其中nN 1...m)，使用下标−n来表示所有其 计算机应用 3
他的智能体，如 A =  a
n
,a
− n
 。在每个时间步中，智能体n根
据其策略
n
选取动作 a
n
 A ，对于下一状态 s  的转移概率
为P(s|s ,A)。在这一假设下，智能体n的最优动作价值函
t
数 Q *n 对于所有其他智能体可能的动作 a
− n
都是已知的，考虑
到所有其他智能体的联合策略 。单智能体的迭代公式如
−n
式(1)所示：
Q ( s ,t a
t
) (1 ) Q ( s ,t a
t
) rt
1
m aa x Q ( s , a )     − + 
+
+   (1)
可以写出在多智能体强化学习系统中，智能体 n 的
Bellman最优方程如式(2)所示：
An
n
( a
n
s
t
) r
Q (*n
s
s ,at
(P
n
s s
)n
,at
n
,a
n
) m aan x Q *n ( s ,a
n
)

  
−
∣−  + 

∣
∣
−
=
− 
  
(2)
从公式2中可看出，随着其他智能体在学习中改变策略
非平稳因子
n
( a
n
s )
i n i
( a
i
s )  
− −
∣ = 
 −
∣
遗忘。因此，IS-DQN期望一个与全局分布相匹配的经验分布
从而避免算法的部分可观测性。
2 算法设计
2.1 基于全局状态预测的增广状态空间
在多路口交通信号控制问题中，不同路口的行动-状态关
系以一种复杂的方式相互关联。如果想要通过一些计算的方
式推算全局状态避免部分可观测性，则需要对每个路口的观
察状态与选择策略进行推断，而这很难实现。然而，在多路
口交通环境中，路口之间的状态并非毫无关联。对于单个路
口，可以通过分析当前和历史状态下不同方向车道的交通流
量长度，对相邻路口的状态进行一定程度的推断。
研究表明，相比直接预测其他智能体的策略，将其他智
能体的混合策略估计包含在状态中，让Q函数对整个混合策
也会随之发生改变。
略进行评估，是一个更优的选择[21]。因此，基于路口对全局
这意味着，算法的收敛过程会随着该非平稳因子的变化而产 状态的推断构建了基于自注意力机制和LSTM的交通状态预
生波动。为了获取其他智能体的状态变化对全局策略进行观 测网络，并设计了新的增广状态空间与混合策略从而避免智
察是一个选择，但在实践中这样的假设可能过于严格。智能 能体部分可观测性导致的非平稳性。
体对其周围环境的观测可能有限，与其他智能体的沟通可能 在每个时间步下，IS-DQN 算法将当前与历史状态输入
不可行或不可靠[17]，其他智能体所观察获取的状态可能不可 预测网络最后获得预测全局状态
用[18]。在这种情况下，智能体必须只使用自己观察可用的信
息进行推理。因此可以得出结论：在类似多路口交通信号控
制问题的多智能体强化学习算法中，非平稳性的主要来源是
智能体对于当前真实环境的时空部分可观测性与对于其他智
能体所采取动作或者策略的不可知性[19]。
针对单路口交通信号控制，为了避免环境的部分可观测
性，深度强化学习算法的一个重要解决方案是采用经验重放
机制。经验重放的工作机制是在训练神经网络时，从经验重
放池中均匀地批量采样经验，而不是仅仅使用最新的经验。
这种方法的优势主要有两个方面。首先，通过随机采样，可
以避免网络过度拟合最近的经验，从而提高了样本的多样性
和利用效率。这种随机性有助于网络学习到更通用的模式，
而不是特定于最近经验的模式。其次，DQN智能体不是直接
在整体的观察样本上进行学习，而是在小批量样本上进行学
习。这种小批量学习的方式，相较于全体样本学习，大幅提
高了训练的效率和速度，使训练过程更高效和灵活。
然而，针对多路口交通信号控制算法，直接采用经验重
放机制则可能会进一步导致深度强化学习算法对于环境认知
的非平稳性：每个路口智能体中的重放经验无法反映当前学
习的动态性。Schaul等[20]的研究表明在选择样本进行训练时，
经验选择可以提高算法训练效果。然而，这些研究并没有考
虑如何作出更持久的决策，即选择哪些样本要保留，哪些样
本要丢弃。也就是说经验重放是巩固学习不同状态下最优策
略的必要组成部分。通过保留过去的经验，并将之融入学习
过程，可以有效地克服按时间顺序进行训练时对早期记忆的
S ，将预测全局状态与当前
状态扩展为增广状态后输入DQN网络。
预测网络以LSTM单元即双层的LSTM隐含层为核心，
添加注意力机制，并设计输入输出向量格式。隐含层状态的
传递给该网络带来了优良的时序预测性能，而添加的注意力
机制可以动态捕获复杂动脉网络上的时空依赖关系[22]。整体
预测网络结构如下图2所示：
图2 IS-DQN中预测网络结构
Fig. 2 Prediction Network Structure in IS-DQN
基于全局状态预测的增广状态空间计算流程如下所示：
预测网络的输入以路口从环境所获取的状态信息为基准，
并规范化为当前时间步下的相位索引p与各车道等待车辆数
量Cnt。输入向量公式如式(3)所示：
Input(t)= p(t),Cnt1(t),...,Cntk(t) (3)
 
LSTM 单元通过其特殊的门控机制学习提取输入向量中
的时序关联信息。在时间步t下，隐含层中的LSTM单元输 4 计算机应用
入时间步 t-1 下的输出信息 h
t−1
、细胞状态 C
t−1
与输入向量
I n p u t ( t ) 。LSTM单元运算公式如式(4)-(8)所示：
it ( W
i
h
t 1
, I n p u t ( t ) b
i
)  =  
−
 + (4)
o
t
( W
o
h
t 1
, I n p u t ( t ) b
o
)  =  
−
 + (5)
f
t
( W
f
h
t 1
, I n p u t ( t ) b
f
)  =  
−
 + (6)
C = f C +i tanh( W h ,Input(t)+b ) (7)
t t t−1 t c  t−1  c
h
t
= o
t
 ta n h ( C
t
) (8)
其中，( )为 Sigmoid 激活函数，tanh( )为双曲正切
函数，W为训练权重，b为偏置项参数。下标i、o、f、c为
LSTM单元中的输入门、输出门、遗忘门与细胞状态，h 为
t
当前时间步下LSTM单元的输出。
注意力层计算输入数据与上下文的相似度从而让模型捕
捉输入数据的关键信息。注意力层的输入为隐含层中 LSTM
单元的输出 h
t
，使用基于感知机的相似度函数 f ( ). 计算获得
单个输入与整体输入的匹配权重 a
t
如式(9)所示：
a =
exp( f(b t,h t))
(9)
t exp( f(b,h ))
t i
n
然后将注意力权重与每一个输入进行点乘累加得到注意
力层的输出 A tte n tio n ( t ) ，如式(10)所示：
A t t e n t i o n ( t ) = 
T
a ht
t
(10)
输出层通过Softmax函数将注意力层的输出归一化为输
出向量 O u tp u t ( t ) ，即预测全局状态 S ，如式(11)所示：
S = O u tp u t ( t ) = S o ft m a x ( A tte n tio n ( t ) ) (11)
考虑到实验过程中对全局状态直接进行预测的效果并不
佳，因此综合实验结果考虑选择了与路口状态关联程度较高
的不同车道方向下拥堵程度作为预测全局状态进行输出。在
每个时间步t下，假设共有k个车道，该预测模型的输出向
量即预测全局状态如式(12)所示：
S = O u tp u t ( t ) =  Q p
1
( t ) ,Q p
2
( t ) ,...,Q p
k
( t ) 
法(FIFO)：在经验重放池填满后，让新的样本不断取代最旧
样本。
然而，这种算法不可避免地会引入时间相关的偏见，并
可能导致样本多样性不足。此外，如果使用大容量的经验重
放池来增加样本多样性，将对存储空间提出更高要求，并降
低算法训练的效率。因此，提出使用蓄水池抽样算法进行经
验样本池更新，从而在经验顺序到达的情况下保证样本的随
机性。基于蓄水池抽样的经验选择流程如算法1所示：
算法1 基于蓄水池抽样的经验选择算法
输入：样本池Sp，重播样本数k
输出：经验重放池Rp
1 for i in Sp(n):
2 | if i<k:
3 | | Rp[i] = Sp[i] # 前k个直接保留
4 | else:
5 | | random_int = random (0, i) #获取随机
数
6 | | if random_int < k:
7 | | | Rp[random_int] = Sp[i]
8 | | end if
9 | end if
10 end for
以上流程可解释为：
⚫ 第
(12)
最后，将当前状态s 与全局状态S组合获得基于全局状
t
态预测的增广状态空间S =s ,S 输入DQN网络。
T t
2.2 基于蓄水池抽样算法的经验选择
正如第一节中所分析的那样，IS-DQN 的经验选择算法
期望能够保留下不同类型的经验样本，避免带来时间上的部
分可观测性，从而使智能体能够对不同状态空间下的经验进
行公平地学习。目前最常用也是最简单的方法是先进先出算
i   1 ,...,k  个样本按照先后次序直接放入到重播样本
池中；
⚫ 第 j   k + 1 ,...,n  个样本，每次先以概率
p =
k
j
选择是否
让该样本留下，若能够留下则以等概率从重放样本池中
选择一条进行替换。
基于以上算法流程，提出并证明以下定理：
k
定理：所有顺序抵达的经验样本均以等概率即 的概率
n
被保存进入经验重放池。
证明：第 i   1 ,...,k  个样本最终被保存在经验重放池的概
率 P ( i ) 为被该经验样本被保存的概率 p ( i ) 乘以不被第
j   k + 1 ,...,n  个样本替换的概率。概率公式如式(13)所示：
P ( i ) = p ( i )  p ( i | k + 1 )  p ( i | k + 2 ) ... p ( i | n ) (13)
对于第i1,...,k个样本被选中的概率为 1。而第 k+1
个样本被选中的概率为 k ，则第 i 个样本被第 k+1 个元素
k+1
替换的概率如式(14)所示：
k 1 1
p(i|k+1)= * = (14)
k+1 k k+1
以此类推则可以得到，在训练结束即索引位置为n时，
第i个样本被保存在经验重放池的概率如式(15)所示：
k k+1 k+2 n−1 k
P(i)=1   ... = (15)
k+1 k+2 k+3 n n 计算机应用 5
对于第 jk+1,...,n个样本，最终被保存在经验重放 骤8至11为训练阶段，每隔C个时间步，算法从存储的经
验中通过蓄水池抽样算法获取一个小的抽样样本给予 DQN
池的概率P(j)为该样本被选中保存的概率 p( j)乘以不被
网络进行训练。步骤4和步骤8为前述分别为2.1的增广状
之后样本替换的概率。概率公式如式(16)所示：
态空间获取和 2.2 的经验选择算法，但由于预测与训练的需
P(j)=p(j)p(j|j+1)p(j|j+2)...p(j|n) (16)
要，IS-DQN算法整体交互流程如图3所示。
第 jk+1,...,n个样本被选中的概率为k。而第j+1个
j
样本被选中的概率为 k ，则第 j 个样本被第 j+1 个样本替
j+1
换的概率如以式(17)所示：
p(j| j+1)=
k *1
=
1
(17)
j+1 k j+1
以此类推则可以得到，在训练结束即索引位置为n时，
第j个样本被保存在经验重放池的概率如式(18)所示：
P(j)=k

j

j+1

j+2 ...n−1 =k (18)
j j+1 j+2 j+3 n n
因此可以证明所有经验样本均以等概率被保存，即经验
重放池的样本是与样本池中近似匹配的小种群，进而避免了
图3 IS-DQN整体交互流程
算法的部分可观测性。
Fig. 3 Overall interactive flowchart of IS-DQN
2.3 IS-DQN算法 如上图所示，状态空间会先经过预测网络处理并计算获
得基于全局状态预测的增广状态空间后再输入 DQN 网络。
基于以上拓展状态空间与经验选择算法，本文提出 IS- 两个网络所需要的训练样本并不一致，因此预测网络与DQN
DQN算法。该算法整体流程如算法2所示： 网络会分别在样本池与经验重放池中进行更新。需要注意的
算法2 IS-DQN算法
是，在第一轮训练结束后才会对预测网络进行初始化，因此
输入：多路口测试仿真环境
步骤4中的预测过程在第一轮中会跳过。最后，经过150回
输出：各回合测试仿真结果
^ 合与环境的交互训练可以得到该算法在环境中每一轮的仿真
1 初始化Q网络并设置 𝑄=𝑄
结果。
2 for 每个训练回合：
3 | for 每个时间步：
4 | | 将环境状态输入预测网络并计算获得 3 实验与结果分析
S =s ,S 
T t
5 | | 以的概率选择随机动作 a 或 3.1 实验环境
t
a t =argmax
aQ( S,a;)
本研究使用开源交通模拟平台 CityFlow 开展实验。
6 | | 执行动作a，环境观测获得奖励r，得 CityFlow是专为大规模交通信号控制设计的平台，可以支持
到下一个状态s
t+1 基于合成和真实数据的道路网络和交通流的灵活定义，并且
7 | | 存储经验元组s,u ,r,,s ,S 进入 CityFlow 优秀的计算速度适用于大规模信号灯路口的模拟
a h
样本池Sp [23]。在实验过程中，首先根据提供的数据集信息配置了
8 | | 从全局样本池中更新重播样本池
CityFlow平台的环境，包括路口布局、路网结构和交通流量
9 | | 更新 r if done
y= r+max aQˆ(s t,a t;) otherwise 等。然后，将实际交通数据输入配置好的模拟环境中，模拟
10 | | 根据重放池更新DQN网络，根据样本
车辆在该环境中行驶。接下来，根据交通状况，IS-DQN 向
池更新预测网络 CityFlow平台发送信号控制指令，包括调整信号灯的变化周
11 | | 每C步使 Qˆ =Q 期和模式等。CityFlow平台接收并执行这些指令后，将新的
12 | end for
交通状态反馈给IS-DQN算法。通过这种方式，在一个高度
13 end for
控制和可再现的环境中，可以对IS-DQN进行全面和深入的
整个 IS-DQN 算法的流程与采用经验池的 DQN 算法基
测试和优化。
本一致。在每个时间步中，步骤4至7为采样阶段，主要过
本实验选取了一个复杂多路口交通环境，在3600s的仿
程为从环境获取信息与并通过预测网络预测全局状态并组合
真时长下，分别使用随机种子生成2100、2700、3300辆不同
为增广状态空间，并将采样结果存储进入经验重放池D；步 6 计算机应用
的车辆以随机路径进入路网，分别对应为低、中、高三种车 除以上算法外，在实验过程中也添加了基于递归神经网
流量条件。对于每种流量条件，用随机种子生成5组车流数 络与DQN算法的DRQN算法作为对比。DRQN算法在DQN
据，最后取这 5 组车流数据下 10 次实验结果的平均值进行 网络中添加LSTM层来保留并利用先前状态信息，从而能训
比较。该多路口交通环境仿真图如图4所示，六个路口的编 练出具有长期记忆能力的智能体。但实验结果表明其无法保
号在图4中依次标出。所有交叉口的道路网络设置与现实中 证收敛，因此不在实验结果中列举。
一致。文献[24]发现模型性能对不同交通信号控制方法与环
3.3 参数设置
境之间的时间步长这一参数并不敏感，因此每个时间步长设
置为10秒。
为了提高学习性能，算法中的参数都通过实验调整为了
最优。经典交通信号控制算法的超参数设置如表1所示：
表1 经典算法的超参数设置
Tab. 1 Hyperparameter setting of classical
timing algorithms
算法名称 超参数 值 含义
FIXTIME
图4 多路口测试环境仿真图
Fig. 4 Simulation diagram of multi intersection
testing environment
3.2 对比算法
为了评估 IS-DQN 的有效性与效率，除了与 DQN 算法
进行比较之外，还将它们与以下已被广泛应用的经典交通控
制方法进行比较。
⚫ 固定配时算法(FIXTIME)：固定配时算法采用预先确定
的相位周期与顺序，是目前使用最广泛的交通信号控制
方法。
⚫ 自组织交通灯控制(SOTL)[25]：自组织交通灯控制算法
是一种基于动态调节车辆等待数量阈值的自适应交通
信号控制方法。由于该算法具备调节能力，因此在众多
城市中得到了广泛应用。
⚫ 最大压力算法(MaxPressure)[26]:MaxPressure 算法引入
了压力的概念——上游排队车辆与下游排队车辆的数
量差异。MaxPressure 计算每个阶段的压力，并进行比
较，最终激活压力最大的阶段。该方法能够有效地调控
交通拥堵，具备经过数学证明的吞吐量特性。
此外，本文还设置了相应的消融实验算法：
⚫ DQN-PS：仅添加了基于全局状态预测的增广状态空间
的DQN算法。
⚫ DQN-ER：使用基于蓄水池抽样的经验选择算法的
DQN算法。
C 80 相位周期
MAXPRESSURE m in  5 最小绿灯时间
SOTL m in  2 最小绿灯时间
SOTL  4 车辆数阈值
SOTL  28 绿灯车辆数阈值
在所有的训练和测试过程中，IS-DQN算法与DQN算法
中的DQN网络都采用了学习率为0.0005的Adam优化器；
最小经验池大小为600；最大经验池大小为50000；折扣因子
为0.8。在预测网络中，采用学习率为0.001的Adam优化器，
隐藏层数为2，隐藏层节点个数为128，采用二值交叉熵作为
损失函数。IS-DQN算法共迭代150轮。
3.4 实验结果
根据对现有交通信号控制的研究，实验选择了汽车行驶
时间作为代表性的指标。在交通领域，这也是判断性能最常
用的衡量标准。该指标以秒为单位，同时考虑了汽车行驶抵
达路口所需时间和汽车在路口等待的时间。因此，更优秀的
算法在相同车流量数据集下能够得到更低的平均行驶时间，
代表该算法能够有效提升车辆通行效率。此外，累积奖励是
强化学习的基本性能指标，实验也将其纳入了对比。在本实
验中，奖励值设定为车辆停止时间的负数。
首先对不同算法在不同交通状况下优化后的平均行驶时
间进行比较，实验结果如表2所示，其中深度强化学习算法
选取150轮迭代中的最后10轮平均值作为结果进行比较。
从表中可以看出在所有交通流情况下，DQN和IS-DQN
算法相较于传统方法都有着显著的优势，这在低交通流量下
尤其明显。而改进后的算法相较于 DQN 算法在大多数情况
下都能保证更优的收敛结果。在最终结果上，IS-DQN相较于
DQN 在低中高的流量情况下各路口的平均行驶时间之和上
分别有8.15%、9.59%、0.85%的优势。
⑥
④
⑤
①
②
③ 计算机应用 7
表2 不同算法在不同交通压力下优化后的平均行驶时间
Tab. 2 The average travel time optimized by different algorithms under different traffic pressure
IS-DQN DQN DQN-PS DQN-ER Fixtime MaxPressure SOTL
低流量路口1 92.520 103.638 93.750 98.904 285.387 143.212 148.432
低流量路口2 85.072 93.101 85.771 89.633 279.508 126.871 128.802
低流量路口3 73.975 83.960 74.444 82.593 272.065 109.183 109.260
低流量路口4 94.085 99.426 94.440 98.913 400.112 152.070 162.543
低流量路口5 95.291 99.374 94.877 96.614 349.340 140.418 149.679
低流量路口6 74.085 81.204 74.266 80.416 345.519 118.796 146.500
中流量路口1 112.058 121.691 114.467 117.215 244.768 156.211 163.154
中流量路口2 106.165 116.094 108.171 109.196 216.307 141.574 153.677
中流量路口3 85.988 94.483 88.368 96.213 225.756 117.185 165.453
中流量路口4 124.960 141.970 126.198 135.349 289.689 171.429 204.084
中流量路口5 108.599 113.521 110.960 115.294 286.784 143.639 178.838
中流量路口6 91.078 107.781 92.318 100.988 258.487 135.075 206.624
高流量路口1 129.778 128.808 127.764 131.759 276.707 166.963 146.500
高流量路口2 125.551 123.464 124.294 131.589 208.357 149.933 162.850
高流量路口3 107.029 109.390 114.653 114.301 201.837 124.199 173.341
高流量路口4 164.431 161.762 161.873 166.006 336.926 188.821 200.651
高流量路口5 118.135 117.691 121.091 121.621 388.053 148.797 163.518
高流量路口6 130.814 141.184 130.136 133.617 242.165 145.862 197.414
高交通流量下，所有路口都处于且长时间处于拥堵状态，
这反而降低了环境之间的非平稳性，这导致了 IS-DQN 与
DQN-PS 算法失去了中低交通流量下的显著优势。尽管高交
通流量下 DQN 算法在多数路口上有一些优势，但在路口 6
上相较于IS-DQN却有一个明显地劣势，体现出IS-DQN算
法所预测全局状态能够更兼顾不同路口拥堵的公平性。此外，
由于固定配时算法在三种流量条件下都处于拥堵状态，因此
其性能表现与车辆随机路径具有更高的相关性。
为了更进一步分析算法的有效性，实验对各个算法在不 图6 各算法在中交通流量下收敛过程
同交通流的150轮迭代过程进行了分析。其中的传统交通信 Fig. 6 The convergence process of each algorithm
号控制算法如 fixtime 等都没有迭代过程，以常函数进行表 under medium traffic flow
示，整体迭代流程如图5~7所示。
图7 各算法在高交通流量下收敛过程
Fig. 7 Convergence process of each algorithm
图5 各算法在低交通流量下收敛过程 under high traffic flow
Fig. 5 The convergence process of each algorithm 从图5~7中可以看出，DQN与IS-DQN算法在各个交通
under low traffic flow 流情况下至多 50 轮迭代就能够拥有超越传统算法的性能。
而正如所预料的那样，IS-DQN算法相较于DQN算法在多数 8 计算机应用
情况下都表现出了良好的性能，尤其是在低交通流情况下。 算法确保经验重放池的公正性。通过在复杂多路口环境下进
数据显示改进后的IS-DQN算法在整体收敛过程中低中高三 行三种不同交通压力的实验，证明了本文所设计的增广状态
种交通流情况下150个收敛回合的平均行驶时间分别减少了 空间与样本抽样算法能够有效地避免部分可观测性从而提升
9.17%、6.58%、2.63%。 路口车辆通行效率。尤其是在中低车流量下，改进后的 IS-
在表1中低交通流量路口中，应用了增广状态空间的算 DQN算法更能保证算法的收敛结果。尽管在动态交通环境下
法IS-DQN与DQN-PS有着明显更优的收敛结果。在图5~7 的性能有待进一步验证，但这已表明IS-DQN算法在应对多
放大的收敛区域中可以明显看出IS-DQN与DQN-ER算法能 路口环境下的交通信号控制问题方面的现实应用具有很大的
够更快更稳定地达到收敛。因此，综合图5~7与表1的结果 潜力。未来的研究将进一步探索结合天气节假日等条件的交
可以得出，通过基于状态预测的增广状态空间能够给算法带 通预测方法在现实交通系统中的应用，建立更全面的拟真环
来更好的收敛结果，而使用基于蓄水池抽样的经验选择算法 境，并对其性能进行更深入的评估和优化。
能够给算法带来更稳定快速的收敛过程。 参考文献
累计奖励是强化学习算法重要的性能判断指标之一。在 [1] KÓVÁRI B, KOLAT M, BÉCSI T, et al. Competitive multi-agent
六个交通路口上，最具代表性的中等交通流量情况下，DQN reinforcement learning for traffic signal control [C]// Proceedings of the
2022 IEEE 20th Jubilee International Symposium on Intelligent
算法和改进后的IS-DQN算法的累计奖励如图8所示。显然，
Systems and Informatics (SISY). IEEE, 2022: 361-366.
改进后的IS-DQN算法在累计奖励方面无论是数值还是稳定 [2] NOAEEM M, NAIK A, GOODMAN L, et al. Reinforcement learning
in urban network traffic signal control: a systematic literature review[J].
性的表现都更出色。结合图5~7的收敛过程，可以得出结论：
Expert Systems with Applications, 2022, 199: 116830.
在中低流量情况下，改进后的 IS-DQN 算法相比 DQN 算法 [3] MA D, XIAO J, SONG X, et al. A back-pressure-based model with
能够处理交通信号控制问题的非平稳性，从而有效学习交通 fixed phase sequences for traffic signal optimization under
oversaturated networks[J]. IEEE Transactions on Intelligent
环境状态、提升车辆通行效率，获得了更好的收敛性能和收
Transportation Systems, 2020, 22(9): 5577-5588.
敛结果。 [4] DUCROCQ R, FARHI N. Deep reinforcement Q-learning for
intelligent traffic signal control with partial detection[J]. International
Journal of Intelligent Transportation Systems Research, 2023, 21(1):
192-206.
[5] HAN G, LIU X, WANG H, et al. An attention reinforcement learning-
based strategy for large-scale adaptive traffic signal control system[J].
Journal of Transportation Engineering, Part A: Systems, 2024, 150(3):
04024001.
[6] YAZDANI M, SARVI M, BAGLOEE S A, et al. Intelligent vehicle
pedestrian light (IVPL): a deep reinforcement learning approach for
traffic signal control[J]. Transportation research part C: emerging
technologies, 2023, 149: 103991.
[7] ZHU R, LI L, WU S, et al. Multi-agent broad reinforcement learning
for intelligent traffic light control[J]. Information Sciences, 2023, 619:
509-525.
[8] KOLAT M, KŐVÁRI B, BÉCSI T, et al. Multi-agent reinforcement
learning for traffic signal control:a cooperative approach[J].
Sustainability, 2023, 15(4): 3479.
[9] ZHANG K, YANG Z, BAŞAR T. Multi-agent reinforcement learning:
A selective overview of theories and algorithms[J]. Handbook of
reinforcement learning and control, 2021: 321-384.
[10] YANG S. Hierarchical graph multi-agent reinforcement learning for
traffic signal control[J]. Information Sciences, 2023, 634: 55-72.
[11] YANG S, YANG B. An inductive heterogeneous graph attention-based
multi-agent deep graph infomax algorithm for adaptive traffic signal
图8 DQN与IS-DQN算法在中交通流量下的累计奖励 control[J]. Information fusion, 2022, 88: 249-262.
[12] ZHAO Z, WANG K, WANG Y, et al. Enhancing traffic signal control
Fig. 8 Cumulative Reward of DQN and IS-DQN by
with composite deep intelligence[J]. Expert Systems with Applications,
episode of medium traffic flow
2024, 244: 123020.
[13] GUO J, CHENG L, WANG S. Cotv: cooperative control for traffic light
4 结语 signals and connected autonomous vehicles using deep reinforcement
learning[J]. IEEE Transactions on Intelligent Transportation Systems,
2023.
本文提出了使用当前成熟的交通预测算法设计新的增广 [14] REN F, DONG W, ZHAO X, et al. Two-layer coordinated
状态的方法来解决多智能体强化学习中的非平稳性问题。同 reinforcement learning for traffic signal control in traffic network[J].
Expert Systems with Applications, 2024, 235: 121111.
时，为了避免经验重放中的偏见，IS-DQN算法采用了蓄水池
)s(
draweR
evitalumuC
)s(
draweR
evitalumuC
C
C
u
u
m
m
u
u la tiv e R e w a rd o f D Q
T rain in g R o u n d
la tiv e R e w a rd o f IS -D
T rain in g R o u n d
N
Q N
Inter1_rew ardInter2_rew
ardInter3_rew
ardInter4_rew
ardInter5_rew
ardInter6_rew
ard
Inter1_rew ardInter2_rew
ardInter3_rew
ardInter4_rew
ardInter5_rew
ardInter6_rew
ard 计算机应用 9
[15] BOKADE R, JIN X, AMATO C. Multi-agent reinforcement learning conference on information and knowledge management. 2019: 1963-
based on representational communication for large-scale traffic signal 1972.
control[J]. IEEE Access, 2023. [25] COOLS S B, GERSHENSON C, D’HOOGHE B. Self-organizing
[16] FANG J, YOU Y, XU M, et al. Multi-objective traffic signal control traffic lights: a realistic simulation[J]. Advances in applied self-
using network-wide agent coordinated reinforcement learning[J]. organizing systems, 2013: 45-55.
Expert Systems with Applications, 2023: 120535. [26] LEVIN M W. Max-Pressure traffic signal timing: a summary of
[17] STONE P, KAMINKA G, KRAUS S, et al. Ad hoc autonomous agent methodological and experimental results[J]. Journal of Transportation
teams: collaboration without pre-coordination [C]// Proceedings of the Engineering, Part A: Systems, 2023, 149(4): 03123001.
AAAI Conference on Artificial Intelligence. 2010, 24(1): 1504-1509.
[18] GMYTRASIEWICZ P J, DOSHI P. A framework for sequential This work is partially supported by General Program of
planning in multi-agent settings[J]. Journal of Artificial Intelligence National Natural Science Foundation of China (No.62276097);
Research, 2005, 24: 49-79.
Natural Science Foundation of Shanghai (No. 22ZR1416500、
[19] HERNANDEZ-LEAL P, KAISERS M, BAARSLAG T, et al. A survey
of learning in multiagent environments: dealing with non- No.23ZR1414900); Shanghai Pilot Program for Basic Research
stationarity[J]. arXiv preprint arXiv:1707.09183, 2017. (22TQ1400100-16).
[20] SCHAUL T, QUAN J, ANTONOGLOU I, et al. Prioritized experience
replay[J]. arXiv preprint arXiv:1511.05952, 2015.
MIAO Zijun, born in 1999, M. S. candidate. His research
[21] TESAURO G. Extending Q-learning to general adaptive multi-agent
interests include deep learning, few-shot learning.
systems[J]. Advances in neural information processing systems, 2003,
16. LUO Fei, born in 1978, Ph. D. His research interests
[22] ABBASIMEHR H, PAKI R. Improving time series forecasting using include cognitive computing and reinforcement learning.
LSTM and attention models[J]. Journal of Ambient Intelligence and DING Weichao, born in 1989, Ph. D. His research interests
Humanized Computing, 2022: 1-19.
include cloud computing, swarm intelligence computing,
[23] TANG Z, NAPHADE M, LIU M Y, et al. Cityflow: a city-scale
federated learning.
benchmark for multi-target multi-camera vehicle tracking and re-
identification [C]// Proceedings of the IEEE/CVF Conference on DONG Wenbo, born in 1978, Ph. D. His research interests
Computer Vision and Pattern Recognition. 2019: 8797-8806. include machine learning and artificial intelligence.
[24] ZHENG G, XIONG Y, ZANG X, et al. Learning phase competition for
traffic signal control [C]// Proceedings of the 28th ACM international --------------------------------------------------------------------------------- 分类号： TP391
学校代码：11066
学 号：202000358049
专 业 学 位 硕 士 论 文
基于图神经网络的特征交互推荐算法研究
Research of Feature Interactive Recommendation
Algorithm Based on Graph Neural Network
研 究 生 姓 名 ：马昕欣
指 导 教 师：崔振东 教授
专业学位类型：电子信息
专业学位领域：计算机技术
论文提交日期：2023 年 6 月 10 日 摘要
随着信息技术的快速发展和大数据的爆发式增长，如何发现有效的目标数据具
有重要意义，推荐系统能够为用户推荐个性偏好的数据信息，从而得到了越来越广泛
的应用。基于特征交互的推荐算法是推荐系统的研究热点之一，近年来提出的特征交
互推荐算法取得了不错的成果，但仍存在一些不足。主要表现为：一方面，传统的机
器学习方法能通过暴力枚举实现低阶交互建模，但无法对高阶的特征组合进行有效
捕捉；另一方面，基于深度学习的方法使用深度神经网络学习高阶特征交互是隐式
的，对特征交互过程缺乏一定的解释性。针对这些问题，本研究基于图神经网络进行
特征交互建模研究。主要内容如下：
（1）提出了一种注意力感知的图匹配特征交互推荐算法。该方法将推荐问题转
变为图匹配问题，把传统点到点的建模范式扩展到了图到图。首先，为了捕捉不同级
别的特征交互过程，该方法将用户和物品信息建模为两个特征图，并从内部交互和外
部交互两个角度来建模特征交互。内部交互捕捉单个特征图内的特征交互，外部交互
捕捉两个特征图之间的节点匹配。其次，在特征节点交互阶段和节点表示融合阶段都
引入注意力机制方法捕捉交互的重要性。最后，在两个公开数据集上开展了实验研
究，实验结果表明所提出的算法相较于对比算法具有良好的预测效果。
（2）提出了一种分层双级别图融合特征交互推荐算法。该方法针对注意力感知
的图匹配特征交互没有引入上下文信息的不足，把推荐问题转变为图分类问题。首
先，将每个特征域视为特征图中的节点，节点之间相连接的边视为特征之间的交互作
用，通过分层图结构学习更新节点之间的连接情况，得到有意义的特征交互。其次，
设计了一个双级别节点和图的表示生成模块，该模块包含两个级别的特征交互和融
合过程，局部级别交互使用边权重来更新节点的表示，全局级别交互通过压缩激励动
态捕捉各个特征域的重要程度。接下来，设计了双线性融合方法，从多个角度对两个
级别交互的节点信息进行融合。最后，通过与多个基线模型进行实验对比，结果证明
分层双级别图融合特征交互推荐算法具有更高的预测准确率。
关键词：推荐系统；图神经网络；特征交互；图匹配；图结构学习
I Abstract
With the rapid development of information technology and the explosive growth of big
data, how to discover effective target data is of great significance, and the recommendation
system can recommend data information for users to match their personality preferences has
been more and more widely used. The recommendation algorithm based on feature
interaction is one of the research hotspots of recommendation systems, and the feature
interaction recommendation algorithm proposed in recent years has achieved good results,
but there are still some shortcomings. On the one hand, traditional machine learning
methods can achieve low-order interaction modeling by violent enumeration, but cannot
effectively capture higher-order feature combinations; on the other hand, deep learning-
based methods using deep neural networks to learn higher-order feature interactions are
implicit, and lack some explanation of the feature interaction process. To address these
problems, this study is based on graph neural networks for feature interaction modeling,
which are mainly as follows:
(1) An attention-aware graph matching feature interaction recommendation algorithm
is proposed. The method transforms the recommendation problem into a graph matching
problem by extending the traditional point-to-point modeling paradigm to a graph-to-graph.
First, to capture different levels of feature interaction processes, the method models user
and item information as two feature graphs and models feature interactions from both
internal and external interactions. The internal interaction captures the feature interactions
within a single feature graph, and the external interaction captures the node matching
between two feature graphs. Secondly, attention mechanism approach is introduced to
capture the importance of interactions in both feature node interaction phase and node
representation fusion phase. Finally, an experimental study is conducted on two publicly
available datasets, and the experimental results show that the proposed algorithm has good
prediction results compared to the comparison algorithm.
(2) A hierarchical two-level graph fusion feature interaction recommendation
III algorithm is proposed. The method addresses the deficiency that attention-aware graph
matching feature interactions do not introduce contextual information, and transforms the
recommendation problem into a graph classification problem. First, each feature field is
regarded as a node in the feature graph, and the connected edges between nodes are regarded
as the interactions between features, and meaningful feature interactions are obtained by
learning to update the connections between nodes through a hierarchical graph structure.
Secondly, a bi-level node and graph representation generation module is designed, which
contains two levels of feature interaction and fusion process, local level interaction uses
edge weights to update the representation of nodes, and global level interaction dynamically
captures the importance of each feature field by compression stimulus. Further, a bilinear
fusion method is designed to fuse the node information from multiple perspectives for both
levels of interaction. Finally, the results are experimentally compared with several baseline
models to demonstrate that the hierarchical bi-level graph fusion feature interaction
recommendation algorithm has higher prediction accuracy.
Key words: Recommender Systems; Graph Neural Networks; Feature Interaction; Graph
Matching; Graph Structure Learning
IV 目 录
1 绪论 ......................................................................................................... 1
1.1 研究背景与意义 ............................................................................... 1
1.2 国内外研究现状 ............................................................................... 2
1.2.1 基于传统的浅层特征交互推荐模型......................................... 2
1.2.2 基于深度学习的深层特征交互推荐模型 ................................ 3
1.3 本文研究内容 ................................................................................... 5
1.4 本文结构安排 ................................................................................... 6
2 相关理论和技术 .................................................................................... 7
2.1 推荐系统概述 ................................................................................... 7
2.2 基于特征交互的推荐算法 .............................................................. 8
2.2.1 FM 模型 ....................................................................................... 8
2.2.2 DeepFM 模型 ............................................................................. 9
2.2.3 Fi-GNN 模型 ............................................................................. 10
2.3 图神经网络相关理论 ..................................................................... 13
2.3.1 图神经网络基本概念 ............................................................... 13
2.3.2 常见图神经网络 ....................................................................... 14
2.3.3 图相似性学习 ........................................................................... 17
2.3.4 图结构学习 ............................................................................... 19
2.4 本章小结 ......................................................................................... 21
3 注意力感知的图匹配特征交互推荐算法 .......................................... 23
3.1 引言 ................................................................................................. 23
3.2 问题描述 ......................................................................................... 23
3.2.1 符号描述 ................................................................................... 23
3.2.2 问题定义 ................................................................................... 23
3.3 模型介绍 ......................................................................................... 24
3.3.1 模型概览 ................................................................................... 24
3.3.2 特征图构建模块 ....................................................................... 25
3.3.3 节点匹配图神经网络模块 ....................................................... 25
3.3.4 节点和图表示生成模块 ........................................................... 27
3.3.5 预测和优化模块 ....................................................................... 27
3.4 算法流程 ......................................................................................... 28
3.5 实验结果与分析 ............................................................................. 29
3.5.1 实验数据集 ............................................................................... 29
3.5.2 评估指标 ................................................................................... 30 3.5.3 基线方法 ................................................................................... 30
3.5.4 实验设置 ................................................................................... 31
3.5.5 实验结果 ................................................................................... 31
3.5.6 参数对比分析 ........................................................................... 32
3.5.7 消融实验 ................................................................................... 34
3.6 本章小结 ......................................................................................... 34
4 分层双级别图融合特征交互推荐算法 .............................................. 37
4.1 引言 ................................................................................................. 37
4.2 问题描述 ......................................................................................... 37
4.2.1 相关概念与表示 ....................................................................... 37
4.2.2 问题定义 ................................................................................... 38
4.3 模型介绍 ......................................................................................... 38
4.3.1 模型概览 ................................................................................... 38
4.3.2 特征图构建模块 ....................................................................... 39
4.3.3 双级别节点和图表示生成模块 ............................................... 41
4.3.4 预测和训练模块 ....................................................................... 44
4.4 算法流程 ......................................................................................... 44
4.5 实验结果与分析 ............................................................................. 46
4.5.1 实验数据集 ............................................................................... 46
4.5.2 评估指标 ................................................................................... 47
4.5.3 基线方法 ................................................................................... 47
4.5.4 实验设置 ................................................................................... 47
4.5.5 实验结果 ................................................................................... 48
4.5.6 参数对比分析 ........................................................................... 49
4.5.7 消融实验 ................................................................................... 51
4.6 本章小结 ......................................................................................... 52
5 总结与展望........................................................................................... 53
参考文献 ................................................................................................... 55 烟台大学硕士学位论文
1 绪论
1.1 研究背景与意义
随着互联网的快速发展，海量的信息丰富了人们的物质和精神世界，人们可以通
过各种各样的方式访问互联网，获取自己所需要的信息。但是，全球信息数据量的爆
炸式增长也为用户带来了选择难题，用户很难从复杂丰富的信息中及时准确地找到
符合自己需求的信息[1]。同时，内容服务商也很难选出满足用户需求的信息[2]，进而
影响了他们为用户所提供服务质量。当信息的获取不再是问题，海量的数据反而干扰
了用户的正常决策，信息过载问题的解决成了当务之急[3-4]。推荐系统作为一种主要
解决信息过载的方式，近年来引起了各方参与者的重视并被广泛应用。推荐系统根据
用户和物品的基本属性信息以及两者之间的历史交互行为数据，发现用户的普遍喜
好和潜在需求规律，获取有价值的信息，向用户推送其感兴趣的商品列表。推荐系统
的实用性和便捷性在生活中已经被广泛证实，例如，淘宝、天猫、亚马逊等电商平台
均搭载推荐系统，根据用户的历史购买记录、商品详细介绍、用户评论等信息，给目
标用户提供推荐列表，其中不仅包括推荐的内容和用户交互的反馈方式，甚至还会给
出推荐理由[5]。一个好的推荐系统不仅可以提升用户的满意度，提高用户对平台的忠
实度，而且可以给商家带来丰厚的利润，最终实现用户和商家的双赢。
目前推荐系统中的推荐算法主要分为三类：基于内容的推荐算法[6-7]、基于协同
过滤的推荐算法[8-9]和混合推荐的推荐算法[10-11]。基于内容的推荐通过对用户和商品
的属性直接分析和计算做出推荐，基于协同过滤的推荐通过用户和商品的交互信息
给用户推荐感兴趣的物品。上述两种方法都有各自的缺点：基于内容的推荐只能推荐
内容相似的商品，从而缺少推荐的多样性，不能给用户带来一定的新鲜感；基于协同
过滤的推荐无法避免数据的稀疏性和冷启动问题。混合推荐不只使用单纯的一种推
荐机制，而是将多个方法融合在一起，从而达到更好的推荐效果，一定程度缓解了上
述问题。
在现有的研究中，利用额外的辅助信息进行建模同样也可以缓解数据稀疏和冷
启动问题。辅助信息建模中最重要的是如何建模特征之间的交互，从而形成具有高信
1 1绪论
息增益的特征组合。在特征交互中，通常分为一阶特征组合、二阶特征组合和高阶特
征组合。一阶特征可以看作是全局建模，二阶以及高阶特征组合是特征间个性化建
模。低阶组合特征和高阶组合特征对最终的个性化推荐都起到了十分重要的作用，广
泛地应用于目前的特征交互推荐算法中，成为了当前的研究热点之一。
1.2 国内外研究现状
对推荐系统来说，仅使用原始的信息进行预测取得的效果不佳。为了给用户做出
更精准的个性化推荐，需要考虑信息之间的交互情况。国内外学者对特征交互推荐进
行了广泛研究，并提出了许多推荐模型。从特征交互的角度看，这些推荐模型主要可
以分为两种类型，即基于传统的特征交互推荐模型和基于深度学习的特征交互推荐
模型。本节将从这两个方面简要介绍当前的研究现状。
1.2.1 基于传统的浅层特征交互推荐模型
当前，大多基于传统的低阶特征交互推荐模型发展比较成熟，这为后续构建基于
深度学习的模型打下基础。相对于只利用用户和物品相互行为信息进行推荐的协同
过滤模型来说，逻辑回归（Logistic Regression，LR）模型[12]综合利用了用户信息、
物品信息、上下文信息等多种不同特征，具有可解释性强、开销小和利于简单部署等
特点。但LR 模型表达能力不强，无法捕捉不同特征之间的交互情况，只能对单一特
征进行线性组合。POLY2 模型[13]延续了 LR 模型的思想，对不同特征之间进行两两
交叉建模，为模型加入了二阶非线性交互特征，从一定程度上增加了组合特征的可能
性，但其根本上还是线性模型，使用暴力组合特征让原本稀疏的特征向量变得更为稀
疏，导致模型的效率不高。为了解决POLY2 模型的缺陷，因子分解机（Factorization
Machine，FM）模型[14]在 2010 年被 Rendle 提出。FM 为了降低训练模型时的开销，
在POLY2的基础上引入了矩阵分解的思想，为每个特征学习一个隐向量，在进行特
征之间的交互时，将两个特征的隐向量内积作为交互权重，赋予重要的特征交互更大
的权重。同时，FM 有效地解决了数据稀疏问题，并且可以学习历史上从未出现过的
特征组合。在FM 模型提出之后，基于FM 的一系列变体被提出。域感知的因子分解
机（Field-aware Factorization Machine，FFM）模型[15]引入了特征域field的概念，将
2 烟台大学硕士学位论文
相同类别的特征都关联到一个特征域上。对于不同的域，每个特征都能学习到不同的
隐向量表示。FFM 模型在多项比赛中斩获冠军，但因其参数量过大，在处理实际业
务时应用性较差。域权重因子分解机（Field-weighted Factorization Machine，FwFM）
模型[16]使用一个标量来表示不同特征域之间的交互强度，在提高模型表达能力的同
时减少了模型的参数量。域矩阵因子分解机（Field-matrixed Factorization Machine，
FmFM）模型[17]用一个二维的域矩阵替换了 FwFM 的标量，提高了模型的性能。注
意力因子分解机（Attentional Factorization Machines，AFM）[18]区分了不同特征交互
的重要性，使用注意力模块来提取不同特征交互对最终结果的重要性，对预测贡献程
度高的特征交互赋予更大的权重值。Facebook 公司提出了梯度提升树（Gradient
Boosting Decision Tree，GBDT）[19]与LR 相融合的组合算法。该方法首先使用GBDT
得到某个叶子节点对应的一组特征组合，再将特征以独热向量的形式传入LR 模型进
行学习。相较于单一的LR 模型，该组合算法有着更优的性能，但非端到端两段式训
练过程，增加了计算的复杂度。
1.2.2 基于深度学习的深层特征交互推荐模型
深度学习在图像处理[20]、自然语言处理[21]和生物医学[22]等众多领域取得优异的
成果，近几年学者们也将深度学习引入推荐系统中，逐渐发展成为了新一代推荐模型
的主流技术。以下将从高阶特征的提取、低阶特征与高阶特征的结合、显式建模特征
交互、图结构建模特征交互四个方面介绍相关研究现状。
（1）高阶特征的提取
基于因子分解机的神经网络（Factorization Machine Supported Neural Network，
FNN）[23]灵感来自于图像领域通过相邻层连接扩大感受野的做法，使用DNN对FM
建模的二阶特征再次进行交叉，从而产生更加高阶的特征组合，达到增强模型学习能
力的目的。Deep Crossing模型[24]将稀疏特征嵌入为稠密的向量，把不同类型的特征
向量拼接后送入带有残差的多层感知机（Multilayer Perceptron，MLP）中，实现完成
特征各个维度充分交叉融合的目的。基于乘积的神经网络（Product-Based Neural
Network，PNN）[25]使用内积和外积操作对不同特征之间的交互进行捕捉，提高了模
型的表达能力。神经因子分解网络（Neural Factorization Machine，NFM）[26]针对FM
3 1绪论
不能进行高阶交互的不足，用一个表达能力强的函数代替 FM 中二阶隐向量内积部
分，并且引入特征交叉池化层，加强了交互能力。
（2）低阶与高阶特征的结合
低阶特征和高阶特征对于最终的推荐预测都是有帮助的，一味地追求高阶特征
提取有可能会淡化低阶交互的影响，因此需要对低阶与高阶交互进行结合。
Wide&Deep 模型[27]通过并行结合 LR 和 DNN 对低阶与高阶交互同时建模，实现了
Wide 部分的“记忆能力”和 Deep 部分的“泛化能力”，在当时成为业界的主流模
型。Deep&Cross模型[28]借鉴了Wide&Deep模型的思路，使用多层交叉层代替了Wide
部分，增加特征之间的交互力度。基于神经网络的因子分解机（Factorization Machine
Based Neural Network，DeepFM）模型[29]针对 Wide&Deep 模型 Wide 部分自动进行
特征组合能力不足的问题，用FM 代替了Wide部分，加强了浅层网络的特征交互能
力。但是该模型的高阶交互使用了隐式的建模方式，不符合特征交互的直观理解，缺
乏良好的解释性。
（3）显式建模特征交互
学者们通过设计独特的模块来显式地建模特征交互，用以提高算法的可解释性。
极深因子分解机（eXtreme Deep Factorization Machine，xDeepFM）模型[30]设计了压
缩交互式网络（Compressed Interaction Network，CIN）代替Deep&Cross 中的多层交
叉层，从而进行显式地特征交互。双线性特征交互网络（Feature Importance and Bilinear
Feature Interaction NETwork，FiBiNET）[31]借鉴图像领域的压缩激励机制[32]动态学习
特征重要性的策略，并使用双线性特征交互网络建模细粒度的特征交互，显式地构建
交互特征。自动特征交互（Automatic Feature Interaction Learning，AutoInt）模型[33]使
用自注意力机制显式地学习高阶特征交互，有效提升了预测的准确率。解耦自注意网
络（DisentanglEd Self-atTentIve Network，DESTINE）[34]将一元交互特征重要性计算
从二阶特征交互中解耦出来，分别学习一元特征重要度和特征对交互，相对于AutoInt
模型增强了单个特征域对最终结果的影响。分层注意力可解释预测模型（Interpretable
CTR Prediction Model with Hierarchical Attention，InterHAt）[35]通过新的层次注意力
机制量化了任意阶数的特征交互影响，根据学习到的特征显著性解释了推荐的结果。
自适应因子网络（Adaptive Factorization Network，AFN）模型[36]设计了带有对数转换
4 烟台大学硕士学位论文
层的结构，将特征组合中每个特征的幂转换为要学习的参数，提取了MLP 忽略的特
征，提升了模型性能的同时增加模型的可解释性。
（4）图结构建模特征交互
随着图神经网络在各个领域取得成功的同时，基于图结构进行特征交互建模也
取得了不错的效果。特征交互的图神经网络（Feature Interaction Graph Neural Network，
Fi-GNN）模型[37]使用自注意力网络和图神经网络学习特征节点的交互，为后续的图
结构建模开创了理论先河。L 正则化统计交互图神经网络（L activation regularization
0 0
Statistical Interaction Graph Neural Network，L -SIGN）[38]使用图神经网络自动发掘对
0
推荐系统有利的二阶特征交互，将特征节点和检测到的有益特征交互边作为输入特
征图，并通过有效地建模和聚合特征节点输出最终的推荐结果。分层意向嵌入网络
（Hierarchical Intention Embedding Network，HIEN）[39]自上而下地考虑属性图中属性
之间的依赖性，同时提出用户意图和项目意图的双重意图，以准确地学习用户和项目
表示。图因子分解机（Graph Factorization Machine，GraphFM）模型[40]使用图神经网
络可以通过迭代多层以建模任意阶数交互的优势，克服了 FM 只能建模二阶交互的
不足。神经图匹配协同过滤（Neural Graph Matching based Collaborative Filtering，
GMCF）模型[41]考虑了不同级别的特征交互对最终推荐预测的影响，将特征交互分为
内部交互和交叉交互两个部分，用以共同决定最终的预测结果。
1.3 本文研究内容
本研究重点关注推荐系统中特征交互的预测任务，对分类变量进行建模，借助图
结构完成特征交互。利用图机器学习中两大相关技术，即图匹配技术和图结构学习技
术，并融合图神经网络主要框架，对现有的图神经网络特征交互推荐算法进行改进。
本研究提出了注意力感知的图匹配特征交互推荐算法和分层双级别图融合特征交互
推荐算法，并通过实验验证了模型的有效性、合理性和准确性。
主要研究内容如下：
首先，提出了一种注意力感知的图匹配特征交互推荐（Attention-aware Graph
Matching Recommendation，AGMRec）算法。AGMRec 算法的基本思想是将用户属
性和物品属性建模为用户和物品两个特征图，把特征交互点到点的建模范式扩展到
5 1绪论
图到图，从内部和外部两个角度来进行特征节点之间的交互，并通过注意力机制对交
互过程进行合理的权重分配。基于两个公开数据集开展实验验证，算法的整体性能、
模块消融实验、模型超参实验等方面都证实了AGMRec算法的合理性和有效性。
其次，鉴于推荐任务中用户和物品发生交互时的上下文环境信息仍能对推荐结
果产生影响，进一步引入上下文信息特征从而提高推荐的准确性，提出了分层双级别
图融合推荐（Hierarchical Dual-level Graph Feature Interaction，HDGFI）算法。HDGFI
将特征域信息建模为图结构中的节点，运用分层邻接矩阵 Top-k 选择机制筛选重要
的特征交互，并从局部和全局两个角度进行特征节点之间的交互。最后，通过实验验
证了HDGFI算法的有效性和准确性。
1.4 本文结构安排
论文章节结构如下：
第一章：绪论。首先，对推荐系统的研究背景与意义进行了相关介绍；其次，概
述了特征交互推荐算法的国内外研究现状；最后，阐述本论文的研究内容和章节结
构。
第二章：相关理论和技术。对涉及到的相关技术进行介绍。首先，概述了推荐系
统以及推荐系统中的主要算法；其次，介绍了图神经网络的基本定义和常见的三种图
神经网络；最后，介绍了图相似性学习方法和图结构学习方法。
第三章：注意力感知的图匹配特征交互推荐算法。首先，介绍了目前特征交互推
荐算法存在的问题；其次，针对目前算法的不足，提出了注意力感知的图匹配特征交
互推荐算法；接下来，对实验所用到的数据集、评价指标和基线模型进行描述；最后，
对实验结果进行了展示和分析，证明该算法能够有效提升推荐预测效果。
第四章：分层双级别图融合特征交互推荐算法。首先，介绍了相关算法的局限性；
然后，提出了分层双级别图融合特征交互推荐算法，并对整体框架、具体的组件进行
了详细介绍；最后，在三个公开数据集上与多个基线方法进行分析比较，证明模型的
有效性和准确性。
第五章：总结与展望。对本文研究工作进行了总结，指出存在的不足，并对未来
工作进行了展望。
6 烟台大学硕士学位论文
2 相关理论和技术
本章是论文相关理论和技术的介绍。首先，介绍了推荐系统的基本概念和基本理
论，对推荐系统进行全面的了解；然后，介绍具有代表性的特征交互推荐算法原理；
其次，介绍图神经网络相关理论；最后，介绍图相似性学习和图结构学习相关技术。
2.1 推荐系统概述
推荐系统作为一种信息过滤工具，通过对用户的偏好进行学习和预测，并向用户
推荐用户可能喜爱的物品。推荐系统包含三大组成部分：用户、物品和推荐方法。其
中，用户是推荐系统的使用者，物品是推荐系统要推荐的商品，推荐方法决定着推荐
结果的好坏，也是推荐系统的核心研究内容。目前，推荐系统在电商平台、金融市场
和社交网络等众多领域中得到了广泛应用；它在帮助用户快速找到自己所需物品的
同时，也为企业和制造商带来巨大效益。一般来说，推荐系统主要分为三个阶段：分
别是召回、排序和调整。推荐系统的三个阶段如图2.1所示。
图2.1 推荐系统的三个阶段
（1）召回阶段
召回阶段主要根据用户的部分特征，从海量的物品库中，快速召回小部分用户潜
在感兴趣的物品[42]。由于召回面对的候选物品数量非常庞大，所以召回阶段的算法
通常具有轻量、快速和低延迟等特性。可使用的召回策略主要有协同过滤召回、内容
相似召回、用户画像召回和热门召回等。由于每个召回策略的出发点和侧重点不同，
一般会采用多种召回策略一起进行召回，将尽可能把与用户相关的物品全部找出来。
（2）排序阶段
经过召回阶段，候选物品数量已经大大减少了，排序阶段使用复杂的点击率预测
7 2相关理论和技术
模型，从用户与物品的交互行为中挖掘更为丰富的信息，将召回的结果进行排序。排
序阶段最常用的是 Pointwise排序方法，它考虑用户和物品的特征，并关注交互时的
上下文环境信息[43]。Pointwise排序方法有基于传统机器学习的LR、FM 等算法，以
及基于深度学习的 DeepFM、Wide&Deep 等算法。若用户和物品初始数据量较少，
可以跳过召回阶段，直接进行排序预测。
（3）调整阶段
在经过召回和排序阶段，由于要考虑购买物品的时效性和真实性，对于重复推
荐、已经或正在购买、已经下线的物品进一步过滤。当前两阶段推荐结果不够时，选
取热门的物品对候选集进行补充，最后将补充的候选集和经过筛选后的候选集进行
合并，把含有完整数据的商品推荐列表反馈给用户。
2.2 基于特征交互的推荐算法
本节按照特征交互推荐算法的发展历史介绍一些主要的代表性算法模型。主要
包含基于传统机器学习特征交互的 FM 模型和基于深度学习的 DeepFM 和 Fi-GNN
模型。
2.2.1 FM 模型
传统的逻辑回归模型学习能力有限，因此 Steffen Rendl 等人提出了 FM 模型。
FM 模型将逻辑回归模型扩展为二阶特征交互，它具有两大优势：其一是进行特征组
合，以两两组合的方式，引入交叉项特征，使模型能够学习到特征与特征之间的关系；
其二是缓解了高维度稀疏矩阵带来的维度爆炸问题，通过引入隐向量，对原始为0的
特征也可以很好地学习。假设一个输入样本的特征向量为X ∈n，初始的模型表达
如公式(2-1)所示。
n n−1 n
y(X)=w +∑ wx +∑ ∑ w (x ∗x ) (2-1)
0 i i ij i j
i=1 i=1 j=i+1
其中，n代表每条样本数据的特征数量，x 是第i个特征的值，w 、w 和w 分别代表
i o i ij
全局偏差、第i个特征的权重以及第i个特征和第 j个特征的交互权重。FM 模型在保
8 烟台大学硕士学位论文
留特征线性关系的同时，通过增加任意两个特征之间的交互结果来提高预测的效果。
从公式(2-1)可以看出二阶组合特征的参数量共n(n−1)/2，在实际应用场景中，样本
的特征向量是及其稀疏的，表现为x 和x 的值大都为0。若直接学习二阶特征交互的
i j
参数，而实际问题中的二阶交互特征有时不存在。为了解决这个问题，引入了矩阵分
解的思想，为每一个特征x 学习一个隐向量v ，将二阶交互权重参数w 用vTv 去替
i i ij i j
代，改进后如公式(2-2)所示。
n n−1 n
y(X)=w +∑wx +∑ ∑ <v,v > xx (2-2)
0 i i i j i j
i=1 i=1 j=i+1
其中，<v ,v >代表两个隐向量之间的点积操作，v 隐向量可以设置为远小于特征
i j i
向量维度的长度。根据矩阵变换原理，将公式(2-2)进行优化为公式(2-3)，使模型的
时间复杂度从原来的O(kn2)降低到O(kn)。公式(2-3)的表示如下：
n−1 n 1 n n 1 n
∑ ∑ <v,v > xx = ∑∑<v,v >xx − ∑<v,v >xx
i j i j i j i j i j i i
2 2
i=1 j=i+1 i=1 j i=1
1 n n k n k 
= ∑∑∑v v xx −∑∑v v xx 
i,f j,f i j i,f i,f i i
2 i=1 j=1 f=1 i=1 f=1 
(2-3)
1 k  n  n  n 
= ∑ ∑v i,fx i∑v j,fx j−∑v i2 ,fx i2 
2 f=1 i=1  i=1  i=1 
 2 
1 k  n  n
= ∑∑v i,fx i −∑v i2 ,fx i2
2 f=1
i=1

i=1

其中，v 是隐向量v 的第 f 个元素。FM 能够对二阶特征交互进行建模，但考虑到
i,f i
效率问题，一般不会直接使用FM 来进行高阶特征交互的学习。
2.2.2 DeepFM 模型
FM 虽然可以对稀疏的数据进行特征交互建模，但只能用线性方式对线性多阶交
互进行建模。实际应用场景中存在着数据高度非线性关系，仅用线性交互模型难以建
模。深度学习网络具有建模复杂特征交互的能力，DNN建模高阶特征交互逐渐成为
9 2相关理论和技术
主流。DeepFM 将 FM 模块与 DNN 模块并行，两个模块共享输入特征向量。其中，
FM 模块用于捕捉一阶和二阶交互特征，DNN 模块用于捕捉高阶交互，整个模型是
一个端到端的结构。DeepFM 模型架构如图2.2所示。
图2.2 DeepFM模型框架图
FM 部分的公式表达在 2.2.1 节已经详细介绍过，本节将介绍 DNN 模块和两部
分融合方法。DNN模块的输入是所有特征向量的拼接向量，其表示如公式(2-4)所示。
y = Relu(W ∗h +b) (2-4)
DNN l l−1 l
其中，Relu是非线性激活函数，W 和b 是第l层的训练参数。最终的模型如公式(2-5)
l l
所示。
 y =Sigmoid(y + y ) (2-5)
FM DNN
其中，Sigmoid激活函数将预测值标准化在0到1之间。DeepFM 模型使用并行捕捉
低阶和高阶特征交互的方式为后续推荐算法设计提供了新的路线，众多的研究在此
基础上进行了更新与完善。
2.2.3 Fi-GNN 模型
10 烟台大学硕士学位论文
当前基于DNN高阶特征交互模型的输入是把特征向量进行简单拼接，然后将结
果输入到多层感知机中。这些做法隐式地捕捉了高阶交互，但缺乏很好的解释性。图
神经网络通过迭代进行消息传递和节点表示更新，可以显式地捕捉节点之间的交互
情况。Li 等人在 2019 年提出 Fi-GNN，这是第一个用图神经网络建模高阶交互的推
荐算法。在Fi-GNN中，用图结构表示各类的特征，每一个节点代表一个特征域，通
过获取邻居节点的状态信息并结合自身当前的隐藏状态来更新自己的当前状态。每
多堆叠一个GNN层，相当于目标节点与邻居节点交互更深了一层，因此，时间步的
数量等于特征交互的阶数。Fi-GNN模型框架如图2.3所示。
图2.3 Fi-GNN模型框架图
Fi-GNN模型中，首先通过一个特征嵌入层将特征转化为低维稠密向量，然后通
过多头注意力机制捕捉成对特征的复杂依赖，接下来构建加权的全连接图，最后通过
堆叠图神经网络来聚合邻居信息。特征交互图神经网络是Fi-GNN的核心部分，本节
主要介绍特征交互图神经网络部分。
在特征交互图神经网络中，主要分为三个步骤，即初始化参数、状态聚合和状态
更新。初始化参数将经过多头注意力机制层得到的向量作为特征图节点初始的隐藏
11 2相关理论和技术
向量。在交互时间步t状态聚合时，每个节点聚合邻居的状态信息，具体的思路是节
点n 的聚合信息是邻居的转换信息的总和：at =∑ A[ n ,n ] W ht−1。其中，A是
i i nj→ni∈ε j i P j
带有权重的邻接矩阵，W 是变换函数。显然，变换函数和邻接矩阵决定了节点的交
P
互，由于每条边上的交互应该不同，因此，需要每条边都有一个独特的权重和变换函
数。在计算邻接矩阵权重时，通过注意力机制学习边权重，节点n 到节点n 的边的
i j
权重计算如公式(2-6)所示。
[ ]
exp(Leakyrelu(W e ||e ))
w(n,n )= w i j
i j ∑exp(Leakyrelu(W [ e ||e ] ))
w i k
k (2-6)
w(n,n ),ifi ≠ j
A[n,n ]= i j
i j
 0,else
考虑到所有边都使用固定的变换函数无法模拟灵活的交互，因此每条边的唯一
变换是必不可少的。由于特征交互图是具有大量边的完全连通图，如果为每条边分配
一个变换权，会造成参数空间的冗余和较高的时间复杂度。因此，Fi-GNN为每条边
分配了一个输入矩阵W 和输出矩阵W ，利用输入矩阵和输出矩阵构造变换函数。
in out
具体的变换函数如公式(2-7)所示。
Wni→nj =Wi W j (2-7)
p out in
在状态更新阶段，利用循环神经网络单元GRU对最近一次节点隐藏状态和聚合
状态信息进行操作，对应的表达式为ht =GRU(ht−1,at)。具体的计算如公式(2-8)所示。
i i i
zt =σ(W at +U ht−1+b )
i z i z i z
rt =σ(W at +U ht−1+b )
i r i r i r
(2-8)
ht = tanh(W at +U (rt ht−1)+b )
i h i h i i h
ht =ht zt +ht−1(1−zt)
i i i i i
其中W 、U 和b 是可训练参数。Fi-GNN 同时引入了残差连接，同时考虑高阶和低
∗ ∗ ∗
阶交互，促进低阶特征的重用和训练时梯度的反向传播，计算过程如公式(2-9)所示。
ht =GRU(ht−1,at)+hl (2-9)
i i i i
12 烟台大学硕士学位论文
2.3 图神经网络相关理论
得益于计算机硬件计算性能和存储能力的大幅提升，近年来深度学习得到了快
速发展，并在各个领域获得巨大成功。然而，现有的神经网络只能对欧式结构数据进
行处理，不能直接将传统的深度学习模型迁移应用到非欧式结构数据中[44]。图神经
网络将实体和实体之间的关系建模为图结构，直接对节点信息和边信息进行集成与
学习，在处理实际问题时可以将各种非欧式数据问题抽象为图结构。图神经网络是一
个学习方法的总称，核心的思想是基于消息传递机制不断更新节点的表示，去更好地
完成下游任务。学者们针对不同类型的图、不同的消息传递机制设计出了各种图神经
网络的变体。本章将从图神经网络的基本概念、常见的图神经网络和图神经网络的应
用三个方面详细介绍图神经网络。
2.3.1 图神经网络基本概念
图结构在生活中无处不在，是一种典型的数据结构。图表示为G ={V,E}，其中
V 是节点的集合， E 是图结构中边的集合。v ∈V 表示图结构中的一个节点，
i
e =(v ,v )表示节点v 和v 之间有一条边连接。N(v )={v |(v,v )∈E}表示节点v 的
ij i j i j i j i j i
邻居集合。一般来说，图可以从下面三个方面来分类。
（1）有向图和无向图
按照边是否有方向，图可以分为有向图和无向图。一个图结构中，若明确用箭头
指明了边的方向，这种图称为有向图，否则称为无向图。在无向图中，一条边用圆括
号表示，且(v,v )与(v ,v )表示意义相同。在有向图中，一条边用尖括号表示，且
i j j i
<v ,v >与<v ,v >表示意义不同。<v ,v >表示从顶点v 发向顶点v 的边，v 为始
i j j i i j i j i
点，v 为终点。
j
（2）同构图和异构图
按照节点和边类型，图可以分为同构图和异构图。若节点的类型和边的类型只有
一种，这种图称为同构图，否则称为异构图。图中节点类型映射函数φ:V → A，边类
13 2相关理论和技术
型映射函数ϕ:E → R，其中 A和 R 分别代表了节点类型结合和边类型集合。当
A + R ≥2时代表异构图，当 A =1，R =1时代表同构图。在同构图中，数据只存在一
种节点类型和边连接关系，在构建网络时所有图结构中节点共享同样的模型参数。在
异构图中，不同类型的节点拥有不同维度的特征和属性。
（3）普通图和超图
按照边连接节点的个数，图可以分为普通图和超图，若一条边可以连接任意数量
的节点，这种图称为超图。若一条边只能连接两个节点，则这种图称为普通图。超图
可以表示为G ={V,E,W}，其中V 为顶点集，E为超边集，W 为超边权重。
图神经网络在不同图上进行学习的核心思想是迭代更新节点的信息，在迭代的
过程中结合自身节点信息和邻居节点信息共同来更新目标节点[45]。图神经网络在计
算过程中主要包括两步，即消息构建和信息聚合。消息构建指的是图中的节点产生一
条消息并传递给它的邻居节点，如公式(2-10)所示。
m(l) = Message(l)(h(l−1)) (2-10)
u u
其中，h(l−1)表示节点u在第(l−1)层的向量表征；Message(l)表示第l层自定义的消
u
息函数，此函数一般为线性变换函数；m(l)为节点u产生的消息信息。在获得每个
u
节点的消息信息后，下一步就是聚合邻域的信息，计算如公式(2-11)所示。
h(l) = Aggregation(l)({m(l),u∈N(v)}) (2-11)
v u
其中，N(v)表示节点v的邻居集合；Aggregation(l)表示第l层的自定义聚合函数，
主要聚合方式有平均池化、加和池化以及基于注意力的池化等；h(l)表示聚合了邻
v
居节点信息的节点v向量。为了考虑节点自身在消息构建和信息聚合时的影响，对
上面两个公式进行修正，修正方法如公式(2-12)所示。
 m(l) =Message(l)(h(l−1)),u∈{N(v)∪v}
 u u (2-12)
h(l) = Aggregation(l)({m(l),u∈N(v)},m(l))
v u v
2.3.2 常见图神经网络
14 烟台大学硕士学位论文
图神经网络根据不同的消息构建和信息传递方式产生了许多的变体，接下来介
绍几种常见的变体形式。
（1）图卷积网络（Graph Convolutional Network，GCN）
图卷积网络[46]类似于卷积神经网络，实际是针对图结构的一个特征提取器。图
卷积网络是谱图卷积一阶局部近似，每一个卷积层仅处理一阶邻域信息，通过叠加若
干个卷积层实现多阶邻域的信息传递。图卷积网络结构如图2.4所示。
图2.4 图卷积网络结构
图卷积网络输入的是节点信息向量矩阵H 和邻接矩阵A，每一个卷积的计算过
程如公式(2-13)所示。
H(l+1)
=σ(D−1/2 AD−1/2
H(l)W(l)) (2-13)
其中，σ是非线性激活函数；W(l)是第l层的线性转换矩阵；A是添加了自连接的邻
接矩阵；D 邻接矩阵的度矩阵。图卷积网络利用整个图的邻接矩阵来更新节点的表
示，因此一般用于直推式任务而不能处理归纳式任务。
（2）图采样和聚集网络（Graph Saple and Aggregation，GraphSAGE）
为了解决图卷积网络不能处理归纳式任务的问题，图采样和聚集网络[47]被提出。
图采样和聚集网络结构如图2.5所示。
15 2相关理论和技术
图2.5 图采样和聚集网络结构
图采样和聚集网络分为三个部分，首先对邻居节点进行采样，然后通过多层聚合
函数不断地将相邻节点融合，最后用融合后的节点信息针对下游任务进行学习。在采
样阶段，定义一个采样邻居节点的个数k，当目标节点邻居节点个数大于k时，通过
采样策略获取k个邻居节点，纳入目标节点的邻居节点集合。若目标节点邻居节点个
数小于k时，有放回地重采样直到采样出k个节点。具体计算如公式(2-14)所示。
h(l) =σ(W(l)⋅CONCAT(h(l−1),Aggregation({m(l),u∈N(v)}))) (2-14)
v v u
其中，h(l)是节点v在第l层的表示，σ是非线性激活函数。首先计算节点v的所有邻
v
居节点消息信息m(l)，然后进行消息的聚合。为了避免节点v自身信息在传递过程中
u
丢失，通过 CONCAT 操作将节点v上一层的输出h(l−1)和邻居聚合后的结果进行拼
v
接，再通过一个线性映射和激活函数得到当前层的节点输出向量。与图卷积网络相
比，图采样和聚集网络引入了三种消息聚合函数，分别为平均聚合，最大池化聚合和
LSTM 聚合。
（3）图注意力网络（Graph Attention Network，GAT）
图卷积网络中假设每个节点同样重要，从而忽略了节点之间关系的重要程度和
每个邻居节点对目标节点的重要程度。注意力机制已经成功应用于图像处理、机器翻
译等领域。研究人员将注意力机制与图卷积网络相结合，提出了图注意力网络[48]。图
注意力层的结构如图2.6所示。
16 烟台大学硕士学位论文
图2.6 图注意力层结构
图注意力网络通过堆叠图注意力层，实现节点表示的更新。具体的计算过程如公
式(2-15)和(2-16)所示。
exp(Att(h(l−1),h(l−1)))
α = v u (2-15)
uv ∑ exp(Att(h(l−1),h(l−1)))
k∈N(v) v k
h(l) =δ(∑ α W(l)h(l−1)) (2-16)
v u∈N(v) uv u
其中，α 表示节点u到节点v的注意力系数，δ是激活函数，N(v)表示节点v的邻居
uv
节点集合。Att(⋅)为注意力计算方法，常见方式是Leakyrelu(aT[W(l)h(l−1) ||W(l)h(l−1)])，
v u
其中，W(l)为节点向量线变换权重矩阵，aT 是可学习的参数，||表示节点向量的拼接
操作。通过公式(2-16)可以得到最终更新的节点v在第l层的表示h(l)。
v
2.3.3 图相似性学习
图神经网络通过迭代聚合局部信息更新目标节点表示，可以有效地学习结构化
数据的表示和解决监督预测问题。当前大多数图神经网络的研究都是围绕单个图结
构进行，而对于两个图或者多个图结构之间的相似性学习在计算机视觉、自然语言处
理和推荐系统领域有更为广泛的应用需求。图相似学习有两种主要学习思路：一种是
图嵌入，得到每个图的向量表示，不同图之间的相似度通过图向量的距离衡量。这种
17 2相关理论和技术
方法的好处是如果需要对数据库中的大量图结构进行对比时，只需利用已有的一些
距离计算方法对数据库中的图向量进行比较即可。另一种是对图进行结对比较，重点
比较两个图之间各个节点的相似性，这种方式精确度更高，但随之而来的是高的计算
复杂度。两种方法的流程如图2.7所示。
图2.7 图相似性计算流程
具体来说，首先给定两个图结构G =(V,E )和G =(V,E )，每个图中的V 和E
1 1 1 2 1 1
代表节点集合和边集合，每个节点 v都具有节点特征向量h 。图相似性学习的任务是
v
设计一个模型 f 来生成两个图的相似性得分，即score= f(G ,G )。图嵌入学习图向
1 2
量的方式可以由2.3.2节所介绍的几种方法得出。
对图比较方法也称为图匹配模型。Li 等人 2019 年提出了图匹配网络（Graph
Matching Network，GMN）[49]改变了每个传播层中节点的更新方式，不仅捕捉了每个
图在边上聚合的信息，而且还考虑了一个跨图匹配向量。跨图匹配向量描述了一个图
中的节点与另一个图中的节点或多个节点的匹配程度。图匹配网络主要分为三个步
骤，即编码层、传播层和聚合层，计算过程如下：
m = f (h(l),h(l),e ),∀(i, j)∈E ∪E (2-17)
j→i message i j ij 1 2
µ = f (h(l),h(l)),∀i∈V, j∈V ori∈V , j∈V (2-18)
j→i match i j 1 2 2 1
18 烟台大学硕士学位论文
h(l+1) = f (h(l),∑m ,∑µ ) (2-19)
i node i j→i j'→i
j j'
其中，f 和 f 分别代表消息的构建和消息聚合，实现方法和普通图神经网络一
message node
致； f 是一个传递跨图信息的函数，使用一个基于注意力的模块来实现。 f 的
match match
计算方法如公式(2-20)和公式(2-21)所示。
exp(s (h(l),h(l)))
a = h i j (2-20)
j→i ∑exp(s (h(l),h(l)))
h i j'
j'
µ =a (h(l) −h(l)) (2-21)
j→i j→i i j
其中，a 是注意力权重；s 是向量相似度计算方法。相似度计算方法常见的有余
j→i h
弦相似度、欧几里得距离等。获得两个图的节点表示后，通过全局池化操作得到两
个图的整体嵌入表示，最后使用向量空间中相似度量来计算两个图的相似性。
2.3.4 图结构学习
图神经网络对图的拓扑结构进行解析和建模过程中，对设定的图结构敏感性很
强[50]。一方面，图神经网络的迭代机制具有级联效应，会将小噪声通过层层消息传播
到邻域，降低其它节点的表示效果。另一方面，将现实对象交互建模为图结构时需要
建模重要的子结构，有限的先验知识和预定义的图结构只携带了部分信息，甚至有些
现实对象之间并不存在天然的图结构，因此建模出的图结构不能有效地对目标任务
进行分析和处理。为了给下游任务提供一个最佳的图结构，许多学者针对图结构学习
方法开展了广泛的研究。图结构学习的学习流程如图2.8所示。
图2.8 图结构学习流程
图结构建模是图学习的一个核心步骤。图结构建模完成对边连接的建模，选择重
19 2相关理论和技术
要的边进行保留，并过滤噪音边连接。目前的图结构建模可以分为三种类型，即基于
度量的方法、基于神经网络的方法和直接方法。以下分别介绍这三种类型的图结构建
模方法。
（1）基于度量的方法
基于度量的方法使用核函数计算节点的相似度作为边权重，根据边倾向于连接
相似节点的假设，通过优化边连接来生成更为准确的图结构。自适应图卷积神经网络
（Adaptive graph convolutional neural networks，AGCN）[51]提出了一个通用灵活的图
卷积网络，利用广义马氏距离计算每对节点之间的相似度，使用高斯核来细化拓扑结
构。迭代深度图学习（Iterative deep graph learning，IDGL）方法[52]基于更好的节点嵌
入学习更好的图结构和基于更好图结构学习更好的节点嵌入的关键原理，使用余弦
相似度核的方式迭代学习图结构和节点嵌入，使图结构足够接近下游的预测任务。
（2）基于神经网络的方法
与基于度量的方法相比，基于神经网络方法图结构建模是利用深度神经网络来
建模给定节点特征和表示边的权重。图学习卷积网络（Graph learning-convolutional
networks，GLCN）[53]通过单层神经网络获得节点对之间的边连接关系。参数化拓扑
去噪网络（Parameterized topological denoising network，PTDNet）[54]使用多层感知机
来学习邻接矩阵并去除与任务无关的边连接，提高了图神经网络的鲁棒性和泛化能
力。
（3）直接方法
直接方法将邻接矩阵视为一个可训练的参数，通过反向传播进行优化。由于直接
方法训练过程中不依赖于节点的表示，所以具有更强大的灵活性，但缺点是相对于其
它两种方法学习邻接矩阵参数较为困难。图学习神经网络（Graph learning neural
networks，GLNN）[55]将邻接矩阵的稀疏性和特征平滑性加入损失函数中，使图拓扑
结构适应输入的数据。离散结构学习图神经网络（Learning Discrete Structures for
Graph Neural Networks，LDS-GNN）[56]将图结构学习问题视为双层规划问题，从具有
可学习参数的伯努利分布中采样，对每对节点之间的边缘进行建模，在学习数据点之
间的离散和稀疏依赖关系的同时训练图卷积网络参数。
20 烟台大学硕士学位论文
2.4 本章小结
本章首先介绍了推荐系统实现过程，包括召回、排序和调整三个阶段；然后针对
三个具有代表性的特征交互推荐算法 FM、DeepFM 和 Fi-GNN 分别进行了介绍；最
后介绍了图神经网络的相关理论，包括图神经网络的基本概念、常见的图神经网络、
图相似性学习和图结构学习等。
21 2相关理论和技术
22 烟台大学硕士学位论文
3 注意力感知的图匹配特征交互推荐算法
3.1 引言
推荐算法根据用户的历史行为对用户兴趣进行建模，为用户推荐满足需求的物
品或信息。基于协同过滤的推荐是一种经典的推荐方法，它根据兴趣相似的用户对相
似的物品有共同偏好的假设进行预测，从而筛选出目标用户可能感兴趣的物品。传统
的协同过滤算法大多根据用户和项目的ID信息进行过滤，忽略了用户和物品的属性
信息，但这些信息的共现性往往对推荐能否成功起着重要作用。学习复杂的属性之间
特征交互对于推荐系统来说是非常必要。例如，在电影推荐场景下，男性用户更偏爱
动作片和科幻片，女性用户则对爱情片更感兴趣。使用用户性别和电影类型两个属性
联合起来进行推荐策略，往往会比单纯考虑单个属性信息更有效。当前特征交互模型
主要存在两方面问题：一方面，使用相同的方法来建模用户与物品属性之间的交互，
但不同类型的属性交互（用户属性-用户属性，用户属性-物品属性）对最终推荐的影
响不同，因此无法明确显示用户和物品属性之间的交互过程；另一方面，现有研究方
法主要通过用户与物品属性之间交互的隐向量直接连接或平均进行最终推荐预测，
但没有考虑不同属性之间的交互权重。
针对上述问题，本章提出了一种注意力感知的图匹配特征交互推荐 AGMRec
（Attention-aware Graph Matching Recommendation）算法。该算法将属性特征建模为
图中的节点，特征之间的交互建模为边，把推荐过程转变为图匹配问题。
3.2 问题描述
基于特征交互的推荐算法旨在根据用户和项目属性特征学习各自的静态表示，
从而给出点击率预测结果。下面给出本章所研究问题的符号定义。
3.2.1 符号描述
属性特征与属性集合。点击记录即一个样本包括用户和项目的属性特征。令AU
和AI 分别表示用户和项目属性，CU ={f , f ,..., f }(f ∈AU)表示第i个点击记录中用
i 1 2 p p
户的属性集合，CI ={f , f ,..., f }(f ∈AI)表示第i个点击记录中项目的属性集合。
i 1 2 q q
3.2.2 问题定义
23 3注意力感知的图匹配特征交互推荐算法
根据 3.2.1 节中定义的用户和项目属性集合，可将所有的点击记录表示为
Dall ={X ,X ,...,X }，其中X ={(CU,CI)}代表第i条点击记录，N 为数据集中的总
1 2 N i i i
体样本数量。预测任务为：学习一个预测函数F(D)，输入已知用户的点击记录集合
D，预估其点击概率Yall ={y ,y ,...,y }，其中y ∈[0,1]，i∈[1,N]，如公式(3-1)所示。
1 2 N i
F(Dall)=Yall (3-1)
3.3 模型介绍
3.3.1 模型概览
在考虑不同属性之间的交互权重的基础上，本研究提出了一个注意力感知图匹
配特征交互推荐算法AGMRec，其结构如图3.1所示。
图3.1 AGMRec模型结构图
AGMRec模型的创新主要包括两点：
（1）本模型将推荐系统中的特征交互问题转换为了图匹配问题，把用户和物品
属性信息建模为两个特征图。特征图中的节点代表特征，特征之间的交互建模为图结
24 烟台大学硕士学位论文
构中的边。AGMRec 模型设计了一个节点匹配图神经网络模块，从内部和外部两个
角度来建模特征交互，显式地建模特征之间的交互过程。
（2）在内部节点交互部分、外部节点匹配部分和节点表示融合部分都运用了注
意力机制。该机制有选择性地增强关联特征之间的交互过程，并自适应地捕捉对最终
预测相对重要的阶数表示。
接下来，按照模型的层次依次介绍具体细节。
3.3.2 特征图构建模块
为了能够更好地表明属性之间的交互，本节将用户和物品属性分别表示为一个
图结构。特征图中的一个节点表示用户或者物品的一个属性信息，节点之间的边代表
一对属性的交互。首先，考虑到属性之间都需要彼此进行交互，将特征图建模为完全
连通图。具体来说，用户特征图表示为G =(V ,E )，其中每个节点v ∈V 对
UAG UAG UAG i UAG
应用户的一个属性信息，E 是所有用户特征图中边的集合。同时，对物品属性信
UAG
息进行相同的操作，获得物品特征图G =(V ,E )。然后，创建一个用户特征图
IAG IAG IAG
的节点属性嵌入矩阵Wu ∈RAU×d ，其中d 是特征嵌入维度，AU 是用户属性的数量。
emb
同样的，创建项目特征图的节点属性嵌入矩阵Wi
∈RAI×d。最终，得到用户和物品
emb
特征图的初始化节点表示Gori ={hori,hori,...,hori },Gori ={hori,hori,...,hori }。
UAG 1 2 UAG IAG 1 2 IAG
3.3.3 节点匹配图神经网络模块
3.3.3.1基于图神经网络的内部交互
AGMRec模型通过在单个特征图的图节点之间进行信息传递完成内部交互。特
征图邻接矩阵是一个二元邻接矩阵，它只能反映属性节点之间是否有关系，并不能
反映特征之间的交互强度。为了更好地表达不同特征节点之间交互的差异，本节利
用注意力机制来学习不同节点之间交互的权重。注意力计算如公式(3-2)所示：
e = Leakyrelu(aT[Wh Wh ]) (3-2)
ij i j
其中，Leakyrelu是激活函数，⊙是元素乘积操作，a∈Rd和W ∈Rd×d 为可训练参数，
e 表示节点v 对于节点v 的重要性。在获得不同邻居节点对中心节点的重要性后，
ij j i
通过softmax函数将重要性系数归一化处理。
25 3注意力感知的图匹配特征交互推荐算法
exp(e )
α = ij (3-3)
ij ∑ exp(e )
j∈N(i)∪i ij
其中，N(i)是节点v 的邻居节点集合，α 是聚合邻居节点时的注意力权重。
i ij
h' =∑ αWh (3-4)
i j∈N(i)∪i ij j
1
hin = ∑ αkWkh (3-5)
i k j∈N(i)∪i ij j
在获得目标节点对于邻居节点的注意力权重后，通过公式(3-4)计算邻居节点的
初始嵌入的加权和来更新目标节点，h'是经过内部特征交互后的节点表示。考虑到不
i
同视角下节点之间的重要性不同，公式(3-5)使用了多头注意力来计算多语义空间中
的复杂依赖关系。完成上述操作后，节点嵌入包含内部信息传递后的二阶交互特征，
表示为：Gin ={hin,hin,...,hin },Gin ={hin,hin,...,hin }。
UAG 1 2 UAG IAG 1 2 IAG
3.3.3.2基于图匹配的外部交互
AGMRec 通过对用户特征图和物品特征图之间的节点匹配进行外部交互。跨级
别的节点匹配更能反映节点之间交互的可能性，例如，男性用户更喜欢运动配件，那
么在外部交互的过程中，节点匹配的相似度应该更高并且彼此传递更多的消息。特征
节点的外部交互主要分为三个主要步骤：（1）计算每个节点的跨级别节点重要性；
（2）计算每个节点的跨级别特征图嵌入；（3）将一个特征图的节点嵌入与另一个特
征图的相关图级嵌入向量进行匹配，生成相似性特征向量。AGMRec 使用余弦相似
度函数来计算跨级节点的重要性，计算如公式(3-6)所示。
β =cos(hin,hin),m∈V ,n∈V (3-6)
mn m n UAG IAG
其中，β 表示G 中节点m与G 中节点n的相似性得分。
mn UAG IAG
接下来，从一个特征图节点的角度来学习另一个特征图的图嵌入。具体来说，对
于一个用户特征图节点m∈V ，相对应的注意力图嵌入向量z 通过对所有G 节
UAG m IAG
点嵌入加权得到。同样的，物品特征图节点n∈V 的注意力图嵌入z 也可以由此得
IAG n
到。计算过程如公式(3-7)和公式(3-8)所示。
z =∑ β hin,m∈V (3-7)
m n∈VIAG mn n UAG
z =∑ β hin,n∈V (3-8)
n m∈UAG mn m IAG
26 烟台大学硕士学位论文
受多头注意力机制的启发，引入了一个可学习的度量矩阵M ∈Rd'×d，从d'个角
度考虑一个节点和其对应的图级嵌入的相似性，从而得到外部交互匹配向量。具体计
算过程如公式(3-9)和公式(3-10)所示。
hout =[cos(hin M ,z M )],t∈{1,2,...,d'},m∈V (3-9)
m m t m t UAG
hout =[cos(hin M ,z M )],t∈{1,2,...,d'},n∈V (3-10)
n n t n t IAG
在上述用户和物品特征图的节点匹配过程后，特征图中的每个节点捕捉到与另
一个图节点的高阶特征交互。所有节点更新后外部交互嵌入表示为 ：
Gout ={hout,hout,...,hout },Gout ={hout,hout,...,hout }。
UAG 1 2 UAG IAG 1 2 IAG
3.3.4 节点和图表示生成模块
在分别学习了用户和物品不同方面的潜在表示后，将它们整合在一起，以获得多
方位的融合嵌入。一种策略是平等地将所有因素相加或平均，但现实问题中并不是所
有方面的因素对最终的嵌入都有相同的影响。因此，首先构建一个两层网络自适应地
学习三个方面的权重系数，其计算方法为：
exp(WT(WT ⋅hori))
γori = 2 1 (3-11)
∑ exp(WT(WT ⋅haspect)
aspect∈{ori,in,out} 2 1
hatt =∑ γaspecthaspect
(3-12)
aspect∈{ori,in,out}
其中，γori是节点初始嵌入的权重系数，W 是可训练参数。通过融合三个方面的特征，
*
得到融合后的嵌入表示为：Gatt ={hatt,hatt,...,hatt },Gatt ={hatt,hatt,...,hatt }。
UAG 1 2 UAG IAG 1 2 IAG
然后，使用加和池化将图内的融合节点表示聚合成特征图的表示。最终，特征图
向量的表示如公式(3-13)所示。
Gfin =∑ hatt,Gfin =∑ hatt
(3-13)
UAG i∈VUAG i IAG i∈VIAG i
3.3.5 预测和优化模块
在获得用户和物品的最终表示后，利用这两个表示的相似度衡量用户对物品的
偏好程度。相似度越高，用户就越喜欢这个物品。使用一个简单的内积运算来预测用
户对目标物品的偏好程度，其计算如公式(3-14)所示：
 y =σ(Gfin ⋅Gfin ) (3-14)
UAG IAG
27 3注意力感知的图匹配特征交互推荐算法
其中，σ是Sigmoid激活函数。
在训练阶段，使用Logloss 作为损失函数，定义如公式(3-15)所示：
1 N ( ( ) ( ))
=− ∑ y log  y +( 1− y ) log 1− y (3-15)
N n n n n
n=1
其中， y 和 y 分别为用户真实点击率和模型预估的点击率，n 为训练样本，N 为训
n n
练样本总数。
3.4 算法流程
AGMRec 模型基于训练集中的用户点击记录，学习率等超参数，输出训练完成
的模型。首先，构建训练集，为每个用户点击记录生成用户和物品特征图；然后，训
练模型，计算每个对图的点击概率和 Logloss，模型优化器选择 Adam；最终，直至
模型收敛或到达指定轮数时停止训练，获得已经完成训练的推荐系统模型。详细步骤
如表3.1所示。
时间复杂度分析：本章节设计的算法时间消耗主要来自四个方面：特征节点的嵌
入、节点内部交互过程、节点外部交互过程、节点表示注意力融合阶段。特征节点嵌
入的时间复杂度表现为O(Cd)，其中C为节点类别one-hot 向量的总体长度，d 为节
点嵌入维度大小。节点内部交互过程的时间复杂度表现为O(m2d)，其中m为特征域
的数量。节点外部交互过程的时间复杂度表现为O(md')，其中d'为可学习度量向量
的个数。节点表示注意力融合阶段的时间复杂度为O(m)。最终，总体时间复杂度为
O(Cd +m2d +md' +m)，可以简化为O(C+m(md +d'))。
表3.1 AGMRec模型的训练
算法 3.1 注意力感知的图匹配特征交互推荐(AGMRec)模型
输入：所有的训练集点击记录Dall ={X ,X ,...,X }，学习率l，批次大小batchsize
1 2 N
输出：训练完成得到AGMRec模型
01：//构造训练集
02：开始构造训练集前，初始训练集D为空
03：for i in [1,N]:{
04： //每条用户-物品点击记录的表示
28 烟台大学硕士学位论文
05： X ={(CU,CI)}，其中CU ={f , f ,..., f }(f ∈AU)，CI ={f , f ,..., f }(f ∈AI)
i i i i 1 2 p p i 1 2 q q
06： //构建用户和物品特征图
07： G =(V ,E )，G =(V ,E )
UAG UAG UAG IAG IAG IAG
08： V =CU ={f , f ,..., f }，V =CI ={f , f ,..., f }
UAG i 1 2 p IAG i 1 2 q
09： E ={(f , f |i∈[1,p]), j∈[1,p],i≠ j} E ={(f , f |i∈[1,q]), j∈[1,q],i≠ j}
UAG i j IAG i j
10： 构建训练集实例(y,G ,G )，存入D
i UAG IAG
11：}
12：//训练模型
13：for i in [1,Epoch]:{
14： for j in [1,N/batchsize]:{
15: 从训练集D中随机取出batchsize个样本构建训练实例D
batch
16： 计算D 的Logloss
batch
17： 利用反向传播更新模型参数}
18：}
在测试阶段，构造的测试集将输入到已训练好的模型中，即可得到预估的点击
率。
3.5 实验结果与分析
本节通过与多个基线模型进行对比，来验证所提出的 AGMRec 模型的有效性。
实验所用硬件的CPU是I5-10400F、24G 内存、GeForce RTX 3060(12G)显卡，运行
在 Windows10 操作系统上。以下将详细介绍实验使用的数据集、模型评价指标、基
线方法和实验结果。
3.5.1 实验数据集
实验基于Book-crossing 数据集[57]和MovieLens 1M 数据集[58]，对AGMRec模型
进行评估。实验数据集中，训练集、验证集、测试集的比例划分为6：2：2。数据集
的描述如表3.2所示。
29 3注意力感知的图匹配特征交互推荐算法
表3.2 数据集描述
数据集 用户数 项目数 用户属性数 项目属性数 样本个数
Book-crossing 4873 53168 87 43157 1050834
MovieLens1M 5950 3533 30 11587 1149238
（1）Book-crossing 数据集。Book-crossing 数据集包含 4873 名用户对 53168 本
图书的评分，每个用户和图书都有若干个相关的属性信息。为了适应数据的稀疏性和
保证数据的质量，实验中将所有用户对图书的明确评分视为正例样本，并只保留拥有
超过20个正例的用户，为每个用户随机选取与正例样本数量相同的负例样本。
（2）MovieLens 1M 数据集。MovieLens 1M 数据集包含用户对电影的评分，每
个数据样本都包含一个用户和一部电影的相关属性信息。实验中将大于 3 的评分视
为正例，保留超过10个正例的用户，为每个正例随机采样一个负例样本。
3.5.2 评估指标
对于点击率预测算法，通常使用AUC（Area Under ROC Curve）和Logloss（Log-
likelihood Loss）两种评估指标。
（1）AUC表示ROC曲线和坐标之间围成的面积，是二元分类任务的常用指标。
其范围介于[0.5, 1]之间。AUC 值越接近 1，表示模型的分类能力越好；若小于或等
于0.5时，代表模型不具有分类能力。AUC 指标的形式化表达如公式(3-16)所示。
∑ ∑ pred(x+)> pred(x−)
i j
AUC= i j (3-16)
N ×N
pos neg
其中，x+和x−分别代表正样本和负样本，N 和N 分别代表正样本和负样本的数
i j pos neg
量。AUC 表示在随机抽取的一对正负样本中，模型对正例样本的预测值高于对负例
样本的预测值的概率。这个概率值越大，证明模型的分类效果越好。
（2）Logloss 表示模型预测值和真实值之间的距离，其值越小代表模型的性能越
好。损失函数的计算由公式(3-15)求得，作为反映样本平均偏差的一个直接度量。
3.5.3 基线方法
实验中，将AGMRec 模型与以下几种基线方法的推荐结果进行了对比：
30 烟台大学硕士学位论文
（1）LR[12]：一种线性组合原始特征的机器学习方法，但无法捕捉特征之间的二
阶交互信息。
（2）FM[14]：在LR 的基础上，通过对两两特征交互进行建模，具有捕捉二阶交
互的功能。
（3）AFM[18]：在FM的基础上，运用注意力机制区分二阶交互的重要性。
（4）NFM[26]：使用特征交互池化的方式代替拼接操作，并将深度学习网络与二
阶特征交互相结合，把特征交互的阶数扩展到了高阶。
（5）DeepFM[29]：将神经网络与 FM 相结合，模型可以同时捕捉高阶交互特征
和二阶交互特征。
（6）InterHAt[35]：在特征阶数上使用层次注意力机制，高阶特征基于低阶特征
生成，精确量化任意阶数的特征交互影响。
（7）Fi-GNN[37]: 首个通过图神经网络建模特征交互的模型，将每个样本构成一
个特征图，每个节点为一个特征域，利用边建模特征之间的交互过程。
（8）GMCF[41]：将用户和物品特征分别建模为两个特征图，通过节点匹配进行
特征交互，进而学习用户和物品的向量表示。该模型是提出 AGMRec 模型的基础。
3.5.4 实验设置
本章实验均是通过Pytorch框架实现，使用Adam 优化器进行求解。为了公平起
见，实验中所有模型都是以 1024 批尺寸的方式进行学习，特征嵌入向量维数为 64，
隐藏层单元数量为256，学习率为1.e-3，L2 正则化权重为5.e-5。
3.5.5 实验结果
实验结果如表3.3所示。
31 3注意力感知的图匹配特征交互推荐算法
表3.3 AGMRec和基线模型的实验结果
Book-crossing MovieLens1M
模型类型 模型
AUC Logloss AUC Logloss
传统
LR 0.7226 0.6096 0.8704 0.4507
FM 0.7981 0.5449 0.8829 0.4317
基于FM
AFM 0.7838 0.5604 0.8747 0.4404
NFM 0.8055 0.5426 0.9051 0.3896
基于DNN DeepFM 0.8114 0.5310 0.9044 0.3919
InterHAt 0.8187 0.5211 0.9086 0.3836
Fi-GNN 0.8217 0.5246 0.9070 0.3902
基于GNN GMCF 0.8278 0.5107 0.9083 0.3836
AGMRec 0.8395 0.4981 0.9148 0.3728
基于表3.3可以得到以下结论：
AGMRec 模型在 Book-crossing 数据集和 MovieLens1M 数据集上实验的评价指
标都优于其它基线模型。针对Book-crossing 数据集的实验结果中，AGMRec模型结
果的 AUC 较次优模型提高了 1.41%，Logloss 较次优模型提高了 2.5%；针对
MovieLens1M 数据集的实验结果中，AGMRec 模型结果的 AUC 较次优模型提高了
0.72%，Logloss 较之前次优模型提高了2.82%。总体来说，AGMRec 模型相较于对比
模型具有更高的性能。实验结果还显示，LR 模型的实验结果最差，说明 LR 用于单
独建模特征重要性无法高效地完成点击率预测任务。FM 和 AFM 性能优于 LR，模
型的成功得益于捕捉了二阶交互特征。深度特征交互模型的总体性能优于传统和二
阶特征交互模型，推测其原因是神经网络的出现可以更好地挖掘特征之间的隐式高
阶交互。基于GNN的特征交互模型以一种新的方式解释了特征交互过程，将属性特
征建模为图结构来建模复杂的交互，提高了模型的性能。
3.5.6 参数对比分析
为了进一步研究超参数对AGMRec模型的影响，基于控制变量的方法对两个主
要超参数进行实验研究。
（1）节点嵌入维度对推荐结果的影响。一般来说，模型的嵌入维度越高，模型
的表示能力就越强。然而，嵌入维度过多不仅会导致推荐成本过高，而且也可能导致
模型的过拟合。Book-crossing 和 MovieLens1M 数据集上的节点嵌入结果如图 3.2 所
示。
32 烟台大学硕士学位论文
(a) Book-crossing数据集中的影响 (b) MovieLens1M数据集中的影响
图3.2 不同嵌入维度对AUC和Logloss的影响
从图3.2可以看出，在Book-crossing数据集和MovieLens1M 数据集上，AUC 指
标随着节点嵌入维度的增加首先上升，当维度为 64 时达到峰值然后开始下降；
Logloss 指标随着节点嵌入维度的增加首先下降，当维度为 64 时达到最优随后开始
上升。实验结果说明，64 的节点嵌入维度能够代表足够多的信息，从而获得良好的
推荐效果。
（2）注意力头数对AUC 和Logloss 的影响。多头注意机制可以捕捉到不同语义
空间的节点之间的关系，并在不同层次上聚合有益的交互特征。增加注意力头数往往
能提高模型的性能，但是过多的注意力头数可能导致过拟合。基于 AGMRec 模型，
针对不同的注意力头数开展了实验研究。当注意力头数设置为 1 时，表示多头注意
力机制被有效地去除。注意力头数对AUC和Logloss影响的实验结果如图3.3所示。
(a) Book-crossing数据集中的影响 (b) MovieLens1M数据集中的影响
图3.3 不同注意力头数对AUC和Logloss的影响
从图 3.3 可以看出，MovieLens1M 数据集使用两个注意力头数时表现最好，而
Book-crossing 数据集是三个注意力头数的结果最优。
33 3注意力感知的图匹配特征交互推荐算法
3.5.7 消融实验
AGMRec 模型主要用了三个方面的注意力来捕捉特征之间的交互，基于此，创
建了三个变体模型来进行消融实验。三个变体模型分别为：
AGMRec_in：除去内部注意力节点消息传递的AGMRec；
AGMRec_out：除去外部注意力节点匹配的AGMRec；
AGMRec_att：除去注意力融合节点表示的AGMRec。
表3.4为AGMRec模型与三个变体模型的性能比较结果。
表3.4 AGMRec与三个变体的性能比较
数据集 Book-crossing MovieLens1M
模型 AUC Logloss AUC Logloss
AGMRec_in 0.8317 0.5063 0.9110 0.3772
AGMRec_out 0.8369 0.5061 0.9127 0.3753
AGMRec_att 0.8313 0.5137 0.9099 0.3795
AGMRec 0.8395 0.4981 0.9148 0.3728
从表 3.4 中可以看出，去除任何一个模块后，AGMRec 模型的性能都会下降。
AGMRec_in与AGMRec相比，虽然利用简单的元素乘积可以捕捉特征节点之间的交
互特征，但是特征之间的相互作用并不具有同等的重要性；在传递信息的过程中考虑
边的权重可以避免噪声对目标节点的影响，能够获得更好的效果。AGMRec_out 与
AGMRec 相比，引入的跨级注意力图匹配方法从一个全新角度建模特征交互过程，
可以对有益的高阶特征交互进行有针对性地建模，提高模型的准确性。本章的目标是
通过不同级别的节点特征生成最终的节点表示， 进而完成推荐预测。通过
AGMRec_att 与 AGMRec 实验结果对比，可以发现一阶、二阶和高阶的特征节点嵌
入表示的直接相加或拼接，并没有考虑到每个方面的特征对最终节点表征的重要性。
通过注意力融合机制学习不同方面的重要性权重可以得到更为准确的节点表示，并
提高算法的预测性能。
3.6 本章小结
本章分析了目前特征交互算法所存在的问题，将传统点到点的建模范式扩展到
了图到图，提出了一种基于注意力感知的图匹配特征交互推荐算法。首先，特征图构
建模块将用户和物品属性信息，建模为用户特征图和物品特征图；其次，运用节点匹
34 烟台大学硕士学位论文
配图神经网络模块内部和外部两个级别的融合过程，获得交互过后的节点表示；接下
来，通过注意力机制进行三方面的节点特征融合；最后，预测模块通过用户和物品最
终向量预估点击率。实验结果表明AGMRec 模型是有效的，在两个公开数据集上推
荐效果优于基线模型。未来工作中，考虑加入更多的辅助信息（物品图片和评论）进
行多模态个性化推荐，以及使用不同的特征融合机制来更为精准地预估点击率结果。
35 3注意力感知的图匹配特征交互推荐算法
36 烟台大学硕士学位论文
4 分层双级别图融合特征交互推荐算法
4.1 引言
个性化推荐系统由于可以解决在线信息过载问题，已经大量应用在了广告、社交
网络和电子商务等领域之中。其核心思想是根据用户的历史购买或点击记录来预估
用户对项目的偏好。它能够有效利用众多的用户画像、项目属性和上下文信息进行特
征交互，特征交互建模已经成为推荐系统的一个重要范式。
大数据中越来越多的属性信息可以被利用作为决策信息。不仅是第三章提到的
用户和物品属性信息，上下文信息对于推荐系统来说也是极为重要。如何建模上下文
信息、用户、物品属性信息的交互成为现阶段研究的重心。同时，现存模型也存在着
两方面主要问题。一方面，并不是所有的特征组合都会产生积极的交互增益，一些不
必要的特征交互在训练过程中往往带来噪音，影响最终的预测结果；另一方面，现存
模型大多是不可解释和隐式建模交互的。
基于上述的问题，本章延伸了第三章的AGMRec模型，提出了分层双级别图融
合特征交互推荐模型HDGFI（Hierarchical Dual-level Graph Feature Interaction）。该
模型将推荐中点击率预估问题转化为图结构的学习问题，在不同交互层中自适应地
选择节点连接，并基于每层的图表示向量显式地生成最终的预估结果。具体来说，每
个特征域视为特征图中的节点，并通过边来建模特征之间的交互。本章设计了一个全
新的交互层，从局部和全局的角度来形成有意义的高阶特征表示。在每个交互层中，
每个特征节点可以通过显式选择最相关的邻居节点进行交互，同时利用压缩激励网
络进行动态的特征重要性选择。最终，通过堆叠一定数目的交互层，形成高阶的特征
交互表示。
4.2 问题描述
4.2.1 相关概念与表示
定义4-1用户、物品集合和点击记录。数据集中包含M 个用户和N个物品。用
37 4分层双级别图融合特征交互推荐算法
户集合表示为U ={u ,u ,...,u }，物品集合表示为V ={v ,v ,...,v }。用户-物品点击记
1 2 M 1 2 N
录可以表示为Y ，其中 y =1表示用户u和物品v产生过点击记录，否则 y =0。
M×N uv uv
定义4-2属性特征域。数据集中包含J 个用户特征域，K个物品特征域，F个上
下文特征域，分别表示为A={A1,A2,...,AJ}，B={B1,B2,...,BK}，C ={C1,C2,...,CF}。
每个用户和物品都与一个属性列表相关联，表示为A ∈A，B ∈B。用户对物品进行
u v
点击时还关联着一个上下文信息列表，表示为C ∈C。
uv
4.2.2 问题定义
根据4.2.1节给出的定义，可将一个点击记录表示为x=[u,v,A ,B ,C ]，其中u
u v uv
和 v 代表用户和物品的 ID，A 和B 代表当前用户和物品的属性列表，C 为当前用
u v uv
户点击物品时的上下文信息列表。推荐任务是设计一个预测模型，给定一个输入样本
x，输出目标用户对候选物品的点击预测概率 y。
4.3 模型介绍
4.3.1 模型概览
本研究提出了一个分层双级别图融合特征交互推荐模型 HDGFI，模型结构如图
4.1所示。
图4.1 HDGFI模型结构图
HDGFI模型的创新主要分为两点：
38 烟台大学硕士学位论文
（1）将推荐系统中的特征交互问题转换为了图分类问题，把特征域建模为节点，
特征之间的交互建模为图结构中的边。同时，模型显式表达特征之间的交互情况，通
过堆叠GNN层捕捉高阶的特征交互，实现了特征交互的可解释性。
（2）通过两个级别过滤和筛选识别出交互增益强的特征交互和全局重要特征。
从局部和全局两个角度动态捕捉特征和特征交互的重要性，并使用一个融合模块合
并两个方面的节点表示，更细粒度地捕捉特征之间的重要性。
以下将逐层介绍HDGFI模型的实现细节。
4.3.2 特征图构建模块
4.3.2.1特征图节点嵌入
在特征交互推荐任务中，输入的原始特征是多字段的稀疏特征。例如，在电影推
荐中有若干特征域，比如{语言：英语，导演：克里斯托弗·诺兰，电影类型：动作
电影、科幻电影…}。这些多域特征不能直接输入到基于 DNN 的模型中。传统的方
法是将特征字段编码为二进制向量，表示为：
x=[x ,x ,...,x ]=[1,0,...0,...,1,...,1,0] (4-1)
1 2 m  
field1 fieldm
其中，x是一个含有m个特征域的输入实例，x 是第m个特征域的二进制编码表示，
m
是特征域的个数。由于特征的总数很大，使得二进制编码向量高维且稀疏，这导
m
致计算效率不高。通过特征嵌入层，可以将二进制编码向量转换为密集的低维向量。
利用公式(4-2)实现这种转换。
e =Wembx (4-2)
i i i
其中，Wemb是仅含一个值的特征域的嵌入矩阵，x 是一个one-hot 向量。对于电影类
i i
型等多值型特征域，进一步扩展公式(4-2)为公式(4-3)，使用相应特征嵌入向量的平均
值来表示多值特征字段。
1
e = Wembx (4-3)
j j j
q
其中，Wemb是多值特征域 j的嵌入矩阵，q是域内特征的数量，x 是mulit-hot 向量。
j j
39 4分层双级别图融合特征交互推荐算法
从而得到输入实例中所有特征域的嵌入向量。
E =[e ,e ,...,e ] (4-4)
1 2 m
其中，e ∈Rd是第m个特征域的嵌入表示，d是嵌入层的维度。将特征域的嵌入视
m
为特征图中节点的表示，同时，这其中还包含着关于特征的一阶交互信息。
4.3.2.2分层邻接矩阵选择层
当前主要通过将特征转换为节点以及特征之间的交互转换为边的方法，来构建
一个完全连通的特征图。然而，并不是所有的交互都有助于提升最终的预测效果，有
些交互则会引发交互噪声。为了捕获具有强交互增益的交互对，并避免不必要的特征
交互产生的噪声，本研究设计了学习每个交互层的图结构来预测特征节点之间连接
的策略。传统的邻接矩阵是离散的，只会出现连接或者不连接两种情况，这使得梯度
难以反向传播。为了解决这个问题，本设计基于Sparse Transformer 的思想为每个层
生成 Top-k 有益邻接矩阵 Al，其中Al 表示节点i和节点 j在l层的连接概率。基于
ij
Top-k选择规则，在分层边缘选择的架构中，只有贡献较大的元素被赋予概率。分层
边选择框架如图4.2所示。
图4.2 分层边选择框架图
首先，通过两层全连接网络将节点对之间的相似性表示成一个注意力分数矩阵
P。
Pl =σ (Wsσ(Ws(el el)+b)+b ) (4-5)
ij 2 2 1 1 i j 1 2
40 烟台大学硕士学位论文
其中Ws和bs是可训练参数，是元素乘积操作，σ和σ 分别是Leakyrelu和Sigmoid
* * 1 2
激活函数。
接下来，通过掩盖操作M (⋅,⋅)对注意力得分矩阵进行 Top-k 选择。通过这种方
法，最重要的k个特征交互被保留下来，而其它相对不重要的信息被舍弃。通过公式
(4-6)可以求解层次结构的有益邻接矩阵。
Pl Pl ≥t
Al =M(Pl,k) = ij ij i (4-6)
ij ij 0 Pl <t
ij i
其中，t 是注意力得分矩阵P中第i行中第t大的值，k是控制每层邻居采样数量的
i
超参数。模型保留得分矩阵中前k大的值，将其余值设为0，也就意味着当前层中
不考虑这两个特征之间的交互作用。
4.3.3 双级别节点和图表示生成模块
在完成特征图构建的基础上，进一步实现节点间的特征交互。双级节点表征生
成的架构如图4.3所示。
(a)局部级别的注意力节点消息传递和聚合 (b)全局级别的压缩激励
图4.3 双级节点表征生成的架构
4.3.3.1局部级别消息传递和聚合
两个有益特征节点之间的交互由一条边来表示，通过一个图注意力网络逐层捕
捉特征之间的高阶交互，实现它们之间的消息传递，其过程如图4.3(a)所示。与传统
的全连接网络有所不同，局部级别的注意力节点消息传递过程中，只有当前层目标节
点的采样邻居才会进行消息传递。注意力系数由公式(4-7)求解。
41 4分层双级别图融合特征交互推荐算法
( ( ))
c(l) = Leakyrelu aT el el (4-7)
ij i j
其中，c(l)表示在l层节点 j对节点i的重要程度，Leakyrelu是激活函数，a∈Rd是一
ij
个权重向量。在获得不同邻居节点对中心节点的重要性后，通过 softmax函数将重要
性系数归一化处理。归一化处理基于公式(4-8)实现。
exp(cl)
α = ij (4-8)
ij ∑ exp(cl)
j∈Nei{i} ij
其中，Nei( i)表示节点i的有益交互邻居集合，α 是目标节点i聚合邻居节点 j时的
ij
注意力权重。在获得中心节点对邻近节点的关注权重后，使用多头注意力融合机制来
更新目标节点的表示。计算方法如公式(4-9)所示。
hl = U ||σ( ∑ AlαuWu( el el )) (4-9)
loci u=1 j∈N i ij ij i j
其中，||表示向量拼接操作，u是注意力头数，αu是第u个注意力头上的注意力得分，
ij
W* 是线性变换矩阵。经过上述操作，可以得到节点的局部级别的表示：
Hl =hl ,hl ,...,hl 。
loc  loc loc loc 
1 2 m
4.3.3.2全局级别压缩激励
局部级别的节点表示学习模块主要关注节点对之间的相互作用，但没有关注到
节点在全图中的重要性。不同特征对目标任务有着不同的重要性，例如，在电影推荐
中，性别、年龄和电影体裁往往比用户的职业和地区更重要。本节希望能动态地增加
重要特征的权重，同时减少不必要特征的权重。压缩激励网络在图像分类任务中取得
了巨大的成功，它可以捕捉通道之间的相互依赖关系，以提高网络的表示能力。为了
保留先前学习的组合特征并动态捕捉特征之间的相对重要性，本节在全局层面设计
了一个用于残差连接的压缩激励模块，如图4.3(b)所示。
第一步为压缩（Squeeze）操作。运用池化方法将各个节点特征[el,el,...,el ]压缩
1 2 m
为一个统计向量S =[s ,s ,...,s ]，池化可以选择最大化、平均和加和等操作。本文选
1 2 m
择了全局平均池化，具体计算如公式(4-10)所示。
42 烟台大学硕士学位论文
1 d′
s = ∑el (4-10)
i d′ i
t=1
其中s 表示第i个特征的全局信息表示。
i
第二步为激励（Excitation）操作。这一步使用了两个全连接层来计算统计向量每
一维度的权重，通过一个缩减率超参数来先压缩维度再扩张维度。具体的计算如公式
(4-11)所示。
( ( ))
att =σ Wgσ WgS (4-11)
glo 3 2 3 1
m m
m× ×m
其中，att 是全局级别的注意力权重，Wg ∈ r ，Wg ∈r 为训练参数，σ 是Tanh
glo 1 2 3
激活函数。
第三步为重加权（Re-weight）。将原始的特征表示[el,el,...,el ]和相应权重att
1 2 m glo
相乘得到新的节点向量Hl ，计算公式如公式(4-12)所示。
glo
Hl =att El =[att ⋅el,att ⋅el,...,att ⋅el ] (4-12)
glo glo glo 1 glo 2 glo m
1 2 m
4.3.3.3双级别节点嵌入融合
一旦获得了局部和全局级别的节点表征，便可使用双线性交叉聚合函数来更新
节点的表示，如公式(4-13)所示。
el =Wl[h ⊕h ,h h ] (4-13)
i ϕ loc glo loc glo
i i i i
其中，⊕和分别代表元素加和和元素乘积操作，Wl是可训练参数。元素相乘的操
ϕ
作可以从相似的特征中传递更多的信息，而相加的操作可以突出具有较大加和值的
特征。
4.3.3.4特征图表示生成
经过上述操作后，节点的表示方法已经得到了更新。换句话说，每个特征节点都
是邻域感知的。进一步，我们设计了一个图表示读出操作，动态地捕捉交互后每一层
的特征图嵌入。该读出操作由所有时间步骤共享，对特征图中所有节点的向量进行平
均池化来得到全局图的向量，计算公式如下。
43 4分层双级别图融合特征交互推荐算法
1 m
ml = ∑el (4-14)
G m i
i=1
然后，将当前层的全局表示向量ml 和上一层读出的特征图向量hl−1共同输入到
G G
GRU中，来更新获得当前层特征图向量hl 。
G
hl =GRU(ml ,hl−1) (4-15)
G G G
初始的特征图向量h0是初始节点嵌入的加和，通过读出操作，图的特征在每个
G
时间步骤中被更新。
4.3.4 预测和训练模块
在双级别节点和图表示生成模块之后，可以得到最后一层的特征图向量。本节采
用以θ为参数的全连接层和Sigmoid激活函数来获得最终的预测，具体如下。
 y =Sigmoid( θT ⋅hL) (4-16)
G
模型使用Logloss 作为损失函数，具体计算如式(4-17)所示。
1 N ( ( ) ( ))
=− ∑ y log  y +( 1− y ) log 1− y (4-17)
N i i i i
i=1
其中，N 是训练样本的数量， y 和 y 分别为索引为i的样本的真实标签和预测标签。
i i
模型的最优参数通过Adam 最小化损失函数求解。
4.4 算法流程
基于上述对 HDGFI 模型的描述，接下来介绍 HDGFI 模型的训练过程。该训练
输入所有训练集中的用户点击记录、学习率等超参数，输出训练完成的HDGFI模型。
首先，为训练数据中每个点击实例构建一个特征图，此特征图中只有特征节点集合，
没有边集合，边的连接情况在训练阶段学习；然后，分层计算特征图的邻接矩阵并进
行局部和全局的特征节点的交互，得到点击预测概率；最后，计算出模型整体损失
Logloss 值，使用 Adam 优化器进行参数更新，直至模型收敛或到达指定轮数时停止
训练。训练详细步骤如表4.1所示。在测试阶段，构造的测试集将输入到已训练好的
44 烟台大学硕士学位论文
模型中，即可得到预估的点击率。
时间复杂度分析：本章节设计的算法时间消耗主要来自四个方面：特征节点的嵌
入、分层邻接矩阵构造、两个级别的节点表示融合、图表示生成。特征节点嵌入的时
间复杂度表现为O(Cd)，其中C为节点类别one-hot 向量的总体长度，d 为节点嵌入
维度大小。分层邻接矩阵构造的时间复杂度表现为O(L(m2d))，其中L为图神经网络
迭代次数， m 为特征域的数量。两个级别的节点表示融合时间复杂度表现为
O(Lm(md +m3 /r))，其中L为迭代层数，r为全局衰减比例。图表示生成的时间复杂
度为O(L(md2))。最终，总体时间复杂度为O(Cd +L(m2d)+Lm(md +m3 /r)+L(md2)))，
可以简化为O(C+m2(d +m2 /r))。
表4.1 HDGFI模型的训练
算法 4.1 分层双级别图融合特征交互推荐(HDGFI)模型
输入：数据集中所有点击实例Dall ={X ,X ,...,X }，学习率l，批次大小batchsize
1 2 N
输出：训练完成的HDGFI模型
01：//构造训练集
02：开始构造训练集前，初始训练集D为空
03：for i in [1,N]:{
04： //每条点击实例的符号化表示
05： x =[u,v,A ,B ,C ]，其中A ∈A,B ∈B,C ∈C
i u v uv u v uv
06： //构建特征图
07： G =(V,E )
i i i
08： V ={u,v,A ,B ,C }
i u v uv
09： E =∅//在训练中学习
i
10： 构建训练集实例(y,G)，存入D
i i
11：}
12：//训练模型
13：for i in [1,Epoch]:{
14： for j in [1,N/batchsize]:{
45 4分层双级别图融合特征交互推荐算法
15: 从训练集D中随机取出batchsize个样本构建训练实例D
batch
16： 计算D 的Logloss
batch
17： 利用反向传播更新模型参数}
18：}
4.5 实验结果与分析
本节通过与多个基线模型进行对比，来验证提出的个性化推荐模型HDGFI的有
效性和合理性。HDGFI模型实现由python语言编写，实验使用硬性条件是：CPU型
号是I5-12400F、32G 内存，GeForce RTX 3060(12G)显卡，运行在 Ubuntu 20.04操作
系统上。下面将详细介绍实验使用的数据集、模型评价指标、基线方法和实验结果等。
4.5.1 实验数据集
实验选择了KKBox[59]、Frappe[60]、MovieLens 1M[58]三个公开数据集。实验过程
中，三个数据集中，训练集、验证集、测试集的划分比例为 6：2：2。三个数据集的
详细信息如表4.2所示。
表4.2 数据集描述
数据集 特征域个数 特征总数 样本个数
KKBox 13 92247 7377418
Frappe 10 5382 288609
MovieLens 1M 10 22100 1149238
（1）KKBox 数据集。KKBox 数据集是一款专业的数字音乐信息服务软件，每
个用户可以在短时间内找到他们喜欢的音乐。数据集包含 13 个特征域信息，例如，
各歌曲的ID、词曲作者姓名、用户的年龄等。
（2）Frappe数据集。Frappe数据集是一个上下文感知应用程序发现工具。Frappe
数据集中每个记录包含用户的ID和APP 的ID，以及天气、城市等8个上下文信息。
（3）MovieLens 1M 数据集。MovieLens 1M 数据集包含用户对电影的评分，每
个数据样本都包含一个用户和一部电影的相关属性信息。实验中将大于 3 的评分视
为正例，保留超过10个正例的用户，为每个正例随机采样一个负例样本。
46 烟台大学硕士学位论文
4.5.2 评估指标
对于点击率预测算法，通常使用AUC（Area Under ROC Curve）和Logloss（Log-
likelihood Loss）两种推荐指标。
（1）AUC 表示ROC 曲线和坐标之间围成的面积，是二元分类任务的常用指标。
其范围介于[0.5, 1]之间，AUC 值越接近1代表模型的分类能力越好，若小于或等于
0.5时代表模型不具有分类能力。具体公式如下所示。
∑ ∑ pred(x+)> pred(x−)
i j
AUC= i j (4-18)
N ×N
pos neg
公式(4-18)是 AUC 指标的形式化表达，其中x+和x−分别代表正样本和负样本，
i j
N 和N 分别代表正样本和负样本的数量。AUC 表示在随机抽取的一对正负样本
pos neg
中，模型对正例样本的预测值高于对负例样本的预测值的概率。这个概率值越大，说
明模型的分类效果越好。
（2）Logloss 表示预测分数与真实标签之间的距离，其值越小代表模型的性能越
好。Logloss 的计算公式和上节预测模块的损失函数相同，在本实验中作为反映样本
平均偏差的一个直接度量。
4.5.3 基线方法
本研究将HDGFI模型的推荐结果与LR[12]、FM[14]、FFM[15]、FmFM[17]、NFM[26]、
FiBiNet[31]、GraphFM[40]等主要基线方法的结果进行比较。其中，FFM 是在FM 的基
础上增加了特征域的概念；FmFM 在 FM 基础上为每对特征增加一个权重值；FiBiNet
使用压缩激励机制动态学习特征重要性；GraphFM使用图神经网络克服FM的缺陷，
并从有益交互学习的角度建模特征交互。其余基线模型见前文3.5.3节的介绍。
4.5.4 实验设置
本实验均是基于Pytorch框架实现，使用Adam优化器进行求解。为了公平起见，
所有模型都是以1024批尺寸的方式进行学习，特征嵌入向量维数为 16，隐藏层单元
47 4分层双级别图融合特征交互推荐算法
数量为 32，L2 正则化权重为 1.e-4。在 KKBox 和 MovieLens 1M 中，学习率为 1.e-
3，在Frappe数据集中，学习率为5.e-3。对于AutoInt，Fi-GNN，GraphFM 模型，迭
代层数都设置为三层。
4.5.5 实验结果
表4.3 HDGFI和基线模型的性能比较
KKBox Frappe MovieLens 1M
模型类型 模型
AUC Logloss AUC Logloss AUC Logloss
传统 LR 0.76647 0.57593 0.93565 0.28721 0.86949 0.43775
FM 0.78961 0.55487 0.96571 0.20912 0.89104 0.42229
AFM 0.79868 0.54858 0.96534 0.21947 0.88224 0.42861
基于FM
FFM 0.79758 0.54323 0.96871 0.19901 0.89563 0.40881
FmFM 0.80591 0.53465 0.96564 0.21608 0.90181 0.39455
NFM 0.80979 0.53088 0.97283 0.20717 0.89975 0.40351
基于 DeepFM 0.81439 0.52556 0.97551 0.18532 0.90617 0.38856
DNN FiBiNet 0.81783 0.52207 0.97554 0.18061 0.90628 0.39021
InterHAt 0.81478 0.52477 0.97447 0.19099 0.90616 0.38707
Fi-GNN 0.81831 0.52033 0.97541 0.18431 0.90668 0.38755
基于
GraphFM 0.82013 0.51872 0.9764 0.17824 0.90782 0.38378
GNN
HDGFI 0.82278 0.51555 0.97894 0.16495 0.91113 0.37871
各模型在三个公开数据集上实验评价指标如表4.3所示。从表中可以看出，所提
出的 HDGFI 模型实验结果的评价指标均优于对比的基线方法。HDGFI 模型的 AUC
指标较次优模型 GraphFM 模型在 KKBox、Frappe、MovieLens 1M 数据集上分别提
升了3.23‰、2.6‰和3.64‰，并且在Logloss 指标上也优于其它的基线模型。总体来
看，基于 DNN 和基于 GNN 为代表的高阶交互模型效果要优于仅关注一阶、二阶组
合特征的模型，特征之间复杂的高阶组合可以为最终的预测带来超越本身信息的交
互增益；基于 GNN 的特征交互模型整体效果要好于基于 DNN 的模型。证明基于
DNN进行特征交互的模型是以一种隐式的方式学习特征交互，而图结构可以以一种
显式的方式建模特征交互过程，具有良好的可解释性。与同为基于 GNN 的模型 Fi-
GNN相比，HDGFI没有将特征图建模为一个完全连通图，而是运用了分层邻接矩阵
学习策略，显式地保留 Top-K 个重要特征交互。这样可以减少不必要的特征交互所
带来的噪声，从而更集中地关注重要交互。与GraphFM 模型相比，HDGFI从局部和
48 烟台大学硕士学位论文
全局两个角度来考虑特征的重要性，实验结果证明HDGFI的推荐效果优于GraphFM。
4.5.6 参数对比分析
为了进一步研究超参数对HDGFI模型的影响，使用控制变量方法对两个主要超
参数进行实验。
（1）各层的邻居采样个数超参数实验。HDGFI模型将第一层的采样个数固定为
特征域的个数，这意味着在第一层建立了一个全连通特征图。各个特征出现在一个输
入实例中，通过全连通方式，模型尽可能地捕捉每个节点对之间的交互关系。在第二
层和第三层选择了不同的邻居采样个数。采样个数超参数结果如图 4.4 所示。其中，
k
和
k
分别表示第二层和第三层目标特征节点邻居采样的个数。
2 3
(a) KKBox数据集邻居采样个数的影响 (b) Frappe数据集邻居采样个数影响
(c) MovieLens 1M邻居采样个数影响
图4.4 邻居采样个数对AUC的影响
49 4分层双级别图融合特征交互推荐算法
图4.4（a）显示的是在 KKBox数据集上第二层和第三层不同的邻居采样个数对
AUC 的影响。可以看出在k =10，k =6时性能达到最优值；当第二层和第三层都选
2 3
择数量为 1 的邻居节点时效果最差。图 4.4（b）显示的是 Frappe 数据集上的结果，
可以看出当k =6，k =2时效果达到峰值。图4.4（c）显示的是MovieLens 1M 数据
2 3
集上的结果，可以看出在k =8，k =4时获得最好的性能。总体来说，k 大于k 时效
2 3 2 3
果要好于k 小于k ，意味着需要逐层减少邻居采样的个数，才能更好地捕捉特征之
2 3
间的有益交互。
（2）全局衰减比率超参实验。针对不同全局衰减比率对模型性能影响，开展了
实验研究，结果如图4.5所示。
(a) KKBox数据集中的影响 (b) Frappe数据集中的影响
(c) MovieLens 1M数据集中的影响
图4.5 不同全局衰减比例对AUC和Logloss的影响
从图4.5中可以看出，在KKBox数据集和Frappe数据集中，最佳的衰减比例为
50 烟台大学硕士学位论文
3，MovieLens 1M 数据集在衰减比例分别取2 和3时，上Logloss 和 AUC 得到了最
佳结果。考虑到三个数据集的特征域数量差别不大，推断原始特征域的数量压缩30%-
40%达到激励的最优效果。
4.5.7 消融实验
为了更好地对HDGFI 模型进行性能评估，进一步开展消融实验研究。HDGFI模
型主要有两大改进：（1）使用了局部级别的注意力消息传递来捕捉成对的有益特征
节点之间的交互；（2）使用了全局级别的压缩激励模块来保留先前层学到的特征组
合信息。
首先，构建两个变体模型 HDGFI_L 和 HDGFI_G，开展局部特征交互和全局级
别动态重要性选择的消融实验。所构建的两个变体模型为：
HDGFI_L：去除局部特征交互的HDGFI模型，使用DNN来捕捉高阶特征交互；
HDGFI_G：去除全局级别动态重要性选择的HDGFI模型。
消融实验的结果如表4.4所示。
表4.4 HDGFI与HDGFI_L和HDGFI_G变体的性能比较
数据集 KKBox Frappe MovieLens 1M
变体方法
AUC Logloss AUC Logloss AUC Logloss
HDGFI_L 0.80779 0.53411 0.97331 0.19246 0.90016 0.39976
HDGFI_G 0.81679 0.52293 0.97598 0.17051 0.90914 0.38133
HDGFI 0.82278 0.51555 0.97894 0.16495 0.91113 0.37871
从表 4.4 中可以观察到，与 HDGFI 模型相比，两个变体模型的性能有所下降，
这表明局部级别和全局级别的特征交互都是必要的。HDGFI_L 与 HDGFI 相比，节
点间的成对交互可以反映局部交互的重要性。与 DNN 隐式捕获高阶交互方法相比，
将特征建模为节点并迭代更新节点表示，可以更好显式地建模特征间的交互。
HDGFI_G 与 HDGFI 相比，全局级别的特征交互可以自适应地捕捉先前层学习到的
特征节点的重要性，使每一层可以学到更为准确的节点表示，进而帮助更好地学习当
前层的特征图表示和下一层的特征图邻接矩阵。
51 4分层双级别图融合特征交互推荐算法
接下来，进一步开展分层邻接矩阵学习和双线融合的消融实验。所构建的两个变
体模型分别是：
HDGFI_E：去除分层邻接矩阵学习Top-k选择的HDGFI模型，在每层都构建一
个完全连通特征图；
HDGFI_B：去除双线性融合的HDGFI模型，使用简单向量拼接替代。
分层邻接矩阵学习和双线性融合消融实验的结果如表4.5所示。
表4.5 HDGFI与HDGFI_E和HDGFI_B变体的性能比较
数据集 KKBox Frappe MovieLens 1M
变体方法
AUC Logloss AUC Logloss AUC Logloss
HDGFI_E 0.82149 0.51716 0.97741 0.16437 0.90939 0.38051
HDGFI_B 0.82111 0.51738 0.97738 0.17088 0.90975 0.38025
HDGFI 0.82278 0.51555 0.97894 0.16495 0.91113 0.37871
从表 4.5 可以看出，相对于 HDGFI 模型，两个变体模型的性能均有所下降。
HDGFI_E与HDGFI相比，特征被建模为全连通特征图，边的权重是固定的。这种方
法在一定程度上保留了所有的特征之间的相互作用，但是不必要的交互对最终的预
测结果有负面的影响。分层的邻接矩阵学习和 Top-k 有益交互选择只关注较强的特
征节点交互，从而过滤相对不重要的特征之间的交互。HDGFI_B 与 HDGFI 的实验
结果相比显示，双线性交叉聚合函数能够更好地对两个级别的节点表示进行细粒度
融合。
4.6 本章小结
本章提出了分层双级别图融合特征交互推荐算法 HDGFI。该模型采用分层邻接
矩阵学习来过滤不必要的特征节点交互，减少交互噪声对预测的干扰；构建了局部消
息传递和全局压缩激励两个级别的交互模块，从两个角度捕捉特征的重要性。针对该
模型开展了实验研究，并与其它主流模型进行了对比分析；进一步开展了HDGFI模
型的超参实验和模块消融实验。实验结果表明，提出的HDGFI在三个公共数据集上
的准确率高于其它算法，模型设计合理有效。
52 烟台大学硕士学位论文
5 总结与展望
随着深度学习和大数据的快速发展，推荐系统近年来受到了广泛的关注和研究，
特征交互推荐算法是推荐系统领域的研究热点之一。当前众多特征交互推荐模型尚
存在一些不足和有待提高之处。首先，现存模型没有对不同级别的特征交互的重要性
进行区分，对所有的特征域进行同等重要地建模和交互，然而不同的特征域交互对最
终预测结果可能产生不同的影响作用；其次，并不是所有的特征交互都能对最终的预
测产生积极的影响，一些不必要的特征交互在训练过程中会带来噪音。本文针对现有
特征交互推荐算法存在的局限性开展研究，运用图领域的两大技术，即图相似性学习
和图结构学习技术，结合图神经网络，提出了注意力感知的图匹配特征交互推荐算法
和分层双级别图融合特征交互推荐算法两种模型。主要工作与研究结果如下：
（1）提出了一种注意力感知的图匹配特征交互推荐（AGMRec）算法。AGMRec
方法将用户和物品的属性信息建模为两个特征图，通过内部和外部两个级别的交互
建模特征组合过程。此外，在特征节点交互阶段和节点表示融合阶段都运用注意力机
制捕捉交互重要性。在两个公开数据集上进行了实验，结果表明AGMRec方法与目
前现有的大多数特征交互推荐方法相比具有一定的优越性。
（2）针对第一个工作未考虑了上下文信息在推荐过程中对预测结果的影响，提
出了一种分层双级别图融合特征交互推荐（HDGFI）方法。该方法将所有特征域建模
为一个特征图，并结合图结构学习思想，在每层选出最重要的交互，消除不相关信息
的影响。同时，在每层图神经网络迭代过程中，从局部和全局两个级别动态捕捉特征
的重要性。在三个公开数据集进行了推荐结果的预测，并进一步完成了超参实验和模
块消融实验，结果表明HDGFI方法合理且有效。
虽然本文提出的两个基于图神经网络的特征交互推荐方法取得了一些积极的研
究成果，但仍存在一些弊端。首先，AGMRec 方法构建了两个完全连通的特征图，
这样可能会使得一些非必要的边带入噪声信息。将来的研究中可以参考HDGFI的研
究思路，重新设计构建特征图模块并且优化消息传递和图匹配方式，以提高模型的性
能和推荐过程的可解释性。其次，HDGFI 模型中目标节点的邻居采样个数k是一个
重要的超参数，网格搜索法耗时且可能会陷入局部最优解，未来研究中计划寻求自适
53 5总结与展望
应最优k值选择方法，提高模型的效率。
54 烟台大学硕士学位论文
参考文献
[1] Batmaz Z, Yurekli A, Bilge A, et al. A review on deep learning for recommender
systems: challenges and remedies[J]. Artificial Intelligence Review, 2019, 52(1): 1-37.
[2] Zhu J, Han L, Gou Z, et al. A Fuzzy Clustering-Based Denoising Model for Evaluating
Uncertainty in Collaborative Filtering Recommender Systems[J]. Journal of the
American Society for Information Science and Technology, 2018, 69(9): 1109-1121.
[3] 魏娟, 李敏. 信息过载影响消费者决策研究的知识图谱分析[J]. 管理现代化,
2022, 42(01): 156-161.
[4] 管其平. 数字化生存中的信息过载及其空间治理[J]. 昆明理工大学学报(社会科
学版), 2021, 21(1): 99-107.
[5] Varma M. Extreme Classification: Tagging on Wikipedia, Recommendation on Amazon
& Advertising on Bing[C]// Proceedings of the Web Conference 2018. 2018: 1897-1897.
[6] Mooney R J, Roy L. Content-based book recommending using learning for text
categorization[C]// Proceedings of the 5th ACM Conference on Digital Libraries. 2000,
195-204.
[7] Medjahed B, Atif Y. Context-based matching for Web service composition[J].
Distributed and Parallel Databases, 2007, 21(1): 5-37.
[8] Breese J S, Heckerman D, Kadie C. Empirical analysis of predictive algorithms for
collaborative filtering[C]// Proceedings of the 14th Conference on Uncertainty in
Artificial Intelligence. 1998: 43-52.
[9] Wang X, He X, Wang M, et al. Neural graph collaborative filtering[C]// Proceedings of
the 42nd International ACM SIGIR Conference on Research and Development in
Information Retrieval. 2019: 165-174.
[10] Huang Z, Yu C, Ni J, et al. An Efficient Hybrid Recommendation Model With Deep
Neural Networks[J]. IEEE Access, 2019, 7: 137900-137912.
[11] Hu J, Liu L, Zhang C, et al. Hybrid Recommendation Algorithm Based on Latent Factor
Model and PersonalRank[J]. Journal of Internet Technology, 2018, 19(3): 919-926.
[12] Richardson M, Dominowska E, Ragno R. Predicting Clicks: Estimating the Click-
55 参考文献
Through Rate for New Ads[C]// Proceedings of the 16th International Conference on
World Wide Web. 2007: 521-530.
[13] 刘梦娟, 曾贵川, 岳威, 等. 基于融合结构的在线广告点击率预测模型[J]. 计算
机学报, 2019, 42(7): 1570-1587.
[14] Rendle S. Factorization Machines[C]// Proceedings of the 2010 IEEE 10th International
Conference on IEEE. 2010: 955-1000.
[15] Juan Y, Zhuang Y, Chin W S, et al. Field-aware Factorization Machines for CTR
Prediction[C]// Proceedings of the 10th ACM Conference. 2016: 43-40.
[16] Pan J, Xu J, Ruiz A L, et al. Field-weighted factorization machines for click-through
rate prediction in display advertising[C]// Proceedings of the 2018 World Wide Web
Conference. 2018: 1349-1357.
[17] Sun Y, Pan J, Zhang A, et al. FM2: Field-matrixed factorization machines for
recommender systems[C]// Proceedings of the Web Conference 2021. 2021: 2828-2837.
[18] Xiao J, Ye H, He X, et al. Attentional Factorization Machines: Learning the Weight of
Feature Interactions via Attention Networks[C]// Proceedings of the 26thInternational
Joint Conference on Artificial Intelligence. 2017: 3119-3125.
[19] Duan D, Gai X, Han Z,et al. Micro-blog misinformation detection based on gradient
boost decision tree[J]. Journal of Computer Applications, 2018, 38(2): 410-414.
[20] Jin K H, Mccann M T, Froustey E, et al. Deep Convolutional Neural Network for
Inverse Problems in Imaging[J]. IEEE Transactions on Image Processing, 2017, 26(9):
4509-4522.
[21] Lauriola I, Lavelli A, Aiolli F. An introduction to Deep Learning in Natural Language
Processing: Models, techniques, and tools[J]. Neurocomputing, 2022, 470(22): 331-
336.
[22] Tianyi Z, Yang H, Valsdottir L R, et al. Identifying drug–target interactions based on
graph convolutional network and deep neural network[J]. Briefings in Bioinformatics,
2021, 22(2): 2141-2150.
[23] Zhang W, Du T, Wang J. Deep learning over multi-field categorical data[C]//
Proceedings of the European conference on information retrieval. 2016: 45-57.
56 烟台大学硕士学位论文
[24] Shan Y, Hoens T R, Jiao J, et al. Deep Crossing: Web-Scale Modeling without Manually
Crafted Combinatorial Features[C]// Proceedings of the SIGKDD International
Conference. ACM, 2016: 255-262.
[25] Qu Y, Cai H, Ren K, et al. Product-based Neural Networks for User Response
Prediction[C]// Proceedings of the 2016 IEEE 16th International Conference. 2016:
1149-1154.
[26] He X, Chua T S. Neural Factorization Machines for Sparse Predictive Analytics[C]//
Proceedings of the 40th International ACM SIGIR Conference on Research and
Development in Information Retrieval. 2017: 355-364.
[27] Cheng H T, Koc L, Harmsen J, et al. Wide & Deep Learning for Recommender
Systems[C]// Proceedings of the 1st Workshop on Deep Learning for Recommender
Systems. ACM, 2016: 7-10.
[28] Wang R, Fu B, Fu G, et al. Deep & cross network for ad click predictions[C]//
Proceedings of the ADKDD'17. 2017: 1-7.
[29] Guo H, Tang R, Ye Y, et al. DeepFM: A Factorization-Machine based Neural Network
for CTR Prediction[C]// Proceedings of the 26th International Joint Conference on
Artificial Intelligence. 2017: 1725-1731.
[30] Lian J, Zhou X, Zhang F, et al. xDeepFM: Combining Explicit and Implicit Feature
Interactions for Recommender Systems[C]// Proceedings of the 24th ACMSIGKDD
International Conference on Knowledge Discovery and Data Mining. 2018: 1754-1763.
[31] Huang T，Zhang Z, Zhang J. FiBiNET: combining feature importance and bilinear
feature interaction for click-through rate prediction[C]// Proceedings of the 13th ACM
Conference on Recommender Systems. 2019: 169-177.
[32] Hu J, Shen L, Sun G, et al. Squeeze-and-Excitation Networks[C]// Proceedings of the
IEEE Conference on Computer Vision and Pattern Recognition. 2018: 7132-7141.
[33] Song w, Shi C, Xiao Z, et al. Autoint: Automatic feature interaction learning via self-
attentive neural networks[C]// Proceedings of the 28th ACM International Conference
on Information and Knowledge Management. 2019: 1161-1170.
[34] Xu Y, Zhu Y, Yu F, et al. Disentangled self-attentive neural networks for click-through
57 参考文献
rate prediction[C]// Proceedings of the 30th ACM International Conference on
Information & Knowledge Management. 2021: 3553-3557.
[35] Li Z, Cheng W, Chen Y, et al. Interpretable click-through rate prediction through
hierarchical attention[C]// Proceedings of the 13th International Conference on Web
Search and Data Mining. 2020: 313-321.
[36] Cheng W, Shen Y, Huang L. Adaptive factorization network: Learning adaptive-order
feature interactions[C]// Proceedings of the AAAI Conference on Artificial Intelligence.
2020, 34(04): 3609-3616.
[37] Li Z, Cui Z, Wu S, et al. Fi-GNN: Modeling Feature Interactions via Graph Neural
Networks for CTR Prediction[C]// Proceedings of the 28th ACM International
Conference on Information and Knowledge Management. 2019: 539-548.
[38] Su Y, Zhang R, Erfani S, et al. Detecting beneficial feature interactions for
recommender systems[C]// Proceedings of the AAAI conference on artificial
intelligence. 2021, 35(5): 4357-4365.
[39] Zheng Z, Zhang C, Gao X, et al. HIEN: hierarchical intention embedding network for
click-through rate prediction[C]// Proceedings of the 45th International ACM SIGIR
Conference on Research and Development in Information Retrieval. 2022: 322-331.
[40] Li Z, Wu S, Cui Z, et al. GraphFM: Graph Factorization Machines for Feature
Interaction Modeling[J]. arXiv preprint arXiv: 2105.11866, 2021.
[41] Su Y, Zhang R, Erfani S M, et al. Neural Graph Matching based Collaborative
Filtering[C]// Proceedings of the 44th International ACM SIGIR Conference on
Research and Development in Information Retrieval. 2021: 849-858.
[42] 黄立威, 江碧涛, 吕守业, 等．基于深度学习的推荐系统研究综述[J]. 计算机学报,
2018, 41(7): 1619-1647.
[43] 项亮. 推荐系统实践[M]．北京市:人民邮电出版社, 2012: 1-200.
[44] 吴静, 谢辉, 姜火文. 图神经网络推荐系统综述[J].计算机科学与探索, 2022,
16(10): 2249-2263.
[45] Gao C, Zheng Y, Li N, et al. Graph neural networks for recommender systems:
Challenges, methods, and directions[J]. arXiv preprint arXiv:2109.12843,2021.
58 烟台大学硕士学位论文
[46] Kipf T N, Welling M. Semi-supervised classification with graph convolutional
networks[J]. arXiv preprint arXiv:1609.02907, 2016.
[47] Hamilton W L, Ying R, Leskovec J. Inductive representation learning on large
graphs[C]// Proceedings of the 31st International Conference on Neural Information
Processing Systems. 2017: 1025-1035.
[48] Velikovi P, Cucurull G, Casanova A, et al. Graph Attention Networks[C]// Proceedings
of the International Conference on Learning Representations. 2018: 1-12.
[49] Li Y, Gu C, Dullien T, et al. Graph Matching Networks for Learning the Similarity of
Graph Structured Objects[C]// Proceedings of the 36th International Conference on
Machine Learning. 2019.
[50] Zhu Y, Xu W, Zhang J, et al. A Survey on Graph Structure Learning: Progress and
Opportunities[J]. arXiv preprint arXiv: 2103.03036, 2021.
[51] Li R, Sheng W, Zhu F, et al. Adaptive Graph Convolutional Neural Networks[J]. arXiv
preprint arXiv:1801.03226,2018.
[52] Chen Y, Wu L, Zaki M J. Iterative Deep Graph Learning for Graph Neural Networks:
Better and Robust Node Embeddings[C]// Proceedings of the Advances in Neural
Information Processing Systems. 2020: 19314-19326.
[53] Jiang B, Zhang Z, Lin D, et al. Semi-Supervised Learning With Graph Learning-
Convolutional Networks[C]// Proceedings of the 2019 IEEE/CVF Conference on
Computer Vision and Pattern Recognition. 2020: 11313-11320.
[54] Luo D, Cheng W, Yu W, et al. Learning to Drop: Robust Graph Neural Network via
Topological Denoising[C]// Proceedings of the fourteenth ACM international
conference on Web Search and Data Mining. 2021: 779-787.
[55] Gao X, Hu W, Guo Z. Exploring Structure-Adaptive Graph Learning for Robust Semi-
Supervised Classification[C]// Proceedings of the 2020 IEEE International Conference
on Multimedia and Expo (ICME). 2020: 1-6.
[56] Franceschi L, Niepert M, Pontil M, et al. Learning discrete structures for graph neural
networks[C]// Proceedings of the international conference on machine learning. PMLR,
2019: 1972-1982.
59 参考文献
[57] http://www2.informatik.uni-freiburg.de/~cziegler/BX/
[58] http://www.grouplens.org/node/73
[59] https://www.kaggle.com/c/kkbox-music-recommendation-challenge/data
[60] http://baltrunas.info/data/CARS2_code.zip
60 烟台大学硕士学位论文
附录一表目录
表3.1 AGMRec模型的训练 .................................................................................. 28
表3.2 数据集描述 .................................................................................................. 30
表3.3 AGMRec和基线模型的性能比较 .............................................................. 32
表3.4 AGMRec与三个变体的性能比较 .............................................................. 34
表4.1 HDGFI模型的训练 ..................................................................................... 45
表4.2 数据集描述 .................................................................................................. 46
表4.3 HDGFI和基线模型的性能比较 ................................................................. 48
表4.4 HDGFI与HDGFI_L和HDGFI_G变体的性能比较 ............................... 51
表4.5 HDGFI与HDGFI_E和HDGFI_B 变体的性能比较 ............................... 52
65 附录一表目录
66 烟台大学硕士学位论文
附录二图目录
图2.1 推荐系统的三个阶段 .................................................................................... 7
图2.2 DeepFM 模型框架图 ................................................................................... 10
图2.3 Fi-GNN模型框架图 .................................................................................... 11
图2.4 图卷积网络结构示意图 .............................................................................. 15
图2.5 图采样和聚集网络结构示意图 .................................................................. 16
图2.6 图注意力层结构示意图 .............................................................................. 17
图2.7 图相似性计算流程图 .................................................................................. 18
图2.8 图结构学习流程图 ...................................................................................... 19
图3.1 AGMRec模型结构图 .................................................................................. 24
图3.2 不同嵌入维度对AUC 和Logloss 的影响 ................................................. 33
图3.3 不同注意力头数对AUC 和Logloss 的影响 ............................................. 33
图4.1 HDGFI模型结构图 ..................................................................................... 38
图4.2 分层边选择框架图 ...................................................................................... 40
图4.3 双级节点表征生成的架构 .......................................................................... 41
图4.4 邻居采样个数对AUC 的影响 .................................................................... 49
图4.5 不同全局衰减比例对AUC 和Logloss 的影响 ......................................... 50
67 --------------------------------------------------------------------------------- Journal of Computer Applications ISSN1001-9081 2018-02-10
计算机应用，2018，38(2):410－414，420 CODEN JYIIDU http: //www．joca．cn
文章编号:1001-9081(2018)02-0410-05 DOI:10．11772/j．issn．1001-9081．2017082368
基于梯度提升决策树的微博虚假消息检测
段大高1，2，盖新新1，韩忠明1，2* ，刘冰心3
(1．北京工商大学计算机与信息工程学院，北京100048; 2．北京工商大学食品安全大数据技术北京市重点实验室，北京100048;
3．UniversityofLiverpool，DepartmentofmathematicalSciences，Liverpool，GBL697ZX)
(* 通信作者电子邮箱hanzhongming@btbu．edu．cn)
摘 要:微博是信息共享的重要平台，同时，也成为虚假消息产生和推广的重要平台，虚假消息的传播严重扰乱
了社会秩序。为了快速、有效地识别微博虚假消息，提出一种基于梯度提升决策树(GBDT)的虚假消息检测方法。首
先，从评论的角度分析微博虚假消息和真实消息之间存在的差异，在此基础上提取评论中的文本内容、用户属性，信
息传播和时间特性的分类特征;然后，基于分类特征，采用GBDT算法实现微博虚假消息识别模型;最后，在两个真实
的微博数据集上进行验证。实验结果表明，基于GBDT的识别模型能有效提高微博虚假消息检测的准确率。
关键词:微博;社交网络;虚假消息;梯度提升决策树;评论
中图分类号: TP391．4; TP181 文献标志码:A
Micro-blog misinformation detection based on gradient boost decision tree
DUAN Dagao1，2， GAI Xinxin1， HAN Zhongming1，2* ，LIU Bingxin3
(1．SchoolofComputerandInformationEngineering，BeijingTechnologyandBusinessUniversity，Beijing100048，China;
2．BeijingKeyLaboratoryofBigDataTechnologyforFoodSafety，BeijingTechnologyandBusinessUniversity，Beijing100048，China;
3．DepartmentofMathematicalSciences，UniversityofLiverpool，Liverpool，GBL697ZX)
Abstract: Micro-blog has become an important platform for information sharing． Meanwhile， it is also one of the main
ways for spreading of different misinformation． In order to detect the micro-blog misinformation quickly and effectively， a
method based on Gradient Boost Decision Tree (GBDT) was proposed． Firstly， classification features of content， user
properties， information dissemination and time characteristic were extracted from the comments of micro-blog． Then an
identification model based on GBDT algorithm was proposed to detect misinformation． Finally， two real micro-blog datasets
were used to verify the efficiency and effectiveness of the model． The experimental results show that the proposed model can
effectively improve the accuracy of micro-blog misinformation detection．
Key words: micro-blog; social network; misinformation; gradient boost decision tree; comment
择了不再给孩子注射疫苗。4 月，微博上纷纷在转一条如何
0 引言
鉴别草莓变色催熟的文章。该文称如果草莓籽是红色的，便
微博是如今网民发布信息和获取信息的主要渠道之一。 是用了染色剂的缘故。浙江宁波、江苏徐州等地市民也的确
根据中国互联网信息中心( China Internet Network Information 发现，市面上很多草莓的籽是红色的，顿时心生不安。很多市
Center，CNNIC) 2017 年1 月发布的全国互联网发展统计报 民不再食用草莓，给社会造成了巨大的经济损失。然而，真实
告［1］，我国网民规模达7．31亿，其中微博用户超过2．67 亿， 的情况是，草莓自然成熟后，有部分草莓籽是会变成红色的。
占整体网民的36．5%。微博的低门槛特性使得用户可以不 有效地识别虚假信息对营造诚信、公平、健康的网络环境以及
受时间地域的限制，自由表达自己的观点，使用户之间分享信 维持正常的社会秩序是十分必要的。
息更加迅速、便捷。微博已经逐步渗透进人们的生活，影响人 现有的研究主要是通过选取文本内容、用户属性和传播
们的生活方式。 特性等方面的特征，然后构建合适的分类模型，以达到识别微
微博平均每天会增加数亿条博文，这些博文中既有真实 博虚假消息的目的。但是，这些研究中往往只选取局部、片面
的信息，也有大量的虚假信息，而虚假信息的泛滥对群众的影 的特征(如选取文本内容特征的统计特征、浅层传播特征或
响非常大。例如:2017 年3 月初，一篇文章在网络上引起轩 者简单的用户属性特征)，没有全面、深入地分析并挖掘影响
然大波，该文称疫苗会损害人体健康，危害无穷，家长们应该 虚假消息识别的主要因素。另外，以往的研究中只是选用单
让孩子远离疫苗，甚至声称孩子自然感染疾病比打疫苗强。 一的分类器对微博虚假消息进行检测，如朴素贝叶斯( Naive
该虚假消息在传播的过程中，误导了网民的思想，很多家长选 Bayes，NB)、支持向量机( Support Vector Machine，SVM)、决
收稿日期:2017-08-28;修回日期:2017-10-10。 基金项目:教育部人文社会科学研究基金资助项目(13YJC860006);北京市自然科学基
金资助项目(4172016);北京市科技计划项目(Z161100001616004)。
作者简介:段大高(1976—)，男，湖南邵阳人，副教授，博士，CCF会员，主要研究方向:多媒体信息处理、现代网络通信、嵌入式系统、智能数
据分析; 盖新新(1990—)，女，河北邢台人，硕士研究生，主要研究方向:数据挖掘; 韩忠明(1972—)，男，山西文水人，副教授，博士，CCF会
员，主要研究方向:海量数据分析与挖掘、互联网挖掘、生物信息学; 刘冰心(1996—)，女，北京人，主要研究方向:数据挖掘。 第2期 段大高等:基于梯度提升决策树的微博虚假消息检测 411
策树(Decision Tree，DT)等，没有考虑使用组合多个弱分类器 虚假信息及早检测方法。该方法利用模型状态持续时间概率
构建强分类器来识别虚假消息，故而识别的精度不高。因此， 为Gamma分布的隐半马尔可夫模型来刻画信息转发者和评
基于微博的短文本特性，本文提取微博评论的文本内容、用户 论者对流行的真实信息的把关行为，基于此来及早识别微博
属性、信息传播和时间特性四个方面的特征，构建基于梯度提 上流行的虚假信息。实验结果表明该方法具有较好的性能和
升决策树(Gradient Boost Decision Tree，GBDT)算法的微博虚 较高的在线检测速度。
假消息识别模型。实验结果表明，本文提出的识别方法能够
2 特征选取
有效提高虚假消息检测的准确率。
微博虚假消息与真实消息的评论存在着很大的差异。在
1 相关工作
文本内容方面，虚假消息的评论具有语气不确定程度强、消极
近几年国内外关于微博虚假消息的研究逐渐增多。在国 词汇多、内容与源消息相关程度弱的特点;在用户属性方面，
外方面，2011年，Castillo等［2］提出了对Twitter话题可信度进
虚假消息的发布者一般是非认证用户，其注册日期比较短、注
行评估的方法，通过提取消息特征、用户特征、话题特征以及 册地信息不够详细，朋友数量远高于粉丝数量，并且不使用顶
传播特征，采用J48决策树分类方法来预测热门话题是否可 级域名;在传播特性方面，网络大V用户对源消息的转发和
信。2012年，Yang等［3］提出客户端类型和微博事件发生的地
URL、@、hashtag等符号信息将会影响用户对源消息的信任程
理位置两种新特征，采用SVM分类方法对谣言进行检测。实 度，进而影响微博的转发量;在时间特性方面，距离源微博发
验结果表明，当微博所涉及的事件发生在国外而且使用非移 布时间越久的微博，其是虚假消息的概率会越小。
动客户端时，此微博被判断为谣言微博的概率较高。2015 基于以上分析，本文中总共选取了11 个特征，并将这些
年，Dayani等［4］通过提取用户特征和内容特征，并采用 K最
特征分为四类:基于文本内容的特征、基于用户的特征、基于
近邻( K-Nearest Neighbors，KNN) 分类器以及 NB 分类器在 信息传播的特征和基于时间的特征。其中，基于文本内容的
Twitter中检测谣言中支持、反对、质疑、中性的评论。实验结
特征已在文献［12］中详细介绍，故在此不再多作阐述。表1
果表明:对于用户特征，KNN分类器的效果并不理想;而对于
列出了文中所使用的全部特征，并对特征作了简单的介绍。
内容特征，朴素贝叶斯能有效检测出谣言话题下的评论数量。
表1 特征及其描述
2015年，Ma等［5］提出基于谣言生命周期的时间序列的社交
Tab． 1 Featuresandtheirdescription
上下文特征，包括微博内容特征、用户特征和传播特征，并采
分类 特征 描述
用线性 SVM 分类器分别在 Twitter 数据集与 DT、随机森林
文本 支持性(SUP) 用户对消息倾向性的态度
(Random Forest，RF)以及SVM-RBF方法作比较。实验结果
内容 内容相关性(COR) 评论是否是对消息的补充
表明:该文中提出方法的精确性比DT、RF以及SVM-RBF方 特征 置信度(CON) 用户发表评论语气的确定程度
法高，且达到与DT、RF以及SVM-RBF相同的精确性的用时 是否认证(VER) 用户身份是否经新浪微博认证
最少。2015年，Liu等［6］提出在Twitter上的实时谣言揭露，通 关注度(ATT) 账户被关注程度
用户
过使用“群众智慧”和系统性方法来挖掘语言特征，并采用 注册日期(RED) 用户注册的实际天数
特征
注册地(POR) 用户注册位置信息的详细程度
DT分类器、RF分类器以及SVM分类器进行实验。实验结果
顶级域名(TLD) 个人介绍中是否有顶级域名
表明:该文中提出的方法在事件只有最初的5条Tweets以及
信息传 URL/@/hashtag 评论包含URL/@/hashtag的数量
最初的一小时内的预测结果都要高于其他方法;而选取两个
播特征 意见领袖(OPL) 意见领袖传播过程中的影响力
实时谣言跟踪网站 snopes．com 和 emergent．info 与人工验证
时间 当前微博发布与原微博发布的
时间差(TID)
方法相比，结果显示该方法能将检测延迟减少25%和50%。 特征 时间跨度(单位:d)
与国外相比，国内关于虚假消息检测的研究相对较少。
2．1 关注度特征
2013年，蒋盛益等［7］对现有成果进行了梳理，总结了这些研
微博用户之间存在的关系有两种:关注与被关注。关注
究的不足，指出了微博信息可信度分析的关键问题和核心方
其他账户，则此账户为所关注账户的粉丝，可以看到其关注账
法，并对未来进行了展望。2013 年，贺刚等［8］提出利用符号
户发表的博文。两个账户互相关注，两个账户即为朋友关系，
特征、链接特征、关键词分布特征和时间差等新特征，将微博
都可以看到彼此发表的博文。郭浩等［13］指出，积极关注别
谣言识别形式化为分类问题，利用SVM分类算法对微博进行
分类，识别结果可以辅助识别谣言。2016 年，路同强等［9］在 人，保持较高的发文数量，就可以吸引更多的粉丝，获得更高
的关注度，使社会化网络媒体营销更加有效。这说明一些在
分析微博谣言传播特点的基础上，结合微博文本内容、微博用
微博上传播虚假消息的账户，可能会关注多个其他账户，以希
户等方面的特征构建特征集合，将半监督学习算法应用到谣
言检测中，以解决人工标注语料代价高昂的问题。2016 年，
望这些账户能够关注自己，看到自己发表的博文并传播这些
吴树芳等［10］在HITS( Hyperlink-Induced Topic Search) 算法的 消息，结果表现为朋友数量远远多于粉丝数量。正常用户的
基础上，提出了融合用户交互行为和博文内容的微博用户可
朋友和粉丝的数量一般相差不多，其微博上的关注关系一般
信度评估算法，分别构建基于交互行为和基于博文内容的微 是现实中朋友关系的映射。因此，将关注度特征计算公式表
博用户有向链接图，通过反复训练法获得可信度阈值，绘制不 示如下:
同可信度算法的用户可信度曲线，验证了算法的可行性和有 ATT u = FOL u/(FOL u + FRI u) (1)
效性。2016年，谢柏林等［11］提出一种基于把关人行为的微博 其中: FOL u表示用户u的粉丝数量，FRI u表示用户u的朋友 412 计算机应用 第38卷
数量。正常用户的关注度值要高于虚假消息传播用户的关注 的角度衡量微博虚假消息与真实消息之间的区别。与真实消
度值。 息相比，在文本内容方面，虚假消息中SUP特征值为负、COR
2．2 顶级域名特征 特征值较低、CON特征值较低的评论更多;在用户属性方面，
顶级域名是付费服务，它具有易查找、可信度高、独立性 虚假消息的发布者一般是VER特征值为0，且ATT特征值较
等优点，一般来说，只有一些有需要的个人或者是公司才会使 低、RED特征值较低、POR特征值较低、TLD特征值为0;在传
用这项服务。而虚假消息传播用户本身是为了盈利，故而只 播特性方面，虚假消息的评论中 URL、@、hashtag 特征值较
会注册一些免费的账户来传播信息，所以此特征具有明显的 低，OPL特征值较低;在时间特性方面，虚假消息中TID特征
区分性。顶级域名特征(TLD)的取值是{0，1}，0表示个人介 值较小的评论更多。特征提取的目的是为了分析影响类别之
绍中有顶级域名的用户的特征值，1 表示个人介绍中无顶级 间差异的主要因素。
域名的用户的特征值。 微博虚假消息识别问题，可以看作一个分类问题。在数
2．3 意见领袖特征 据量较大的情况下，需要选择一个分类速度高且准确率也高
王永强［14］指出，所谓意见领袖，指的是人际传播网络中 的模型。因此本文中选用GBDT算法，它是由Friedman［15］提
经常为他人提供信息、意见、评论并对他人施加影响的“活跃 出的组合决策树模型，是一种由多个弱分类器经过多次迭代
分子”，是大众传播效果形成过程的中介或过滤环节。意见 形成的强分类器。与传统Boosting算法( 如Adaboost) 不同的
领袖在信息传播过程中的影响是巨大的。例如，2010 年12 是，GBDT算法的基分类器是回归树，其迭代的目的是通过计
月6日，微博上爆出金庸先生“去世”的消息，当晚《中国新闻 算上一次模型的负梯度来改进模型，然后在残差减少的梯度
周刊》在官方微博上转发了这则微博，这则消息事后被证实 方向上建立新的决策树;Adaboost算法通过简单地调整正确、
为谣言。但网络大V的转发加速了消息的传播，导致此谣言 错误样本的权重来改进模型，二者有本质区别。
在数分钟内即被转发近千条。为了衡量意见领袖在传播过程 现给定微博数据样本{(x，y)}(i = 1，2，…，n)。由于虚
i i
中的影响，本文中将用户分为两类:认证用户和普通用户，主 假消息识别是一个分类过程，故采用对数损失函数，即:
要获取认证用户在传播过程中的影响。由此，将意见领袖特 q
L(y，F(x)) = 2∑log(1 + exp( －2yp)) (4)
征的计算公式表示为: i i
i=1
{
REP /REP ， 认证用户 其中:x = (x ，x ，…，x )，n为样本的数量，q为虚假消息识
OPL = ver ori (2) i 1i 2i qi
u 0， 普通用户 别中特征的数量，y i 为样本的实际标签，p i 为样本的预测标
其中: REP 表示通过认证用户微博被转发的数量，REP 表 签。GBDT算法的详细步骤如下:
ver ori
示源消息的转发数量。如果是普通用户，则意见领袖特征为 1)初始化模型，估计使损失函数最小化的常数值β:
0。 n
F (x) = arg min∑L(y，β) (5)
0 i
2．4 时间差特征 β i=1
谣言的传播有四个阶段:潜伏期、变异期、爆发期和消亡 2) 在上一次模型损失函数的梯度下降方向上建立模型，
期。谣言的爆发期通常时间比较短暂。在谣言微博发布后， 从m = 1到M(M为迭代次数):
随即会出现一系列辟谣的微博，并且其传播要比谣言微博快 ①计算损失函数的负梯度在当前模型的值，将它作为残
很多，所以，距离谣言源微博时间越久的微博，它是谣言的概 差r im 的估计值:
[ ]
率会越小。根据以上分析，用时间差特征来表示当前评论发 r = － L(y i，F(x i)) ; i = 1，2，…，n (6)
im F(x)
布时间距微博源消息发布时间的间隔，其计算公式表示如下: i Fm(x)=Fm－1(x)
TID = TIM － TIM (3)
②将①中得到的估计残差作为输入，拟合一棵回归树，
w w m
其中: TIM 表示当前评论w的发布时间，TIM 表示源消息m
求得回归树的叶节点区域R j，m(j = 1，2，…，J)。
w m
的发布时间。时间差特征以天为单位。
③为使损失函数极小化，对于j = 1，2，…，J，求得沿梯度
2．5 其他特征 下降方向的最优步长β jm:
是否认证特征( VER)、注册日期特征( RED)、注册地特 β = arg min ∑ L(y，F (x) + β) (7)
jm i m－1
征(POR)在一定程度上反映了用户的可信度。本文中通过是
β xi∈Rj，m
④更新模型F (x):
否认证特征将用户分为两类:认证用户和普通用户。是否认 m
J
证特征的取值是{0，1}，0 表示普通用户的特征值，1 表示认 F (x) = F (x) + ∑β I; x∈R (8)
m m－1 jm jm
j=1
证用户的特征值。注册日期特征是指用户注册的实际天数，
3) 迭代结束，得到模型F (x):
M
通过计算用户当前评论的发表时间与用户的注册日期的差值
M J
来实现。注册地特征衡量用户注册位置信息的详细程度，其 F M(x) = ∑∑β jmI; x∈R
jm
(9)
m=1 j=1
取值是{0，0．5，1}，0表示注册位置信息为空的用户的特征
4) 根据得到的模型，估算样本预测为正类的概率p (x)
+
值，0．5表示注册位置信息中只有省份的用户的特征值，1 表
和预测为负类的概率p (x):
{ －
示注册位置信息中既有省份又有城市的用户的特征值。
1
p (x) = p(y = 1|x) =
+ r 1 + e－2FM(x)
3 特征选取 (10)
1
p (x) = p(y = －1|x) =
本文在微博消息的评论中提取四个方面的特征，从不同 － r 1 + e2FM(x) 第2期 段大高等:基于梯度提升决策树的微博虚假消息检测 413
5) 据以下准则预测样本标签y(x)，其中c( －1，1) 是代 Acc = 识别正确的微博数 / 总微博数 (16)
价函数，表示当真实类别为1，预测类别为 －1时的代价: 4．4 结果分析
y(x) = 2* l{c( －1，1)p (x) ＞ c(1，－1)p (x)} －1 微博虚假消息的评论存在着语气不确定程度强、消极词
+ －
(11) 汇多、重复源消息等的特点。基于此，通过统计微博消息中被
其中:l{}是将布尔值转换为{0，1}函数。 模型判定为虚假消息评论的比例，可以得到一个阈值，当微博
消息中的虚假评论达到这个阈值的时候，则此微博被判定为
4 实验结果与分析
虚假消息。
为了比较不同分类器分类的结果，本文选择Castillo等［2］
4．1 实验数据
使用的J48决策树分类器、Yang等［3］使用的SVM分类器以
本文实验数据集有两个:数据集1 选自文献［16］，其数
及Kwon等［18］使用的RF分类器。其中，SVM核函数选择径
据采集自新浪微博社区管理中心和新浪微博API接口，总共
向基核函数(Radial Basis Function，RBF)，使用LIBSVM［19］中
包含2313个谣言和2351个非谣言，内容包括旅游、球赛、娱
乐、生活、常识等话题。数据集2 是在文献［17］中数据集的
的grid来寻找最优的参数c和γ。
基础上，采集新浪微博社区管理中心中的不实信息作为谣言 4．4．1 实验阈值
数据，然后在新浪微博上爬取与谣言微博具有相同时间跨度
实验以正确率Acc为基准，使用不同分类器获得使正确
的微博作为非谣言数据，保留原微博字数超过10，评论数超
率Acc最高的阈值，称为最佳阈值，它可以最好地将虚假消息
过200条的微博。处理后的数据集2总共包含447个谣言和
与真实消息区分开。两个数据集的最佳阈值统计结果如表3
455个非谣言，内容主要是2013年和2014年的热点新闻。两
所示。
个数据集的统计情况见表2。相比数据集2，数据集1包含的 表3 数据集的最佳阈值
特征的相关信息更多，本文在数据集1中提取了表1 中介绍 Tab． 3 Thebestthresholdofthedatasets
的所有特征;而数据集2则缺少表1中某些特征的相关信息， 数据集 分类器 最佳阈值 数据集 分类器 最佳阈值
最终在数据集2 中提取了 SUP、COR、CON、URL、@、hashtag GBDT 0．16 GBDT 0．17
和TID特征。本文中提出的虚假消息识别模型是一个综合模 RF 0．27 RF 0．28
1 2
型，如果需要针对具体某个事件进行识别，可以结合本文中的 SVM 0．40 SVM 0．45
J48 0．45 J48 0．48
模型，并使用和事件本身相关的特征进行识别。实验按照
8∶ 2的比例随机划分数据集，即数据集的80%作训练集，余下
4．4．2 特征重要性
20%作测试集，均采用十折交叉验证。
为了验证特征在分类过程中的影响，以正确率Acc为基
表2 数据集的统计情况 准，用GBDT分类器的默认参数来对不同的特征进行训练，数
Tab． 2 Statisticsofthedataset 据集1 使用表1 中的全部特征，数据集2 使用 SUP、COR、
用户 微博 事件 谣言 非谣言 CON、URL、@、hashtag和TID特征，两个数据集的训练结果如
数据集
数量 数量 数量 数量 数量
表4所示。其中，特征前面的“－”符号表示不包括该特征的
1 2746818 3805656 4664 2313 2351
特征集，Acc中的“—”表示实验没有使用该特征集。
2 205391 286714 902 447 455
表4 不同特征对分类的影响
4．2 特征归一化 Tab． 4 Influenceonclassificationwithdifferentfeatures
从评论中提取的特征如果直接用于分类，其相差过大的 Acc Acc
特征集 特征集
权重范围将会影响分类器的准确性。为此，对特征进行归一 数据集1 数据集2 数据集1 数据集2
化处理是十分有必要的。本文使用式(12) 对特征进行归一 ( －)SUP 0．891 0．872 ( －)TLD 0．880 —
化处理，归一化后特征权重限定在［0，1］区间，可以消除离群 ( －)COR 0．883 0．773 ( －)URL 0．881 0．881
( －)CON 0．888 0．886 ( －)@ 0．882 0．889
数据对分类的影响，也可以使计算过程收敛得更快。
( －)VER 0．887 — ( －)hashtag 0．891 0．890
x － min(x )
y = i，j ．j (12) ( －)ATT 0．884 — ( －)OPL 0．887 —
i，j max(x ) － min(x )
．j ．j ( －)RED 0．870 — ( －)TID 0．831 0．887
其中:min(x．j) 表示第j列特征权重的最小值，max(x．j) 表示
( －)POR 0．886 — ALL 0．894 0．892
第j列特征权重的最大值。
4．3 评价指标 从表4中可以明显看出，实验中用到的所有特征都有助
为了评测微博虚假消息检测的结果，本文选用查准率 于提升微博虚假消息的检测效果。其中，数据集1 使用所有
(P)、查全率(R) 以及F1值作为评价标准。 特征(ALL) 的正确率 Acc 是0．894，高于数据集2(0．892)。
P = TP/(TP + FP) (13) 这是因为数据集1使用了表1中的全部特征，数据集2 只使
R = TP/(TP + FN) (14) 用表1中的部分特征。在数据集1 中，时间差特征( TID) 和
F1 = 2PR/(P + R) (15) 注册日期特征(RED)对总体分类结果影响是最大的;在数据
其中:TP是被正确判别为谣言的微博数，FP是被错误判别为谣 集2中，内容相关性特征( COR) 和支持性特征( SUP) 对总体
言的微博数，FN是被错误判别为非谣言的微博数。另外，为了衡 分类结果影响是最大的。这是因为数据集1中的话题，例如
量总体的分类效果，采用下面的公式计算总体分类正确率: 生活、常识等，其讨论的时间会比较长，所以在数据集1中，关 414 计算机应用 第38卷
于时间特征的重要性会比较高;数据集2的话题是热点新闻， mationCenter (CNNIC)． Statistical report on Internet development
其评论内容比数据集1更加规范，所以在数据集2中，起重要 inChina［R］． Beijing: ChinaInternetNetworkInformationCenter，
作用的主要是基于文本内容的特征，而新闻的时效一般都比 2017．)
［2］ CASTILLOC，MENDOZAM，POBLETEB． Informationcredibility
较短，故时间差特征( TID) 在数据集2 中体现的重要性没有
ontwitter ［C］// WWW '11: Proceedings of the20th International
在数据集1中的重要性高。
ConferenceonWorld Wide Web． New York: ACM，2011: 675 －
4．4．3 分类结果
684．
为了便于比较，实验将GBDT、RF、J48中决策树的最大深
［3］ YANGF，LIUY，YUX，etal． AutomaticdetectionofrumoronSina
度统一设定为15，SVM 核函数选择 RBF，使用 LIBSVM 寻找
Weibo ［C］// MDS '12: Proceedings of the 2012 ACM SIGKDD
最优的参数c和γ。两个数据集的实验结果如表5所示。其中，
Workshop on Mining Data Semantics． New York: ACM， 2012:
F表示虚假消息，T表示真实消息。
ArticleNo． 13．
从表5中可以看出，GBDT分类器的正确率Acc要明显高
［4］ DAYANIR，CHHABRAN，KADIANT，etal． Rumordetectionin
于SVM和J48。这是因为GBDT是一种由多个弱分类器形成
Twitter: ananalysisinretrospect［C］//ANTS2015: Proceedingsof
的强分类器，其效果要好于单一的分类器;GBDT分类器的分 the2015 IEEEInternationalConferenceon Advanced Networksand
类效果要好于RF，这是因为GBDT的输出是所有结果的累 TelecommuncationsSystems． Piscataway，NJ: IEEE，2015: 1－3．
积，RF采用多数投票原则决定最终结果，且 RF训练调参时 ［5］ MAJ，GAOW，WEIZ，etal． Detectrumorsusingtimeseriesofso-
依赖于决策树的最大深度，而GBDT只需很小的深度就可以 cialcontextinformationonmicrobloggingwebsites［C］// CIKM'15:
达到很高的精度，实验中为了提高分类速度，没有给RF增大 Proceedingsofthe24thACMInternationalonConferenceonInforma-
深度。数据集1中GBDT分类器的正确率Acc要高于数据集 tionandKnowledge Management． New York: ACM，2015: 1751－
2中GBDT分类器的Acc，因为数据集1中使用了表1中的全 1754．
［6］ LIUX， NOURBAKHSH A， LI Q， et al． Real-time rumor debun-
部特征，数据集2只使用表1中的部分特征，且数据集1比数
kingon twitter ［C］// CIKM '15: Proceedings of the 24th ACM
据集2数据量大，故分类模型加精确。
InternationalonConferenceon Information and Knowledge Manage-
表5 不同分类器的分类结果
ment． NewYork: ACM，2015: 1867－1870．
Tab． 5 Classificationresultsofdifferentclassifiers
［7］ 蒋盛益，陈东沂，庞观松，等．微博信息可信度分析研究综述［J］．
数据 分类
Acc P(F) R(F) F1(F) P(T) R(T) F1(T) 图书情报工作，2013，57(12):136－142． (JIANG S Y， CHEN D
集 器
Y，PANG G S， et al． Research review of information credibility
GBDT 0．940 0．932 0．949 0．940 0．946 0．930 0．938
analysisonmicroblog［J］． Library and Information Service，2013，
RF 0．908 0．869 0．948 0．907 0．956 0．877 0．915
1 57(12):136－142．)
SVM 0．881 0．873 0．897 0．885 0．889 0．864 0．876
J48 0．858 0．853 0．893 0．873 0．836 0．863 0．849 ［8］ 贺刚，吕学强，李卓，等．微博谣言识别研究［J］．图书情报工作，
GBDT 0．929 0．920 0．936 0．928 0．929 0．910 0．919 2013，57(23):114－120． (HE G， LYU X Q， LI Z， et al． Auto-
RF 0．910 0．900 0．930 0．915 0．925 0．887 0．906 maticrumoridentificationonmicroblog［J］． LibraryandInformation
2
SVM 0．900 0．880 0．911 0．895 0．907 0．868 0．887 Service，2013，57(23):114－120．)
J48 0．883 0．869 0．876 0．872 0．874 0．869 0．871 ［9］ 路同强，石冰，闫中敏，等．一种用于微博谣言检测的半监督学习
算法［J］．计算机应用研究，2016，33(3):744 －748． (LU T Q，
5 结语
SHI B， YAN Z M， et al． Semi-supervised learning algorithm
本文从微博评论的角度在文本内容、用户属性、信息传播 appliedtomicroblogrumorsdetection ［J］． Application Research of
Computers，2016，33(3): 744－748．)
和时间特性四个方面分析影响分类的因素并提取分类特征，
［10］ 吴树芳，徐建民．基于HITS算法的微博用户可信度评估［J］．山
并基于GBDT算法设计微博虚假消息识别模型。通过在两个
东大学学报(工学版)，2016，46(2):1－7． (WU S F， XU J M．
微博数据集上的对比实验分析可以看到，模型在数据集1 上
Evaluationofmicroblog users'credibility based on HITS algorithm
的实验结果要好于在数据集2上的实验结果;在数据集1中，
［J］． Journal of Shandong University (Engineering Science)，
起主要作用的是基于时间的特征，在数据集2中，起主要作用
2016，46(2): 1－7．)
的是基于文本内容的特征。两个数据集上的实验均表明，本
［11］ 谢柏林，蒋盛益，周咏梅，等．基于把关人行为的微博虚假信息
文提出的基于GBDT的方法能够有效提高微博虚假消息检测
及早检测方法［J］．计算机学报，2016，39(4):730－744． (XIEB
的准确率。
L，JIANGSY，ZHOUYM，etal． Misinformationdetectionbased
但是，微博虚假消息检测的价值体现在能够及早地发现
on gatekeepers' behaviors in microblog ［J］． Chinese Journal of
并处理，以减少对社会的危害。因此，下一步的工作重点是通 Computers，2016，39(4): 730－744．)
过借助传播模型以及消息传播过程中用户的认知与识别能 ［12］ 段大高，王长生，韩忠明，等．基于微博评论的虚假消息检测模
力，综合更复杂的特征来构建合适的模型，实现实时检测微博 型［J］． 计算机仿真，2016，33(1):386 －390． (DUAN D G，
虚假消息的目的。 WANGCS，HANZM，etal． Arumordetectionmodelbased on
参考文献: Weibo'reviews［J］． Computer Simulation，2016，33(1): 386 －
［1］ 中国互联网络信息中心．中国互联网络发展状况统计报告［R］． 390．)
北京:中国互联网信息中心，2017． (ChinaInternetNetwork Infor- (下转第420页) 420 计算机应用 第38卷
－590． IEEE 14th International Conference on Scalable Computing and
［6］ LONGC，WONG R C-W， YU P S， et al． On optimal worst-case CommunicationsandItsAssociated Workshops． Washington， DC:
matching ［C］// SIGMOD '13: Proceedings of the 2013 ACM IEEEComputerSociety，2014: 212－219．
SIGMOD International Conference on Management of Data． New ［14］ 宋天舒，童咏昕．空间众包环境下的三类对象在线任务分配
York: ACM，2013: 845－856． ［J］．软件学报，2017，28(3):611 －630． (SONG T S， TONG Y
［7］ TONGY，SHEJ，DINGB，etal． Onlinemobilemicro-taskalloca- X． Threetypesof objects online task allocation space crowdsourc-
tioninspatialcrowdsourcing［C］// ICDE2016: Proceedingsofthe ingenvironment．［J］ Journal of Software， 2017， 28(3): 611 －
2016 IEEE32ndInternationalConferenceonDataEngineering． Pis- 630．)
cataway，NJ: IEEE，2016: 49－60． ［15］ REN J， ZHANG Y， ZHANG K， et al． SACRM: Social Aware
［8］ LEONGHOUU，MOURATIDISK，MAMOULISN． Continuousspa- CrowdsourcingwithReputationManagementinmobilesensing［J］．
tial assignmentofmovingusers［J］． TheVLDBJournal—TheInter- ComputerCommunications，2014，65: 55－65．
nationalJournalonVeryLargeDataBases，2010，19(2): 141－160． ［16］ DAIW， WANG Y， JIN Q， et al． An integrated incentive frame-
［9］ GAREY M R， JOHNSON D S． Computers and Intractability: A workfor mobile crowdsourced sensing ［J］． Tsinghua Science and
GuidetotheTheoryofNP-completeness［M］． New York: W． H． Technology，2016，21(2): 146－156．
Freeman，1979: 90－91． ［17］ 张晓航，李国良，冯建华．大数据群体计算中用户主题感知的任
［10］ MEHTAA． Onlinematchingandadallocation［J］． Foundations＆ 务分配［J］． 计算机研究与发展，2015，52(2): 309 －317．
TrendsinTheoreticalComputerScience，2013，8(4): 265－368． (ZHANGXH，LIGL，FENGJH． Usertopicawaretaskassign-
［11］ WANGY，WONGSC-W． Two-sidedonlinebipartitematchingand mentinlargedatagroup computing ［J］． Journal of Computer Re-
vertexcover: beatingthegreedyalgorithm［C］// ICALP2015: Pro- searchandDevelopment，2015，52 (2): 309－317)．
ceedingsofthe2015InternationalColloquiumonAutomata，Langua- ［18］ CHEN Z， FU R， ZHAO Z， etal． gMission : a general spatial
ges，andProgramming，LNCS9134． Berlin: Springer，2015: 1070 crowdsourcingplatform ［J］． Proceedings of the Very Large Data
－1081． BaseEndowment，2014，7(13): 1629－1632．
［12］ TING H F， XIANG X． Near optimal algorithms for online maxi-
mum edge-weighted b-matching and two-sided vertex-weighted This workispartiallysupportedbytheNationalNaturalScienceFoun-
b-matching［J］． TheoreticalComputerScience，2015，607(P2): dationofChina (61170052)， the Jinan City University Institute of inde-
247－256． pendentinnovationproject(201401211)．
［13］ HASSANUU，CURRYE． Amulti-armedbanditapproach toon-
line spatial task assignment ［C］// UIC-ATC-ScalCom '14: Pro- LIUHui，bornin1992，M． S． candidate． Hisresearchinterestsin-
ceedingsofthe2014 IEEE11thInternationalConferenceon Ubiq- cludecrowdsourcing，deeplearning．
uitousIntelligence and Computing， and 2014 IEEE 11th Interna- LISheng'en，borinin1963，Ph． D．，professor． Hisresearch inter-
tionalConferenceonAutonomicandTrustedComputing，and2014 estsincludedatawarehouse，onlineanalysis，datamining．
(上接第414页) ［18］ KWONS， CHA M， JUNG K， et al． Prominent features of rumor
［13］ 郭浩，陆余良，王宇，等．多特征微博垃圾互粉检测方法［J］．中 propagationinonlinesocialmedia［C］// ICDM2013: Proceedings
国科技论文，2012，7(7):548－551． (GUOH，LUYL， WANG ofthe2013 IEEE13th International Conference on Data Mining．
Y，etal． Detectionofspam mutual concerns in micro-blogs based Piscataway，NJ: IEEE，2013: 1103－1108．
onmulti-features［J］． China Sciencepaper，2012，7(7): 548 － ［19］ CHANGC-C，LINC-J． LIBSVM: alibraryforsupportvectorma-
551．) chines［J］． ACMTransactionsonIntelligentSystemsandTechnol-
［14］ 王永强．微博意见领袖 少数派的权利［N］．中国经营报， ogy(TIST)，2011，2(3): ArticleNo． 27．
2011-09-19 (C05)． (WANG Y Q． Micro-blog opinion leaders
theminority' rights ［N］． China Business Journal， 2011-09-19 Thiswork is partially supported by the Humanities and Social Sci-
(C05)．) encesFoundation of Ministry of Education (13YJC860006)， the Beijing
［15］ FRIEDMANJH． Greedyfunctionapproximation: agradientboos- Municipal Natural Science Foundation (4172016)， the Beijing Science
tingmachine［J］． TheAnnalsofStatistics，2001，29(5): 1189－ andTechnologyProject(Z161100001616004)．
1232．
［16］ MAJ，GAOW，MITRA P， et al． Detecting rumors from microb- DUANDagao，bornin1976，Ph． D．， associate professor． His re-
logswith recurrent neural networks ［C］// IJCAI2016: Proceed- searchinterests include multi-media information processing， modern net-
ingsofthe25thInternationalJoint Conference on Artificial Intelli- workcommunication，embeddedsystem，intelligentdataanalysis．
gence． London: dblpComputerScienceBibliography，2016: 3818 GAIXinxin，bornin1990，M． S． candidate． Herresearchinterests
－3824． includedatamining．
［17］ JINZ，CAOJ，JIANGY-G，etal． Newscredibilityevaluation on HANZhongming，bornin1972，Ph． D．，associate professor． His
microblogwithahierarchicalpropagationmodel［C］// ICDM'14: research interests include mass data analysis and mining， Web mining，
Proceedings of the 2014 IEEE International Conference on Data bioinformatics．
Mining． Washington，DC: IEEE Computer Society，2014: 230－ LIU Bingxin， born in 1996． Her research interests include data
239． mining． --------------------------------------------------------------------------------- 第４１卷 第７期 计 算 机 学 报 Ｖｏｌ．４１ Ｎｏ．７
２０１８年７月 ＣＨＩＮＥＳＥ ＪＯＵＲＮＡＬ ＯＦ ＣＯＭＰＵＴＥＲＳ Ｊｕｌｙ ２０１８
基于深度学习的推荐系统研究综述
黄立威１） 江碧涛１） 吕守业１） 刘艳博１） 李德毅２）
１）（北京市遥感信息研究所 北京 １００１９２）
２）（清华大学计算机科学与技术系 北京 １０００８４）
摘 要 深度学习是机器学习领域一个重要的研究方向，近年来在图像处理、自然语言理解、语音识别和在线广告
等领域取得了突破性进展．将深度学习融入推荐系统中，研究如何整合海量的多源异构数据，构建更加贴合用户偏
好需求的用户模型，以提高推荐系统的性能和用户满意度，成为基于深度学习的推荐系统的主要任务．该文对近几
年基于深度学习的推荐系统研究进展进行综述，分析其与传统推荐系统的区别以及优势，并对其主要的研究方向、
应用进展等进行概括、比较和分析．最后，对基于深度学习的推荐系统的未来发展趋势进行分析和展望．
关键词 推荐系统；深度学习；协同过滤；个性化服务；数据挖掘；多源异构数据
中图法分类号 ＴＰ１８ ＤＯＩ号 １０．１１８９７／ＳＰ．Ｊ．１０１６．２０１８．０１６１９
Ｓｕｒｖｅｙ ｏｎ Ｄｅｅｐ Ｌｅａｒｎｉｎｇ Ｂａｓｅｄ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ
ＨＵＡＮＧ Ｌｉ－Ｗｅｉ １） ＪＩＡＮＧ Ｂｉ－Ｔａｏ１） ＬＶ Ｓｈｏｕ－Ｙｅ１） ＬＩＵ Ｙａｎ－Ｂｏ１） ＬＩ Ｄｅ－Ｙｉ ２）
１）（Ｂｅｉｊｉｎｇ Ｉｎｓｔｉｔｕｔｅ ｏｆ Ｒｅｍｏｔｅ Ｓｅｎｓｉｎｇ，Ｂｅｉｊｉｎｇ １００１９２）
２）（Ｄｅｐａｒｔｍｅｎｔ ｏｆ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，Ｔｓｉｎｇｈｕａ Ｕｎｉｖｅｒｓｉｔｙ，Ｂｅｉｊｉｎｇ １０００８４）
Ａｂｓｔｒａｃｔ Ｗｉｔｈ ｔｈｅ ｅｖｅｒ－ｇｒｏｗｉｎｇ ｖｏｌｕｍｅ，ｃｏｍｐｌｅｘｉｔｙ ａｎｄ ｄｙｎａｍｉｃｉｔｙ ｏｆ ｏｎｌｉｎｅ ｉｎｆｏｒｍａｔｉｏｎ，
ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｈａｖｅ ｂｅｅｎ ａｎ ｅｆｆｅｃｔｉｖｅ ｋｅｙ ｓｏｌｕｔｉｏｎ ｔｏ ｈａｎｄｌｅ ｔｈｅ ｉｎｃｒｅａｓｉｎｇ ｉｎｆｏｒｍａｔｉｏｎ
ｏｖｅｒｌｏａｄ ｐｒｏｂｌｅｍ ｂｙ ｒｅｔｒｉｅｖｉｎｇ ｔｈｅ ｍｏｓｔ ｒｅｌｅｖａｎｔ ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ ｓｅｒｖｉｃｅｓ ｆｒｏｍ ａ ｈｕｇｅ ａｍｏｕｎｔ ｏｆ
ｄａｔａ，ａｎｄ ｐｒｏｖｉｄｉｎｇ ｐｅｒｓｏｎａｌｉｚｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．Ｉｎ ｒｅｃｅｎｔ ｙｅａｒｓ，ｄｅｅｐ ｌｅａｒｎｉｎｇ ｔｅｃｈｎｏｌｏｇｙ ｈａｓ
ｂｅｃｏｍｅ ａｎ ｉｍｐｏｒｔａｎｔ ｒｅｓｅａｒｃｈ ｄｉｒｅｃｔｉｏｎ ｉｎ ｔｈｅ ｆｉｅｌｄ ｏｆ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ，ｗｈｉｃｈ ｈａｓ ｂｅｅｎ ｗｉｄｅｌｙ
ａｐｐｌｉｅｄ ｉｎ ｔｈｅ ｉｍａｇｅ ｐｒｏｃｅｓｓｉｎｇ，ｎａｔｕｒａｌ ｌａｎｇｕａｇｅ ｕｎｄｅｒｓｔａｎｄｉｎｇ，ｓｐｅｅｃｈ ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｏｎｌｉｎｅ
ａｄｖｅｒｔｉｓｉｎｇ．Ｍｅａｎｗｈｉｌｅ，ｒｅｃｅｎｔ ｓｔｕｄｉｅｓ ａｌｓｏ ｄｅｍｏｎｓｔｒａｔｅ ｉｔｓ ｅｆｆｅｃｔｉｖｅｎｅｓｓ ｉｎ ｃｏｐｉｎｇ ｗｉｔｈ ｉｎｆｏｒｍａｔｉｏｎ
ｒｅｔｒｉｅｖａｌ ａｎｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｔａｓｋｓ．Ａｐｐｌｙｉｎｇ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｔｅｃｈｎｉｑｕｅｓ ｉｎｔｏ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ
ｈａｓ ｂｅｅｎ ｇａｉｎｉｎｇ ｍｏｍｅｎｔｕｍ ｄｕｅ ｔｏ ｉｔｓ ｓｔａｔｅ－ｏｆ－ｔｈｅ－ａｒｔ ｐｅｒｆｏｒｍａｎｃｅｓ ａｎｄ ｈｉｇｈ－ｑｕａｌｉｔｙ ｒｅｃｏｍｍｅｎ－
ｄａｔｉｏｎｓ．Ｉｎ ｔｈｉｓ ｐａｐｅｒ，ｗｅ ｉｎｖｅｓｔｉｇａｔｅ ｔｈｅ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ，ｆｏｒ ｗｈｉｃｈ
ｔｈｅ ｍａｉｎ ｔａｓｋｓ ａｒｅ ｈｏｗ ｔｏ ｏｒｇａｎｉｚｅ ｔｈｅ ｍａｓｓｉｖｅ ｍｕｌｔｉ－ｓｏｕｒｃｅ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｄａｔａ，ｂｕｉｌｄ ｍｏｒｅ
ｓｕｉｔａｂｌｅ ｕｓｅｒ ｍｏｄｅｌｓ ａｃｃｏｒｄｉｎｇ ｔｏ ｕｓｅｒ ｐｒｅｆｅｒｅｎｃｅｓ ｒｅｑｕｉｒｅｍｅｎｔｓ，ａｎｄ ｉｍｐｒｏｖｅ ｔｈｅ ｐｅｒｆｏｒｍａｎｃｅ
ａｎｄ ｕｓｅｒ ｓａｔｉｓｆａｃｔｉｏｎ．Ｆｏｒ ｓｐｅｃｉｆｉｃ，ｗｅ ｆｉｒｓｔ ｉｎｔｒｏｄｕｃｅ ｔｈｅ ｂａｓｉｃ ｃｏｎｃｅｐｔｓ ａｎｄ ｍｅｔｈｏｄｓ ｏｆ ｔｒａｄｉｔｉｏｎａｌ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍｓ，ｉｎｃｌｕｄｉｎｇ ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄ，ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ
ａｎｄ ｈｙｂｒｉｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄ，ａｎｄ ｔｈｅｎ ｗｅ ｇｉｖｅ ａｎ ｏｖｅｒｖｉｅｗ ｏｆ ｔｈｅ ｍａｉｎ ｄｅｅｐ ｌｅａｒｎｉｎｇ
ｔｅｃｈｎｉｑｕｅｓ ａｎｄ ｂｒｉｅｆｌｙ ｉｎｔｒｏｄｕｃｅ ｔｈｅｉｒ ａｐｐｌｉｃａｔｉｏｎｓ ｉｎ ｔｈｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ．Ａｎｄ ｓｅｃｏｎｄｌｙ，
ｗｅ ｐｒｏｖｉｄｅ ａ ｃｏｍｐｒｅｈｅｎｓｉｖｅ ｓｕｍｍａｒｙ ｏｆ ｃｕｒｒｅｎｔ ｒｅｓｅａｒｃｈ ｏｎ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ
ｓｙｓｔｅｍｓ．Ａｃｃｏｒｄｉｎｇ ｔｏ ｔｈｅ ｄａｔａ ｓｏｕｒｃｅｓ ｕｓｅｄ ｉｎ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ａｎｄ ｔｈｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｏｆ ｔｈｅ
收稿日期：２０１７－０５－１８；在线出版日期：２０１８－０３－０５．本课题得到国家“九七三”重点基础研究发展计划项目基金（２０１４ＣＢ３４０４０４）、国家自
然科学基金重大研究计划（９１６３８３０１）、国家自然科学基金（６１２７２１１１，６１２７３２１６，６１６００１１９５０）资助．黄立威，男，１９８５年生，博士，中国计
算机学会（ＣＣＦ）会员，主要研究方向为机器学习、推荐系统．Ｅ－ｍａｉｌ：ｄｒ＿ｈｕａｎｇｌｗ＠１６３．ｃｏｍ．江碧涛，女，１９６７年生，博士，研究员，主要研
究领域为数据挖掘．吕守业，男，１９７９年生，博士，研究员，主要研究领域为数据挖掘．刘艳博，女，１９８８年生，硕士，工程师，主要研究方向
为图像处理、机器学习．李德毅，男，１９４４年生，博士，研究员，中国工程院院士，主要研究领域为人工智能． １６２０ 计 算 机 学 报 ２０１８年
ｔｒａｄｉｔｉｏｎａｌ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ，ｗｅ ｃａｔｅｇｏｒｉｚｅ ｔｈｅ ｃｕｒｒｅｎｔ ｒｅｓｅａｒｃｈ ｉｎｔｏ ｆｉｖｅ ｍａｉｎ ｄｉｒｅｃｔｉｏｎｓ：
ｔｈｅ ａｐｐｌｉｃａｔｉｏｎ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｉｎ ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ，ｔｈｅ ａｐｐｌｉｃａｔｉｏｎ ｏｆ ｄｅｅｐ
ｌｅａｒｎｉｎｇ ｉｎ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ，ｔｈｅ ａｐｐｌｉｃａｔｉｏｎ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｉｎ ｈｙｂｒｉｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ，
ｔｈｅ ａｐｐｌｉｃａｔｉｏｎ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｉｎ ｓｏｃｉａｌ ｎｅｔｗｏｒｋ－ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ，ａｎｄ ｔｈｅ ａｐｐｌｉｃａｔｉｏｎ
ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｉｎ ｃｏｎｔｅｘｔ－ａｗａｒｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ．Ｔｈｅｎ，ｗｅ ａｎａｌｙｚｅ ｔｈｅ ｄｉｆｆｅｒｅｎｃｅｓ ａｎｄ
ａｄｖａｎｔａｇｅｓ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｃｏｍｐａｒｅｄ ｗｉｔｈ ｔｈｅ ｔｒａｄｉｔｉｏｎａｌ ｒｅｃｏｍｍｅｎｄｅｒ
ｓｙｓｔｅｍｓ．Ｆｉｒｓｔ，ｂｙ ｕｓｉｎｇ ｄｅｅｐ ｌｅａｒｎｉｎｇ，ｃｏｍｐｌｅｘ ｆｅａｔｕｒｅ ｅｎｇｉｎｅｅｒｉｎｇ ｃａｎ ｂｅ ａｖｏｉｄｅｄ，ｅｓｐｅｃｉａｌｌｙ
ｗｈｅｎ ｆａｃｅｄ ｗｉｔｈ ｕｎｓｔｒｕｃｔｕｒｅｄ ｄａｔａ ｓｕｃｈ ａｓ ｉｍａｇｅ ａｎｄ ｖｉｄｅｏ．Ｓｅｃｏｎｄ，ｄｅｅｐ ｌｅａｒｎｉｎｇ ｃａｎ ｌｅａｒｎ ｔｈｅ
ｍｕｌｔｉ－ｌｅｖｅｌ ａｎｄ ａｂｓｔｒａｃｔ ｆｅａｔｕｒｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｏｆ ｕｓｅｒｓ ａｎｄ ｉｔｅｍｓ，ａｎｄ ｉｓ ａｂｌｅ ｔｏ ｅｆｆｅｃｔｉｖｅｌｙ ｃａｐｔｕｒｅ
ｔｈｅ ｎｏｎ－ｌｉｎｅａｒ ａｎｄ ｎｏｎ－ｔｒｉｖｉａｌ ｕｓｅｒ－ｉｔｅｍ ｉｎｔｅｒａｃｔｉｏｎｓ．Ｔｈｉｒｄ，ｄｅｅｐ ｌｅａｒｎｉｎｇ ｃａｎ ｉｎｃｏｒｐｏｒａｔｅ ｖａｒｉｏｕｓ
ｍｕｌｔｉ－ｓｏｕｒｃｅ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｄａｔａ ｉｎｔｏ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ，ａｎｄ ｈｅｌｐ ｔｏ ｍｉｔｉｇａｔｅ ｔｈｅ ｄａｔａ ｓｐａｒｓｅｎｅｓｓ
ｐｒｏｂｌｅｍ ｃｏｎｓｉｄｅｒａｂｌｙ．Ｆｉｎａｌｌｙ，ｔｈｉｓ ｐａｐｅｒ ｓｕｍｍａｒｉｚｅｓ ｔｈｅ ｆｕｔｕｒｅ ｄｅｖｅｌｏｐｍｅｎｔ ｔｒｅｎｄ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ
ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ，ｅ．ｇ．，ｔｈｅ ｃｏｍｂｉｎａｔｉｏｎ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ａｎｄ ｔｒａｄｉｔｉｏｎａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ
ｍｅｔｈｏｄｓ，ｔｈｅ ａｐｐｌｉｃａｔｉｏｎ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｉｎ ｃｒｏｓｓ ｄｏｍａｉｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ，ｔｈｅ ｃｏｍｂｉｎａｔｉｏｎ ｏｆ
ｔｈｅ ａｔｔｅｎｔｉｏｎ ｍｅｃｈａｎｉｓｍ ａｎｄ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ，ｎｅｗ ｄｅｅｐ ｌｅａｒｎｉｎｇ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｒｃｈｉｔｅｃｔｕｒｅｓ ａｎｄ ｔｈｅ ｉｎｔｅｒｐｒｅｔａｂｉｌｉｔｙ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ
ｓｙｓｔｅｍｓ．Ｉｎ ｓｈｏｒｔ，ｄｅｅｐ ｌｅａｒｎｉｎｇ ｈａｓ ｂｅｃｏｍｅ ｐｏｐｕｌａｒ ｉｎ ｔｈｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｃｏｍｍｕｎｉｔｙ
ｂｏｔｈ ｉｎ ａｃａｄｅｍｉａ ａｎｄ ｉｎ ｉｎｄｕｓｔｒｙ．Ｍｅａｎｗｈｉｌｅ，ｔｈｉｓ ａｒｅａ ｏｆ ｒｅｓｅａｒｃｈ ｉｓ ｖｅｒｙ ｙｏｕｎｇ，ｔｈｅｒｅ ｉｓ ｍｕｃｈ
ｒｏｏｍ ｆｏｒ ｉｍｐｒｏｖｅｍｅｎｔ ｉｎ ｔｈｅ ａｆｏｒｅｍｅｎｔｉｏｎｅｄ ｒｅｓｅａｒｃｈ ｄｉｒｅｃｔｉｏｎｓ，ｂｕｔ ｗｅ ａｌｓｏ ｂｅｌｉｅｖｅ ｔｈａｔ ｄｅｅｐ
ｌｅａｒｎｉｎｇ ｗｉｌｌ ｒｅｖｏｌｕｔｉｏｎｉｚｅ ｔｈｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｄｒａｍａｔｉｃａｌｌｙ ａｎｄ ｂｒｉｎｇ ｍｏｒｅ ｏｐｐｏｒｔｕｎｉｔｉｅｓ ｉｎ
ｒｅｉｎｖｅｎｔｉｎｇ ｔｈｅ ｕｓｅｒ ｅｘｐｅｒｉｅｎｃｅｓ ｆｏｒ ｂｅｔｔｅｒ ｃｕｓｔｏｍｅｒ ｓａｔｉｓｆａｃｔｉｏｎ ｉｎ ｔｈｅ ｎｅａｒ ｆｕｔｕｒｅ．
Ｋｅｙｗｏｒｄｓ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ；ｄｅｅｐ ｌｅａｒｎｉｎｇ；ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ；ｐｅｒｓｏｎａｌｉｚｅｄ ｓｅｒｖｉｃｅｓ；
ｄａｔａ ｍｉｎｉｎｇ；ｍｕｌｔｉ－ｓｏｕｒｃｅ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｄａｔａ
（如Ａｍａｚｏｎ、ｅＢａｙ、Ｎｅｔｆｌｉｘ、阿里巴巴等）、信息检索
１ 引 言 （如ｉＧｏｏｇｌｅ、ＭｙＹａｈｏｏ、百度等）、社交网络（Ｆａｃｅ－
ｂｏｏｋ、Ｔｗｉｔｔｅｒ、腾讯等）、位置服务（如Ｆｏｕｒｓｑｕａｒｅ、
近年来，随着云计算、大数据、物联网等技术的 Ｙｅｌｐ、大众点评等）、新闻推送（如 Ｇｏｏｇｌｅ Ｎｅｗｓ、
迅猛发展，互联网空间中各类应用的层出不穷引发 ＧｒｏｕｐＬｅｎｓ、今日头条等）等各个领域．
了数据规模的爆炸式增长［１］．根据国际数据集团 传统的推荐方法主要包括协同过滤、基于内容
（ＩＤＣ）２０１２年的一份报告显示：到２０２０年，预计全 的推荐方法和混合推荐方法．其中，最经典的算法是
球数据总量是２０１１年的２２倍，将达到３５．２ＺＢ［２］． 协同过滤，如矩阵因子分解，其利用用户与项目之间
大数据中蕴含着丰富的价值与巨大的潜力，将给人 的交互信息为用户进行推荐，协同过滤是目前应用
类社会带来变革性的发展，但同时也带来了严重的 最为广泛的推荐算法，近年来在Ｎｅｔｆｌｉｘ大奖赛中屡
“信息过载”问题，如何快速有效地从纷繁复杂的数 获大奖，但是同时也遭遇到了严重的数据稀疏（一个
据中获取有价值的信息成为了当前大数据发展的关 用户评分过的项目仅仅占总项目数量的极少部分）
键难题．推荐系统作为解决“信息过载”问题的有效 和冷启动（新的用户和新的项目往往没有评分数据）
方法［３］，已经成为学术界和工业界的关注热点并得 问题．此外，经典的协同过滤方法采用浅层模型无法
到了广泛应用，形成了众多相关研究成果．推荐系统 学习到用户和项目的深层次特征．基于内容的推荐
根据用户需求、兴趣等，通过推荐算法从海量数据中 方法利用用户已选择的项目来寻找其它类似属性的
挖掘出用户感兴趣的项目（如信息、服务、物品等）， 项目进行推荐，但是这种方法需要有效的特征提取，
并将结果以个性化列表的形式推荐给用户．目前，推 传统的浅层模型依赖于人工设计特征，其有效性及
荐系统在很多领域得到了成功应用，包括电子商务 可扩展性非常有限，制约了基于内容的推荐方法的 ７期 黄立威等：基于深度学习的推荐系统研究综述 １６２１
性能．随着互联网中越来越多的数据能够被感知获 关注．推荐系统的核心是推荐算法，它利用用户与项
取，包括图像、文本、标签在内的多源异构数据蕴含 目之间的二元关系，基于用户历史行为记录或相似
着丰富的用户行为信息及个性化需求信息，融合多 性关系帮助发现用户可能感兴趣的项目．文献［３］给
源异构辅助信息（ｓｉｄｅ ｉｎｆｏｒｍａｔｉｏｎ）的混合推荐方法 出了推荐算法的形式化定义：用Ｕ表示所有用户
由于能够缓解传统推荐系统中的数据稀疏和冷启动 （ｕｓｅｒ）的集合，用Ｉ表示所有项目（ｉｔｅｍ）的集合．在
问题，而越来越受到重视，但是由于辅助信息往往具 实际系统中，Ｕ和Ｉ具有非常大的规模．定义一个效
有多模态、数据异构、大规模、数据稀疏和分布不均 用函数ｓ，用来计算项目ｉ对用户ｕ的推荐度，即ｓ：
匀等复杂特征，融合多源异构数据的混合推荐方法 Ｕ×Ｉ→Ｒ，其中Ｒ是一个全序集合（在一定范围内
研究依然面临着严峻的挑战［４－５］． 非负的整数或实数），推荐算法的研究问题就是通过
近年来，深度学习在图像处理、自然语言理解和 计算推荐度为每一个用户ｕ∈Ｕ找到其最感兴趣的
语音识别等领域取得了突破性进展［６］，已经成为人 项目ｉ′∈Ｉ，如下：
工智能的一个热潮，为推荐系统的研究带来了新的 ｕ∈Ｕ，ｉ′ ｕ＝ａｒｇ ｍａｘｓ（ｕ，ｉ） （１）
ｉ∈Ｉ
机遇．一方面，深度学习可通过学习一种深层次非线
推荐系统中的用户和项目都可以通过一组不
性网络结构，表征用户和项目相关的海量数据，具有
同的属性或特征来进行表示．推荐系统面临的一
强大的从样本中学习数据集本质特征的能力，能够
个关键问题是效用函数ｓ通常定义在Ｕ×Ｉ的一个
获取用户和项目的深层次特征表示．另一方面，深度 子空间上，推荐算法必须将ｓ外推到整个Ｕ×Ｉ空
学习通过从多源异构数据中进行自动特征学习，从 间．例如，我们通常将推荐度定义为用户对项目的
而将不同数据映射到一个相同的隐空间，能够获得 评分，但真实的推荐系统中，用户仅仅评分了一小
数据的统一表征［７］，在此基础上融合传统推荐方法 部分项目，因此在选择推荐度最高的项目推荐给
进行推荐，能够有效利用多源异构数据，缓解传统推 用户之前，必须先根据已知的评分来实现对未知
荐系统中的数据稀疏和冷启动问题．近三年来，基于 评分的预测，这就是外推的过程．推荐算法对未知
深度学习的推荐系统研究开始受到国际学术界和工 评分的预测能够采用不同的方法，包括近似理论、
业界越来越多的关注，ＡＣＭ 推荐系统年会（ＡＣＭ 机器学习和各种启发式方法等．但是传统的推荐
ＲｅｃＳｙｓ）在２０１６年专门召开了第一届基于深度学 方法主要可以分为以下３种［２２］：基于内容的推荐
习的推荐系统研究专题研讨会（ＤＬＲＳ’１６），研讨会 （ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ）［２３］、协同过滤推荐
指出深度学习将是推荐系统的下一个重要方向 ， （ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ）［２４］和混合
ＤＬＲＳ’１７也已经在意大利的科莫举行．计算机领域 推荐（ｈｙｂｒｉｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ）［２５］．
的数据挖掘和机器学习顶级会议（ＳＩＧＫＤＤ，ＮＩＰＳ， （１）基于内容的推荐．主要根据用户已经选择
ＳＩＧＩＲ，ＷＷＷ，ＡＡＡＩ等）中，基于深度学习的推荐 或者评分的项目，挖掘其它内容上相似的项目作为
系统研究的文章逐年增加，国内外许多大学和研究 推荐，属于Ｓｃｈａｆｅｒ划分［２６］中的项目到项目关联
机构也对基于深度学习的推荐系统开展了广泛研 （Ｉｔｅｍ－ｔｏ－Ｉｔｅｍ Ｃｏｒｒｅｌａｔｉｏｎ）的方法．首先通过显式
究［８－２０］．基于深度学习的推荐系统研究目前已经成 反馈（例如评分、喜欢／不喜欢）或隐式反馈（例如观
为推荐系统领域的研究热点之一． 看、搜索、点击、购买等行为）的方式获取用户交互过
本文主要对基于深度学习的推荐系统的研究与 的项目，然后从这些项目的特征中学习用户的偏好
应用进展进行综述．第２节简要介绍传统的推荐算 并表示为特征，就能计算用户与待预测项目在内容
法；第３节介绍了深度学习的主要方法；第４节重点 （由特征刻画）上的匹配度（或相似度），最后根据匹
分析基于深度学习的推荐系统的研究进展；第５节 配度对所有待预测项目进行排序，从而为用户推荐
展望基于深度学习的推荐系统的未来研究趋势；第 潜在感兴趣的项目．基于内容的推荐方法依赖于关
６节是全文总结． 于用户偏好和项目的特征信息，不需要大量的评分
记录，因此不存在评分数据稀疏的问题．同时，对于
２ 传统推荐系统 新项目，只需要进行特征提取就可以向用户进行推
荐，解决了新项目的冷启动问题，但常常会遭遇到特
２０世纪９０年代，协同过滤技术［２１］的首次提出， 征提取困难的问题．
标志着推荐系统成为了一门独立的学科而受到广泛 （２）协同过滤推荐．源于现实生活中口碑相传 １６２２ 计 算 机 学 报 ２０１８年
（ｗｏｒｄ－ｏｆ－ｍｏｕｔｈ）的过程，协同过滤利用相似用户之 一个热潮［２７］．深度学习通过组合低层特征形成更加
间具有相似兴趣偏好的方法，来发现用户对项目的 稠密的高层语义抽象，从而自动发现数据的分布式
潜在偏好．主要包括启发式和基于模型两种类型，启 特征表示，解决了传统机器学习中需要人工设计特
发式方法首先通过用户的历史评分差异计算用户 征的问题，在图像识别、机器翻译、语音识别和在线
（或者项目）之间的相似度，然后根据用户的历史评 广告等领域取得了突破性进展．图像识别领域，在
分和用户之间的相似度计算效用值，基于模型的方 ２０１６年的ＩｍａｇｅＮｅｔ图像分类竞赛中，深度学习的
法主要通过构建一个用户偏好模型预测用户对项目 准确率超过了９７％．在机器翻译领域，基于深度学
的潜在偏好．协同过滤仅仅需要利用用户的历史评 习的Ｇｏｏｇｌｅ神经机器翻译系统（ＧＮＭＴ）在英语与
分数据，因此简单有效，是目前应用最为成功的推荐 西班牙语和英语与法语的翻译中都取得了接近于
方法．但是，由于用户对项目的评分数据相对项目的 人类的翻译水平［２８］．在语音识别领域，２０１６年年
总数量非常少，常常遭遇数据稀疏的问题，此外，对 底百度、科大讯飞和搜狗都宣布，他们基于深度学
于新的用户或项目，由于没有评分数据而无法进行 习的中文语音识别准确率都超过了９７％．在线广
推荐，存在冷启动问题． 告领域，深度学习被广泛应用于广告点击率预测，在
（３）混合推荐．考虑到单一推荐方法都存在各 Ｇｏｏｇｌｅ［９，２９］、微软［３０，３１］、华为［３２］、阿里巴巴［３３］等企业
自的不足，通过组合不同的推荐算法进行混合推荐， 的应用中取得了很大成功．深度学习涉及相当广泛
往往能够产生更好的推荐性能．常见的组合策略主 的机器学习技术和结构，下面我们对常用的深度学
要包括３种，分别为后融合、中融合和前融合．后融 习模型和方法进行介绍
合是指将两种或两种以上的推荐算法产生的推荐结 ３．１ 自编码器
果，以投票机制、线性组合或者可信度选择组合等方 １９８６年 Ｗｉｌｌｉａｍｓ等人［３４］提出了自编码器（Ａｕ－
式来产生最终的推荐结果，本质上是决策层面上的 ｔｏｅｎｃｏｄｅｒ，ＡＥ）的概念，并将其用于高维复杂数据
混合．中融合的基本框架是以一种推荐算法为基础， 处理．自编码器通过一个编码和一个解码过程来重
同时融合另一种推荐算法，例如：以协同过滤算法为 构输入数据，学习数据的隐层表示．基本的自编码器
框架，融入基于内容的推荐算法可以有效缓解数据
可视为一个三层神经网络结构：一个输入层ｘ、一个
稀疏问题，本质上是模型层面上的混合．前融合则是
隐层ｈ和一个输出层ｙ，其中输出层和输入层具有
直接将多种推荐算法融合到统一的模型中，然后从
相同的规模，结构如图１所示．
各类数据中提取的特征作为模型的输入，由统一的
模型产生推荐结果，例如，将所有用户属性、用户行
为等数据作为输入，通过训练一个统一的分类器产
生推荐结果，本质上是特征层面的融合．
需要注意的是，随着社交媒体的迅速发展，大量
的用户生成内容（如社会化关系、标签、评论、位置信
息）能够被获取，推荐系统的内容更加多样，包括商
品、朋友、标签、音乐、视频、新闻等；同时，除了传统
的推荐方法，也催生了大量新的推荐方法，例如，基
于社交网络的推荐方法、情境感知的推荐方法等；推
图１ 自编码器结构示意图
荐的对象也更加多样，不仅仅针对单个用户，还可以
针对一群用户，产生了组推荐；随着移动互联网的发 自编码器的目的是使得输入ｘ与输出ｙ尽可能
展，位置社交网络的推荐系统也受到越来越多的关
接近，这种接近程度通过重构误差表示，根据数据的
注．因此可以发现，推荐系统在推荐内容、推荐方法、
不同形式，通常重构误差有均方误差和交叉熵两种
推荐对象等各个方面都朝着越来越多元的方向发展．
定义方式．
如果仅仅通过最小化输入输出之间的误差来实
３ 深度学习技术 现对模型的训练，自编码器很容易学习到一个恒等
函数．为了解决这个问题，研究者提出了一系列自编
码器的变种，其中比较经典的包括稀疏自编码器［３５］
深度学习已经成为互联网大数据和人工智能的 ７期 黄立威等：基于深度学习的推荐系统研究综述 １６２３
和降噪自编码器［３５］．通过在损失函数中加入Ｌ１正 从ＲＢＭ的结构可以发现，在给定隐层单元的状
则项，便可以训练得到稀疏自编码器，其目的是对过 态时，可见层单元之间是条件独立的；反之，在给定可
大的权重进行惩罚，使隐层表示中的大量节点为０， 见层单元的状态时，各隐层单元之间也条件独立．因
从而确保隐层表示尽量稀疏．降噪自编码器则是通 此，尽管无法有效计算ＲＢＭ 所表示的分布，但是通
过在自动编码器的输入数据中加入噪声得到，这样 过Ｇｉｂｂｓ采样能够得到ＲＢＭ 所表示的分布的随机
降噪自编码器在重构输入数据时，就被迫去除这种 样本．Ｇｉｂｂｓ采样的问题是需要使用较大的采样步
噪声来学习到更加鲁棒的输入数据的表达，降噪自 数，使得 ＲＢＭ 的训练效率仍不高．考虑到这种情
编码器通过这种方式提升了泛化能力．２００７年，
况，Ｈｉｎｔｏｎ［４５］提出了一种对比散度（Ｃｏｎｔｒａｓｔｉｖｅ
Ｂｅｎｇｉｏ等人［３６］通过堆叠多个降噪自编码器，提出了 Ｄｉｖｅｒｇｅｎｃｅ，ＣＤ）快速学习算法，ＣＤ算法同样利用
栈式降噪自动编码器（Ｓｔａｃｋｅｄ Ｄｅｎｏｉｓｉｎｇ Ａｕｔｏｅｎ－
Ｇｉｂｂｓ采样过程（即每次迭代包括从可见层更新隐
层，以及从隐层更新可见层）来获得随机样本，但是
ｃｏｄｅｒ，ＳＤＡＥ）的概念，其是一种深度神经网络结构，
只需迭代ｋ（通常ｋ＝１）次就可获得对模型的估计，
通过逐层非监督学习的预训练可以学习多层次的数
而不需要像Ｇｉｂｂｓ采样一样直到可见层和隐层达到
据抽象表示．
平稳分布．
自编码器，尤其是栈式降噪自编码器，在推荐系
ＲＢＭ是推荐系统中最早被应用的神经网络模
统中主要被应用于学习用户和项目的隐层特征表
型［４６－５０］，当前的应用主要是通过对用户的评分数据
示［４－５，１７，２０，３７－４２］，其通过对用户或项目相关的信息（包
进行重构学习到用户的隐表示，从而实现对未知评
括评分数据和文本、图像等信息）进行重构学习到用
分的预测．应用场景主要是用户评分预测．
户或项目的隐表示，然后基于这种隐表示预测用户
３．３ 深度信念网络
对项目的偏好．应用场景主要包括评分预测、文本推
Ｈｉｎｔｏｎ等人在２００６年提出了一种深度信念网
荐、图像推荐等．
络（Ｄｅｅｐ Ｂｅｌｉｅｆ Ｎｅｔｗｏｒｋ，ＤＢＮ）［５１］，其是一种由多
３．２ 受限玻尔兹曼机
层非线性变量连接组成的生成式模型．在深度信念
玻尔兹曼机（Ｂｏｌｔｚｍａｎｎ Ｍａｃｈｉｎｅ，ＢＭ）［４３］是一
网络中，靠近可见层的部分是多个贝叶斯信念网络，
种生成式随机神经网络，由 Ｈｉｎｔｏｎ和Ｓｅｊｎｏｗｓｋｉ在
最远离可见层的部分则是一个 ＲＢＭ，其结构如图３
１９８６年提出，ＢＭ由一些可见单元（对应可见变量，
所示．ＤＢＮ的结构可以看作由多个受限玻尔兹曼机
亦即数据样本）和一些隐层单元（对应隐层变量）构
层叠构成，网络中前一个ＲＢＭ 的隐层视为下一个
成，可见变量和隐层变量都是二元变量，其状态取
ＲＢＭ 的可见层．这样，在ＤＢＮ的训练过程中，每一
０－１，状态０表示该神经元处于抑制状态，状态１代
个ＲＢＭ都可以使用上一个ＲＢＭ的输出单独训练，
表该神经元处于激活状态．ＢＭ 能够学习数据中复 因此与传统的神经网络相比，ＤＢＮ的训练更加简
杂的规则，具有强大的无监督学习能力．但是，玻尔
单．同时，通过这种训练方法，ＤＢＮ也能够从无标记
兹曼机的训练过程非常耗时．为此，Ｈｉｎｔｏｎ和
数据获取深层次的特征表示．
Ｓｅｊｎｏｗｓｋｉ［４３］进一步提出了一种受限玻尔兹曼机
（Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ Ｍａｃｈｉｎｅ，ＲＢＭ），其在玻尔
兹曼机的基础上，通过去除同层变量之间的所有连
接极大地提高了学习效率．受限玻尔兹曼机的结构
如图２所示，包括可见层ｖ以及隐层ｈ，两层之间的
节点是全连接的，同层节点间是互不连接的．
图３ 深度信念网络结构示意图
ＤＢＮ网络的训练可采用一种贪婪逐层算法［５２］．
首先，由最底层ＲＢＭ开始，通过对比散度算法从原
图２ 受限玻尔兹曼机结构示意图
始观测数据中学习第一层隐层单元的状态，然后将 １６２４ 计 算 机 学 报 ２０１８年
参数保存，将隐层单元的状态作为下一层ＲＢＭ 的 ＲＮＮ的最大特点在于神经网络各隐层之间的
输入，按照这种方式继续训练，直到整个深层结构训 节点是具有连接的，它能够通过获取输入层的输出
练完成． 和前一时刻的隐层状态来计算当前时刻隐层的输
深度信念网络当前在推荐系统中应用较少．由 出，也就是说ＲＮＮ能够对过去的信息进行记忆．理
于ＤＢＮ在建模一维数据上比较有效，因此被应用 论上来说，ＲＮＮ能够对任意长度的序列数据进行建
于提取音乐的特征表示，从而进行音乐推荐［５３］．当 模，但在实际应用中往往假设当前状态仅与前几个
前的应用场景仅限于音乐推荐． 时刻的历史状态相关，从而帮助降低模型的复杂度，
３．４ 卷积神经网络 图５是一个典型的ＲＮＮ结构，包含输入单元、输出
卷积神经网络（Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ， 单元和隐层单元．
ＣＮＮ）已成为当前图像理解领域的研究热点［５４－５６］．
卷积神经网络是一种多层感知机，主要被用来处理
二维图像数据．相比传统的多层感知机，ＣＮＮ使用
池化操作减少了模型中的神经元数量，同时对输入
空间的平移不变性具有更高的鲁棒性．另外，ＣＮＮ
的权值共享网络结构能够减少模型中参数数量，降
低了网络模型的复杂度，提升了模型的泛化能力．尤
其是当网络的输入是多维图像时，通过将图像直接
图５ 循环神经网络结构示意图
作为网络的输入，从而避免了传统图像处理算法中 将ＲＮＮ展开之后发现，它是一类所有层共享
复杂的特征提取和数据重建过程．卷积神经网络的 相同权值的深度前馈神经网络．但是，普通的ＲＮＮ
基本结构由输入层、卷积层、下采样层（池化层）、全 结构存在梯度消失问题，很难解决学习数据之间的
连接层和输出层构成，如图４所示． 长程依赖关系．针对这个问题，研究者相继提出了一
些ＲＮＮ的变种，其中最著名的包括 Ｈｏｃｈｒｅｉｔｅｒ等
人［６６］提出的长短时记忆网络（Ｌｏｎｇ Ｓｈｏｒｔ－Ｔｅｒｍ
Ｍｅｍｏｒｙ，ＬＳＴＭ）和Ｃｈｏ等人［６７］提出的门限循环单
元（Ｇａｔｅｄ Ｒｅｃｕｒｒｅｎｔ Ｕｎｉｔ，ＧＲＵ）．ＬＳＴＭ 和 ＧＲＵ
采用了特殊的隐层结构，通过增加保存长期状态的
隐层单元，能够更加有效地建模长程依赖关系，是目
图４ 卷积神经网络结构示意图
前应用最为广泛的循环神经网络模型．近几年，随着
卷积神经网络在推荐系统中应用较为广 深度学习的不断发展，通过增加更加广泛的记忆模
泛［５，５７－６２］，主要被用于从图像、文本、音频等内容中
块，研究者提出了记忆网络（Ｍｅｍｏｒｙ Ｎｅｔｗｏｒｋ）［６８］、
提取项目的隐藏特征，从而获取项目的低维向量表 栈式增强循环网络（Ｓｔａｃｋ－ａｕｇｍｅｎｔｅｄ Ｒｅｃｕｒｒｅｎｔ
示，并结合用户隐表示为用户产生推荐．当前的应用 Ｎｅｔ）［６９］、神经图灵机（Ｎｅｕｒａｌ Ｔｕｒｉｎｇ Ｍａｃｈｉｎｅｓ，
场景主要包括图像推荐、音乐推荐、文本推荐等． ＮＴＭ）［７０］和可 微 分神 经 计 算 机 （Ｄｉｆｆｅｒｅｎｔｉａｂｌｅ
３．５ 循环神经网络 Ｎｅｕｒａｌ Ｃｏｍｐｕｔｅｒ，ＤＮＣ）［７１］等模型来建模数据之间
１９８６年 Ｗｉｌｌｉａｍｓ等人［３４］提出循环神经网络 长程依赖关系．尤其是ＮＴＭ 等工作，通过将ＲＮＮ
（Ｒｅｃｕｒｒｅｎｔ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ，ＲＮＮ）的概念．普通的 与注意力机制进行结合，极大地发展了循环神经网
全连接网络或卷积神经网络，是从输入层到隐层再 络的研究与应用．
到输出层的结构，层与层之间是全连接的，每层之间 循环神经网络在推荐系统中的应用主要是用
的节点是无连接的．这种神经网络结构在面对序列 来建模数据之间的序列影响，从而帮助获取更有
数据建模时往往显得无能为力．例如，当需要预测句 效的用户和项目隐表示．主要包括两个方面：首先
子中下一个单词是什么的时候，一般需要依据前面 是被应用于建模推荐系统中用户行为的序列模
的单词．ＲＮＮ因为能够建模序列数据中不同时刻数 式［１０，１２，７２－７８］，其次是在获取用户和项目隐表示的过
据之间的依赖关系，在机器翻译［６３］、语音识别［６４］、图 程中，循环神经网络被应用于建模用户和项目相关
标标注生成［６５］等领域取得了广泛应用． 的文本信息中词语之间序列影响［４，３８］．当前的应用 ７期 黄立威等：基于深度学习的推荐系统研究综述 １６２５
场景主要包括评分预测、图像推荐、文本推荐、基于 对项目的评分或偏好；
位置社交网络中的兴趣点推荐等． （３）深度学习在混合推荐系统中的应用．利用
用户的显式反馈或隐式反馈数据、用户画像和项目
４ 基于深度学习的推荐系统 内容数据，以及各种类型的用户生成内容产生推荐，
模型层面主要是基于内容的推荐方法与协同过滤方
基于深度学习的推荐系统通常将各类用户和项 法的组合；
目相关的数据作为输入，利用深度学习模型学习到 （４）深度学习在基于社交网络的推荐系统中的
用户和项目的隐表示，并基于这种隐表示为用户产 应用．利用用户的显式反馈或隐式反馈数据、用户
生项目推荐．一个基本的架构如图６所示，包含输入 的社会化关系等各类数据，采用深度学习模型重点
层、模型层和输出层．输入层的数据主要包括：用户 建模用户之间的社会关系影响，更好地发现用户对
的显式反馈（评分、喜欢／不喜欢）或隐式反馈数据 项目的偏好；
（浏览、点击等行为数据）、用户画像（性别、年龄、喜 （５）深度学习在情景感知的推荐系统中的应
好等）和项目内容（文本、图像等描述或内容）数据、 用．利用用户的显式反馈或隐式反馈数据以及用户
用户生成内容（社会化关系、标注、评论等辅助数 的情境信息等各类数据，采用深度学习模型对用户
据）．在模型层，使用的深度学习模型比较广泛，包括 情境进行建模，发现用户在特定情境下的偏好．
自编码器、受限玻尔兹曼机、卷积神经网络、循环神 ４．１ 深度学习在基于内容的推荐系统中的应用
经网络等．在输出层，通过利用学习到的用户和项目 基于内容的推荐方法的性能严重依赖于有效的
隐表示，通过内积、Ｓｏｆｔｍａｘ、相似度计算等方法产 数据特征提取．深度学习的最大优势是能够通过一
生项目的推荐列表． 种通用的端到端的过程学习到数据的特征，自动获
取到数据的高层次表示，而不依赖于人工设计特征．
因此，深度学习在基于内容的推荐中主要被用于从
项目的内容信息中提取项目的隐表示，以及从用户
的画像信息以及历史行为数据中获取用户的隐表
示，然后基于隐表示通过计算用户和项目的匹配度
来产生推荐．在假设用户和项目携带辅助信息的情
况下，深度神经网络模型被作为有效的特征提取
工具．
４．１．１ 基于多层感知机的方法
深度结构化语义模型．Ｅｌｋａｈｋｙ等人［１１］考虑到
传统的基于内容的推荐系统中，用户特征难以获取
的问题，通过分析用户的浏览记录和搜索记录提取
图６ 基于深度学习的推荐系统框架 用户的特征，从而丰富用户的特征表示．作者将深度
本文通过充分调研当前深度学习在推荐系统研 结构化语义模型（Ｄｅｅｐ Ｓｔｒｕｃｔｕｒｅｄ Ｓｅｍａｎｔｉｃ Ｍｏｄｅｌｓ，
究中的应用情况，根据推荐系统中利用的数据类型
ＤＳＳＭ）［７９］进行扩展，提出了一种多视角深度神经网
并结合传统推荐系统的分类，将当前的研究主要分 络模型（Ｍｕｌｔｉ－Ｖｉｅｗ Ｄｅｅｐ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ，Ｍｕｌｔｉ－
为５个方向： Ｖｉｅｗ ＤＮＮ），该模型通过用户和项目两种信息实体
（１）深度学习在基于内容的推荐系统中的应 的语义匹配来实现用户的项目推荐，是一种实用性
用．利用用户的显式反馈或隐式反馈数据、用户画 非常强的基于内容的推荐方法．其基本思想是设置
像和项目内容数据，以及各种类型的用户生成内容， 两类映射通路，分别通过深度学习模型将两类信息
采用深度学习方法来学习用户与项目的隐向量，并 实体映射到同一个隐空间，在这个隐含空间中通过
将与用户访问过的项目相似的项目推荐给用户； 余弦相似度计算两个实体的匹配度，然后根据匹配
（２）深度学习在协同过滤中的应用．利用用户 度产生推荐．图７展示了一个 Ｍｕｌｔｉ－Ｖｉｅｗ ＤＮＮ的
的显式反馈或隐式反馈数据，采用深度学习方法学 通用示意图，在用户视角上，通过利用用户的搜索、
习用户或项目的隐向量，从而基于隐向量预测用户 浏览、下载、视频观看等历史记录作为输入ｘ ，通过
Ｕ １６２６ 计 算 机 学 报 ２０１８年
深度学习模型学习用户的隐表示ｙ，在项目视角 感知的个性化新闻推荐问题．通过在ＤＳＳＭ 中增加
Ｕ
上，通过利用项目的标题、类别、描述等信息作为 一个位置通道，利用 ＭＬＰ从用户信息、项目信息和
输入ｘ，通过深度学习模型学习项目的隐表示ｙ， 位置局部主题分布中学习用户、项目和位置的隐表
ｉ ｉ
模型共包括一个用户视角和Ｎ个项目视角，其中 示，最后联合３个方面的信息计算特定位置下用户
Ｎ为所有项目的数量，用户视角的深度神经网络 兴趣与新闻内容之间的关联度来产生新闻推荐．
模型为ｆ （ｘ，Ｗ ），第ｉ个项目视角的深度神经 深广学习模型．Ｃｈｅｎｇ等人［９］通过利用用户特
Ｕ Ｕ Ｕ
网络模型为ｆ ｉ（ｘ ｉ，Ｗ ｉ）．假设有 Ｍ 个样本｛（ｘ ｕ，ｊ， 征、情境特征和项目特征等多源异构数据，提出了一
ｘ ａ，ｊ）｝ ０ｊＭ，其中，（ｘ ｕ，ｊ，ｘ ａ，ｊ）表示用户ｕ和项目ａ 种深广学习（Ｗｉｄｅ＆Ｄｅｅｐ Ｌｅａｒｎｉｎｇ）模型，用于手机
之间的一次交互，通过拟合用户与项目的交互历史 ＡＰＰ推荐，模型同时具有了高的记忆（ｍｅｍｏｒｉｚａｔｉｏｎ）
进行参数学习： 能力和泛化（ｇｅｎｅｒａｌｉｚａｔｉｏｎ）能力．记忆主要依靠统
Ｍ ｅｃｏｓ（ｆＵ（ｘ Ｕ，ｊ，ＷＵ），ｆａ（ｘａ，ｊ，Ｗａ） 计方法，通过关联学习分析历史记录中的共现现象，
ａｒｇ ｍａｘ ∑ （２）
ＷＵ，Ｗ１，…，ＷＮｊ＝１ ∑ｅｃｏｓ（ｆＵ（ｘ Ｕ，ｊ，ＷＵ），ｆａ（ｘａ，ｊ，Ｗａ） 主要利用了相关性，不具有泛化性且需要手动特征
１ａＮ 工程．泛化需要研究关联的传递性，通过探索更多的
信息能够提升推荐的多样性．图８展示了一个深广
学习模型的通用示意图，这种模型联合训练一个宽
广线性模型（图中左侧）和一个深度神经网络（图中
右侧）来确保模型记忆能力和泛化能力的均衡．
图７ Ｍｕｌｔｉ－Ｖｉｅｗ ＤＮＮ的模型结构
图８ 深广学习模型的模型结构
在模型训练完成之后，基于模型学习到的用户
隐表示ｙ 和项目隐表示ｙ，通过在隐空间中计算用
类似于深广学习模型，Ｈｅ等人［８２］利用深度神
Ｕ ｉ
户和项目的相似度，选择相似度最高的ｋ个项目产 经网络采用非线性方式建模用户与项目之间的复杂
生推荐． 交互，提出一种神经协同过滤方法（Ｎｅｕｒａｌ Ｃｏｌｌａｂｏ－
Ｚｈｅｎｇ等人［１８］通过采用与ＤＳＳＭ相似的结构， ｒａｔｉｖｅ Ｆｉｌｔｅｒｉｎｇ，ＮＣＦ），将用户和项目的特征作为输
入，然后利用多层神经网络学习用户与项目之间的
考虑将评论信息融入到推荐系统中以缓解推荐系
统的数据稀疏问题，并提高推荐系统的质量，提出
交互函数．通过将ＮＣＦ结构进行实例化，得到一种
了一种深度协作神经网络模型（Ｄｅｅｐ Ｃｏｏｐｅｒａｔｉｖｅ
矩阵因子分解的泛化结构和一种多层感知机结构，
Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ，ＤｅｅｐＣｏＮＮ）．其主要思路是利用 分别可以建模用户与项目之间交互的线性和非线
两个并行的神经网络模型学习用户和项目的隐特
性特征，最后在ＮＣＦ框架下组合以上两种结构，提
征，一个网络通过用户的所有评论数据建模了用户 出一种神经矩阵因子分解模型（Ｎｅｕｒａｌ Ｍａｔｒｉｘ
的偏好，另一个网络通过项目的所有评论信息建模 Ｆａｃｔｏｒｉｚａｔｉｏｎ Ｍｏｄｅｌ，ＮｅｕＭＦ），在建模用户与项目
项目的特征，然后在两个神经网络上面构建一个交 的交互中组合了矩阵因子分解的线性特征和深度神
互层来预测用户对项目的评分．该方法通过利用用 经网络的非线性特征．
户评论的文本内容信息，有效提升了推荐的质量． 基于 ＭＬＰ的广告点击率预测．多层感知机模
Ｘｕ等人［８０］基于ＤＳＳＭ模型研究了标签感知的个性 型目前在广告点击率预测问题中得到了广泛应用．
化推荐问题，分别利用用户的所有标签和项目的所 Ｗｅｂ领域中的输入特征通常是离散和稀疏的，为了
有标签定义用户和项目的输入特征，从而学习用户 有效建模这类数据，学习特征之间的交互至关重
和项目的隐表示，通过计算用户隐表示和项目隐表 要［８１，８３］．其中一种思路是利用 ＭＬＰ直接学习特征
示的相似度来产生推荐．Ｃｈｅｎ等人［８１］研究了位置 之间的交互，例如 Ｗｉｄｅ＆Ｄｅｅｐ［９］、Ｄｅｅｐ Ｃｒｏｓｓｉｎｇ［３０］、 ７期 黄立威等：基于深度学习的推荐系统研究综述 １６２７
Ｄｅｅｐ＆Ｃｒｏｓｓ［２９］、ＤＥＦ［３１］和 ＤＩＮ［３３］．另一种思路是 化机和深度神经网络建模低层次和高层次的特征交
结合因子化机［８３］与 ＭＬＰ，首先利用因子化机建模 互，相比 Ｗｉｄｅ＆Ｄｅｅｐ，ＤｅｅｐＦＭ 不需要进行人工的
特征之间的成对交互，然后通过增加全连接层来进 特征工程处理．Ｈｅ等人［８５］研究了稀疏数据输入情
一步建模高阶的特征交互，例如 ＰＮＮ［８４］、Ｄｅｅｐ－ 况下的推荐问题，基于因子化机模型提出了一种神
ＦＭ［３２］、ＮＦＭ［８５］和ＡＦＭ［８６］． 经因子化机模型（Ｎｅｕｒａｌ Ｆａｃｔｏｒｉｚａｔｉｏｎ Ｍａｃｈｉｎｅ，
Ｓｈａｎ等人［３０］提出了一种Ｄｅｅｐ Ｃｒｏｓｓｉｎｇ模型 ＮＦＭ），能够实现特征之间的高层次非线性交互，从
用于广告点击率预测．Ｄｅｅｐ Ｃｒｏｓｓｉｎｇ的模型结构如 而提升预测能力．该模型与深广模型的最大区别是，
图９所示，是由一个嵌入层、一个堆栈层、一个残差 其在特征嵌入层之上增加了一个双线性交互池化操
单元和一个评分层组成的多层感知机．Ｗａｎｇ等 作．相比深广学习模型，神经因子化机模型在使用
人［２９］基于Ｄｅｅｐ Ｃｒｏｓｓｉｎｇ，提出了一个Ｄｅｅｐ＆Ｃｒｏｓｓ 更少隐层的情况下获得了更好的预测性能，而且因
网络模型用户广告点击率预测．Ｄｅｅｐ＆Ｃｒｏｓｓ同时 为参数更少，训练更加容易．Ｘｉａｏ等人［８６］通过扩展
在输入特征上采用一个深度网络（Ｄｅｅｐ Ｎｅｔｗｏｒｋ） ＮＦＭ模型，提出了一种注意力因子化机模型
和交叉网络（Ｃｒｏｓｓ Ｎｅｔｗｏｒｋ），然后组合两部分输出 （Ａｔｔｅｎｔｉｏｎａｌ Ｆａｃｔｏｒｉｚａｔｉｏｎ Ｍａｃｈｉｎｅ，ＡＦＭ），通过将
进行预测．Ｄｅｅｐ＆Ｃｒｏｓｓ同时集成了深度神经网络 注意力机制引入双线性交互池化操作中，提升了
（ＤＮＮ）和Ｄｅｅｐ Ｃｒｏｓｓｉｎｇ的优点．Ｚｈｕ等人［３１］基于 ＮＦＭ的表示能力和可解释性．
Ｄｅｅｐ Ｃｒｏｓｓｉｎｇ提出了一个深度嵌入森林模型（Ｄｅｅｐ
Ｅｍｂｅｄｄｉｎｇ Ｆｏｒｅｓｔ，ＤＥＦ），将Ｄｅｅｐ Ｃｒｏｓｓｉｎｇ中的残
差单元替换为森林层，通过预训练能够降低模型的
在线预测时间．Ｚｈｏｕ等人［３３］考虑到大部分点击率
预测研究中缺乏对用户行为多样性和局部激活
（Ｌｏｃａｌ Ａｃｔｉｖａｔｉｏｎ）现象的建模，提出了一种深度兴
趣网络（Ｄｅｅｐ Ｉｎｔｅｒｅｓｔ Ｎｅｔｗｏｒｋ，ＤＩＮ），ＤＩＮ基于一
种多层感知机结构，通过引入用户兴趣分布和注意
力机制实现对用户行为多样性和局部激活现象的
建模．
图１０ ＰＮＮ模型的模型结构
基于ＭＬＰ的ＹｏｕＴｕｂｅ视频推荐方法．Ｃｏｖｉｎｇｔｏｎ
等人［８］通过利用用户信息、情境信息、历史行为数据
和项目的特征信息等多源异构数据，提出了一种深
度神经网络模型用于ＹｏｕＴｕｂｅ视频推荐．ＹｏｕＴｕｂｅ
视频推荐主要面临三个方面的挑战：可扩展性、新鲜
度和数据噪声问题．为了克服这三个挑战，该研究将
深度神经网络模型应用到视频推荐系统的两个关键
图９ Ｄｅｅｐ Ｃｒｏｓｓｉｎｇ模型的模型结构 过程：候选集生成和排序，系统架构如图１１所示．候
选集生成的目的是从海量视频库中筛选出和用户相
Ｑｕ等人［８４］基于因子化机模型和 ＭＬＰ提出了
关的几百个视频，主要利用用户在ＹｏｕＴｕｂｅ上的历
一个基于产品的神经网络模型 （Ｐｒｏｄｕｃｔ－ｂａｓｅｄ
史行为数据、用户特征和情境信息建模用户对视频
Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ，ＰＮＮ）．模型结构如图１０所示，由
的个性化偏好，其核心方法是将推荐问题转化为一
一个特征嵌入层、一个成对特征交互层和两个全连
个基于深度神经网络的分类问题，寻找与用户向量
接层组成．Ｇｕｏ等人［３２］基于 Ｗｉｄｅ＆Ｄｅｅｐ，结合因
（神经网络变换后的特征向量）距离最近的Ｎ个视
子化机和深度学习，提出了一种基于深度网络的因
频．排序过程是通过进一步考虑更多的视频特征，利
子化机模型（Ｆａｃｔｏｒｉｚａｔｉｏｎ－Ｍａｃｈｉｎｅ ｂａｓｅｄ Ｎｅｕｒａｌ
用神经网络和逻辑回归模型对每个候选视频进行打
Ｎｅｔｗｏｒｋ，ＤｅｅｐＦＭ）进行点击率预测，分别采用因子
分，并根据打分值对视频进行排序． １６２８ 计 算 机 学 报 ２０１８年
章推荐问题，ＤＡＤＭ 利用ＣＮＮ来学习文章的语义
信息，同时利用注意力机制来抓住编辑者文章选择
行为的动态性．
比较深度学习方法．Ｌｅｉ等人［６１］基于深度学习
方法研究了图像推荐的问题．该研究指出图像推荐
最重要的是需要在图像的语义理解与用户对图像的
偏好或意图之间建立桥梁，因此学习到的图像表示
不仅仅需要具有高的表达性和可分类性，更重要的
是需要反映用户对图像的偏好．针对这个问题，该研
图１１ Ｃｏｖｉｎｇｔｏｎ等人［８］提出的方法的模型架构
究提出了一种比较深度学习方法（Ｃｏｍｐａｒａｔｉｖｅ
４．１．２ 基于卷积神经网络的方法 Ｄｅｅｐ Ｌｅａｒｎｉｎｇ，ＣＤＬ），其主要思路是利用 ＭＬＰ和
基于注意力的ＣＮＮ．Ｇｏｎｇ等人［８７］提出了一种
ＣＮＮ分别从用户的多源异构数据（包括用户画像、
基于注意力的卷积神经网络（ＣＮＮ）来进行微博中
标签信息等）和图像的视觉信息中学习用户和图像
的Ｈａｓｈｔａｇ推荐．总的来说，作者将 Ｈａｓｈｔａｇ推荐
的隐表示，并将用户和图像映射到同一隐空间中．模
作为一个多标记分类问题，ＣＮＮ被作为一种特征提
型的训练过程中，利用了比较学习的思想，即同时利
取手段来获取微博的特征．提出的模型包括一个全
用正反馈图像和负反馈图像，比较它们与用户之间
局通道和一个局部注意力通道．全局通道由一个卷
距离（即正反馈图像与用户的距离应该比负反馈图
积层和一个Ｐｏｏｌｉｎｇ层组成，局部注意力通道由一
像与用户的距离要小），并采用交叉熵损失函数进行
个注意力层和一个Ｐｏｏｌｉｎｇ层组成，模型的架构如
参数学习．最后通过计算用户和图像之间的距离来
图１２所示．
产生图像推荐．
基于ＣＮＮ的音乐推荐．Ｖａｎ ｄｅｎ Ｏｏｒｄ等人［５７］研
究了如何利用深度学习模型来解决音乐推荐系统中
的冷启动问题．在音乐推荐中，协同过滤通常面临冷
启动问题，即对于一些没有用户数据的音乐，往往不
能够被推荐给用户．作者首先利用用户的历史收听数
据和音乐的音频信号数据，通过组合加权矩阵因子分
解和卷积神经网络，将用户和音乐投影到一个共享
的隐空间，从而能够学习到用户和歌曲的隐表示．对
图１２ 基于注意力的ＣＮＮ模型架构 于新的歌曲，可以通过训练好的卷积神经网络从自
之后，Ｚｈａｎｇ等人［８８］通过利用多模信息来进行
身的音频信号中提取出歌曲的隐表示，从而能够在
共享隐空间中通过计算用户与新音乐之间的相似性
微博的Ｈａｓｈｔａｇ推荐．该工作考虑了文本和图像，
分别采用ＣＮＮ和ＲＮＮ从图像和文本中提取特征，
来为用户推荐音乐，帮助解决新项目的冷启动问题．
然后组合两个方面的特征进行标签推荐．同时，考虑 ４．１．３ 基于循环神经网络的方法
到标签仅仅与图像和文本中的部分信息存在关联，
基于注意力的ＲＮＮ．前面我们讨论过基于注意
力的ＣＮＮ模型．与其类似，注意力机制也被用于基
该工作采用注意力机制来建模这种局部关联性．Ｓｅｏ
等人［８９］研究了如何利用评论信息来进行推荐的问
于ＲＮＮ的推荐方法中，Ｌｉ等人［９１］提出了一种基于
题．模型是一个基于注意力的ＣＮＮ模型，其包含一 注意力的ＬＳＴＭ来进行微博中的Ｈａｓｈｔａｇ推荐，注
个用户网络和一个项目网络，分别采用ＣＮＮ从用 意力机制与ＲＮＮ结合的优势是能够抓住文本的序
户的所有评论和项目的所有评论中学习用户和项目
列特征，同时能够从微博中识别最具有信息量的词．
的隐表示，同时采用注意力机制来建模评论中的不 模型首先利用 ＬＳＴＭ 来学习微博的隐状态（ｈ １，
同部分与用户偏好和项目特征的关联度．Ｗａｎｇ等 ｈ ２，…，ｈ Ｎ），同时采用主题模型来学习微博的主题
人［９０］提出了一种动态注意力深度模型（Ｄｙｎａｍｉｃ 分布．隐状态的注意力权值ａ通过微博第ｊ个位置
ｊ
Ａｔｔｅｎｔｉｏｎ Ｄｅｅｐ Ｍｏｄｅｌ，ＤＡＤＭ）来研究编辑者的文 附近的词和微博的主题分布来计算．注意力层的输 ７期 黄立威等：基于深度学习的推荐系统研究综述 １６２９
Ｎ 偏好得到的用户表示，然后利用两种隐表示分别做
出ｖｅｃ＝∑ａｈ．模型的架构如图１３所示．
ｊ ｊ 内积，并组合两种内积通过拟合用户－项目评分矩阵
ｊ＝１
进行模型训练，最后基于学习到的两种表示对未知
评分进行预测．
总的来说，深度学习能够有效缓解用户和项目
特征提取困难的问题，以及新项目的冷启动问题，同
时能够将用户和项目特征提取与推荐过程融合到统
一的框架中，但是并不能够解决基于内容的推荐方
法其自身存在的新用户问题，也不能为用户发现新
的感兴趣的资源，只能发现与用户已有兴趣相似的
资源．
４．２ 深度学习在协同过滤中的应用
图１３ 基于注意力的ＲＮＮ模型架构 协同过滤，如矩阵因子分解，通过学习用户和向
类似于文献［８７，９１］的工作，Ｈｕａｎｇ等人［９２］使
量的低维向量表示来实现推荐，通常面临可扩展性
用记忆网络 （Ｍｅｍｏｒｙ Ｎｅｔｗｏｒｋｓ）代替 ＣＮＮ 和
不足的问题［４６］．深度学习由于能够适应于大规模数
ＬＳＴＭ，提出了一个基于注意力的记忆网络来进行
据处理，目前被广泛应用于协同过滤推荐问题中．基
Ｈａｓｈｔａｇ推荐．此外，Ｈｕａｎｇ等人［９３］还提出了一个基 于深度学习的协同过滤方法利用用户对项目的显式
反馈或隐式反馈数据，采用深度学习训练一个推荐
于注意力的记忆网络来进行微博的提示推荐．考虑到
微博语句长度通常很短，存在单词稀疏和单词同义问
模型，是一类基于模型的协同过滤推荐方法．其主要
题，仅仅依靠语言模型（如词嵌入模型）获得的推荐 思路是将用户的评分向量或项目的被评分向量作为
性能往往非常有限．作者通过利用用户的历史微博
输入，利用深度学习模型学习用户或项目的隐表示，
作为外部记忆单元来建模用户的兴趣，提升了提示 然后利用逐点损失（Ｐｏｉｎｔ－ｗｉｓｅ Ｌｏｓｓ）和成对损失
推荐的准确性．具体地，作者利用两个记忆网络分别 （Ｐａｉｒ－ｗｉｓｅ Ｌｏｓｓ）等类型的损失函数构建目标优化
从作者的历史微博和目标用户的历史微博中发现作
函数对深度学习模型的参数进行优化，最后利用学
者和目标用户的兴趣，最后联合微博的内容、作者的 习到的隐表示进行项目推荐．根据深度学习模型的
兴趣和目标用户的兴趣实现微博用户的提示推荐．
不同，本文将深度学习应用到协同过滤中的研究分
基于ＲＮＮ的新闻推荐．Ｏｋｕｒａ等人［９４］采用深 为５类．
度学习方法研究了新闻推荐问题．首先为了抓住文 ４．２．１ 基于受限玻尔兹曼机的协同过滤方法
章的语义信息，采用降噪自编码器（ＤＡＥ）从新闻中 基于ＲＢＭ的协同过滤．２００７年Ｓａｌａｋｈｕｔｄｉｎｏｖ
提取文章的隐表示；然后为了学习用户的偏好，采用 等人［４６］首次将深度学习应用于解决推荐问题，提出
ＲＮＮ从用户的历史行为列表中学习用户的隐表示； 一种基于受限玻尔兹曼机的协同过滤推荐模型．假
最后，为了利用用户与新闻之间的关联，基于新闻和 设有ｍ部电影，则使用ｍ个Ｓｏｆｔｍａｘ单元来作为可
用户的隐表示采用点乘的方式为用户产生新闻推荐 见单元构造ＲＢＭ．每个用户都有一个单独的 ＲＢＭ，
列表． 对于不同的ＲＢＭ 仅仅是可见单元不同，因为不同
４．１．４ 基于深度信念网络的方法 的用户会对相同的电影打分，因此所有这些 ＲＢＭ
基于ＤＢＮ的音乐推荐．传统的基于内容的音乐 的可见单元共享相同的偏置以及可见单元与隐层单
推荐将音乐内容特征提取与音乐推荐分为两个独立 元的连接权值 Ｗ．Ｓａｌａｋｈｕｔｄｉｎｏｖ等人对传统的
过程，这可能导致推荐性能的不足，Ｗａｎｇ等人［５３］ ＲＢＭ模型进行了改进，一是在可见层，评分数据通过
通过深度信念网络和概率矩阵分解 （Ｐｒｏｂａｂｉｌｉｓｔｉｃ 一个固定长度的０－１向量进行表示；二是考虑到用户
Ｍａｔｒｉｘ Ｆａｃｔｏｒｉｚａｔｉｏｎ，ＰＭＦ）将两个过程组合到一个 只对很少的项目进行了评分，使用一种不与任何隐
统一框架中，提升了音乐推荐的性能．具体地，首先 层单元连接的 Ｍｉｓｓｉｎｇ单元表示未评分的项目．为
学习两种用户和项目的隐表示，一种是利用概率矩 了考虑用户未评分的电影的信息，Ｓａｌａｋｈｕｔｄｉｎｏｖ等
阵分解学习到用户和项目表示，第二种是采用深度 人采用一个０－１向量ｒ表示电影是否被评分过，通
信念网络从音乐中提取的音乐特征表示以及由用户 过融入这种辅助信息提出了一种条件ＲＢＭ．模型的 １６３０ 计 算 机 学 报 ２０１８年
结构如图１４所示． 由于受限玻尔兹曼机的训练过程往往依靠变分推理
和蒙特卡罗采样等近似优化方法，训练的时间过长，
导致基于受限玻尔兹曼机的协同过滤方法在实际应
用中受到很大限制．
４．２．２ 基于自编码器的协同过滤方法
最近，自编码器也被应用于协同过滤中，其通
过对用户或项目的显式或隐式反馈数据进行重构，
能够学习用户或项目的隐表示，并基于这种隐表示
预测用户对项目的偏好．图１５给出了一个基本的模
型结构，给定一个用户的评分向量Ｒ，其中包含评
ｉ
分数据（图中用灰色圆圈表示）和未评分数据（图中
用白色圆圈表示），通过最小化自编码器的重构误差
（Ｒ，Ｒ′）训练得到模型的参数，最后对未知评分进
ｉ ｉ
行预测：
图１４ 基于ＲＢＭ的协同过滤方法的模型结构
＾
Ｒ ｉ＝ｇ（Ｗ′ ｉｆ（Ｗ ｉＲ ｉ＋μ）＋ｂ） （５）
根据ＲＢＭ模型可见层单元之间和隐层单元之
间条件独立的性质，当给定可见单元状态时，可见单
其中，ｇ和ｆ为激励函数，Ｗ ｉ和Ｗ′ ｉ为权值矩阵，μ和
ｂ为偏置向量．
元ｖ与隐层单元ｈ的条件概率可以表示为
Ｆ
ｅｘｐ （ｂｋ＋∑ｈｗｋ）
ｉ ｊ ｉｊ
ｐ（ｖｋ＝１｜ｈ）＝ ｊ＝１ （３）
ｉ Ｋ Ｆ
∑ｅｘｐ （ｂｌ＋∑ｈｗｌ）
ｉ ｊ ｉｊ
ｌ＝１ ｊ＝１
ｍ Ｋ ｍ
ｐ（ｈ＝１｜ｖ，ｒ）＝σ（ｂ＋∑∑ｖｋｗｋ＋∑ｒＤ ）（４）
ｊ ｊ ｉ ｉｊ ｉ ｉｊ
ｉ＝１ｋ＝１ ｉ＝１
其中，Ｋ和Ｆ分别表示用户和隐变量的数量，模型
图１５ 基于自编码器的协同过滤方法的模型架构
需要训练的参数包括权值｛ｗｋ｝，隐层节点偏置
ｉｊ 基于自编码器的协同过滤方法．Ｓｅｄｈａｉｎ等
｛ｂ ｊ｝和可视节点偏置｛ｂ ｉｋ｝．参数训练采用２００２年
人［３７］提出了一种基于自编码器的协同过滤方法
Ｈｉｎｔｏｎ提出的对比散度算法［４５］．
（ＡｕｔｏＲｅｃ），该模型的输入为评分矩阵Ｒ中的一行
Ｐｈｕｎｇ等人［４７］通过将Ｓａｌａｋｈｕｔｄｉｎｏｖ等人的工
（Ｕｓｅｒ－ｂａｓｅｄ）或者一列（Ｉｔｅｍ－ｂａｓｅｄ），利用一个编码
作进行扩展，用于建模用户评分的序数特征，采用一 过程和一个解码过程产生输出，通过最小化重构误
种统一的方式同时抓住了相似性和共现性．此外，考 差进行模型参数优化．Ｓｔｒｕｂ等人［９５］采用两个栈式
虑到 ＲＢＭ 模型仅仅利用了项目之间的关联， 降噪自编码器（ＳＤＡＥ），将用户和项目的评分向量分
Ｇｅｏｒｇｉｅｖ等人［４８］通过增加用户之间的关联，对 别作为输入，分别学习用户和项目的隐表示，然后通
ＲＢＭ模型进行了扩展，并且对模型的训练和预测过 过隐表示对缺失评分进行预测．该方法与ＡｕｔｏＲｅｃ
程进行了简化，同时还使得模型能够直接处理实值 略微不同，其针对评分矩阵的数据稀疏问题，在训练
评分数据．何洁月等人［４９］将ＲＢＭ模型进行扩展，提 过程中通过将评分矩阵中的缺失值直接归零，从而
出一种基于实值状态的玻尔兹曼机，该模型从三个 减少了网络的连接数量，但同时这种方式也导致未
方面对ＲＢＭ进行改进，一是能够直接将评分数据 评分数据的信息被忽略．
作为可见单元的状态，不再需要转化为Ｋ维的０－１ 协同降噪自编码器模型．Ｗｕ等人［２０］利用降噪
向量表示，二是在训练数据中增加使用了未评分信 自编码器来解决ｔｏｐ－Ｎ推荐问题，提出了一种协同
息，三是将好友信任关系融入到该模型之中，能够有 降噪自编码器模型（Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｄｅｎｏｉｓｉｎｇ Ａｕｔｏ－
效缓解模型的稀疏性． Ｅｎｃｏｄｅｒｓ，ＣＤＡＥ）．ＣＤＡＥ与 ＡｕｔｏＲｅｃ方法的结构
基于受限玻尔兹曼机的协同过滤方法的最大问 类似，通过将用户的评分向量作为输入，学习用户的
题是连接隐层和可见层的权重参数规模过大，同时 低维向量表示来进行推荐．但是与ＡｕｔｏＲｅｃ相比存 ７期 黄立威等：基于深度学习的推荐系统研究综述 １６３１
在一些差异：一是该方法不是评分预测，而是ｔｏｐ－Ｎ 式表示映射到同一个隐空间中，进而通过计算两个
推荐；二是该方法通过在评分向量中加入了噪声数 实体之间的相似性实现项目的推荐．图１６是一个基
据，提升了模型的鲁棒性；三是考虑不同用户的个性 本的分布式表示模型，给定一个用户的访问序列Ｓ＝
ｊ
化因素，为每个用户引入了一个用户因子提升了推 ｛ｖ ，…，ｖ ，ｖ，ｖ ，…，ｖ ｝，定义一个目标项
ｉ－ｋ ｉ－１ ｉ ｉ＋１ ｉ＋ｋ
荐的准确性． 目（Ｔａｒｇｅｔ Ｉｔｅｍ）ｖ∈Ｖ，其中Ｖ是所有项目的集合，
ｉ
基于自编码器的表示学习．Ｗｕ等人在［２０］中 序列中其它所有项目为 ｖ的情境项目（Ｃｏｎｔｅｘｔ
ｉ
指出，自编码器在最小重构误差时既能采用逐点损 Ｉｔｅｍｓ），给定Ｓ，能够通过最大化序列的似然（Ｓ）
ｊ ｊ
失（Ｐｏｉｎｔ－ｗｉｓｅ Ｌｏｓｓ）也能采用成对损失（Ｐａｉｒ－ｗｉｓｅ 求目标序列ｖ的分布式表示：
ｉ
Ｌｏｓｓ），但具体选择需要针对特定的任务来决定，可 １
（Ｓ）＝ ∑ ∑ｌｏｇｐ（ｖ ｜ｖ） （６）
是作者并没有给出选择的依据．Ｚｈｕａｎｇ等人［９６］在 ｊ ｜Ｓ ｊ｜
ｖｉ∈Ｓ ｊ－ｋｃｋ
ｉ＋ｃ ｉ
后来的研究中指出，推荐问题中每个用户的评分标 其中ｐ（ｖ ｜ｖ）为给定目标项目ｖ，生成情境项目
ｉ＋ｃ ｉ ｉ
准存在差异，例如有的用户对自己不是特别满意的 ｖ 的概率，通常采用Ｓｏｆｔｍａｘ函数进行定义：
ｉ＋ｃ
项目可能给出高分，而一些标准苛刻的用户可能对 ｅｘｐ（ｖ ·ｖ）
ｐ（ｖ ｜ｖ）＝ ｉ＋ｃ ｉ （７）
ｉ＋ｃ ｉ
满足自己要求的项目给出低分，因此，推荐系统的评 ∑ｅｘｐ（ｖ·ｖ）
ｔ ｉ
分预测不仅仅需要使预测的评分数据与真实评分数
ｖｔ∈Ｖ
据一致，而且还需要使预测的评分数据之间的相对
排序与真实评分数据排序一致．针对这个问题，作者
提出在推荐问题中融入成对排序损失（Ｐａｉｒ－ｗｉｓｅ
Ｒａｎｋｉｎｇ Ｌｏｓｓ）来确保预测数据与真实数据的排序
保持一致．模型利用自编码器分别学习用户和项目
的隐表示，再通过组合逐点损失和成对排序损失构
建目标函数，采用梯度下降方法进行参数优化，最后
基于学习到的用户和项目隐表示，通过内积方式进
行评分预测． 图１６ 分布式表示模型结构
基于自编码器的协同过滤方法通常来说简单有 对模型的学习通常采用 Ｍｉｋｏｌｏｖ等人［９７］提出
效，尤其是利用栈式降噪自编码器，通过提高模型的 的层次Ｓｏｆｔｍａｘ和Ｎｅｇａｔｉｖｅ Ｓａｍｐｌｉｎｇ方法．最终，
深度和增加噪声，推荐的有效性和鲁棒性都得到了 通过学习到的项目分布式表示，能够利用基于用户
提升． 的协同过滤、最近邻等方法来产生推荐．
４．２．３ 基于分布式表示技术的协同过滤方法 基于分布式表示技术的下一次购物篮推荐．
传统的协同过滤（如矩阵因子分解）忽略了用户
Ｗａｎｇ等人［９８］将分布式表示技术用于解决下一次购
行为中的序列模式，但是很多推荐场景中，序列模式
物篮推荐问题．购物篮推荐问题是给定用户的购物
会对推荐的结果起到至关重要的作用，例如基于会
历史（通常是交易数据的序列），预测用户下一次购
话的推荐（Ｓｅｓｓｉｏｎ－ｂａｓｅｄ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ）问题中，
物行为要选择的物品．该研究考虑建模用户的历史
一个会话中之前的行为对后面的行为具有决定性作
序列行为和用户的长时偏好进行购物篮推荐，提出
用．传统的序列模式建模方法（例如马尔科夫模型）
了一种层次表示模型（Ｈｉｅｒａｒｃｈｉｃａｌ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ
往往存在计算复杂且准确性不高的问题．
Ｍｏｄｅｌ，ＨＲＭ）．ＨＲＭ 是一种两层结构的混合表示
最近几年，浅层神经网络模型得到了广泛应用，
模型，第一层通过聚合最后一次交易中的所有项目
特别是词分布式表示模型（Ｅｍｂｅｄｄｉｎｇ Ｍｏｄｅｌｓ）．分
的隐向量形成交易表示（建模序列模式），第二层通
布式表示模型最早应用在自然语言处理领域中，利
过聚合用户的隐向量（建模用户偏好）和交易表示构
用背景信息构建词汇的分布式表示．分布式表示模
建混合表示，最终利用混合表示进行下一次购物篮
型往往简单而且比较有效，因此很快被用于建模推
预测．模型结构如图１７所示，ｖＵ和ｖＩ分别表示用户
荐系统中的用户行为序列模式．其核心思想是利用 ｕ ｉ
ｕ和项目ｉ的隐向量，对于用户ｕ，给定其上一次交
用户对项目的访问序列同时构建用户和项目（或者
易历史序列Ｔｕ ，需要预测下一次购物序列Ｔｕ，
其它背景信息）的分布式表示，并将多种实体的分布 ｔ－１ ｔ １６３２ 计 算 机 学 报 ２０１８年
ＨＲＭ定义用户ｕ在下一次购物中选择项目ｉ的概 注［９８］．但是，这种方法仅仅建模了用户行为的局部
率为 情境信息，并不能完全有效地抓住用户行为的序列
ｅｘｐ（ｖＩ·ｖＨｙｂｒｉｄ） 模式．
ｐ（ｉ∈Ｔｕ ｜ｕ，Ｔｕ ）＝ ｉ ｕ，ｔ－１ （８）
ｔ ｔ－１ ｜Ｉ｜ ４．２．４ 基于循环神经网络的协同过滤方法
∑ｅｘｐ（ｖＩ·ｖＨｙｂｒｉｄ）
ｊ ｕ，ｔ－１ 循环神经网络模型正是针对序列数据建模而提
ｊ＝１
其中｜Ｉ｜表示所有项目的数量，ｖ ｕＨ ，ｙ ｔｂ －ｒｉ １ｄ是第二层通过 出，因此很快被引入到用户行为序列模式建模的研
聚合用户隐向量ｖＵ和交易表示ｆ （ｖＩ∈Ｔｕ ）构建 究中．基于循环神经网络的协同过滤与基于分布式
ｕ １ ｉ ｔ－１
的混合表示，即 表示技术的协同过滤类似，都能用来建模用户行为
ｖＨｙｂｒｉｄ＝ｆ（ｖＵ，ｆ（ｖＩ∈Ｔｕ ）） （９） 的序列模式，但区别在于分布式表示技术仅仅抓住
ｕ，ｔ－１ ２ ｕ １ ｉ ｔ－１
其中ｆ（·）和ｆ（·）都是聚合函数，可以是最大池 了用户行为的局部情境信息，而ＲＮＮ能够建模用
１ ２
化（Ｍａｘ Ｐｏｏｌｉｎｇ）和平均池化（Ａｖｅｒａｇｅ Ｐｏｏｌｉｎｇ）等 户行为之间的相互依赖关系．基于循环神经网络的
形式．最后通过对所有用户的历史交易数据进行拟 协同过滤的主要思路是利用循环神经网络建模用户
合，采用梯度下降方法进行模型的训练，进而利用训 历史序列行为对当前时刻用户行为的影响，从而实
练好的ＨＲＭ进行下一次购物篮预测． 现用户的项目推荐和行为预测．图１８是一个基本的
基于ＲＮＮ的协同过滤方法框架，已知一个用户的
行为序列Ｓ＝｛ｘ，ｘ，…，ｘ｝，首先，对其进行嵌入
１ ２ ｔ
式表示并作为循环神经网络在每一时刻的输入，时
刻ｔ的隐向量ｈ＝ｆ（Ｖｘ＋Ｗｈ ），其中ｆ为激励
ｔ ｔ ｔ－１
函数．输出ｏ为时刻ｔ选择特定项目的概率，通常基
ｔ
于ｔ时刻的隐向量采用Ｓｏｆｔｍａｘ等方法进行计算．
根据应用场景不同，基于循环神经网络的协同过滤
模型主要被用于基于会话的推荐、融入时间序列信
图１７ ＨＲＭ的模型结构
息的协同过滤等应用中．
基于分布式表示技术的广告推荐．Ｇｒｂｏｖｉｃ等
人［１４］利用分布式表示技术研究邮件系统的广告推
荐问题，利用用户与不同电子商务网站之间的邮件
往来获取到的用户历史购买行为数据，预测用户
对产品的兴趣．首先，作者提出了两种产品分布式
表示方法获取用户或项目的分布式表示，一种是
Ｐｒｏｄ２Ｖｅｃ方法，所有产品被独立考虑，其在产品层
次上建模，采用分布式表示技术将所有产品嵌入到
图１８ 基于循环神经网络的推荐方法的模型架构
一个连续的、低维的向量空间；另一种方法是 基于会话的推荐．基于会话的推荐系统主要利
Ｂａｇｇｅｄ－Ｐｒｏｄ２Ｖｅｃ，其考虑一封邮件中可能包含多 用当前会话中的历史行为记录预测下一步点击每个
个产品的购买行为，在邮件层次上进行建模，采用分 项目的概率，其最大特点是仅仅考虑了一个会话期
布式表示技术获取到更加有效的产品向量表示．获 间的行为数据．Ｈｉｄａｓｉ等人［７５］采用ＧＲＵ来抓住会
取项目的分布式表示之后，作者提出了两种推荐模 话中行为之间的依赖关系，基本架构如图１９所示，
型，一种是产品到产品的推荐模型，其在嵌入式空间 在每一个时间点上，模型的输入是当前点击的项目
中计算产品之间的相似度，然后利用基于用户的协 的ｏｎｅ－ｈｏｔ编码，然后通过一个嵌入层压缩为低维
同过滤产生广告推荐；另一种是用户到产品的推荐 连续向量，中间是多个基本的ＧＲＵ层和一个前向
模型，其通过将用户和产品嵌入到统一的低维空间， 层，输出层利用Ｓｏｆｔｍａｘ等方法计算的每个项目的
从而通过计算用户与产品的相似度产生推荐．
点击概率．为了实现并行计算，该研究通过把不同的
基于分布式表示技术的协同过滤方法，能够建 会话拼接起来，然后采用 ｍｉｎｉ－ｂａｔｃｈ处理．此外，在
模用户行为的序列影响．同时，由于其简单而且训练
输出阶段，考虑到项目数量太多会导致计算量过大，
高效，目前在推荐系统研究中引起了大量的关
该研究通过对所有项目进行抽样，仅仅预测部分项 ７期 黄立威等：基于深度学习的推荐系统研究综述 １６３３
目被点击的概率． 模用户偏好的演化，同时假设项目的特征保持不变．
但是在实际的推荐系统中，项目的特征可能发生变
化，例如一部电影的受欢迎程度或者受众群体会随
着时间发生改变．Ｄａｉ等人［７８］考虑到用户偏好和项
目特征会因为用户交互而随时间演化，基于循环神
经网络和多维时间点过程模型，提出了一种循环共
演化特征嵌入过程模型（Ｒｅｃｕｒｒｅｎｔ Ｃｏｅｖｏｌｕｔｉｏｎａｒｙ
Ｆｅａｔｕｒｅ Ｅｍｂｅｄｄｉｎｇ Ｐｒｏｃｅｓｓｅｓ）实现用户偏好和项
目特征的演化跟踪，并学习用户和项目在每一时刻
图１９ Ｈｉｄａｓｉ等人［７５］提出的方法的模型结构 的隐表示，最后通过对用户和项目的隐表示进行内
积来产生项目推荐．Ｗｕ等人［１０］通过利用循环神经
在文献［７６］中，Ｔａｎ等人对Ｈｉｄａｓｉ等人［７５］的工
网络建模用户偏好和项目特征的演化，提出了一种
作提出了一系列改进，一是数据增强（ｄａｔａ ａｕｇｍｅｎ－
循环推荐网络（Ｒｅｃｕｒｒｅｎｔ Ｒｅｃｏｍｍｅｎｄｅｒ Ｎｅｔｗｏｒｋ，
ｔａｔｉｏｎ），首先是通过将每一个长度的序列都作为一
ＲＲＮ），能够预测用户未来的行为轨迹．具体地，
个训练样本来增加训练样本的数量，然后采用嵌入
ＲＲＮ首先利用低维矩阵因子分解学习用户和项目
式Ｄｒｏｐｏｕｔ随机去除一些序列中的节点，帮助缓解
的静态隐表示，同时将用户的历史评分数据作为输
由于噪声数据导致的过拟合；二是预训练，考虑到
入，采用ＬＳＴＭ学习用户和项目在每一时刻的动态
用户偏好会随时间变化，通过利用所有历史数据
隐表示，最后通过聚合两类隐表示的内积实现单一
对模型进行预训练，然后仅仅利用最近的数据进
时刻的评分预测．
行更精细粒度的训练，这样同时抓住了用户的长
基于循环神经网络的协同过滤方法，由于其能
时偏好和短时偏好；三是利用特权信息（Ｐｒｉｖｉｌｅｇｅｄ
够有效建模用户行为中的序列模式．同时通过改变
Ｉｎｆｏｒｍａｔｉｏｎ）进行训练，在模型训练过程中，通过融
循环神经网络的输入［７７］和定义不同的权值矩阵［７３］，
入用户行为序列中预测时间点之后的数据，提升了
还能够融入时间等情境信息［１０］，以及各种类型的辅
模型的预测精度．
助数据来提升推荐的质量［７２］，模型具有高的适用
融入时间序列信息的协同过滤．传统的协同过
性，在当前的推荐系统中得到了广泛应用．
滤方法并没有考虑用户行为的时间信息，但是时
４．２．５ 基于生成对抗网络的协同过滤方法
间信息反映了用户行为的时间序列模式，有效地利
Ｗａｎｇ等人［１００］提出的ＩＲＧＡＮ首次将ＧＡＮ引
用时间信息有利于提升推荐系统的性能．Ｓｏｎｇ等
入到信息检索领域，实现了信息检索建模中两种思
人［１２］通过融入时间信息并在多种粒度上建模用户
维流派（生成检索模型和判别检索模型）的统一描
的兴趣偏好，提出一种多等级时间深度语义结构化
述．生成检索模型聚焦于给定一个查询ｑ，生成相关
模型（Ｍｕｔｌｉ－Ｒａｔｅ ＴＤＳＳＭ）．Ｌｉｕ等人［７３］考虑到推荐
的文档ｄ，判别检索模型聚焦于给定一个查询和文
系统中的用户行为往往存在多种类型，采用循环
档（ｑ，ｄ），预测二者之间的相关性．ＩＲＧＡＮ的目的
神经网络模型和 Ｌｏｇ双线性模型（Ｌｏｇ－ＢｉＬｉｎｅａｒ， 是借鉴ＧＡＮ中生成器和判别器相互对抗的思想，采
ＬＢＬ）［９９］分别建模用户行为之间的长程依赖关系和
用一个博弈理论式中的极小化极大算法来将生成检
短时情境信息，从而提出了一种循环Ｌｏｇ双线性模
索模型和判别检索模型集成到一个统一的框架中．
型（Ｒｅｃｕｒｒｅｎｔ Ｌｏｇ－ＢｉＬｉｎｅａｒ，ＲＬＢＬ），实现对用户在 形式上讲，假设ｐ （ｄ｜ｑ，ｒ）是用户真实的偏
ｔｒｕｅ ｎ
下一时刻的行为类型预测．Ｗｕ等人［７７］将循环神经
好分布，生成检索模型ｐ（ｄ｜ｑ，ｒ）需要尽力接近用
θ ｎ
网络用于建模用户的时间序列行为，该研究区分了 户真实的偏好分布，判别检索模型ｆ（ｑ，ｄ）需要尽

不同类型的显式反馈和隐式反馈数据，并组合一个 力区分相关文档和不相关文档．类似于ＧＡＮ，可以
循环部分和一个非循环部分来对用户进行推荐．循 定义ＩＲＧＡＮ的目标函数：
环部分是一个ＲＮＮ结构，其通过区分不同的行为 Ｎ
类型抓住所有历史反馈对当前用户行为的影响．非
ＪＧ＊，Ｄ＊ ＝ｍｉ θｎｍ ａｘ ｎ∑ ＝１｛Ｅ ｄ～ｐｔｒｕｅ（ｄ｜ｑｎ，ｒ）［ｌｏｇＤ（ｄ｜ｑ ｎ）］＋
循环部分是一个全连接神经网络结构，其主要建模 Ｅ ｄ～ｐθ（ｄ｜ｑｎ，ｒ）［ｌｏｇ（１－Ｄ（ｄ｜ｑ ｎ））］｝（１０）
了用户基本的偏好． 其中，Ｄ（ｄ｜ｑ）＝σ（ｆ（ｄ，ｑ）），σ是一个ｓｉｇｍｏｉｄ函
ｎ ｎ
以上研究实际上仅仅利用了用户的序列行为建 数，θ和分别是生成检索模型和判别检索模型的 １６３４ 计 算 机 学 报 ２０１８年
参数，能够通过采用梯度下降法进行迭代学习而获 仍然无法改变传统协同过滤方法存在的数据稀疏问
取到．以上目标函数是通过采用成对排序损失来构 题，以及新用户和新项目的冷启动问题．
建的，假设ｐ（ｄ｜ｑ，ｒ）能够通过一个Ｓｏｆｔｍａｘ函数 ４．３ 深度学习在混合推荐系统中的应用
θ ｎ
进行定义： 传统的协同过滤方法仅仅利用了用户的显式反
ｅｘｐ（ｇ（ｑ，ｄ）） 馈或隐式反馈数据，面临数据稀疏问题．通过融入用
ｐ（ｄ｜ｑ，ｒ）＝ θ ｉ （１１）
θ ｉ ∑ｅｘｐ（ｇ（ｑ，ｄ）） 户画像数据、项目内容数据、社会化标注、评论等辅
θ ｉ
ｄｉ 助数据，混合推荐方法能够有效缓解数据稀疏问题，
ｇ（ｑ，ｄ）是给定查询ｑ，生成文档ｄ的概率，
θ ｉ 但是这种方法面临最大的难题是辅助数据的表示问
ｇ（ｑ，ｄ）和ｆ（ｑ，ｄ）通常根据具体的任务进行定义，
θ  题，经典的方法，如协同主题回归（Ｃｏｌｌａｂｏｒａｔｉｖｅ
可以是相同的形式或不同的形式．在文献［１００］中，
Ｔｏｐｉｃ Ｒｅｇｒｅｓｓｉｏｎ，ＣＴＲ）［１０４］，并不能够获取有效的
作者将其定义为相同的形式：ｇ θ（ｑ，ｄ）＝ｓ（ｑ，ｄ）和
辅助数据表示［４］．深度学习通过自动特征提取，能够
ｆ（ｑ，ｄ）＝ｓ（ｑ，ｄ）．在项目推荐任务中，作者采用了
 从辅助数据中学习到有效的用户和项目隐表示．
矩阵因子分解方法来定义ｓ（ｑ，ｄ）：
基于深度学习的推荐方法的主要思路是组合基
ｓ（ｕ，ｉ）＝ｂ＋ＵＴＶ （１２）
ｉ ｕ ｉ 于内容的推荐方法与协同过滤，将用户或项目的特
其中，ｂ ｉ是项目ｉ的偏置，Ｕ ｕ和Ｖ ｉ分别为用户ｕ和项
征学习与项目推荐过程集成到一个统一的框架中，
目ｉ的隐向量．ｓ（ｕ，ｉ）也可以通过因子化机或者神
首先利用各类深度学习模型学习用户或项目的隐特
经网络进行定义． 征，并结合传统的协同过滤方法构建统一的优化函
生成对抗网络由于引入了对抗机制，在推荐系
数进行参数训练，然后利用训练出来的模型获取用
统中能够取得不错的效果．但目前，生成对抗网络在
户和项目最终的隐向量，进而实现用户的项目推荐．
推荐系统中的应用还处于探索阶段，更深入的研究
根据深度学习模型的不同，本文将基于深度学习的
有待于进一步展开．
推荐方法分为以下两类．
４．２．６ 基于其它深度学习模型的协同过滤方法 ４．３．１ 基于自编码器的混合推荐方法
除了ＲＢＭ、ＡＥ、分布式表示技术、ＲＮＮ和对抗
当前，自编码器在基于深度学习的混合推荐方
神经网络之外，目前被用于协同过滤的深度学习模
法中应用最为广泛．基于自编码器的混合推荐方法
型还包括卷积神经网络、神经自回归分布估计模
的基本架构如图２０所示，自编码器由于具有强的表
型（Ｎｅｕｒａｌ Ａｕｔｏｒｅｇｒｅｓｓｉｖｅ Ｄｉｓｔｒｉｂｕｔｉｏｎ Ｅｓｔｉｍａｔｏｒ， 示学习能力，很自然地用来从用户特征Ｘ或项目特
ＮＡＤＥ）［１０１］．
征Ｙ中学习用户隐表示Ｕ或项目隐表示Ｖ，然后
Ｇｅｎｇ等人［５８］针对社交内容网络中用户与图像
之间的连接稀疏以及图像内容多样的问题，提出了
一种神经网络模型来学习社交内容网络中用户和图
像的统一表示．该模型利用用户和图像之间由于历
史交互形成的二部图网络结构，采用卷积神经网络
模型通过最大化模块度［１０２］的方法学习用户与图像
的深层次统一表示，从而在同一空间中通过计算用
户和图像的相似度为用户进行图像推荐．Ｚｈｅｎｇ等
人［１０３］考虑到基于ＲＢＭ 的协同过滤存在优化困难
的问题，使用ＮＡＤＥ替代ＲＢＭ 来进行协同过滤推
荐，ＮＡＤＥ不需要融入任何隐变量，因此避免了复
杂的隐变量推理过程，从而降低了模型复杂度．
总的来说，基于深度学习的协同过滤能够看做
是传统隐因子模型的一种非线性泛化［２０］．其最大的
优点是在学习用户和项目隐表示的过程中引入了非
线性的特征变换，相比传统的协同过滤方法（如矩阵
因子分解）具有更好的性能［８２，９６］．但同时这类方法 图２０ 基于自编码器的混合推荐方法的模型架构 ７期 黄立威等：基于深度学习的推荐系统研究综述 １６３５
将隐表示融入到隐因子模型中拟合用户 －项目交互 其中λ、λ、λ、λ和λ是超参数，Ｃ是一个置信度参
ｗ ｎ ｕ ｓ ｖ
矩阵Ｒ（如评分矩阵），最后联合自编码器的重构误 数矩阵．
差（Ｘ，Ｕ）和（Ｙ，Ｖ），以及拟合交互矩阵的误差 之后，有研究者对ＣＤＬ模型进行了一系列扩
（Ｒ，Ｕ，Ｖ）构建统一的损失函数，通过梯度下降等方 展．文献［３９］中，Ｗａｎｇ等人将ＣＤＬ扩展应用到标
法学习到最终的用户和项目隐表示，从而对用户进 签推荐问题中，提出一种关系栈式降噪自编码器
行推荐．在不同研究中，可能同时利用了项目特征信 模型（Ｒｅｌａｔｉｏｎａｌ Ｓｔａｃｋｅｄ Ｄｅｎｏｉｓｉｎｇ Ａｕｔｏｅｎｃｏｄｅｒ，
息和用户特征信息，也可能只利用了其中一种． ＲＳＤＡＥ）．该研究采用ＳＤＡＥ从项目的内容信息中
协同深度学习模型．Ｗａｎｇ等人在ＫＤＤ２０１５年 学习项目的隐表示，利用概率矩阵分解建模标签与项
的论文［４］中提出了一种贝叶斯版本的降噪自编码器 目之间的共现信息，同时融入了标签系统中可能存在
模型，即贝叶斯栈式降噪自编码器模型 （Ｂａｙｅｓｉａｎ 的各类关系数据．ＣＤＬ模型中，项目的文本辅助信
ＳＤＡＥ），然后组合Ｂａｙｅｓｉａｎ ＳＤＡＥ和概率矩阵分 息是由词袋模型表示，这种方式忽略了文本内容中
解，提出了一种协同深度学习（Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｄｅｅｐ 词语序列所包含的信息．针对这个问题，Ｗａｎｇ等
Ｌｅａｒｎｉｎｇ，ＣＤＬ）混合推荐方法．该方法主要利用项 人［３８］提出了一种协同循环自编码器模型（Ｄｅｎｏｉｓｉｎｇ
目的文本类辅助数据，采用Ｂａｙｅｓｉａｎ ＳＤＡＥ学习项 Ｒｅｃｕｒｒｅｎｔ Ａｕｔｏｅｎｃｏｄｅｒ，ＣＲＡＥ），用来代替ＳＤＡＥ
目的隐表示．ＣＤＬ模型的图表示如图２１所示，假设 进行项目推荐．ＣＲＡＥ拥有一种自编码器结构，在编
系统有Ｉ个用户和Ｊ个项目，对应一个评分矩阵 码器和解码器中，分别利用一个循环神经网络建模
Ｒ＝［Ｒ ］ ，文本数据用词袋模型表示，所有项目 文本序列的生成，从而抓住文本中词语的序列信息．
ｉｊ Ｉ×Ｊ
的文本数据对应一个特征矩阵Ｘ ｃ（每一行代表一个 另外一个 ＣＤＬ的扩展是协同变分自编码器方法
项目的词频向量）．通过在Ｘ ｃ中加入噪声得到自编 （Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｖａｒｉａｔｉｏｎａｌ Ａｕｔｏｅｎｃｏｄｅｒ，ＣＶＡＥ）［４２］，
码器的输入Ｘ ０，自编码器第ｌ层的输出为Ｘ ｌ，相应 ＣＶＡＥ使用变分自编码器代替ＳＤＡＥ从项目的内
权值矩阵和偏置为Ｗ ｌ和ｂ ｌ．ＣＤＬ的生成过程如下： 容中学习项目的隐表示．其相比ＣＤＬ，推理的过程
（１）对ＳＤＡＥ网络的每一层ｌ 更加简单，且不需要在输入中加入噪声，能够从图
①对权值矩阵Ｗ ｌ的每一列ｎ，提取 像、文本等项目内容中提取特征．此外，Ｙｉｎｇ等
Ｗ ｌ，＊ｎ～ （０，λ ｗ－１Ｉ Ｋｌ） 人［１０５］将ＣＤＬ模型进行扩展，提出一种协同深度排
②提取偏置向量ｂ ｌ～ （０，λ ｗ－１Ｉ Ｋｌ） 序模型（Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｄｅｅｐ Ｒａｎｋｉｎｇ，ＣＤＲ），ＣＤＲ
③对Ｘ的每一行ｊ，提取 与ＣＤＬ的区别在于，ＣＤＲ利用了成对损失函数代
ｌ
Ｘ ｌ，ｊ＊～ （σ（Ｘ ｌ－１，ｊ＊Ｗ ｌ＋ｂ ｌ），λ ｓ－１Ｉ Ｋｌ） 替ＣＤＬ使用的逐点损失函数进行模型优化．
（２）对每个项目ｊ 协同知识库嵌入模型．Ｚｈａｎｇ等人［５］利用一个
①提取一个干净的输入Ｘ ｃ，ｊ＊～ （Ｘ Ｌ，ｊ＊，λ ｎ－１Ｉ Ｊ） 与ＣＤＬ相似的模型架构，融入项目之间的结构化信
②提取一个隐项目偏移向量ε～ （０，λ－１ 息（项目之间的各类关系）和非结构化信息（文本数
ｊ ｖ
Ｉ ），然后设置隐项目向量为 据和图像数据）到推荐系统中，通过组合深度学习方
Ｋ
ｖ＝ε＋ＸＴ 法和概率矩阵分解模型，提出了一种协同知识库嵌
ｊ ｊ Ｌ／２，ｊ＊
（３）对每个用户ｉ，提取一个隐用户向量： 入模型（Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｋｎｏｗｌｅｄｇｅ Ｂａｓｅ Ｅｍｂｅｄｄｉｎｇ，
ｕ＝ （０，λ－１Ｉ ） ＣＫＥ）．ＣＫＥ利用了三种非监督表示学习方法从项
ｉ ｕ Ｋ
（４）对每对用户和项目（ｉ，ｊ），提取一个评分Ｒ 目相关的结构化和非结构化数据中学习项目的隐表
ｉｊ
Ｒ ～ （ｕＴｖ，Ｃ－１） 示．具体来说，为了利用项目相关的结构化信息，通
ｉｊ ｉ ｊ ｉｊ
过采用一种知识库嵌入式方法ＴｒａｎｓＲ［１０６］将项目嵌
入到隐空间来学习项目的结构化向量，利用项目相
关的文本信息通过采用ＳＤＡＥ提取文本的分布式
表示来得到项目的文本向量，利用项目相关的图像
信息通过提出一种栈式卷积自编码器（Ｓｔａｃｋｅｄ
Ｃｏｎｖｏｌｕｔｉｏｎａｌ ＡｕｔｏＥｎｃｏｄｅｒｓ，ＳＣＡＥ）模型提取视觉
图像的分布式表示来得到项目的视觉向量，并通过
图２１ ＣＤＬ的模型结构 融合项目的三类向量得到项目的隐表示，最后结合 １６３６ 计 算 机 学 报 ２０１８年
ＰＭＦ学习到用户和项目最终的隐表示．与ＣＤＬ相 外，还融入了自编码器的重构误差，而其它监督深度
比，ＣＫＥ集成了更多的辅助信息来学习项目的隐表 学习方法将从辅助信息中学习用户和项目隐表示的
示，另外，ＣＫＥ中的协同过滤利用了成对排序损失． 过程和拟合协同信息的过程集成到一个统一的监督
基于ＳＤＡＥ的方法．Ｗｅｉ等人［４１］通过组合协同 学习框架中，从而在最终的模型优化过程中只拟合
过滤方法 ＴｉｍｅＳＶＤ＋＋［１０７］和栈式降噪自编码器 用户与项目的显式反馈或隐式反馈数据．因此，与基
ＳＤＡＥ，提出了一种混合推荐方法．该研究利用 于自编码器的混合推荐方法的最大区别在于最终优
ＳＤＡＥ从项目的辅助信息中学习项目的隐表示，利 化目标函数的构建．图２２给出了一个基本的模型架
用ＴｉｍｅＳＶＤ＋＋拟合用户和项目之间的评分矩阵． 构，深度学习模型用来从用户特征Ｘ和项目特征Ｙ
与ＣＤＬ相比，该模型利用的ＴｉｍｅＳＶＤ＋＋是一类 中学习用户隐表示Ｕ或项目隐表示Ｖ（此处并没有
融合了时间因素的隐因子模型，因此建模了用户偏 自编码器的输入数据重构过程），然后将隐表示融入
好和项目特征随时间的变化，有利于提升推荐系统 到隐因子模型中拟合用户－项目交互矩阵Ｒ（如评分
的性能． 矩阵），通过拟合交互矩阵的误差（Ｒ，Ｕ，Ｖ）构建统
基于ｍＤＡ的方法．Ｌｉ等人［１７］通过将边缘降噪 一的目标优化函数，利用最终学习到的用户和项目
自编码器（Ｍａｒｇｉｎａｌｉｚｅｄ Ｄｅｎｏｉｓｉｎｇ Ａｕｔｏｅｎｃｏｄｅｒ， 隐表示对用户产生推荐．
ｍＤＡ）［１０８］和概率矩阵分解方法进行组合，提出一种
混合推荐方法．ｍＤＡ是降噪自编码器的一类扩展，
其通过对降噪自编码器的输入噪声进行边缘化，避
免了训练降噪自编码器所需要的大的计算开销，提
升了模型的可扩展性．与ＣＤＬ和ＣＲＡＥ的不同之
处在于，该模型不仅考虑了项目相关的辅助信息来
学习项目的隐表示，还融入了用户相关的辅助数据
来学习用户的隐表示，此外该模型并没有像ＣＤＬ和
ＣＲＡＥ一样采用贝叶斯形式，而是利用边缘降噪自编
码器，具有更少的模型参数，具有更高的可扩展性． 图２２ 基于其它深度学习模型的混合推荐方法模型架构
基于ａＳＤＡＥ的方法．Ｄｏｎｇ等人［４０］提出了一种
基于 ＭＬＰ的混合推荐方法．传统矩阵分解方
基于附加栈式降噪自编码器（Ａｄｄｉｔｉｏｎａｌ Ｓｔａｃｋｅｄ 法通常采用内积的方式来衡量用户向量和项目向量
Ｄｅｎｏｉｓｉｎｇ Ａｕｔｏｅｎｃｏｄｅｒ，ａＳＤＡＥ）的混合推荐方法， 的距离，Ｈｓｉｅｈ等人［１５］利用测度学习来学习数据之
ａＳＤＡＥ是ＳＤＡＥ的扩展，其输入是用户或者项目的
间的相似度，并将测度学习（Ｍｅｔｒｉｃ Ｌｅａｒｎｉｎｇ，ＭＬ）
评分向量，ａＳＤＡＥ在ＳＤＡＥ的每个隐层都加入用户
和协同过滤结合，提出了一种协同测度学习
或者项目的辅助信息，在输出端同时重构输入数据
（Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｍｅｔｒｉｃ Ｌｅａｒｎｉｎｇ，ＣＭＬ）方法．该研
和辅助数据．该研究利用ａＳＤＡＥ学习用户和项目
究指出内积操作由于不具有距离相似度的传递性，
的隐表示，然后结合矩阵因子分解（ＭＦ）和ａＳＤＡＥ
并不是一个合理的距离测度，会带来相似度学习不
构建联合目标优化函数，采用梯度下降方法进行参
准确的问题．因此，ＣＭＬ通过大边界最近邻方法
数优化，进而对未知评分进行预测．相比ＣＤＬ方法，
（Ｌａｒｇｅ Ｍａｒｇｉｎ Ｎｅａｒｅｓｔ Ｎｅｉｇｈｂｏｒ，ＬＭＮＮ）进行测
该模型能够融入更加精细的辅助数据，且具有更少
度学习来学习数据之间的相似度．最后，在测度学习
的模型参数．
损失函数的基础上，通过 ＭＬＰ融入项目相关的特
４．３．２ 基于其它深度学习模型的混合推荐方法
征数据，同时将加权近似排序成对损失［１０９］融入用
除了自编码器之外，目前被用于混合推荐的深
户的隐式反馈数据，并加入正则化因子，构建统一的
度学习模型还包括多层感知机、卷积神经网络和循
目标优化函数，最后学习到用户和项目隐向量，进而
环神经网络等．虽然基于深度学习的混合推荐方法
实现Ｔｏｐ－Ｋ推荐．
都采用深度学习加协同过滤的模型框架，但是自编
Ｃｈｅｎ等人［１１０］在多媒体推荐中，通过引入两种
码器从辅助信息中学习用户和项目隐表示的过程是
层次的注意力机制到隐因子模型中，提出了一个
一个非监督过程，因此在模型最终的优化过程中除
注意力 协 同 过 滤 模 型 （Ａｔｔｅｎｔｉｖｅ Ｃｏｌｌａｂｏｒａｔｉｖｅ
了拟合用户与项目的显式反馈或隐式反馈数据之 ７期 黄立威等：基于深度学习的推荐系统研究综述 １６３７
Ｆｉｌｔｅｒｉｎｇ，ＡＣＦ）．ＡＣＦ是一个多层感知机，包括两 型、深度学习的方法和隐因子方法三个方面的选择
种层次的注意力机制，一个项目层次的注意力机制 不同，表１总结了相关的代表性研究．
被用来刻画不同项目匹配用户兴趣的程度，一个部
表１ 基于深度学习的混合推荐方法比较
件层次的注意力机制被用来抓住多媒体辅助信息中
研究 辅助数据类型 深度学习模型 隐因子模型
对用户最具有代表性的特征． Ｗａｎｇ ｅｔ ａｌ．［４］ 文本 ＳＤＡＥ ＰＭＦ
基于ＣＮＮ的混合推荐方法．Ｋｉｍ等人［５９］利用 Ｗａｎｇ ｅｔ ａｌ．［３８］ 文本、关系 ＲＳＤＡＥ ＰＭＦ
卷积神经网络将项目相关的文本辅助数据融入到推
Ｗａｎｇ ｅｔ ａｌ．［３９］ 文本 ＣＲＡＥ ＰＭＦ
Ｙｉｎｇ ｅｔ ａｌ．［１０５］ 文本 ＳＤＡＥ ＰＭＦ
荐系统中，提出了一种卷积矩阵因子分解模型
Ｌｉ ｅｔ ａｌ．［４２］ 文本、图像等 ＶＡＥ ＰＭＦ
（Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｍａｔｒｉｘ Ｆａｃｔｏｒｉｚａｔｉｏｎ，ＣｏｎｖＭＦ）．考 文本、图像、 ＳＤＡＥ、ＳＣＡＥ、
Ｚｈａｎｇ ｅｔ ａｌ．［５］ ＰＭＦ
关系等 ＴｒａｎｓＲ
虑到ＣＤＬ等方法采用词袋模型对文本进行表示时，
用户和项目
无法有效利用文本内部的情境信息，ＣｏｎｖＭＦ利用 Ｌｉ ｅｔ ａｌ．［１７］ 特征 ｍＤＡ ＰＭＦ
ＣＮＮ的多层卷积操作抓住文本中词语之间的相互 Ｗｅｉ ｅｔ ａｌ．［４１］ 用户特征 ＳＤＡＥ ＴｉｍｅＳＶＤ＋＋
用户和项目
关联，并帮助学习用户和项目的隐表示，提升推荐系 Ｄｏｎｇ ｅｔ ａｌ．［４０］ ａＳＤＡＥ ＭＦ
特征
统评分预测的准确性．ＣｏｎｖＭＦ首先对文档中的每 图像、文本、
Ｈｓｉｅｈ ｅｔ ａｌ．［１５］ ＭＬＰ ＭＬ
标签等
个词做嵌入式表示，然后将所有嵌入式向量拼接成
图像、视频、 Ａｔｔｅｎｔｉｏｎ－ｂａｓｅｄ
一个矩阵，这样每篇文档就可用一个二维矩阵表示， Ｃｈｅｎ ｅｔ ａｌ．［１１０］ 音频等 ＭＬＰ ＳＶＤ
然后在该矩阵上进行卷积、池化以及映射，从而获取 Ｋｉｍ ｅｔ ａｌ．［５９］ 文本 ＣＮＮ ＭＦ
Ｂａｎｓａｌ ｅｔ ａｌ．［１９］ 文本 ＧＲＵ ＬＦＭ
到项目的隐向量．ＣｏｎｖＭ的目标函数由矩阵因子分
Ｌｉ ｅｔ ａｌ．［１１１］ 文本 ＭＬＰ、ＧＲＵ ＭＦ
解和ＣＮＮ的损失函数共同组成．
基于ＲＮＮ的混合推荐方法．与ＣｏｎｖＭＦ相同， 总的来说，基于深度学习的混合推荐通过融入
为了抓住文本辅助数据中词语之间的序列关系 ， 辅助信息能够有效缓解协同过滤推荐中存在的数据
Ｂａｎｓａｌ等人［１９］基于循环神经网络模型提出了一种 稀疏和冷启动问题．但是，目前的大部分研究都是针
文本推荐方法，在利用评分数据的同时，还利用了文 对具体的辅助数据而采用不同的深度学习模型，构
本内容信息和文本标签数据进行推荐．具体来说，为 建一个针对所有数据的、统一的混合推荐框架是下
了更好地抓住文本中词语的序列模式，该模型利用 一步的重要方向．
ＧＲＵ学习文本内容的向量表示，然后基于隐因子模 ４．４ 深度学习在基于社交网络的推荐系统中的应用
型采用一个多任务学习框架（包括文本推荐和标签 当前，社交网络作为一种开放的公众参与的信
预测两个任务）构建一个联合优化目标函数，在监督 息交流与业务服务平台，迅速进入了人们的日常工
学习框架下实现对模型参数的优化．与 ＣＤＬ和 作和生活中．同时，随着移动互联网的发展，位置社
ＣＲＡＥ相比，虽然该模型也利用了项目相关的文本 交网络也已经迅速普及．基于社交网络的推荐系统
数据学习项目的隐向量表示，但是该模型是一个完 旨在解决社交媒体平台中“信息过载”的问题，已经
全端到端的监督学习架构． 成为社交媒体挖掘领域的热门话题．目前，深度学习
Ｌｉ等人［１１１］利用深度学习模型研究了Ａｐｐ的评 与基于社交网络的推荐系统的结合也引发了一系列
分预测与抽象ｔｉｐｓ生成问题，通过一个多任务学习 的研究成果，主要可以分为两个方向：（１）基于深度
框架同时进行评分预测与抽象ｔｉｐｓ生成．具体地， 学习的社交网络社会化关系影响建模；（２）基于深
在评分预测任务中，作者利用用户和项目的隐向量 度学习的位置社交网络序列模式建模．
作为输入，利用一个多层感知机（ＭＬＰ）来进行评分 ４．４．１ 基于深度学习的社交网络社会化关系影响
预测．在抽象ｔｉｐｓ生成中，将用户和项目的隐向量 建模
作为输入，利用一个ＧＲＵ来进行文本生成．最后在 社交网络中用户之间存在各种类型的社会化关
一个多任务框架中进行模型训练． 系（例如朋友关系、关注关系等），用户之间通过社会
基于深度学习的混合推荐中，深度学习方法主 化关系会产生相互影响，并具有相似的兴趣偏好．基
要用于从辅助数据中学习用户和项目的隐表示．当 于社交网络的推荐系统最重要的是需要通过建模用
前的大部分研究都采用深度学习加隐因子模型的推 户之间的社会化关系影响来提升推荐系统的质量．
荐框架，各种研究的区别主要体现在辅助数据的类 通常，社会化关系通过图结构进行表示，因此传统的 １６３８ 计 算 机 学 报 ２０１８年
方法一般采用图模型或正则化技术来建模用户之间 电子商务网站中的产品．首先，通过利用神经网络模
的社会化关系影响［１１２］，但是这些方法容易受到图 型（即 Ｗｏｒｄ２Ｖｅｃ和Ｐａｒａ２Ｖｅｃ）从用户购买行为数
结构的稀疏性以及高的计算复杂性的影响．当前，针 据中学习用户和项目的嵌入式表示，同时为了融入
对这些问题，研究者通过利用深度学习开展了一些 社交网络信息，利用改进的梯度Ｂｏｏｓｔ树方法从社
针对性工作． 交媒体用户数据中学习用户的嵌入表示，最后，利用
基于 ＭＬＰ的推荐方法．Ｗａｎｇ等人［１１３］研究了 基于特征的矩阵因子分解联合以上两个方面的隐表
跨信息网络和社交网络的社会化推荐问题，即如何 示进行模型训练和预测．
利用信息网络中用户与项目之间的交互和社交网络 基于自编码器的推荐方法．Ｄｅｎｇ等人［１１５］针对
中用户之间的连接，将信息网络中的项目推荐给社 传统矩阵因子分解中用户和项目的隐特征初始化困
交网络中的潜在用户．该研究通过分别在两个领域 难以及用户信任关系多样化的问题，采用深度自编
进行嵌入式学习，同时让桥接用户（同时出现在两个 码器模型初始化用户和项目的隐特征向量，通过正
网络中的用户）共享相同的嵌入式表示，来学习用户 则化技术融入用户信任关系的影响到推荐系统中，
和项目一致的隐表示．在信息网络领域，作者基于 有效提升了推荐系统的性能．Ｐａｎ等人［１１６］研究了如
ＭＬＰ，提出了一种属性感知的深度协同过滤模型 何融入信任关系到评分预测问题中，作者采用降噪
（Ａｔｔｒｉｂｕｔｅｄ－ａｗａｒｅ Ｄｅｅｐ ＣＦ Ｍｏｄｅｌ），模型架构如图 自编码器分别通过重构用户的评分向量和信任关系
２３所示．模型将用户和项目的ＩＤ号以及它们的属 向量学习评分隐向量和信任隐向量，中间通过一个
性信息作为输入，通过多层神经网络预测用户对项
加权隐层来平衡这两类隐向量的重要性，基于学习
目的偏好．在社交网络领域，基于信息网络中桥接用
到的隐向量来进行ｔｏｐ－Ｎ推荐．此外，文章还利用了
户的隐表示，通过假设朋友之间具有相近的兴趣来
一个关联正则项来避免由于数据稀疏所导致的过拟
学习其它用户的隐表示，最后通过组合两个领域的
合问题．
损失函数构建统一的优化函数进行模型训练． 基于 ＲＢＭ 的推荐方法．Ｎｇｕｙｅｎ等人［５０］在
Ｓａｌａｋｈｕｔｄｉｎｏｖ等人［４６］的工作的基础上，通过两种
方式建模社会化关系对推荐结果的影响，一种是将
社会化关系和用户评分一样，都作为ＲＢＭ 的观测
变量，通过同时拟合社会化关系和用户评分实现社
会化影响建模；另一种是在ＲＢＭ 中增加一个隐含
层，在这个隐层上通过朋友间的权值共享实现社会
化影响建模．
通过深度学习方法将社交网络中的社会化关系
影响融入到推荐系统中，有利于缓解推荐系统的数
据稀疏和冷启动问题，从而提升推荐系统的质量．但
图２３ 属性感知的深度协同过滤模型架构
总的来说，深度学习在基于社交网络的推荐系统中
基于分布式表示技术的推荐方法．Ｙａｎｇ等人［７４］
的应用还非常少，诸如如何区分关系的类型和强度、
为了融入社会化影响到推荐系统中，采用了基于深
如何有效建模结构洞等社会理论到推荐系统中，都
度学习的网络表示技术建模用户之间的社会化影 还有待深入的研究．
响．基于用户的社交网络结构，通过网络表示技术将
４．４．２ 基于深度学习的位置社交网络序列模式建模
用户节点嵌入到一个共享的隐空间，每个用户用一 位置社交网络中，所有项目（也就是兴趣点，
个低维、稠密的向量进行表示．通过使用网络表示技 Ｐｏｉｎｔ－Ｏｆ－Ｉｎｔｅｒｅｓｔ，ＰＯＩ）都具有位置属性，用户行为
术建模社交网络的生成，能够缓解社交网络图结构 具有时间和空间上的序列模式，对这种时空序列模
的稀疏性问题，同时基于深度学习的网络表示技术 式的建模有利于提升ＰＯＩ推荐的准确率．因此，位
具有高的可扩展性，能够适应于大规模数据集． 置社交网络的推荐系统除了需要关注用户之间的社
Ｚｈａｏ等人［１１４］通过组合深度学习与矩阵因子分解， 会化关系，还需要抓住用户的位置影响、序列移动模
研究如何利用社交网络数据为社交网络中的冷启动 式等因素．
用户（在电子商务网站中没有购买记录的用户）推荐 基于 ＭＬＰ的推荐方法．Ｙａｎｇ等人［１１７］指出当 ７期 黄立威等：基于深度学习的推荐系统研究综述 １６３９
前的ＰＯＩ推荐方法都是针对特定的数据和问题而 友的影响、用户的短时序列情境和长时序列情境共
设计，提出了一种通用的半监督学习模型，即偏好与 同建模行为序列的生成．为了刻画两种情境信息，在
情境嵌入模型（Ｐｒｅｆｅｒｅｎｃｅ ａｎｄ Ｃｏｎｔｅｘｔ Ｅｍｂｅｄｄｉｎｇ， 短时和长时两个情境下分别采用ＲＮＮ和ＧＲＵ抓
ＰＡＣＥ），能够利用相邻用户和位置的信息来缓解推 住用户移动模式中的序列关联性．最后组合社会网
荐系统的数据稀疏问题．ＰＡＣＥ首先构建情境图作 络的构建和移动轨迹的生成建立目标函数，采用随
为观测数据，包括利用位置间的距离构建的位置图， 机梯度下降法进行模型训练．
以及利用用户间的朋友关系构建的用户图．ＰＡＣＥ 基于分布式表示的推荐方法．Ｏｚｓｏｙ［１１８］利用用
的模型架构如图２４所示，其输入是用户和项目的 户与项目之间的共现信息，采用 Ｗｏｒｄ２Ｖｅｃ技术开
ｏｎｅ－ｈｏｔ向量，输出是用户和项目的情境信息以及 展位 置 社 交 网 络 推 荐 问 题 研 究．首 先，通 过
用户对ＰＯＩ的访问次数，分别建模了用户与用户之 Ｗｏｒｄ２Ｖｅｃ技术利用用户的历史签到行为将用户和
间的情境、项目与项目之间的情境，以及用户对ＰＯＩ 项目嵌入到一个共享的低维空间，然后，借鉴基于内
的偏好．最后，ＰＡＣＥ联合三个方面的损失建立优化 容的推荐方法和基于用户的协同过滤方法，采用最
函数，通过学习到的模型进行ＰＯＩ推荐． 近邻算法找到用户最感兴趣的项目，并产生用户的
项目推荐．Ｚｈａｏ等人［１１９］考虑建模用户的兴趣偏好
和移动模式来进行兴趣点推荐，提出了一种序列嵌
入排序模型（ＳＥｑｕｅｎｔｉａｌ Ｅｍｂｅｄｄｉｎｇ Ｒａｎｋ，ＳＥＥＲ）
模型．具体来说，ＳＥＥＲ利用分布式表示技术学习用
户的嵌入式表示，然后将用户嵌入作为约束加入到
成对排序模型中来抓住用户行为的序列模式，同时
ＳＥＥＲ还融入了时间和空间信息．
通过深度学习方法将用户行为序列模式融入到
推荐系统中，有利于抓住用户行为之间的依赖关系，
从而提升推荐系统的质量．深度学习在位置社交网
络推荐系统中的应用目前主要聚焦在序列模式建
图２４ 偏好与情境嵌入模型架构 模，其研究还有待进一步拓展，例如，如何通过深度
基于ＣＮＮ的推荐方法．Ｗａｎｇ等人［６２］研究了 学习融合各类异构的时空数据，以及如何集成社会
如何融入图像内容信息来提升ＰＯＩ推荐的问题， 化关系影响、位置影响、时间影响和序列模式等要素
作者基于ＣＮＮ和概率矩阵因子分解，提出了一种 构建统一的推荐框架等．
视觉内容增强的 ＰＯＩ推荐模型（Ｖｉｓｕａｌ Ｃｏｎｔｅｎｔ ４．５ 深度学习在情境感知的推荐系统中的应用
Ｅｎｈａｎｃｅｄ ＰＯＩ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ，ＶＰＯＩ）．ＶＰＯＩ利 情境感知的推荐系统主要通过集成用户的情境
用ＣＮＮ从图像内容中提取特征，通过用户－图像关 信息到推荐过程中，从而改善推荐效果．在情境感知
系、ＰＯＩ－图像关系和用户－ＰＯＩ关系三类关系，构建 的推荐系统中，因为考虑了情境信息，传统的推荐函
了一个概率主题模型，最后将图像的特征提取和概 数从ｓ：Ｕ×Ｉ→Ｒ变为ｓ：Ｕ×Ｉ×Ｃ→Ｒ，其中Ｃ表示
率主题模型融合到一个统一框架中构建优化函数， 所有情境的集合．当前，深度学习在情境感知的推荐
采用Ｎｅｇａｔｉｖｅ Ｓａｍｐｌｉｎｇ方法进行参数优化． 系统中的应用主要集中在如何采用深度学习方法对
基于ＲＮＮ的推荐方法．Ｌｉｕ等人［７２］研究了位 情境信息进行有效建模，主要表现在两个方面：
置社交网络中的行为预测问题，通过利用循环神经 （１）如何采用深度学习方法融入情境信息到推荐系
网络抓住序列行为之间的依赖关系，从而基于用户 统中，即基于深度学习的情境感知的推荐；（２）如何
的历史行为序列帮助预测下一时刻的行为．Ｙａｎｇ等 采用深度学习方法实现对情境信息的有效表示，即
人［７４］利用循环神经网络建模位置社交网络中的用 基于深度学习的情境信息表示．
户序列移动模式，同时融合用户的社会化关系影响 基于深度学习的情境感知的推荐．传统的情境
进行位置推荐．具体地，模型由两个部分组成：社会 感知的推荐系统通过将问题转化为一个三维矩阵上
网络的构建和移动轨迹的生成．首先采用网络嵌入 的矩阵补全问题，能够简单地融入情境信息到推荐
方法构建社会网络，再利用用户的访问偏好、用户朋 系统中．但是对于很多复杂场景下的推荐问题（例如 １６４０ 计 算 机 学 报 ２０１８年
序列推荐问题），融入情境信息到推荐系统中是很困 各种类型的、粗糙的情境数据中提取隐情境表示，然
难的［１２０］．Ｌｉｕ等人［７２，１２０］考虑到传统的序列推荐除 后采用隐因子模型融合隐情境表示、清晰的情境信
了需要考虑用户的序列影响，还需要考虑用户行 息和用户对项目评分数据构建一个评分模型来进行
为的情境信息，通过改进传统的循环神神经网络 评分预测，通过融入隐情境信息提升了推荐系统的
结构融入了情境信息到序列推荐中．在文献［７２］ 质量．Ｒａｗａｔ等人［６０］利用深度神经网络模型研究了
中，作者提出了一种空时循环神经网络模型（Ｓｐａｔｉａｌ 融合用户情境信息的图像标签推荐问题，同时考虑
Ｔｅｍｐｏｒａｌ Ｒｅｃｕｒｒｅｎｔ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ，ＳＴ－ＲＮＮ）， 了用户情境信息和图像语义信息．主要思路是采用
针对不同粒度的时间间隔和距离长度，通过在循环 深度卷积神经网络学习图像的语义表示，采用一个
神经网络模型中定义不同的时间转换矩阵和位置转 深度神经网络学习用户的情境表示，最后联合两方
换矩阵，有效地抓住了连续的时间和空间情境信息 面的表示，将标签推荐问题作为一个多标记分类问
对用户行为的影响，提升了位置推荐的质量．在文 题进行标签推荐．
献［１２０］中，作者将情境信息分为输入情境（如位置、 总的来说，深度学习应用于情境感知的推荐系
天气等）和转换情境（时间间隔长度），通过在循环神 统中．一方面，在很多复杂推荐场景中，通过深度学
经网络中采用可适应的、情境具体的输入矩阵和转 习方法能够有效融入情境信息到推荐系统中；另一
换矩阵对两种情境信息进行建模，帮助提升了序列 方面，通过深度学习获取情境信息的隐表示，并在此
推荐的质量． 基础上进行情境感知的推荐，能够有效融入各类粗
基于深度学习的情境信息表示．传统的情境感 糙的情境数据，缓解情境感知的推荐系统中的数据
知的推荐系统通常采用图模型、主题模型和张量分 稀疏问题．但同时，由于情境数据被表示为隐情境，
解技术等，但是，当情境数据大量增加时，这些技术 模型面临可解释性不足的问题．
会因为情境集合维度过大而遭遇到严重的数据稀疏 ４．６ 应用比较
问题．深度学习通过将各种类型的情境数据进行建 基于深度学习的推荐方法能够融入多源异构数
模，并表示为一个低维、稠密的隐向量，能够有效缓 据进行推荐，包括用户的显式反馈或隐式反馈数据、
解这种数据稀疏问题［１２１］． 用户画像和项目内容数据、用户生成内容等．深度学
Ｚｈｏｕ等人［１２２］将分布式表示技术用于情境信息 习方法通过将多源异构数据作为输入从而采用一个
建模，提出一种多情境轨迹嵌入模型（Ｍｕｌｔｉ－Ｃｏｎｔｅｘｔ 端到端的模式自动训练预测模型，能够有效融入多
Ｔｒａｊｅｃｔｏｒｙ Ｅｍｂｅｄｄｉｎｇ Ｍｏｄｅｌ，ＭＣ－ＴＥＭ），通过将 源异构数据到推荐系统中，从而缓解传统推荐系统
包括用户、轨迹、临近的地点、类别、时间、区域在内 中面临的数据稀疏和冷启动问题，并提升推荐系统
的情境信息嵌入到一个统一的隐空间中，能够抓住 的能力．其主要的优势表现在：（１）可以避免复杂的
多种类型的情境信息用于轨迹数据挖掘，此外，分布 人工特征工程［５，５３，６１］，尤其是面对图像、视频等非结
式表示技术通过刻画相关因素之间的距离以及联 构化数据，深度学习的表示学习能力能够帮助从非
系，可以增加模型的可解释性．Ｈｕａｎｇ等人［１２３］提出 结构化数据中提取特征信息；（２）可以学习非线性
了一种神经概率模型用于基于情境的引用推荐．首 的多层次抽象特征表示，而且获取的特征通常是稠
先用一个词语序列来表示情境，然后利用词分布式 密和低维的，这是传统浅层模型所不具备的［９，２９－３３］；
表示学习方法学习情境和文档的向量表示，最后通 （３）可以克服不同数据之间的异构性，将各类粗糙
过神经概率模型联合情境和文档的向量表示来产生 的原始数据作为输入来学习用户和项目的隐表
文章推荐．Ｆａｎｇ等人［１２４］提出了一种 Ｅｎｃｏｎｄｅｒ－ 示［５，８，１７，８０］．但同时也存在一些不足：（１）可扩展性问
Ｄｅｃｏｎｄｅｒ结构来解决情境感知的引用推荐问题，在 题．当前，虽然深度学习在 ＹｏｕＴｕｂｅ视频推荐［８］、
解码器中，作者采用了一个基于 ＣＮＮ的深度模型 Ｇｏｏｇｌｅ的Ａｐｐ推荐［９］和Ｙａｈｏｏ的新闻推荐［９４］等实
来学习情境数据的隐表示，在解码器中，作者利用一 际场景中得到了应用，但由于其模型复杂往往需要
个ＲＮＮ来生成引用的文章标题，同时利用作者的 长的训练时间，如何平衡模型可扩性和复杂度仍然
元数据构建了一个作者网络来抓住作者的自身偏 是一个大的问题；（２）可解释性问题．深度学习模型
好，采用注意力机制抓住不同部分输入对生成文章 往往类似于一个黑盒，容易带来推荐系统可解释性
标题的重要性．Ｕｎｇｅｒ等人［１２１］将情境信息分为清晰 不足的问题，如何在增强推荐能力的同时增强可解
情境信息和隐情境信息，首先采用深度自编码器从 释性仍然有待深入研究． ７期 黄立威等：基于深度学习的推荐系统研究综述 １６４１
总的来说，基于深度学习的推荐系统利用深度 型以及推荐对象等方面存在着差异．表２列出了
学习方法学习用户和项目的隐表示，从而实现项目 ５个主要研究方向在深度学习模型、数据类型方面
推荐，但是不同类型的方法在深度学习模型、数据类 的区别，以及各自的优点和面临的难点问题．
表２ 深度学习在不同推荐系统中的应用比较
应用方向 深度学习模型 数据类型 主要优点 主要难点
用户的显式反馈或隐式
深度学习在基于 １．自动的用户和项目特征提取 １．新用户冷启动问题
ＭＬＰ、ＣＮＮ、ＲＮＮ、 反馈数据、用户画像和
内容的推荐系统 ２．不存在新项目的冷启动问题 ２．不能为用户发现多样的感兴趣
ＤＢＮ等 项目内容数据，以及各
中的应用 ３．高的可扩展性 的资源
种类型的用户生成内容
ＲＢＭ、ＡＥ、ＣＮＮ、 用户与项目之间的显式 １．系统自动化程度高
深度学习在协同 １．数据稀疏问题
ＮＡＤＥ、ＲＮＮ、 反馈或隐式反馈数据 ２．推荐结果丰富
过滤中的应用 ２．新用户和新项目冷启动问题
ＧＡＮ等 （如评分矩阵） ３．能够实现非线性特征建模
用户的显式反馈或隐式 １．不存在冷启动问题
深度学习在混合 ＡＥ、ＣＮＮ、ＲＮＮ、 反馈数据、用户画像和 ２．不受数据稀疏问题约束 １．异构数据的有效特征表达
推荐中的应用 ＭＬＰ等 项目内容数据，以及各 ３．有效利用辅助数据提升推荐 ２．各类推荐算法的混合
种类型的用户生成内容 性能
用户与项目之间的显式 １．探索更多基于深度学习的模型架
１．缓解推荐系统的数据稀疏问题
深度学习在基于 ＲＢＭ、ＡＥ、分布式 反馈或隐式反馈数据、 构来有效建模社会化关系影响
２．缓解推荐系统的冷启动问题
社交网络的推荐 表示技术、ＣＮＮ、 用户的社会化关系数 ２．位置社交网络中，如何同时融合
３．能够建模社会化关系影响和
系统中的应用 ＲＮＮ、ＭＬＰ等 据，以及时间、位置等情 用户移动模式、社会化影响、时
用户行为序列模式
境数据 间影响、位置影响等多种要素
用户与项目之间的显式
深度学习在情境
分布式表示技术、 反馈或隐式反馈数据， １．能够融合各种类型的情境数据 １．确定不同情境信息的作用程度
感知的推荐系统
ＡＥ、ＲＮＮ、ＭＬＰ等 用户的情境信息（时间、 ２．能够实现情境数据的有效表示 ２．提升情境模型的可解释性
中的应用
地点、天气等）
更多的研究者加以关注．
５ 基于深度学习的推荐系统研究趋势 （２）基于深度学习的跨领域信息融合的推荐
展望 随着数据获取能力的不断提升，用户在不同领
域的历史记录或项目在不同领域的信息能够被获
随着大数据时代的不断深入，深度学习在推荐 取．例如，一个用户可能在多个社交媒体平台上注册
系统中的应用已经受到学术界和工业界越来越多的 账号，融合用户在不同平台上的数据能够进行跨领
重视，基于深度学习的推荐系统研究已经成为当前 域信息融合的推荐，帮助克服单一领域信息的不足，
的研究热点．但是基于上面的讨论可以看到，目前深 从而有效缓解传统推荐系统中的数据稀疏和冷启动
度学习在推荐系统中的应用仍处于起步阶段，在未 问题，同时利用多个领域数据能够更好地发现用户
来必将会有更多、更广泛的尝试［１２５］．以下总结了五 的个性化偏好．针对跨领域推荐问题的研究，当前最
个可能的研究方向． 主要的研究方法包括基于协同过滤的方法［１２６］、基
（１）深度学习与现有推荐方法的结合 于迁移学习的方法［１２７］和基于张量分解的方法［１２８］
传统的推荐方法，包括基于内容的方法和协同 等．但是，这些方法都只针对不同领域中特定类型的
过滤方法，都采用浅层模型进行预测，依赖于人工特 信息进行融合，适应性非常有限．当前，利用深度学
征提取，很难有效学习到深层次的用户和项目隐表 习技术，通过将各类数据通过嵌入式表示等方法作
示．通过利用深度学习模型融合广泛的多源异构数 为统一输入，构建深层预测模型能够有效融合各种
据，包括社会化关系、用户或项目属性、以及用户的 不同类型的、跨平台的异构数据进行推荐，已经在
评论和标签信息等，能够学习到更加抽象、更加稠密 Ｇｏｏｇｌｅ［８］和微软［１０］等互联网公司的实际系统中被
的用户和项目的深层次表示，同时采用深层神经网 应用．未来，通过构建深度学习模型来实现跨领域信
络结构构建预测模型也能够更好地抓住用户和项目 息融合的推荐将是学术界和工业界研究的重点方向．
之间交互的非线性结构特征［１５］．但同时，传统的推 （３）注意力机制与基于深度学习的推荐系统的
荐方法，具有简单、可解释性强等优势．因此，将深度 结合
学习与现有推荐方法结合，能够融合两种方法的优 基于注意力机制的深度学习是人类视觉中的选
势，虽然目前已有相关研究出现，但这个方向仍值得 择注意力机制与深度神经网络的结合，目前在计算 １６４２ 计 算 机 学 报 ２０１８年
机视觉、自然语言处理等领域取得了巨大成功．当 系统的可解释性．
前，注意力机制已经被应用于 ＭＬＰ、ＲＮＮ、ＣＮＮ和
其它深度学习模型，其中最为引人关注的是基于注 ６ 结束语
意力的ＲＮＮ和基于注意力的ＣＮＮ．基于注意力的
ＲＮＮ能够更好地建模序列数据中的长期记忆，基于 在互联网迅猛发展的今天，随着互联网用户对
注意力的ＣＮＮ能够从输入中识别与问题最具有 信息需求的日益膨胀，“信息过载”问题逐年升温，推
信息量的部分．将注意力机制应用到在推荐系统 荐系统在各个领域的数字化进程中扮演着越来越重
中，能够帮助推荐系统抓住项目中最具有信息量 要的角色．将深度学习技术融入推荐系统中，开展基
的特征，推荐最具有代表性的项目，同时增强模型 于深度学习的推荐系统研究，通过从海量数据中学
的可解释性［１１０］．当前，注意力机制已经在 Ｈａｓｈｔａｇ 习用户和项目的隐表示，然后构建推荐模型，最终向
推荐［８７，８８，９１，９２］、文章推荐［９０］、多媒体推荐［１１０］、引用 用户产生有效的推荐列表．与传统的推荐系统相比，
推荐［１２４］等问题中得到了应用．但是总的来说，目前 基于深度学习的推荐系统能够利用深度学习技术通
的研究还比较少，未来还待更深入和更广泛的研究． 过融合各种类型的多源异构数据，自动学习用户和
（４）新的深度学习推荐系统架构 项目抽象的隐藏特征，建模用户行为中的序列模式，
对于推荐系统来说，涉及到不同的推荐对象和 能够更有效地反映用户的不同偏好以及提高推荐的
推荐场景，例如电影推荐、音乐推荐、图像推荐、商品 准确性．本文在分析传统推荐算法所存在问题的基
推荐、地理位置推荐等等．一方面，针对所有任务构 础上，介绍和分析了基于深度学习的推荐系统的
建统一的深度学习推荐模型几乎是不可能的，需要 研究现状和进展，并讨论了今后的发展方向，希望
根据不同的推荐场景考虑不同的数据构建新的深度 能对相关领域的研究人员和工程技术人员提供有
学习框架来产生推荐，包括推荐项目的具体内容信 益的帮助．
息，推荐系统中涉及的辅助数据（评论、标签、用户画
像信息、用户的社会化关系等），以及推荐的情景信 参 考 文 献
息（时间、位置等）等，因此，面对新的推荐场景需要
设计新的深度学习推荐系统架构．另一方面，当前的 ［１］ Ｍａｒｚ Ｎ，Ｗａｒｒｅｎ Ｊ．Ｂｉｇ Ｄａｔａ：Ｐｒｉｎｃｉｐｌｅｓ ａｎｄ Ｂｅｓｔ Ｐｒａｃｔｉｃｅｓ
推荐系统需要建模的要素众多，不仅仅包括用户与 ｏｆ Ｓｃａｌａｂｌｅ Ｒｅａｌｔｉｍｅ Ｄａｔａ Ｓｙｓｔｅｍｓ．Ｇｒｅｅｎｗｉｃｈ，ＵＳＡ：
Ｍａｎｎｉｎｇ Ｐｕｂｌｉｃａｔｉｏｎｓ Ｃｏ．，２０１５
项目之间的交互数据，还涉及到用户行为的时空序
［２］ Ｇａｎｔｚ Ｊ，Ｒｅｉｎｓｅｌ Ｄ．Ｔｈｅ Ｄｉｇｉｔａｌ Ｕｎｉｖｅｒｓｅ ｉｎ ２０２０：Ｂｉｇ Ｄａｔａ，
列模式、社会化关系影响、用户偏好的动态演化和项
Ｂｉｇｇｅｒ Ｄｉｇｉｔａｌ Ｓｈａｄｏｗｓ，ａｎｄ Ｂｉｇｇｅｓｔ Ｇｒｏｗｔｈ ｉｎ ｔｈｅ Ｆａｒ Ｅａｓｔ．
目特征的动态变化等，建模更多的要素能够提升推 ＩＤＣ ｉＶｉｅｗ：ＩＤＣ Ａｎａｌｙｚｅ ｔｈｅ ｆｕｔｕｒｅ，２０１２，２００７（２０１２）：
荐系统的性能．因此，研究能够表达和融合多种要素 １－１６
的、新的深度学习架构也是未来的研究方向之一． ［３］ Ａｄｏｍａｖｉｃｉｕｓ Ｇ，Ｔｕｚｈｉｌｉｎ Ａ．Ｔｏｗａｒｄ ｔｈｅ ｎｅｘｔ ｇｅｎｅｒａｔｉｏｎ ｏｆ
（５）基于深度学习的推荐系统的可解释性
ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ：Ａ ｓｕｒｖｅｙ ｏｆ ｔｈｅ ｓｔａｔｅ－ｏｆ－ｔｈｅ－ａｒｔ ａｎｄ
ｐｏｓｓｉｂｌｅ ｅｘｔｅｎｓｉｏｎｓ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｋｎｏｗｌｅｄｇｅ ａｎｄ
推荐系统除了直接展示推荐结果之外，往往还
Ｄａｔａ Ｅｎｇｉｎｅｅｒｉｎｇ，２００５，１７（６）：７３４－７４９
要展示恰当的推荐理由来告诉用户为什么系统认为 ［４］ Ｗａｎｇ Ｈ，Ｗａｎｇ Ｎ，Ｙｅｕｎｇ Ｄ Ｙ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｄｅｅｐ ｌｅａｒｎｉｎｇ
这样的推荐是合理的．提升推荐系统的可解释性可 ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２１ｓｔ ＡＣＭ
以提高用户对推荐结果的接受度，同时也可以提高 ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ
用户在系统透明度、可信度、可辨性、有效性和满意 ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓｙｄｎｅｙ，Ａｕｓｔｒａｌｉａ，２０１５：１２３５－１２４４
［５］ Ｚｈａｎｇ Ｆ，Ｙｕａｎ Ｎ Ｊ，Ｌｉａｎ Ｄ，ｅｔ ａｌ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｋｎｏｗｌｅｄｇｅ
度等方面的体验．已有的推荐方法使用主题模型学
ｂａｓｅ ｅｍｂｅｄｄｉｎｇ ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
习到的话题［１０４］以及显式的物品特征［１２９］来加强可
ｔｈｅ ２２ｎｄ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
解释性．但是，基于深度学习推荐系统采用端到端的 Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ，
模型直接将多源异构数据作为输入预测用户对项目 ＵＳＡ，２０１６：３５３－３６２
的偏好，模型训练的结果是给出深度神经网络的结 ［６］ ＬｅＣｕｎ Ｙ，Ｂｅｎｇｉｏ Ｙ，Ｈｉｎｔｏｎ Ｇ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ．Ｎａｔｕｒｅ，
２０１５，５２１（７５５３）：４３６－４４４
构和神经元之间的连接权重，很难对推荐结果直接
［７］ Ｐｅｎｇ Ｙ，Ｚｈｕ Ｗ，Ｚｈａｏ Ｙ，ｅｔ ａｌ．Ｃｒｏｓｓ－ｍｅｄｉａ ａｎａｌｙｓｉｓ ａｎｄ
给出合理的解释．因此，有必要从数据、模型和经济
ｒｅａｓｏｎｉｎｇ：Ａｄｖａｎｃｅｓ ａｎｄ ｄｉｒｅｃｔｉｏｎｓ．Ｆｒｏｎｔｉｅｒｓ ｏｆ Ｉｎｆｏｒｍａｔｉｏｎ
意义等层面上进行研究，提升基于深度学习的推荐 Ｔｅｃｈｎｏｌｏｇｙ ＆Ｅｌｅｃｔｒｏｎｉｃ Ｅｎｇｉｎｅｅｒｉｎｇ，２０１７，１８（１）：４４－５７ ７期 黄立威等：基于深度学习的推荐系统研究综述 １６４３
［８］ Ｃｏｖｉｎｇｔｏｎ Ｐ，Ａｄａｍｓ Ｊ，Ｓａｒｇｉｎ Ｅ．Ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ［２１］ Ｓｕ Ｘ，Ｋｈｏｓｈｇｏｆｔａａｒ Ｔ Ｍ．Ａ ｓｕｒｖｅｙ ｏｆ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ
ｙｏｕｔｕｂｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １０ｔｈ ＡＣＭ ｔｅｃｈｎｉｑｕｅｓ．Ａｄｖａｎｃｅｓ ｉｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２００９，２００９：４
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１６： ［２２］ Ｖｅｒｂｅｒｔ Ｋ，Ｍａｎｏｕｓｅｌｉｓ Ｎ，Ｏｃｈｏａ Ｘ，ｅｔ ａｌ．Ｃｏｎｔｅｘｔ－ａｗａｒｅ
１９１－１９８ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｆｏｒ ｌｅａｒｎｉｎｇ：Ａ ｓｕｒｖｅｙ ａｎｄ ｆｕｔｕｒｅ
［９］ Ｃｈｅｎｇ Ｈ Ｔ，Ｋｏｃ Ｌ，Ｈａｒｍｓｅｎ Ｊ，ｅｔ ａｌ．Ｗｉｄｅ ＆ｄｅｅｐ ｌｅａｒｎｉｎｇ ｃｈａｌｌｅｎｇｅｓ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｌｅａｒｎｉｎｇ Ｔｅｃｈｎｏｌｏｇｉｅｓ，
ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １ｓｔ Ｗｏｒｋｓｈｏｐ ２０１２，５（４）：３１８－３３５
ｏｎ Ｄｅｅｐ Ｌｅａｒｎｉｎｇ ｆｏｒ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｂｏｓｔｏｎ，ＵＳＡ， ［２３］ Ｍｏｏｎｅｙ Ｒ Ｊ，Ｒｏｙ Ｌ．Ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｂｏｏｋ ｒｅｃｏｍｍｅｎｄｉｎｇ
２０１６：７－１０ ｕｓｉｎｇ ｌｅａｒｎｉｎｇ ｆｏｒ ｔｅｘｔ ｃａｔｅｇｏｒｉｚａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ５ｔｈ
［１０］ Ｗｕ Ｃ Ｙ，Ａｈｍｅｄ Ａ，Ｂｅｕｔｅｌ Ａ，ｅｔ ａｌ．Ｒｅｃｕｒｒｅｎｔ ｒｅｃｏｍｍｅｎｄｅｒ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｄｉｇｉｔａｌ ｌｉｂｒａｒｉｅｓ．Ｓａｎ Ａｎｔｏｎｉｏ，ＵＳＡ，
ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １０ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ ２０００：１９５－２０４
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｃａｍｂｒｉｄｇｅ， ［２４］ Ｂｒｅｅｓｅ Ｊ Ｓ，Ｈｅｃｋｅｒｍａｎ Ｄ，Ｋａｄｉｅ Ｃ．Ｅｍｐｉｒｉｃａｌ ａｎａｌｙｓｉｓ ｏｆ
ＵＫ，２０１７：４９５－５０３ ｐｒｅｄｉｃｔｉｖｅ ａｌｇｏｒｉｔｈｍｓ ｆｏｒ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ
［１１］ Ｅｌｋａｈｋｙ Ａ Ｍ，Ｓｏｎｇ Ｙ，Ｈｅ Ｘ．Ａ ｍｕｌｔｉ－ｖｉｅｗ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｏｆ ｔｈｅ １４ｔｈ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｕｎｃｅｒｔａｉｎｔｙ ｉｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．
ａｐｐｒｏａｃｈ ｆｏｒ ｃｒｏｓｓ ｄｏｍａｉｎ ｕｓｅｒ ｍｏｄｅｌｉｎｇ ｉｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ Ｍａｄｉｓｏｎ，ＵＳＡ，１９９８：４３－５２
ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ［２５］ Ｂａｌａｂａｎｏｖｉ＇ｃ Ｍ，Ｓｈｏｈａｍ Ｙ．Ｆａｂ：Ｃｏｎｔｅｎｔ－ｂａｓｅｄ，ｃｏｌｌａｂｏｒａｔｉｖｅ
ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｆｌｏｒｅｎｃｅ，Ｉｔａｌｙ，２０１５：２７８－２８８ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ ｏｆ ｔｈｅ ＡＣＭ，１９９７，４０（３）：
［１２］ Ｓｏｎｇ Ｙ，Ｅｌｋａｈｋｙ Ａ Ｍ，Ｈｅ Ｘ．Ｍｕｌｔｉ－ｒａｔｅ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆｏｒ ６６－７２
ｔｅｍｐｏｒａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３９ｔｈ Ｉｎｔｅｒｎａ－ ［２６］ Ｓｃｈａｆｅｒ Ｊ Ｂ，Ｋｏｎｓｔａｎ Ｊ，Ｒｉｅｄｌ Ｊ．Ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｉｎ
ｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｅ－ｃｏｍｍｅｒｃｅ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １ｓｔ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ｐｉｓａ，Ｉｔａｌｙ，２０１６：９０９－９１２ Ｅｌｅｃｔｒｏｎｉｃ Ｃｏｍｍｅｒｃｅ．Ｄｅｎｖｅｒ，ＵＳＡ，１９９９：１５８－１６６
［１３］ Ｖａｓｉｌｅ Ｆ，Ｓｍｉｒｎｏｖａ Ｅ，Ｃｏｎｎｅａｕ Ａ．Ｍｅｔａ－Ｐｒｏｄ２Ｖｅｃ：Ｐｒｏｄｕｃｔ ［２７］ Ｓｉｌｖｅｒ Ｄ，Ｈｕａｎｇ Ａ，Ｍａｄｄｉｓｏｎ Ｃ Ｊ，ｅｔ ａｌ．Ｍａｓｔｅｒｉｎｇ ｔｈｅ
ｅｍｂｅｄｄｉｎｇｓ ｕｓｉｎｇ ｓｉｄｅ－ｉｎｆｏｒｍａｔｉｏｎ ｆｏｒ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／ ｇａｍｅ ｏｆ Ｇｏ ｗｉｔｈ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ａｎｄ ｔｒｅｅ ｓｅａｒｃｈ．
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ． Ｎａｔｕｒｅ，２０１６，５２９（７５８７）：４８４－４８９
Ｂｏｓｔｏｎ，ＵＳＡ，２０１６：２２５－２３２ ［２８］ Ｗｕ Ｙ，Ｓｃｈｕｓｔｅｒ Ｍ，Ｃｈｅｎ Ｚ，ｅｔ ａｌ．Ｇｏｏｇｌｅ’ｓ ｎｅｕｒａｌ ｍａｃｈｉｎｅ
［１４］ Ｇｒｂｏｖｉｃ Ｍ，Ｒａｄｏｓａｖｌｊｅｖｉｃ Ｖ，Ｄｊｕｒｉｃ Ｎ，ｅｔ ａｌ．Ｅ－ｃｏｍｍｅｒｃｅ ｉｎ ｔｒａｎｓｌａｔｉｏｎ ｓｙｓｔｅｍ：Ｂｒｉｄｇｉｎｇ ｔｈｅ ｇａｐ ｂｅｔｗｅｅｎ ｈｕｍａｎ ａｎｄ
ｙｏｕｒ ｉｎｂｏｘ：Ｐｒｏｄｕｃｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ ａｔ ｓｃａｌｅ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｍａｃｈｉｎｅ ｔｒａｎｓｌａｔｉｏｎ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１６０９．０８１４４，２０１６
ｏｆ ｔｈｅ ２１ｓｔ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ［２９］ Ｗａｎｇ Ｒ，Ｆｕ Ｂ，Ｆｕ Ｇ，ｅｔ ａｌ．Ｄｅｅｐ ＆ｃｒｏｓｓ ｎｅｔｗｏｒｋ ｆｏｒ ａｄ
Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓｙｄｎｅｙ，Ａｕｓｔｒａｌｉａ， ｃｌｉｃｋ ｐｒｅｄｉｃｔｉｏｎｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１７０８．０５１２３，２０１７
２０１５：１８０９－１８１８ ［３０］ Ｓｈａｎ Ｙ，Ｈｏｅｎｓ Ｔ Ｒ，Ｊｉａｏ Ｊ，ｅｔ ａｌ．Ｄｅｅｐ ｃｒｏｓｓｉｎｇ：Ｗｅｂ－ｓｃａｌｅ
［１５］ Ｈｓｉｅｈ Ｃ Ｋ，Ｙａｎｇ Ｌ，Ｃｕｉ Ｙ，ｅｔ ａｌ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｍｅｔｒｉｃ ｍｏｄｅｌｉｎｇ ｗｉｔｈｏｕｔ ｍａｎｕａｌｌｙ ｃｒａｆｔｅｄ ｃｏｍｂｉｎａｔｏｒｉａｌ ｆｅａｔｕｒｅｓ／／
ｌｅａｒｎｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２２ｎｄ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ
ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｐｅｒｔｈ，Ａｕｓｔｒａｌｉａ，２０１７：１９３－２０１ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓａｎ
［１６］ Ｒｏｙ Ｓ，Ｇｕｎｔｕｋｕ Ｓ Ｃ．Ｌａｔｅｎｔ ｆａｃｔｏｒ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｆｏｒ ｃｏｌｄ－ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１６：２５５－２６２
ｓｔａｒｔ ｖｉｄｅｏ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １０ｔｈ ＡＣＭ ［３１］ Ｚｈｕ Ｊ，Ｓｈａｎ Ｙ，Ｍａｏ Ｊ Ｃ，ｅｔ ａｌ．Ｄｅｅｐ ｅｍｂｅｄｄｉｎｇ ｆｏｒｅｓｔ：
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１６： Ｆｏｒｅｓｔ－ｂａｓｅｄ ｓｅｒｖｉｎｇ ｗｉｔｈ ｄｅｅｐ ｅｍｂｅｄｄｉｎｇ ｆｅａｔｕｒｅｓ．ａｒＸｉｖ
９９－１０６ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１７０３．０５２９１，２０１７
［１７］ Ｌｉ Ｓ，Ｋａｗａｌｅ Ｊ，Ｆｕ Ｙ．Ｄｅｅｐ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｖｉａ ［３２］ Ｇｕｏ Ｈ，Ｔａｎｇ Ｒ，Ｙｅ Ｙ，ｅｔ ａｌ．ＤｅｅｐＦＭ：Ａ ｆａｃｔｏｒｉｚａｔｉｏｎ－
ｍａｒｇｉｎａｌｉｚｅｄ ｄｅｎｏｉｓｉｎｇ ａｕｔｏ－ｅｎｃｏｄｅｒ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ ｍａｃｈｉｎｅ ｂａｓｅｄ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｆｏｒ ＣＴＲ ｐｒｅｄｉｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ ｏｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ ｏｆ ｔｈｅ ２６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ
Ｋｎｏｗｌｅｄｇｅ Ｍａｎａｇｅｍｅｎｔ．Ｍｅｌｂｏｕｒｎｅ，Ａｕｓｔｒａｌｉａ，２０１５：８１１－ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｍｅｌｂｏｕｒｎｅ，Ａｕｓｔｒａｌｉａ，２０１７：１７２５－１７３１
８２０ ［３３］ Ｚｈｏｕ Ｇ，Ｓｏｎｇ Ｃ，Ｚｈｕ Ｘ，ｅｔ ａｌ．Ｄｅｅｐ ｉｎｔｅｒｅｓｔ ｎｅｔｗｏｒｋ ｆｏｒ
［１８］ Ｚｈｅｎｇ Ｌ，Ｎｏｒｏｏｚｉ Ｖ，Ｙｕ Ｐ Ｓ．Ｊｏｉｎｔ ｄｅｅｐ ｍｏｄｅｌｉｎｇ ｏｆ ｕｓｅｒｓ ｃｌｉｃｋ－ｔｈｒｏｕｇｈ ｒａｔｅ ｐｒｅｄｉｃｔｉｏｎ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１７０６．
ａｎｄ ｉｔｅｍｓ ｕｓｉｎｇ ｒｅｖｉｅｗｓ ｆｏｒ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ０６９７８，２０１７
ｔｈｅ １０ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ ［３４］ Ｗｉｌｌｉａｍｓ Ｄ，Ｈｉｎｔｏｎ Ｇ．Ｌｅａｒｎｉｎｇ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｂｙ ｂａｃｋ－
Ｄａｔａ Ｍｉｎｉｎｇ．Ｃａｍｂｒｉｄｇｅ，ＵＫ，２０１７：４２５－４３４ ｐｒｏｐａｇａｔｉｎｇ ｅｒｒｏｒｓ．Ｎａｔｕｒｅ，１９８６，３２３（６０８８）：５３３－５３８
［１９］ Ｂａｎｓａｌ Ｔ，Ｂｅｌａｎｇｅｒ Ｄ，ＭｃＣａｌｌｕｍ Ａ．Ａｓｋ ｔｈｅ ＧＲＵ：Ｍｕｌｔｉ－ ［３５］ Ｂｅｎｇｉｏ Ｙ，Ｌａｍｂｌｉｎ Ｐ，Ｐｏｐｏｖｉｃｉ Ｄ，ｅｔ ａｌ．Ｇｒｅｅｄｙ ｌａｙｅｒ－ｗｉｓｅ
ｔａｓｋ ｌｅａｒｎｉｎｇ ｆｏｒ ｄｅｅｐ ｔｅｘｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｒａｉｎｉｎｇ ｏｆ ｄｅｅｐ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ
ｔｈｅ １０ｔｈ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｂｏｓｔｏｎ， Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｖａｎｃｏｕｖｅｒ，Ｃａｎａｄａ，
ＵＳＡ，２０１６：１０７－１１４ ２００７，１９：１５３
［２０］ Ｗｕ Ｙ，ＤｕＢｏｉｓ Ｃ，Ｚｈｅｎｇ Ａ Ｘ，ｅｔ ａｌ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｄｅｎｏｉｓｉｎｇ ［３６］ Ｖｉｎｃｅｎｔ Ｐ，Ｌａｒｏｃｈｅｌｌｅ Ｈ，Ｂｅｎｇｉｏ Ｙ，ｅｔ ａｌ．Ｅｘｔｒａｃｔｉｎｇ ａｎｄ
ａｕｔｏ－ｅｎｃｏｄｅｒｓ ｆｏｒ ｔｏｐ－ｎ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｃｏｍｐｏｓｉｎｇ ｒｏｂｕｓｔ ｆｅａｔｕｒｅｓ ｗｉｔｈ ｄｅｎｏｉｓｉｎｇ ａｕｔｏｅｎｃｏｄｅｒｓ／／
ｏｆ ｔｈｅ ９ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２５ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ
Ｄａｔａ Ｍｉｎｉｎｇ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１６：１５３－１６２ Ｌｅａｒｎｉｎｇ．Ｈｅｌｓｉｎｋｉ，Ｆｉｎｌａｎｄ，２００８：１０９６－１１０３ １６４４ 计 算 机 学 报 ２０１８年
［３７］ Ｓｅｄｈａｉｎ Ｓ，Ｍｅｎｏｎ Ａ Ｋ，Ｓａｎｎｅｒ Ｓ，ｅｔ ａｌ．Ａｕｔｏｒｅｃ：Ａｕｔｏｅｎ－ ［５１］ Ｈｉｎｔｏｎ Ｇ Ｅ，Ｏｓｉｎｄｅｒｏ Ｓ，Ｔｅｈ Ｙ Ｗ．Ａ ｆａｓｔ ｌｅａｒｎｉｎｇ
ｃｏｄｅｒｓ ｍｅｅｔ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ ａｌｇｏｒｉｔｈｍ ｆｏｒ ｄｅｅｐ ｂｅｌｉｅｆ ｎｅｔｓ．Ｎｅｕｒａｌ Ｃｏｍｐｕｔａｔｉｏｎ，２００６，
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｆｌｏｒｅｎｃｅ， １８（７）：１５２７－１５５４
Ｉｔａｌｙ，２０１５：１１１－１１２ ［５２］ Ｂｅｎｇｉｏ Ｙ．Ｌｅａｒｎｉｎｇ ｄｅｅｐ ａｒｃｈｉｔｅｃｔｕｒｅｓ ｆｏｒ ＡＩ．Ｆｏｕｎｄａｔｉｏｎｓ
［３８］ Ｗａｎｇ Ｈ，Ｓｈｉ Ｘ，Ｙｅｕｎｇ Ｄ Ｙ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｒｅｃｕｒｒｅｎｔ ａｎｄ Ｔｒｅｎｄｓ?ｉｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ，２００９，２（１）：１－１２７
ａｕｔｏｅｎｃｏｄｅｒ：Ｒｅｃｏｍｍｅｎｄ ｗｈｉｌｅ ｌｅａｒｎｉｎｇ ｔｏ ｆｉｌｌ ｉｎ ｔｈｅ ｂｌａｎｋｓ ［５３］ Ｗａｎｇ Ｘ，Ｗａｎｇ Ｙ．Ｉｍｐｒｏｖｉｎｇ ｃｏｎｔｅｎｔ－ｂａｓｅｄ ａｎｄ ｈｙｂｒｉｄ
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ ｍｕｓｉｃ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｕｓｉｎｇ ｄｅｅｐ ｌｅａｒｎｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｂａｒｃｅｌｏｎａ，Ｓｐａｉｎ，２０１６：４１５－４２３
ｔｈｅ ２２ｎｄ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍｕｌｔｉｍｅｄｉａ．
［３９］ Ｗａｎｇ Ｈ，Ｓｈｉ Ｘ，Ｙｅｕｎｇ Ｄ Ｙ．Ｒｅｌａｔｉｏｎａｌ ｓｔａｃｋｅｄ ｄｅｎｏｉｓｉｎｇ Ｏｒｌａｎｄｏ，ＵＳＡ，２０１４：６２７－６３６
ａｕｔｏｅｎｃｏｄｅｒ ｆｏｒ ｔａｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
［５４］ ＬｅＣｕｎ Ｙ，Ｂｏｓｅｒ Ｂ，Ｄｅｎｋｅｒ Ｊ Ｓ，ｅｔ ａｌ．Ｂａｃｋｐｒｏｐａｇａｔｉｏｎ ａｐｐｌｉｅｄ
２９ｔｈ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ａｕｓｔｉｎ，ＵＳＡ，
ｔｏ ｈａｎｄｗｒｉｔｔｅｎ ｚｉｐ ｃｏｄｅ ｒｅｃｏｇｎｉｔｉｏｎ．Ｎｅｕｒａｌ Ｃｏｍｐｕｔａｔｉｏｎ，
２０１５：３０５２－３０５８
１９８９，１（４）：５４１－５５１
［４０］ Ｄｏｎｇ Ｘ，Ｙｕ Ｌ，Ｗｕ Ｚ，ｅｔ ａｌ．Ａ ｈｙｂｒｉｄ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ
［５５］ ＬｅＣｕｎ Ｙ，Ｂｏｔｔｏｕ Ｌ，Ｂｅｎｇｉｏ Ｙ，ｅｔ ａｌ．Ｇｒａｄｉｅｎｔ－ｂａｓｅｄ
ｍｏｄｅｌ ｗｉｔｈ ｄｅｅｐ ｓｔｒｕｃｔｕｒｅ ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／
ｌｅａｒｎｉｎｇ ａｐｐｌｉｅｄ ｔｏ ｄｏｃｕｍｅｎｔ ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３１ｓｔ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ
ＩＥＥＥ，１９９８，８６（１１）：２２７８－２３２４
Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１７：１３０９－１３１５
［４１］ Ｗｅｉ Ｊ，Ｈｅ Ｊ，Ｃｈｅｎ Ｋ，ｅｔ ａｌ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ａｎｄ ｄｅｅｐ ［５６］ Ｋｒｉｚｈｅｖｓｋｙ Ａ，Ｓｕｔｓｋｅｖｅｒ Ｉ，Ｈｉｎｔｏｎ Ｇ Ｅ．ＩｍａｇｅＮｅｔ ｃｌａｓｓｉｆｉ－
ｃａｔｉｏｎ ｗｉｔｈ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ ｆｏｒ ｃｏｌｄ ｓｔａｒｔ ｉｔｅｍｓ．
Ｅｘｐｅｒｔ Ｓｙｓｔｅｍｓ ｗｉｔｈ Ａｐｐｌｉｃａｔｉｏｎｓ，２０１７，６９：２９－３９ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．
［４２］ Ｌｉ Ｘ，Ｓｈｅ Ｊ．Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｖａｒｉａｔｉｏｎａｌ Ａｕｔｏｅｎｃｏｄｅｒ ｆｏｒ Ｌａｋｅ Ｔａｈｏｅ，ＵＳＡ，２０１２：１０９７－１１０５
Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２３ｒｄ ＡＣＭ ＳＩＧＫＤＤ ［５７］ Ｖａｎ ｄｅｎ Ｏｏｒｄ Ａ，Ｄｉｅｌｅｍａｎ Ｓ，Ｓｃｈｒａｕｗｅｎ Ｂ．Ｄｅｅｐ ｃｏｎｔｅｎｔ－
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ ｂａｓｅｄ ｍｕｓｉｃ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ
Ｍｉｎｉｎｇ．Ｈａｌｉｆａｘ，Ｃａｎａｄａ，２０１７：３０５－３１４ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｌａｋｅ Ｔａｈｏｅ，
［４３］ Ｈｉｎｔｏｎ Ｇ Ｅ，Ｓｅｊｎｏｗｓｋｉ Ｔ Ｊ．Ｌｅａｒｎｉｎｇ ａｎｄ Ｒｅｌｅａｒｎｉｎｇ ｉｎ ＵＳＡ，２０１３：２６４３－２６５１
Ｂｏｌｔｚｍａｎｎ Ｍａｃｈｉｎｅｓ．Ｍａｓｓａｃｈｕｓｅｔｔｓ，ＵＳＡ：ＭＩＴ Ｐｒｅｓｓ，１９８６ ［５８］ Ｇｅｎｇ Ｘ，Ｚｈａｎｇ Ｈ，Ｂｉａｎ Ｊ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ ｉｍａｇｅ ａｎｄ ｕｓｅｒ
［４４］ Ｓｍｏｌｅｎｓｋｙ Ｐ．Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ ｉｎ Ｄｙｎａｍｉｃａｌ Ｓｙｓｔｅｍｓ： ｆｅａｔｕｒｅｓ ｆｏｒ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｉｎ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
Ｆｏｕｎｄａｔｉｏｎｓ ｏｆ Ｈａｒｍｏｎｙ Ｔｈｅｏｒｙ ［Ｐｈ．Ｄ．ｄｉｓｓｅｒｔａｔｉｏｎ］． ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．
Ｃｏｌｏｒａｄｏ Ｕｎｉｖｅｒｓｉｔｙ ａｔ Ｂｏｕｌｄｅｒ Ｄｅｐａｒｔｍｅｎｔ ｏｆ Ｃｏｍｐｕｔｅｒ Ｓａｎｔｉａｇｏ，Ｃｈｉｌｅ，２０１５：４２７４－４２８２
Ｓｃｉｅｎｃｅ，Ｃｏｌｏｒａｄｏ，ＵＳＡ，１９８６ ［５９］ Ｋｉｍ Ｄ，Ｐａｒｋ Ｃ，Ｏｈ Ｊ，ｅｔ ａｌ．Ｃｏｎｖｏｌｕｔｉｏｎａｌ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ
［４５］ Ｈｉｎｔｏｎ Ｇ Ｅ．Ａ ｐｒａｃｔｉｃａｌ ｇｕｉｄｅ ｔｏ ｔｒａｉｎｉｎｇ ｒｅｓｔｒｉｃｔｅｄ ｆｏｒ ｄｏｃｕｍｅｎｔ ｃｏｎｔｅｘｔ－ａｗａｒｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ．Ｍｏｍｅｎｔｕｍ，２０１０，９（１）：９２６ ｔｈｅ １０ｔｈ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｂｏｓｔｏｎ，
［４６］ Ｓａｌａｋｈｕｔｄｉｎｏｖ Ｒ，Ｍｎｉｈ Ａ，Ｈｉｎｔｏｎ Ｇ．Ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ＵＳＡ，２０１６：２３３－２４０
ｍａｃｈｉｎｅｓ ｆｏｒ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ
［６０］ Ｒａｗａｔ Ｙ Ｓ，Ｋａｎｋａｎｈａｌｌｉ Ｍ Ｓ．ＣｏｎＴａｇＮｅｔ：Ｅｘｐｌｏｉｔｉｎｇ ｕｓｅｒ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｃｏｒｖａｌｉｓ，
ｃｏｎｔｅｘｔ ｆｏｒ ｉｍａｇｅ ｔａｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ＵＳＡ，２００７：７９１－７９８
２０１６ＡＣＭ ｏｎ Ｍｕｌｔｉｍｅｄｉａ Ｃｏｎｆｅｒｅｎｃｅ．Ａｍｓｔｅｒｄａｍ，Ｎｅｔｈｅｒｌａｎｄ，
［４７］ Ｐｈｕｎｇ Ｄ Ｑ，Ｖｅｎｋａｔｅｓｈ Ｓ．Ｏｒｄｉｎａｌ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ ｆｏｒ
２０１６：１１０２－１１０６
ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２５ｔｈ Ｃｏｎｆｅｒｅｎｃｅ
［６１］ Ｌｅｉ Ｃ，Ｌｉｕ Ｄ，Ｌｉ Ｗ，ｅｔ ａｌ．Ｃｏｍｐａｒａｔｉｖｅ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｏｆ
ｏｎ Ｕｎｃｅｒｔａｉｎｔｙ ｉｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｖｉｒｇｉｎｉａ，ＵＳＡ，
ｈｙｂｒｉｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｆｏｒ ｉｍａｇｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
２００９：５４８－５５６
ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
［４８］ Ｇｅｏｒｇｉｅｖ Ｋ，Ｎａｋｏｖ Ｐ．Ａ ｎｏｎ－ＩＩＤ ｆｒａｍｅｗｏｒｋ ｆｏｒ ｃｏｌｌａｂｏｒａｔｉｖｅ
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｌａｓ Ｖｅｇａｓ，ＵＳＡ，２０１６：２５４５－２５５３
ｆｉｌｔｅｒｉｎｇ ｗｉｔｈ ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
［６２］ Ｗａｎｇ Ｓ，Ｗａｎｇ Ｙ，Ｔａｎｇ Ｊ，ｅｔ ａｌ．Ｗｈａｔ ｙｏｕｒ ｉｍａｇｅｓ ｒｅｖｅａｌ：
ｔｈｅ ３０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．
Ａｔｌａｎｔａ，ＵＳＡ，２０１３：１１４８－１１５６
Ｅｘｐｌｏｉｔｉｎｇ ｖｉｓｕａｌ ｃｏｎｔｅｎｔｓ ｆｏｒ ｐｏｉｎｔ－ｏｆ－ｉｎｔｅｒｅｓｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ
［４９］ Ｈｅ Ｊｉｅ－Ｙｕｅ， Ｍａ Ｂｅｉ．Ｂａｓｅｄ－ｏｎ ｒｅａｌ－ｖａｌｕｅｄ ｃｏｎｄｉｔｉｏｎａｌ
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ
Ｗｉｄｅ Ｗｅｂ．Ｗｅｓｔｅｒｎ Ａｕｓｔｒａｌｉａ，２０１７：３９１－４００
ｒｅｓｔｒｉｃｔｅｄ Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅ ａｎｄ ｓｏｃｉａｌ ｎｅｔｗｏｒｋ ｆｏｒ ｃｏｌｌａｂｏ－
ｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１６，３９（１）： ［６３］ Ｓｕｔｓｋｅｖｅｒ Ｉ，Ｖｉｎｙａｌｓ Ｏ，Ｌｅ Ｑ Ｖ．Ｓｅｑｕｅｎｃｅ ｔｏ ｓｅｑｕｅｎｃｅ
１８３－１９５（ｉｎ Ｃｈｉｎｅｓｅ） ｌｅａｒｎｉｎｇ ｗｉｔｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ
（何洁月，马贝．利用社交关系的实值条件受限玻尔兹曼机 ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，
协同过滤推荐算法．计算机学报，２０１６，３９（１）：１８３－１９５） ２０１４：３１０４－３１１２
［５０］ Ｎｇｕｙｅｎ Ｔ Ｔ，Ｌａｕｗ Ｈ Ｗ．Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｆｏｒ ［６４］ Ｇｒａｖｅｓ Ａ，Ｊａｉｔｌｙ Ｎ．Ｔｏｗａｒｄｓ ｅｎｄ－ｔｏ－ｅｎｄ ｓｐｅｅｃｈ ｒｅｃｏｇｎｉｔｉｏｎ
ｈｏｍｏｐｈｉｌｉｃ ｐｒｅｆｅｒｅｎｃｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １０ｔｈ ＡＣＭ ｗｉｔｈ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３１ｓｔ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１６： Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｂｅｉｊｉｎｇ，
３１７－３２４ Ｃｈｉｎａ，２０１４：１７６４－１７７２ ７期 黄立威等：基于深度学习的推荐系统研究综述 １６４５
［６５］ Ｋａｒｐａｔｈｙ Ａ，Ｆｅｉ－Ｆｅｉ Ｌ．Ｄｅｅｐ ｖｉｓｕａｌ－ｓｅｍａｎｔｉｃ ａｌｉｇｎｍｅｎｔｓ ｆｏｒ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｕｓｉｎｇ ａ ｄｅｅｐ－ｓｅｍａｎｔｉｃ ｓｉｍｉｌａｒｉｔｙ ｍｏｄｅｌ ｗｉｔｈ
ｇｅｎｅｒａｔｉｎｇ ｉｍａｇｅ ｄｅｓｃｒｉｐｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ ｎｅｇａｔｉｖｅ ｓａｍｐｌｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２５ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ． ｏｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ Ｋｎｏｗｌｅｄｇｅ Ｍａｎａｇｅｍｅｎｔ．
Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：３１２８－３１３７ Ｉｎｄｉａｎａｐｏｌｉｓ，ＵＳＡ，２０１６：１９２１－１９２４
［６６］ Ｈｏｃｈｒｅｉｔｅｒ Ｓ，Ｓｃｈｍｉｄｈｕｂｅｒ Ｊ．Ｌｏｎｇ ｓｈｏｒｔ－ｔｅｒｍ ｍｅｍｏｒｙ． ［８１］ Ｃｈｅｎ Ｃ，Ｍｅｎｇ Ｘ，Ｘｕ Ｚ，ｅｔ ａｌ．Ｌｏｃａｔｉｏｎ－ａｗａｒｅ ｐｅｒｓｏｎａｌｉｚｅｄ
Ｎｅｕｒａｌ Ｃｏｍｐｕｔａｔｉｏｎ，１９９７，９（８）：１７３５－１７８０ ｎｅｗｓ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｗｉｔｈ ｄｅｅｐ ｓｅｍａｎｔｉｃ ａｎａｌｙｓｉｓ．ＩＥＥＥ
［６７］ Ｃｈｏ Ｋ，Ｖａｎ Ｍｅｒｒｉｎｂｏｅｒ Ｂ，Ｂａｈｄａｎａｕ Ｄ，ｅｔ ａｌ．Ｏｎ ｔｈｅ
Ａｃｃｅｓｓ，２０１７，５（９９）：１６２４－１６３８
ｐｒｏｐｅｒｔｉｅｓ ｏｆ ｎｅｕｒａｌ ｍａｃｈｉｎｅ ｔｒａｎｓｌａｔｉｏｎ：Ｅｎｃｏｄｅｒ－ｄｅｃｏｄｅｒ ［８２］ Ｈｅ Ｘ，Ｌｉａｏ Ｌ，Ｚｈａｎｇ Ｈ，ｅｔ ａｌ．Ｎｅｕｒａｌ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ
ａｐｐｒｏａｃｈｅｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１４０９．１２５９，２０１４ ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ
Ｗｅｂ．Ｐｅｒｔｈ，Ａｕｓｔｒａｌｉａ，２０１７：１７３－１８２
［６８］ Ｗｅｓｔｏｎ Ｊ，Ｃｈｏｐｒａ Ｓ，Ｂｏｒｄｅｓ Ａ．Ｍｅｍｏｒｙ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ
［８３］ Ｒｅｎｄｌｅ Ｓ．Ｆａｃｔｏｒｉｚａｔｉｏｎ ｍａｃｈｉｎｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１０
ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１４１０．３９１６，２０１４
ＩＥＥＥ １０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓｙｄｎｅｙ，
［６９］Ｊｏｕｌｉｎ Ａ，Ｍｉｋｏｌｏｖ Ｔ．Ｉｎｆｅｒｒｉｎｇ ａｌｇｏｒｉｔｈｍｉｃ ｐａｔｔｅｒｎｓ ｗｉｔｈ
Ａｕｓｔｒａｌｉａ，２０１０：９９５－１０００
ｓｔａｃｋ－ａｕｇｍｅｎｔｅｄ ｒｅｃｕｒｒｅｎｔ ｎｅｔｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ
［８４］ Ｑｕ Ｙ，Ｃａｉ Ｈ，Ｒｅｎ Ｋ，ｅｔ ａｌ．Ｐｒｏｄｕｃｔ－ｂａｓｅｄ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ
ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，
ｆｏｒ ｕｓｅｒ ｒｅｓｐｏｎｓｅ ｐｒｅｄｉｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１６ＩＥＥＥ
２０１５：１９０－１９８
１６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｄａｔａ Ｍｉｎｉｎｇ．Ｂａｒｃｅｌｏｎａ，
［７０］ Ｇｒａｖｅｓ Ａ，Ｗａｙｎｅ Ｇ，Ｄａｎｉｈｅｌｋａ Ｉ．Ｎｅｕｒａｌ ｔｕｒｉｎｇ ｍａｃｈｉｎｅｓ．
Ｓｐａｉｎ，２０１６：１１４９－１１５４
ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１４１０．５４０１，２０１４
［８５］ Ｈｅ Ｘ，Ｃｈｕａ Ｔ Ｓ．Ｎｅｕｒａｌ ｆａｃｔｏｒｉｚａｔｉｏｎ ｍａｃｈｉｎｅｓ ｆｏｒ ｓｐａｒｓｅ
［７１］ Ｇｒａｖｅｓ Ａ，Ｗａｙｎｅ Ｇ，Ｒｅｙｎｏｌｄｓ Ｍ，ｅｔ ａｌ．Ｈｙｂｒｉｄ ｃｏｍｐｕｔｉｎｇ ｐｒｅｄｉｃｔｉｖｅ ａｎａｌｙｔｉｃｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ４０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ
ｕｓｉｎｇ ａ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｗｉｔｈ ｄｙｎａｍｉｃ ｅｘｔｅｒｎａｌ ｍｅｍｏｒｙ． ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ
Ｎａｔｕｒｅ，２０１６，５３８（７６２６）：４７１－４７６ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ｔｏｋｙｏ，Ｊａｐａｎ，２０１７：３５５－３６４
［７２］ Ｌｉｕ Ｑ，Ｗｕ Ｓ，Ｗａｎｇ Ｌ，ｅｔ ａｌ．Ｐｒｅｄｉｃｔｉｎｇ ｔｈｅ ｎｅｘｔ ｌｏｃａｔｉｏｎ： ［８６］ Ｘｉａｏ Ｊ，Ｙｅ Ｈ，Ｈｅ Ｘ，ｅｔ ａｌ．Ａｔｔｅｎｔｉｏｎａｌ ｆａｃｔｏｒｉｚａｔｉｏｎ
Ａ ｒｅｃｕｒｒｅｎｔ ｍｏｄｅｌ ｗｉｔｈ ｓｐａｔｉａｌ ａｎｄ ｔｅｍｐｏｒａｌ ｃｏｎｔｅｘｔｓ／／ ｍａｃｈｉｎｅｓ：Ｌｅａｒｎｉｎｇ ｔｈｅ ｗｅｉｇｈｔ ｏｆ ｆｅａｔｕｒｅ ｉｎｔｅｒａｃｔｉｏｎｓ ｖｉａ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３０ｔｈ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ ａｔｔｅｎｔｉｏｎ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ
Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｐｈｏｅｎｉｘ，ＵＳＡ，２０１６：１９４－２００ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ． Ｍｅｌｂｏｕｒｎｅ，
［７３］ Ｌｉｕ Ｑ，Ｗｕ Ｓ，Ｗａｎｇ Ｌ．Ｍｕｌｔｉ－ｂｅｈａｖｉｏｒａｌ ｓｅｑｕｅｎｔｉａｌ ｐｒｅｄｉｃ－ Ａｕｓｔｒａｌｉａ，２０１７：３１１９－３１２５
ｔｉｏｎ ｗｉｔｈ ｒｅｃｕｒｒｅｎｔ ｌｏｇ－ｂｉｌｉｎｅａｒ ｍｏｄｅｌ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ ［８７］ Ｇｏｎｇ Ｙ，Ｚｈａｎｇ Ｑ．Ｈａｓｈｔａｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｕｓｉｎｇ ａｔｔｅｎｔｉｏｎ－
Ｋｎｏｗｌｅｄｇｅ ａｎｄ Ｄａｔａ Ｅｎｇｉｎｅｅｒｉｎｇ，２０１７，２９（６）：１２５４－１２６７ ｂａｓｅｄ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２５ｔｈ
［７４］ Ｙａｎｇ Ｃ，Ｓｕｎ Ｍ，Ｚｈａｏ Ｗ Ｘ，ｅｔ ａｌ．Ａ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｎｅｗ
ａｐｐｒｏａｃｈ ｔｏ ｊｏｉｎｔｌｙ ｍｏｄｅｌｉｎｇ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ ａｎｄ ｍｏｂｉｌｅ
Ｙｏｒｋ，ＵＳＡ，２０１６：２７８２－２７８８
ｔｒａｊｅｃｔｏｒｉｅｓ．ＡＣＭ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｓｙｓｔｅｍｓ， ［８８］ Ｚｈａｎｇ Ｑ，Ｗａｎｇ Ｊ，Ｈｕａｎｇ Ｈ，ｅｔ ａｌ．Ｈａｓｈｔａｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ
２０１７，３５（４）：３６ ｆｏｒ ｍｕｌｔｉｍｏｄａｌ ｍｉｃｒｏｂｌｏｇ ｕｓｉｎｇ ｃｏ－ａｔｔｅｎｔｉｏｎ ｎｅｔｗｏｒｋ／／
［７５］ Ｈｉｄａｓｉ Ｂ，Ｋａｒａｔｚｏｇｌｏｕ Ａ，Ｂａｌｔｒｕｎａｓ Ｌ，ｅｔ ａｌ．Ｓｅｓｓｉｏｎ－ｂａｓｅｄ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｍｅｌｂｏｕｒｎｅ，Ａｕｓｔｒａｌｉａ，２０１７：３４２０－
ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ ｗｉｔｈ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ
ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１５１１．０６９３９，２０１５ ３４２６
［８９］ Ｓｅｏ Ｓ，Ｈｕａｎｇ Ｊ，Ｙａｎｇ Ｈ，ｅｔ ａｌ．Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｏｆ
［７６］ Ｔａｎ Ｙ Ｋ，Ｘｕ Ｘ，Ｌｉｕ Ｙ．Ｉｍｐｒｏｖｅｄ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ
ｕｓｅｒｓ ａｎｄ ｉｔｅｍｓ ｆｏｒ ｒｅｖｉｅｗ ｒａｔｉｎｇ ｐｒｅｄｉｃｔｉｏｎ ｕｓｉｎｇ ａｔｔｅｎｔｉｏｎ－
ｆｏｒ ｓｅｓｓｉｏｎ－ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １ｓｔ
ｂａｓｅｄ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３ｒｄ
Ｗｏｒｋｓｈｏｐ ｏｎ Ｄｅｅｐ Ｌｅａｒｎｉｎｇ ｆｏｒ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｗｏｒｋｓｈｏｐ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｍｅｔｈｏｄｓ ｆｏｒ
Ｂｏｓｔｏｎ，ＵＳＡ，２０１６：１７－２２
Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ（ＳＤＭ’１７）．Ｈｕｓｔｏｎ，ＵＳＡ，２０１７
［７７］ Ｗｕ Ｃ，Ｗａｎｇ Ｊ，Ｌｉｕ Ｊ，ｅｔ ａｌ．Ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｂａｓｅｄ
［９０］ Ｗａｎｇ Ｘ，Ｙｕ Ｌ，Ｒｅｎ Ｋ，ｅｔ ａｌ．Ｄｙｎａｍｉｃ ａｔｔｅｎｔｉｏｎ ｄｅｅｐ ｍｏｄｅｌ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｆｏｒ ｔｉｍｅ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｆｅｅｄｂａｃｋ．Ｋｎｏｗｌｅｄｇｅ－
ｆｏｒ ａｒｔｉｃｌｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｂｙ ｌｅａｒｎｉｎｇ ｈｕｍａｎ ｅｄｉｔｏｒｓ’
Ｂａｓｅｄ Ｓｙｓｔｅｍｓ，２０１６，１０９：９０－１０３
ｄｅｍｏｎｓｔｒａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２３ｒｄ ＡＣＭ ＳＩＧＫＤＤ
［７８］ Ｄａｉ Ｈ，Ｗａｎｇ Ｙ，Ｔｒｉｖｅｄｉ Ｒ，ｅｔ ａｌ．Ｒｅｃｕｒｒｅｎｔ ｃｏｅｖｏｌｕｔｉｏｎａｒｙ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ
ｆｅａｔｕｒｅ ｅｍｂｅｄｄｉｎｇ ｐｒｏｃｅｓｓｅｓ ｆｏｒ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ
Ｍｉｎｉｎｇ．Ｈａｌｉｆａｘ，Ｃａｎａｄａ，２０１７：２０５１－２０５９
ｏｆ ｔｈｅ １ｓｔ Ｗｏｒｋｓｈｏｐ ｏｎ Ｄｅｅｐ Ｌｅａｒｎｉｎｇ ｆｏｒ Ｒｅｃｏｍｍｅｎｄｅｒ ［９１］ Ｌｉ Ｙ，Ｌｉｕ Ｔ，Ｊｉａｎｇ Ｊ，ｅｔ ａｌ．Ｈａｓｈｔａｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｗｉｔｈ
Ｓｙｓｔｅｍｓ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１６：２９－３４
ｔｏｐｉｃａｌ ａｔｔｅｎｔｉｏｎ－ｂａｓｅｄ ＬＳＴＭ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２６ｔｈ
［７９］ Ｈｕａｎｇ Ｐ Ｓ，Ｈｅ Ｘ，Ｇａｏ Ｊ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ ｄｅｅｐ ｓｔｒｕｃｔｕｒｅｄ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔａｔｉｏｎａｌ Ｌｉｎｇｕｉｓｔｉｃｓ．
ｓｅｍａｎｔｉｃ ｍｏｄｅｌｓ ｆｏｒ ｗｅｂ ｓｅａｒｃｈ ｕｓｉｎｇ ｃｌｉｃｋｔｈｒｏｕｇｈ ｄａｔａ／／ Ｏｓａｋａ，Ｊａｐａｎ，２０１６：３０１９－３０２９
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２２ｎｄ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ［９２］ Ｈｕａｎｇ Ｈ，Ｚｈａｎｇ Ｑ，Ｇｏｎｇ Ｙ，ｅｔ ａｌ．Ｈａｓｈｔａｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ ＆Ｋｎｏｗｌｅｄｇｅ Ｍａｎａｇｅｍｅｎｔ．Ｓａｎ ｕｓｉｎｇ ｅｎｄ－ｔｏ－ｅｎｄ ｍｅｍｏｒｙ ｎｅｔｗｏｒｋｓ ｗｉｔｈ ｈｉｅｒａｒｃｈｉｃａｌ ａｔｔｅｎｔｉｏｎ
Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１３：２３３３－２３３８ ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
［８０］ Ｘｕ Ｚ，Ｃｈｅｎ Ｃ，Ｌｕｋａｓｉｅｗｉｃｚ Ｔ，ｅｔ ａｌ．Ｔａｇ－ａｗａｒｅ ｐｅｒｓｏｎａｌｉｚｅｄ Ｃｏｍｐｕｔａｔｉｏｎａｌ Ｌｉｎｇｕｉｓｔｉｃｓ．Ｏｓａｋａ，Ｊａｐａｎ，２０１６：９４３－９５２ １６４６ 计 算 机 学 报 ２０１８年
［９３］ Ｈｕａｎｇ Ｈ，Ｚｈａｎｇ Ｑ，Ｈｕａｎｇ Ｘ，ｅｔ ａｌ．Ｍｅｎｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ Ａ ｈｙｂｒｉｄ ｐａｉｒ－ｗｉｓｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｌｇｏｒｉｔｈｍ ｗｉｔｈ ｉｍｐｌｉｃｉｔ
ｆｏｒ ｔｗｉｔｔｅｒ ｗｉｔｈ ｅｎｄ－ｔｏ－ｅｎｄ ｍｅｍｏｒｙ ｎｅｔｗｏｒｋ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｆｅｅｄｂａｃｋ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０ｔｈ Ｐａｃｉｆｉｃ－Ａｓｉａ Ｃｏｎｆｅｒｅｎｃｅ
ｏｆ ｔｈｅ ２６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ａｕｃｋｌａｎｄ，Ｎｅｗ
Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｍｅｌｂｏｕｒｎｅ，Ａｕｓｔｒａｌｉａ，２０１７：１８７２－１８７８ Ｚｅａｌａｎｄ，２０１６：５５５－５６７
［９４］ Ｏｋｕｒａ Ｓ，Ｔａｇａｍｉ Ｙ，Ｏｎｏ Ｓ，ｅｔ ａｌ．Ｅｍｂｅｄｄｉｎｇ－ｂａｓｅｄ ｎｅｗｓ ［１０６］ Ｌｉｎ Ｙ，Ｌｉｕ Ｚ，Ｚｈｕ Ｘ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ ｅｎｔｉｔｙ ａｎｄ ｒｅｌａｔｉｏｎ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｆｏｒ ｍｉｌｌｉｏｎｓ ｏｆ ｕｓｅｒｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ｅｍｂｅｄｄｉｎｇｓ ｆｏｒ ｋｎｏｗｌｅｄｇｅ ｇｒａｐｈ ｃｏｍｐｌｅｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ
２３ｒｄ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ ｏｆ ｔｈｅ ２９ｔｈ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．
Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｈａｌｉｆａｘ，Ｃａｎａｄａ，２０１７：１９３３－ Ａｕｓｔｉｎ，ＵＳＡ，２０１５：２１８１－２１８７
１９４２ ［１０７］ Ｋｏｒｅｎ Ｙ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｗｉｔｈ ｔｅｍｐｏｒａｌ ｄｙｎａｍｉｃｓ．
［９５］ Ｓｔｒｕｂ Ｆ，Ｍａｒｙ Ｊ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｗｉｔｈ ｓｔａｃｋｅｄ Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ ｏｆ ｔｈｅ ＡＣＭ，２０１０，５３（４）：８９－９７
ｄｅｎｏｉｓｉｎｇ ＡｕｔｏＥｎｃｏｄｅｒｓ ａｎｄ ｓｐａｒｓｅ ｉｎｐｕｔｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ［１０８］ Ｃｈｅｎ Ｍ，Ｘｕ Ｚ，Ｗｅｉｎｂｅｒｇｅｒ Ｋ，ｅｔ ａｌ．Ｍａｒｇｉｎａｌｉｚｅｄ ｄｅｎｏｉｓｉｎｇ
ｔｈｅ ＮＩＰＳ Ｗｏｒｋｓｈｏｐ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ ｆｏｒ ｅＣｏｍｍｅｒｃｅ． ａｕｔｏｅｎｃｏｄｅｒｓ ｆｏｒ ｄｏｍａｉｎ ａｄａｐｔａｔｉｏｎ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：
Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，２０１５ １２０６．４６８３，２０１２
［９６］ Ｚｈｕａｎｇ Ｆ，Ｌｕｏ Ｄ，Ｙｕａｎ Ｎ Ｊ，ｅｔ ａｌ．Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ［１０９］ Ｒｅｎｄｌｅ Ｓ，Ｆｒｅｕｄｅｎｔｈａｌｅｒ Ｃ，Ｇａｎｔｎｅｒ Ｚ，ｅｔ ａｌ．ＢＰＲ：Ｂａｙｅｓｉａｎ
ｗｉｔｈ ｐａｉｒ－ｗｉｓｅ ｃｏｎｓｔｒａｉｎｔｓ ｆｏｒ ｃｏｌｌａｂｏｒａｔｉｖｅ ｒａｎｋｉｎｇ／／ ｐｅｒｓｏｎａｌｉｚｅｄ ｒａｎｋｉｎｇ ｆｒｏｍ ｉｍｐｌｉｃｉｔ ｆｅｅｄｂａｃｋ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １０ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ｔｈｅ ２５ｔｈ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｕｎｃｅｒｔａｉｎｔｙ ｉｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．
Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｃａｍｂｒｉｄｇｅ，ＵＫ，２０１７：５６７－ Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，２００９：４５２－４６１
５７５ ［１１０］ Ｃｈｅｎ Ｊ，Ｚｈａｎｇ Ｈ，Ｈｅ Ｘ，ｅｔ ａｌ．Ａｔｔｅｎｔｉｖｅ ｃｏｌｌａｂｏｒａｔｉｖｅ
［９７］ Ｍｉｋｏｌｏｖ Ｔ，Ｓｕｔｓｋｅｖｅｒ Ｉ，Ｃｈｅｎ Ｋ，ｅｔ ａｌ．Ｄｉｓｔｒｉｂｕｔｅｄ ｒｅｐｒｅ－ ｆｉｌｔｅｒｉｎｇ：Ｍｕｌｔｉｍｅｄｉａ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｗｉｔｈ ｉｔｅｍ－ａｎｄ ｃｏｍｐｏ－
ｓｅｎｔａｔｉｏｎｓ ｏｆ ｗｏｒｄｓ ａｎｄ ｐｈｒａｓｅｓ ａｎｄ ｔｈｅｉｒ ｃｏｍｐｏｓｉｔｉｏｎａｌｉｔｙ／／ ｎｅｎｔ－ｌｅｖｅｌ ａｔｔｅｎｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ４０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ
ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ
Ｓｙｓｔｅｍｓ．Ｌａｋｅ Ｔａｈｏｅ，ＵＳＡ，２０１３：３１１１－３１１９ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ｔｏｋｙｏ，Ｊａｐａｎ，２０１７：３３５－３４４
［１１１］ Ｌｉ Ｐ，Ｗａｎｇ Ｚ，Ｒｅｎ Ｚ，ｅｔ ａｌ．Ｎｅｕｒａｌ ｒａｔｉｎｇ ｒｅｇｒｅｓｓｉｏｎ ｗｉｔｈ
［９８］ Ｗａｎｇ Ｐ，Ｇｕｏ Ｊ，Ｌａｎ Ｙ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ ｈｉｅｒａｒｃｈｉｃａｌ ｒｅｐｒｅ－
ａｂｓｔｒａｃｔｉｖｅ ｔｉｐｓ ｇｅｎｅｒａｔｉｏｎ ｆｏｒ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｓｅｎｔａｔｉｏｎ ｍｏｄｅｌ ｆｏｒ ｎｅｘｔ ｂａｓｋｅｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｏｆ ｔｈｅ ４０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ
ｏｆ ｔｈｅ ３８ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ
ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ｔｏｋｙｏ，Ｊａｐａｎ，
ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ｓａｎｔｉａｇｏ，Ｃｈｉｌｅ，
２０１７：３４５－３５４
２０１５：４０３－４１２
［１１２］ Ｍａ Ｈ，Ｚｈｏｕ Ｄ，Ｌｉｕ Ｃ，ｅｔ ａｌ．Ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｗｉｔｈ
［９９］ Ｍｎｉｈ Ａ，Ｈｉｎｔｏｎ Ｇ．Ｔｈｒｅｅ ｎｅｗ ｇｒａｐｈｉｃａｌ ｍｏｄｅｌｓ ｆｏｒ ｓｔａｔｉｓｔｉｃａｌ
ｓｏｃｉａｌ ｒｅｇｕｌａｒｉｚａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ４ｔｈ ＡＣＭ Ｉｎｔｅｒｎａ－
ｌａｎｇｕａｇｅ ｍｏｄｅｌｌｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ
ｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｈｏｎｇ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｃｏｒｖａｌｌｉｓ，ＵＳＡ，２００７：
Ｋｏｎｇ，Ｃｈｉｎａ，２０１１：２８７－２９６
６４１－６４８
［１１３］ Ｗａｎｇ Ｘ，Ｈｅ Ｘ，Ｎｉｅ Ｌ，ｅｔ ａｌ．Ｉｔｅｍ ｓｉｌｋ ｒｏａｄ：Ｒｅｃｏｍｍｅｎｄｉｎｇ
［１００］ Ｗａｎｇ Ｊ，Ｙｕ Ｌ，Ｚｈａｎｇ Ｗ，ｅｔ ａｌ．ＩＲＧＡＮ：Ａ ｍｉｎｉｍａｘ ｇａｍｅ
ｉｔｅｍｓ ｆｒｏｍ ｉｎｆｏｒｍａｔｉｏｎ ｄｏｍａｉｎｓ ｔｏ ｓｏｃｉａｌ ｕｓｅｒｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｆｏｒ ｕｎｉｆｙｉｎｇ ｇｅｎｅｒａｔｉｖｅ ａｎｄ ｄｉｓｃｒｉｍｉｎａｔｉｖｅ ｉｎｆｏｒｍａｔｉｏｎ ｒｅｔｒｉｅｖａｌ
ｏｆ ｔｈｅ ４０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ
ｍｏｄｅｌｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ４０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ
ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ｔｏｋｙｏ，Ｊａｐａｎ，
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ
２０１７：１８５－１９４
Ｒｅｔｒｉｅｖａｌ．Ｔｏｋｙｏ，Ｊａｐａｎ，２０１７：５１５－５２４
［１１４］ Ｚｈａｏ Ｗ Ｘ，Ｌｉ Ｓ，Ｈｅ Ｙ，ｅｔ ａｌ．Ｃｏｎｎｅｃｔｉｎｇ ｓｏｃｉａｌ ｍｅｄｉａ ｔｏ
［１０１］ Ｌａｒｏｃｈｅｌｌｅ Ｈ，Ｍｕｒｒａｙ Ｉ．Ｔｈｅ ｎｅｕｒａｌ ａｕｔｏｒｅｇｒｅｓｓｉｖｅ ｄｉｓｔｒｉ－
ｅ－ｃｏｍｍｅｒｃｅ：Ｃｏｌｄ－ｓｔａｒｔ ｐｒｏｄｕｃｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｕｓｉｎｇ
ｂｕｔｉｏｎ ｅｓｔｉｍａｔｏｒ．Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，
ｍｉｃｒｏｂｌｏｇｇｉｎｇ ｉｎｆｏｒｍａｔｉｏｎ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｋｎｏｗｌｅｄｇｅ
２０１１，１５：２９－３７
ａｎｄ Ｄａｔａ Ｅｎｇｉｎｅｅｒｉｎｇ，２０１６，２８（５）：１１４７－１１５９
［１０２］ Ｃｌａｕｓｅｔ Ａ，Ｎｅｗｍａｎ Ｍ Ｅ Ｊ，Ｍｏｏｒｅ Ｃ．Ｆｉｎｄｉｎｇ ｃｏｍｍｕｎｉｔｙ ［１１５］ Ｄｅｎｇ Ｓ，Ｈｕａｎｇ Ｌ，Ｘｕ Ｇ，ｅｔ ａｌ．Ｏｎ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆｏｒ
ｓｔｒｕｃｔｕｒｅ ｉｎ ｖｅｒｙ ｌａｒｇｅ ｎｅｔｗｏｒｋｓ．Ｐｈｙｓｉｃａｌ Ｒｅｖｉｅｗ Ｅ，２００４，
ｔｒｕｓｔ－ａｗａｒｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ ｉｎ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ．ＩＥＥＥ
７０（６）：０６６１１１
Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ ＆ Ｌｅａｒｎｉｎｇ Ｓｙｓｔｅｍｓ，
［１０３］ Ｚｈｅｎｇ Ｙ，Ｔａｎｇ Ｂ，Ｄｉｎｇ Ｗ，ｅｔ ａｌ．Ａ ｎｅｕｒａｌ ａｕｔｏｒｅｇｒｅｓｓｉｖｅ ２０１７，２８（５）：１１６４
ａｐｐｒｏａｃｈ ｔｏ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３３ｒｄ ［１１６］ Ｐａｎ Ｙ，Ｈｅ Ｆ，Ｙｕ Ｈ．Ｔｒｕｓｔ－ａｗａｒｅ ｃｏｌｌａｂｏｒａｔｉｖｅ ｄｅｎｏｉｓｉｎｇ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｎｅｗ Ｙｏｒｋ， ａｕｔｏ－ｅｎｃｏｄｅｒ ｆｏｒ ｔｏｐ－Ｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ
ＵＳＡ，２０１６：７６４－７７３ ａｒＸｉｖ：１７０３．０１７６０，２０１７
［１０４］ Ｗａｎｇ Ｃ，Ｂｌｅｉ Ｄ Ｍ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｔｏｐｉｃ ｍｏｄｅｌｉｎｇ ｆｏｒ ｒｅｃｏｍ－ ［１１７］ Ｙａｎｇ Ｃ，Ｂａｉ Ｌ，Ｚｈａｎｇ Ｃ，ｅｔ ａｌ．Ｂｒｉｄｇｉｎｇ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ
ｍｅｎｄｉｎｇ ｓｃｉｅｎｔｉｆｉｃ ａｒｔｉｃｌｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １７ｔｈ ＡＣＭ ａｎｄ ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ｌｅａｒｎｉｎｇ：Ａ ｎｅｕｒａｌ ａｐｐｒｏａｃｈ ｆｏｒ ＰＯＩ
ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２３ｒｄ ＡＣＭ ＳＩＧＫＤＤ
ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓａｎ Ｄｉｅｇｏ，ＵＳＡ，２０１１：４４８－４５６ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ
［１０５］ Ｙｉｎｇ Ｈ，Ｃｈｅｎ Ｌ，Ｘｉｏｎｇ Ｙ，ｅｔ ａｌ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｄｅｅｐ ｒａｎｋｉｎｇ： Ｍｉｎｉｎｇ．Ｈａｌｉｆａｘ，Ｃａｎａｄａ，２０１７：１２４５－１２５４ ７期 黄立威等：基于深度学习的推荐系统研究综述 １６４７
［１１８］ Ｏｚｓｏｙ Ｍ Ｇ．Ｆｒｏｍ ｗｏｒｄ ｅｍｂｅｄｄｉｎｇｓ ｔｏ ｉｔｅｍ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ． ｃｉｔａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ４０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ
ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１６０１．０１３５６，２０１６ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ
［１１９］ Ｚｈａｏ Ｓ，Ｚｈａｏ Ｔ，Ｋｉｎｇ Ｉ，ｅｔ ａｌ．Ｇｅｏ－Ｔｅａｓｅｒ：Ｇｅｏ－ｔｅｍｐｏｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ｔｏｋｙｏ，Ｊａｐａｎ，２０１７：１０９３－１０９６
ｓｅｑｕｅｎｔｉａｌ ｅｍｂｅｄｄｉｎｇ ｒａｎｋ ｆｏｒ ｐｏｉｎｔ－ｏｆ－ｉｎｔｅｒｅｓｔ ｒｅｃｏｍｍｅｎ－ ［１２５］ Ｚｈａｎｇ Ｓ，Ｙａｏ Ｌ，Ｓｕｎ Ａ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ
ｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ｓｙｓｔｅｍ：Ａ ｓｕｒｖｅｙ ａｎｄ ｎｅｗ ｐｅｒｓｐｅｃｔｉｖｅｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：
Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ Ｃｏｍｐａｎｉｏｎ．Ｐｅｒｔｈ，Ａｕｓｔｒａｌｉａ，２０１７：１５３－ １７０７．０７４３５，２０１７
１６２ ［１２６］ Ｓｉｎｇｈ Ａ Ｐ，Ｇｏｒｄｏｎ Ｇ Ｊ．Ｒｅｌａｔｉｏｎａｌ ｌｅａｒｎｉｎｇ ｖｉａ ｃｏｌｌｅｃｔｉｖｅ
［１２０］ Ｌｉｕ Ｑ，Ｗｕ Ｓ，Ｗａｎｇ Ｄ，ｅｔ ａｌ．Ｃｏｎｔｅｘｔ－ａｗａｒｅ ｓｅｑｕｅｎｔｉａｌ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １４ｔｈ ＡＣＭ ＳＩＧＫＤＤ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１６ ＩＥＥＥ １６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｄａｔａ Ｍｉｎｉｎｇ．Ｂａｒｃｅｌｏｎａ，Ｓｐａｉｎ， Ｍｉｎｉｎｇ．Ｌａｓ Ｖｅｇａｓ，ＵＳＡ，２００８：６５０－６５８
２０１６：１０５３－１０５８ ［１２７］ Ｌｉ Ｂ，Ｙａｎｇ Ｑ，Ｘｕｅ Ｘ．Ｃａｎ ｍｏｖｉｅｓ ａｎｄ ｂｏｏｋｓ ｃｏｌｌａｂｏｒａｔｅ？
［１２１］ Ｕｎｇｅｒ Ｍ，Ｂａｒ Ａ，Ｓｈａｐｉｒａ Ｂ，ｅｔ ａｌ．Ｔｏｗａｒｄｓ ｌａｔｅｎｔ ｃｏｎｔｅｘｔ－ ｃｒｏｓｓ－ｄｏｍａｉｎ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｆｏｒ ｓｐａｒｓｉｔｙ ｒｅｄｕｃｔｉｏｎ／／
ａｗａｒｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍｓ．Ｋｎｏｗｌｅｄｇｅ－Ｂａｓｅｄ Ｓｙｓｔｅｍｓ， Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２１ｓｔ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
２０１６，１０４：１６５－１７８ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ，Ｐａｓａｄｅｎａ，ＵＳＡ，２００９：２０５２－２０５７
［１２２］ Ｚｈｏｕ Ｎ，Ｚｈａｏ Ｗ Ｘ，Ｚｈａｎｇ Ｘ，ｅｔ ａｌ．Ａ ｇｅｎｅｒａｌ ｍｕｌｔｉ－ｃｏｎｔｅｘｔ ［１２８］ Ｈｕ Ｌ，Ｃａｏ Ｊ，Ｘｕ Ｇ，ｅｔ ａｌ．Ｐｅｒｓｏｎａｌｉｚｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｖｉａ
ｅｍｂｅｄｄｉｎｇ ｍｏｄｅｌ ｆｏｒ ｍｉｎｉｎｇ ｈｕｍａｎ ｔｒａｊｅｃｔｏｒｙ ｄａｔａ．ＩＥＥＥ ｃｒｏｓｓ－ｄｏｍａｉｎ ｔｒｉａｄｉｃ ｆａｃｔｏｒｉｚａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２２ｎｄ
Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｋｎｏｗｌｅｄｇｅ ａｎｄ Ｄａｔａ Ｅｎｇｉｎｅｅｒｉｎｇ，２０１６， Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｒｉｏ ｄｅ Ｊａｎｅｉｒｏ，
２８（８）：１９４５－１９５８ Ｂｒａｚｉｌ，２０１３：５９５－６０６
［１２３］ Ｈｕａｎｇ Ｗ，Ｗｕ Ｚ，Ｌｉａｎｇ Ｃ，ｅｔ ａｌ．Ａ ｎｅｕｒａｌ ｐｒｏｂａｂｉｌｉｓｔｉｃ ［１２９］ Ｚｈａｏ Ｗ Ｘ，Ｗａｎｇ Ｊ，Ｈｅ Ｙ，ｅｔ ａｌ．Ｍｉｎｉｎｇ ｐｒｏｄｕｃｔ ａｄｏｐｔｅｒ
ｍｏｄｅｌ ｆｏｒ ｃｏｎｔｅｘｔ ｂａｓｅｄ ｃｉｔａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｉｎｆｏｒｍａｔｉｏｎ ｆｒｏｍ ｏｎｌｉｎｅ ｒｅｖｉｅｗｓ ｆｏｒ ｉｍｐｒｏｖｉｎｇ ｐｒｏｄｕｃｔ
ｏｆ ｔｈｅ ２９ｔｈ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ． ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．ＡＣＭ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ
Ａｕｓｔｉｎ，ＵＳＡ，２０１５：２４０４－２４１０ ｆｒｏｍ Ｄａｔａ，２０１６，１０（３）：２９
［１２４］ Ｆａｎｇ Ｙ，Ｆａｎｇ Ｙ．Ｎｅｕｒａｌ ｃｉｔａｔｉｏｎ ｎｅｔｗｏｒｋ ｆｏｒ ｃｏｎｔｅｘｔ－ａｗａｒｅ
ＨＵＡＮＧ Ｌｉ－Ｗｅｉ，ｂｏｒｎ ｉｎ １９８５， ＬＶ Ｓｈｏｕ－Ｙｅ，ｂｏｒｎ ｉｎ １９７９，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ．Ｈｉｓ
Ｐｈ．Ｄ．Ｈｉｓ ｍａｉｎ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｍａｉｎ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｆｏｃｕｓ ｏｎ ｄａｔａ ｍｉｎｉｎｇ．
ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ａｎｄ ｒｅｃｏｍｍｅｎｄｅｒ ＬＩＵ Ｙａｎ－Ｂｏ，ｂｏｒｎ ｉｎ １９８８，Ｍ．Ｓ．，ｅｎｇｉｎｅｅｒ．Ｈｅｒ ｍａｉｎ
ｓｙｓｔｅｍｓ． ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｉｍａｇｅ ｐｒｏｃｅｓｓｉｎｇ ａｎｄ ｍａｃｈｉｎｅ
ｌｅａｒｎｉｎｇ．
ＬＩ Ｄｅ－Ｙｉ，ｂｏｒｎ ｉｎ １９４４，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ，Ａｃａｄｅｍｉ－
ｃｉａｎ ｏｆ ｔｈｅ Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ ｏｆ Ｅｎｇｉｎｅｅｒｉｎｇ．Ｈｉｓ ｍａｉｎ
ＪＩＡＮＧ Ｂｉ－Ｔａｏ，ｂｏｒｎ ｉｎ １９６７，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ．Ｈｅｒ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｆｏｃｕｓ ｏｎ ａｒｔｉｆｉｃｉａｌ ｉｎｔｅｌｌｉｇｅｎｃｅ．
ｍａｉｎ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｆｏｃｕｓ ｏｎ ｄａｔａ ｍｉｎｉｎｇ．
Ｂａｃｋｇｒｏｕｎｄ
Ｄｅｅｐ Ｌｅａｒｎｉｎｇ ｉｓ ｏｎｅ ｏｆ ｔｈｅ ｎｅｘｔ ｂｉｇ ｔｈｉｎｇｓ ｉｎ ｒｅｃｏｍ－ ｆｕｔｕｒｅ ｄｅｖｅｌｏｐｍｅｎｔ ｔｒｅｎｄ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｒｅｃｏｍｍｅｎ－
ｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍｓ ｔｅｃｈｎｏｌｏｇｙ．Ｔｈｅ ｐａｓｔ ｆｅｗ ｙｅａｒｓ ｈａｖｅ ｓｅｅｎ ｄａｔｉｏｎ ｓｙｓｔｅｍｓ．
ｔｈｅ ｔｒｅｍｅｎｄｏｕｓ ｓｕｃｃｅｓｓ ｏｆ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｉｎ ａ ｎｕｍｂｅｒ Ｔｈｅ ｗｏｒｋ ｉｓ ｓｕｐｐｏｒｔｅｄ ｂｙ ｔｈｅ Ｎａｔｉｏｎａｌ Ｂａｓｉｃ Ｒｅｓｅａｒｃｈ
ｏｆ ｃｏｍｐｌｅｘ ｔａｓｋｓ ｓｕｃｈ ａｓ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ，ｎａｔｕｒａｌ ｌａｎｇｕａｇｅ Ｐｒｏｇｒａｍ ｏｆ Ｃｈｉｎａ （９７３ Ｐｒｏｇｒａｍ）ｕｎｄｅｒ Ｇｒａｎｔ Ｎｏ．
ｐｒｏｃｅｓｓｉｎｇ ａｎｄ ｓｐｅｅｃｈ ｒｅｃｏｇｎｉｔｉｏｎ．Ａｆｔｅｒ ｉｔｓ ｒｅｌａｔｉｖｅｌｙ ｓｌｏｗ ２０１４ＣＢ３４０４０４，ｔｈｅ Ｍａｊｏｒ Ｒｅｓｅａｒｃｈ Ｐｌａｎ ｏｆ ｔｈｅ Ｎａｔｉｏｎａｌ
ｕｐｔａｋｅ ｂｙ ｔｈｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｃｏｍｍｕｎｉｔｙ，ｄｅｅｐ ｌｅａｒｎｉｎｇ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｃｈｉｎａ ｕｎｄｅｒ Ｇｒａｎｔ Ｎｏ．
ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｂｅｃａｍｅ ｗｉｄｅｌｙ ｐｏｐｕｌａｒ ｉｎ ｐａｓｔ ９１６３８３０１ａｎｄ ｔｈｅ Ｎａｔｉｏｎａｌ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ Ｆｏｕｎｄａｔｉｏｎ ｏｆ
ｔｈｒｅｅ ｙｅａｒｓ．Ｔｈｉｓ ｐａｐｅｒ ｇｉｖｅｓ ａ ｃｏｍｐｒｅｈｅｎｓｉｖｅ ｏｖｅｒｖｉｅｗ ｏｆ Ｃｈｉｎａ ｕｎｄｅｒ Ｇｒａｎｔ Ｎｏｓ．６１２７２１１１， ６１２７３２１６ ａｎｄ
ｔｈｅ ｃｕｒｒｅｎｔ ｓｔａｔｅ ｏｆ ｔｈｅ ａｒｔ ａｎｄ ｐｒｏｖｉｄｅｓ ａ ｔｈｏｒｏｕｇｈ ａｎａｌｙｓｉｓ ６１６００１１９５０．Ａｌ ｌｏｆ ｔｈｅｓｅ ｐｒｏｊｅｃｔｓ ａｒｅ ａｒｏｕｎｄ ｔｈｅ ｐｒｏｂｌｅｍ ｏｆ
ａｎｄ ｃｏｍｐａｒｉｓｏｎ ｏｆ ｔｈｅ ｌａｔｅｓｔ ｓｔｕｄｉｅｓ ｏｎ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｄａｔａ ｍｉｎｉｎｇ，ｄｅｅｐ ｌｅａｒｎｉｎｇ，ｒｅｍｏｔｅ ｓｅｎｓｉｎｇ ｉｎｆｏｒｍａｔｉｏｎ ｐｒｏ－
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍｓ，ｉｎｃｌｕｄｉｎｇ ｔｈｅ ｃｏｍｐａｒｉｓｏｎ ｗｉｔｈ ｔｈｅ ｃｅｓｓｉｎｇ，ａｎｄ ｔｈｅ ｒｅｓｅａｒｃｈ ｏｆ ｔｈｅｓｅ ｔｏｐｉｃｓ ｈａｓ ｂｅｅｎ ｓｔｕｄｉｅｄ ｂｙ
ｔｒａｄｉｔｉｏｎａｌ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ，ｔｈｅ ｍａｉｎ ｒｅｓｅａｒｃｈ ｄｉｒｅｃｔｉｏｎ ｏｕｒ ｇｒｏｕｐ ｆｏｒ ｍａｎｙ ｙｅａｒｓ．
ａｎｄ ａｐｐｌｉｃａｔｉｏｎ ｐｒｏｇｒｅｓｓ．Ｉｎ ａｄｄｉｔｉｏｎ，ｔｈｅ ｐａｐｅｒ ｄｉｓｃｕｓｓｅｓ ｔｈｅ --------------------------------------------------------------------------------- 第41卷第4期 电 子 与 信 息 学 报 Vol. 41No. 4
2019年4月 Journal of Electronics & Information Technology Apr. 2019
基于深度学习的混合兴趣点推荐算法
冯 浩① 黄 坤① 李 晶*② 高 榕② 刘东华② 宋成芳②
①(中国舰船研究设计中心 武汉 430064)
②(武汉大学计算机学院 武汉 430072)
摘 要：针对现有兴趣点推荐的初始化和忽视评论信息语义上下文信息的问题，将深度学习融入推荐系统中已经
成为兴趣点推荐研究的热点之一。该文提出一种基于深度学习的混合兴趣点推荐模型(MFM-HNN)。该模型基于
神经网络融合评论信息与用户签到信息来提高兴趣点推荐的性能。具体地，利用卷积神经网络学习评论信息的特
征表示，利用降噪自动编码对用户签到信息进行初始化。进而，基于扩展的矩阵分解模型融合评论信息特征和用
户签到信息的初始值进行兴趣点推荐。在真实签到数据集上进行实验，结果表明所提MFM-HNN模型相比其他先
进的兴趣点推荐具有更好的推荐性能。
关键词：推荐算法；兴趣点；矩阵分解；神经网络；深度学习
中图分类号：TP311 文献标识码：A 文章编号：1009-5896(2019)04-0880-08
DOI: 10.11999/JEIT180458
Hybrid Point of Interest Recommendation Algorithm
Based on Deep Learning
FENG Hao① HUANG Kun① LI Jing② GAO Rong②
LIU Donghua② SONG Chengfang②
①(China Ship Development and Design Center, Wuhan 430064, China)
②(Computer School, Wuhan University, Wuhan 430072, China)
Abstract: When modeling user preferences, the current researches of group recommendation ignore the problem
of modeling initialization and the review information accompanied with rating information for recommender
models, integrating deep learning into the recommendation system becomes a hotspot of Point-Of-Interest
(POI) recommendation. In this paper, a new POI recommendation model called Matrix Factorization Model
integrated with Hybrid Neural Networks (MFM-HNN) is proposed. The model improves the performance of
POI recommendation by fusing review text and check-in information based on Neural Network (NN).
Specifically, the convolutional neural network is used to learn the feature representation of the review text and
the check-in information is initialized by using the stacked denoising autoencoder. Furthermore, the extended
matrix factorization model is exploited to fuse the review information feature and the initial value of the check-
in information for POI recommendation. As is shown in the experimental results on real datasets, the proposed
MFM-HNN achieves better recommendation performances than the other state-of-the-art POI recommendation
algorithms.
Key words: Recommendation algorithm; Point-Of-Interest (POI); Matrix factorization; Neural Network (NN);
Deep learning
1 引言 信、微博、Facebook、Flickr等社交网络吸引数十
亿用户互相交流和共享信息。近年来社交网络应用
随着智能手机及其智能设备的飞速发展，微
的一个明显进步是引入空间技术，促发了位置社交
收稿日期：2018-05-14；改回日期：2018-11-26；网络出版：2018-12-05 网络(Location-Based Social Network, LBSN)的出
*通信作者： 李晶 leejingcn@163.com 现，如Foursquare, Twinkle和GeoLife[1]。在位置社
基金项目：国家自然科学基金(41201404)，中央高校基本科研业务 交网络中基于空间技术的位置也被称为兴趣点[2]
费专项资金(2042015gf0009)
(Point-Of-Interest, POI)，例如餐馆、商店和博物
Foundation Items: The National Natural Science Foundation of
馆等。兴趣点推荐广泛研究用户和兴趣点的相关信
China (41201404), The Fundamental Research Funds for the
息对于用户行为的影响，不仅帮助用户在位置社交
Central Universities of China (2042015gf0009) 第4期 冯 浩等：基于深度学习的混合兴趣点推荐算法 881
网络的海量数据中找到自己感兴趣的信息，从而探 2 基于混合神经网络矩阵分解的兴趣点推
索新的兴趣点和新的地理区域(如城市)，丰富用户 荐模型
的生活体验。同时也帮助相关服务提供商向潜在用
本节介绍MFM-HNN模型如图1所示，左侧的
户提供个性化服务，从而提高营业收入[3]。
虚线边框表示签到信息预处理组件，右侧的虚线边
近年来，针对位置社交网络中的兴趣点推荐问 框表示评论信息特征学习组件。输入用(~;~; )三
题，大量的研究已经展开，但是已有的兴趣点推荐
元组，其中，~ =[u ;u ; ;u ]表示用户集合，
1 2 m
算法存在如下的问题： ¢¢¢
~=[i;i ; ;i ]表示兴趣点集合， =[x ;x ; ;x ]
i 2 n 1 2 n
(1)大多数POI推荐工作[4—6]将评论信息与签到 ¢¢¢ ¢¢¢
表示评论信息集合。具体地，通过SDAE学习用户
信息关联起来降低数据的稀疏性，然而，评论信息
~和兴趣点~的初始化参数，得到最优化的用户签
在相关POI研究工作中还没有得到充分利用。大多
到特征 和兴趣点签到特征 ；通过CNN网络
L=2 L=2
数利用评论信息的推荐系统的工作都集中在使用狄
学习评论信息 得到潜在特征向量 。然后融合签
利克雷分配模型(Latent Dirichlet Allocation,
到特征 和兴趣点潜在特征 ，得到兴趣点的特
L=2
LDA)[7,8] 挖掘评论信息的主题。但是，该模型通常
征 进行兴趣点评分预测。下面对模型的各个组件
利用词袋模型处理评论信息，忽视了评论信息的语
的学习过程进行详细的介绍。
义上下文信息。而且，当数据过于稀疏时，LDA
模型学习的潜在特征表示可能不是非常有效，性能
无法令人满意[9—11]。
(2)大多数基于机器学习的POI推荐的研究都是
利用矩阵分解技术来进行兴趣点的推荐[12—14]。基于
矩阵分解模型的方法对用户和兴趣点潜在特征矩阵
的初始化很敏感[15]。然而，大多数基于矩阵分解的
推荐工作回避或忽视了这个问题，采用非常简单的
方法(如随机或零初始化)初始化用户和项目的潜在
特征。
因此，本文提出一种利用深度学习技术融合用
户评论信息的兴趣点推荐算法(MFM-HNN)。本文
的内容如下：
(1)利用卷积神经网络(Convolutional Neural
Network, CNN)[10,16]自动获取评论信息中兴趣点的 图 1 基于混合神经网络矩阵分解的兴趣点推荐模型
深层次特征，并且可以同时考虑词序和上下文信息
2.1 评论信息特征学习组件
对提取的用户潜在兴趣特征的影响，生成比
卷积层：任意一个兴趣点的评论信息的集合表
LDA模型更好的潜在特征表示。特别是在用户-签
示为x = w ;w ; ;w ，利用词向量模型将x 中
i 1 2 n i
到矩阵比较稀疏时，CNN的使用有助于深入了解 f ¢¢¢ g
每个单词w 按出现的先后顺序映射为相应的词向量
i
评论信息，产生更好的潜在模型。
i
Rp £1，x i就转换为词序不变的词向量矩阵
(2)提出一种通过逐层非监督学习的预训练数 2 p l
R £
2
据的隐层表示的初始化方法。利用深度堆栈降噪自
=[ 0 1 n 1] (1)
动编码器(Stacked Denoising AutoEncoder, ¢¢¢ ¡
其中， , p表示单词w 的嵌入维度， 表示在
i i
SDAE)[11,17]通过对用户或兴趣点相关的签到信息进
x 的i处的单词的词向量，l是x 的长度。假设卷积
i i
行 提高重 矩构 阵学 分习 解用 过户 程或 的兴 学趣 习点 效的 率最 和佳 性初 能始 。值，从而有效 窗口的大小为wd, x i的第i个上下文特征cj
i
(cj
i
2R)
(3)提出一种基于深度学习模型和经典矩阵分
是由第j个共享权重 cj 2Rp £wd通过卷积窗口对x
i
的第i步的内容 进行卷积得到的。即
(:;i:(i+wd 1))
解模型框架融合兴趣点相关信息和签到信息，并将 ¡
其用于用户对于兴趣点偏好的评分预测，给出具体 cj i =f cj ¤ (:;i:(i+wd ¡1))+bj c (2)
其中， 表示卷积操作, bj是偏置项，f表示激活函数。
的建模过程。基于两个真实的LBSN签到数据集进 ¤ ¡ c ¢
行大量实验，验证本文所提算法的推荐性能。实验
多次卷积之后得到兴趣点特征向量 j Rl ¡wd+1表示为
2
结果表明本文所提推荐算法优于其他先进的兴趣点 j =[cj ;cj ; ;cj ] (3)
1 2 ¢¢¢ l ¡wd+1
推荐算法。 池化层：从上下文特征向量中提取最大的特征 882 电 子 与 信 息 学 报 第 41 卷
向量表示该兴趣点的潜在特征。一个兴趣点的评论 其中， ; 表示权重矩阵， 表示偏置向量，
l l l
信息x i的上下文特征表示为 j，即 ¸ ;¸ 表示正则化参数。因此，MFM-HNN模型的
j = max 1 j ; max 2 j ; ¢¢¢; max n jc (4) 最终目标函数为
m
输出h层：³将池´化层提³取的´ 特征向量³映射´i到不同
= R T 2 ¸h ( u ^u)2
维度的向量空间，用于不同的任务。这里将特征向 L ¡ hj ¡ h j ¡ m h ¡ h
hj u=1
X¡ ¢ X
量 j映射到k d维向量空间用于本文的推荐任务。 n
¸j ( v ^v)2 ¸h ( 2 + 2 )
=tanh f2 tanh f1 j + f1 + f2 (5) ¡ n
j=1
j ¡ j ¡ w
h
k l kF k l kF
X X
³ n ³ ´o ´
其中， 2Rkd, f12Rf £nc, f22Rkd£f是映射矩 ¡¸j
w
(
k l
k2 F+
k l
k2 F)
阵， f12Rf, f22Rkd是偏移向量。最终，完成了 Xj
n
兴趣点评论信息x 的上下文特征的提取。因此，通
i ¸ (~ cnn( ;x )) 2
过CNN学习兴趣点上下文特征的目标函数表示为 ¡ cnn k j ¡ j kF
j=1
X
n
Lcnn= i k( i ¡cnn( ;x i)) k2 +¸c Wnn j ij k i k2(6) ¡¸c wnnj cnnj k cnn k2 F¡¸ h m k h k2 F
X X j=1 h=1
X X
2.2 签到信息预处理组件 n
给定输入 u和 v分别表示用户偏好特征和兴 ¡¸ j k j k2 F (11)
趣点特征，每个用户偏好特征表示为 u =[f ; j=1
i i;1 X
f i;2; ¢¢¢;f i;n]T，每个兴趣点的特征表示为 v
i
=[f 1;i; 2.3 参数学习
f 2;i; ¢¢¢;f m;i]T。降噪自动编码器随机破坏 u和 v获 对于参数 h; j的更新，本文利用随机梯度下
得~u和~v，破坏后每个用户的偏好特征和每个兴
降法进行学习， ( ; )表示目标函数。假设与
趣点的特征分别表示为：~u i =[f~ i;1;f~ i;2; ¢¢¢;f~ i;n]T和 h; j无关的变量L 为定值。更新规则为
~v i =[f~ 1;i;f~ 2;i; ¢¢¢;f~ m;i]T。具体过程可以表示为
= ´
@
( ; )
u =g( 1~u + u) h h ¡ @ h L 9
(12)
^uv == fg (( 1 2~v u+ + v) u^) 9 > > > (7) j = j ¡´ @@ j L( ; ) > > > =
=
^v =f( 2 v+ v^) 其中，´是学习率，梯度更新的结果为> > >
;
>
其中，~u和~v表示破坏后的 u和> > ;v, ^u和^v表示重 @
构的 u和 v, u和 v表示输入的潜在表示。 ; @ L( ; )= ¡ R hj ¡ T h j ( ¡ j)
h hj 9
表
活
藏层示
函
可权
数
以重
。
表矩
如
示阵
图
为， 1所示表 ，示 堆偏 栈置 降向 噪量 自。g 动( ¢ 编)和 码f 器( ¢) 多表 个示 隐激 ¡X
¸h m
¡ um
=1( u h¡^u
h)¢ @@^u
h h¡¸ h
h> > >
> > > > >
>
>
X > >
其中， 0为破坏l = 的g 输( 入l ，l ¡ l1+ 1l ;) 2; ;L 1 。( 对8) @@ j L( ; )= ¡ hj R hj ¡ T h j ¡ T h > > > > > > > >
于输入~u和~v，第L层的输出2 为f ¢¢¢ ¡ g X¡ n ¢ @¡ ^i ¢ > > > > >(13)
^u =f( L L+ u^) ¡¸j n i j ¡^i j @ j > =
^v =f( L L+ v^) ) (9) Xj=1 n¡ ¢ j > > >
>
>
其中，前L=2层作为编码器，后L=2层作为解码 ¸ (~ cnn( ;x )) > >
器。因此，重构数据的损失函数为 ¡ cnn Xj=1 j ¡ j > > > > >
>
>
arg m l;in
l; l
u
¡
^u 2 F+ v
¡
^v 2
F
@ @~ j j¡¸ j j > > > > >
> > >
° ° ° ° >
>
° ° ° ° 通过学习用户和兴趣点的潜在特征表示，> >兴趣
° 2° °2 ° ;
+¸ +
Ã k l kF k l kF ! 点潜在特征表示和偏好预测为
l
X
+¸ Ã k l k2 F+ k l k2 F ! (10) R^ u;i ¼( u)T i =( u)T ³cnn( ; i)+ i L=2 ´ (14)
Xl 本文提出模型的学习算法过程如表1所示。 第4期 冯 浩等：基于深度学习的混合兴趣点推荐算法 883
表 1 MFM-HNN模型学习算法 dl
RC k = (16)
vl
输入： i; u; v;~u;~v;T;B
其中，对模型在不同参数下的性能时进行多次评
输出：
L 估。在实验中，选择P@1, P@5和P@10，以及
(1) For t<T Do
RC@1, RC@5，和RC@10作为评估指标。
(2) 从兴趣点评论中随机选取一个兴趣点的评论矩阵 进行训练，
i
训练批次大小为¯0，每一个批次的大小为B，计算训练过程 3.3 实验设计
中的损失 Lcnn 本文采用3种不同的策略从不同的角度进行测
(3) if t>T or Lcnn足够小 试，以验证本文算法的有效性。
(4) end (1)与主流先进的算法进行对比：本文与4种先
(5) for t<T Do 进主流兴趣点推荐算法进行比较，从而验证算法的
(6) 从兴趣点评分中随机选取一个兴趣点的用户-兴趣点对(~u i;~v i) 高效性。
进行训练，训练批次大小为¯1，每一个批次的大小为B，计算
(2)潜在特征预处理的测试：通过对矩阵分解
训练过程中的损失
Lui
过程中矩阵交互的潜在特征的预处理，验证本文所
(7) if t>T or Lui足够小
提初始化方法的有效性。
(8) end
(3)SDAE层数的测试：类似于文献[9]验证SDAE
(9) 计算最终的损失值 L= Lcnn+ Lui
的层数对模型性能的影响。
(10) return
L
首先，选定了4个兴趣点推荐算法用于对比：
2.4 复杂度分析 (1)IRenMF：文献[20]提出利用两个层次的地
在更新卷积权重学习文本的潜在特征向量时， 理邻域关系进行地理位置信息的建模，其中假设签
卷积神经网络的复杂度为O(n plN)，其中N表示兴 到兴趣点的地理邻域兴趣点更适合推荐给用户。
c
趣点评论信息的数量，p表示嵌入的维度，l表示一 (2)ASMF：文献[21]根据朋友的类别(社交朋
个兴趣点评论信息的长度，n 表示学习的上下文特 友、位置朋友和邻居朋友)提出一个两阶段框架来
c
征的数量。编码器更新用户和兴趣点的复杂度为 进行基于用户社交信息的兴趣点推荐。
O(2´k )，其中´是词汇量大小，k 是输出的潜在维 (3)LCARS：文献[7]基于LDA主题模型利用用
1 1
度。更新权重和偏差的复杂度为O(m´k +n´k )。因 户的签到数据和评论文本信息来构建兴趣点推荐系统。
1 1
此，总的复杂度为O(m´k +n´k +n plN+2´k )。 (4)CDL：文献[9]提出的一种层次贝叶斯模
1 1 c 1
型，该模型提取内容的有效深度特征表示，同时捕
3 实验
捉相似度以及物品(和用户)之间的隐含关系。本文
3.1 实验数据集
实验中，基于这种方法建模用户签到行为。
本文选用公开的Foursquare[18]的两个数据集验
其次，将4种经典方法初始化方法与本文提出
证模型的有效性。Foursquare数据集是对美国洛杉
的初始化方法进行比较：
矶(LA)和纽约(NYC)的签到的统计，如表2所示。
(1)随机初始化(random initialization)：文献
针对签到(评论)采用类似于文献[9,19]的方法对文本
[18]提出基于用户随机设置。
信息进行预处理。
(2)零初始化(zero initialization)：文献[18]提
3.2 评价指标
出初始值设置为零。
本文采用准确率和召回率作为位置推荐的评价
(3)K-means初始化(K-means initialization)：
指标来评估推荐算法的性能，分别用P@k和RC@k
文献[22]提出基于K-means方法进行初始化设置。
来表示。对一个用户u, dl表示观察到的兴趣点数量，
(4)归一化切割初始化(Normalized-CUT ini-
vl表示已访问的兴趣点数量，P@k和RC@k定义为
tialization, NCUT)：文献[23]提出基于NCUT的方
dl
P k = (15) 法进行初始化设置。
k
最后基于不同的层数验证对于本文模型推荐性
表 2 数据集统计 能的影响。
数据统计 LA NYC 3.4 参数设置
用户数量 30,208 47,240 对于不同的模型参数设置为：对于IRenMF:
兴趣点数量 142,798 203,765 K=100, ®=0.4, ¸ =¸ =0.015, ¸ =1, #NN=10,
1 2 3
签到数量(评论) 244,861 388,954 #clusters=50；对于ASMF: K=100, ®=0.4,
用户-位置矩阵密度 5.68×10–5 4.04×10–5 ¸ =¸ =0.01, ¸ =0.1, ³=0.4, °=0.4, "=0.4；对于
u v q 884 电 子 与 信 息 学 报 第 41 卷
LCARS: K=100, ®=® =50/K, ¯=¯ = 0.01, 如图2所示，ASMF的方法相对于其他4种方法表现
0 0
°=° =0.5；对于两层的CDL模型： ¸ =0:1; 出排名第4的推荐性能。可能的解释是因为ASMF
0 h
¸ =1;¸j =0:0001;¸j =100，对于SDAE的设置 侧重于利用社交信息。
j w n
与本文提出的MFM-HNN相同。 (4) CDL: CDL可以产生比上述模型，特别是
对于本文所提MFM-HNN模型，SDAE采用30%
LCARS模型更优的推荐结果。但是，在对评论文
本信息的潜在特征进行学习时没有考虑词序对学习
的噪声擦除以从清洁输入 获得损坏的输入~。丢弃
的潜在特征的影响，因此，导致CDL模型最终体现
率为0.1以实现自适应正则化，防止过拟合。隐藏单
出第2好的推荐结果。
元数K 为1000，中间层数为200。潜在因子的数量
l
(5) MFM-HNN：如图2所示，基于2个数据集
为 = = =200。学习率为0.2。¸ =0:01;
h j k h
j j j j j j MFM-HNN模型在推荐性能上表现最好。MFM-
¸ =0:1;¸j =0:0001;¸j =5可以实现良好的性能。
j w n HNN模型在对评论信息的潜在特征进行学习时，
3.5 实验结果分析
充分考虑词序及上下文信息对学习的潜在特征表示
3.5.1 推荐模型的比较与分析
的影响，克服LDA模型的先验分布建模前难以定
网络结构的设置为：8000-1000-200-1000-8000,
义，以及当评论信息非常稀少时主题的比例不能有
SDAE的编码层为3时，本文MFM-HNN模型与现
效地代表项目的潜在特征的问题。同时，MFM-
有主流先进算法的性能对比结果如图2所示。
HNN模型在进行矩阵分解实现用户-兴趣点特征的
(1) IRenMF：这种方法受到数据集数据缺失
交互时，特征的初始值采用本文所提基于神经网络
的影响很大，如表1，本文两个数据集的用户-兴趣
方法进行选取，避免了优化时陷入局部最优解。因
点的矩阵密度相对偏低。因此，如图2所示，IRenMF
此，MFM-HNN模型最终体现出最好的推荐效果。
相对于其他4种方法体现出最差的推荐性能。
3.5.2 预训练初始化参数的影响
(2) LCARS：这种方法依然受到数据稀疏性的 为了验证本文所提利用自动编码器进行初始化
影响，同时数据过于稀疏时，基于LDA模型无法 的有效性，将本文所提初始化方法与几种经典的初
有效学习兴趣点的潜在特征，同时相比社交信息和 始化方法进行对比实验，例如随机初始化、零初始
地理信息对于POI推荐性能的影响，评论文本信息 化、K-means初始化和归一化切割初始化。本文所
的影响是最小。因此，如图2所示，LCARS的方法 提参数初始化方法与以上提到的几种初始化方法的
相对于其他4种方法表现出排名第3的推荐性能。 对比结果如图3所示。
(3) ASMF: ASMF的表现不如IRenMF模型， 从图3可以看出，本文所提初始化模型降噪编
图 2 MFM-HNN模型基于LA数据集和NYC数据集与其他4个模型的推荐性能对比 第4期 冯 浩等：基于深度学习的混合兴趣点推荐算法 885
码器预处理方法优于其他的初始化方法，有效避免 3.5.3 编码器层数的影响
了矩阵分解过程中由于初始值造成的局部最优问 为了研究编码器的层数变化对本文所提模型的
题。主要原因在于：(1)本文提出的模型应用原始 影响，本文设计了不同层数的编码器的实验，验证
用户、兴趣点特征向量学习用户和兴趣点的特征， 编码器层数的变化对推荐性能的影响。其中，DA-1,
相当于学习模型的全局最小化；(2)学习的初始化 DA-2等表示编码器的层数，实验结果如图4所示。
向量可以更好地体现用户和兴趣点原始的相似关系。 图4显示了基于不同数据集LA和NYC，随着编
图 3 基于LA和NYC数据集的5个初始化方法的性能对比
图 4 MFM-HNN模型基于LA数据集和NYC数据集在不同层数的性能对比 886 电 子 与 信 息 学 报 第 41 卷
码器层数的变化，召回率和准确率的变化情况。从 10.7544/issn1000-1239.2016.20160202.
图4中可以看出，当层数为1和2时，召回率和准确 YU Yonghong, GAO Yang, and WANG Hao. A ranking
率都相当低，而随着层数的增加，召回率和准确率 based Poisson matrix factorization model for point-of-
都在一定程度上得到了提高。即当反馈矩阵非常稀 interest recommendation[J]. Journal of Computer Research
疏时，兴趣点推荐的性能取决于潜在特征表示的质 and Development, 2016, 53(8): 1651–1663. doi: 10.7544/
量。当层数为3时，召回率和准确率达到最佳值， issn1000-1239.2016.20160202.
[6] LIM K H, CHAN J, LECKIE C, et al. Personalized trip
表明MFM-HNN模型利用SDAE作为预处理组件可
recommendation for tourists based on user interests, points
以有效提高推荐的精确度。当层数为4，开始出现
of interest visit durations and visit recency[J]. Knowledge
拟合，降低了MFM-HNN模型的推荐性能。因此，
and Information Systems, 2018, 54(2): 375–406. doi: 10.1007/
本文设置层数为3是合理的。
s10115-017-1056-y.
4 结束语
[7] YIN Hongzhi, SUN Yizhou, CUI Bin, et al. LCARS: A
本文提出了一种基于深度学习的混合兴趣点推 location-content-aware recommender system[C]. Proceedings
荐算法(MFM-HNN)用于兴趣点的推荐，以及利用 of the 19th ACM SIGKDD International Conference on
深度自动编码器来学习矩阵分解过程中用户和兴趣 Knowledge Discovery and Data Mining, Chicago, USA,
点的潜在特征向量初始值。MFM-HNN模型采用卷 2013: 221–229. doi: 10.1145/2487575.2487608.
积神经网络模型学习评论信息的上下文特征，从而 [8] ZHANG Jiadong, CHOW Chiyin, and ZHENG Yu. ORec:
提取了更精确的特征表示实现了评论信息的建模。 An opinion-based point-of-interest recommendation
framework[C]. Proceedings of the 24th ACM International
对于矩阵分解模型中用户和兴趣点交互的建模，则
on Conference on Information and Knowledge Management,
利用降噪自动编码器学习用户和兴趣点的潜在特征
Melbourne, Australia, 2015: 1641–1650. doi: 10.1145/
向量的最佳初始值有效避免矩阵分解的过程中陷入
2806416.2806516.
局部最优解。最终利用矩阵分解技术融合上述2种
[9] WANG Hao, WANG Naiyan, and YEUNG D Y.
建模实现对用户提供兴趣点推荐服务。在未来的工
Collaborative deep learning for recommender systems[C].
作中，基于深度学习框架融合多种上下文信息将是
Proceedings of the 21th ACM SIGKDD International
一个值得关注的方向。
Conference on Knowledge Discovery and Data Mining,
参 考 文 献
Sydney, Australia, 2015: 1235–1244. doi: 10.1145/
[1] LI Jun, BENEDIKTSSON J A, ZHANG Bing, et al. Spatial 2783258.2783273.
technology and social media in remote sensing: A survey[J]. [10] KIM D, PARK C, OH J, et al. Convolutional matrix
Proceedings of the IEEE, 2017, 105(10): 1855–1864. doi: factorization for document context-aware
10.1109/JPROC.2017.2729890. recommendation[C]. Proceedings of the 10th ACM
[2] YANG, C, BAI Lanxiao, ZHANG Chao, et al. Bridging Conference on Recommender Systems, Boston, USA, 2016:
collaborative filtering and semi-supervised learning: A 233–240. doi: 10.1145/2959100.2959165.
neural approach for POI recommendation[C]. Proceedings of [11] DONG Xing, YU Lei, WU Zhonghuo, et al. A hybrid
the 23rd ACM SIGKDD International Conference on collaborative filtering model with deep structure for
Knowledge Discovery and Data Mining, Halifax, Canada, recommender systems[C]. Proceedings of the 31st AAAI
2017: 1245–1254. doi: 10.1145/3097983.3098094. Conference on Artificial Intelligence, San Francisco, USA,
[3] LIU Yiding, PHAM T A N, CONG Gao, et al. An 2017: 1309–1315.
experimental evaluation of point-of-interest recommendation [12] 任星怡, 宋美娜, 宋俊德. 基于位置社交网络的上下文感知的
in location-based social networks[J]. Proceedings of the 兴趣点推荐[J]. 计算机学报, 2017, 40(4): 824–841. doi:
VLDB Endowment, 2017, 10(10): 1010–1021. doi: 10.11897/SP.J.1016.2017.00824.
10.14778/3115404.3115407. REN Xingyi, SONG Meina, and SONG Junde. Context-
[4] MAZUMDAR P, PATRA B K, BABU K S, et al. Hidden aware point-of-interest recommendation in location-based
location prediction using check-in patterns in location-based social networks[J]. Chinese Journal of Computer, 2017,
social networks[J]. Knowledge and Information Systems, 40(4): 824–841. doi: 10.11897/SP.J.1016.2017.00824.
2017, 57(3): 571–601. doi: 10.1007/s10115-018-1170-5. [13] GAO Rong, LI Jing, LI Xuefei, et al. A personalized point-
[5] 余永红, 高阳, 王皓. 基于Ranking的泊松矩阵分解兴趣点推荐 of-interest recommendation model via fusion of geo-social
算法[J]. 计算机研究与发展, 2016, 53(8): 1651–1663. doi: information[J]. Neurocomputing, 2018, 273: 159–170. doi: 第4期 冯 浩等：基于深度学习的混合兴趣点推荐算法 887
10.1016/j.neucom.2017.08.020. geographical neighborhood characteristics for location
[14] LIAN Defu, ZHENG Kai, GE Yong, et al. GeoMF++: recommendation[C]. Proceedings of the 23rd ACM
Scalable location recommendation via joint geographical International Conference on Information and Knowledge
modeling and matrix factorization[J]. ACM Transactions on Management, Shanghai, China, 2014: 739–748. doi:
Information Systems, 2018, 36(3): 33. doi: 10.1145/3182166. 10.1145/2661829.2662002.
[15] ZDUNEK R. Initialization of nonnegative matrix [21] LI Huayu, GE Yong, HONG Richang, et al. Point-of-
factorization with vertices of convex polytope[C]. interest recommendations: Learning potential check-ins from
Proceedings of the 11st International Conference on friends[C]. Proceedings of the 22nd ACM SIGKDD
Artificial Intelligence and Soft Computing, Zakopane, International Conference on Knowledge Discovery and Data
Poland, 2012: 448–455. doi: 10.1007/978-3-642-29347-4_52. Mining, San Francisco, USA, 2016: 975–984. doi:
[16] YANG Cheng, SUN Maosong, ZHAO W X, et al. A neural 10.1145/2939672.2939767.
network approach to jointly modeling social networks and [22] ORCHAND M. Least square quantization in PCM[J]. IEEE
mobile trajectories[J]. ACM Transactions on Information Transaction on Information Theory, 1982, 28(2): 129–137.
Systems, 2017, 35(4): 36. doi: 10.1145/3041658. doi: 10.1109/TIT.1982.1056489.
[17] DENG Shuiguang, HUANG Longtao, XU Guangdong, et al. [23] SHI J and MALIK J. Normalized cuts and image
On deep learning for trust-aware recommendations in social segmentation[J]. IEEE Transactions on Pattern Analysis
networks[J]. IEEE Transactions on Neural Networks and and Machine Intelligence, 2000, 22(8): 888–905. doi:
Learning Systems, 2017, 28(5): 1164–1177. doi: 10.1109/ 10.1109/34.868688.
TNNLS.2016.2514368.
[18] GAO Huiji, TANG Jiliang, HU Xia, et al. Content-aware 冯 浩：男，1979年生，博士，高级工程师，研究方向为体系结构
point of interest recommendation on location-based social 和系统工程.
networks[C]. Proceedings of the 29th AAAI Conference on 黄 坤：男，1979年生，博士，高级工程师，研究方向为人工智能
Artificial Intelligence, Austin, Texas, 2015: 1721–1727. 和系统工程.
[19] ZHANG Fuzheng, YUAN N J, ZHENG Kai, et al. 李 晶：男，1967年生，博士，教授，研究方向为数据挖掘和多媒
Exploiting dining preference for restaurant 体技术.
recommendation[C]. Proceedings of the 25th International 高 榕：男，1981年生，博士，研究方向为数据挖掘和智能推荐.
Conference on World Wide Web, Montréal, Canada, 2016: 刘东华：女，1989年生，博士生，研究方向为数据挖掘和智能推荐.
725–735. doi: 10.1145/2872427.2882995. 宋成芳：男，1978年生，博士，讲师，研究方向为可视化分析和位
[20] LIU Yong, WEI Wei, SUN Aixin, et al. Exploiting 置服务. --------------------------------------------------------------------------------- 第３９卷 第７期 计 算 机 学 报 Ｖｏｌ．３９ Ｎｏ．７
２０１６年７月 ＣＨＩＮＥＳＥ ＪＯＵＲＮＡＬ ＯＦ ＣＯＭＰＵＴＥＲＳ Ｊｕｌｙ ２０１６
基于深度学习的鲁棒性视觉跟踪方法
高君宇 杨小汕 张天柱 徐常胜
（中国科学院自动化研究所模式识别国家重点实验室 北京 １００１９０）
摘 要 传统的视觉跟踪方法（如Ｌ１等）大多直接使用视频序列各帧内的像素级特征进行建模，而没有考虑到各
图像块内部的深层视觉特征信息．在现实世界的固定摄像头视频监控场景中，通常可以找到一块区域，该区域中目
标物体具有清晰、易于分辨的表观．因此，文中在各视频场景内事先选定一块可以清晰分辨目标表观的参考区域用
以构造训练样本，并构建了一个两路对称且权值共享的深度卷积神经网络．该深度网络使得参考区域外目标的输
出特征尽可能与参考区域内目标的输出特征相似，以获得参考区域内目标良好表征的特性．经过训练后的深度卷
积神经网络模型具有增强目标可识别性的特点，可以应用在使用浅层特征的跟踪系统（如Ｌ１等）中以提高其鲁棒
性．文中在Ｌ１跟踪系统的框架下使用训练好的深度网络提取目标候选的特征进行稀疏表示，从而获得了跟踪过
程中应对遮挡、光照变化等问题的鲁棒性．文中在２５个行人视频中与当前国际上流行的９种方法对比，结果显示
文中提出的方法的平均重叠率比次优的方法高０．１１，平均中心位置误差比次优的方法低１．０．
关键词 深度学习；卷积神经网络；视觉跟踪；鲁棒性；Ｌ１跟踪系统；计算机视觉
中图法分类号 ＴＰ１８ ＤＯＩ号 １０．１１８９７／ＳＰ．Ｊ．１０１６．２０１６．０１４１９
Ｒｏｂｕｓｔ Ｖｉｓｕａｌ Ｔｒａｃｋｉｎｇ Ｍｅｔｈｏｄ ｖｉａ Ｄｅｅｐ Ｌｅａｒｎｉｎｇ
ＧＡＯ Ｊｕｎ－Ｙｕ ＹＡＮＧ Ｘｉａｏ－Ｓｈａｎ ＺＨＡＮＧ Ｔｉａｎ－Ｚｈｕ ＸＵ Ｃｈａｎｇ－Ｓｈｅｎｇ
（Ｓｔａｔｅ Ｋｅｙ Ｌａｂｏｒａｔｏｒｙ ｏｆ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ，Ｉｎｓｔｉｔｕｔｅ ｏｆ Ａｕｔｏｍａｔｉｏｎ，Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ，Ｂｅｉｊｉｎｇ １００１９０）
Ａｂｓｔｒａｃｔ Ｔｈｅ ｔｒａｄｉｔｉｏｎａｌ ｔｒａｃｋｉｎｇ ｍｅｔｈｏｄｓ（ｅ．ｇ．Ｌ１ｔｒａｃｋｅｒ）ｇｅｎｅｒａｌｌｙ ａｄｏｐｔ ｔｈｅ ｐｉｘｅｌ ｖａｌｕｅｓ ａｓ
ｆｅａｔｕｒｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ，ａｎｄ ｉｇｎｏｒｅ ｔｈｅ ｄｅｅｐ ｖｉｓｕａｌ ｆｅａｔｕｒｅｓ ｏｆ ｉｍａｇｅ ｐａｔｃｈｅｓ．Ｉｎ ａ ｆｉｘｅｄ ｖｉｄｅｏ
ｓｃｅｎｅ ｏｆ ｔｈｅ ｒｅａｌ ｗｏｒｌｄ，ｗｅ ｒｅａｌｉｚｅ ｔｈａｔ ｗｅ ｃａｎ ｕｓｕａｌｌｙ ｆｉｎｄ ａｎ ａｒｅａ ｗｈｅｒｅ ｔｈｅ ｔａｒｇｅｔｓ ｈａｖｅ ｃｌｅａｒ
ａｐｐｅａｒａｎｃｅ ａｎｄ ａｒｅ ｅａｓｙ ｔｏ ｄｉｓｔｉｎｇｕｉｓｈ．Ｔｈｅｒｅｆｏｒｅ，ｉｎ ｔｈｉｓ ｐａｐｅｒ，ｗｅ ｓｅｌｅｃｔ ａ ｒｅｇｉｏｎ ｉｎ ｅａｃｈ ｖｉｄｅｏ
ｔｏ ｃｏｎｓｔｒｕｃｔ ｔｒａｉｎｉｎｇ ｓｅｔ ｆｏｒ ｄｅｅｐ ｍｏｄｅｌ ｌｅａｒｎｉｎｇ．Ｉｎ ｔｈｅ ｐｒｏｐｏｓｅｄ ｄｅｅｐ ｍｏｄｅｌ，ｗｅ ｄｅｓｉｇｎ ａ ｄｅｅｐ
ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｗｈｉｃｈ ｈａｓ ｔｗｏ ｓｙｍｍｅｔｒｉｃａｌ ｐａｔｈｓ ｗｉｔｈ ｔｈｅ ｓｈａｒｅｄ ｗｅｉｇｈｔｓ．Ｔｈｅ ｇｏａｌ
ｏｆ ｔｈｅ ｐｒｏｐｏｓｅｄ ｄｅｅｐ ｎｅｔｗｏｒｋ ｉｓ ｔｏ ｒｅｄｕｃｅ ｔｈｅ ｄｉｆｆｅｒｅｎｃｅ ｂｅｔｗｅｅｎ ｔｈｅ ｆｅａｔｕｒｅｓ ｏｆ ａ ｔａｒｇｅｔ ｏｕｔ ｏｆ
ｔｈｅ ｒｅｇｉｏｎ ａｎｄ ｉｎ ｔｈｅ ｒｅｇｉｏｎ．Ａｓ ａ ｒｅｓｕｌｔ，ｔｈｅ ｌｅａｒｎｅｄ ｄｅｅｐ ｎｅｔｗｏｒｋ ｃａｎ ｅｎｈａｎｃｅ ｔｈｅ ａｐｐｅａｒａｎｃｅ
ｆｅａｔｕｒｅ ｏｆ ｔａｒｇｅｔｓ ａｎｄ ｂｅｎｅｆｉｔ ｔｈｅ ｔｒａｃｋｅｒｓ ｔｈａｔ ｕｔｉｌｉｚｅ ｌｏｗ－ｌｅｖｅｌ ｆｅａｔｕｒｅｓ，ｓｕｃｈ ａｓ Ｌ１ｔｒａｃｋｅｒ．Ｆｉｎａｌｌｙ，
ｗｅ ｕｔｉｌｉｚｅ ｔｈｉｓ ｐｒｅ－ｔｒａｉｎｅｄ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋ ｉｎ ｔｈｅ Ｌ１ｔｒａｃｋｅｒ ｔｏ ｅｘｔｒａｃｔ ｆｅａｔｕｒｅｓ ｆｏｒ
ｓｐａｒｓｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ．Ｃｏｎｓｅｑｕｅｎｔｌｙ，ｏｕｒ ｍｅｔｈｏｄ ａｃｈｉｅｖｅｓ ｔｈｅ ｒｏｂｕｓｔｎｅｓｓ ｉｎ ｔｒａｃｋｉｎｇ ｆｏｒ ｈａｎｄｌｉｎｇ
ｔｈｅ ｃｈａｌｌｅｎｇｅｓ ｓｕｃｈ ａｓ ｏｃｃｌｕｓｉｏｎ ａｎｄ ｉｌｌｕｍｉｎａｔｉｏｎ ｃｈａｎｇｅｓ．Ｗｅ ｅｖａｌｕａｔｅ ｔｈｅ ｐｒｏｐｏｓｅｄ ａｐｐｒｏａｃｈ ｏｎ
２５ｃｈａｌｌｅｎｇｉｎｇ ｖｉｄｅｏｓ ａｇａｉｎｓｔ ｗｉｔｈ ９ｓｔａｔｅ－ｏｆ－ｔｈｅ－ａｒｔ ｔｒａｃｋｅｒｓ．Ｔｈｅ ｅｘｔｅｎｓｉｖｅ ｒｅｓｕｌｔｓ ｓｈｏｗ ｔｈａｔ
ｔｈｅ ｐｒｏｐｏｓｅｄ ａｌｇｏｒｉｔｈｍ ｉｓ ０．１１ｈｉｇｈｅｒ ｔｈａｎ ｔｈｅ ｓｅｃｏｎｄ ｂｅｓｔ ｗｉｔｈ ａｖｅｒａｇｅ ｏｖｅｒｌａｐ，ａｎｄ ｉｓ １．０ｌｏｗｅｒ
ｔｈａｎ ｔｈｅ ｓｅｃｏｎｄ ｂｅｓｔ ｗｉｔｈ ｔｈｅ ａｖｅｒａｇｅ ｃｅｎｔｅｒ ｌｏｃａｔｉｏｎ ｅｒｒｏｒｓ．
Ｋｅｙｗｏｒｄｓ ｄｅｅｐ ｌｅａｒｎｉｎｇ；ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒｏｎ ｎｅｔｗｏｒｋｓ；ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ；ｒｏｂｕｓｔ；Ｌ１ｔｒａｃｋｅｒ；
ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ
收稿日期：２０１５－１０－１８；在线出版日期：２０１６－０１－１５．本课题得到国家“九七三”重点基础研究发展规划项目基金（２０１２ＣＢ３１６３０４）和国家自
然科学基金重点项目（６１４３２０１９）资助．高君宇，男，１９９４年生，博士研究生，主要研究方向为计算机视觉和多媒体．Ｅ－ｍａｉｌ：
ｇａｏｊｕｎｙｕ２０１２＠ｇｍａｉｌ．ｃｏｍ．杨小汕，男，１９８９年生，博士研究生，中国计算机学会（ＣＣＦ）会员，主要研究方向为图像、视频的识别（排序）、
深度学习．张天柱，男，１９８２年生，博士，副研究员，主要研究方向为计算机视觉和多媒体．徐常胜（通信作者），男，１９６９年生，博士，研究
员，中国计算机学会（ＣＣＦ）会员，主要研究领域为多媒体分析／索引／检索、模式识别和计算机视觉．Ｅ－ｍａｉｌ：ｃｓｘｕ＠ｎｌｐｒ．ｉａ．ａｃ．ｃｎ． １４２０ 计 算 机 学 报 ２０１６年
然近年来关于视觉跟踪算法的研究取得了较大的
１ 引 言 进展［３－１０］，但其在现实中应对各类复杂场景时仍然
面临着巨大的挑战，例如遮挡、亮度变化、姿态变
视觉跟踪是当前计算机视觉领域的研究热点， 化、尺度变化等，如图１所示，在一个视频序列中
其广泛应用于物体智能识别、人机交互、车辆定位等 可能出现多种跟踪挑战．所以，如何使跟踪算法更
方面［１］．视觉跟踪还可应用于智能视频监控技术 具鲁棒性以适应上述挑战仍然是目前研究聚焦的
中，服务智慧城市的发展和公共安全的需求［２］．虽 核心．
图１ 视频序列中可能出现的多种挑战（遮挡、光照变化、尺度变化、姿态变化等）
大多数跟踪算法都可划为判别型和生成型方 示，达到跟踪目的．Ｆｒａｇ跟踪系统［１７］通过使用局部
法［１１－１２，１６］．判别型方法将跟踪问题建模为一个二元 块的直方图表示对物体的外观进行建模，以解决部
分类问题，用以找到区分目标物体和背景的决策边 分遮挡问题．Ｊｉａ等人［１８］提出了一种自适应的结构
界．Ａｖｉｄａｎ［１１］将许多弱分类器组合成一个强分类 化局部稀疏外观模型进行跟踪．Ｚｈｏｎｇ等人［１９］使用
器，提出了一种全局跟踪方法．Ｂａｂｅｎｋｏ等人［１２］提 基于稀疏表示的局部块间协同的模型以获得跟踪的
出了一种基于在线多示例学习的跟踪方法．Ｇｒａｂｎｅｒ 鲁棒性．Ｚｈａｎｇ等人［２０］在在线跟踪中引入了多专家
等人［１３］提出了一种在线ｂｏｏｓｔｉｎｇ方法来更新可区 重建机制，通过求解一个熵最小化问题重建当前的
分的特征．Ｓｔｒｕｃｋ跟踪系统［５］利用一类核函数实现 跟踪系统．肖国强等人［２１］提出了一种基于中心宏块
结构化输出跟踪结果．Ｋａｌａｌ等人［１４］提出了Ｐ－Ｎ学 的视频目标跟踪算法，引入了一个中心宏块的概念，
习算法，通过对潜在正负样本结构信息的学习构造 通过两个层次的相似性度量，以建立相邻帧之间目
出目标跟踪的分类器．黄福珍等人［１５］提出了一种基 标的对应关系．
于Ｌｅｖｅｌ Ｓｅｔ的人脸跟踪方法，利用图像帧间差分快 判别模型和生成模型中大多数方法直接使用视
速检测出运动区域，并根据人脸图像的投影映射规 频图像序列中的像素值进行建模，当跟踪过程中出
则确定人脸所在的外接矩形，从而判定跟踪过程中 现严重的遮挡、复杂背景等较大挑战时，浅层的像
的人脸位置． 素级特征无法很好地应对．而经过学习得到的深
与判别模型相反，生成跟踪模型通过学习一个 层视觉结构特征利于处理这些问题．近年来，深度
模型来表示目标物体，然后使用此模型以最小的重 学习框架已经应用于计算机视觉领域并取得了良好
构误差搜索图像区域，以达到跟踪目的．Ｍｅｉ等 的效果．其中，卷积神经网络（Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｎｅｕｒｏｎ
人［１６］提出了Ｌ１跟踪系统，通过对目标进行稀疏表 Ｎｅｔｗｏｒｋｓ，ＣＮＮ）由卷积层和全连接层构成，通过共 ７期 高君宇等：基于深度学习的鲁棒性视觉跟踪方法 １４２１
享权重和池化层（ｐｏｏｌｉｎｇ ｌａｙｅｒ）来降低参数的数目 到参考区域内，以获得参考区域内目标样本的良好
和提升效果，具有良好地学习图像深层视觉特征的 表观特性．同时，本文改进了传统的用于分类的卷积
能力．因此，本文提出了一种新颖的深度卷积神经网 神经网络，构造了一个两路对称且权值共享的网络
络结构，利用视频场景中的区域位置特性以提高视 模型，使其能学习到增强目标可识别性的权重参数，
觉跟踪的鲁棒性． 并将此网络应用到视觉跟踪过程中．本文将出现在
本文提出了一种基于深度学习的跟踪算法．该 参考区域的目标样本和不在参考区域的同一目标的
算法基于如下观察：在一个固定摄像头的视频场景 样本构成样本对，作为训练深度网络的输入．此网络
中，可以找到一块较好的区域，例如一块位置适中、 分为对称且权值共享的两条路径，每路都由３层卷
表现平整的马路等，如图２所示（黑白图①）．图２中 积层和一层全连接层组成．两种类型的样本分别通
８张图片内矩形框所围成的区域即本文选择的部分 过这两条路径并在全连接层输出固定维度的特征
参考区域．在参考区域中目标物体通常会有清晰、易 （如１０×１０），通过最小化欧氏距离函数，使负样本
分辨的表观，而当目标物体出现在参考区域外时，由 输出的特征尽可能与正样本相似．由于是固定摄像
于非参考区域可能具有复杂的环境，目标物体的表 头场景下的视觉跟踪且选取的参考区域固定，所以
观易于呈现出不清晰、不完整的情况，如图３所示． 该网络学习出的权重参数对于出现在该摄像头内的
这个发现启发本文在跟踪过程中利用参考区域的位 目标物体具有通用性．各摄像头对应的深度网络进
置特性以增强目标的可识别性，即将目标样本映射 行训练的样本对数量的均值为４０ ５３０对，其中充分
图２ ８个视频场景中的参考区域
包含了遮挡、亮度变化、姿态变化等阻碍跟踪性能的
① 根据投稿格式要求，文中均使用黑白图片．为了便于读者理
情况，使得学习到的模型具备适应各类问题的鲁
解本文（尤其是实验结果与分析部分），推荐浏览彩色版图
片，请访问：ｈｔｔｐ：／／ｎｌｐｒ－ｗｅｂ．ｉａ．ａｃ．ｃｎ／ｍｍｃ／ｈｏｍｅｐａｇｅ／
棒性．
ｊｙｇａｏ／ｒｅｓｕｌｔ－ｇｊｙ．ｈｔｍｌ １４２２ 计 算 机 学 报 ２０１６年
图３ 参考区域内外的目标样本差异
在跟踪过程中，深度网络输出的相应特征可以 的方法，良好地解决了部分遮挡问题．文献［２５］构造
提高许多直接使用浅层特征的跟踪系统的鲁棒性， 了一个一致性低秩稀疏模型，利用粒子采样中粒子
如Ｌ１跟踪系统．本文的实验部分以Ｌ１跟踪系统［３］ 之间的固有关系提高了跟踪过程的鲁棒性．王宇霞
为例，提出了一种基于深度学习的 Ｌ１跟踪系统 等人［２６］提出了一种基于自重构粒子滤波算法的目
（Ｄｅｅｐ Ｌｅａｒｎｉｎｇ Ｌ１ｔｒａｃｋｅｒ），通过使用模板特征和 标跟踪，该算法能够通过分裂跟踪器以应对复杂多
每一帧内粒子采样块对应的输出特征，通过求解一 变的跟踪环境，同时，合并过程能够从多个跟踪器中
个规则化最小二乘问题，实现用模板特征集对目 选出最优跟踪器，利用合并冗余的跟踪器以达到减
１
标特征进行稀疏表示．本文提出的基于深度学习的 少计算量的效果．
Ｌ１跟踪算法具有以下优点：（１）模型在应对遮挡、 另一方面，近年来深度学习已经开始应用于视
光照变化、物体姿态改变等方面具有较高的鲁棒性． 觉跟踪．但这类方法依然存在两个问题：（１）由于深
由本文学习得到的卷积神经网络模型可以应用于其 度学习模型规模巨大，所以需要大量的样本进行
他已有的跟踪模型中进行特征提取；（２）经过深度 训练；（２）深度学习庞大的规模导致其在应用中产
学习训练得到的模型在该摄像头内进行目标跟踪具 生了大量的时间开销．为了解决缺少样本的问题，
有很强的通用性；（３）本文提出的模型在应对初始 Ｗａｎｇ等人［２７］使用大量的辅助图像离线训练了一个
帧内目标模糊或残缺的状况时较其他模型更优．通 栈式去噪自编码器，对目标候选进行特征提取，并将
过在２５个视频中与前文提及的目前国际上最为先 这样的特征应用于粒子滤波的框架中，同时，在跟踪
进的９种方法进行对比，本文提出的方法在平均重 过程中更新自编码器．更多的学者选择使用卷积神
叠率和平均中心位置误差的评价指标上超过了其他 经网络进行视觉跟踪．Ｆａｎ等人［２８］同样利用大量的
跟踪系统． 辅助图像训练深度卷积神经网络，并将模型应用于
行人跟踪中，取得了较好的效果．Ｚｈｏｕ等人［２９］使用
２ 相关工作 多个神经网络的聚合体进行目标跟踪．然而，这些方
法由于缺少大量跟踪过程中的实际数据，所以效果
本文将提出的深度学习模型应用于一类基于稀 提升的程度有限．为此，Ｌｉ等人［３０－３２］设计了层次较
疏表示的生成型跟踪系统中，如Ｌ１跟踪系统［３］．近 浅的卷积神经网络，设定了一个特殊的损失函数，并
年来，基于稀疏表示的跟踪方法得到了较大的发展． 以在线的方式对跟踪过程中产生的样本进行训练．
文献［２２－２３］利用粒子滤波方法中目标周围的采样 还有另外的一些方法试图解决上述的两个问题．
粒子具有相似性和依赖性的关系，提出了一个由多 Ｈｏｎｇ等人［３３］利用卷积神经网络提取特征，并使用
个粒子共同构建的协同稀疏模型．文献［２４］构造了 在线更新的ＳＶＭ 对跟踪过程中的样本进行分类，
一个结构化的多任务稀疏学习模型，提升了跟踪过 将正样本的特征进行反向传播，从而得到正样本对
程的鲁棒性．文献［２５］采用部分匹配进行稀疏表示 应的显著图并以此显著图来进行判别式跟踪．Ｗａｎｇ ７期 高君宇等：基于深度学习的鲁棒性视觉跟踪方法 １４２３
等人［３４］利用离线训练好的卷积神经网络模型提取 传统的跟踪方法（如Ｌ１跟踪系统）．之后介绍本文
层次特征并用以进行在线跟踪．Ｃｈｅｎ等人［３５］利用 据此深度网络模型改进了的Ｌ１跟踪算法．
类似于文献［２７］的方式训练了一个卷积神经网络， ３．１ 基于参考区域特征变换的深度网络
而Ｈｕ等人［３６］则训练了一个卷积深度置信网络 图４展示了本文提出的基于参考区域特征变换
（Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｄｅｅｐ Ｂｅｌｉｅｆ Ｎｅｔｗｏｒｋ，ＣＤＢＮ）应用 的深度网络架构．输入ｄａｔａ＝（ｘ０，ｙ０），其中ｘ０表示
于跟踪过程．Ｚｈａｎｇ等人［３７］使用目标区域中随机提 出现在参考区域中的样本，ｙ０表示未出现在参考区
取的归一化图像块作为卷积神经网络的滤波器，从 域中的同一目标的的样本．ｘ０所对应样本的表观大
而实现了不用训练卷积神经网络的快速特征提取． 部分清晰、易于分辨，ｙ０所对应样本中包含了大量的
Ｋｕｅｎ等人［３８］提出了一种通过强短时限制和栈式卷 遮挡、光照变化、姿态变化等情况．将ｘ０、ｙ０根据通
积自编码器学习到目标表示的不变性．文献［３９］利 道数、高度和宽度进行尺寸归整，使得ｘ０，ｙ０∈
用了一种半监督的深度学习方法进行目标跟踪． Ｒ３×１００×１００，即ｎ＝３×１００×１００．两者各自通过对称
０
且权值共享的三层卷积层、三层池化层和一层ｘ０全
３ 基于深度学习的视觉跟踪方法 连接层，并在全连接层输出各自的特征，维度为
１００．由于ｘ０，ｙ０通过的路径相互对称且对应层权值
本节首先介绍了基于参考区域特征变换的深度 共享，所以下面本文只介绍如何获得ｘ０对应的输出
网络模型，训练好的深度网络模型可以应用于许多 特征．
图４ 深度网络的架构
在第一个卷积层中，ｘ０通过一个权重矩阵Ｗ１得 可以写作Ｗ珮 ＊ｘ～，所以本文省略了ｂ以便于表达．本
到了９６个特征映射，Ｗ１包含９６个子矩阵，即Ｗ１＝ 文使用最大池采样［４１］的方式对特征映射进行下采
［Ｗ１；Ｗ１；…；Ｗ１ ］，Ｗ１∈Ｒ３×１１×１１，其中Ｗ１表示 样，下采样滤波器的尺寸为３×３，采样间隔为２，得
１ ２ ９６ ｉ ｉ
第一个卷积层中每个卷积核对应的参数，卷积核的 到ｘ１∈Ｒ１１×１１．通过将所有的ｘ１连接在一起，可以
ｉ ｉ
通道数和尺寸分别为３和１１×１１，采样间隔为４．因 得到一个完整的特征映射ｘ１∈Ｒ９６×１１×１１，其维度为
此输出的９６个特征映射｛ｘ１｝９６ 是通过对ｘ０卷积响 ｎ＝９６×１１×１１．
ｉ ｉ＝１ １
应的和经过非线性激励函数计算得到的．每个ｘ１通 １
ｉ ｆ（ｚ）＝ （２）
过式（１）进行计算： １＋ｅｘｐ（－ｚ）
ｘ１＝ｄｏｗｎ（ｆ（Ｗ１＊ｘ０）） （１） 在第二层中，为了能更充分地利用输入信息
ｉ ｉ
本文选用ｓｉｇｍｏｉｄ函数作为激活函数ｆ（·），对 ｘ１，本文在每个ｘ ｉ１的外侧进行填补，填补的尺度为
自变量逐元素进行计算，其表达式见式（２）．“＊”代表 ２．之后将ｘ１与２５６个卷积核依次进行卷积，对应的
三维卷积．注意到传统的卷积神经网络模型［４０］中含 权重参数为 Ｗ２＝［Ｗ２；Ｗ２；…；Ｗ２ ］，Ｗ２∈
１ ２ ２５６ ｉ
有偏置项ｂ，其输出为ｆ（Ｗ＊ｘ＋ｂ），但是Ｗ＊ｘ＋ｂ Ｒ９６×５×５每个卷积核的通道数和尺寸分别为９６和 １４２４ 计 算 机 学 报 ２０１６年
５×５，采样间隔
ｘ
ｉ为 ２＝１ ｄ， ｏ可 ｗｎ得
（ｆ（Ｗ ｉ２＊ｘ１）） （３）
ｐ（ｘ ｔ｜ｙ
１：ｔ）＝ｐ（ｙ
ｔ
ｐ｜ｘ （ｙｔ） ｔｐ ｜ｙ（ｘ １：ｔｔ｜ －ｙ １）１：ｔ－１）
（８）
这一层采用尺寸为３×３的滤波器进行下采样， ｔ帧内目标的最优状态可以通过估计其最大后
采样间隔为２，因此ｘ ｉ２∈Ｒ５×５，将所有的特征映射 验概率求解：ｘ ｔ＊＝ａｒｇ ｘｍａｘｐ（ｘ｜ｙ １：ｔ），当使用序列重
ｘ２组成ｘ２∈Ｒ２５６×５×５，其维度为ｎ＝２５６×５×５． 要性采样技术时，后验概率可以用一组具有不同权
ｉ ２
在第三层中，本文将ｘ２映射到ｘ３，且这一层不 重的粒子Ｓ＝｛ｘ１，ｘ２，…，ｘＮ｝进行近似．其权重在
ｔ ｔ ｔ ｔ
包含池化．３２个卷积核依次与ｘ２进行卷积，卷 简化的条件下满足ｗｉ∝ｗｉ ｐ（ｙ｜ｘｉ）．
ｔ ｔ－１ ｔ ｔ
积核的通道数和尺寸分别为３×３，每个输入ｘ２填 ３．２．２ 基于特征的稀疏表示
ｉ
补的尺度为１．卷积核对应的权重参数记为Ｗ３＝ 稀疏表示的目的是为了计算粒子ｘ的似然分
ｔ
［Ｗ３；Ｗ３；…；Ｗ３ ］，Ｗ３∈Ｒ２５６×３×３． 布，即ｐ（ｚ｜ｘ）．在ｔ帧，给定目标模板的特征集
１ ２ ３２ ｉ ｔ ｔ
ｘ ｉ３＝ｆ（Ｗ ｉ３＊ｘ２） （４） Ｔ ｔ＝［ｔ ｔ１，ｔ ｔ２，…，ｔ ｔｎ］，令Ｓ ｔ＝｛ｘ ｔ１，ｘ ｔ２，…，ｘ ｔＮ｝表示采
其中ｘ ｉ３∈Ｒ５×５，将所有的ｘ ｉ３连接成一个具有ｎ ３＝ 样粒子的状态且令Ｏ ｔ＝｛ｙ ｔ１，ｙ ｔ２，…，ｙ ｔＮ｝表示目标候
３２×５×５＝８００维的向量，即ｘ３∈Ｒ８００． 选的特征集．由于经过深度网络训练出的特征在应
最后一层是全连接层，从而输出原始数据的最 对遮挡问题时十分有效，所以本文不使用单位模板．
终特征ｘ４，其维度为ｎ＝１００．使用的权重矩阵为 目标候选特征可以由目标模板特征集近似线性表示
４
Ｗ４∈Ｒｎ４×ｎ３． 如式（９）：
ｘ４＝Ｗ４ｘ ３ （５） ｙｉ ｔ≈Ｔ ｔａ，ｙ ｔｉ∈Ｏ ｔ （９）
同样，ｙ０也经过相同的深度网络进行变换，最
式中ａ＝（ａ １，ａ ２，…，ａ ｎ）Ｔ称为目标系数向量．本文希
后得到其在最后一个全连接层的输出特征ｙ４．对于
望ａ是稀疏的，另外，本文给ａ附加了非负约束以增
训练数据中的所有样本对，本文可以得到两个对应
强Ｌ１跟踪系统的鲁棒性［１６］．因此，对于每一个目标
的特征集合Ｘ４＝｛ｘ４｝ｍ 和Ｙ４＝｛ｙ４｝ｍ ，其中ｍ表 候选特征ｙ ｔｉ，其稀疏表示可以通过求解如下的 １－范
ｉ＝１ ｉ＝１
示训练实例的数目．本文的目标函数是最小化正、负
数最小化问题实现，并加以非负约束：
样本之间的欧氏距离： ｍｉｎ１ ｙｉ－Ｔａ２＋λａ ，ａ０ （１０）
２ ｔ ｔ ２ １ ｊ
ｍ ａ
１
Ｗａ １ｒ ，Ｗｇ
２
，ｍ Ｗｉ ３ｎ
，Ｗ４２ｍ
ｉ∑
＝１
ｘ ｉ４－ｙ ｉ４ ２
２
（６） 最后，ｘ ｔｉ的似然概率由式（１１）给出：
式（６）中 · ２表示２－范数．通过优化式（６）可以 ｐ（ｚ ｔ｜ｘｉ ｔ）＝ Γ１ ｅｘｐ｛－αｙ ｔｉ－Ｔ ｔｃｉ ２ ２｝ （１１）
获得上述整个深度网络的权重，学习到的权重具有
式（１１）中，α是一个常数用来控制高斯核的形
将样本映射到参考区域中的功能，本文将训练好的
状，Γ是正则因子，ｃｉ是式（１０）所求得的最优解．此
卷积神经网络用在Ｌ１跟踪系统的框架下进行特征
时，帧ｔ内目标状态的最优解可由式（１２）求得
提取．
３．２ 改进的Ｌ１跟踪系统
ｘ ｔ＊＝ａｒ ｘｇ
ｔｉ
∈ｍ Ｓａ ｔｘｐ（ｚ ｔ｜ｘ ｔｉ） （１２）
本文参考了Ｂａｏ等人［３］提出的 ＡＰＧ－Ｌ１跟踪 另外，本文引入了一种模板更新机制［１６］以适应
系统，本文主要的改动是利用训练好的深度网络对 跟踪过程中的光照和姿态变化等，但由于模型中使
采样图像块和模板提取特征（而不是原始像素）并进 用的是图像块的特征，所以本文调整了模板更新的
行稀疏表示，且不需要考虑单位模板和遮挡情况的 阈值．本文还参考了 Ｍｅｉ等人［４２］提出的最小误差边
处理． 界，用以加速求解上述－范数最小化问题．该理论
１
３．２．１ 粒子滤波 得出每一个粒子ｘｉ的似然分布有如下上界：
ｔ
在视觉跟踪中，粒子滤波是估计下一帧目标位 １
ｐ（ｚ｜ｘｉ） ｅｘｐ｛－Ｔａ＾－ｙｉ ２｝ｑ（ｚ｜ｘｉ）（１３）
置后验概率的重要方法，包括预测和更新两步．本 ｔ ｔ Γ ｔ ｔ ２ ｔ ｔ
文用ｘ ｔ表示在ｔ帧时目标物体的状态，用ｙ １：ｔ－１＝ 其中ｑ（ｚ ｔ｜ｘｉ ｔ）是粒子状态ｘ ｔｉ似然分布的上界，当
｛ｙ １，ｙ ２，…，ｙ ｔ－１｝表示１～ｔ时刻所有的观测．粒子滤
ｑ（ｚ｜ｘｉ）＜
１ ∑ｉ－１
ｐ（ｚ｜ｘｊ）时，粒子ｘｉ将不会在重
ｔ ｔ ２ Ｎ ｔ ｔ ｔ
波通过下面两个概率进行预测和更新： ｊ＝１
采样中出现．本文使用两阶段的重采样方法以降低
ｐ（ｘ ｔ｜ｙ １：ｔ－１）＝∫ｐ（ｘ ｔ｜ｘ ｔ－１）ｐ（ｘ ｔ－１｜ｙ １：ｔ－１）ｄｘ ｔ－１（７） 跟踪过程中所需粒子数目［４２］．ａ＾通过式（１４）求得 ７期 高君宇等：基于深度学习的鲁棒性视觉跟踪方法 １４２５
１ 的９种跟踪算法进行对比，这些算法分别简写为
ａ＾＝ａｒｇ
ａ
ｍｉｎ
２
Ｔ ｔａ－ｙ２
２
（１４）
ＯＡＢ［１３］、Ｆｒａｇ［１７］、Ｓｔｒｕｃｋ［５］、Ｌ１［３］、ＴＬＤ［１４］、ＭＥＥＭ［２０］、
相比于ＡＰＧ－Ｌ１［１０］跟踪算法，本文的主要改动
ＬＳＴ［１８］、ＳＤＧ［１９］、ＭＩＬ［１２］．
是使用基于参考区域特征变换的深度卷积神经网络 ４．１ 定量分析
模型对模板和粒子采样的图像块提取特征以进行稀
为了定量分析每个跟踪系统的性能，本文使用
疏表示，并且由于训练好的卷积神经网络具有应对
中心位置误差和重叠率两种度量方式．这两种度量
遮挡的能力，所以在Ｌ１框架中本文不考虑遮挡情
方式各有侧重，中心位置误差是跟踪结果和实际
况，见算法１．
情况中心点间的欧氏距离．重叠率是ＰＡＳＣＡＬ竞赛
算法１． 基于深度学习的Ｌ１跟踪算法． 中目标检测的评分标准［４４］，即对于给定的跟踪边界
输入：当前帧Ｆ；
ｔ 框ＲＯＩ 和实际情况的边界框 ＲＯＩ ，通过使用
Ｔ ＧＴ
粒子集Ｓ ＝｛ｘｉ ｝Ｎ
ｔ－１ ｔ－１ｉ＝１ ａｒｅａ（ＲＯＩ∩ＲＯＩ ）
模板特征集Ｔ ｔ－１＝｛ｔ ｉ｝ ｉｎ ＝１ ｓｃｏｒｅ＝ ａｒｅａ（ＲＯＩ ＴＴ ∪ＲＯＩ ＧＧ ＴＴ ）衡量跟踪系统的性能．
输出：根据式（１２）求得的ｘ ｔ＊ 本文在２５个图像序列上与９种当前流行的跟踪系
１．ｆｏｒ ｉ＝１ｔｏ Ｎｄｏ 统对比，结果见表１和表２．表中粗体和粗斜体的数
２．根据ｘｉ 得到新的粒子ｘｉ，并通过深度网络得到
ｔ－１ ｔ 据分别表示最好和次好的结果．根据平均重叠率的
对应的输出特征ｙｉ；
ｔ 衡量标准，本文提出基于深度学习的视觉跟踪方法
３．求解式（１４）对应的问题；
（ＤＤＬ１）在２５个测试视频中有１６个排名第一，５个
４．根据式（１３）计算ｑ．
ｉ
排名第二，ＤＤＬ１方法在整个数据集上的平均重叠
５．ｅｎｄ ｆｏｒ
６．根据ｑ值，以降序方式对粒子进行排序；
率为０．６８，比次优的Ｓｔｒｕｃｋ方法高０．１１，比Ｌ１方
７．令ｉ＝１且τ＝０．
法高０．１６，比最低的ＴＬＤ方法高０．２６．总的来说，
８．ｗｈｉｌｅ ｉ＜Ｎａｎｄ ｑτｄｏ 本文提出的基于深度学习跟踪算法较好地超过了当
ｉ
９．求解式（１０）的最小化问题［３］； 前流行的其他算法．根据平均中心位置误差的衡量
１０．根据式（１１）计算似然分布ｐｉ； 标准，本文提出的ＤＤＬ１跟踪方法在２５个测试视频
１１．τ＝τ＋ ２１ Ｎｐｉ； 中有１０个排名第一，４个排名第二，在整个数据集
上的平均中心位置误差为１７．６５，比次优的Ｓｔｒｕｃｋ
１２．ｉ＝ｉ＋１；
方法低１．０，比Ｌ１方法低５０．３１，比最低的ＴＬＤ方
１３．ｅｎｄ ｗｈｉｌｅ
１４．对于ｊｉ，令ｐ＝０；
法低６８．５２．图５展示了其中１８个视频的逐帧中心
ｊ
１５．更新模板特征集Ｔ ； 位置误差，可以看出，在跟踪过程中，本文提出的方
ｔ－１
１６．根据ｐ更新粒子集Ｓ ｔ－１． 法的误差较其他９种方法保持在一个较低的水平．
４．２ 定性分析
４ 实验结果与分析 图６展示了２５个视频序列上的１０个跟踪系统
的部分跟踪结果，图内这些视频序列的名称均为原
由于本文提出的深度网络应用于固定摄像头场 数据集视频名称的缩写．下文将根据跟踪过程中的
景，并且需要大量已标注的样本进行训练，所以本文 主要困难对各跟踪结果进行分析．
使用北京大学数字视频编解码技术国家工程实验室 （１）遮挡．ｈｓｌｎ１３．１１为多人交错行走，目标在
（ＮＥＬＶＴ）的ＰＫＵ－ＳＶＤ－Ｂ数据集进行验证．该数 过程中多次被严重遮挡，Ｌ１、Ｆｒａｇ、ＯＡＢ与ＴＬＤ算
据集也成功应用于２０１５年全国研究生智慧城市技 法在２３帧、４４帧、６１帧和６５帧附近跟丢目标，其余
术与创意设计大赛中．实验使用了该数据集中２５个 算法成功地进行了跟踪，但效果没有本文提出的方
行人目标的视频．这些视频具有多类场景并包含了大 法好．ｙｇｑ５．１０中目标沿路旁行走，在３９帧时，ＴＬＤ
量的遮挡、光照变化、姿态变化、密集背景、初始帧目 算法跟丢了目标，而ＤＤＬ１方法可以一直紧凑地跟
标模糊或残缺等情况．本次实验中，本文使用伯克利 踪目标．视频ｄｎｍ１．３中，目标被一辆汽车部分遮
大学视觉与学习中心（ＢＶＬＣ）提供的开源深度学习 挡，Ｆｒａｇ和ＴＬＤ算法分别在２５帧和２９帧处跟丢，
架构Ｃａｆｆｅ［４３］训练本文的深度神经网络．在之后的 ＤＤＬ１方法效果显著．视频ｂｗｂ２．２和视频ｂｗｂ２．３
Ｌ１框架中，本文令λ＝０．２，模板个数ｍ＝１０，粒子 中行人被树枝遮挡，本文提出的方法较好地应对了
数目ｎ＝６００．最后的实验结果与当前国际上流行 这类问题． １４２６ 计 算 机 学 报 ２０１６年
表１ ２５个视频上１０个跟踪系统的平均重叠率
视频 ＤＬＬ１ ＯＡＢ Ｆｒａｇ Ｓｔｒｕｃｋ Ｌ１ ＴＬＤ ＭＥＥＭ ＬＳＴ ＳＤＧ ＭＩＬ
ｂｗｂ２．２ ０．７５ ０．６９ ０．７０ ０．６６ ０．６５ ０．２３ ０．６８ ０．７２ ０．７０ ０．７１
ｂｗｂ２．３ ０．３９ ０．４３ ０．３５ ０．４３ ０．３４ ０．２８ ０．２０ ０．２８ ０．３９ ０．３３
ｂｗｂ２．４ ０．６７ ０．３１ ０．３５ ０．４１ ０．７４ ０．５１ ０．４１ ０．６０ ０．３９ ０．４０
ｄｃｍ６．１１ ０．９０ ０．６６ ０．２４ ０．６８ ０．７５ ０．２３ ０．１７ ０．７１ ０．７２ ０．６８
ｄｃｍ６．１２ ０．７４ ０．４５ ０．３４ ０．４９ ０．７１ ０．１３ ０．４９ ０．５２ ０．３９ ０．４３
ｄｍｎ３．２ ０．３２ ０．１４ ０．２７ ０．１６ ０．１２ ０．１５ ０．２５ ０．２８ ０．２９ ０．２９
ｄｎｍ１．３ ０．８３ ０．８１ ０．６１ ０．８１ ０．８２ ０．６９ ０．８１ ０．８１ ０．８２ ０．８２
ｄｎｍ１．４ ０．７０ ０．６６ ０．６５ ０．６７ ０．５１ ０．５２ ０．６６ ０．６４ ０．６３ ０．６５
ｈｓｌｎ１３．１１ ０．６８ ０．４８ ０．３５ ０．３９ ０．１６ ０．３８ ０．２６ ０．３５ ０．４９ ０．３６
ｈｓｌｎ１３．１５ ０．８２ ０．５９ ０．４４ ０．６１ ０．６７ ０．４９ ０．５７ ０．６０ ０．５５ ０．６１
ｈｓｌｗ１４．１１ ０．７２ ０．５２ ０．６８ ０．５０ ０．４９ ０．６２ ０．５７ ０．５４ ０．５８ ０．６０
ｊｃｒｎ９．３ ０．６２ ０．５４ ０．４５ ０．５６ ０．１６ ０．３１ ０．１２ ０．７２ ０．５８ ０．５６
ｊｃｒｎ９．７ ０．５４ ０．４９ ０．４５ ０．５２ ０．３９ ０．２５ ０．４９ ０．６６ ０．５４ ０．４９
ｊｃｒｗ１０．３ ０．７１ ０．６８ ０．７６ ０．７５ ０．７８ ０．３８ ０．７３ ０．８０ ０．８１ ０．７５
ｊｃｒｗ１０．７ ０．８１ ０．７０ ０．７０ ０．７０ ０．８１ ０．６４ ０．７１ ０．７７ ０．７９ ０．６９
ｊｃｒｗ１０．１５ ０．７７ ０．６５ ０．６０ ０．６７ ０．７２ ０．６３ ０．６１ ０．６７ ０．６９ ０．６８
ｗｍｈｂｅ１１．１１ ０．６１ ０．３８ ０．４０ ０．４３ ０．２７ ０．５２ ０．４０ ０．４９ ０．４２ ０．４１
ｗｍｈｂｅ１１．１５ ０．６４ ０．５０ ０．３９ ０．４５ ０．６３ ０．４４ ０．４８ ０．４９ ０．４５ ０．４６
ｗｍｈｂｗ１２．１１ ０．６３ ０．５７ ０．５７ ０．７２ ０．５４ ０．５４ ０．５５ ０．６１ ０．５９ ０．５４
ｗｍｈｄ７．１１ ０．５７ ０．６１ ０．５２ ０．６６ ０．７１ ０．２９ ０．６１ ０．６９ ０．６９ ０．６５
ｗｍｈｄ７．１５ ０．６９ ０．６４ ０．５９ ０．６５ ０．６９ ０．４９ ０．５２ ０．６７ ０．６５ ０．６４
ｙｇｎ４．１２ ０．８１ ０．６８ ０．０９ ０．７３ ０．２３ ０．８２ ０．７０ ０．３３ ０．３７ ０．７０
ｙｇｑ５．１０ ０．８４ ０．８５ ０．８７ ０．８６ ０．８７ ０．６４ ０．８６ ０．９０ ０．８８ ０．８７
ｙｇｑ５．１１ ０．７５ ０．７２ ０．０５ ０．７１ ０．２５ ０．１０ ０．６８ ０．６８ ０．７０ ０．７１
ｙｔｗ８．７ ０．５１ ０．０９ ０．２０ ０．２２ ０．１６ ０．２５ ０．２２ ０．２２ ０．１９ ０．１０
表２ ２５个视频上１０个跟踪系统的平均中心位置误差
视频 ＤＬＬ１ ＯＡＢ Ｆｒａｇ Ｓｔｒｕｃｋ Ｌ１ ＴＬＤ ＭＥＥＭ ＬＳＴ ＳＤＧ ＭＩＬ
ｂｗｂ２．２ ４．９ ４．３ ４．０ ５．１ ３．７ ２５．７ ５．３ ３．５ ３．３ ４．５
ｂｗｂ２．３ １５．１ ２１．４ ４０．９ １６．７ ３５．１ ３２．７ ３５．６ ３４．６ ３１．０ ２９．９
ｂｗｂ２．４ １２．５ ８４．７ ９４．３ ８．０ ６．６ ３８．９ ５．８ ２９．１ ７８．３ ９．２
ｄｃｍ６．１１ ４．６ ５．２ ５９．４ ７．５ ５．１ ３５．６ ５４．４ ６．５ ６．６ ４．８
ｄｃｍ６．１２ ６．８ １０．５ １２３．７ ８．５ ８．６ １３７．２ １２．６ ３７．２ ７０．２ １２．６
ｄｍｎ３．２ ２１．５ ５０．５ ２９．４ ５６．５ ５４．９ ４２．５ ２４．８ ２６．４ ２６．７ ２２．０
ｄｎｍ１．３ ３．１ ３．０ １３．４ ３．１ ３．３ ９．０ ４．１ ２．９ ３．３ ３．４
ｄｎｍ１．４ ７．４ ２０．０ ２０．１ １９．５ ２３．８ ２２．４ １７．２ ２０．６ ２１．８ ２０．９
ｈｓｌｎ１３．１１ ３８．２ ４８．０ １８０．６ ５８．６ ２９６．５ １３５．５ ７５．１ ６２．８ ５０．８ ４９．０
ｈｓｌｎ１３．１５ １３．４ ２８．９ １３０．５ １５．６ ３７．５ ９３．５ ３１．０ ３３．４ ３８．１ ２０．８
ｈｓｌｗ１４．１１ ６．８ ２７．４ ５．８ １３．８ １２．５ ８．３ ９．８ １０．２ ９．０ ８．９
ｊｃｒｎ９．３ ２３．８ ３２．０ ４４．８ ２２．１ ８９．４ ２７９．７ １０３．２ ２５．１ ４３．４ ２８．０
ｊｃｒｎ９．７ ６２．３ ３４．８ ５６．１ ２２．２ １０４．４ ２７９．２ ４０．９ ２４．１ ３２．５ ３６．８
ｊｃｒｗ１０．３ １０．５ １５．０ ７．５ ９．１ １０．８ ４０．９ ９．３ ９．８ ７．９ ８．０
ｊｃｒｗ１０．７ ８．０ ８．２ ９．２ ７．５ ８．２ ２６．６ ８．３ ７．１ ６．９ １０．２
ｊｃｒｗ１０．１５ １６．０ １９．１ ３７．３ １４．９ ２３．１ ５４．０ ３８．４ ２１．１ １５．５ １４．７
ｗｍｈｂｅ１１．１１ ６２．３ ５７．８ ４９．８ ２１．０ １７７．７ ３８．２ ３８．２ ２６．６ ４０．９ ２７．７
ｗｍｈｂｅ１１．１５ ３０．５ ２５．２ １０３．４ ５７．８ ５３．２ ２３９．８ ４１．６ ６５．０ ６２．０ ４６．２
ｗｍｈｂｗ１２．１１ ２３．１ ６９．６ ８９．２ １９．２ ２２０．６ ９８．９ ９８．３ ４６．３ ６７．１ ７４．２
ｗｍｈｄ７．１１ ３０．４ ２１．７ ３５．８ １２．１ ２６．３ １１０．０ ２０．３ ２２．０ １９．０ １２．４
ｗｍｈｄ７．１５ １５．１ １３．８ ２０．９ １１．６ ２１．３ ２０５．２ ３０．０ ２０．７ ２１．０ １２．９
ｙｇｎ４．１２ ６．５ １２．６ ３９４．９ １０．１ ２９４．６ ７．２ ９．２ ２１０．１ １８８．１ １２．２
ｙｇｑ５．１０ ３．４ ４．５ ３．４ ３．５ ３．１ １４．８ ３．４ ２．４ ２．８ ３．２
ｙｇｑ５．１１ ５．６ ６．０ １８８．５ ６．８ １６１．１ １６１．２ １０．１ ７．６ ７．９ ６．２
ｙｔｗ８．７ ９．５ ４５．６ １６．７ ３５．３ １７．７ １７．３ １５．０ １７．３ ２０．７ ５２．４
（２）突然运动．ｈｓｌｗ１４．１１中目标在１５帧时由 的效果．视频ｙｇｑ５．１０中，目标斜向横穿马路，姿态
静止突然转身移动，ＯＡＢ算法当即跟丢，Ｓｔｒｕｃｋ、 发生了较大的变化，Ｌ１、Ｆｒａｇ、ＴＬＤ 算法分别在
ＭＥＥＭ和ＬＳＴ算法在１５帧后跟丢，Ｌ１、ＴＬＤ、ＳＤＧ、 ２０帧、２４帧、２５帧时跟丢目标，本文构建的算法可
ＭＩＬ算法在２０帧后出现较大误差，本文的算法与 以一直跟上．
Ｆｒａｇ跟踪系统表现最好． （４）尺度变化．视频ｂｗｂ２．４中，目标从远处骑
（３）姿态变化．ｙｇｎ４．１２中目标骑行转弯，姿态 行到近处，尺度发生了很大的变化，Ｆｒａｇ、ＯＡＢ、
不断变化．Ｆｒａｇ、Ｌ１、ＬＳＴ和ＳＤＧ分别在５帧、１８帧、 ＴＬＤ、ＬＳＴ算法依次跟丢了目标，本文提出的基于
２８帧和３０帧后跟丢目标．本文的方法取得了极好 深度学习的跟踪方法取得了很好的效果． ７期 高君宇等：基于深度学习的鲁棒性视觉跟踪方法 １４２７
图５ １８个视频中１０种方法的逐帧中心位置误差（推荐观看彩色版以获得最佳效果） １４２８ 计 算 机 学 报 ２０１６年 ７期 高君宇等：基于深度学习的鲁棒性视觉跟踪方法 １４２９ １４３０ 计 算 机 学 报 ２０１６年 ７期 高君宇等：基于深度学习的鲁棒性视觉跟踪方法 １４３１
图６ ２５个视频中１０种方法的跟踪结果（推荐观看彩色版以获得最佳效果）
（５）目标初始帧模糊．ｄｍｎ３．２中目标初始帧仅 ＭＥＥＭ、ＴＬＤ相继跟丢目标，本文的跟踪系统获得
为出现在视频边界附近的一小部分模糊的侧身，且 了最佳效果．
ｄｍｎ３．２视频场景复杂，人流巨大．大多数跟踪算法 （８）亮度变化和尺度变化．ｗｍｈｂｅ１１．１５视频中
均在１２帧附近跟丢，本文的算法获得了最好的跟踪 目标从较远的树荫处走到较近的明处．Ｌ１、ＭＥＥＭ、
效果．ｙｔｗ８．７中目标初始帧位于人流量很大场景 Ｆｒａｇ、ＳＤＧ、ＯＡＢ等均在１００帧之后出现较大误差，
中，且初始状态为被严重遮挡，仅露出头部和颈部， 本文的方法具有显著的效果．
最终只有本文的算法可以跟上．这也正体现了本文 （９）遮挡、突然运动和姿态变化．ｗｍｈｂｗ１２．１１
提出的基于深度学习算法的鲁棒性． 中目标在静止一段时间后突然斜向穿越马路，且
（６）遮挡和姿态变化．ｄｎｍ１．４中目标骑行过程 被路旁的汽车严重遮挡．Ｌ１、ＭＥＥＭ、Ｆｒａｇ、ＭＩＬ、
中转了一个较大的弧度，且被附近建筑遮挡，其他方 ＯＡＢ、ＴＬＤ和ＳＤＧ方法均在１０２帧后跟丢．本文的
法均在２０帧后出现了较大的偏差，有的跟踪框不断 方法成功地跟踪了目标，效果仅次于Ｓｔｒｕｃｋ跟踪
变小有的变大． 系统．
（７）遮挡和尺度变化．ｄｃｍ６．１２中目标由远及
近骑行，在１４帧时被行驶的汽车遮挡住了下半身， ５ 结束语
ＴＬＤ算法当即跟丢，Ｆｒａｇ、ＳＤＧ、ＬＳＴ跟踪系统也在
４７帧、６２帧、７０帧时跟丢目标．ｄｃｍ６．１１中，行人由 本文提出了一个新颖的基于深度学习的视觉跟
近及远行走，在４０帧时被其他行人部分遮挡，Ｆｒａｇ、 踪方法，其核心思想是利用固定摄像头下视频场景 １４３２ 计 算 机 学 报 ２０１６年
中一块利于分辨目标的区域构造训练样本，并试图 ［７］ Ｓａｌｔｉ Ｓ，Ｃａｖａｌｌａｒｏ Ａ，Ｄｉ Ｓｔｅｆａｎｏ Ｌ．Ａｄａｐｔｉｖｅ ａｐｐｅａｒａｎｃｅ
学习到一种映射变换模型，将不在参考区域中的样 ｍｏｄｅｌｉｎｇ ｆｏｒ ｖｉｄｅｏ ｔｒａｃｋｉｎｇ：Ｓｕｒｖｅｙ ａｎｄ ｅｖａｌｕａｔｉｏｎ．ＩＥＥＥ
Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｉｍａｇｅ Ｐｒｏｃｅｓｓｉｎｇ，２０１２，２１（１０）：４３３４－４３４８
本映射到参考区域中．由于参考区域具有良好的位
［８］ Ｗｕ Ｙ，Ｌｉｍ Ｊ，Ｙａｎｇ Ｍ－Ｈ．Ｏｎｌｉｎｅ ｏｂｊｅｃｔ ｔｒａｃｋｉｎｇ：Ａ ｂｅｎｃｈｍａｒｋ
置特性，所以训练出的深度网络具有增强目标可识
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１３ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ
别性的特点．该网络可以提高多种传统跟踪系统的 Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｏｒｅｇｏｎ，ＵＳＡ，２０１３：２４１１－
鲁棒性，如Ｌ１跟踪系统．通过实验，本文在２５个行 ２４１８
人目标视频中与其他９种近年来国际上流行的跟踪 ［９］ Ｚｈａｎｇ Ｔ，Ｇｈａｎｅｍ Ｂ，Ａｈｕｊａ Ｎ．Ｒｏｂｕｓｔ ｍｕｌｔｉ－ｏｂｊｅｃｔ ｔｒａｃｋｉｎｇ
系统进行比较，结果显示，本文构建的算法超越了这 ｖｉａ ｃｒｏｓｓ－ｄｏｍａｉｎ ｃｏｎｔｅｘｔｕａｌ ｉｎｆｏｒｍａｔｉｏｎ ｆｏｒ ｓｐｏｒｔｓ ｖｉｄｅｏ ａｎａｌｙｓｉｓ
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１２ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
些已有算法．在后续的工作中，本文将不仅考虑参考
Ａｃｏｕｓｔｉｃｓ，Ｓｐｅｅｃｈ ａｎｄ Ｓｉｇｎａｌ Ｐｒｏｃｅｓｓｉｎｇ．Ｋｙｏｔｏ，Ｊａｐａｎ，
区域中样本和不在参考区域中样本构成的样本对，
２０１２：９８５－９８８
还要考虑以背景作为负样本与目标样本构成样本对 ［１０］ Ｙｕｎ Ｔｉｎｇ－Ｊｉｎ，Ｇｕｏ Ｙｏｎｇ－Ｃａｉ，Ｇａｏ Ｃｈａｏ．Ｈｕｍａｎ ｔｒａｃｋｉｎｇ ｉｎ
进行训练，这样可以更好地增加目标与背景之间的 ｉｎｆｒａｒｅｄ ｉｍａｇｅｓ ｂａｓｅｄ ｏｎ ｐａｒｔｉｃｌｅｓ Ｍｅａｎ－Ｓｈｉｆｔ ｍｉｇｒａｔｉｏｎ
可区分性．另外，利用跨域映射的跟踪思路［４５］，对于 ａｌｇｏｒｉｔｈｍ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，２００９，３２（６）：
出现在不同摄像头的同一样本，可以训练一个基于
１２２２－１２２８（ｉｎ Ｃｈｉｎｅｓｅ）
（云廷进，郭永彩，高潮．基于粒子 Ｍｅａｎ Ｓｈｉｆｔ迁移的红外
多摄像头场景参考区域的统一模型，使得训练好的
人体目标跟踪算法．计算机学报，２００９，３２（６）：１２２２－１２２８）
模型在多摄像头间具有良好的通用性．
［１１］ Ａｖｉｄａｎ Ｓ．Ｅｎｓｅｍｂｌｅ ｔｒａｃｋｉｎｇ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｐａｔｔｅｒｎ
Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２００７，２９（２）：２６１－２７１
致 谢 在此诚挚地感谢北京大学数字视频编解码 ［１２］ Ｂａｂｅｎｋｏ Ｂ，Ｙａｎｇ Ｍ－Ｈ，Ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ ｗｉｔｈ ｏｎｌｉｎｅ ｍｕｌｔｉｐｌｅ
技术国家工程实验室（ＮＥＬＶＴ）提供的ＰＫＵ－ＳＶＤ－ ｉｎｓｔａｎｃｅ ｌｅａｒｎｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２００９ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ
ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｍｉａｍｉ，ＵＳＡ，
Ｂ数据集．并对给本文给出宝贵意见和建议的应龙
２００９：９８３－９９０
师兄等表示感谢！
［１３］ Ｇｒａｂｎｅｒ Ｈ，Ｇｒａｂｎｅｒ Ｍ，Ｂｉｓｃｈｏｆ Ｈ．Ｒｅａｌ－ｔｉｍｅ ｔｒａｃｋｉｎｇ ｖｉａ
ｏｎ－ｌｉｎｅ ｂｏｏｓｔｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｂｒｉｔｉｓｈ Ｍａｃｈｉｎｅ Ｖｉｓｉｏｎ
参 考 文 献 Ｃｏｎｆｅｒｅｎｃｅ．Ｅｄｉｎｂｕｒｇｈ，Ｇｅｒｍａｎｙ，２００６，１（５）：６－１５
［１４］ Ｋａｌａｌ Ｚ，Ｍａｔａｓ Ｊ，Ｍｉｋｏｌａｊｃｚｙｋ Ｋ．Ｐ－Ｎ ｌｅａｒｎｉｎｇ：Ｂｏｏｔｓｔｒａｐ－
［１］ Ｚｈａｎｇ Ｔ，Ｌｉｕ Ｓ，Ｘｕ Ｃ，ｅｔ ａｌ．Ｓｔｒｕｃｔｕｒａｌ ｓｐａｒｓｅ ｔｒａｃｋｉｎｇ／／ ｐｉｎｇ ｂｉｎａｒｙ ｃｌａｓｓｉｆｉｅｒｓ ｂｙ ｓｔｒｕｃｔｕｒａｌ ｃｏｎｓｔｒａｉｎｔｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ
ｏｆ ｔｈｅ ２０１０ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：１５０－１５８ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１０：４９－５６
［２］ Ｈｕａｎｇ Ｋａｉ－Ｑｉ，Ｃｈｅｎ Ｘｉａｏ－Ｔａｎｇ，Ｋａｎｇ Ｙｕｎ－Ｆｅｎｇ，ｅｔ ａｌ． ［１５］ Ｈｕａｎｇ Ｆｕ－Ｚｈｅｎ，Ｓｕ Ｊｉａｎ－Ｂｏ．Ｆａｃｅ ｃｏｎｔｏｕｒ ｅｘｔｒａｃｔｉｏｎ ａｎｄ
Ｉｎｔｅｌｌｉｇｅｎｔ ｖｉｓｕａｌ ｓｕｒｖｅｉｌｌａｎｃｅ：Ａ ｒｅｖｉｅｗ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ ｔｒａｃｋｉｎｇ ｕｓｉｎｇ Ｌｅｖｅｌ Ｓｅｔｓ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，
Ｃｏｍｐｕｔｅｒｓ，２０１５，３８（６）：１０９３－１１１８（ｉｎ Ｃｈｉｎｅｓｅ） ２００３，２６（４）：４９１－４９６（ｉｎ Ｃｈｉｎｅｓｅ）
（黄凯奇，陈晓棠，康运锋等．智能视频监控技术综述．计算 （黄福珍，苏剑波．基于Ｌｅｖｅｌ Ｓｅｔ方法的人脸轮廓提取与跟
机学报，２０１５，３８（６）：１０９３－１１１８） 踪．计算机学报，２００３，２６（４）：４９１－４９６）
［３］ Ｂａｏ Ｃ，Ｗｕ Ｙ，Ｌｉｎｇ Ｈ，ｅｔ ａｌ．Ｒｅａｌ ｔｉｍｅ ｒｏｂｕｓｔ Ｌ１ｔｒａｃｋｅｒ ［１６］ Ｍｅｉ Ｘ，Ｌｉｎｇ Ｈ．Ｒｏｂｕｓｔ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ ｕｓｉｎｇ Ｌ１ｍｉｎｉｍｉｚａｔｉｏｎ
ｕｓｉｎｇ ａｃｃｅｌｅｒａｔｅｄ ｐｒｏｘｉｍａｌ ｇｒａｄｉｅｎｔ ａｐｐｒｏａｃｈ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ １２ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
ｔｈｅ ２０１２ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｋｙｏｔｏ，Ｊａｐａｎ，２００９：１４３６－１４４３
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｒｈｏｄｅ Ｉｓｌａｎｄ，ＵＳＡ，２０１２：１８３０－１８３７ ［１７］ Ａｄａｍ Ａ，Ｒｉｖｌｉｎ Ｅ，Ｓｈｉｍｓｈｏｎｉ Ｉ．Ｒｏｂｕｓｔ ｆｒａｇｍｅｎｔｓ－ｂａｓｅｄ
［４］ Ｆａｎ Ｊ，Ｓｈｅｎ Ｘ，Ｗｕ Ｙ．Ｓｃｒｉｂｂｌｅ ｔｒａｃｋｅｒ：Ａ ｍａｔｔｉｎｇ－ｂａｓｅｄ ｔｒａｃｋｉｎｇ ｕｓｉｎｇ ｔｈｅ ｉｎｔｅｇｒａｌ ｈｉｓｔｏｇｒａｍ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２００６
ａｐｐｒｏａｃｈ ｆｏｒ ｒｏｂｕｓｔ ｔｒａｃｋｉｎｇ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｐａｔｔｅｒｎ ＩＥＥＥ Ｃｏｍｐｕｔｅｒ Ｓｏｃｉｅｔｙ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ
Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０１２，３４（８）：１６３３－１６４４ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２００６：７９８－８０５
［５］ Ｈａｒｅ Ｓ，Ｓａｆｆａｒｉ Ａ，Ｔｏｒｒ Ｐ Ｈ．Ｓｔｒｕｃｋ：Ｓｔｒｕｃｔｕｒｅｄ ｏｕｔｐｕｔ ［１８］Ｊｉａ Ｘ，Ｌｕ Ｈ，Ｙａｎｇ Ｍ－Ｈ．Ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ ｖｉａ ａｄａｐｔｉｖｅ
ｔｒａｃｋｉｎｇ ｗｉｔｈ ｋｅｒｎｅｌｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１１ＩＥＥＥ Ｉｎｔｅｒ－ ｓｔｒｕｃｔｕｒａｌ ｌｏｃａｌ ｓｐａｒｓｅ ａｐｐｅａｒａｎｃｅ ｍｏｄｅｌ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｂａｒｃｅｌｏｎａ，Ｓｐａｉｎ， ２０１２ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
２０１１：２６３－２７０ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｒｈｏｄｅ Ｉｓｌａｎｄ，ＵＳＡ，２０１２：１８２２－１８２９
［６］ Ｋｒｉｓｔａｎ Ｍ，Ｐｆｌｕｇｆｅｌｄｅｒ Ｒ，Ｌｅｏｎａｔｄｉｓ Ａ，ｅｔ ａｌ．Ｔｈｅ ｖｉｓｕａｌ ［１９］ Ｚｈｏｎｇ Ｗ，Ｌｕ Ｈ，Ｙａｎｇ Ｍ－Ｈ．Ｒｏｂｕｓｔ ｏｂｊｅｃｔ ｔｒａｃｋｉｎｇ ｖｉａ
ｏｂｊｅｃｔ ｔｒａｃｋｉｎｇ ＶＯＴ２０１３ｃｈａｌｌｅｎｇｅ ｒｅｓｕｌｔｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｓｐａｒｓｉｔｙ－ｂａｓｅｄ ｃｏｌｌａｂｏｒａｔｉｖｅ ｍｏｄｅｌ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１２
ｔｈｅ ２０１３ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
Ｗｏｒｋｓｈｏｐｓ．Ｓｙｄｎｅｙ，Ａｕｓｔｒａｌｉａ，２０１３：９８－１１１ Ｒｈｏｄｅ Ｉｓｌａｎｄ，ＵＳＡ，２０１２：１８３８－１８４５ ７期 高君宇等：基于深度学习的鲁棒性视觉跟踪方法 １４３３
［２０］ Ｚｈａｎｇ Ｊ，Ｍａ Ｓ，Ｓｃｌａｒｏｆｆ Ｓ．ＭＥＥＭ：Ｒｏｂｕｓｔ ｔｒａｃｋｉｎｇ ｖｉａ Ｃｏｎｆｅｒｅｎｃｅ．Ｎｏｔｔｉｎｇｈａｍ，Ｅｎｇｌａｎｄ，２０１４：１－１１
ｍｕｌｔｉｐｌｅ ｅｘｐｅｒｔｓ ｕｓｉｎｇ ｅｎｔｒｏｐｙ ｍｉｎｉｍｉｚａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ［３３］ Ｈｏｎｇ Ｓ，Ｙｏｕ Ｔ，Ｋｗａｋ Ｓ，ｅｔ ａｌ．Ｏｎｌｉｎｅ ｔｒａｃｋｉｎｇ ｂｙ ｌｅａｒｎｉｎｇ
ｔｈｅ ２０１４Ｅｕｒｏｐｅａｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｚｕｒｉｃｈ， ｄｉｓｃｒｉｍｉｎａｔｉｖｅ ｓａｌｉｅｎｃｙ ｍａｐ ｗｉｔｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ
Ｓｗｉｔｚｅｒｌａｎｄ，２０１４：１８８－２０３ ｎｅｔｗｏｒｋ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１５０２０６７９６，２０１５
［２１］ Ｘｉａｏ Ｇｕｏ－Ｑｉａｎｇ，Ｋａｎｇ Ｑｉｎ，Ｊｉａｎｇ Ｊｉａｎ－Ｍｉｎ，ｅｔ ａｌ．Ｔｒａｃｋｉｎｇ ［３４］ Ｗａｎｇ Ｎ，Ｌｉ Ｓ，Ｇｕｐｔａ Ａ，ｅｔ ａｌ．Ｔｒａｎｓｆｅｒｒｉｎｇ ｒｉｃｈ ｆｅａｔｕｒｅ
ｖｉｄｅｏ ｏｂｊｅｃｔ ｂａｓｅｄ ｏｎ ｃｅｎｔｒａｌ ｍａｃｒｏｂｌｏｃｋｓ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ ｈｉｅｒａｒｃｈｉｅｓ ｆｏｒ ｒｏｂｕｓｔ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：
Ｃｏｍｐｕｔｅｒｓ，２０１１，３４（９）：１７１２－１７１８（ｉｎ Ｃｈｉｎｅｓｅ） １５０１０４５８７，２０１５
（肖国强，康勤，江健民等．基于中心宏块的视频目标跟踪算 ［３５］ Ｃｈｅｎ Ｙ，Ｙａｎｇ Ｘ，Ｚｈｏｎｇ Ｂ，ｅｔ ａｌ．ＣＮＮＴｒａｃｋｅｒ：Ｏｎｌｉｎｅ
法．计算机学报，２０１１，３４（９）：１７１２－１７１８）
ｄｉｓｃｒｉｍｉｎａｔｉｖｅ ｏｂｊｅｃｔ ｔｒａｃｋｉｎｇ ｖｉａ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ
［２２］ Ｚｈａｎｇ Ｔ，Ｇｈａｎｅｍ Ｂ，Ｌｉｕ Ｓ，ｅｔ ａｌ．Ｒｏｂｕｓｔ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ ｖｉａ ｎｅｔｗｏｒｋ．Ａｐｐｌｉｅｄ Ｓｏｆｔ Ｃｏｍｐｕｔｉｎｇ，２０１５，３８（６）：１０８８－１０９８
ｍｕｌｔｉ－ｔａｓｋ ｓｐａｒｓｅ ｌｅａｒｎｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１２ＩＥＥＥ ［３６］ Ｈｕ Ｄ，Ｚｈｏｕ Ｘ，Ｗｕ Ｊ．Ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ ｂａｓｅｄ ｏｎ ｃｏｎｖｏｌｕｔｉｏｎａｌ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ． ｄｅｅｐ ｂｅｌｉｅｆ ｎｅｔｗｏｒｋ／／Ｃｈｅｎ Ｙｕｎｊｉ，Ｉｅｎｎｅ Ｐ，Ｊｉ Ｑｉｎｇ ｅｄｓ．
Ｒｈｏｄｅ Ｉｓｌａｎｄ，ＵＳＡ，２０１２：２０４２－２０４９
Ａｄｖａｎｃｅｄ Ｐａｒａｌｌｅｌ Ｐｒｏｃｅｓｓｉｎｇ Ｔｅｃｈｎｏｌｏｇｉｅｓ．Ｓｐｒｉｎｇｅｒ Ｉｎｔｅｒ－
［２３］ Ｚｈａｎｇ Ｔ，Ｇｈａｎｅｍ Ｂ，Ｌｉｕ Ｓ，ｅｔ ａｌ．Ｌｏｗ－ｒａｎｋ ｓｐａｒｓｅ ｌｅａｒｎｉｎｇ ｎａｔｉｏｎａｌ Ｐｕｂｌｉｓｈｉｎｇ，２０１５：１０３－１１５
ｆｏｒ ｒｏｂｕｓｔ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１２Ｅｕｒｏｐｅａｎ ［３７］ Ｚｈａｎｇ Ｋ，Ｌｉｕ Ｑ，Ｗｕ Ｙ，ｅｔ ａｌ．Ｒｏｂｕｓｔ ｔｒａｃｋｉｎｇ ｖｉａ ｃｏｎｖｏｌｕ－
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｆｉｒｅｎｚｅ，Ｉｔａｌｙ，２０１２：４７０－
ｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｗｉｔｈｏｕｔ ｌｅａｒｎｉｎｇ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：
４８４
１５０１０４５０５，２０１５
［２４］ Ｚｈａｎｇ Ｔ，Ｇｈａｎｅｍ Ｂ，Ｌｉｕ Ｓ，ｅｔ ａｌ．Ｒｏｂｕｓｔ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ ｖｉａ
［３８］ Ｋｕｅｎ Ｊ，Ｌｉｍ Ｋ Ｍ，Ｌｅｅ Ｃ Ｐ．Ｓｅｌｆ－ｔａｕｇｈｔ ｌｅａｒｎｉｎｇ ｏｆ ａ ｄｅｅｐ
ｓｔｒｕｃｔｕｒｅｄ ｍｕｌｔｉ－ｔａｓｋ ｓｐａｒｓｅ ｌｅａｒｎｉｎｇ．Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｕｒｎａｌ
ｉｎｖａｒｉａｎｔ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｆｏｒ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ ｖｉａ ｔｅｍｐｏｒａｌ
ｏｆ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ，２０１３，１０１（２）：３６７－３８３
ｓｌｏｗｎｅｓｓ ｐｒｉｎｃｉｐｌｅ．Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ，２０１５，４８（１０）：
［２５］ Ｚｈａｎｇ Ｔ，Ｌｉｕ Ｓ，Ａｈｕｊａ Ｎ，ｅｔ ａｌ．Ｒｏｂｕｓｔ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ ｖｉａ
２９６４－２９８２
ｃｏｎｓｉｓｔｅｎｔ ｌｏｗ－ｒａｎｋ ｓｐａｒｓｅ ｌｅａｒｎｉｎｇ．Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｕｒｎａｌ ｏｆ
［３９］ Ｄｏｕｌａｍｉｓ Ｎ，Ｄｏｕｌａｍｉｓ Ａ．Ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆｏｒ
Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ，２０１４，１１１（２）：１７１－１９０
ｏｂｊｅｃｔ ｔｒａｃｋｉｎｇ ａｎｄ ｃｌａｓｓｉｆｉｃａｔｉｏｎ／／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１４
［２６］ Ｗａｎｇ Ｙｕ－Ｘｉａ，Ｚｈａｏ Ｑｉｎｇ－Ｊｉｅ，Ｃａｉ Ｙｉ－Ｍｉｎｇ，ｅｔ ａｌ．Ｔｒａｃｋｉｎｇ
ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｍａｇｅ Ｐｒｏｃｅｓｓｉｎｇ．Ｐａｉｒｓ，
ｂｙ ａｕｔｏ－ｒｅｃｏｎｓｔｒｕｃｔｉｎｇ ｐａｒｔｉｃｌｅ ｆｉｌｔｅｒ ｔｒａｃｋｅｒｓ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ
Ｆｒａｎｃｅ，２０１４：８４８－８５２
ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１６，３９（７）：１２９４－１３０６（ｉｎ Ｃｈｉｎｅｓｅ）
［４０］ Ｋａｒｐａｔｈｙ Ａ，Ｔｏｄｅｒｉｃｉ Ｇ，Ｓｈｅｔｔｙ Ｓ，ｅｔ ａｌ．Ｌａｒｇｅ－ｓｃａｌｅ ｖｉｄｅｏ
（王宇霞，赵清杰，蔡艺明等．基于自重构粒子滤波算法的目
ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｗｉｔｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
标跟踪．计算机学报，２０１６，３９（７）：１２９４－１３０６）
ｏｆ ｔｈｅ ２０１４ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
［２７］ Ｗａｎｇ Ｎ，Ｙｅｕｎｇ Ｄ－Ｙ．Ｌｅａｒｎｉｎｇ ａ ｄｅｅｐ ｃｏｍｐａｃｔ ｉｍａｇｅ
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４：１７２５－１７３２
ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｆｏｒ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１３
［４１］ Ｓｅｒｒｅ Ｔ，Ｒｉｅｓｅｎｈｕｂｅｒ Ｍ，Ｌｏｕｉｅ Ｊ，ｅｔ ａｌ．Ｏｎ ｔｈｅ ｒｏｌｅ ｏｆ
Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｈａｒｒａｈｓ
ｏｂｊｅｃｔ－ｓｐｅｃｉｆｉｃ ｆｅａｔｕｒｅｓ ｆｏｒ ｒｅａｌ ｗｏｒｌｄ ｏｂｊｅｃｔ ｒｅｃｏｇｎｉｔｉｏｎ ｉｎ
ａｎｄ Ｈａｒｖｅｙｓ，Ｌａｋｅ Ｔａｈｏｅ，２０１３：８０９－８１７
［２８］ Ｆａｎ Ｊ，Ｘｕ Ｗ，Ｗｕ Ｙ，ｅｔ ａｌ．Ｈｕｍａｎ ｔｒａｃｋｉｎｇ ｕｓｉｎｇ ｃｏｎｖｏｌｕ－
ｂｉｏｌｏｇｉｃａｌ ｖｉｓｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｂｉｏｌｏｇｉｃａｌｌｙ Ｍｏｔｉｖａｔｅｄ
Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｔüｂｉｎｇｅｎ，Ｇｅｒｍａｎｙ，２００２：３８７－３９７
ｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｎｅｕｒａｌ
Ｎｅｔｗｏｒｋｓ，２０１０，２１（１０）：１６１０－１６２３ ［４２］ Ｍｅｉ Ｘ，Ｌｉｎｇ Ｈ，Ｗｕ Ｙ，ｅｔ ａｌ．Ｍｉｎｉｍｕｍ ｅｒｒｏｒ ｂｏｕｎｄｅｄ
［２９］ Ｚｈｏｕ Ｘ，Ｘｉｅ Ｌ，Ｚｈａｎｇ Ｐ，ｅｔ ａｌ．Ａｎ ｅｎｓｅｍｂｌｅ ｏｆ ｄｅｅｐ ｎｅｕｒａｌ ｅｆｆｉｃｉｅｎｔ１ｔｒａｃｋｅｒ ｗｉｔｈ ｏｃｃｌｕｓｉｏｎ ｄｅｔｅｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
ｎｅｔｗｏｒｋｓ ｆｏｒ ｏｂｊｅｃｔ ｔｒａｃｋｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１４ＩＥＥＥ ｔｈｅ ２０１１ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｍａｇｅ Ｐｒｏｃｅｓｓｉｎｇ．Ｐａｉｒｓ，Ｆｒａｎｃｅ， Ｒｅｃｏｇｎｉｔｉｏｎ．Ｃｏｌｏｒａｄｏ Ｓｐｒｉｎｇｓ，ＵＳＡ，２０１１：１２５７－１２６４
２０１４：８４３－８４７ ［４３］Ｊｉａ Ｙ，Ｓｈｅｌｈａｍｅｒ Ｅ，Ｄｏｎａｈｕｅ Ｊ，ｅｔ ａｌ．Ｃａｆｆｅ：Ｃｏｎｖｏｌｕｔｉｏｎａｌ
［３０］ Ｌｉ Ｈ，Ｌｉ Ｙ，Ｐｏｒｉｋｌｉ Ｆ．Ｒｏｂｕｓｔ ｏｎｌｉｎｅ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ ｗｉｔｈ ａ ａｒｃｈｉｔｅｃｔｕｒｅ ｆｏｒ ｆａｓｔ ｆｅａｔｕｒｅ ｅｍｂｅｄｄｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｓｉｎｇｌｅ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１４ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍｕｌｔｉｍｅｄｉａ．Ｏｒｌａｎｄｏ，
Ａｓｉａｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｓｉｎｇａｐｏｒｅ，２０１５： ＵＳＡ，２０１４：６７５－６７８
１９４－２０９ ［４４］ Ｅｖｅｒｉｎｇｈａｍ Ｍ，Ｖａｎ Ｇｏｏｌ Ｌ，Ｗｉｌｌｉａｍｓ Ｃ Ｋ，ｅｔ ａｌ．Ｔｈｅ
［３１］ Ｌｉ Ｈ，Ｌｉ Ｙ，Ｐｏｒｉｋｌｉ Ｆ．ＤｅｅｐＴｒａｃｋ：Ｌｅａｒｎｉｎｇ ｄｉｓｃｒｉｍｉｎａｔｉｖｅ ｐａｓｃａｌ ｖｉｓｕａｌ ｏｂｊｅｃｔ ｃｌａｓｓｅｓ（ＶＯＣ）ｃｈａｌｌｅｎｇｅ．Ｉｎｔｅｒｎａｔｉｏｎａｌ
ｆｅａｔｕｒｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｏｎｌｉｎｅ ｆｏｒ ｒｏｂｕｓｔ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ． Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ，２０１０，８８（２）：３０３－３３８
ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１５０３０００７２，２０１５ ［４５］ Ｚｈａｎｇ Ｔ，Ｘｕ Ｃ．Ｃｒｏｓｓ－ｄｏｍａｉｎ ｍｕｌｔｉ－ｅｖｅｎｔ ｔｒａｃｋｉｎｇ ｖｉａ
［３２］ Ｌｉ Ｈ，Ｌｉ Ｙ，Ｐｏｒｉｋｌｉ Ｆ．ＤｅｅｐＴｒａｃｋ：Ｌｅａｒｎｉｎｇ ｄｉｓｃｒｉｍｉｎａｔｉｖｅ ＣＯ－ＰＭＨＴ．ＡＣＭ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｍｕｌｔｉｍｅｄｉａ Ｃｏｍｐｕｔｉｎｇ，
ｆｅａｔｕｒｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｂｙ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ，ａｎｄ Ａｐｐｌｉｃａｔｉｏｎｓ（ＴＯＭＭ），２０１４，１０（４）：
ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｂｒｉｔｉｓｈ Ｍａｃｈｉｎｅ Ｖｉｓｉｏｎ ３１－４２ １４３４ 计 算 机 学 报 ２０１６年
ＧＡＯ Ｊｕｎ－Ｙｕ，ｂｏｒｎ ｉｎ １９９４，Ｐｈ．Ｄ． ＹＡＮＧ Ｘｉａｏ－Ｓｈａｎ，ｂｏｒｎ ｉｎ １９８９，Ｐｈ．Ｄ．ｃａｎｄｉｄａｔｅ．Ｈｉｓ
ｃａｎｄｉｄａｔｅ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｒｅｃｏｇｎｉｔｉｏｎ／ｒａｎｋｉｎｇ ｏｆ ｉｍａｇｅ ａｎｄ
ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ ａｎｄ ｍｕｌｔｉｍｅｄｉａ． ｖｉｄｅｏ，ｄｅｅｐ ｌｅａｒｎｉｎｇ．
ＺＨＡＮＧ Ｔｉａｎ－Ｚｈｕ，ｂｏｒｎ ｉｎ １９８２，Ｐｈ．Ｄ．，ａｓｓｏｃｉａｔｅ
ｐｒｏｆｅｓｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ ａｎｄ
ｍｕｌｔｉｍｅｄｉａ．
ＸＵ Ｃｈａｎｇ－Ｓｈｅｎｇ，ｂｏｒｎ ｉｎ １９６９，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ．Ｈｉｓ
ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｍｕｌｔｉｍｅｄｉａ ｃｏｎｔｅｎｔ ａｎａｌｙｓｉｓ／
ｉｎｄｅｘｉｎｇ／ｒｅｔｒｉｅｖａｌ，ｐａｔｔｅｒｎ ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ．
Ｂａｃｋｇｒｏｕｎｄ
Ｔｈｅ ｐａｓｔ ｆｅｗ ｙｅａｒｓ ｈａｖｅ ｂｅｅｎ ｓｏ ｉｎｓｐｉｒｉｎｇ ｉｎ ｔｈｅ ｈｉｓｔｏｒｙ ｅｒｒｏｒ．Ａｌｔｈｏｕｇｈ ｔｈｅｓｅ ｍｅｔｈｏｄｓ ｈａｖｅ ｓｏｍｅ ａｄｖａｎｔａｇｅｓ ｉｎ
ｏｆ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ．Ｌａｒｇｅ ａｍｏｕｎｔｓ ｏｆ ｌｉｔｅｒａｔｕｒｅｓ ｈａｖｅ ｂｅｅｎ ｃｅｒｔａｉｎ ｖｉｄｅｏ ｓｃｅｎｅｓ，ｍｏｓｔ ｏｆ ｔｈｅｍ ｕｓｅ ｔｈｅ ｐｉｘｅｌｓ ｏｆ ｅａｃｈ
ｐｕｂｌｉｓｈｅｄ ｗｈｅｎ ｕｔｉｌｉｚｉｎｇ ｔｈｅ ｂｉｏｌｏｇｉｃａｌｌｙ－ｉｎｓｐｉｒｅｄ Ｃｏｎｖｏｌｕ－ ｖｉｄｅｏ ｓｅｑｕｅｎｃｅ ｄｉｒｅｃｔｌｙ，ｉｇｎｏｒｉｎｇ ｔｈｏｓｅ ｉｍａｇｅ ｐａｔｃｈｅｓ’ｉｎｎｅｒ
ｔｉｏｎａｌ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ（ＣＮＮ）ｔｏ ｓｏｍｅ ｈａｒｄ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ ｄｅｅｐ ｆｅａｔｕｒｅｓ．Ａｎｄ ｗｅ ｔｈｉｎｋ ｔｈｅｓｅ ｔｒａｃｋｅｒｓ ａｒｅ ｐｒｏｍｉｓｉｎｇ ｆｏｒ
ｐｒｏｂｌｅｍｓ，ｓｕｃｈ ａｓ ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ ａｎｄ ｉｍａｇｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｂｅｔｔｅｒ ｔｒａｃｋｉｎｇ ａｃｃｕｒａｃｙ ｗｈｅｎ ｔｈｅｙ ｕｓｅ ｔｈｅ ｄｅｅｐ ｆｅａｔｕｒｅ．Ｏｕｒ
ｐｒｏｂｌｅｍｓ．Ｎｅｖｅｒｔｈｅｌｅｓｓ，ｔｈｅｒｅ ａｒｅ ｓｔｉｌｌ ｓｏｍｅ ｏｔｈｅｒ ｃｏｍｐｕｔｅｒ ａｐｐｒｏａｃｈ ｄｅｓｉｇｎｓ ａ ｎｏｖｅｌ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒｏｎ ｎｅｔｗｏｒｋ
ｖｉｓｉｏｎ ｔａｓｋｓ ｌｏｎｇｉｎｇ ｆｏｒ ｂｅｔｔｅｒ ｓｏｌｕｔｉｏｎｓ，ｓｕｃｈ ａｓ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ． ｗｈｉｃｈ ｈａｓ ｔｗｏ ｓｙｍｍｅｔｒｉｃａｌ ｐａｔｈｓ ｓｈａｒｅｄ ｗｅｉｇｈｔｓ．Ｔｈｉｓ ｗｉｌｌ
Ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ ｉｓ ｏｎｅ ｏｆ ｔｈｅ ｍｏｓｔ ｉｍｐｏｒｔａｎｔ ｄｏｍａｉｎ ｉｎ ａ ｅｎｈａｎｃｅ ｔｈｅ ａｐｐｅａｒａｎｃｅ ｆｅａｔｕｒｅ ｏｆ ｔａｒｇｅｔｓ，ｔｈｅｎ ａｃｈｉｅｖｅｓ
ｗｉｄｅ ｒａｎｇｅ ｏｆ ａｐｐｌｉｃａｔｉｏｎｓ ｉｎ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ，ｓｕｃｈ ａｓ ｈｕｍａｎ ｂｅｔｔｅｒ ｒｅｓｕｌｔｓ．
ｃｏｍｐｕｔｅｒ ｉｎｔｅｒａｃｔｉｏｎ，ｒｏｂｏｔｉｃｓ，ｓｕｒｖｅｉｌｌａｎｃｅ ａｎｄ ｖｅｈｉｃｌｅ Ｔｈｉｓ ｒｅｓｅａｒｃｈ ｇｒｏｕｐ ｈａｓ ｓｏｍｅ ａｃｈｉｅｖｅｍｅｎｔ ａｂｏｕｔ ｄｅｅｐ
ｔｒａｃｋｉｎｇ，ｅｔｃ．Ａｌｔｈｏｕｇｈ ｔｈｅ ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ ｉｎ ｌｅａｒｎｉｎｇ ａｎｄ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ ｉｎ ｔｈｅ ｐａｓｔ ｆｅｗ ｙｅａｒｓ．Ｚｈａｎｇ
ｔｈｅｓｅ ｙｅａｒｓ，ｔｈｅｒｅ ａｒｅ ｎｏ ｕｎｉｆｉｅｄ ｔｈｅｏｒｙ ｓｙｓｔｅｍ ｆｒａｍｅ．Ｍｏｓｔ Ｔｉａｎｚｈｕ ｅｌ ａｌ．ｐｕｂｌｉｓｈｅｄ ｐａｐｅｒｓ ｏｎ ＣＶＰＲ ｉｎ ２０１３ａｎｄ ２０１４，
ｔｒａｃｋｅｒｓ ａｒｅ ｄｅｖｅｌｏｐｅｄ ｆｒｏｍ ｔｈｅ ｄｉｓｃｒｉｍｉｎａｔｉｖｅ ｏｒ ｇｅｎｅｒａｔｉｖｅ ｗｈｉｃｈ ｆｏｃｕｓ ｏｎ ｒｏｂｕｓｔ ｖｉｓｕａｌ ｔｒａｃｋｉｎｇ．Ｙａｎｇ Ｘｉａｏｓｈａｎ ｅｔ ａｌ．
ｐｅｒｓｐｅｃｔｉｖｅｓ．Ｄｉｓｃｒｉｍｉｎａｔｉｖｅ ａｐｐｒｏａｃｈｅｓ ｆｏｒｍｕｌａｔｅ ｔｈｅ ｔｒａｃｋｉｎｇ ｄｅｖｏｔｅ ｔｏ ｉｍａｇｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｕｓｉｎｇ ｄｅｅｐ ｌｅａｒｎｉｎｇ，ａｎｄ ｐｕｂｌｉｓｈｅｄ
ｐｒｏｂｌｅｍ ａｓ ａ ｂｉｎａｒｙ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｐｒｏｂｌｅｍ ｉｎ ｏｒｄｅｒ ｔｏ ｆｉｎｄ ｔｈｅ ｐａｐｅｒｓ ｏｎ Ｍｕｌｔｉｍｅｄｉａ Ｓｙｓｔ，２０１５ａｎｄ ＩＣＩＭＣＳ，２０１３．
ｄｅｃｉｓｉｏｎ ｂｏｕｎｄａｒｙ ｆｏｒ ｓｅｐａｒａｔｉｎｇ ｔｈｅ ｔａｒｇｅｔ ｏｂｊｅｃｔ ｆｒｏｍ ｔｈｅ Ｔｈｉｓ ｗｏｒｋ ｉｓ ｓｕｐｐｏｒｔｅｄ ｉｎ ｐａｒｔ ｂｙ ｔｈｅ Ｎａｔｉｏｎａｌ Ｂａｓｉｃ
ｂａｃｋｇｒｏｕｎｄ．Ａｎｄ ｉｎ ｃｏｎｔｒａｓｔ，ｇｅｎｅｒａｔｉｖｅ ｔｒａｃｋｅｒｓ ｔｙｐｉｃａｌｌｙ Ｒｅｓｅａｒｃｈ Ｐｒｏｇｒａｍ（９７３Ｐｒｏｇｒａｍ）ｏｆ Ｃｈｉｎａ（Ｎｏ．２０１２ＣＢ３１６３０４）
ｌｅａｒｎ ａ ｍｏｄｅｌ ｔｏ ｒｅｐｒｅｓｅｎｔ ｔｈｅ ｔａｒｇｅｔ ｏｂｊｅｃｔ ａｎｄ ｔｈｅｎ ｕｓｅ ｉｔ ｔｏ ａｎｄ ｔｈｅ Ｎａｔｉｏｎａｌ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｃｈｉｎａ（Ｋｅｙ
ｓｅａｒｃｈ ｆｏｒ ｔｈｅ ｆｒａｍｅ ｒｅｇｉｏｎ ｗｉｔｈ ｍｉｎｉｍａｌ ｒｅｃｏｎｓｔｒｕｃｔｉｏｎ Ｐｒｏｇｒａｍ，６１４３２０１９）． --------------------------------------------------------------------------------- 第４２卷 第６期 计 算 机 学 报 Ｖｏｌ．４２ Ｎｏ．６
２０１９年６月 ＣＨＩＮＥＳＥ ＪＯＵＲＮＡＬ ＯＦ ＣＯＭＰＵＴＥＲＳ Ｊｕｎｅ ２０１９
基于用户评论的深度情感分析和多视图协同融合的
混合推荐方法
张宜浩１） 朱小飞２） 徐传运１） 董世都１）
１）（重庆理工大学两江人工智能学院 重庆 ４０００５４）
２）（重庆理工大学计算机科学与工程学院 重庆 ４０００５４）
摘 要 目前，大多数推荐技术使用用户评分来推断用户偏好．当有充足的评分信息时，协同过滤技术表现良好．
然而，评分数据普遍存在着稀疏性，或者难以让用户将其偏好表示为对物品的评分等级，故有效性受到限制．基于
内容的推荐方法依据物品的内容来寻找与目标用户喜欢的物品内容相似的物品．在目标用户没有充足的历史数据
的情况下，该方法仍然不充分，其推荐效果也很有限．当前，融合多视图的兴趣偏好信息构建混合推荐系统是个性
化推荐研究发展的趋势．混合推荐系统通过融合用户物品的交互评分、隐式反馈和辅助信息进行个性化推荐，故本
文提出了一种新颖的基于用户评论的深度情感分析和多视图协同融合的混合推荐方法．针对用户评论、物品内容
描述等短文本的情感及语义难以分析，单一推荐视图易导致对用户画像建模粗放等问题，本文利用词向量对用户
评论的短文本进行分布式表征，并结合长短期记忆网络实现从上下文语义层面对用户评论的情感进行分析．同时，
本文提出基于观点预过滤和基于用户评分嵌入的情感融合方法，设计了一种嵌入的网络结构对用户评论进行深层
语义分析和情感计算，以解决用户评分与真实兴趣偏好存在较大偏差、评分等级分布极度不均衡等问题．此外，本
文利用分布式的段落向量表征对物品内容描述的短文本进行相似度计算，并设计了候选物品相似性的计算方法及
度量Ｋ个最近邻物品的方法，解决了推荐系统中物品的内容信息不易挖掘和利用的问题．最后，本文提出了一种基
于协同训练的融合用户评分、情感倾向和物品内容信息的混合推荐算法，实现对稀疏的用户评分矩阵的循环填充
和修正，进而实现基于评分预测的ＴｏｐＮ推荐．该方法解决了混合推荐系统中不同兴趣偏好的多推荐视图难以融
合的问题，同时在一定程度上解决了推荐系统建模中缺乏足够的有标签数据问题．本文在亚马逊数据集上进行实
验，与多种经典的和当前先进的推荐算法进行性能对比，采用平方误差、命中率和标准化折扣累积增益进行性能评
价．实验结果表明，本文提出的算法在挖掘用户情感上效果显著；在１０个推荐数据集上，系统的评分预测和ＴｏｐＮ
推荐指标皆有不同程度的显著改进．
关键词 混合推荐；分布式表征；情感分析；协同训练；评分矩阵
中图法分类号 ＴＰ３９１ ＤＯＩ号 １０．１１８９７／ＳＰ．Ｊ．１０１６．２０１９．０１３１６
Ｈｙｂｒｉｄ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ Ａｐｐｒｏａｃｈ Ｂａｓｅｄ ｏｎ Ｄｅｅｐ Ｓｅｎｔｉｍｅｎｔ Ａｎａｌｙｓｉｓ ｏｆ
Ｕｓｅｒ Ｒｅｖｉｅｗｓ ａｎｄ Ｍｕｌｔｉ－Ｖｉｅｗ Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｆｕｓｉｏｎ
ＺＨＡＮＧ Ｙｉ－Ｈａｏ１） ＺＨＵ Ｘｉａｏ－Ｆｅｉ ２） ＸＵ Ｃｈｕａｎ－Ｙｕｎ１） ＤＯＮＧ Ｓｈｉ－Ｄｕ１）
１）（Ｓｃｈｏｏｌ ｏｆ Ｌｉａｎｇｊｉａｎｇ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ，Ｃｈｏｎｇｑｉｎｇ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｔｅｃｈｎｏｌｏｇｙ，Ｃｈｏｎｇｑｉｎｇ ４０００５４）
２）（Ｃｏｌｌｅｇｅ ｏｆ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ ａｎｄ Ｅｎｇｉｎｅｅｒｉｎｇ，Ｃｈｏｎｇｑｉｎｇ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｔｅｃｈｎｏｌｏｇｙ，Ｃｈｏｎｇｑｉｎｇ ４０００５４）
Ａｂｓｔｒａｃｔ Ｃｕｒｒｅｎｔｌｙ，ｍｏｓｔ ｒｅｃｏｍｍｅｎｄｅｒ ｔｅｃｈｎｉｑｕｅｓ ｕｓｅ ｕｓｅｒ ｒａｔｉｎｇｓ ｔｏ ｉｎｆｅｒ ｕｓｅｒ ｐｒｅｆｅｒｅｎｃｅｓ．
Ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｔｅｃｈｎｉｑｕｅｓ ｐｅｒｆｏｒｍ ｗｅｌｌ ｗｈｅｎ ｔｈｅｒｅ ｉｓ ｓｕｆｆｉｃｉｅｎｔ ｒａｔｉｎｇ ｉｎｆｏｒｍａｔｉｏｎ．Ｈｏｗｅｖｅｒ，
ｔｈｅｉｒ ｅｆｆｅｃｔｉｖｅｎｅｓｓ ｉｓ ｌｉｍｉｔｅｄ ｂｅｃａｕｓｅ ｏｆ ｔｈｅ ｒａｔｉｎｇ ｓｐａｒｓｉｔｙ ｐｒｏｂｌｅｍ，ｏｒ ｔｈｅ ｄｉｆｆｉｃｕｌｔｙ ｉｎ ｌｅｔｔｉｎｇ
收稿日期：２０１８－０５－２０；在线出版日期：２０１９－０３－０５．本课题得到国家自然科学基金（６１７０２０６３）、重庆市基础科学与前沿技术研究重点专项
（ｃｓｔｃ２０１７ｊｃｙｊＢＸ００５９）资助．张宜浩，博士，副教授，中国计算机学会（ＣＣＦ）会员，主要研究方向为推荐系统、机器学习、自然语言处理．
Ｅ－ｍａｉｌ：ｙｈｚｈａｎｇ＠ｃｑｕｔ．ｅｄｕ．ｃｎ．朱小飞，博士，教授，中国计算机学会（ＣＣＦ）会员，主要研究领域为大数据搜索与推荐、Ｗｅｂ挖掘、机器学
习．徐传运，博士，副教授，中国计算机学会（ＣＣＦ）会员，主要研究方向为机器学习、图像处理．董世都，博士，副教授，中国计算机学会
（ＣＣＦ）会员，主要研究方向为机器学习、图像处理． ６期 张宜浩等：基于用户评论的深度情感分析和多视图协同融合的混合推荐方法 １３１７
ｕｓｅｒｓ ｅｘｐｒｅｓｓ ｔｈｅｉｒ ｐｒｅｆｅｒｅｎｃｅｓ ａｓ ｓｃａｌａｒ ｒａｔｉｎｇｓ ｏｎ ｉｔｅｍｓ．Ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ｍｅｔｈｏｄｓ
ｒｅｌｙ ｉｎｓｔｅａｄ ｏｎ ｔｈｅ ｃｏｎｔｅｎｔ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｏｆ ｉｔｅｍｓ ｔｏ ｌｏｃａｔｅ ｉｔｅｍｓ ｔｈａｔ ｈａｖｅ ｓｉｍｉｌａｒ ｃｏｎｔｅｎｔ ｔｏ
ｉｔｅｍｓ ｔｈｅ ｔａｒｇｅｔ ｕｓｅｒ ｌｉｋｅｄ．Ｈｏｗｅｖｅｒ，ｔｈｅｓｅ ｍｅｔｈｏｄｓ ａｒｅ ｓｔｉｌｌ ｉｎａｄｅｑｕａｔｅ ａｎｄ ｉｔｓ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ
ｅｆｆｅｃｔ ｉｓ ｌｉｍｉｔｅｄ，ｅｓｐｅｃｉａｌｌｙ ｗｈｅｎ ｔｈｅ ｔａｒｇｅｔ ｕｓｅｒ ｈａｓ ｌｉｔｔｌｅ ｈｉｓｔｏｒｉｃａｌ ｄａｔａ．Ａｔ ｐｒｅｓｅｎｔ，ｉｔ ｉｓ ａ ｒｅｃｅｎｔ
ｄｅｖｅｌｏｐｍｅｎｔ ｔｒｅｎｄ ｔｏ ｄｏ ｐｅｒｓｏｎａｌｉｚｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｔｈｒｏｕｇｈ ｆｕｓｉｎｇ ｍｕｌｔｉ－ｖｉｅｗ ｏｆ ｉｎｔｅｒｅｓｔ
ｐｒｅｆｅｒｅｎｃｅｓ ｔｏ ｂｕｉｌｄ ｔｈｅ ｈｙｂｒｉｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｏｄｅｌ，ｗｈｉｃｈ ｕｓｕａｌｌｙ ｍａｋｅｓ ｐｅｒｓｏｎａｌｉｚｅｄ ｒｅｃｏｍ－
ｍｅｎｄａｔｉｏｎ ｗｉｔｈ ｕｓｅｒ－ｉｔｅｍ ｉｎｔｅｒａｃｔｉｏｎ ｒａｔｉｎｇｓ，ｉｍｐｌｉｃｉｔ ｆｅｅｄｂａｃｋ ａｎｄ ａｕｘｉｌｉａｒｙ ｉｎｆｏｒｍａｔｉｏｎ ｉｎ ｈｙｂｒｉｄ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ．Ｉｎ ｔｈｉｓ ｐａｐｅｒ，ａ ｎｏｖｅｌ ｈｙｂｒｉｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｌｇｏｒｉｔｈｍ ｉｓ ｐｒｏｐｏｓｅｄ
ｔｈａｔ ｂａｓｅｄ ｏｎ ｄｅｅｐ ｓｅｎｔｉｍｅｎｔ ａｎａｌｙｓｉｓ ｏｆ ｕｓｅｒ ｒｅｖｉｅｗｓ ａｎｄ ｍｕｌｔｉ－ｖｉｅｗ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｕｓｉｏｎ．Ｆｏｒ
ｔｈｅｓｅ ｐｒｏｂｌｅｍｓ ｔｈａｔ ｉｔ ｉｓ ｄｉｆｆｉｃｕｌｔ ｔｏ ａｎａｌｙｚｅ ｕｓｅｒ ｒｅｖｉｅｗｓ’ｓｅｎｔｉｍｅｎｔ ａｎｄ ｉｔｅｍｓ ｃｏｎｔｅｎｔ’ｓｅｍａｎｔｉｃｓ，
ａｎｄ ａ ｓｉｎｇｌｅ ｖｉｅｗ ｏｆ ｔｈｅ ｒｅｃｏｍｍｅｎｄｅｄ ｍｏｄｅｌ ｌｅａｄ ｔｏ ｕｓｅｒ ｐｒｏｆｉｌｅ ｉｓ ｅｘｔｅｎｓｉｖｅ，ｗｅ ｕｓｅ Ｗｏｒｄ２ｖｅｃ ｔｏ
ｃｈａｒａｃｔｅｒｉｚｅ ｔｈｅ ｓｈｏｒｔ ｔｅｘｔｓ ｏｆ ｕｓｅｒ ｒｅｖｉｅｗｓ ａｎｄ ｃｏｍｂｉｎｅ ｌｏｎｇ ｓｈｏｒｔ－ｔｅｒｍ ｍｅｍｏｒｙ ｎｅｔｗｏｒｋｓ ｔｏ
ｒｅａｌｉｚｅ ｔｈｅ ｓｅｎｔｉｍｅｎｔ ａｎａｌｙｓｉｓ ｏｆ ｔｈｅ ｕｓｅｒ ｒｅｖｉｅｗ ｏｎ ｔｈｅ ｃｏｎｔｅｘｔ ｓｅｍａｎｔｉｃ ｌｅｖｅｌ．Ａｔ ｔｈｅ ｓａｍｅ ｔｉｍｅ，
ａ ｓｅｎｔｉｍｅｎｔ ｆｕｓｉｏｎ ｍｅｔｈｏｄ ｂａｓｅｄ ｏｎ ｏｐｉｎｉｏｎ ｐｒｅ－ｆｉｌｔｅｒｉｎｇ ａｎｄ ｕｓｅｒ ｒａｔｉｎｇ ｅｍｂｅｄｄｉｎｇ ｉｓ ｐｒｏｐｏｓｅｄ，
ａｎｄ ａｎ ｅｍｂｅｄｄｅｄ ｎｅｔｗｏｒｋ ｓｔｒｕｃｔｕｒｅ ｉｓ ｄｅｓｉｇｎｅｄ ｆｏｒ ｄｅｅｐ ｓｅｍａｎｔｉｃ ａｎａｌｙｓｉｓ ａｎｄ ｓｅｎｔｉｍｅｎｔ ｃａｌｃｕｌａｔｉｏｎ
ｏｆ ｕｓｅｒ’ｓ ｒｅｖｉｅｗ．Ｔｈｅ ｐｒｏｐｏｓｅｄ ｍｅｔｈｏｄ ｗｉｌｌ ｓｏｌｖｅ ｔｈｅ ｐｒｏｂｌｅｍ ｔｈａｔ ｔｈｅｒｅ ｉｓ ａ ｇｒｅａｔ ｄｅｖｉａｔｉｏｎ
ｂｅｔｗｅｅｎ ｔｈｅ ｕｓｅｒ’ｓ ｒａｔｉｎｇ ａｎｄ ｒｅａｌ ｉｎｔｅｒｅｓｔ ｐｒｅｆｅｒｅｎｃｅ，ａｎｄ ａｌｓｏ ｓｏｌｖｅ ｔｈｅ ｅｘｔｒｅｍｅ ｉｍｂａｌａｎｃｅ
ｐｒｏｂｌｅｍ ｏｆ ｔｈｅ ｕｓｅｒ ｒａｔｉｎｇ ｄｉｓｔｒｉｂｕｔｉｏｎ．Ｉｎ ａｄｄｉｔｉｏｎ，ｗｅ ｕｓｅ ｔｈｅ ｄｉｓｔｒｉｂｕｔｅｄ ｖｅｃｔｏｒ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ
ｏｆ ｐａｒａｇｒａｐｈ ｔｏ ｃｈａｒａｃｔｅｒｉｚｅ ｔｈｅ ｓｈｏｒｔ ｔｅｘｔ ｏｆ ｔｈｅ ｉｔｅｍ’ｓ ｔｅｘｔ ｄｅｓｃｒｉｐｔｉｏｎ，ｓｏ ａｓ ｔｏ ｒｅａｌｉｚｅ ｔｈｅ
ｓｉｍｉｌａｒｉｔｙ ｃａｌｃｕｌａｔｉｏｎ ｏｆ ｔｈｅ ｉｔｅｍ’ｓ ｃｏｎｔｅｎｔ．Ｗｅ ｄｅｓｉｇｎ ａ ｍｅｔｈｏｄ ｔｏ ｍｅａｓｕｒｅ ｔｈｅ ｓｉｍｉｌａｒｉｔｙ ｏｆ
ｃａｎｄｉｄａｔｅ ｉｔｅｍｓ ａｎｄ ｃａｌｃｕｌａｔｅ Ｋｎｅａｒｅｓｔ ｎｅｉｇｈｂｏｒ ｉｔｅｍｓ，ｗｈｉｃｈ ｓｏｌｖｅｓ ｔｈｅ ｐｒｏｂｌｅｍ ｔｈａｔ ｔｈｅ ｉｔｅｍ’ｓ
ｃｏｎｔｅｎｔ ｉｎｆｏｒｍａｔｉｏｎ ｉｓ ｎｏｔ ｅａｓｙ ｔｏ ｍｉｎｅ ａｎｄ ｕｓｅ ｉｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ．Ｆｉｎａｌｌｙ，ａ ｆｕｓｉｏｎ
ｍｅｔｈｏｄ ｏｆ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｖｉｅｗ ｂａｓｅｄ ｏｎ ｃｏｌｌａｂｏｒａｔｉｖｅ ｔｒａｉｎｉｎｇ ｉｓ ｐｒｏｐｏｓｅｄ，ｗｈｉｃｈ ｉｎｔｅｇｒａｔｅｓ
ｕｓｅｒ ｒａｔｉｎｇｓ，ｓｅｎｔｉｍｅｎｔ ｐｒｅｆｅｒｅｎｃｅｓ ａｎｄ ｉｔｅｍ’ｓ ｃｏｎｔｅｎｔ ｉｎｆｏｒｍａｔｉｏｎ．Ｉｔ ｃａｎ ｆｉｌｌ ａｎｄ ｍｏｄｉｆｙ ｔｈｅ
ｓｐａｒｓｅ ｕｓｅｒ ｒａｔｉｎｇｓ ｍａｔｒｉｘ，ａｎｄ ｔｈｅｎ ｒｅａｌｉｚｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｂａｓｅｄ ｏｎ ｒａｔｉｎｇｓ ｐｒｅｄｉｃｔｉｏｎ．Ｉｔ ｓｏｌｖｅｓ
ｔｈｅ ｐｒｏｂｌｅｍ ｔｈａｔ ｍｕｌｔｉ－ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｖｉｅｗｓ ｗｉｔｈ ｄｉｆｆｅｒｅｎｔ ｉｎｔｅｒｅｓｔｓ ａｎｄ ｐｒｅｆｅｒｅｎｃｅｓ ａｒｅ ｄｉｆｆｉｃｕｌｔ
ｔｏ ｆｕｓｅ ｉｎ ｈｙｂｒｉｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ，ａｎｄ ｓｏｌｖｅｓ ｔｈｅ ｐｒｏｂｌｅｍ ｏｆ ｌａｃｋ ｏｆ ｓｕｆｆｉｃｉｅｎｔ ｌａｂｅｌｅｄ ｄａｔａ
ｆｏｒ ｍｏｄｅｌｉｎｇ ｉｎ ａ ｃｅｒｔａｉｎ ｄｅｇｒｅｅ．Ｗｅ ｃｏｎｄｕｃｔ ｔｈｅ ｅｘｐｅｒｉｍｅｎｔｓ ｏｎ Ａｍａｚｏｎ ｐｒｏｄｕｃｔ ｄａｔａｓｅｔ，ａｎｄ
ｃｏｍｐａｒｅ ｏｕｒ ａｌｇｏｒｉｔｈｍ ｗｉｔｈ ａ ｖａｒｉｅｔｙ ｏｆ ｃｌａｓｓｉｃ ａｎｄ ｓｔａｔｅ－ｏｆ－ｔｈｅ－ａｒｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｌｇｏｒｉｔｈｍｓ．
Ｓｐｅｃｉａｌｌｙ，ｔｈｅ ｒｅｓｕｌｔｓ ａｒｅ ｅｖａｌｕａｔｅｄ ｉｎ Ｍｅａｎ Ｓｑｕａｒｅｄ Ｅｒｒｏｒ，Ｈｉｔ Ｒａｄｉｏ，ａｎｄ Ｎｏｒｍａｌｉｚｅｄ Ｄｉｓｃｏｕｎｔｅｄ
Ｃｕｍｕｌａｔｉｖｅ Ｇａｉｎ．Ｔｈｅ ｅｘｐｅｒｉｍｅｎｔ ｒｅｓｕｌｔ ｓｈｏｗｓ ｔｈａｔ ｔｈｅ ａｌｇｏｒｉｔｈｍ ｐｒｏｐｏｓｅｄ ｉｎ ｔｈｉｓ ｐａｐｅｒ ｈａｓ ａ
ｓｉｇｎｉｆｉｃａｎｔ ｅｆｆｅｃｔ ｉｎ ｍｉｎｉｎｇ ｕｓｅｒ’ｓ ｓｅｎｔｉｍｅｎｔ．Ｏｎ ｔｈｅ ｔｅｎ ｒｅｃｏｍｍｅｎｄｅｄ ｄａｔａｓｅｔｓ，ｏｕｒ ａｌｇｏｒｉｔｈｍ
ｈａｓ ａｌｓｏ ａ ｓｉｇｎｉｆｉｃａｎｔ ｉｍｐｒｏｖｅｍｅｎｔ ｉｎ ｔｈｅ ａｃｃｕｒａｃｙ ｏｆ ｔｈｅ ｓｃｏｒｅ ｐｒｅｄｉｃｔｉｏｎ ａｎｄ ＴｏｐＮｐｅｒｆｏｒｍａｎｃｅ
ｏｆ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ ｉｎ ｄｉｆｆｅｒｅｎｔ ｄｅｇｒｅｅｓ．
Ｋｅｙｗｏｒｄｓ ｈｙｂｒｉｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ；ｄｉｓｔｒｉｂｕｔｅｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ；ｓｅｎｔｉｍｅｎｔ ａｎａｌｙｓｉｓ；ｃｏｌｌａｂｏｒａｔｉｖｅ
ｔｒａｉｎｉｎｇ；ｓｃｏｒｉｎｇ ｍａｔｒｉｘ
推荐算法如雨后春笋般出现．纵观推荐算法的发展
１ 引 言 历程，协同过滤和隐语义模型［１］是推荐系统发展早
期较流行的算法，其在过去十多年间得到了长足发
随着电子商务和社交网络等信息技术的迅速发 展．鉴于深度学习技术在人工智能诸多应用中取得
展，“信息超载”成为困扰人们网络生活的主旋律．个 的显著成效，基于深度学习的推荐模型也逐渐成为
性化推荐作为一种帮助用户快速搜寻有用信息的有 研究者追逐的焦点［２－３］．目前，用户评分矩阵（Ｒａｔｉｎｇ
效工具，越来越受到人们的青睐．伴随而来的，各种 Ｍａｔｒｉｘ）仍然是大多数推荐系统利用的主要行为偏 １３１８ 计 算 机 学 报 ２０１９年
好信息［４］，但基于用户评论［５］、用户隐式反馈［６］、物 表明这种噪声数据会对协同过滤的推荐结果产生较
品内容信息［７］的推荐越来越受到人们的关注，然而 大的负面影响．
受文本挖掘、用户行为分析等方面的制约，这些方面 在基于内容的推荐方面，物品内容的描述文本
研究取得的进展并不十分令人满意，但它们在解决 信息是一个重要的推荐依据．基于内容的推荐能有
推荐系统的推荐准确性、冷启动、可解释性等方面具 效解决系统的冷启动问题［１２］，且不受打分稀疏性的
有重要的潜力． 约束，能够发掘隐藏的“暗信息”，具有良好的用户体
在推荐算法的发展历程中，一种传统的为研究 验，因此受到广泛的关注．然而，针对物品内容的短
者推崇的是协同过滤算法，其目标是将用户和物品 文本自然语言描述（通常较短且零散），无足够的信
间的二元关系转化为评分预测问题，然后依据用户 息量供机器进行统计推断，这给物品内容的语义理
对物品的评分进行协同过滤或排序［８］，进而产生推 解带来了巨大困难．
荐列表．随后大量的研究工作发现，由于受用户评分
当前，利用深度学习技术融合多源异构数据［１３］、
真实性的制约以及评分矩阵稀疏性的影响，依据用
融合评分矩阵及评论文本［１４］、融合多特征的协同推
户评分产生的推荐结果并不能准确地体现用户的兴
荐［１５］成为研究的热点．本文在上述研究的基础上，
趣偏好［８－９］．基于此，研究者们做了大量的后续工作． 针对推荐系统中用户评分分布的不均衡及多推荐视
图不易融合的问题，提出了基于用户评论的深度情
Ｚｈａｎｇ等人［１０］通过比较用户评分和评论文本的情感
感分析与多视图协同融合的混合推荐方法（ＨＲＳＭ
倾向，指出用户评分并不能真实反映用户评论的情
算法），此处多视图即推荐系统中的多维度推荐因
感倾向．扈中凯等人［５］对用户评分进行统计分析，发
素．本文的混合推荐方法融合了用户评分矩阵、用户
现用户对物品的评分比较随意、且评分等级分布极
评论文本、物品的内容描述信息等三个推荐视图．与
度不均衡（如图１中的统计数据［５］，评分等级为５分
传统的加权融合和级联型等混合方法不同，本文设
的占９６．２％，评分等级为４分的占３．５％，评分等级
计了一种基于协同训练的推荐算法，实现用户评分
为１～３分的仅占０．３％）．同时，本文对实验中来自
的行为视图和物品描述的内容视图的融合．本文主
亚马逊１９９５年至２０１３年的Ａｕｔｏｍｏｔｉｖｅ等１０个数
要贡献在于提出了基于协同训练的多推荐视图融合
据集的４ １２０ ９４８条用户评论数据进行统计分析，得
的评分预测方法，并探讨了利用基于深度学习的自
出类似的结论，即用户的评分等级分布极度不均（评
然语言处理技术对推荐系统中用户评论文本等辅助
分等级为１～５分的分别占比４．８％、４．４％、９．０％、
信息进行整合的技巧．本文的创新主要体现在以下
２１．７％、６０．１％）．研究表明，这种评分分布极度不均
３个方面：
衡的状况给协同过滤推荐造成了极大的困扰．陈龙
（１）提出基于协同训练的推荐视图融合方法．
等人［１１］对用户评论的情感倾向进行分析，发现商品
设计了一种基于协同训练的融合用户评分、情感偏
评论的评分是一种弱标注标签，即评论中可能存在
好和物品内容信息的推荐算法，实现对稀疏的用户
实际情感语义与评分不一致的情况（如一条５星级
评分矩阵的循环填充和修正，进而实现基于评分预
的评分对应的评论中仍然存在负面描述）．这种情感
测的推荐．解决了混合推荐系统中不同兴趣偏好的
语义与评分不相符的标注数据称为噪声数据．研究
多推荐视图不易融合的问题，同时在一定程度上解
决了推荐系统建模中缺乏足够的有标签数据问题；
（２）提出基于观点预过滤和基于用户评分嵌入
的情感融合方法．设计一种嵌入的网络结构实现从
上下文层面对用户评论进行深层语义分析和情感计
算，并比较其在挖掘用户评论信息方面的效果．解决
了推荐系统中用户原始评分与真实兴趣偏好存在偏
差且评分等级分布不均衡的问题；
（３）研究在推荐系统建模中融合多种自然语言
处理技术的技巧．本文利用分布式的段落向量表征
对物品内容描述的短文本进行相似度计算，并设计
图１ 用户评分等级分布图 度量候选物品相似性的计算方法及计算Ｋ个最近 ６期 张宜浩等：基于用户评论的深度情感分析和多视图协同融合的混合推荐方法 １３１９
邻物品的方法，解决了推荐系统中物品内容的文本 在推荐系统中，通过对真实数据分析也表明：用户评
描述信息不易挖掘和利用的问题． 分往往与用户的兴趣偏好存在着较大的偏差，而用
户评论等短文本信息可能更真实地反映了用户的兴
２ 相关工作 趣偏好，故对用户评论的短文本的语义理解和情感
挖掘是解决推荐系统中用户评分不真实、分布不均
在协同过滤推荐中，基于用户历史评分数据的 的重要途径［５，１８］．
推荐算法通常面临着数据稀疏的问题，而这种稀疏 在基于内容的推荐中，物品的内容信息是一个
的用户评分通常会导致推荐质量下降［１６］；此外，原 重要的推荐依据，它也是用来解决推荐系统中冷启
始数据的不完整及算法本身处理数据的特殊性，也 动问题的重要途径，但这种推荐方法会受到信息获
会导致最终推荐效果不理想［１７］．当前，基于用户评 取技术的约束．在众多的物品内容表现形式中，一种
论、用户隐式反馈挖掘的推荐研究受到了高度的重 重要的形式是商家对物品的自然语言描述，传统的
视，但其受文本挖掘和情感分析等技术的困扰．田超 自然言语处理技术（如Ｂａｇ ｏｆ Ｗｏｒｄｓ）将文本表示成
等人［１８］通过整合网上商城的用户评论进行情感分 一个Ｗ 维的独热向量，该表示方法缺点非常明显，
析，实现ＳｕｐｅｒＲａｎｋ智能推荐系统原型．Ｓｈｍｕｅｌｉ等 其假设所有对象都是相互独立的，容易受到数据稀
人［１９］将用户评论信息作为协同过滤推荐的依据，并 疏问题的影响［２７］；同时，这种自然语言处理技术不
将其和内容信息并入因子模型中进行混合推荐． 能从语义层面对物品的内容信息进行分析，因此对
Ｚｈａｎｇ等人［２０］研究用户评论作弊对推荐系统的制 物品内容的短文本进行语义理解和相似度计算是解
约，提出了一种基于可疑行为扩散的统一框架，使得 决问题的关键．在对短文本的语义理解方面，研究者
系统人员不需要关心具体的作弊方法就能以较高的 做了大量的工作．Ｗａｎｇ等人［２８］利用语义聚类和卷
准确率识别作弊用户以及作弊行为．Ｗａｎｇ等人［２］ 积神经网络对短文本进行建模，并在模型中使用预
针对评分数据在应用中的稀疏性问题，提出结合物 训练的词嵌入来引入额外知识．王仲远等人［２９］归纳
品内容的深度表示及协同训练构建评分矩阵．Ｗｕ 了当前比较流行的短文本语义理解模型：隐性模型、
等人［２１］通过对Ｓｔａｃｋｅｄ Ｄｅｎｏｉｓｉｎｇ Ａｕｔｏｅｎｃｏｄｅｒｓ进 半显性模型、显性模型．Ｍａ等人［３０］提出一个新颖有
行扩展来提高评分预测的精确度．Ｃｈｅｎ等人［２２］归 效的框架，利用社会化媒体的内容信息来实现评分
纳总结了各种各样的基于评论的推荐方法，通过 预测．Ｌｉａｎ等人［３１］提出了一个深度混合模型来提高
将用户生成的有价值的评论信息融入用户建模和 个性化新闻推荐系统的表征学习能力．
推荐过程中，实现对用户评论推荐因素的挖掘，包 基于内容的推荐是依据用户喜爱的物品内容信
括考虑评论的有用性、评论的主题、评论的总体观 息找到相似物品进行推荐，当前较流行的做法是利
点、评论的内容、评论的情感等．为了充分挖掘推 用信息检索中的相关理论、方法与技术来实现对物
荐系统中用户评论的上下文信息，以及减少评论中 品内容信息的建模．由于评分（ｒａｔｉｎｇ）相对于物品
无关信息对推荐准确性的影响．Ｚｈａｎｇ等人［２３］提出 （ｉｔｅｍ）的稀疏性，基于模型的推荐通常缺乏足够的
了一种协同多级嵌入模型，它利用一个投影层将词 有标签数据［３２］．半监督学习作为一种同时利用有标
嵌入模型整合进标准的评分矩阵模型中来解决上述 签数据和无标签数据建模，来改进系统性能的学习
两个局限．Ｚｈａｎｇ等人［２４］提出一种深度协同神经网 策略，在推荐系统建模中得到较广泛的应用［３３－３４］．鉴
络（ＤｅｅｐＣｏＮＮ），在网络的最后一层中耦合两个并 于推荐系统中各个推荐因素相对独立的特点，其很
行的神经网络来实现混合推荐，其中一个网络学习 容易被划分为多个“充分冗余视图”，为利用协同训练
用户评论的行为信息，另外一个网络从用户评论中 策略构建推荐预测模型创造了天然的条件．Ｗｕ等
学习物品的属性信息．Ｃｈｅｎ等人［２５］通过引入一种 人［３３］利用无标签和有标签用户信息（Ｕｓｅｒ Ｐｒｏｆｉｌｅ）
新颖的注意力机制挖掘用户评论的有用性信息，提 构建一个多分类模型，实现了一个半监督混合推荐
出了基于神经注意回归模型的推荐系统，可以预测 系统（ＨｙＳＡＤ）．Ｚｈａｎｇ等人［３４］提出了一个基于上
精确的评分及每条评论的有用性．Ｈａｎ等人［２６］从异 下文感知的半监督协同训练方法，来解决推荐系统
构信息网络中提取不同层面的特征，利用精心设计 中的冷启动问题．Ｄｉｎｇ等人［３５］将视图数据集成到基
的深度神经网络来学习各个层面的潜在因子，然后 于隐式反馈的推荐系统中，以挖掘购买等主要反馈
将其融合到一个注意力机制中实现协同过滤推荐． 数据以外的隐藏偏好信息．Ｗａｎｇ等人［３６］提出一种 １３２０ 计 算 机 学 报 ２０１９年
新的基于树增强的嵌入方法，来学习显式的决策规 过滤推荐模型提供更加精确的反映用户真实兴趣偏
则和不可见的交叉特征，使推荐过程更加透明且有 好的综合评分数据．另一方面，我们对物品内容描述
解释性． 的文本信息进行挖掘，利用神经网络的方法将其表
示成为分布式的段落向量，实现对物品内容的相似
３ 基于协同训练的混合推荐系统模型 度计算，进而构建基于物品内容的推荐模型．最
后，本文利用协同训练策略实现对两个推荐视图
鉴于上述对推荐系统研究现状的论述，本文提 的融合，并在协同训练中增加了基于置信度估计
出了一种基于用户评论的深度情感分析与多源推荐 与聚类分析的数据选择策略，尽量消除迭代训练中
视图协同融合的混合推荐方法．一方面，我们通过挖 加入到训练数据池中的数据分布偏差．在此基础上，
掘用户评论的情感倾向，以实现对用户原始评分 利用协同训练模型输出的评分矩阵和物品的相似
偏离用户真实兴趣偏好的纠正，采用观点预过滤 度，对初始推荐结果进行过滤和排序，从而得到最终
（ｏｐｉｎｉｏｎ ｐｒｅ－ｆｉｌｔｅｒｉｎｇ）方法［３７］实现对用户的情感倾 推荐结果．基于协同训练的混合推荐系统框架如图２
向和原始评分等级的综合度量，为基于物品的协同 所示．
图２ 基于协同训练的混合推荐系统框架
３．１ 用户评论的情感分析 词向量（Ｗｏｒｄ２ｖｅｃ）作为一种进行高效率词嵌套
３．１．１ 用户评论文本的分布式向量表示 学习的预测模型［３８］，其包括连续词袋模型（ＣＢＯＷ）
通过对推荐系统中的用户评论文本进行统计分 和Ｓｋｉｐ－Ｇｒａｍ模型两种变体．ＣＢＯＷ 通过窗口范围
析，发现其呈现形式通常是关键词和短文本．研究表 内的词语预测中心词出现的概率，而Ｓｋｉｐ－Ｇｒａｍ则
明，这些短文本信息通常与长文本的处理方法不尽 是基于中心词预测窗口范围内词语出现的概率，其
相同．短文本具有长度短、语法不规则的特点，且亦 训练目标就是找出对预测句子或文档中的周围词语
无足够的信息量来供研究者进行统计和推断．传统 有用的词语的向量表示．假如对于一个给定句子，
的诸如词性标注、句法分析等自然语言处理技术在 ｗ，ｗ，…，ｗ 表示句子中的词语，Ｓｋｉｐ－Ｇｒａｍ模型
１ ２ Ｔ
短文本分析方面基本无能为力．早期对短文本的分 的目标函数ｇ（ｗ）就是求最大化平均对数概率．
析和应用主要通过枚举或关键词匹配的方式，对文 １ Ｔ
ｇ（ｗ）＝ ∑ ∑ ｌｏｇｐ（ｗ ｜ｗ） （１）
本的语义理解基本避而不谈，而自动化的短文本理 Ｔ ｔ＋ｊ ｔ
ｔ＝１ －ｃｊｃ，ｊ≠０
解通常需要依赖额外的知识．本文利用基于词向量 在式（１）中，ｃ表示训练文本的数量，ｃ越大，可能
的关键词表示方法，解决了传统稀疏表示方式的维 会使得模型的准确率越高．Ｓｋｉｐ－Ｇｒａｍ模型使用层次
数灾难，且无法表示语义信息的问题．同时也挖掘了 Ｓｏｆｔｍａｘ函数来定义ｐ（ｗ ｜ｗ）．层次Ｓｏｆｔｍａｘ使
ｔ＋ｊ ｔ
词之间的关联属性，从而提高了关键词语义表示的 用Ｗ 个字作为叶子的输出层的二叉树表示，并且对
准确度． 于每个节点明确表示其子节点的相对概率，利用随 ６期 张宜浩等：基于用户评论的深度情感分析和多视图协同融合的混合推荐方法 １３２１
机游走算法分配每个单词的概率． 胞状态．它通过在神经元中增加输入门、遗忘门和输
Ｗｏｒｄ２ｖｅｃ可以自动从大规模无标注用户评论 出门三个“门”结构来达到增强或遗忘信息的目的，
中学习到句法和语义信息，实现对用户评论中关键 使得自循环的权重是变化的．基于ＬＳＴＭ 的模型在
词的表征．利用 Ｗｏｒｄ２ｖｅｃ对用户评论的短文本信 参数固定的情况下，通过动态改变不同时刻的累积，
息进行向量表示，主要分为以下两个步骤： 可以有效避免 ＲＮＮ网络结构容易出现的梯度膨
（１）根据收集的用户评论文本数据，利用Ｓｋｉｐ－ 胀，甚至梯度消失等问题．在ＬＳＴＭ网络结构中，每
Ｇｒａｍ或ＣＢＯＷ训练词向量模型，将每个词表示成 个ＬＳＴＭ单元的计算公式如式（２）～（７）所示：
Ｋ维向量实数值； ｆ＝σ（Ｗ ·［ｈ ，ｘ］＋ｂ） （２）
ｔ ｆ ｔ－１ ｔ ｆ
（２）对于用户评论的短文本，在分词的基础上 ｉ＝σ（Ｗ·［ｈ ，ｘ］＋ｂ） （３）
ｔ ｉ ｔ－１ ｔ ｉ
利用ＴＦ－ＩＤＦ等算法抽取Ｔｏｐ－Ｎ 个词表示文本的 Ｃ～ ＝ｔａｎｈ（Ｗ ·［ｈ ，ｘ］＋ｂ） （４）
ｔ Ｃ ｔ－１ ｔ Ｃ
情感，然后从词向量模型中查找得到抽取的Ｔｏｐ－Ｎ
Ｃ＝ｆ＊Ｃ ＋ｉ＊Ｃ～ （５）
ｔ ｔ ｔ－１ ｔ ｔ
个词的Ｋ维向量表示．
Ｏ＝σ（Ｗ ·［ｈ ，ｘ］＋ｂ） （６）
在得到每个关键词的Ｋ维实数向量表示后， ｔ Ｏ ｔ－１ ｔ Ｏ
ｈ＝Ｏ＊ｔａｎｈ（Ｃ） （７）
一种较为普遍的做法是利用加权平均的方式对关 ｔ ｔ ｔ
在式（２）～（７）中，ｆ表示遗忘门，ｉ表示输入门，
键词的向量进行处理，将其等价于用户评论文本 ｔ ｔ
的向量表示，以实现对评论信息的情感分析．这种 Ｏ ｔ表示输出门；Ｃ～ ｔ表示前一时刻细胞的状态，Ｃ ｔ表示
加权平均的处理方法忽略了词语间的排列顺序对情
当前细胞的状态，ｈ ｔ－１和ｈ ｔ分别表示前一时刻单元
感预测模型的影响．因为基于 Ｗｏｒｄ２ｖｅｃ的词向量
的输出和当前单元的输出．
表示只是基于词的维度进行“语义分析”，而对词 本文采用基于 Ｗｏｒｄ２ｖｅｃ和ＬＳＴＭ的用户评论
向量进行加权平均的处理方式并不具备上下文的 的情感分析方法如图３所示．首先利用 Ｗｏｒｄ２ｖｅｃ将
“语义分析”能力，故本文构建基于词向量和长短期 矩阵形式的输入编码为较低维度的一维向量，以保
记忆网络的情感计算模型来实现对用户评论的情感 留大多数有用信息；然后利用ＬＳＴＭ 算法训练用户
分析．
评论文本的情感分类模型，实现对用户评论的评分
３．１．２ 基于词向量和长短期记忆网络的情感计算
等级预测．同时，为了兼顾用户评分和评论信息对真
在文本信息处理中，常用的方法是循环神经网络 实情感的交互影响，本文采用基于观点预过滤的方
（ＲＮＮ）．然而，ＲＮＮ在处理长序列时会导致优化时 法和基于用户评分嵌入的方法分别对用户评分和情
出现梯度消失的问题．为解决这一问题，研究人员提 感预测评分进行融合．前者是利用ＬＳＴＭ 网络得到
出了门限（Ｇａｔｅｄ ＲＮＮ），其中最著名的就是长短期 预测评分后，同原始用户评分进行加权求和，基于用
记忆网络（ＬＳＴＭ）．研究也表明：在很多任务上，采用 户评分嵌入的方法则是将ＬＳＴＭ 网络向量与用户
ＬＳＴＭ结构的神经网络比标准ＲＮＮ网络表现更好． 评分信息进行结合，将结果作为最后一层的输入，直
ＬＳＴＭ利用“门”结构来去除或增加信息到细 接输出最终的综合评分．
图３ 基于用户评分嵌入的情感分析方法
基于观点预过滤［３７］（ｏｐｉｎｉｏｎ ｐｒｅ－ｆｉｌｔｅｒｉｎｇ）的方 进行情感分析，预测得到每个用户对物品评论的情
法，利用 Ｗｏｒｄ２ｖｅｃ和ＬＳＴＭ 对用户评论文本建模 感倾向分数Ｓｃｏｒｅ，对用户的原始评分进行加权求
ｒ １３２２ 计 算 机 学 报 ２０１９年
和得出综合评分Ｓｃｏｒｅ． 在得到物品内容的惟一ｄ维分布式向量表示后，
ｃ
Ｓｃｏｒｅ＝αＳｃｏｒｅ＋（１－α）Ｓｃｏｒｅ （８） 就可以利用相似度计算的方式得到每两个物品内容
ｃ ｒ ｏ
在式（８）中，Ｓｃｏｒｅ表示用户对物品评论的情感 之间的相似度和距离．本文利用余弦公式度量两个物
ｒ
预测评分，Ｓｃｏｒｅ表示用户对物品的原始评分，α是 品间的相似度，同时利用马氏距离计算两个物品内容
ｏ
两个评分间权重的平衡因子． 自然语言描述的距离．假设两个物品内容自然语言
基于用户评分嵌入的方法是在对用户评论信息 描述的段落向量表示为ＰＶ＝（ｘ ，ｘ ，…，ｘ ）和
ａ １１ １２ １ｄ
进行情感分析的基础上，将得到的ＬＳＴＭ 输出向量 ＰＶ＝（ｘ ，ｘ ，…，ｘ ），其中ｄ表示两个段落向量
ｂ ２１ ２２ ２ｄ
与用户评分信息进行结合（如式（９）所示），然后将上 的维度．则它们间的相似度和距离分别定义式（１０）
述结果作为最后一层（全连接层）的输入，并通过 和式（１１）：
ｓｏｆｔｍａｘ激活函数直接输出最终的综合情感评分． ＰＶ·ＰＶ
ｓｉｍ（ＰＶ，ＰＶ）＝ ｄ ｄ
Ｈ ｉ＝ｈ ｔＳｃｏｒｅ（Ｕｓｅｒ ｉ） （９） ａ ｂ ＰＶ
ｄ
２·ＰＶ
ｄ
２
３．２ 基于物品内容的相似度计算 ｉ＝ｄ
∑ｘｘ
１ｉ ２ｉ
在推荐系统中，对物品内容的自然语言描述较
＝ ｉ＝０ （１０）
短且大多是不完整的句子，通常也不遵循语法规则． ｉ＝ｄ ｉ＝ｄ
槡∑ｘ２ 槡∑ｘ２
本文利用段落向量（Ｐａｒａｇｒａｐｈ Ｖｅｃｔｏｒ）［３９］对物品内 １ｉ ２ｉ
ｉ＝０ ｉ＝０
容描述的短文本进行分布式表示．段落向量是一种 ｄｉｓ（ＰＶ，ＰＶ）＝槡（ＰＶ－ＰＶ）ＴＳ－１（ＰＶ－ＰＶ）
ａ ｂ ａ ｂ ａ ｂ
基于神经网络的隐性短文本理解模型，它将短文
（１１）
本向量当作“语境”用于辅助推理，在极大似然估计
其中Ｓ是特征向量ＰＶ 和ＰＶ的协方差矩阵．
ａ ｂ
中，文本向量亦被作为模型参数进行更新．同基于
３．３ 基于协同训练的推荐视图融合
Ｗｏｒｄ２ｖｅｃ的文本向量表示方法相比，它在模型训练
在构建混合推荐系统时，本文利用用户综合评
过程中对段落也增加了编码．与普通的词一样，段落
分视图构建基于物品的协同过滤推荐模型；与此同
编码也是被先映射成一个向量（即段落编码向量）．
时，利用物品内容的自然语言描述视图构建基于物
在计算中，段落编码向量和词向量累加或者连接起
品内容的推荐模型；最后基于协同训练策略实现两
来，作为输出层Ｓｏｆｔｍａｘ的输入．在对物品内容描述
个推荐视图的融合．在数据选择方面，利用基于置信
文本的训练过程中，段落编码保持不变，相当于在每
度估计与聚类分析的数据选择算法对数据进行过
次预测单词概率时，其都整合了整个句子的语义信
滤，而后加入到另一个分类器的训练数据池中，进行
息．在预测阶段，我们给物品内容的描述文本分配一
下一轮训练，如此迭代．基于协同训练的推荐视图融
新的段落编码，同时保持词向量和输出层Ｓｏｆｔｍａｘ
合的框架如图５所示．
的参数不变．最后，我们利用梯度下降法训练新的物
品内容描述文本，直至其收敛，从而得到物品内容的
低维向量表示．物品内容的段落向量分布式表征如
图４所示．
图５ 基于协同训练的推荐视图融合
３．３．１ 基于协同训练的混合推荐算法
基于协同训练的混合推荐算法是在用户对物品
图４ 物品内容的段落向量分布式表征 评分的基础上构建初始评分矩阵；然后利用观点预 ６期 张宜浩等：基于用户评论的深度情感分析和多视图协同融合的混合推荐方法 １３２３
过滤的方法度量综合评分，从而更新评分矩阵；最后 ／／在ｍ×ｎ的评分矩阵中，行向量表示用户，列向量表
设计一个基于协同训练的混合推荐算法，依据综合 示物品．其中Ｒ（ｉ）表示评分矩阵的列向量，Ｒ ｕ（ｉ）表示用户ｕ
对物品ｉ的评分
评分矩阵和物品内容描述的向量相似度来循环地填
２．更新训练数据评分Ｒ（ｉ）：／／利用观点预过滤的方法
充和优化评分矩阵，进而实现推荐和排序．基于协同 ｕ
计算用户对物品的综合评分．其中Ｔｉｍｅ 表示当前时间，
ｃｕｒ
训练的混合推荐算法流程如图６所示．
Ｔｉｍｅ 表示用户对物品的评论时间，时间只取年份
Ｒｕ（ｉ）
Ｒ→ ｕ（ｉ）＝｛Ｒ→ ｍ×ｎ（Ｕ，Ｉ）∈｛１，５｝｜ｍ＝ｕ，ｎ＝ｉ｝，
Ｒ（ｉ）＝αＲ→ ｕ（ｉ）＋（１－α）Ｒ ｕ（ｉ）
．
ｕ Ｔｉｍｅ －Ｔｉｍｅ
ｃｕｒ Ｒｕ（ｉ）
３．更新训练数据集：／／将评分４的标记为正类，加入
数据池Ｄ ｉ（＋）中，将评分２的标记为负类，加入数据池
Ｄ（－）中
ｉ
Ｄ Ｌ＝｛Ｄ ｉ（＋）∪Ｄ ｉ（－）｝，
Ｄ ｉ（＋）＝｛Ｒ（ｉ）Ｔ｜Ｒ（ｉ）∈Ｒ ｍ×ｎ（Ｕ，Ｉ），Ｌ（ｉ）４｝，
Ｄ ｉ（－）＝｛Ｒ（ｉ）Ｔ｜Ｒ（ｉ）∈Ｒ ｍ×ｎ（Ｕ，Ｉ），Ｌ（ｉ）２｝．
４．训练基于物品的协同过滤推荐模型，用分类器ｈ对
１
候选数据Ｄ＝｛Ｒ（ｉ）Ｔ｜Ｒ（ｉ）∈Ｒ ｍ×ｎ（Ｕ，Ｉ），Ｒ ｕ（ｉ）＝｝进行预
测，得到预测标签Ｌ（ｉ）；
Ｄ′ Ｌ←｛（Ｄ（ｉ），Ｌ（ｉ））｝．
５．利用基于置信度估计与聚类分析的数据选择算法对
数据进行筛选，返回预加入训练数据池的数据．／／Ｄ 表示一
Ｌ
次迭代中原有的数据，Ｄ′表示一次迭代中增加的数据（数据
Ｌ
的标签为协同过滤模型的预测评分）
Ｒｅｔｕｒｎ Ｄ ｔｒａｉｎ＝｛Ｄ Ｌ∪Ｄ′ Ｌ｝．
在算法１中，利用基于物品的协同过滤推荐方
法，来填充用户评分矩阵的缺省值；同时更新用户ｕ
的训练数据集．在情感分类模型中，一般分为细粒度
（５级分类）和粗粒度（２级分类），考虑到２级情感分
类模型的准确率远高于５级情感分类模型［３８］，故本
图６ 基于协同训练的混合推荐算法流程
文的推荐算法中采用２级情感分类．分别将用户情
在推荐系统中，用户ｕ对物品ｉ的评分记为Ｒ ｕ（ｉ）； 感为正面和负面的评分设置为５分和１分；然后利
对应的评分矩阵为Ｒ （Ｕ，Ｉ），其中行向量ｍ表示 用观点预过滤的方法对用户情感评分和原始评分进
ｍ×ｎ
用户的个数，列向量ｎ表示物品的个数．在基于物品 行综合度量；最后利用基于物品的协同过滤模型实
的协同过滤推荐模型中，输入用户的原始评分矩阵 现对评分矩阵的预测和填充，并利用基于置信度估
Ｒ （Ｕ，Ｉ），其中Ｒ（ｉ）∈｛１，２，３，４，５｝，以及情感分析 计与聚类分析的数据选择算法对数据进行筛选，将
ｍ×ｎ ｕ
模型预测的虚拟评分矩阵Ｒ→ （Ｕ，Ｉ），其中Ｒ→ （ｉ）∈ 增量数据加入用户ｕ的训练数据集．
ｍ×ｎ ｕ
｛１，５｝，１表示用户情感为负面，５表示用户情感为 在基于物品内容描述模型中，利用Ｋ最近邻算
正面，输出为数据集Ｄ ．基于物品的协同过滤推 法来计算物品内容描述的距离，通过物品的余弦相
ｔｒａｉｎ
荐算法的描述如算法１所示．
似度以及Ｋ个最近邻物品（马氏距离）的评分来更
算法１． 基于物品的协同过滤推荐算法． 新或填充用户评分和缺省值，将其利用到基于物品
输入：用户对物品的评分矩阵Ｒ （Ｕ，Ｉ），情感计算模 内容的推荐模型中进行下一步迭代．基于物品内容
ｍ×ｎ
型预测的虚拟评分Ｒ→ （Ｕ，Ｉ） 的推荐算法描述如算法２所示．
ｍ×ｎ
输出：基于物品协同过滤推荐的训练数据集Ｄ 算法２． 基于物品内容的推荐算法．
ｔｒａｉｎ
１．根据用户评分矩阵，抽取针对用户ｕ的训练数据Ｄ ｉ＝ 输入：用户对物品的预测评分Ｄ′ Ｌ＝｛（Ｄ（ｉ），Ｌ（ｉ）｝，物品
｛Ｒ（ｉ）Ｔ｜Ｒ（ｉ）∈Ｒ ｍ×ｎ（Ｕ，Ｉ），Ｒ ｕ（ｉ）≠，ｉ∈［１，ｎ］｝，其类别标 内容描述的向量表示ＰＶ（Ｉｔｅｍ），训练数据集Ｄ
ｔｒａｉｎ
签为Ｌ（ｉ）＝Ｒ ｕ（ｉ）∈｛１，２，３，４，５｝； 输出：评分矩阵Ｒ ｍ×ｎ（Ｕ，Ｉ） １３２４ 计 算 机 学 报 ２０１９年
１．根据训练数据集Ｄ ，获取用户的物品集合： 的内容描述信息（物品的元数据视图），实现对两种
ｔｒａｉｎ
Ｄ ｉｔ＝｛ＰＶ（ｉ）∈ＰＶ（Ｉｔｅｍ）｜Ｌ（ｉ）４∪Ｌ（ｉ）２｝． 推荐视图的融合，达到了较好的混合推荐效果．
２．选取２ｐ个用户评分为Φ的物品候选集，分别计算候
３．３．２ 协同训练中的数据选择
选物品与数据集Ｄ ｉｔ中物品的距离和相似度：
本文在构建协同训练模型时，增加了数据选择
ＦＯＲＥＡＣＨＤ ｉ∈Ｄ ２ｐｄｏ
策略对欲加入训练池的数据进行筛选．规定用户的
ＦＯＲＥＡＣＨＤ ｊ∈Ｄ ｉｔｄｏ
每一评分等级为数据中的一个分类类别；在数据池
ｄｉｓ（Ｄ ｉ，Ｄ ｊ）＝槡（Ｄ ｉ－Ｄ ｊ）ＴＳ－１（Ｄ ｉ－Ｄ ｊ） 中的训练数据为有标签数据，待预测的数据为无标
ｓｉｍ（Ｄ ｉ，Ｄ ｊ）＝ ＤＤ ｉ·Ｄ Ｄｊ ． 签数据．在数据选择策略中，不仅考虑样本属于某一
ｉ ｊ 类别的置信度分数，同时也要求选择的样本在每一个
３．选择Ｋ个最近邻物品｛Ｄ，Ｄ，…，Ｄ ｝：／／ａ标记Ｋ
１ ２ Ｋ ｑ
（聚类）簇内是均匀分布的，可以避免选择的训练数据
个最近邻物品中每个评分等级的个数，ｄｉｓ表示物品Ｄ与Ｋ
ｑ ｉ
在高斯分布上存在较大的估计偏差．基于置信度估计
个最近邻物品的平均距离
ＦＯＲＥＡＣＨｑ∈｛１，２，３，４，５｝ｄｏ 与聚类分析的数据选择算法描述如算法３所示．
ｉｆ（ｑ－１Ｌ（Ｋ）ｑ） 算法３． 基于置信度估计与聚类分析的数据
ａ＝＋＋； 选择算法．
ｑ
１ａｑ 输入：训练样本集（ｘ，ｙ）
ｄｉｓ ｑ＝ ａ∑ｓｉｍ（Ｄ ｉ，Ｄ ｊ）．
输出：样本集（ｘ，ｙ）的选择标签Ｆｌａｇ＝｛ｔｒｕｅ，ｆａｌｓｅ｝
ｑ １
４．根据物品内容相似度更新评分矩阵的值： １．初始化
ＦＯＲＥＡＣＨＤ ｉ∈Ｄ ２ｐｄｏ （ａ）将训练数据中每一评分等级作为一类，计算训练样
Ｓｃｏｒｅ＝ａｒｇ ｍａｘ（ａ ｊ｜ｊ∈｛１，２，３，４，５｝） 本与每一类ｃ的相似度作为该样本的置信度估计度量，记为
Ｒ ｕ（ｉ）＝Ｓｃｏｒｅ＊ｄｉｓ（ｑ）． ｆ（ｃ；ｘ）．
５．针对不同用户ｕ的Ｒ（ｉ）值得，更新物品ｉ的评分； ２．训练数据划分
ｕ
Ｌ（ｉ′）←Ｒ（ｉ）． （ａ）利用Ｋｍｅａｎｓ聚类算法将候选数据划分为ｋ个子簇
６．更新训练数据的评分； Ｄ １，Ｄ ２，…，Ｄ ｋ．
Ｄ′ Ｌ＝｛（Ｄ（ｉ），Ｌ（ｉ））｝←｛（Ｄ（ｉ），Ｌ（ｉ′））｝． （ｂ）计算：
７．利用基于置信度估计与聚类分析的数据选择算法对 ｎｌ ｋ：聚类子簇Ｄ ｋ中的有标签样本的数目；
Ｄ′进行数据分布分析，并返回筛选的数据． ｎｕ：聚类子簇Ｄ中的无标签样本的数目；
Ｌ ｋ ｋ
Ｒｅｔｕｒｎ Ｒ ｍ×ｎ（Ｕ，Ｉ）． ｎｌ ｋ，ｃ：属于类ｃ且属于聚类子簇Ｄ ｋ中的有标签样本数目；
混合推荐方法将多种推荐技术进行混合相互弥 ｎｕ ：属于类ｃ且属于聚类子簇Ｄ中的无标签样本数目．
ｋ，ｃ ｋ
补缺点，从而获得更好的推荐效果．与传统的混合推 （ｃ）计算每一个聚类簇的先验概率：
荐技术（如加权融合、混合推荐、级联型推荐）不同， Ｐ（Ｄ）＝（ｎｌ＋ｎｕ）∑（ｎｌ＋ｎｕ）．
ｋ ｋ ｋ ｋ ｋ
本文在构建混合推荐系统时，采用了协同训练策略 ｋ
（ｄ）计算针对每一类别和聚类簇的概率：
构 内建 容基 的于 推物 荐（品 算的 法协 ２同 ）的过滤 混推 合荐 模（ 型算 ．法 在１ 协） 同和 训基 练于 模物 型品
Ｐ（ｃ｜Ｄ
ｋ）＝αＰ ｌ（ｃ｜Ｄ ｋ）＋（１ Ｚ－α）Ｐ ｕ（ｃ｜Ｄ ｋ）＋β
，
的每一次迭代训练过程中，利用计算的综合评分数 其中Ｐ ｌ（ｃ｜Ｄ ｋ）＝ｎｌ ｋ，ｃ／ｎｌ ｋ，Ｐ ｕ（ｃ｜Ｄ ｋ）＝ｎ ｋｕ ，ｃ／ｎ ｋｕ，α是Ｐ ｌ（ｃ｜Ｄ ｋ）
据训练评分预测模型，实现对评分矩阵的填充和更 和Ｐ ｕ（ｃ｜Ｄ ｋ）的平衡因子， β是一个数值极小的常量，Ｚ是使
新；然后根据更新后的评分矩阵和物品的内容描述
Ｐ（ｃ｜Ｄ ｋ）成为概率函数的归一化因子．
３．数据选择
信息（评分４和评分２的物品分别放入用户喜欢
（ａ）根据概率Ｐ（Ｄ）选择聚类簇Ｄ，在聚类簇Ｄ内依
和不喜欢的物品训练池中），训练得到基于物品内容 ｋ ｋ ｋ
据概率Ｐ（ｃ｜Ｄ ｋ）选择类别ｃ．
的推荐模型，从而对评分矩阵进行填充和更新，将其
（ｂ）求聚类簇Ｄ和类ｃ的样本的交集，选择具有最高
ｋ
作为基于物品的协同过滤推荐模型的输入，进行下
置信度估计的前ｍ个样本（令其Ｆｌａｇ＝ｔｒｕｅ）．
一次迭代训练．相较于加权融合混合推荐需要不断 （ｃ）重复（ａ）～（ｂ）步直至筛选完所有候选预加入训练
调整各推荐结果的权值、混合推荐的排序困难、以及 池的数据．
级联型推荐的分阶段过程，本文提出的基于协同训 ３．３．３ 算法的时间复杂度分析
练的混合推荐方法，在每次迭代训练中充分利用了 本文提出的基于协同训练的混合推荐算法，其
用户对物品的评分信息（Ｉｔｅｍ Ｐｒｏｆｉｌｅ视图）和物品 时间开销主要来源于用户评论的情感分析、物品内 ６期 张宜浩等：基于用户评论的深度情感分析和多视图协同融合的混合推荐方法 １３２５
容的相似度计算、基于物品的协同过滤模型及数据 ｒ 是用户ｕ对物品ｉ的实际评分，而ｒ～ 是预测评
ｕｉ ｕｉ
选择几个方面．其中，基于用户评论的情感分析是利 分，Ｔ 为用户ｕ对物品ｉ的真实评分条数，则推荐
用ＬＳＴＭ算法训练情感分类模型，是通过离线训练 １
系统的评测指标ＭＳＥ＝ ∑（ｒ －ｒ～ ）２．
ｕｉ ｕｉ
生成，不计入本文 ＨＲＳＭ 算法的时间复杂度．假设 Ｔ ｕ，ｉ∈Ｔ
在推荐系统中，用户数为ｍ，物品数量为ｎ，物品内 ４．２ 情感分析实验
容的向量维度为ｄ，则物品内容相似度计算的时间 本文在Ａｍａｚｏｎ ｐｒｏｄｕｃｔ ｄａｔａ上评测情感分类
复杂度为Ｏ（ｄ＊ｎ）；基于物品的协同过滤模型，在最 模型的性能．我们从 Ａｍａｚｏｎ评论数据集中选取
糟的情况下，其时间复杂度为Ｏ（ｍ＊ｎ），但现实情 Ａｕｔｏｍｏｔｉｖｅ、Ｂａｂｙ等１０个数据集中的１２ ０００条用
况下，由于用户评分数据的稀疏性，其只需计算 户评论，并人工标注每条评论文本的Ｐｏｓｉｔｉｖｅ（标签
Ｏ（ｍ＋ｎ）次．数据选择算法的时间复杂度为Ｏ（ｎｌｔ）， 为５）和Ｎｅｇａｔｉｖｅ（标签为１）情感标签，用于模型训
其中ｎ为物品数量，ｌ为代表聚类中心数，ｔ代表迭 练和测试．为了减少人工标注和校对的工作量，本文
代次数，ｌ和ｔ均为常数．假设协同训练算法中，协同 从数据集中选取６０００条评分为５或４（“ｏｖｅｒａｌｌ”：
训练的次数为ｃ（ｃ为常数），则本文算法的计算次数 ５．０或“ｏｖｅｒａｌｌ”：４．０）的数据，将其放入Ｐｏｓｉｔｉｖｅ的
为ｃ＊［（ｄ＊ｎ）＋（ｍ＊ｎ）＋ｎ］，或ｃ＊［（ｄ＊ｎ）＋ 样本集中，以供人工标注和校对；同时选取６０００条
（ｍ＋ｎ）＋ｎ］．由于在推荐系统中，一般情况下用户数 评分为１或２（“ｏｖｅｒａｌｌ”：１．０或“ｏｖｅｒａｌｌ”：２．０）的数
大于物品内容向量的维度（ｍ＞ｄ），故本文提出的混合 据，将其放入 Ｎｅｇａｔｉｖｅ的样本集中，以供人工标注
推荐算法的时间复杂度，最糟的情况下为Ｏ（ｍ＊ｎ）， 和校对．
即等同于基于领域的协同过滤推荐算法；一般情况 本文利用Ｓｃｉｋｉｔ－Ｌｅａｒｎ机器学习库构建情感分
下为Ｏ（ｄ＊ｎ），即等同于基于内容的推荐算法． 类模型，选取Ｓｃｉｋｉｔ－Ｌｅａｒｎ中经典的ＳＶＭ算法作为
基分类算法．在ＳＶＭ算法中，设置其核函数为高斯
４ 实验结果与分析 核（ｋｅｒｎｅｌ＝‘ｒｂｆ’），得到模型的平均准确率为
８１．９％．同时，本文选取 ＴｅｎｓｏｒＦｌｏｗ＋Ｋｅｒａｓ作为
４．１ 实验数据集及评价指标 深度学习框架，分别构建基于ＬＳＴＭ 的情感分类模
本文在 Ａｍａｚｏｎ ｐｒｏｄｕｃｔ ｄａｔａ［４０］上进行实验． 型和基于ＬＳＴＭ 的用户评分嵌入方法的情感分类
该数据集涵盖了从１９９５年７月至２０１３年３月来自 模型．在评论文本中单词的分布向量表示方面，利用
亚马逊的约３５００万条评论．数据集包括：用户信息、 ｇｅｎｓｉｍ对Ａｍａｚｏｎ数据集上所有的评论文本进行
物品信息及纯文本评论信息．其中，用户信息由一些 训练，从而得到评论文本中单词的词向量表示．在
明确的用户元数据组成，如名称、位置、用户等级、一 ｅｐｏｃｈｓ＝２０时得到模型的最高平均准确率分别为
些导出的统计信息等；物品信息包括物品Ｉｄ、物品 ９１．６％和９１．８％．情感分类模型的对比实验结果如
的标题、物品的价格等；评论信息包括用户Ｉｄ、物品 表２所示．
Ｉｄ、评论者、纯文本评论、物品评分、时间戳、用户的
表２ 情感分类模型的准确率
统计反馈等．关于数据集的描述如表１所示．
情感分类方法 评论情感 准确率／％
Ｐｏｓｉｔｉｖｅ ８２．５
表１ Ａｍａｚｏｎ ｐｒｏｄｕｃｔ ｄａｔａ描述
ＳＶＭ方法 Ｎｅｇａｔｉｖｅ ８１．３
数据集统计 数目 Ａｖｅｒａｇｅ ８１．９
评论条数 ３４６８６７７０ Ｐｏｓｉｔｉｖｅ ９２．２
用户个数 ６６４３６６９ ＬＳＴＭ方法 Ｎｅｇａｔｉｖｅ ９１．０
物品个数 ２４４１０５３ Ａｖｅｒａｇｅ ９１．６
评论＞５０条的用户个数 ５６７７２ Ｐｏｓｉｔｉｖｅ ９２．６
每条评论包含词的中位数 ８２ ＬＳＴＭ方法 Ｎｅｇａｔｉｖｅ ９１．０
（评分嵌入）
时间跨度 １９９５．０７～２０１３．０３
Ａｖｅｒａｇｅ ９１．８
在基于用户评论的短文本信息的情感分析模型 从表２中的数据可以看出，相比ＳＶＭ 算法，利
中，本文利用信息检索中的准确率这一度量指标对 用ＬＳＴＭ 训练的情感分类模型，其准确率得到非
情感分类实验进行评估．在混合推荐模型中，采用推 常明显的提高，平均准确率提高了近１０％．本文也
荐系统中经典的评价指标均方误差ＭＳＥ（Ｍｅａｎｓ－ 比较了基于ＬＳＴＭ 的情感分类中嵌入用户评分的
Ｓｑｕａｒｅｄ Ｅｒｒｏｒ）．假定测试集中的用户ｕ和物品ｉ， 方式，在相同的参数设置下，其平均准确率与仅使用 １３２６ 计 算 机 学 报 ２０１９年
评论文本训练模型相差不大，平均准确率提高了 （３）ＳＶＤ＋＋算法［４４］．该方法是一种改进的奇
０．２％． 异值分解（ＳＶＤ）技术，在ＳＶＤ的基础上引入隐式反
为更清晰地展示ＬＳＴＭ 算法训练得到的情感 馈．使用用户的历史浏览数据、用户历史评分数据等
分类模型的性能，我们比较了在不同迭代次数中模型 作为新的参数；
的准确率．分别设置ｅｐｏｃｈｓ＝｛１，１０，２０，３０，…，１００｝， （４）ＨＦＴ算法 （Ｈｉｄｄｅｎ Ｆａｃｔｏｒｓ ａｎｄ Ｈｉｄｄｅｎ
采用１０折交叉验证法对数据集进行评测，得到详细 Ｔｏｐｉｃｓ）［４０］．它通过对用户评分和用户评论进行建
的情感分类模型性能指标如图７所示． 模，在用户评论的主题分布和用户或物品的潜在因
素间建立联系；
（５）ＤＭＦ算法（Ｄｅｅｐ Ｍａｔｒｉｘ Ｆａｃｔｏｒｉｚａｔｉｏｎ）［４５］．
利用评分和隐式反馈构建用户评分矩阵，将其作为
输入，然后利用深度神经网络将用户和物品映射到
共同低维空间；
（６）ＮＣＦ算法（Ｎｅｕｒａｌ Ｃｏｌｌａｂｏｒａｔｉｖｅ Ｆｉｌｔｅｒｉｎｇ）［４６］．
一个基于协同过滤的用于模拟用户和物品潜在特征
的神经网络框架，利用多层感知机制来学习用户－物
品间的交互．
４．３．２ 两种情感分析方法的ＭＳＥ性能对比
为了实现用户评分与用户评论信息情感的融
合，本文设计了两种方法：基于观点预过滤的方法和
图７ 情感分类模型准确率
基于用户评分嵌入的方法．在观点预过滤的方法中，
设置α＝０．７时推荐模型取得了最佳效果．利用本文
在图７基于ＬＳＴＭ和 Ｗｏｒｄ２ｖｅｃ的情感分类模
提出的推荐模型，在Ａｍａｚｏｎ ｐｒｏｄｕｃｔ ｄａｔａ的１０个
型对比实验中，设置模型的损失函数为对数损失
数据集上得到的预测评分结果如表３所示．
（ｂｉｎａｒｙ＿ｃｒｏｓｓｅｎｔｒｏｐｙ），在训练模型时设置优化器
为ａｄａｍ，ｂａｔｃｈ＿ｓｉｚｅ＝３２，ｄｒｏｐｏｕｔ＝０．８．从图中的 表３ 基于两种情感综合方法的评分预测结果（ＭＳＥ值）
数据可以看出，当ｅｐｏｃｈｓ＝２０时，嵌入用户评分的模 数据集 观点预过滤方法 评分嵌入方法
型准确率达到最高点９１．８％．随着迭代次数的进一步
Ａｕｔｏｍｏｔｉｖｅ １．３１３ １．３０５
Ｂａｂｙ １．４３５ １．５１４
增加，模型的准确率在９０％以上起伏震荡，这表明模
Ｂｅａｕｔｙ １．３７３ １．３４１
型性能较为平稳，且取得了较好的分类准确率． Ｅｌｅｃｔｒｏｎｉｃｓ １．２８７ １．３５７
Ｈｏｍｅ ａｎｄ Ｋｉｔｃｈｅｎ １．１３２ １．１５６
４．３ 推荐预测实验 Ｋｉｎｄｌｅ Ｓｔｏｒｅ １．５１３ １．５３６
４．３．１ 对比算法
Ｍｕｓｉｃａｌ Ｉｎｓｔｒｕｍｅｎｔｓ １．２７２ １．１５７
Ｏｆｆｉｃｅ Ｐｒｏｄｕｃｔｓ １．３１２ １．３３６
在本文的实验中，选取了６种较为经典的推荐
Ｐｅｔ Ｓｕｐｐｌｉｅｓ １．５９８ １．６７２
算法，其中前４种推荐算法［４１］主要评测ＭＳＥ性能 Ｓｐｏｒｔｓ ａｎｄ Ｏｕｔｄｏｏｒｓ ０．９６６ １．０１５
Ａｖｅｒａｇｅ １．３２０ １．３３９
指标，作为本文提出的 ＨＲＳＭ 算法的对比方法；后
２种推荐算法主要基于ＴｏｐＮ推荐，用来评估本文 从表３中的实验数据来看，将上述两种情感融
ＨＲＳＭ算法在推荐方面的性能．这６种对比推荐算 合方法引入到本文提出的 ＨＲＳＭ 算法中得到的实
法详细描述如下： 验结果比较接近，两者互有胜负．从平均成绩来看，
（１）ＩｔｅｍＫＮＮ算法［４２］．该方法将聚类物品分成 基于观点预过滤的方法要好于评分嵌入方法，故本
若干类，并使用每个类别的平均评分作为算法的预 文后面的实验，在情感分析上采用的是基于观点预
测评分； 过滤的方法．
（２）ＭＦ算法（Ｍａｔｒｉｘ Ｆａｃｔｏｒｉｚａｔｉｏｎ）［４３］．该方法 ４．３．３ 模型的评分预测结果
是一种特征分解算法，它对“用户－物品”评分矩阵进 在推荐算法的实验环节，使用模型的预测评分与
行分解，得到一个用户隐向量矩阵和一个物品隐向 真实评分的平方误差ＭＳＥ作为评价指标来衡量各
量矩阵，从而预测原评分矩阵中缺失的评分； 种推荐算法的实验效果．在相同的Ａｍａｚｏｎ ｐｒｏｄｕｃｔ ６期 张宜浩等：基于用户评论的深度情感分析和多视图协同融合的混合推荐方法 １３２７
ｄａｔａ上，分别利用ＩｔｅｍＫＮＮ算法、ＭＦ算法、ＳＶＤ＋＋ ＨＦＴ算法的结果．在 ＭＦ算法中，设置ｎｕｍ＿ｆａｃ－
算法、ＨＦＴ算法以及本文提出的 ＨＲＳＭ 算法进行 ｔｏｒｓ＝２０，ｂｉａｓ＿ｒｅｇ＝０．２５，ｒｅｇ＿ｕ＝０．４，ｒｅｇ＿ｉ＝１．２，
比较实验．在本文提出的 ＨＲＳＭ 算法中，设置取得 ｆｒｅｑｕｅｎｃｙ＿ｒｅｇｕｌａｒｉｚａｔｉｏｎ＝ｔｒｕｅ，ｌｅａｒｎ＿ｒａｔｅ＝０．０３，
最佳结果时的参数α＝０．６，Ｋ＝６０．此外在本节的 ｎｕｍ＿ｉｔｅｒ＝８０，ｂｏｌｄ＿ｄｒｉｖｅｒ＝ｔｒｕｅ．在ＳＶＤ＋＋算法
ＨＲＳＭ算法中，采用观点预过滤方法的综合评分结 中，设置ｎｕｍ＿ｆａｃｔｏｒｓ＝１０，ｒｅｇｕｌａｒｉｚａｔｉｏｎ＝０．１，
果．对于其它每一种推荐算法，参数亦设置为获得最 ｂｉａｓ＿ｒｅｇ＝０．００５，ｂｉａｓ＿ｌｅａｒｎ＿ｒａｔｅ＝０．００７，ｌｅａｒｎ＿
佳结果时的参数．本文使用 ＭｙＭｅｄｉａＬｉｔｅ推荐系统 ｒａｔｅ＝０．０１，ｎｕｍ＿ｉｔｅｒ＝５０．在测试集上得到的ＭＳＥ
库［４７］来获得ＩｔｅｍＫＮＮ算法、ＭＦ算法、ＳＶＤ＋＋算 指标如表４所示．
法的实验结果，并使用论文中提供的源代码获得
表４ 推荐模型的评分预测结果（ＭＳＥ值）
数据集 ＩｔｅｍＫＮＮ算法 ＭＦ算法 ＳＶＤ＋＋算法 ＨＦＴ算法 ＨＲＳＭ算法
Ａｕｔｏｍｏｔｉｖｅ １．５４８ １．６０１ １．５７２ １．４１９ １．３１３
Ｂａｂｙ １．６０５ １．６５４ １．６２７ １．５４９ １．４３５
Ｂｅａｕｔｙ １．６１２ １．６８７ １．６１６ １．３７３ １．４０７
Ｅｌｅｃｔｒｏｎｉｃｓ １．６４４ １．６８８ １．６６１ １．６５９ １．４８７
Ｈｏｍｅ ａｎｄ Ｋｉｔｃｈｅｎ １．６３５ １．７０５ １．６７３ １．５３３ １．４３２
Ｋｉｎｄｌｅ Ｓｔｏｒｅ １．４８２ １．５０２ １．４３６ １．３４１ １．３７３
Ｍｕｓｉｃａｌ Ｉｎｓｔｒｕｍｅｎｔｓ １．４０４ １．４５４ １．４５５ １．４１２ １．２７２
Ｏｆｆｉｃｅ Ｐｒｏｄｕｃｔｓ １．６７６ １．７８７ １．７５４ １．６１７ １．４１２
Ｐｅｔ Ｓｕｐｐｌｉｅｓ １．６７９ １．７０５ １．６７１ １．６８２ １．６９９
Ｓｐｏｒｔｓ ａｎｄ Ｏｕｔｄｏｏｒｓ １．３２１ １．３５７ １．３３１ １．１１８ ０．９６６
表４显示了本文提出的算法和ＩｔｅｍＫＮＮ 算 １２．６８％和１３．６０％；研究表明在基于物品内容推
法、ＭＦ算法、ＳＶＤ＋＋算法、ＨＦＴ算法等４种经典 荐视图中融入用户评论信息有助于改善系统性
算法在Ａｍａｚｏｎ ｐｒｏｄｕｃｔ ｄａｔａ上实验结果．总体来 能．在其它３个数据集Ｂｅａｕｔｙ、Ｋｉｎｄｌｅ Ｓｔｏｒｅ和Ｐｅｔ
看，本文提出的 ＨＲＳＭ 算法在 ＭＳＥ评价指标上 Ｓｕｐｐｌｉｅｓ上，ＨＲＳＭ 算法相比最好的算法分别有
优于其它４种经典的推荐算法，其中 ＭＦ算法总体 ２．４８％、２．３９％、１．１９％的降低．分析表明在Ｂｅａｕｔｙ、
表现最差，这表明一个简单的评分矩阵分解算法不 Ｋｉｎｄｌｅ Ｓｔｏｒｅ和 Ｐｅｔ Ｓｕｐｐｌｉｅｓ这三个数据集上，
太适合于在Ａｍａｚｏｎ实验数据集上构建推荐模型． ＨＲＳＭ算法的效果都要比 ＭＦ算法要好，但相比
ＩｔｅｍＫＮＮ算法的总体性能与ＳＶＤ＋＋算法较相 ＨＦＴ算法和ＳＶＤ＋＋算法有略微的降低．可能的
近，ＳＶＤ＋＋算法的性能较 ＭＦ算法有较明显的提 原因是：购买儿童和女性用品的用户多为女性，其对
高，这表明在模型中增加用户历史数据可以提高推 物品的质量要求比较严格，其兴趣偏好波动也比较
荐模型的性能，同时也表明本文期望利用用户评论 大，故评论信息和兴趣偏好并非总是正相关．这表明
等辅助信息提高推荐效果具有可行性． 通过多推荐视图的融合并不总是能提高模型的性
进一步对表４中的实验数据分析，发现在Ａｍａｚｏｎ 能，如果模型中引入一些不可靠的推荐因素，反而会
ｐｒｏｄｕｃｔ ｄａｔａ中的１０个实验数据集上，本文提出 对系统的性能起反作用．
的ＨＲＳＭ算法相较其它４种较为经典的算法在 综合上述分析数据，本文提出的ＨＲＳＭ算法在
Ａｕｔｏｍｏｔｉｖｅ、Ｂａｂｙ等７个数据集上获胜．分析计算 ＭＳＥ评价指标上较传统算法有明显的改善，表明
显示：在 Ａｕｔｏｍｏｔｉｖｅ、Ｂａｂｙ数据集上，ＨＲＳＭ 算法 推荐模型的预测准确率与真实的用户评分相关，
相比最好的算法（ＨＦＴ）提升了７．４７％和７．３６％； 也表明利用基于观点预过滤的方法来融合虚拟评
在Ｅｌｅｃｔｒｏｎｉｃｓ和 Ｍｕｓｉｃａｌ Ｉｎｓｔｒｕｍｅｎｔｓ数据集上， 分并得到用户的综合评分，能有效地改善用户的
ＨＲＳＭ算法相比最好的算法（ＩｔｅｍＫＮＮ）提升了 评分准确性，并最终影响推荐模型的评分预测准确
９．５５％和９．４０％；研究发现这两类物品有较丰富的 率．此外，冷启动问题是推荐场景中的一个备受关注
用户评论信息，在模型中引入这些隐式参数能有效 的问题，然而很少有记录（包括评分和评论）被认为
地降低系统评分的均方差．在 Ｈｏｍｅ ａｎｄ Ｋｉｔｃｈｅｎ、 与“冷启动”相关．本文提出的ＨＲＳＭ算法结合了基
Ｏｆｆｉｃｅ Ｐｒｏｄｕｃｔｓ和Ｓｐｏｒｔｓ ａｎｄ Ｏｕｔｄｏｏｒｓ数据集上， 于物品的协同过滤推荐和基于物品内容的推荐，在
ＨＲＳＭ算法相比最好的算法（ＨＦＴ）提升了６．５９％、 推荐因素中融入了用户评论的情感倾向，以及物品 １３２８ 计 算 机 学 报 ２０１９年
内容的自然语言描述的语义信息，从理论上分析，这
些辅助信息在一定程度上将有助力解决推荐系统的
冷启动问题．
４．４ 推荐预测中参数的影响
４．４．１ 平衡因子α的影响
在本文提出的 ＨＲＳＭ 算法中，有一个重要的参
数α，它反映了基于观点预过滤（ｏｐｉｎｉｏｎ ｐｒｅ－ｆｉｌｔｅｒｉｎｇ）
方法中原始用户评分和用户评论的情感分析虚拟评
分的权重问题．对该物品的情感倾向进行综合评分
时利用公式Ｓｃｏｒｅ＝αＳｃｏｒｅ＋（１－α）Ｓｃｏｒｅ，其中
ｃ ｒ ｏ
Ｓｃｏｒｅ是用户对物品的原始评分值，Ｓｃｏｒｅ是模型预
ｏ ｒ
测的用户对物品的虚拟评分．α的值越大，则表示情
感分类模型预测的虚拟评分在综合评分中的权重越
图９ 随着α的取值变化，模型在Ｋｉｎｄｌｅ Ｓｔｏｒｅ等
大．在本实验中，分别设置α的值从０到１．０，步长
５个数据集上的ＭＳＥ值
为０．１．在１０个Ａｍａｚｏｎ数据集上得到的实验结果
如图８、图９所示．在图８、图９中，当α＝０时，表示
取得了最小的ＭＳＥ值．相较于当α＝０时，模型只
只考虑用户的原始评分，当α＝１时，表示只考虑用
考虑用户的原始评分，当α≠０时（即考虑虚拟评分
户的虚拟评分．
在综合评分中的作用），模型的ＭＳＥ值得都有不同
程度的降低，表明α对推荐系统的预测评分模型有
着重要的影响．
对图８和图９中的实验数据进行分析，可以看
出利用情感分类模型计算出来的虚拟评分对推荐预
测评分模型的准确性有重要影响．这也在一定程度
上验证了本文提出的设想，即在用户的原始评分较
随意、且评分等级分布极度不均衡的情况下，用户的
评论信息更能反映用户的真实兴趣偏好．采用基于
观点预过滤方法对原始用户评分和用户评论的情感
虚拟评分进行加权综合，可以在一定程度上解决用
户原始评分与真实兴趣偏好存在较大偏差的问题，
从而减少噪声数据对评分预测的估计偏差．
４．４．２ 最近邻物品个数Ｋ的影响
图８ 随着α的取值变化，模型在Ａｕｔｏｍｏｔｉｖｅ等
本文利用协同训练策略对用户评分数据和物品
５个数据集上的ＭＳＥ值
内容描述信息进行融合，构建混合推荐系统．在基于
从图８的数据可以看出，α＝０．６时，在Ａｕｔｏｍｏｔｉｖｅ 物品内容推荐模型中，利用 ＫＮＮ算法来计算物品
等５个评论数据集中，有４个数据集的ＭＳＥ值取 内容描述的距离，同时利用余弦相似度度量物品内
得最小值；而α＝０．７时，另一数据集 Ｈｏｍｅ ａｎｄ 容描述的相似度，以期利用Ｋ个最近邻物品的评分
Ｋｉｔｃｈｅｎ的ＭＳＥ值取得最小值．在基于观点预过滤 来更新或填充用户评分和缺省值．实验表明选取适
（ｏｐｉｎｉｏｎ ｐｒｅ－ｆｉｌｔｅｒｉｎｇ）方法中，α的值代表虚拟评分 当的Ｋ值对最终的推荐结果有重要影响．在本实验
在综合评分中的权重．故图８中的实验数据表明：相 中，分别设Ｋ的值为｛５，１０，２０，４０，６０，８０，１００｝，在
较于用户的原始评分，虚拟评分在推荐预测评分模 １０个 Ａｍａｚｏｎ ｐｒｏｄｕｃｔ ｄａｔａ上得到的实验结果如
型中起着更重要的作用．图９表示模型在 Ｋｉｎｄｌｅ 图１０、图１１所示．
Ｓｔｏｒｅ等５个数据集上随着α的取值变化而变化的 从图１０的数据可以看出，在Ｋ＝６０时，模型在
ＭＳＥ值．对图中的数据进行分析，我们几乎可以得 Ａｕｔｏｍｏｔｉｖｅ、Ｂａｂｙ、Ｂｅａｕｔｙ、Ｅｌｅｃｔｒｏｎｉｃｓ等４个数据
出与图８相似的结论，即α＝０．６或α＝０．７时，模型 集的 ＭＳＥ值取得最小值；当 Ｋ＝８０时，模型的 ６期 张宜浩等：基于用户评论的深度情感分析和多视图协同融合的混合推荐方法 １３２９
定的区域内，就可以获得比较好的 ＭＳＥ精度．例
如，在本实验中，选择Ｋ的范围在［５０，７０］之间都是
比较好的取值．故本文在利用 ＫＮＮ算法计算相似
物品的内容描述时，即在表５中的对比实验结果中
选取Ｋ＝６０作为ＨＲＳＭ算法的参数．
４．５ 推荐结果分析
为了评估推荐模型的性能，本文采用了大多数文
献中广泛采用的留一法［４６］（ｌｅａｖｅ－ｏｎｅ－ｏｕｔ）．本文使
用命中率ＨＲ（Ｈｉｔ Ｒａｄｉｏ）和标准化折扣累积增益
ＮＤＣＧ（Ｎｏｒｍａｌｉｚｅｄ Ｄｉｓｃｏｕｎｔｅｄ Ｃｕｍｕｌａｔｉｖｅ Ｇａｉｎ）［２６，４６］
来评估模型的性能．
Ｎｕｍｂｅｒ ｏｆ Ｈｉｔｓ＠Ｎ
ＨＲ＠Ｎ＝ ，其中分母表示
｜ＧＴ｜
图１０ 随着最近邻居数Ｋ的取值变化，模型在 候选测试集的数量，分子表示每个用户前Ｎ个被推
Ａｕｔｏｍｏｔｉｖｅ等５个数据集上的ＭＳＥ值
荐物品中属于测试集合物品列表的个数总和．
ＤＣＧ
ＮＤＣＧ ＝ Ｎ ，其中分子ＤＣＧ 表示按
Ｎ Ｎ
ｉｄｅａｌＤＣＧ
Ｎ
模型排名的计算结果，分母ｉｄｅａｌＤＣＧ 表示按实际
Ｎ
Ｎ ２ｒｅｌｉ－１
等级排名的计算结果．ＤＣＧ ＝∑ ，其中
Ｎ ｌｏｇ（ｉ＋１）
ｉ＝１ ２
ｒｅｌ表示第ｉ个位置的“等级关联性”，ｉ表示推荐结
ｉ
果的位置．
在本节实验的ＴｏｐＮ推荐中，选取１００个用户
未评定过且与用户喜欢的物品最相似的物品作为候
选物品，在前４种推荐算法及本文的 ＨＲＳＭ 算法
中，利用评分预测模型中得到的用户评分Ｓｃｏｒｅ，
ｕｉ
以及候选推荐物品与目标用户ｕ喜欢物品的相似度
Ｓｉｍ 的乘积作为ＴｏｐＮ推荐排序的主要依据，同时
ｉｊ
图１１ 随着最近邻居数Ｋ的取值变化，模型在
也考虑推荐物品的时效性．在ＤＭＦ算法中，使用交
Ｋｉｎｄｌｅ Ｓｔｏｒｅ等５个数据集上的ＭＳＥ值 互矩阵Ｙ作为输入，构建一个２层的模型，设置顶层的
因子数为６４．在ＮＣＦ算法中，深度神经网络使用一
ＭＳＥ值在Ｈｏｍｅ ａｎｄ Ｋｉｔｃｈｅｎ数据集上取得最小．
个４层的全连接层，设置为ｌａｙｅｒｓ＝［６４，３２，１６，８］，
在上述５个数据集上，随着Ｋ值的继续增加，模型
正负实例比为１∶４，使用高斯分布（均值为０，标准
的ＭＳＥ值也在增加，表明推荐模型的效果变差．
差为０．０１）随机初始化模型参数，并用 ｍｉｎｉ－ｂａｔｃｈ
图１１是模型在Ｋｉｎｄｌｅ Ｓｔｏｒｅ等５个数据集上随着
Ａｄａｍ优化模型．得到的不同推荐算法的ＨＲ＠Ｎ
最近邻居数Ｋ的取值变化而变化的ＭＳＥ值，从图
和ＮＤＣＧ＠Ｎ性能比较如表５．
中的数据可以得出，当Ｋ＝６０时，模型在５个数据 表５显示了不同的推荐算法在ＴｏｐＮ推荐中的
集上取得了最小的ＭＳＥ值，而随着Ｋ值的继续增 最佳实验结果．从实验结果可以看出，本文提出的
加，模型的ＭＳＥ值也在增加，表明推荐模型的效果 ＨＲＳＭ算法在 ＨＲ＠Ｎ评价指标上取得了较其它
随着Ｋ值的增加反而变差． 算法更好的性能．相较于当前较流行的基于深度学
从图１０和图１１中的数据可以看出，模型在１０个 习的ＤＭＦ算法和ＮＣＦ算法，由于本文提出的算法
数据集上的推荐效果与选取的最近邻居数Ｋ的取 挖掘了用户评论信息，以及在协同训练模型中利用
值有较大的关系．当然，在一些数据集上，推荐模型 了物品内容的描述文本信息，所以可以较好地克服
的ＭＳＥ精度对Ｋ值也不是特别敏感，只在选择一 推荐系统的冷启动问题，因此在反映推荐系统的召 １３３０ 计 算 机 学 报 ２０１９年
表５ 不同算法的ＨＲ＠Ｎ和ＮＤＣＧ＠Ｎ比较
评测指标 ＩｔｅｍＫＮＮ算法 ＭＦ算法 ＳＶＤ＋＋算法 ＨＦＴ算法 ＤＭＦ算法 ＮＣＦ算法 ＨＲＳＭ算法
ＨＲ＠５ ０．１８９７ ０．３０２７ ０．３０８２ ０．３０３５ ０．２６９３ ０．３１１７ ０．３１５６
ＮＤＣＧ＠５ ０．１２７９ ０．２０６８ ０．２０６３ ０．１９１７ ０．１８４８ ０．２１４１ ０．２１６３
ＨＲ＠１０ ０．３１２６ ０．４２７８ ０．３２２５ ０．３２０６ ０．３７１５ ０．４３０９ ０．４４９３
ＮＤＣＧ＠１０ ０．１６７２ ０．２４７１ ０．２４８３ ０．２３１９ ０．２１７９ ０．２５２４ ０．２５４５
ＨＲ＠１５ ０．３９０１ ０．５０５４ ０．４６７２ ０．４４０９ ０．４３２８ ０．５２５８ ０．５４８７
ＮＤＣＧ＠１５ ０．１８７７ ０．２６７６ ０．２７０１ ０．２６８５ ０．２３３２ ０．２７７４ ０．２６８９
ＨＲ＠２０ ０．４４３１ ０．５６８０ ０．５６９２ ０．５６１０ ０．４８５０ ０．５８９７ ０．５９３２
ＮＤＣＧ＠２０ ０．２００２ ０．２８２４ ０．２７４９ ０．２６０６ ０．２４５８ ０．２９２５ ０．２９０６
回率性能（ＨＲ＠Ｎ）上取得了较好的成绩．在ＮＤ－
表６ 推荐算法的时间消耗比较 （单位：ｍｉｎ）
ＣＧ＠Ｎ评价指标上，ＨＲＳＭ 算法和ＮＣＦ算法各取 数据集 Ａｕｔｏｍｏｔｉｖｅ Ｅｌｅｃｔｒｏｎｉｃｓ
得了两项最佳成绩．ＮＣＦ利用深度神经网络构建用 ＩｔｅｍＫＮＮ算法 ３１．５ ２０６．８
ＭＦ算法 １１．９ ８０．７
户与物品之间的交互，在学习二者交互的潜在因子 ＳＶＤ＋＋算法 １２．６ ８２．８
方面表现出了较强的能力，在ＮＤＣＧ＠１５和ＮＤ－ ＨＦＴ算法 ２０．８ ２２０．２
ＤＭＦ算法 ２６．７ １８５．６
ＣＧ＠２０指标上获得了较 ＨＲＳＭ 算法更好的性能． ＮＣＦ算法 ２３．６ １５６．１
ＨＲＳＭ算法 ３３．６ １８０．３
同时，在挖掘用户偏好的时效性方面，考虑到本文实
验数据的涵盖了１９９５年至２０１３年，时间跨度非常 从表６中的数据可以看出，ＭＦ和ＳＶＤ＋＋算
大．本文在利用观点预过滤的方法计算用户对物品 法速度最快，因为他们使用了梯度下降的方法进行
的综合评分时，加入了对用户评论的时间维度．遵循 近似计算，大大减少了时间消耗；ＤＭＦ和 ＮＣＦ等
时间越近，权重因子越大，时间越远，权重因子越小 深度学习算法利用ＧＰＵ加速，其训练速度也只比
的线性函数；同时在进行 ＴｏｐＮ推荐排序时，也考 ＨＦＴ 算 法 略 慢；本 文 提 出 的 ＨＲＳＭ 算 法 与
虑了推荐物品的时效性因素．实验表明，在推荐过程 ＩｔｅｍＫＮＮ算法的处理时间相当．综合比较而言，在
中考虑时间跨度对最终的推荐结果有较重要的
Ａｕｔｏｍｏｔｉｖｅ数据集上，ＨＲＳＭ 算法训练时间最长，
影响．
但在 Ｅｌｅｃｔｒｏｎｉｃｓ数据集上（Ｅｌｅｃｔｒｏｎｉｃｓ数据集是
对表５的实验数据进一步分析，通过在推荐模
Ａｕｔｏｍｏｔｉｖｅ数据集的９倍），ＨＲＳＭ 算法训练时长
要小于ＩｔｅｍＫＮＮ、ＨＦＴ和ＤＭＦ算法．这表明随着
型中融入用户评论信息、物品的内容描述信息等构
数据集的加大，ＨＲＳＭ算法的时间消耗下降速度更
建混合推荐系统，较传统的基于物品的协同过滤算
快．考虑到用户的评分矩阵预测和赋值在整个推荐
法及利用主题分布信息等构建模型在各方面性能上
过程中是离线进行的，故不影响ＴｏｐＮ推荐最终的
均有较大的提升，这也验证本文提出的通过融合多
实时性．
个推荐视图构建混合推荐系统的设想的可行性．在
在内存消耗方面，由于 ＭＦ和ＳＶＤ＋＋算法需
反映推荐系统的召回率性能（ＨＲ＠Ｎ）上，ＨＲＳＭ
要将一个用户评分矩阵分解为三个大的矩阵，这三
算法取得了最佳的成绩，表明ＨＲＳＭ算法可在一定
个矩阵都需存储在计算机内存中，所以需要消耗较
程度上解决推荐系统的冷启动问题．
多的内存；ＩｔｅｍＫＮＮ算法只需存储物品的内容信
４．６ 推荐算法的时间和内存消耗比较
息，ＨＲＳＭ算法也只需要存储用户评分矩阵和物品
在推荐系统时间消耗方面，大多数推荐算法是
内容信息，且这里的物品内容信息用低维向量表示，
基于ＲＭＳＥ值最小化的目标，因此评分矩阵的预测
内存空间消耗远小于 ＭＦ和ＳＶＤ＋＋等基于矩阵
与循环赋值是一个重要的时间优化目标．本文实验
因式分解的方法．ＤＭＦ和ＮＣＦ等深度学习算法在
使用的计算机平台是６４位操作系统，Ｉｎｔｅｌ ｉ７－８７００ 训练过程中由于参数众多、需要进行批量训练，故内
ＣＰＵ，８ＧＢ内存，ＮＶＩＤＩＡ ＧＴＸ１０８０ ８Ｇ．实验中随 存消耗是最大的．
机选择了 Ａｕｔｏｍｏｔｉｖｅ和Ｅｌｅｃｔｒｏｎｉｃｓ两个数据集，
在ＤＭＦ和ＮＣＦ模型中，设置ｅｐｏｃｈｓ＝１００，将深度 ５ 总结与展望
学习模型的训练时间作为算法的时间消耗，得到的
几种推荐算法的时间消耗比较如表６所示． 推荐系统作为解决信息过载的最有效工具，其 ６期 张宜浩等：基于用户评论的深度情感分析和多视图协同融合的混合推荐方法 １３３１
在当前的学术界和工业界都备受关注．一直以来协 参 考 文 献
同过滤推荐和基于内容的推荐是两种最重要的推荐
方法，但单一的协同过滤推荐模型或多或少地受评 ［１］ Ｃｒｅｍｏｎｅｓｉ Ｐ，Ｋｏｒｅｎ Ｙ，Ｔｕｒｒｉｎ Ｒ．Ｐｅｒｆｏｒｍａｎｃｅ ｏｆ ｒｅｃｏｍｍｅｎｄｅｒ
ａｌｇｏｒｉｔｈｍｓ ｏｎ ｔｏｐ－Ｎｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｔａｓｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
分数据稀疏、冷启动等制约；而基于内容的推荐，其
ｔｈｅ ４ｔｈ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｂａｒｃｅｌｏｎａ，
推荐因素通常不够充分，特别是当目标用户可用的
Ｓｐａｉｎ，２０１０：３９－４６
历史数据较少时．融合多视图的兴趣偏好信息构建 ［２］ Ｗａｎｇ Ｈ，Ｗａｎｇ Ｎ，Ｙｅｕｎｇ Ｄ Ｙ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｄｅｅｐ ｌｅａｒｎｉｎｇ
混合推荐模型是个性化推荐研究发展的趋势．鉴于 ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２１ｓｔ ＡＣＭ
ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ
用户评论、物品内容描述等短文本的情感及语义难
ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓｙｄｎｅｙ，Ａｕｓｔｒａｌｉａ，２０１５：１２３５－１２４４
以分析，单一视图的推荐模型易导致对用户画像的 ［３］ Ｗｅｉ Ｊ，Ｈｅ Ｊ，Ｃｈｅｎ Ｋ，ｅｔ ａｌ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ａｎｄ ｄｅｅｐ
建模粗放等问题．本文在对用户行为偏好进行分析 ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ ｆｏｒ ｃｏｌｄ ｓｔａｒｔ ｉｔｅｍｓ．
的基础上，将研究聚焦于文本信息的情感挖掘和深 Ｅｘｐｅｒｔ Ｓｙｓｔｅｍｓ ｗｉｔｈ Ａｐｐｌｉｃａｔｉｏｎｓ，２０１７，６９：２９－３９
［４］ Ｂｏｂａｄｉｌｌａ Ｊ，Ｏｒｔｅｇａ Ｆ，Ｈｅｒｎａｎｄｏ Ａ，ｅｔ ａｌ．Ｒｅｃｏｍｍｅｎｄｅｒ
层语义分析；同时挖掘物品内容的自然语言描述信
ｓｙｓｔｅｍｓ ｓｕｒｖｅｙ．Ｋｎｏｗｌｅｄｇｅ－Ｂａｓｅｄ Ｓｙｓｔｅｍｓ，２０１３，４６：１０９－１３２
息，并结合半监督学习中的协同训练的策略实现基 ［５］ Ｈｕ Ｚｈｏｎｇ－Ｋａｉ，Ｚｈｅｎｇ Ｘｉａｏ－Ｌｉｎ，Ｗｕ Ｙａ－Ｆｅｎｇ，ｅｔ ａｌ．Ｐｒｏｄｕｃｔ
于物品的协同过滤推荐视图和基于内容推荐视图的 ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｌｇｏｒｉｔｈｍ ｂａｓｅｄ ｏｎ ｕｓｅｒ’ｓ ｒｅｖｉｅｗｓ ｍｉｎｉｎｇ．
融合，来构建混合推荐系统．该方法一定程度上解决
Ｊｏｕｒｎａｌ ｏｆ Ｚｈｅｊｉａｎｇ Ｕｎｉｖｅｒｓｉｔｙ（Ｅｎｇｉｎｅｅｒｉｎｇ Ｓｃｉｅｎｃｅ），２０１３，
４７（８）：１４７５－１４８５（ｉｎ Ｃｈｉｎｅｓｅ）
了基于模型推荐方法缺乏足够有标签数据的问题．
（扈中凯，郑小林，吴亚峰等．基于用户评论挖掘的产品推荐
在Ａｍａｚｏｎ ｐｒｏｄｕｃｔ ｄａｔａ上的对比实验表明本文提 算法．浙江大学学报（工学版），２０１３，４７（８）：１４７５－１４８５）
出的综合情感评分的有效性，有助于解决推荐系统 ［６］ Ｗａｎｇ Ｚｈｉ－Ｓｈｅｎｇ，Ｌｉ Ｑｉ，Ｗａｎｇ Ｊｉｎｇ，ｅｔ ａｌ．Ｒｅａｌ－ｔｉｍｅ ｐｅｒｓｏｎａｌｉｚｅｄ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｂａｓｅｄ ｏｎ ｉｍｐｌｉｃｉｔ ｕｓｅｒ ｆｅｅｄｂａｃｋ ｄａｔａ ｓｔｒｅａｍ．
中用户原始评分与真实兴趣偏好存在偏差、且评分
Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１６，３９（１）：５２－６４（ｉｎ Ｃｈｉｎｅｓｅ）
等级分布极度不均衡的问题．在推荐效果方面，将本
（王智圣，李琪，汪静等．基于隐式用户反馈数据流的实时个
文提出的ＨＲＳＭ算法与４种较为经典的推荐算法 性化推荐．计算机学报，２０１６，３９（１）：５２－６４）
ＩｔｅｍＫＮＮ算法、ＭＦ算法、ＳＶＤ＋＋算法、ＨＦＴ算 ［７］ Ｚｈａｎｇ Ｆ，Ｙｕａｎ Ｎ Ｊ，Ｌｉａｎ Ｄ，ｅｔ ａｌ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｋｎｏｗｌｅｄｇｅ
ｂａｓｅ ｅｍｂｅｄｄｉｎｇ ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
法进行对比，结果表明本文提出的ＨＲＳＭ算法在均
２２ｎｄ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ
方误差评价指标（ＭＳＥ）上有显著的改善．在ＴｏｐＮ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１６：
推荐上，通过与上述４种推荐算法和当前较流行的 ３５３－３６２
基于深度学习的ＤＭＦ算法和 ＮＣＦ算法进行对比
［８］ Ｈｕａｎｇ Ｚｈｅｎ－Ｈｕａ，Ｚｈａｎｇ Ｊｉａ－Ｗｅｎ，Ｔｉａｎ Ｃｈｕｎ－Ｑｉ，ｅｔ ａｌ．
Ｓｕｒｖｅｙ ｏｎ ｌｅａｒｎｉｎｇ－ｔｏ－ｒａｎｋ ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｌｇｏｒｉｔｈｍ．
实验，结果显示本文提出的 ＨＲＳＭ算法在ＨＲ＠Ｎ
Ｊｏｕｒｎａｌ ｏｆ Ｓｏｆｔｗａｒｅ，２０１６，２７（３）：６９１－７１３（ｉｎ Ｃｈｉｎｅｓｅ）
和ＮＤＣＧ＠Ｎ均取得了较好的成绩．这表明在推荐 （黄震华，张佳雯，田春岐等．基于排序学习的推荐算法研究
模型中融入物品的内容描述视图，及对辅助信息建 综述．软件学报，２０１６，２７（３）：６９１－７１３）
模，可以提高推荐的准确性，一定程度上解决推荐系
［９］ Ｋａｒａｔｚｏｇｌｏｕ Ａ，Ｂａｌｔｒｕｎａｓ Ｌ，Ｓｈｉ Ｙ．Ｌｅａｒｎｉｎｇ ｔｏ ｒａｎｋ ｆｏｒ
ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ７ｔｈ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ
统面临的冷启动问题．
ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｈｏｎｇ Ｋｏｎｇ，Ｃｈｉｎａ，２０１３：４９３－４９４
本文提出了基于用户评论的深度情感分析与多 ［１０］ Ｚｈａｎｇ Ｙ，Ｚｈａｎｇ Ｈ，Ｚｈａｎｇ Ｍ，ｅｔ ａｌ．Ｄｏ ｕｓｅｒｓ ｒａｔｅ ｏｒ ｒｅｖｉｅｗ？：
源推荐视图协同融合的混合推荐方法，从上下文层 Ｂｏｏｓｔ ｐｈｒａｓｅ－ｌｅｖｅｌ ｓｅｎｔｉｍｅｎｔ ｌａｂｅｌｉｎｇ ｗｉｔｈ ｒｅｖｉｅｗ－ｌｅｖｅｌ ｓｅｎｔｉｍｅｎｔ
ｃｌａｓｓｉｆｉｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３７ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ
面对用户评论的短文本进行语义分析和情感计算．
ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ＆Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ
通过利用段落向量对物品内容描述的短文本进行相 Ｒｅｔｒｉｅｖａｌ．Ｇｏｌｄ Ｃｏａｓｔ，Ａｕｓｔｒａｌｉａ，２０１４：１０２７－１０３０
似度计算，并基于协同训练的策略来解决多推荐视 ［１１］ Ｃｈｅｎ Ｌｏｎｇ，Ｇｕａｎ Ｚｉ－Ｙｕ，Ｈｅ Ｊｉｎ－Ｈｏｎｇ，ｅｔ ａｌ．Ａ ｓｕｒｖｅｙ ｏｎ
图的融合问题．由于本文提出的ＨＲＳＭ推荐算法兼
ｓｅｎｔｉｍｅｎｔ ｃｌａｓｓｉｆｉｃａｔｉｏｎ．Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｒｅｓｅａｒｃｈ ａｎｄ
Ｄｅｖｅｌｏｐｍｅｎｔ，２０１７，５４（６）：１１５０－１１７０（ｉｎ Ｃｈｉｎｅｓｅ）
顾了物品的内容信息，故有效地解决了推荐系统的
（陈龙，管子玉，何金红等．情感分类研究进展．计算机研究
冷启动问题，同时提高了推荐系统的推荐召回率．下 与发展，２０１７，５４（６）：１１５０－１１７０）
一步的工作，我们拟从互联网电商网站上收集并整 ［１２］ Ｚｈａｎｇ Ｗ，Ｗａｎｇ Ｊ．Ａ ｃｏｌｌｅｃｔｉｖｅ Ｂａｙｅｓｉａｎ Ｐｏｉｓｓｏｎ ｆａｃｔｏｒｉｚａｔｉｏｎ
理推荐系统数据集，对本文提出的推荐算法进行评
ｍｏｄｅｌ ｆｏｒ ｃｏｌｄ－ｓｔａｒｔ ｌｏｃａｌ ｅｖｅｎｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｏｆ ｔｈｅ ２１ｓｔ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
测、改进和参数调优设置，设计合理的推荐过滤和排
Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓｙｄｎｅｙ，Ａｕｓｔｒａｌｉａ，
序算法，进一步用本文提出的ＨＲＳＭ推荐算法在推 ２０１５：１４５５－１４６４
荐准确率和召回率等方面进行实验． ［１３］ Ｈｕａｎｇ Ｌｉ－Ｗｅｉ，Ｊｉａｎｇ Ｂｉ－Ｔａｏ，Ｌｖ Ｓｈｏｕ－Ｙｅ，ｅｔ ａｌ．Ｓｕｒｖｅｙ ｏｎ １３３２ 计 算 机 学 报 ２０１９年
ｄｅｅｐ ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｒｅｇｒｅｓｓｉｏｎ ｗｉｔｈ ｒｅｖｉｅｗ－ｌｅｖｅｌ ｅｘｐｌａｎａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１８，４１（７）：１６１９－１６４７（ｉｎ Ｃｈｉｎｅｓｅ） ２０１８Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．
（黄立威，江碧涛，吕守业等．基于深度学习的推荐系统研究 Ｌｙｏｎ，Ｆｒａｎｃｅ，２０１８：１５８３－１５９２
综述．计算机学报，２０１８，４１（７）：１６１９－１６４７） ［２６］ Ｈａｎ Ｘ，Ｓｈｉ Ｃ，Ｗａｎｇ Ｓ，ｅｔ ａｌ．Ａｓｐｅｃｔ－ｌｅｖｅｌ ｄｅｅｐ ｃｏｌｌａｂｏｒａｔｉｖｅ
［１４］ Ｌｉ Ｌｉｎ，Ｌｉｕ Ｊｉｎ－Ｈａｎｇ，Ｍｅｎｇ Ｘｉａｎｇ－Ｆｕ，ｅｔ ａｌ．Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｆｉｌｔｅｒｉｎｇ ｖｉａ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｍｏｄｅｌｓ ｂｙ ｅｘｐｌｏｉｔｉｎｇ ｒａｔｉｎｇ ｍａｔｒｉｘ ａｎｄ ｒｅｖｉｅｗ ｔｅｘｔ．Ｃｈｉｎｅｓｅ ｏｆ ｔｈｅ ２７ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ
Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１８，４１（７）：１５５９－１５７３（ｉｎ Ｃｈｉｎｅｓｅ） Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｓｔｏｃｋｈｏｌｍ，Ｓｗｅｄｅｎ，２０１８：３３９３－３３９９
（李琳，刘锦行，孟祥福等．融合评分矩阵与评论文本的商品 ［２７］ Ｌｉｕ Ｚｈｉ－Ｙｕａｎ，Ｓｕｎ Ｍａｏ－Ｓｏｎｇ，Ｌｉｎ Ｙａｎ－Ｋａｉ，ｅｔ ａｌ．Ｋｎｏｗｌｅｄｇｅ
推荐模型．计算机学报，２０１８，４１（７）：１５５９－１５７３） ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ：Ａ ｒｅｖｉｅｗ．Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ
［１５］ Ｘｉｅ Ｘｉｎ－Ｑｉａｎｇ，Ｙａｎｇ Ｘｉａｏ－Ｃｈｕｎ，Ｗａｎｇ Ｂｉｎ，ｅｔ ａｌ．Ｍｕｌｔｉ－ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ，２０１６，５３（２）：１－１６（ｉｎ Ｃｈｉｎｅｓｅ）
ｆｅａｔｕｒｅ ｆｕｓｅｄ ｓｏｆｔｗａｒｅ ｄｅｖｅｌｏｐｅｒ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．Ｊｏｕｒｎａｌ ｏｆ
（刘知远，孙茂松，林衍凯等．知识表示学习研究进展．计算
Ｓｏｆｔｗａｒｅ，２０１８，２９（８）：２３０６－２３２１（ｉｎ Ｃｈｉｎｅｓｅ） 机研究与发展，２０１６，５３（２）：１－１６）
（谢新强，杨晓春，王斌等．一种多特征融合的软件开发者推 ［２８］ Ｗａｎｇ Ｐ，Ｘｕ Ｊ，Ｘｕ Ｂ，ｅｔ ａｌ．Ｓｅｍａｎｔｉｃ ｃｌｕｓｔｅｒｉｎｇ ａｎｄ ｃｏｎｖｏ－
荐．软件学报，２０１８，２９（８）：２３０６－２３２１） ｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｆｏｒ ｓｈｏｒｔ ｔｅｘｔ ｃａｔｅｇｏｒｉｚａｔｉｏｎ／／
［１６］ Ｐａｎ Ｙｉ－Ｔｅｎｇ，Ｈｅ Ｆａ－Ｚｈｉ，Ｙｕ Ｈａｉ－Ｐｉｎｇ．Ｓｏｃｉａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ５３ｒｄ Ａｎｎｕａｌ Ｍｅｅｔｉｎｇ ｏｆ ｔｈｅ Ａｓｓｏｃｉａｔｉｏｎ
ｆｏｒ Ｃｏｍｐｕｔａｔｉｏｎａｌ Ｌｉｎｇｕｉｓｔｉｃｓ．Ｂｅｉｊｉｎｇ，Ｃｈｉｎａ，２０１５：３５２－
ａｌｇｏｒｉｔｈｍ ｕｓｉｎｇ ｉｍｐｌｉｃｉｔ ｓｉｍｉｌａｒｉｔｙ ｉｎ ｔｒｕｓｔ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ
ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１８，４１（１）：６５－８１（ｉｎ Ｃｈｉｎｅｓｅ） ３５７
（潘一腾，何发智，于海平．一种基于信任关系隐含相似度的 ［２９］ Ｗａｎｇ Ｚｈｏｎｇ－Ｙｕａｎ，Ｃｈｅｎ Ｊｉａｎ－Ｐｅｎｇ，Ｗａｎｇ Ｈａｉ－Ｘｕｎ，Ｗｅｎ
社会化推荐算法．计算机学报，２０１８，４１（１）：６５－８１） Ｊｉ－Ｒｏｎｇ．Ｓｈｏｒｔ ｔｅｘｔ ｕｎｄｅｒｓｔａｎｄｉｎｇ：Ａ ｓｕｒｖｅｙ．Ｊｏｕｒｎａｌ ｏｆ
［１７］ Ｋｏｎｇ Ｘｉｎ－Ｘｉｎ，Ｓｕ Ｂｅｎ－Ｃｈａｎｇ，Ｗａｎｇ Ｈｏｎｇ－Ｚｈｉ，ｅｔ ａｌ．Ｒｅｓｅａｒｃｈ
Ｃｏｍｐｕｔｅｒ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ，２０１６，５３（２）：２６２－２６９（ｉｎ
Ｃｈｉｎｅｓｅ）
ｏｎ ｔｈｅ ｍｏｄｅｌｉｎｇ ａｎｄ ｒｅｌａｔｅｄ ａｌｇｏｒｉｔｈｍｓ ｏｆ ｌａｂｅｌ－ｗｅｉｇｈｔ ｒａｔｉｎｇ
（王仲远，陈健鹏，王海勋，文继荣．短文本理解研究．计算
ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，
机研究与发展，２０１６，５３（２）：２６２－２６９）
２０１７，４０（６）：１４４０－１４５２（ｉｎ Ｃｈｉｎｅｓｅ）
［３０］ Ｍａ Ｗ，Ｚｈａｎｇ Ｍ，Ｗａｎｇ Ｃ，ｅｔ ａｌ．Ｙｏｕｒ ｔｗｅｅｔｓ ｒｅｖｅａｌ ｗｈａｔ
（孔欣欣，苏本昌，王宏志等．基于标签权重评分的推荐模型
ｙｏｕ ｌｉｋｅ：Ｉｎｔｒｏｄｕｃｉｎｇ ｃｒｏｓｓ－ｍｅｄｉａ ｃｏｎｔｅｎｔ ｉｎｆｏｒｍａｔｉｏｎ ｉｎｔｏ
及算法研究．计算机学报，２０１７，４０（６）：１４４０－１４５２）
ｍｕｌｔｉ－ｄｏｍａｉｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２７ｔｈ
［１８］ Ｔｉａｎ Ｃｈａｏ，Ｑｉｎ Ｚｕｏ－Ｙａｎ，Ｚｈｕ Ｑｉｎｇ，ｅｔ ａｌ．ＳｕｐｅｒＲａｎｋ：Ａｎ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．
ｉｎｔｅｌｌｉｇｅｎｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ ｂａｓｅｄ ｏｎ ｒｅｖｉｅｗ ａｎａｌｙｓｉｓ．
Ｓｔｏｃｋｈｏｌｍ，Ｓｗｅｄｅｎ，２０１８：３４８４－３４９０
Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ，２０１０，４７（１）：
［３１］ Ｌｉａｎ Ｊ，Ｚｈａｎｇ Ｆ，Ｘｉｅ Ｘ，ｅｔ ａｌ．Ｔｏｗａｒｄｓ ｂｅｔｔｅｒ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ
４９４－４９８（ｉｎ Ｃｈｉｎｅｓｅ）
ｌｅａｒｎｉｎｇ ｆｏｒ ｐｅｒｓｏｎａｌｉｚｅｄ ｎｅｗｓ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ：Ａ ｍｕｌｔｉ－
（田超，覃左言，朱青等．ＳｕｐｅｒＲａｎｋ：基于评论分析的智能
ｃｈａｎｎｅｌ ｄｅｅｐ ｆｕｓｉｏｎ ａｐｐｒｏａｃｈ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２７ｔｈ
推荐系统．计算机研究与发展，２０１０，４７（１）：４９４－４９８）
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．
［１９］ Ｓｈｍｕｅｌｉ Ｅ，Ｋａｇｉａｎ Ａ，Ｋｏｒｅｎ Ｙ，ｅｔ ａｌ．Ｃａｒｅ ｔｏ ｃｏｍｍｅｎｔ？：
Ｓｔｏｃｋｈｏｌｍ，Ｓｗｅｄｅｎ，２０１８：３８０５－３８１１
Ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ ｆｏｒ ｃｏｍｍｅｎｔｉｎｇ ｏｎ ｎｅｗｓ ｓｔｏｒｉｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
［３２］ Ｎｇｕｙｅｎ Ｔ Ｔ，Ｈｕｉ Ｐ Ｍ，Ｈａｒｐｅｒ Ｆ Ｍ，ｅｔ ａｌ．Ｅｘｐｌｏｒｉｎｇ ｔｈｅ
ｏｆ ｔｈｅ ２１ｓｔ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．
ｆｉｌｔｅｒ ｂｕｂｂｌｅ：Ｔｈｅ ｅｆｆｅｃｔ ｏｆ ｕｓｉｎｇ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｏｎ
Ｌｙｏｎ，Ｆｒａｎｃｅ，２０１２：４２９－４３８
ｃｏｎｔｅｎｔ ｄｉｖｅｒｓｉｔｙ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２３ｒｄ Ｉｎｔｅｒｎａｔｉｏｎａｌ
［２０］ Ｚｈａｎｇ Ｙ，Ｔａｎ Ｙ，Ｚｈａｎｇ Ｍ，ｅｔ ａｌ．Ｃａｔｃｈ ｔｈｅ ｂｌａｃｋ ｓｈｅｅｐ： Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｓｅｏｕｌ，Ｋｏｒｅａ，２０１４：６７７－
Ｕｎｉｆｉｅｄ ｆｒａｍｅｗｏｒｋ ｆｏｒ ｓｈｉｌｌｉｎｇ ａｔｔａｃｋ ｄｅｔｅｃｔｉｏｎ ｂａｓｅｄ ｏｎ
６８６
ｆｒａｕｄｕｌｅｎｔ ａｃｔｉｏｎ ｐｒｏｐａｇａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ ［３３］ Ｗｕ Ｚ，Ｗｕ Ｊ，Ｃａｏ Ｊ，ｅｔ ａｌ．ＨｙＳＡＤ：Ａ ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．
ｈｙｂｒｉｄ ｓｈｉｌｌｉｎｇ ａｔｔａｃｋ ｄｅｔｅｃｔｏｒ ｆｏｒ ｔｒｕｓｔｗｏｒｔｈｙ ｐｒｏｄｕｃｔ
Ｂｕｅｎｏｓ Ａｉｒｅｓ，Ａｒｇｅｎｔｉｎａ，２０１５：２４０８－２４１４ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １８ｔｈ ＡＣＭ ＳＩＧＫＤＤ
［２１］ Ｗｕ Ｙ，ＤｕＢｏｉｓ Ｃ，Ｚｈｅｎｇ Ａ Ｘ，ｅｔ ａｌ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｄｅｎｏｉｓｉｎｇ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ
ａｕｔｏ－ｅｎｃｏｄｅｒｓ ｆｏｒ ｔｏｐ－Ｎｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ Ｍｉｎｉｎｇ．Ｂｅｉｊｉｎｇ，Ｃｈｉｎａ，２０１２：９８５－９９３
ｏｆ ｔｈｅ ９ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ ［３４］ Ｚｈａｎｇ Ｍ，Ｔａｎｇ Ｊ，Ｚｈａｎｇ Ｘ，ｅｔ ａｌ．Ａｄｄｒｅｓｓｉｎｇ ｃｏｌｄ ｓｔａｒｔ ｉｎ
Ｄａｔａ Ｍｉｎｉｎｇ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１６：１５３－１６２ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ：Ａ ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ｃｏ－ｔｒａｉｎｉｎｇ ａｌｇｏｒｉｔｈｍ
［２２］ Ｃｈｅｎ Ｌ，Ｃｈｅｎ Ｇ，Ｗａｎｇ Ｆ．Ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｂａｓｅｄ ｏｎ ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３７ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ
ｕｓｅｒ ｒｅｖｉｅｗｓ：ｔｈｅ ｓｔａｔｅ ｏｆ ｔｈｅ ａｒｔ．Ｕｓｅｒ Ｍｏｄｅｌｉｎｇ ａｎｄ Ｕｓｅｒ－ ｏｎ Ｒｅｓｅａｒｃｈ ＆Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ｇｏｌｄ
Ａｄａｐｔｅｄ Ｉｎｔｅｒａｃｔｉｏｎ，２０１５，２５（２）：９９－１５４ Ｃｏａｓｔ，Ａｕｓｔｒａｌｉａ，２０１４：７３－８２
［２３］ Ｚｈａｎｇ Ｗ，Ｙｕａｎ Ｑ，Ｈａｎ Ｊ，ｅｔ ａｌ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｍｕｌｔｉ－ｌｅｖｅｌ ［３５］ Ｄｉｎｇ Ｊ，Ｙｕ Ｇ，Ｈｅ Ｘ，ｅｔ ａｌ．Ｉｍｐｒｏｖｉｎｇ ｉｍｐｌｉｃｉｔ ｒｅｃｏｍｍｅｎｄｅｒ
ｅｍｂｅｄｄｉｎｇ ｌｅａｒｎｉｎｇ ｆｒｏｍ ｒｅｖｉｅｗｓ ｆｏｒ ｒａｔｉｎｇ ｐｒｅｄｉｃｔｉｏｎ／／ ｓｙｓｔｅｍｓ ｗｉｔｈ ｖｉｅｗ ｄａｔａ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２７ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２５ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｓｔｏｃｋｈｏｌｍ，Ｓｗｅｄｅｎ，
Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１６：２９８６－２９９２ ２０１８：３３４３－３３４９
［２４］ Ｚｈｅｎｇ Ｌ，Ｎｏｒｏｏｚｉ Ｖ，Ｙｕ Ｐ Ｓ．Ｊｏｉｎｔ ｄｅｅｐ ｍｏｄｅｌｉｎｇ ｏｆ ｕｓｅｒｓ ［３６］ Ｗａｎｇ Ｘ，Ｈｅ Ｘ，Ｆｅｎｇ Ｆ，ｅｔ ａｌ．ＴＥＭ：Ｔｒｅｅ－ｅｎｈａｎｃｅｄ ｅｍｂｅｄｄｉｎｇ
ａｎｄ ｉｔｅｍｓ ｕｓｉｎｇ ｒｅｖｉｅｗｓ ｆｏｒ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｍｏｄｅｌ ｆｏｒ ｅｘｐｌａｉｎａｂｌｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｔｈｅ １０ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ ２０１８Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．
Ｄａｔａ Ｍｉｎｉｎｇ．Ｃａｍｂｒｉｄｇｅ，Ｕｎｉｔｅｄ Ｋｉｎｇｄｏｍ，２０１７：４２５－４３４ Ｌｙｏｎ，Ｆｒａｎｃｅ，２０１８：１５４３－１５５２
［２５］ Ｃｈｅｎ Ｃ，Ｚｈａｎｇ Ｍ，Ｌｉｕ Ｙ，ｅｔ ａｌ．Ｎｅｕｒａｌ ａｔｔｅｎｔｉｏｎａｌ ｒａｔｉｎｇ ［３７］ Ｐｅｒｏ，Ｈｏｒｖｔｈ Ｔ．Ｏｐｉｎｉｏｎ－ｄｒｉｖｅｎ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ ｆｏｒ ６期 张宜浩等：基于用户评论的深度情感分析和多视图协同融合的混合推荐方法 １３３３
ｒａｔｉｎｇ ｐｒｅｄｉｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２１ｓｔ Ｉｎｔｅｒｎａｔｉｏｎａｌ ｔｈｅ １０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｕｓｅｒ Ｍｏｄｅｌｉｎｇ，Ａｄａｐｔａｔｉｏｎ，ａｎｄ Ｐｅｒｓｏｎａｌｉｚａｔｉｏｎ． Ｈｏｎｇ Ｋｏｎｇ，Ｃｈｉｎａ，２００１：２８５－２９５
Ｒｏｍｅ，Ｉｔａｌｙ，２０１３：１－１３ ［４３］ Ｋｏｒｅｎ Ｙ，Ｂｅｌｌ Ｒ，Ｖｏｌｉｎｓｋｙ Ｃ．Ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ ｔｅｃｈｎｉｑｕｅｓ
［３８］ Ｍｉｋｏｌｏｖ Ｔ，Ｓｕｔｓｋｅｖｅｒ Ｉ，Ｃｈｅｎ Ｋ，ｅｔ ａｌ．Ｄｉｓｔｒｉｂｕｔｅｄ ｒｅｐｒｅ－ ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ．Ｃｏｍｐｕｔｅｒ，２００９，４２（８）：４２－４９
ｓｅｎｔａｔｉｏｎｓ ｏｆ ｗｏｒｄｓ ａｎｄ ｐｈｒａｓｅｓ ａｎｄ ｔｈｅｉｒ ｃｏｍｐｏｓｉｔｉｏｎａｌｉｔｙ／／ ［４４］ Ｋｏｒｅｎ Ｙ．Ｆａｃｔｏｒｉｚａｔｉｏｎ ｍｅｅｔｓ ｔｈｅ ｎｅｉｇｈｂｏｒｈｏｏｄ：Ａ ｍｕｌｔｉｆａｃｅｔｅｄ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｍｏｄｅｌ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １４ｔｈ ＡＣＭ
Ｓｙｓｔｅｍｓ．Ｌａｋｅ Ｔａｈｏｅ，ＵＳＡ，２０１３：３１１１－３１１９ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ
［３９］ Ｌｅ Ｑ，Ｍｉｋｏｌｏｖ Ｔ．Ｄｉｓｔｒｉｂｕｔｅｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｏｆ ｓｅｎｔｅｎｃｅｓ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｌａｓ Ｖｅｇａｓ，ＵＳＡ，２００８：４２６－４３４
ａｎｄ ｄｏｃｕｍｅｎｔｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ［４５］ Ｘｕｅ Ｈ Ｊ，Ｄａｉ Ｘ，Ｚｈａｎｇ Ｊ，ｅｔ ａｌ．Ｄｅｅｐ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ
ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｂｅｉｊｉｎｇ，Ｃｈｉｎａ，２０１４：１１８８－１１９６ ｍｏｄｅｌｓ ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２６ｔｈ
［４０］ ＭｃＡｕｌｅｙ Ｊ，Ｌｅｓｋｏｖｅｃ Ｊ．Ｈｉｄｄｅｎ ｆａｃｔｏｒｓ ａｎｄ ｈｉｄｄｅｎ ｔｏｐｉｃｓ： Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．
Ｕｎｄｅｒｓｔａｎｄｉｎｇ ｒａｔｉｎｇ ｄｉｍｅｎｓｉｏｎｓ ｗｉｔｈ ｒｅｖｉｅｗ ｔｅｘｔ／／Ｐｒｏｃｅｅｄｉｎｇｓ Ｍｅｌｂｏｕｒｎｅ，Ａｕｓｔｒａｌｉａ，２０１７：３２０３－３２０９
ｏｆ ｔｈｅ ７ｔｈ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｈｏｎｇ ［４６］ Ｈｅ Ｘ，Ｌｉａｏ Ｌ，Ｚｈａｎｇ Ｈ，ｅｔ ａｌ．Ｎｅｕｒａｌ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ
Ｋｏｎｇ，Ｃｈｉｎａ，２０１３：１６５－１７２ ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ
［４１］ Ｑｉｕ Ｌ，Ｇａｏ Ｓ，Ｃｈｅｎｇ Ｗ，ｅｔ ａｌ．Ａｓｐｅｃｔ－ｂａｓｅｄ ｌａｔｅｎｔ ｆａｃｔｏｒ Ｗｉｄｅ Ｗｅｂ．Ｐｅｒｔｈ，Ａｕｓｔｒａｌｉａ，２０１７：１７３－１８２
ｍｏｄｅｌ ｂｙ ｉｎｔｅｇｒａｔｉｎｇ ｒａｔｉｎｇｓ ａｎｄ ｒｅｖｉｅｗｓ ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ［４７］ Ｇａｎｔｎｅｒ Ｚ，Ｒｅｎｄｌｅ Ｓ，Ｆｒｅｕｄｅｎｔｈａｌｅｒ Ｃ，ｅｔ ａｌ．ＭｙＭｅｄｉａＬｉｔｅ：
ｓｙｓｔｅｍ．Ｋｎｏｗｌｅｄｇｅ－Ｂａｓｅｄ Ｓｙｓｔｅｍｓ，２０１６，１１０：２３３－２４３ Ａ ｆｒｅｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ ｌｉｂｒａｒｙ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ５ｔｈ
［４２］ Ｓａｒｗａｒ Ｂ，Ｋａｒｙｐｉｓ Ｇ，Ｋｏｎｓｔａｎ Ｊ，ｅｔ ａｌ．Ｉｔｅｍ－ｂａｓｅｄ ｃｏｌｌａｂｏ－ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｃｈｉｃａｇｏ，ＵＳＡ，
ｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｌｇｏｒｉｔｈｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ２０１１：３０５－３０８
ＺＨＡＮＧ Ｙｉ－Ｈａｏ，Ｐｈ．Ｄ．，ａｓｓｏｃｉａｔｅ ＺＨＵ Ｘｉａｏ－Ｆｅｉ，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ
ｐｒｏｆｅｓｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｉｎｃｌｕｄｅ ｂｉｇ ｄａｔａ ｓｅａｒｃｈ ａｎｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ，ｗｅｂ ｍｉｎｉｎｇ，
ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ，ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ．
ａｎｄ ｎａｔｕｒａｌ ｌａｎｇｕａｇｅ ｐｒｏｃｅｓｓｉｎｇ． ＸＵ Ｃｈｕａｎ－Ｙｕｎ，Ｐｈ．Ｄ．，ａｓｓｏｃｉａｔｅ ｐｒｏｆｅｓｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ
ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ａｎｄ ｉｍａｇｅ ｐｒｏｃｅｓｓｉｎｇ．
ＤＯＮＧ Ｓｈｉ－Ｄｕ，Ｐｈ．Ｄ．，ａｓｓｏｃｉａｔｅ ｐｒｏｆｅｓｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ
ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ａｎｄ ｉｍａｇｅ ｐｒｏｃｅｓｓｉｎｇ．
Ｂａｃｋｇｒｏｕｎｄ
Ｗｉｔｈ ｔｈｅ ｒａｐｉｄ ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ Ｅ－ｃｏｍｍｅｒｃｅ ａｎｄ ｓｏｃｉａｌ ｕｓｅｒ ｒｅａｃｈ ｉｓ ｅｘｔｅｎｓｉｖｅ．
ｎｅｔｗｏｒｋｓ，ｉｎｆｏｒｍａｔｉｏｎ ｏｖｅｒｌｏａｄ ｉｓ ｂｅｃｏｍｉｎｇ ａ ｓｅｒｉｏｕｓ ｐｒｏｂｌｅｍ． Ｉｎ ｔｈｉｓ ｐａｐｅｒ，ｗｅ ｆｏｃｕｓ ｏｎ ｔｈｅ ｆｏｌｌｏｗｉｎｇ ｉｓｓｕｅｓ：（１）ｓｔｕｄｙ
Ａｓ ｔｈｅ ｍｏｓｔ ｅｆｆｅｃｔｉｖｅ ｔｏｏｌ ｆｏｒ ｓｏｌｖｉｎｇ ｉｎｆｏｒｍａｔｉｏｎ ｏｖｅｒｌｏａｄ， ｔｈｅ ｄｉｓｔｒｉｂｕｔｅｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｏｆ ｔｈｅ ｓｈｏｒｔ ｔｅｘｔ ｂａｓｅｄ ｏｎ ｔｈｅ
ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍｓ ｈａｖｅ ａｔｔｒａｃｔｅｄ ａｔｔｅｎｔｉｏｎ ｉｎ ｂｏｔｈ ｐａｒａｇｒａｐｈ ｖｅｃｔｏｒ，ａｎｄ ｒｅａｌｉｚｅ ｔｈｅ ｓｅｎｔｉｍｅｎｔ ａｎａｌｙｓｉｓ ｏｆ ｔｈｅ
ａｃａｄｅｍｉａ ａｎｄ ｉｎｄｕｓｔｒｙ．Ｃｕｒｒｅｎｔｌｙ，ｍｏｓｔ ｏｆ ｔｈｅ ｖａｒｉｏｕｓ ｔｙｐｅｓ ｕｓｅｒ ｒｅｖｉｅｗ ｏｎ ｔｈｅ ｃｏｎｔｅｘｔ ｓｅｍａｎｔｉｃ ｌｅｖｅｌ．Ｔｈｅ ｐｒｏｐｏｓｅｄ
ｏｆ ｒｅｃｏｍｍｅｎｄｅｒ ｔｅｃｈｎｉｑｕｅｓ ｕｓｅ ｕｓｅｒ－ｐｒｏｖｉｄｅｄ ｒａｔｉｎｇｓ ｔｏ ｉｎｆｅｒ ｍｅｔｈｏｄ ｗｉｌｌ ｓｏｌｖｅ ｔｈｅ ｐｒｏｂｌｅｍ ｔｈａｔ ｔｈｅｒｅ ｉｓ ａ ｇｒｅａｔ ｄｅｖｉａｔｉｏｎ
ｕｓｅｒ ｐｒｅｆｅｒｅｎｃｅｓ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｔｅｃｈｎｉｑｕｅｓ ｐｅｒｆｏｒｍ ｂｅｔｗｅｅｎ ｔｈｅ ｕｓｅｒ’ｓ ｒａｔｉｎｇ ａｎｄ ｒｅａｌ ｉｎｔｅｒｅｓｔ ｐｒｅｆｅｒｅｎｃｅ，ａｎｄ
ｗｅｌｌ ｗｈｅｎ ｔｈｅｒｅ ｉｓ ｓｕｆｆｉｃｉｅｎｔ ｒａｔｉｎｇ ｉｎｆｏｒｍａｔｉｏｎ．Ｈｏｗｅｖｅｒ， ａｌｓｏ ｓｏｌｖｅ ｔｈｅ ｅｘｔｒｅｍｅ ｉｍｂａｌａｎｃｅ ｐｒｏｂｌｅｍ ｏｆ ｔｈｅ ｕｓｅｒ ｒａｔｉｎｇ
ｔｈｅｉｒ ｅｆｆｅｃｔｉｖｅｎｅｓｓ ｉｓ ｌｉｍｉｔｅｄ ｗｈｅｎ ｔｈｅ ｗｅｌｌ－ｋｎｏｗｎ ｒａｔｉｎｇ ｄｉｓｔｒｉｂｕｔｉｏｎ；（２）ｓｔｕｄｙ ｔｈｅ ｓｉｍｉｌａｒｉｔｙ ｃａｌｃｕｌａｔｉｏｎ ｍｅｔｈｏｄ ｏｆ
ｓｐａｒｓｉｔｙ ｐｒｏｂｌｅｍ ｏｃｃｕｒｓ，ｄｕｅ ｔｏ ｔｈｅ ｐｏｏｒ ｃｏｖｅｒａｇｅ ｏｆ ｒｅｃｏｍ－ ｓｈｏｒｔ ｔｅｘｔ ｂａｓｅｄ ｏｎ ｗｏｒｄ ｅｍｂｅｄｄｉｎｇ ａｎｄ ｐａｒａｇｒａｐｈ ｖｅｃｔｏｒ，
ｍｅｎｄａｔｉｏｎ ｓｐａｃｅ，ｏｒ ｔｈｅ ｄｉｆｆｉｃｕｌｔｙ ｉｎ ｌｅｔｔｉｎｇ ｕｓｅｒｓ ｅｘｐｒｅｓｓ ａｎｄ ｓｔｕｄｙ ｔｈｅ ｆｕｓｉｏｎ ｍｅｔｈｏｄ ｏｆ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｖｉｅｗ ｂａｓｅｄ
ｔｈｅｉｒ ｐｒｅｆｅｒｅｎｃｅｓ ａｓ ｓｃａｌａｒ ｒａｔｉｎｇｓ ｏｎ ｉｔｅｍｓ．Ｏｕｒｓ ｒｅｓｅａｒｃｈ ｏｎ ｏｎ ｃｏｌｌａｂｏｒａｔｉｖｅ ｔｒａｉｎｉｎｇ．Ｔｈｅ ｐｒｏｐｏｓｅｄ ｍｅｔｈｏｄ ｗｉｌｌ ａｄｄｒｅｓｓ
ｕｓｅｒ’ｓ ｒａｔｉｎｇｓ ａｌｓｏ ｓｈｏｗｓ ｔｈａｔ ｔｈｅｒｅ ｉｓ ａ ｇｒｅａｔ ｄｅｖｉａｔｉｏｎ ｔｈｅ ｃｈａｌｌｅｎｇｅ ｏｆ ｓｉｍｉｌａｒｉｔｙ ｃａｌｃｕｌａｔｉｏｎ ｏｆ ｉｔｅｍ ｃｏｎｔｅｎｔｓ，ａｎｄ
ｂｅｔｗｅｅｎ ｔｈｅ ｕｓｅｒｓ’ｒａｔｉｎｇ ａｎｄ ｒｅａｌ ｉｎｔｅｒｅｓｔ ｐｒｅｆｅｒｅｎｃｅ．Ｃｏｎｔｅｎｔ－ ｓｏｌｖｅ ｔｈｅ ｐｒｏｂｌｅｍ ｏｆ ｔｈｅ ｌａｃｋ ｏｆ ｓｕｆｆｉｃｉｅｎｔ ｌａｂｅｌｅｄ ｄａｔａ ｆｏｒ
ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ａｐｐｒｏａｃｈｅｓ ｈａｖｅ ｂｅｅｎ ｄｅｖｅｌｏｐｅｄ ｔｈａｔ ｒｅｌｙ ｍｏｄｅｌｉｎｇ．Ｗｅ ｓｔｕｄｙ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｏｎ ｔｈｅ ｂａｓｉｓ ｏｆ ｕｓｅｒ’ｓ
ｉｎｓｔｅａｄ ｏｎ ｔｈｅ ｃｏｎｔｅｎｔ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｏｆ ｉｔｅｍｓ ｔｏ ｌｏｃａｔｅ ｉｔｅｍｓ ｂｅｈａｖｉｏｒ ａｎａｌｙｓｉｓ，ｗｈｉｃｈ ｗｉｌｌ ｆｏｃｕｓ ｏｎ ｓｅｎｔｉｍｅｎｔ ｍｉｎｉｎｇ ａｎｄ
ｔｈａｔ ｈａｖｅ ｓｉｍｉｌａｒ ｃｏｎｔｅｎｔ ｔｏ ｉｔｅｍｓ ｔｈｅ ｔａｒｇｅｔ ｕｓｅｒ ｌｉｋｅｄ． ｄｅｅｐ ｓｅｍａｎｔｉｃ ａｎａｌｙｓｉｓ ｏｆ ｔｈｅ ｔｅｘｔ ｉｎｆｏｒｍａｔｉｏｎ，ａｎｄ ｗｉｌｌ
Ｈｏｗｅｖｅｒ，ｔｈｅｓｅ ｍｅｔｈｏｄｓ ａｒｅ ｓｔｉｌｌ ｉｎａｄｅｑｕａｔｅ，ｅｓｐｅｃｉａｌｌｙ ｃｏｎｓｅｑｕｅｎｔｉａｌｌｙ ａｃｈｉｅｖｅ ｔｈｅ ｉｎｔｅｇｒａｔｉｏｎ ｏｆ ｍｕｌｔｉ－ｒｅｃｏｍｍｅｎｄｅｄ
ｗｈｅｎ ｔｈｅ ｔａｒｇｅｔ ｕｓｅｒ ｈａｓ ｌｉｔｔｌｅ ｈｉｓｔｏｒｉｃａｌ ｄａｔａ．Ｔｈｅｙ ａｒｅ ａｌｓｏ ｖｉｅｗｓ ａｎｄ ｔｈｅ ｐｅｒｓｏｎａｌｉｚｅｄ ｎｅｅｄｓ ｏｆ ｕｓｅｒｓ．
ｏｆ ｌｉｍｉｔｅｄ ｕｓｅｆｕｌｎｅｓｓ ｗｈｅｎ ｔｈｅ ｓｐａｒｓｉｔｙ ｌｅｖｅｌ ｏｆ ｏｖｅｒａｌｌ ｄａｔａ ｉｓ Ｔｈｉｓ ｗｏｒｋ ｉｓ ｓｕｐｐｏｒｔｅｄ ｂｙ ｔｈｅ Ｎａｔｉｏｎａｌ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ
ｈｉｇｈ．Ａｔ ｐｒｅｓｅｎｔ，ｉｔ ｉｓ ａ ｒｅｃｅｎｔ ｄｅｖｅｌｏｐｍｅｎｔ ｔｒｅｎｄ ｔｏ ｄｏ Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｃｈｉｎａ（Ｎｏ．６１７０２０６３），ｔｈｅ Ｋｅｙ Ｐｒｏｊｅｃｔ ｏｆ
ｐｅｒｓｏｎａｌｉｚｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｔｈｒｏｕｇｈ ｆｕｓｉｎｇ ｍｕｌｔｉ－ｖｉｅｗ ｏｆ Ｃｈｏｎｇｑｉｎｇ Ｂａｓｉｃ Ｓｃｉｅｎｃｅ ａｎｄ Ｆｒｏｎｔｉｅｒ Ｔｅｃｈｎｏｌｏｇｙ Ｒｅｓｅａｒｃｈ
ｉｎｔｅｒｅｓｔ ｐｒｅｆｅｒｅｎｃｅｓ ｔｏ ｂｕｉｌｄ ｔｈｅ ｈｙｂｒｉｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ （Ｎｏ．ｃｓｔｃ２０１７ｊｃｙｊＢＸ００５９）．
ｍｏｄｅｌ，ａｓ ａ ｓｉｎｇｌｅ ｖｉｅｗ ｏｆ ｔｈｅ ｒｅｃｏｍｍｅｎｄｅｄ ｍｏｄｅｌ ｌｅａｄ ｔｏ --------------------------------------------------------------------------------- 第４２卷 第７期 计 算 机 学 报 Ｖｏｌ．４２ Ｎｏ．７
２０１９年７月 ＣＨＩＮＥＳＥ ＪＯＵＲＮＡＬ ＯＦ ＣＯＭＰＵＴＥＲＳ Ｊｕｌｙ ２０１９
基于融合结构的在线广告点击率预测模型
刘梦娟 曾贵川 岳 威 刘 瑶 秦志光
（电子科技大学信息与软件工程学院 成都 ６１００５４）
摘 要 点击率预测作为推荐系统和在线广告的关键环节，在学术界和工业界均受到了极大的关注．论文首先对
几种典型的点击率预测模型进行研究，然后探索了基于融合结构的深度学习方法，并在此基础上提出一种基于融
合结构的点击率预测模型，该模型能够灵活融合不同结构的深度神经网络来分别学习原始高维稀疏特征的高阶表
示，从而使点击率预测模型能够利用更丰富的高阶特征信息．论文利用真实数据集来评价模型的预测性能，实验结
果显示，基于融合结构的深度学习预测模型，能够比传统的点击率预测模型以及最新的基于深度学习的预测模型
获得更好的性能．
关键词 点击率预测；逻辑回归；因子分解机；深度神经网络；融合结构
中图法分类号 ＴＰ１８ ＤＯＩ号 １０．１１８９７／ＳＰ．Ｊ．１０１６．２０１９．０１５７０
Ａ Ｈｙｂｒｉｄ Ｎｅｔｗｏｒｋ Ｂａｓｅｄ ＣＴＲ Ｐｒｅｄｉｃｔｉｏｎ Ｍｏｄｅｌ ｆｏｒ Ｏｎｌｉｎｅ Ａｄｖｅｒｔｉｓｉｎｇ
ＬＩＵ Ｍｅｎｇ－Ｊｕａｎ ＺＥＮＧ Ｇｕｉ－Ｃｈｕａｎ ＹＵＥ Ｗｅｉ ＬＩＵ Ｙａｏ ＱＩＮ Ｚｈｉ－Ｇｕａｎｇ
（Ｄｅｐａｒｔｍｅｎｔ ｏｆ Ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ Ｓｏｆｔｗａｒｅ Ｅｎｇｉｎｅｅｒｉｎｇ，Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｅｌｅｃｔｒｏｎｉｃ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ ｏｆ Ｃｈｉｎａ，Ｃｈｅｎｇｄｕ ６１００５４）
Ａｂｓｔｒａｃｔ Ａｓ ｔｈｅ ｋｅｙ ｃｏｍｐｏｎｅｎｔ ｏｆ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ ａｎｄ ｏｎｌｉｎｅ ａｄｖｅｒｔｉｓｉｎｇ，ｔｈｅ ｃｌｉｃｋ－ｔｈｒｏｕｇｈ
ｒａｔｅ（ＣＴＲ）ｐｒｅｄｉｃｔｉｏｎ ｈａｓ ｒｅｃｅｉｖｅｄ ｇｒｅａｔ ａｔｔｅｎｔｉｏｎ ｉｎ ｂｏｔｈ ｔｈｅ ａｃａｄｅｍｉａ ａｎｄ ｔｈｅ ｉｎｄｕｓｔｒｙ．Ｔｈｅ ｍｏｓｔ
ｃｏｍｍｏｎ ａｐｐｒｏａｃｈｅｓ ｔｏ ＣＴＲ ｐｒｅｄｉｃｔｉｏｎ ａｒｅ ｒｅｇａｒｄｉｎｇ ｉｔ ａｓ ａ ｒｅｇｒｅｓｓｉｏｎ ｐｒｅｄｉｃｔｉｏｎ ｔａｓｋ ｉｎ ｍａｃｈｉｎｅ
ｌｅａｒｎｉｎｇ．Ａｔ ｂｅｇｉｎｎｉｎｇ，ｓｉｍｐｌｅ ｍｏｄｅｌｓ ｌｉｋｅ ｌｏｇｉｓｔｉｃ ｒｅｇｒｅｓｓｉｏｎ（ＬＲ）ａｎｄ ｆａｃｔｏｒｉｚａｔｉｏｎ ｍａｃｈｉｎｅ（ＦＭ）
ａｒｅ ｕｓｅｄ ｔｏ ｄｏ ｐｒｅｄｉｃｔｉｏｎｓ，ｈｏｗｅｖｅｒ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ ｐｅｒｆｏｒｍａｎｃｅｓ ａｒｅ ｎｏｔ ｓｏ ｇｏｏｄ ｂｅｃａｕｓｅ ｏｎｌｙ
ｌｏｗ－ｏｒｄｅｒ ｆｅａｔｕｒｅ ｉｎｔｅｒａｃｔｉｏｎｓ ａｒｅ ｅｘｐｌｏｒｅｄ．Ｔｈｅｒｅｆｏｒｅ，ｍｏｄｅｌｓ ｗｉｔｈ ｓｔｒｏｎｇｅｒ ａｂｉｌｉｔｙ ｏｆ ｆｅａｔｕｒｅ
ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ａｒｅ ｄｅｖｅｌｏｐｅｄ，ｆｏｒ ｅｘａｍｐｌｅ，ａ Ｆａｃｔｏｒｉｚａｔｉｏｎ－ｍａｃｈｉｎｅ ｓｕｐｐｏｒｔｅｄ Ｎｅｕｒａｌ
Ｎｅｔｗｏｒｋ（ＦＮＮ）ａｎｄ ａ Ｐｒｏｄｕｃｔ－ｂａｓｅｄ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ（ＰＮＮ），ｗｈｉｃｈ ａｒｅ ｐｒｏｍｉｓｉｎｇ ｔｏ ｅｘｐｌｏｉｔ
ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｔｏ ｌｅａｒｎ ｓｏｐｈｉｓｔｉｃａｔｅｄ ａｎｄ ｓｅｌｅｃｔｉｖｅ ｆｅａｔｕｒｅ ｉｎｔｅｒａｃｔｉｏｎｓ．Ｔｈｅ ｍａｊｏｒ ｄｏｗｎｓｉｄｅ
ｏｆ ＦＮＮ ａｎｄ ＰＮＮ ｉｓ ｔｈａｔ ｔｈｅｙ ｆｏｃｕｓ ｍｏｒｅ ｏｎ ｈｉｇｈ－ｏｒｄｅｒ ｆｅａｔｕｒｅ ｉｎｔｅｒａｃｔｉｏｎｓ ｗｈｉｌｅ ｃａｐｔｕｒｅ ｌｉｔｔｌｅ
ｌｏｗ－ｏｒｄｅｒ ｉｎｔｅｒａｃｔｉｏｎｓ．Ｉｎ ｏｒｄｅｒ ｔｏ ｍａｋｅ ｆｕｌｌ ｕｓｅ ｏｆ ｌｏｗ－ａｎｄ ｈｉｇｈ－ｏｒｄｅｒ ｆｅａｔｕｒｅ ｉｎｔｅｒａｃｔｉｏｎｓ，ｓｏｍｅ
ｈｙｂｒｉｄ ａｒｃｈｉｔｅｃｔｕｒｅｓ ａｒｅ ｐｒｏｐｏｓｅｄ，ｃｏｎｔａｉｎｉｎｇ ｂｏｔｈ ａ ｓｈａｌｌｏｗ ｃｏｍｐｏｎｅｎｔ ａｎｄ ａ ｄｅｅｐ ｃｏｍｐｏｎｅｎｔ．
Ｉｎ ｔｈｉｓ ｐａｐｅｒ，ｗｅ ｆｉｒｓｔｌｙ ｓｔｕｄｙ ｓｅｖｅｒａｌ ｔｙｐｉｃａｌ ＣＴＲ ｐｒｅｄｉｃｔｉｏｎ ｍｏｄｅｌｓ，ｅｓｐｅｃｉａｌｌｙ ｔｈｅ ｄｅｅｐ ｌｅａｒｎｉｎｇ
ｍｏｄｅｌｓ ｂａｓｅｄ ｏｎ ｈｙｂｒｉｄ ａｒｃｈｉｔｅｃｔｕｒｅｓ，ｔｏ ｄｅｓｃｒｉｂｅ ｔｈｅ ｄｅｖｅｌｏｐｍｅｎｔ ｐｒｏｃｅｓｓ ｏｆ ＣＴＲ ｐｒｅｄｉｃｔｉｏｎ；
ａｎｄ ｔｈｅｎ，ｉｎｓｐｉｒｅｄ ｂｙ ｅｘｉｓｔｉｎｇ ｗｏｒｋｓ，ａ ｎｅｗ ｃｌｉｃｋ－ｔｈｒｏｕｇｈ ｒａｔｅ ｐｒｅｄｉｃｔｉｏｎ ｍｏｄｅｌ ｂａｓｅｄ ｏｎ ａ ｈｙｂｒｉｄ
ｎｅｔｗｏｒｋ ｉｓ ｐｒｏｐｏｓｅｄ—ＤＰＳＮ（Ｄｅｅｐ ＆Ｐｒｏｄｕｃｔ ｓｕｐｐｏｒｔｅｄ Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ）．Ｔｈｅ ｎｅｗ ｍｏｄｅｌ ｃａｎ
ｉｎｔｅｇｒａｔｅ ｄｉｆｆｅｒｅｎｔ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ（ＤＮＮｓ）ｔｏ ｌｅａｒｎ ｔｈｅ ｈｉｇｈ－ｏｒｄｅｒ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｏｆ ｏｒｉｇｉｎａｌ
ｈｉｇｈ－ｄｉｍｅｎｓｉｏｎａｌ ｓｐａｒｓｅ ｆｅａｔｕｒｅｓ ｒｅｓｐｅｃｔｉｖｅｌｙ，ｗｈｉｃｈ ｅｎａｂｌｅｓ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ ｍｏｄｅｌ ｔｏ ｔａｋｅ ａｄｖａｎｔａｇｅ
ｏｆ ｍｏｒｅ ａｂｕｎｄａｎｔ ｉｎｆｏｒｍａｔｉｏｎ ｏｆ ｈｉｇｈ－ｏｒｄｅｒ ｆｅａｔｕｒｅ ｉｎｔｅｒａｃｔｉｏｎｓ．Ｉｎ ａｄｄｉｔｉｏｎ，ｗｅ ａｌｓｏ ｄｅｓｉｇｎ ａ
收稿日期：２０１８－０４－２９；在线出版日期：２０１９－０１－２５．本课题得到国家自然科学基金（６１２０２４４５，６１５０２０８７）、中央高校基本业务费项目
（ＺＹＧＸ２０１６Ｊ０９６）资助．刘梦娟，博士，副教授，主要研究方向为数据挖掘、广告计算、机器学习．Ｅ－ｍａｉｌ：ｍｊｌｉｕ＠ｕｅｓｔｃ．ｅｄｕ．ｃｎ．曾贵川，硕
士研究生，主要研究方向为广告计算、机器学习．岳 威，硕士研究生，主要研究方向为广告计算、机器学习．刘 瑶，博士，副教授，主要
研究方向为数据挖掘、机器学习．秦志光，博士，教授，博士生导师，主要研究领域为数据挖掘、网络安全． ７期 刘梦娟等：基于融合结构的在线广告点击率预测模型 １５７１
ｎｅｗ ｅｍｂｅｄｄｉｎｇ ｌａｙｅｒ ｆｏｒ ＤＰＳＮ，ｗｈｅｒｅ ｎｏｄｅｓ ｃｏｍｅ ｆｒｏｍ ｎｏｔ ｏｎｌｙ ｔｈｅ ｅｍｂｅｄｄｉｎｇ ｖｅｃｔｏｒ ｂｕｔ ａｌｓｏ
ｔｈｅ ｗｅｉｇｈｔ ｏｆ ｅａｃｈ ｆｅａｔｕｒｅ，ｗｈｉｃｈ ａｒｅ ｂｏｔｈ ｐｒｅ－ｔｒａｉｎｅｄ ｂｙ ＦＭ ｍｏｄｅｌ．Ｔｏ ｏｕｒ ｂｅｓｔ ｋｎｏｗｌｅｄｇｅ，
ｔｈｉｓ ｉｓ ｔｈｅ ｆｉｒｓｔ ａｔｔｅｍｐｔ ｔｏ ｉｍｐｒｏｖｅ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ ｐｅｒｆｏｒｍａｎｃｅ ｂｙ ａｄｄｉｎｇ ｆｅｗ ｗｅｉｇｈｔ ｎｏｄｅｓ ｉｎ ｔｈｅ
ｅｍｂｅｄｄｉｎｇ ｌａｙｅｒ．Ｆｕｒｔｈｅｒｍｏｒｅ，ａ ｓｉｍｐｌｉｆｉｅｄ ａｎａｌｙｓｉｓ ｏｆ ｔｈｅ ｐａｒａｍｅｔｅｒ ｃｏｍｐｌｅｘｉｔｙ ｉｓ ｇｉｖｅｎ；
ｍｅａｎｗｈｉｌｅ，ｔｈｅ ｃｏｎｖｅｒｇｅｎｃｅ ｏｆ ｔｈｅ ＤＰＳＮ ｍｏｄｅｌ ｉｓ ａｎａｌｙｚｅｄ ａｎｄ ｐｒｏｖｅｄ．Ｗｅ ｅｖａｌｕａｔｅ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ
ｐｅｒｆｏｒｍａｎｃｅ ｏｆ ｔｈｅ ｐｒｏｐｏｓｅｄ ｍｏｄｅｌ ｂａｓｅｄ ｏｎ ｔｗｏ ｒｅａｌ－ｗｏｒｌｄ ｄａｔａ ｓｅｔｓ，ｉＰｉｎＹｏｕ ａｎｄ Ｃｒｉｔｅｏ，ｂｙ
ｕｓｉｎｇ ＬｏｇＬｏｓｓ ａｎｄ ＡＵＣ ｍｅｔｒｉｃｓ．Ｉｎ ｔｈｅ ｆｉｒｓｔ ａｎｄ ｓｅｃｏｎｄ ｅｘｐｅｒｉｍｅｎｔｓ，ｗｅ ｖｅｒｉｆｙ ｔｈｅ ｃｏｎｖｅｒｇｅｎｃｅ ｏｆ
ｔｈｅ ＤＰＳＮ ｍｏｄｅｌ ａｎｄ ｉｌｌｕｓｔｒａｔｅ ｔｈｅ ｐｅｒｆｏｒｍａｎｃｅ ｉｍｐｒｏｖｅｍｅｎｔｓ ｏｆ ＦＮＮ ａｎｄ ＰＮＮ ｂｙ ａｄｄｉｎｇ ｔｈｅ
ｗｅｉｇｈｔ ｎｏｄｅｓ ｏｆ ｅａｃｈ ｆｅａｔｕｒｅ ｉｎ ｔｈｅ ｅｍｂｅｄｄｉｎｇ ｌａｙｅｒ．Ｉｎ ｔｈｅ ｔｈｉｒｄ ｅｘｐｅｒｉｍｅｎｔ，ｗｅ ａｎａｌｙｚｅ ｔｈｅ
ｉｎｆｌｕｅｎｃｅｓ ｏｆ ｄｉｆｆｅｒｅｎｔ ｍｏｄｅｌ ｐａｒａｍｅｔｅｒｓ ｏｎ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ ｐｅｒｆｏｒｍａｎｃｅ ｏｆ ＤＰＳＮ，ｉｎｃｌｕｄｉｎｇ ｔｈｅ
ｎｕｍｂｅｒ ｏｆ ｈｉｄｄｅｎ ｌａｙｅｒｓ，ｈｉｄｄｅｎ ｌａｙｅｒ ｎｏｄｅｓ，ａｃｔｉｖａｔｉｏｎ ｆｕｎｃｔｉｏｎ，ａｎｄ ｅｍｂｅｄｄｅｄ ｖｅｃｔｏｒ ｄｉｍｅｎｓｉｏｎ．
Ｔｈｅ ｆｏｕｒｔｈ ｅｘｐｅｒｉｍｅｎｔ ｉｓ ｕｓｅｄ ｔｏ ｅｖａｌｕａｔｅ ｔｈｅ ｅｆｆｅｃｔｓ ｏｆ ｔｈｅ ｎｅｗ ｅｍｂｅｄｄｉｎｇ ｌａｙｅｒ ｏｎ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ
ｐｅｒｆｏｒｍａｎｃｅ ｏｆ ｔｈｅ ＤＰＳＮ ｍｏｄｅｌ．Ｔｈｅ ｆｉｆｔｈ ａｎｄ ｓｉｘｔｈ ｅｘｐｅｒｉｍｅｎｔｓ ｒｅｓｐｅｃｔｉｖｅｌｙ ｃｏｍｐａｒｅ ｔｈｅ
ｉｎｆｌｕｅｎｃｅｓ ｏｆ ｄｉｆｆｅｒｅｎｔ ａｒｃｈｉｔｅｃｔｕｒｅｓ ａｎｄ ｎｅｇａｔｉｖｅ ｓａｍｐｌｉｎｇ ｒａｔｉｏｓ ｏｎ ＤＰＳＮ ｐｒｅｄｉｃｔｉｏｎ ｐｅｒｆｏｒｍａｎｃｅ．
Ｔｈｅ ｌａｓｔ ｅｘｐｅｒｉｍｅｎｔ ｉｓ ｔｏ ｃｏｍｐａｒｅ ｔｈｅ ｐｅｒｆｏｒｍａｎｃｅ ｏｆ ｔｈｅ ＤＰＳＮ ｍｏｄｅｌ ｗｉｔｈ ｏｔｈｅｒ ｔｙｐｉｃａｌ ＣＴＲ
ｐｒｅｄｉｃｔｉｏｎ ｍｏｄｅｌｓ，ａｎｄ ｔｈｅ ｅｘｐｅｒｉｍｅｎｔａｌ ｒｅｓｕｌｔｓ ｄｅｍｏｎｓｔｒａｔｅ ｔｈａｔ ｔｈｅ ｎｅｗ ｍｏｄｅｌ ｈａｓ ｂｅｔｔｅｒ
ｐｅｒｆｏｒｍａｎｃｅ ｔｈａｎ ｍａｊｏｒ ｓｔａｔ－ｏｆ－ｔｈｅ－ａｒｔ ｍｏｄｅｌｓ ｏｎ ＬｏｇＬｏｓｓ ｍｅｔｒｉｃｓ ａｎｄ ＡＵＣ ｍｅｔｒｉｃｓ．
Ｋｅｙｗｏｒｄｓ ｃｌｉｃｋ－ｔｈｒｏｕｇｈ ｒａｔｅ；ｌｏｇｉｓｔｉｃ ｒｅｇｒｅｓｓｉｏｎ；ｆａｃｔｏｒｉｚａｔｉｏｎ ｍａｃｈｉｎｅ；ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ；
ｈｙｂｒｉｄ ｎｅｔｗｏｒｋ
息，而且考虑了二阶特征组合携带的信息，但是由于
１ 引 言 ＣＴＲ预测模型的输入特征通常是经过独热（ｏｎｅ－ｈｏｔ）
编码［８］后的高维稀疏二值化特征向量，将特征进行
随着互联网的广泛普及以及大数据技术的快速 两两组合的计算复杂度会变得非常大，导致学习效
发展，广告商利用互联网平台进行广告精准营销成 率大幅降低．因此在工业界，更多采用的是特征工程
为可能．与传统广告相比，在线广告在覆盖范围、灵 来完成手动的特征组合工作，以捕获特征间的高阶
活性、针对性、成本和效果评估等方面拥有得天独厚 信息．
的优势，而且已经发展成为具有数十亿美元的产 近几年，非线性模型在ＣＴＲ预测中逐渐获得
业［１］．在线广告的主要目标之一是在给定预算的情 关注．例如因子分解机模型（Ｆａｃｔｏｒｉｚａｔｉｏｎ Ｍａｃｈｉｎｅ，
况下，最大化广告商的收益，例如最大化广告的点击 ＦＭ）［９－１０］通过将高维稀疏特征映射到低维稠密向量
次数或者转换次数［２］．因此，在线广告的一个重要环 中，并通过向量内积的方式来学习特征两两之间的
节是对将广告投放到一个曝光机会（ａｄ ｉｍｐｒｅｓｓｉｏｎ） 隐含信息，从而大幅减少了特征两两组合导致的计
的用户点击概率进行预测，应尽可能将广告投放到预 算复杂度；ＦＭ 的缺陷在于每个特征都只学习一个
测点击率高的曝光机会，这就是点击率（Ｃｌｉｃｋ－Ｔｈｒｏｕｇｈ 隐含向量，在与其它特征进行组合时，同一个特征产
Ｒａｔｅ，ＣＴＲ）预测问题． 生的影响力是相同的，而事实上当与不同特征域的
ＣＴＲ预测是一个典型的回归问题．目前工业界 特征组合时，隐含向量可能表现出不同的分布．为
应用最广泛的预测方法是利用逻辑回归 （Ｌｏｇｉｓｔｉｃ 此，文献［６］进一步提出了特征域相关的因子分解机
Ｒｅｇｒｅｓｓｉｏｎ，ＬＲ）来学习ＣＴＲ预测模型［２－４］．ＬＲ的优 模型ＦＦＭ（Ｆｉｅｌｄ－ａｗａｒｅ Ｆａｃｔｏｒｉｚａｔｉｏｎ Ｍａｃｈｉｎｅｓ），其
点是简单、非常容易实现大规模实时并行处理，但是 基本思想是将特征分割为若干域，每个特征将针对
线性模型的学习能力有限，不能捕获高阶特征携带 不同特征域学习不同的隐含向量，利用ＦＦＭ 方案，
的信息（非线性信息）［５］，从而限制了ＬＲ的预测性 作者分别在Ｃｒｉｔｅｏ和Ａｖａｚｕ举办的全球ＣＴＲ预测
能．为此文献［６］提出可以利用Ｐｏｌｙ２模型［７］来进行 大赛中获得了冠军［６］．Ｐｏｌｙ２、ＦＭ、ＦＦＭ 都是在ＬＲ
ＣＴＲ预测，该模型不仅考虑了一阶特征携带的信 基础上增加对二阶特征组合的权重自动学习的模 １５７２ 计 算 机 学 报 ２０１９年
型．除此之外，Ｆａｃｅｂｏｏｋ的研究人员提出了另一种 深度学习融合结构 Ｗｉｄｅ ＆Ｄｅｅｐ，该结构将线性模
筛选特征和特征组合的方式，称为 ＧＢＤＴ＋ＬＲ方 型和深度学习模型进行巧妙地融合，不仅考虑了低
案［１１］，该方案利用ＧＢＤＴ（Ｇｒａｄｉｅｎｔ Ｂｏｏｓｔ Ｄｅｃｉｓｉｏｎ 阶特征携带的信息，也考虑了高阶特征之间的交互
Ｔｒｅｅ）来帮助筛选有区分度的特征和组合特征，作为 信息，因此能够获得超过ＦＮＮ和ＰＮＮ的预测性
ＬＲ模型的输入，从而增强ＬＲ的非线性学习能力． 能．文献［１７］在 Ｗｉｄｅ ＆Ｄｅｅｐ的基础上，将线性模型
深度学习在计算机视觉［１２］、语音识别［１３］、自然 （Ｗｉｄｅ）替换为ＦＭ模型，从而提出ＤｅｅｐＦＭ．
语言处理［１４］等领域取得巨大成功，其在探索特征间 本文借鉴 Ｗｉｄｅ ＆Ｄｅｅｐ的思路，设计了一个基
高阶隐含信息的能力也被应用到了ＣＴＲ预测中． 于融合结构的深度神经网络来建立 ＣＴＲ预测模
文献［５］提出了ＦＮＮ（Ｆａｃｔｏｒｉｚａｔｉｏｎ Ｍａｃｈｉｎｅ ｓｕｐ－ 型，称为ＤＰＳＮ（Ｄｅｅｐ＆Ｐｒｏｄｕｃｔ ｓｕｐｐｏｒｔｅｄ Ｓｔａｃｋｉｎｇ
ｐｏｒｔｅｄ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ）模型，该模型利用一个带嵌 Ｎｅｔｗｏｒｋ），如图１所示．该结构由 Ｄｅｅｐ Ｎｅｔｗｏｒｋ、
入层（Ｅｍｂｅｄｄｉｎｇ ｌａｙｅｒ）的深度神经网络（Ｄｅｅｐ Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ和Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ三部分组成，
Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ，ＤＮＮ）来完成点击率预测，其特点 其中Ｄｅｅｐ Ｎｅｔｗｏｒｋ和Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ分别用于
是通过ＦＭ模型预先训练得到每个特征域的稠密隐 学习特征间的高阶表示，Ｄｅｅｐ Ｎｅｔｗｏｒｋ是一个简
含向量，将隐含向量作为ＤＮＮ的输入进行训练．文 单的 ＤＮＮ，Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ则借鉴了 ＰＮＮ 在
献［１５］仍然使用ＤＮＮ来预测点击率，不同之处在 ＤＮＮ的输入位置增加一个Ｐｒｏｄｕｃｔ层；最终通过
于ＤＮＮ的结构中引入了一个Ｐｒｏｄｕｃｔ层，ＤＮＮ的 Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ将前两个部分的参数进行联合
输入单元不仅包括每个特征域的隐含向量，还包括 训练，以有效捕获不同特征表示之间的关系，从而
任意两个特征域向量的积运算，这种方案称为ＰＮＮ 得到最终的ＣＴＲ预测值．与已有的深度学习方案
（Ｐｒｏｄｕｃｔ－ｂａｓｅｄ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ）． 类似，ＤＰＳＮ中也引入了一个嵌入层，用于将原始
ＦＮＮ和ＰＮＮ充分利用了ＤＮＮ对特征高阶隐 高维稀疏的二值化特征映射为固定维度的低维稠
含信息的表示能力，但忽略了一阶特征携带的信息， 密向量，作为Ｄｅｅｐ Ｎｅｔｗｏｒｋ和Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ的
而实验证明一阶特征对于ＣＴＲ预测也是非常重要 共同输入．为了验证ＤＰＳＮ的预测性能，本文利用
的，为此Ｇｏｏｇｌｅ的研究人员在文献［１６］中提出一种 ｉＰｉｎＹｏｕ和Ｃｒｉｔｅｏ的公开数据集完成了大量实验，
图１ ＤＰＳＮ采用的融合结构 ７期 刘梦娟等：基于融合结构的在线广告点击率预测模型 １５７３
结果显示在ＬｏｇＬｏｓｓ和 ＡＵＣ指标上，ＤＰＳＮ能够 如前所述，为了减少ＤＮＮ中的输入单元数，在
比传统的点击率预测模型以及已有的基于深度学 基于ＤＮＮ的ＣＴＲ预测模型中，需要将独热编码后
习的预测模型获得更好的性能． 的每个特征映射为一个固定维度的嵌入向量，再将
所有嵌入向量拼接起来作为输入．假设独热编码后
２ 相关工作 的特征数为ｎ，每个嵌入向量的维度为Ｄ，特征的嵌
入向量ｖ可以写为一个矩阵，如式（２）所示．
相比于传统的浅层学习，ＤＮＮ在特征学习方 熿ｖ １燄 熿ｖ１ １ ｖ２ １ … ｖ １Ｄ 燄
面表现出巨大的潜力［５］，因此，近两年将 ＤＮＮ用
ｖ ｖ１ ｖ２ … ｖＤ
于ＣＴＲ预测已经成为一种研究趋势．本节将对几 ｖ＝ ２ ＝ ２ ２ ２ （２）
    
种典型的基于ＤＮＮ的ＣＴＲ预测模型进行介绍和
对比． 燀ｖ ｎ燅 燀ｖ ｎ１ ｖ ｎ２ … ｖ ｎＤ 燅
对于一个样本，由于属于相同特征域的特征只有
在此之前，首先对ＣＴＲ预测模型原始特征的
１个有取值，因此ＤＮＮ模型的输入单元数为Ｎ×Ｄ，
预处理方法以及在ＤＮＮ方案中常用的映射方法
进行简单介绍［５，１８］．在ＣＴＲ预测中，使用的特征主 这里Ｎ表示特征向量中特征域的个数．图２展示了
要是分类特征（ｃａｔｅｇｏｒｉｃａｌ ｆｅａｔｕｒｅｓ），例如用户的性
将特征映射为嵌入向量作为输入的一个示例．假设
别（Ｇｅｎｄｅｒ）、所在的城市（Ｃｉｔｙ）等，分类特征不能直
独热编码后的样本特征为［１，０，０，０，１］，其中前两个
接用于预测计算，因此通常使用独热（ｏｎｅ－ｈｏｔ）编码
比特为Ｇｅｎｄｅｒ特征域，后三个比特为Ｃｉｔｙ特征域，
对分类特征进行预处理，例如 Ｇｅｎｄｅｒ特征有两种 嵌入向量的维度为２，可将男性特征和Ｂｅｉｊｉｎｇ特征
可能取值（Ｆｅｍａｌｅ／Ｍａｌｅ），因此Ｇｅｎｄｅｒ特征可编码 映射为两个嵌入向量，假设为［０．２，０．８］和［０．６，０．４］，
为２比特，［０，１］表示Ｆｅｍａｌｅ，［１，０］表示 Ｍａｌｅ；Ｃｉｔｙ 最后将两个嵌入向量拼接起来作为输入，因此映射
特征有三种可能取值（Ｂｅｉｊｉｎｇ／Ｓｈａｎｇｈａｉ／Ｃｈｅｎｇｄｕ）， 后的嵌入单元的数量为４．需要说明的是不同的特
因此Ｃｉｔｙ特征可编码为３比特，分别对应［０，０，１］， 征对应的嵌入向量是不同的，例如 Ｍａｌｅ和Ｆｅｍａｌｅ
［０，１，０］，［１，０，０］．例如，一个位于北京的男性用户， 分别对应的是不同的嵌入向量．此外，如果样本中包
其编码后的原始特征向量为 含有数值特征，在ＣＴＲ预测中通常将数值特征利
［１，０］ ［０，０，１］． 用分箱技术转化为分类特征，再按照分类特征的预
烏烐烑 烏 烐 烑
Ｇｅｎｄｅｒ＝Ｍａｌｅ Ｃｉｔｙ＝Ｂｅｉｊｉｎｇ 处理方法来编码．
在ＣＴＲ预测中，通常将独热编码后的每个比
特称为一个特征，例如［１，０］中第一个比特表示男性
特征，第二个比特表示女性特征，样本中出现的特征
取值为１，其余取值为０．因此对于一个样本，编码后
的特征向量是一个超高维度的稀疏向量，如果将该
特征向量直接输入到ＤＮＮ中会使得需要学习的参
数非常多，产生巨大的计算开销．因此在基于ＤＮＮ 图２ 嵌入向量的示例
的ＣＴＲ预测模型中，通常会在输入层和第一个隐藏 本节将详细介绍几种比较典型的基于ＤＮＮ的
层之间增加一个嵌入层，用于降低ＤＮＮ的输入单元 ＣＴＲ预测模型，各种模型的结构如图３和图４所示．
数．这里引入了特征域（ｆｉｅｌｄ）和嵌入向量（ｅｍｂｅｄｄｉｎｇ 图３（ａ）是ＦＮＮ模型［５］，它是一个采用因子分解机
ｖｅｃｔｏｒ）的概念，首先将编码后的特征按照其物理属 模型ＦＭ预先初始化嵌入向量的前馈神经网络，其
性划分为若干特征域，例如［ｂ１，ｂ２］表示Ｇｅｎｄｅｒ特
特点是嵌入的特征域向量是预先训练的，因此可以
征域，［ｂ１，ｂ２，ｂ３］表示Ｃｉｔｙ特征域，在每个样本中，
大幅降低ＤＮＮ参数训练的计算复杂度．图３（ｂ）是
每个特征域中只有一个特征的值为１，其余为０．假
ＰＮＮ模型［１５］，不同于ＦＮＮ，它在Ｅｍｂｅｄｄｉｎｇ ｌａｙｅｒ
设特征域ｃ在整个样本集中有Ｍ 种取值可能，则独
和第一个隐藏层之间增加了一个Ｐｒｏｄｕｃｔ ｌａｙｅｒ，以
热编码后的表示如式（１），ｃ是一个由二值化元素组
捕捉高阶特征之间的相互作用．根据ｐｒｏｄｕｃｔ操作
成的向量，每个元素ｂｉ∈｛０，１｝．
的不同类型，有三种变化：ＩＰＮＮ、ＯＰＮＮ、ＰＮＮ＊，其
Ｍ
ｃ＝（ｂ１，ｂ２，…，ｂＭ ），∑ｂｉ＝１ （１） 中ＩＰＮＮ表示任意两个特征域的嵌入向量做内积，
ｉ＝１ １５７４ 计 算 机 学 报 ２０１９年
图３ ＦＮＮ模型和ＰＮＮ模型的结构
图４ 两种典型的融合结构
ＯＰＮＮ表示任意两个特征域的嵌入向量做外积， 加入了嵌入层，其中ＦＮＮ、ＰＮＮ以及 Ｗｉｄｅ ＆Ｄｅｅｐ
ＰＮＮ＊表示将内积和外积的输出结果拼接起来．不 和ＤｅｅｐＦＭ的 Ｄｅｅｐ部分的输入只依赖于嵌入向
同于ＦＮＮ，ＰＮＮ在嵌入层的输入中不仅考虑了一 量；而在低阶部分，Ｗｉｄｅ ＆Ｄｅｅｐ输入的是原始特征
阶特征的嵌入向量，还考虑了任意两个特征嵌入向 和交叉积的变换特征，ＤｅｅｐＦＭ 输入的是原始特征
量之间的组合操作． 及嵌入向量的内积．基于上述分析，本文提出的
这里ＦＮＮ模型和ＰＮＮ模型忽略了一阶特征的 ＤＰＳＮ模型采用了与 Ｗｉｄｅ ＆Ｄｅｅｐ和ＤｅｅｐＦＭ类似
相互作用．为此Ｇｏｏｇｌｅ提出一种能够同时考虑低阶 的融合结构，其特点是利用两个不同的前馈神经网
和高阶特征相互作用的融合结构Ｗｉｄｅ＆Ｄｅｅｐ［１６］，如 络来分别学习特征之间的高阶表示，通过Ｓｔａｃｋｉｎｇ
图４（ａ）所示，该结构将线性模型和ＤＮＮ结合起来 Ｎｅｔｗｏｒｋ将两个前馈网络输出的特征域高阶表示拼
联合训练，相比于单独的线性模型和深度学习模型，
接起来作为一个新的ＤＮＮ输入进行ＣＴＲ预测．此
融合结构的预测性能有一定提升，但是其 Ｗｉｄｅ部 外，ＤＰＳＮ不同于其它深度学习模型之处在于嵌入
分仍然依赖于特征工程．文献［１７］提出的ＤｅｅｐＦＭ
层的设计，除了包括每个特征的嵌入向量，还包括特
模型重新设计了融合结构，如图４（ｂ）所示，该结构
征的一阶权重，作为对嵌入向量表示的补充．
将ＦＭ模型和ＤＮＮ结合起来联合训练，优点是不
需要特征工程支持，同时也可以学习低阶和高阶特
表１ 基于ＤＮＮ的ＣＴＲ预测模型的特点
征的相互作用．
ＦＮＮ ＰＮＮ ＤＰＳＮ Ｗｉｄｅ＆Ｄｅｅｐ ＤｅｅｐＦＭ
特征工程 × × × √ ×
表１展示了几种典型基于ＤＮＮ的ＣＴＲ预测
低阶特征 × × × √ √
模型与ＤＰＳＮ的特点对比．分析发现几种典型方案 高阶特征 √ √ √ √ √
嵌入层 √ √ √ √ √
均选择了前馈神经网络来学习高阶特征的表示，在
网络结构 ＤＮＮ ＤＮＮ ３个ＤＮＮ ＬＲ＋ＤＮＮ ＦＭ＋ＤＮＮ
网络结构上均在第一个隐藏层（Ｈｉｄｄｅｎ ｌａｙｅｒ）之前 嵌入向量训练 预训练嵌入向量 嵌入向量作为整体训练 ７期 刘梦娟等：基于融合结构的在线广告点击率预测模型 １５７５
入，进行高阶交叉特征的探索，从而得到更多不同的
３ 基于融合结构的ＣＴＲ预测模型 高阶特征的组合模式，提供给最终的ＣＴＲ预测．在
后续实验中，论文也通过单一结构和融合结构的对
本节将详细介绍论文提出的ＤＰＳＮ模型，如图 比实验，验证了该设计的有效性．下面将按照由底向
１所示．首先介绍模型设计的动机；然后按照由底向 上的顺序介绍本文提出的ＤＰＳＮ模型包含的各组
上的顺序逐一介绍模型的组成，包括：（１）嵌入层， 成部分．
着重介绍从原始输入特征到嵌入层一阶特征权重单 ３．２ 嵌入层
元和嵌入向量单元的映射方法；（２）Ｄｅｅｐ Ｎｅｔｗｏｒｋ， 如前所述，ＣＴＲ预测中使用的原始特征通常是
前馈神经网络，用于学习输入仅为一阶特征相关信 超高维度的稀疏向量，如果将其直接输入到ＤＮＮ
息的高阶特征表达；（３）Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ，前馈神 中，将会产生非常巨大的计算开销，因此将每个原始
经网络，用于学习输入增加了二阶交叉特征的高阶 特征映射为固定维度的嵌入向量将会大幅降低输入
特征表达；（４）Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ，前馈神经网络，用 单元的个数．在ＤＰＳＮ中设计了一个不同于ＦＮＮ
于拼接前两个ＤＮＮ的输出，并进一步挖掘不同的 和ＰＮＮ的嵌入层，其中的单元除了每个特征对应
高阶特征表达之间的交叉信息；在此基础上，介绍模 的嵌入向量还包括一阶特征的权重，如图５所示．
型参数的学习算法，并对模型的参数复杂度给出了
简化的理论分析；最后分析和证明了ＤＰＳＮ模型的
收敛性．
３．１ 设计动机
本文在设计ＤＰＳＮ模型时，主要受到两个方面
的启发．一是ＦＮＮ和ＰＮＮ采用ＦＭ模型进行预训
练，从而得到每个特征的嵌入向量，这里认为嵌入向 图５ 嵌入层的结构
量携带了对应特征的重要信息，因此可以在嵌入层 在ＣＴＲ预测中，可利用的特征主要来自于三
采用嵌入向量来替代原始特征．而ＦＭ 模型中不仅 个方面：广告特征（如广告创意、广告内容类别等）、
可以学到特征的嵌入向量，还可以学到一阶特征在 上下文特征（如网页内容主题、广告位的位置及尺寸
预测ＣＴＲ时对应的权重，如３．２节的式（３）所示，这 等）、用户特征（如用户类别标签、地理位置、人口统
里一阶特征的权重也携带了反映该特征的重要信 计特征等）［１９］．假设独热编码后的原始特征向量中
息，而在目前已有的基于ＤＮＮ的预测模型中，都只 有Ｎ个特征域，第ｉ个特征域中有Ｍ 个特征，每个
考虑了每个特征对应的嵌入向量，而忽略了一阶特 特征对应的嵌入向量的维度为Ｄ，则对应的嵌入层
征的权重．因此，本文尝试将一阶特征的权重也作为 中有Ｎ个嵌入向量，每个嵌入向量中有Ｄ个单元
信息单元，引入到嵌入层，并在后续实验中验证该设 节点，由于同一个样本中每个特征域只可能出现一
计的有效性，在嵌入层中加入一阶特征权重单元的 个特征，因此嵌入层中的一阶特征的权重单元数为
ＦＮＮ和ＰＮＮ方案都显著优于只考虑嵌入向量单元 Ｎ，嵌入层中总的单元数为（Ｄ＋１）×Ｎ．类似于ＦＭ
的方案． 模型，在ＤＰＳＮ的嵌入层每个特征都有自己的一阶
第二个启发是 Ｗｉｄｅ＆Ｄｅｅｐ和ＤｅｅｐＦＭ的融合 权重，因此特征域ｉ的Ｍ个特征的一阶权重可用向
结构，这两个方案采用的都是“深度模型＋浅层模型” 量ｗｅ ｉ＝［ｗｅｉ １，ｗｅｉ ２，…，ｗｅｉ Ｍ］表示．
的结构，将样本原始特征分别输入到两个不同的模 每个特征的嵌入向量和一阶权重可以作为模型
型学习不同的特征表达，然后拼接起来联合学习，完 参数进行端到端的统一训练（例如 Ｗｉｄｅ ＆Ｄｅｅｐ和
成最终的ＣＴＲ预测，其基本思路是在最终预测时 ＤｅｅｐＦＭ），也可以采用其它ＣＴＲ预测模型进行预
比单一深度学习模型增加更多的有效信息．受这一
先训练．在本文提出的ＤＰＳＮ中采用ＦＭ模型［１０］在
思想启发，本文设计出一种“深度模型＋深度模型”的
训练集上进行预训练，从而得到每个特征的嵌入向
结构，将经过预处理后的嵌入层单元分别输入到两
量和一阶权重，公式如式（３）所示，这里ｆ（ｗｅ，ｖ，ｘ ｉ）
个不同结构的ＤＮＮ中，一个ＤＮＮ只考虑一阶特征
表示基于样本ｉ的点击率预测值，ｘ ｉ表示样本ｉ特征
的信息作为输入进行高阶交叉特征的探索，另一个
向量，ｘ ｉ＝（ｘ ｉ１，ｘ ｉ２，…ｘ ｉｎ），ｎ表示独热编码后的特征
ＤＮＮ同时考虑一阶和二阶组合特征的信息作为输 数，ｘ ｉｋ和ｘｌ ｉ分别表示样本ｉ的第ｋ个特征的值和第ｌ １５７６ 计 算 机 学 报 ２０１９年
个特征的值，ｖ和ｖ表示第ｋ个特征和第ｌ个特征的 需要说明的是，由于在ＤＮＮ隐层节点的计算
ｋ ｌ
隐含向量．用训练好的ＦＭ 模型中每个特征的一阶 中是按“节点”进行交叉组合，因此输入如果只考虑
权重初始化嵌入层的一阶权重节点的值，用ＦＭ 模 特征的嵌入向量，将会使交叉组合不是按照每个“特
型中每个特征的隐含向量初始化嵌入向量节点的 征”来完成，各嵌入向量的每个单元节点将作为一个
值．仍然沿用图２的例子，假设训练好的ＦＭ 模型 独立的输入值，只有一阶特征对应的权重才反映的
中，男性特征的一阶权重为０．４，北京特征的一阶权 是一个完整特征信息，示意如图７所示．因此，直观
重为０．２，则嵌入层的映射结果如图６所示，包括６ 地认为一阶特征的权重值在隐层节点的交叉组合中
个单元节点． 将起着更为有意义的作用．
ｎ ｎ
ｆ（ｗｅ，ｖ，ｘ）＝ｗｅＴｘ＋∑ ∑（〈ｖ·ｖ〉·ｘｋ·ｘｌ）（３）
ｉ ｉ ｋ ｌ ｉ ｉ
ｋ＝１ｌ＝ｋ＋１
Ｄ
其中，〈ｖ·ｖ〉＝∑ｖＤｖ Ｄ．
ｋ ｌ ｋ ｌ
ｄ＝１
图７ 嵌入层到隐层节点的连接示意
３．４ Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ
Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ也是一个包含多个隐层的前
馈神经网络，不同于Ｄｅｅｐ Ｎｅｔｗｏｒｋ，它在嵌入层和
图６ 嵌入层映射的例子 第１个隐层之间增加一个Ｐｒｏｄｕｃｔ层，如图１所示，
该层不仅包含嵌入层的单元节点，还包含任意两个
３．３ Ｄｅｅｐ Ｎｅｔｗｏｒｋ
特征的嵌入向量进行两两内积的单元节点，计算如
Ｄｅｅｐ Ｎｅｔｗｏｒｋ是一个包含多个隐层的前馈神
经网络，用于学习输入仅为一阶特征相关的高阶特 式（６）所示，这里ｐ ｉ，ｋ表示嵌入向量ｖ ｉ和ｖ ｋ的内积，
征之间的交互信息，如图１所示．在Ｄｅｅｐ Ｎｅｔｗｏｒｋ 因此在Ｐｒｏｄｕｃｔ层有Ｎ×（Ｎ－１）／２个Ｐｒｏｄｕｃｔ节
中，嵌入层的每个节点与第１个隐层的每个节点全 点，这里Ｎ表示嵌入层嵌入向量的个数；Ｐｒｏｄｕｃｔ层
连接，第１个隐层中每个节点的输出值采用式（４）计 的节点与第１个隐层的节点全连接，隐层中每个节
算，其中ｈ∈Rｎ１是第１个隐层节点的输出向量，ｎ 点的激活函数ｆ（·）都采用ＲｅＬＵ，因此每个节点输
１ １
是第１个隐层的节点数，Ｗ 表示嵌入层节点到第１ 出值的计算方法与Ｄｅｅｐ Ｎｅｔｗｏｒｋ相同；在Ｐｒｏｄｕｃｔ
０
个隐层节点的连接权重，Ｗ ∈Rｎ１×ｎ０，ｎ是嵌入层的 Ｎｅｔｗｏｒｋ中最后１个隐层节点的输出值将直接作为
０ ０
节点数，ｘ∈Rｎ０是嵌入层的输出向量，ｂ表示第１ 输入传输到Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ输入层的部分节点．
０ ０
个隐层的偏置向量，ｂ ０∈Rｎ１，隐层节点的激活函数 熿ｖ ｋ１ 燄
ｆ（·）采用ＲｅＬＵ［２０］． ｖ２ Ｄ
ｈ １＝ｆ（Ｗ ０ｘ ０＋ｂ ０） （４）
ｐ ｉ，ｋ＝〈ｖ ｉ·ｖ ｋ〉＝［ｖ ｉ１ ｖ ｉ２ … ｖ ｉＤ］ ｋ ＝ ｔ∑ ＝１ｖ ｉｔｖｔ
ｋ
Ｄｅｅｐ Ｎｅｔｗｏｒｋ是一个前馈深度神经网络，每个 ｖＤ
燀ｋ燅
隐层的节点数和隐层的层数可调整，隐层之间每个 （６）
节点均采用全连接，第ｌ＋１个隐层节点的输出值计 由于ＤＮＮ中，是按照“节点”进行加权求和来
算如式（５）所示，Ｗ 表示第ｌ个隐层节点到第ｌ＋１ 完成特征交叉，没有考虑“叉积”这样的组合方式，因
ｌ
个隐层节点的连接权重，Ｗ ∈Rｎｌ＋１×ｎｌ，ｎ和ｎ 分 此在Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ中输入信息不仅包含了一阶
ｌ ｌ ｌ＋１
特征相关的信息，还包含了二阶特征的“叉积”信息，
别是第ｌ个隐层和第ｌ＋１个隐层的节点数，ｈ∈Rｎｌ
ｌ
从而使输入ＤＮＮ的信息更丰富，可以得到更多的
是第ｌ个隐层节点的输出值，ｂ表示第ｌ＋１个隐层
ｌ
的偏置向量，ｂ ｌ∈Rｎｌ＋１，隐层中所有节点的激活函数
不同于Ｄｅｅｐ Ｎｅｔｗｏｒｋ的高阶特征组合模式．
ｆ（·）都采用ＲｅＬＵ；最后１个隐层节点的输出值将
３．５ Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ
Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ主要用于将Ｄｅｅｐ Ｎｅｔｗｏｒｋ
直接作为输入传输到Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ输入层的
和Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ输出的高阶特征表示拼接起来
部分节点；
作为一个新的ＤＮＮ的输入，使得整个模型能够联
ｈ ＝ｆ（Ｗｈ＋ｂ） （５）
ｌ＋１ ｌ ｌ ｌ ７期 刘梦娟等：基于融合结构的在线广告点击率预测模型 １５７７
合起来进行参数训练．为了进一步挖掘不同高阶特 ｇ（θ），得到如下表达式：
征之间的交叉信息，ＤＰＳＮ中将拼接后的特征向量输 Ｌ（θ）≈Ｌ（θ）＋ｇ（θ）Ｔ（θ－θ）
０ ０ ０
入到一个新的ＤＮＮ中，如图１所示．这里隐层的数量 ｓ．ｔ．Ｌ（θ）＜Ｌ（θ）
０
是可调整的，当隐层数为０时，Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ就 ｇ（θ ０）Ｔ（θ－θ ０）＜０ （９）
简化为拼接各高阶特征，然后进行预测输出的功能． 为了尽快降低损失函数的值，梯度向量ｇ（θ）和参
０
实际上，后续实验结果说明，增加少量隐层确实可以 数差值向量（θ－θ）的夹角需要达到１８０°，即沿负梯
０
在一定程度上提升预测性能． 度方向下降．由此可以得到参数更新规则：
假设Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ的输入层有（ｎ Ｄ＋ｎ Ｐ） θ－θ ０＝－ηｇ（θ ０）θ＝θ ０－ηｇ（θ ０） （１０）
个节点，这里ｎ 表示Ｄｅｅｐ Ｎｅｔｗｏｒｋ的最后１个隐 其中， η是一个比较小的正实数，也称为学习率或步
Ｄ
层的节点数，ｎ 表示Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ的最后１个 长．根据式（９）、式（１０）得到的参数θ能使得损失函
Ｐ
隐层的节点数，输入层的节点与第１个隐层的节点 数的值减小，因而更接近最优解．将式（１０）的结果记
全连接，隐层之间的节点都采用全连接，隐层中每个 为θ １，按照相同的方式迭代地更新参数，参数最终
节点的激活函数ｆ（·）都采用ＲｅＬＵ，因此隐层中每 会达到损失函数的极小值点，因此参数更新规则如
个节点的输出值都采用式（５）计算，最后输出节点 式（１１）所示，ｔ＝０，１，２，…代表迭代轮次．
用于计算预测点击率，输出节点的激活函数采用 θ ｔ＋１＝θ ｔ＋Δθ ｔ＝θ ｔ－ηｇ（θ ｔ） （１１）
Ｓｉｇｍｏｉｄ函数［２１］，预测点击率ｐ的计算公式如式（７） 本节的最后对融合结构的参数复杂度进行一个
所示，这里ＷＳ表示最后１个隐层到输出节点的权重 简化的理论分析．假设Ｎ为特征域个数，Ｄ为嵌入
Ｌ
向量，ＷＳ∈RｎＬ，ｈＳ表示最后１个隐层的输出向量，
向量的维度，所有ＤＮＮ网络都有相同的隐层数Ｌ，
Ｌ Ｌ
且每个隐层的节点数相同，记为ｍ，则：
ｈＳ∈RｎＬ，ｂＳ表示输出节点的偏置．
Ｌ Ｌ （１）Ｄｅｅｐ Ｎｅｔｗｏｒｋ的参数个数为
ｐ＝Ｓｉｇｍｏｉｄ（ＷＳｈＳ＋ｂＳ） （７）
Ｌ Ｌ Ｌ （Ｎ×Ｄ＋Ｎ）×ｍ＋ｍ＋（ｍ２＋ｍ）×（Ｌ－１）．
３．６ 模型训练
（２）Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ的参数个数为
为了对融合结构中的权重和偏置参数进行学
习，本论文使用对数损失函数作为目标函数来优化 （
Ｎ×Ｄ＋Ｎ＋Ｎ×（Ｎ－１）
） ×ｍ＋ｍ＋（ｍ２＋ｍ）×（Ｌ－１）．
２
模型参数，如式（８）所示，
（３）Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ的参数个数为
Ｎ
Ｌ（θ）＝－１ ∑（ｙｌｏｇｐ（ｘ，θ）＋ ２×ｍ２＋２×ｍ＋（ｍ２＋ｍ）×（Ｌ－１）＋１．
Ｎ ｉ ｉ
ｉ＝１ （４）融合结构的参数复杂度为
（１－ｙ ｉ）ｌｏｇ（１－ｐ（ｘ ｉ，θ）））＋λ
２
ｗ２
２
（８） （３Ｌ－１）ｍ２＋（３Ｌ＋１）ｍ＋（２Ｄ＋１．５＋０．５ Ｎ）Ｎｍ＋１．
因此，在ＤＰＳＮ模型中，对模型参数影响最大
这里Ｌ（θ）是对数损失函数，θ表示融合结构的参
的是每个隐层的神经元节点数，按照ｍ的２次方倍
数，ｐ（ｘ，θ）表示根据样本ｉ的特征向量ｘ基于融合
ｉ ｉ
增长．此外，每个 ＤＮＮ的隐层数也会影响模型参
结构当前参数θ计算得到的预测点击率，ｙ表示样
ｉ
数，而嵌入向量维度和特征域数目通常只会影响从
本ｉ中关于点击行为的真实标记，有点击行为为１，
嵌入层到第一个隐层的模型参数．后续实验将会逐
无点击行为为０，Ｎ表示训练数据集中的样本数，
一对各个超参数对模型预测性能及参数复杂度的影
λｗ２／２表示Ｌ２正则化项［２２］，用于防止过拟合，λ
２
响进行分析．
是正则化参数，由手动设置，ｗ是融合结构中所有
３．７ 模型的收敛性分析
节点之间边的权重向量；参数学习的目标是求解
如３．６节所述，本文使用对数损失函数来最小
使对数损失函数最小的融合结构参数．论文使用随
化模型误差，因此模型的目标函数如式（８）所示：
机梯度下降（Ｓｔｏｃｈａｓｔｉｃ Ｇｒａｄｉｅｎｔ Ｄｅｓｃｅｎｔ，ＳＧＤ）算
Ｎ
１
法［２３－２４］来求解式（８）中的融合结构参数θ，包括节点 Ｌ（θ）＝－ Ｎ∑（ｙ ｉｌｏｇｐ（ｘ ｉ，θ）＋
ｉ＝１
之间边的权重和节点的偏置向量．
（１－ｙ）ｌｏｇ（１－ｐ（ｘ，θ）））＋λ ｗ ２．
这里对梯度下降求解的基本过程及涉及的参数 ｉ ｉ ２ ２
进行简要介绍．ＳＧＤ是利用了 Ｔａｙｌｏｒ展开式的一 目前已有大量的研究［２５－２６］证明，只要目标函数是凸
阶近似推导出来的，将损失函数Ｌ（θ）在初值的邻域 函数，在数据线性不可分或有正则项时，使用梯度下
内展开，将导数 Ｌ／θ记为关于θ的梯度向量 降法求解模型参数一定能够收敛，即在梯度下降法 １５７８ 计 算 机 学 报 ２０１９年
中每一轮训练都是沿着梯度下降的方向更新参数， 由于二阶导数非负，Ｆ（ｖ）是关于ｖ的凸函数，从而
逐步逼近目标函数的极小值．因此，只需证明式（８） 证明式（１２）为凸函数．因此得证式（８）为凸函数．
是一个凸函数，即可证明模型收敛．在证明之前首先
介绍两个定理． ４ 实验及性能评价
定理１． 凸函数的复合还是凸函数．
定理２． 凸函数的正线性组合还是凸函数． 为了对提出的ＤＰＳＮ模型的预测性能进行评
证明． 价，本文基于ｉＰｉｎＹｏｕ① 和Ｃｒｉｔｅｏ② 两个公开数据集
首先对于式（８）中的Ｌ２正则项 完成了大量的实验．本节首先对数据集及评价指标
ｎ 进行介绍，然后描述了８种作为对比的典型ＣＴＲ预
ｗ２＝∑ｗ２，
２ ｉ 测模型，最后通过７组实验展示ＤＰＳＮ模型的预测
ｉ＝１
显然，该项是处处可微分的凸函数，其中ｗ是模型 性能，并对实验结果展开讨论．
的权重向量．因此只需证明式（８）中的对数损失函数 ４．１ ｉＰｉｎＹｏｕ和Ｃｒｉｔｅｏ数据集及评价指标
是凸函数，记为
本文实验采用的ｉＰｉｎＹｏｕ数据集是ｉＰｉｎＹｏｕ公
Ｎ
Ｊ（θ）＝－１
∑（ｙｌｏｇｐ（ｘ，θ）＋
司在２０１３年发布的一个真实广告投放的数据集，包
Ｎ ｉ ｉ
ｉ＝１ 括曝光机会、竞价、点击、转化四类日志，其中曝光机
（１－ｙ）ｌｏｇ（１－ｐ（ｘ，θ））） （１２）
ｉ ｉ 会和点击日志可用于点击率预测．具体来说，在本文
由于ＤＰＳＮ模型使用Ｓｉｇｍｏｉｄ函数作为最终输出
实验中，每个样本对应了一次广告曝光，特征信息包
单元的激活函数，因此式（１２）中样本ｉ的输出预测
括用户的相关信息（例如用户类别标签、使用的浏览
值为
器、ＩＰ地址、所在区域、城市等）、广告位的相关信息
１
ｐ（ｘ，θ）＝ （１３） （例如广告位的宽度、高度、可见性、所在网站的域名
ｉ １＋ｅ－ｖｉ
以及ＵＲＬ等），投放的广告ＩＤ，以及最终的点击情
其中ｖ是样本ｉ最终输出节点的值．根据定理１与
ｉ
况（用户点击为１，无点击为０）．考虑到ＣＴＲ预测模
定理２，证明Ｊ（θ）是凸函数，只需证明式（１４）是凸
型是针对每个广告商的，因此本论文采用了其中
函数，
Ａｄｖｅｒｔｉｓｅｒ ＩＤ分别为１４５８、３３８６、３３５８、３４２７的四
Ｆ（ｖ）＝－ｌｏｇ（ １＋１ ｅ－ｖ） ＝ｌｏｇ（１＋ｅ－ｖ） （１４）
个广告商的投放和点击日志分别建立了四个数据
对式（１４）求二阶导数，得：
集．所有实验均采用前７天的样本作为训练集，采用
－ｅ－ｖ ｅｖ
后３天的样本作为测试集，表２展示了四个数据集
Ｆ′（ｖ）＝ ，Ｆ″（ｖ）＝ ０．
１＋ｅ－ｖ （１＋ｅｖ）２ 中样本的统计情况．
表２ ｉＰｉｎＹｏｕ四个数据集的统计情况
样本数 点击数 实际点击率（１０－３） 特征域数 特征数 嵌入层单元数
训练集 ３０８３０５６ ２４５４ ０．７９５９６ １６ ５６０８０２ １７６
Ａｄｖｅｒｔｉｓｅｒ ＩＤ＝１４５８
测试集 ６１４６３８ ５１５ ０．８３７８９ １６ ５６０８０２ １７６
训练集 ２８４７８０２ ２０７６ ０．７２８９８ １６ ５５６８８４ １７６
Ａｄｖｅｒｔｉｓｅｒ ＩＤ＝３３８６
测试集 ５４５４２１ ４４５ ０．８１５８８ １６ ５５６８８４ １７６
训练集 １７４２１０４ １３５８ ０．７７９５２ １６ ４９１７００ １７６
Ａｄｖｅｒｔｉｓｅｒ ＩＤ＝３３５８
测试集 ３００９２８ ２６０ ０．８６３９９ １６ ４９１７００ １７６
训练集 ２５９３７６５ １９２６ ０．７４２５５ １６ ５５１１５８ １７６
Ａｄｖｅｒｔｉｓｅｒ ＩＤ＝３４２７
测试集 ５３６７９５ ３６６ ０．６８１８２ １６ ５５１１５８ １７６
从表２观察发现真实互联网上广告投放的点击 元数目大幅下降为１７６，这里假设每个嵌入向量的
率是非常低的，即数据集中正负样本的比例严重不 维度为Ｄ＝１０．
平衡，会使得模型对正样本的学习不充分，从而降低 Ｃｒｉｔｅｏ数据集是Ｃｒｉｔｅｏ公司在２０１４年Ｋａｇｇｌｅ
ＣＴＲ预测模型的精度［２７］．此外，可以发现独热编码 平台上发起的展示广告点击率预测大赛的数据集．
后原始特征的数目是非常巨大的，达到５０万量级，
将其直接输入ＤＮＮ必然导致巨大的计算开销，经 ① ｉＰｉｎＹｏｕ：ｈｔｔｐ：／／ｄａｔａ．ｃｏｍｐｕｔａｔｉｏｎａｌ－ａｄｖｅｒｔｉｓｉｎｇ．ｏｒｇ／
② Ｃｒｉｔｅｏ ｈｔｔｐ：／／ｌａｂｓ．ｃｒｉｔｅｏ．ｃｏｍ／２０１４／０２／ｄｏｗｎｌｏａｄ－ｋａｇｇｌｅ－
过本文提出的嵌入向量映射后，使输入ＤＮＮ的单 ｄｉｓｐｌａｙ－ａｄｖｅｒｔｉｓｉｎｇ－ｃｈａｌｌｅｎｇｅ－ｄａｔａｓｅｔ／ ７期 刘梦娟等：基于融合结构的在线广告点击率预测模型 １５７９
该数据集包含４５ ８４０ ６１６条真实展示广告的特征值 的比例将样本按顺序划分为训练集和测试集．此外，
与点击反馈，来自于Ｃｒｉｔｅｏ公司连续７天的交易流 为了降低实验的时间开销与空间开销，在不显著降
量．为了减小数据规模及保持正负样本的比例平衡， 低模型性能的前提下，本文弃用了５个特征取值过
该数据集已经对样本进行了负采样，使得点击率提 多的分类特征，即只使用了１３个数值特征和２１个
升至约２５．６％．数据集包含１３个数值特征以及２６个 分类特征，并且将数值特征转化为分类特征进行预
分类特征，并且为了保护隐私，所有分类特征的值均 处理．表３展示了本文实验采用的Ｃｒｉｔｅｏ数据集的
被Ｈａｓｈ到３２位的字符串上，因此这些特征现实含 样本统计情况．目前，ｉＰｉｎＹｏｕ和Ｃｒｉｔｅｏ数据集已逐
义是无法知晓的，同时有些特征存在缺失值．在本文 步成为学术界衡量ＣＴＲ预测模型性能的基准数据
的实验中，首先对缺失值进行了填补，然后按照５∶１ 集［５，１５，１７］．
表３ Ｃｒｉｔｅｏ数据集的统计情况
样本数 点击数 实际点击率 特征域数 特征数 嵌入层单元数
训练集 ３８２０２９２７ ９７８９３５０ ０．２５６２４ ３４ ５６９３５４ ３７４
测试集 ７６３７６８９ １９５６０８８ ０．２５６１１ ３４ ５６９３５４ ３７４
实验使用ＡＵＣ［２８］和ＬｏｇＬｏｓｓ［２９］作为主要的评 型与其它典型ＣＴＲ预测模型的性能进行对比．论
价指标，其中ＡＵＣ是ＲＯＣ曲线下的面积，ＡＵＣ值越 文在ＧｉｔＨｕｂ上分享了本文的所有实验代码和实验
大，说明ＣＴＲ预测模型的性能越好；ＬｏｇＬｏｓｓ是交叉 结果②．
熵损失，ＬｏｇＬｏｓｓ越小，说明预测模型的性能越好． ４．３．１ ＤＰＳＮ模型的收敛性验证
４．２ 对比模型 本节将通过实验验证ＤＰＳＮ融合模型的收敛
为了进行对比，本文选择了７种具有代表性的ＣＴＲ 性．图８展示了ＤＰＳＮ融合结构在ｉＰｉｎＹｏｕ的１４５８、
预测模型，包括ＬＲ［２］、ＦＭ［１０］、ＧＢＤＴ＋ＬＲ［１１］以及最 ３３８６训练集上ＬｏｇＬｏｓｓ随着训练轮次逐渐降低直
新的ＦＮＮ［５］、ＰＮＮ［１５］、Ｗｉｄｅ ＆Ｄｅｅｐ［１６］、ＤｅｅｐＦＭ［１７］ 至收敛的过程，学习率均设为０．００８．观察发现，
等深度学习模型．所有对比模型都是基于ＴｅｎｓｏｒＦｌｏｗ① １４５８在２３２轮次收敛，３３８６在１７５轮次收敛，３３８６
实现的，对于包含深度神经网络的方案，为了简化， 的收敛速度快于１４５８．由此可证明ＤＰＳＮ融合结构
设置每个隐层节点的激活函数为ＲｅＬＵ，输出节点 由于采用了交叉熵损失作为损失函数，因此能够保
的激活函数为Ｓｉｇｍｏｉｄ，最优化参数求解均采用随 证模型的收敛性．为了获得更快的收敛速度，在后续
机梯度下降法．此外，论文还对比了一种用投票机制 实验中将学习率设置为０．１．
做模型融合的方案，即分别用ＦＮＮ和ＰＮＮ学习模
型得到ＣＴＲ预测值，再将两个ＣＴＲ预测值按各自
０．５的权重求和作为融合模型的ＣＴＲ预测值，这种
融合方案记为ＦＮＮ＋ＰＮＮ．
４．３ 性能评价及分析
本节将通过７组实验对ＤＰＳＮ模型的性能进
行评价，并对实验结果展开讨论．其中第１组实验用
于验证ＤＰＳＮ模型的收敛性；第２组实验用于说明
增加一阶特征权重信息对ＦＮＮ和ＰＮＮ模型预测
性能的提升；第３组实验是分析不同的模型超参对 图８ ＤＰＳＮ在ｉＰｉｎＹｏｕ １４５８和３３８６上的训练过程
ＤＰＳＮ模型预测性能的影响，包括：隐层数、隐层节
４．３．２ 一阶特征权重节点对预测性能的影响
点数、激活函数、嵌入向量维度；第４组实验用于评
ＤＰＳＮ的一个重要改进是将ＦＭ预训练的一阶
价本文提出的新的嵌入层结构对ＤＰＳＮ模型预测 特征的权重作为特征的信息加入到嵌入层，实验２
性能的影响；第５组实验是对比单一结构和融合结
构对模型预测性能的影响；第６组实验用于分析负
① ＴｅｎｓｏｒＦｌｏｗ．ｈｔｔｐｓ：／／ｗｗｗ．ｔｅｎｓｏｒｆｌｏｗ．ｏｒｇ／
采样对预测性能的影响；第７组实验是将ＤＰＳＮ模 ② 本文实验代码和实验结果．ｈｔｔｐｓ：／／ｇｉｔｈｕｂ．ｃｏｍ／ｍｊｌｉｕ－ａｄｖｅｒ－
ｔｉｓｉｎｇ １５８０ 计 算 机 学 报 ２０１９年
对比分析了原始的ＦＮＮ和ＰＮＮ模型在加入一阶 层后，预测性能均是提升的，例如１４５８数据集，
特征权重后预测性能的变化．实验基于ｉＰｉｎＹｏｕ的 ＦＮＮ在ＡＵＣ指标上提升了０．３６９％，ＬｏｇＬｏｓｓ指
四个数据集完成，结果如表４所示．观察发现，无论 标上提升了０．３２０％，ＰＮＮ在 ＡＵＣ指标上提升了
是ＦＮＮ还是ＰＮＮ，加入一阶特征权重节点到嵌入 ０．５２６％，ＬｏｇＬｏｓｓ指标上提升了０．１２２％．
表４ 一阶特征权重对ＦＮＮ和ＰＮＮ模型性能的影响
原ＦＮＮ 新ＦＮＮ 原ＰＮＮ 新ＰＮＮ
ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３）
１４５８ ０．７０６１ ６．５６１ ０．７０８８ ６．５４０ ０．７０６２ ６．５４７ ０．７０９９ ６．５３９
３３８６ ０．７９８６ ５．９２０ ０．８００３ ５．９０２ ０．８０３４ ５．９１６ ０．８０４５ ５．９０９
３３５８ ０．８１０３ ６．０６７ ０．８１１６ ６．０５６ ０．８０９１ ６．０５８ ０．８１２０ ６．０５０
３４２７ ０．７５８７ ５．２６２ ０．７５９１ ５．２５７ ０．７５８８ ５．２６１ ０．７６０８ ５．２６３
分析提升的原因，主要是在深度神经网络中，隐 可能性越大．具体地，对于１４５８数据集，从ＡＵＣ指
层节点对于特征的组合是按输入的每个“节点”进行 标来说，预测性能最好的结构是每个ＤＮＮ有３个
的，如果只考虑将嵌入向量作为输入，在进行组合时 隐层，每个隐层的节点数为５００，对于３３８６数据集，
将会把一个嵌入向量的每个单元节点作为一个独立 预测性能最好的是每个ＤＮＮ有２个隐层，每个隐
的输入，而不是按照“特征”为单位进行组合，而预训 层的节点数为５００．从ＬｏｇＬｏｓｓ指标来看，这两个结
练的一阶特征的权重节点，包含了“特征”作为独立 构的隐层设置也能取得较好的效果．
输入的重要信息．因此在融合模型中，将预训练的一 表６展示了不同隐层数和每个隐层不同神经
阶特征的权重作为节点加入到嵌入层中是一个有效 元数对需要学习的模型参数的影响．可以看到影响
的设计，进一步验证参见实验４． 最大的确实是每个隐层的神经元数目，当每层５００
４．３．３ 不同超参数对ＤＰＳＮ模型的性能影响 个节点时，即或每个ＤＮＮ只有１个隐层，需要学习
（１）隐层数对预测性能的影响
的模型参数也达到了７０万量级，模型参数随着隐层
实验３－１用于分析不同隐层数对ＤＰＳＮ模型预 数增加而增加，当增加到５层时，每个隐层５００个节
测性能的影响．由于 ＤＰＳＮ 包括 Ｄｅｅｐ Ｎｅｔｗｏｒｋ、
点的模型参数达到了３７０万量级．本实验中选择的
Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ、Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ三个前馈神经 最优隐层数设置，也牺牲了一定的参数复杂度为
网络，因此需要设置三个神经网络中的隐层数目，在
代价，不过随着硬件性能的提升，这个代价是可以
本实验中采用了一个简化的参数设置，首先假设三
接受的．
个神经网络中的隐层结构相同，即相同的层数和每
层单元数．为此，在实验３－１中，设置每个ＤＮＮ中每 表６ 不同隐层数下ＤＰＳＮ需要学习的模型参数
个隐层的单元数分别为１００和５００，隐层数从１层 隐层层数 每层１００个节点 每层５００个节点
１ ６７６０１ ７３８００１
逐层增加到５层，实验结果如表５所示．观察发现，
２ ９７９０１ １４８９５０１
并非隐层数越多，预测性能越好，无论是ＡＵＣ指标 ３ １２８２０１ ２２４１００１
４ １５８５０１ ２９９２５０１
还是ＬｏｇＬｏｓｓ指标，当隐层数增加到５时，１４５８和
５ １８８８０１ ３７４４００１
３３８６数 据 集 的 预 测 性 能 都 不 太 理 想，这 是
因为隐层层数越多，模型越复杂，出现过拟合［３０］的 （２）Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ的隐层数对性能的影响
实验３－２是在实验３－１的基础上，进一步探索
表５ 实验３－１不同隐层数对性能的影响
Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ隐层数对模型预测性能的影响，
１４５８ ３３８６
评价指标
ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３）
用于验证Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ中引入ＤＮＮ的影响．
｛１００｝ ０．７０９３ ６．５４５２ ０．８０２９ ５．９０６６ 在本实验中，将Ｄｅｅｐ Ｎｅｔｗｏｒｋ和Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ
｛１００－１００｝ ０．７０５７ ６．５５１７ ０．８０３０ ５．９２１０
｛１００－１００－１００｝ ０．７１０６ ６．５３６６ ０．８００９ ５．９１２９
的隐层数设为一致，改变Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ中隐层
｛１００－１００－１００－１００｝ ０．７１０７ ６．５３８６ ０．８００７ ５．９１１６ 数从０层逐层增加到５层，其中对于１４５８数据集，
｛１００－１００－１００－１００－１００｝０．７０６９ ６．５４４０ ０．７９８１ ５．９１３９
｛５００｝ ０．７１１９ ６．５３７７ ０．８０１６ ５．８９７７
设置Ｄｅｅｐ Ｎｅｔｗｏｒｋ和Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ的隐层数
｛５００－５００｝ ０．７１１８ ６．５３６４ ０．８０４６ ５．９０２１ 为３层，对于３３８６数据集，设置隐层数为２层，所有
｛５００－５００－５００｝ ０．７１２６ ６．５３６１ ０．７９９３ ５．９０８４
隐层的节点数均为５００，实验结果如表７和图９所
｛５００－５００－５００－５００｝ ０．７１０３ ６．５４７５ ０．８００２ ５．９０９１
｛５００－５００－５００－５００－５００｝０．７０８６ ６．５４６７ ０．７８８９ ５．９４４８ 示．观察发现，直接拼接Ｄｅｅｐ和Ｐｒｏｄｕｃｔ网络的输 ７期 刘梦娟等：基于融合结构的在线广告点击率预测模型 １５８１
出，不进行进一步高阶特征交叉信息挖掘得到的 隐层数均为３层；对于３３８６数据集，三个ＤＮＮ的
预测性能（Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ的隐层数为０）略微低 隐层数为２层．这是一个选择了性能最优而牺牲了
于在Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ中引入隐层进行高阶特征 模型参数复杂度的折中设置．
交叉信息挖掘得到的预测性能，因此在Ｓｔａｃｋｉｎｇ （３）每层神经元数目对预测性能的影响
Ｎｅｔｗｏｒｋ中引入ＤＮＮ进行高阶特征交叉信息的挖 实验３－３用于分析不同隐层的神经单元数目对
掘对于提升模型的预测性能有一定帮助．此外，不同 模型预测性能的影响．考虑每个隐层设置不同的神
的Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ隐层数目对于模型的预测性能 经元数，将使得实验非常复杂，为此，简化为所有隐
影响较小，其中对于ＡＵＣ指标，１４５８数据集在３个 层的神经元数相同，依次改变每个隐层的神经元数
隐层的结构下，能够取得最好的预测性能，比０个隐 分别为｛１００，２００，３００，４００，５００，６００，７００｝，实验结果
层的最差性能提升了０．３１１５％，３３８６数据集在２个 如表８和图１０所示．观察发现，每个隐层的神经元
隐层的结构下，能够取得最优的预测性能，比０个隐 数目增加并不能一直提升预测性能，但是会大幅增
层的最差性能提升了０．６９２５％；对于ＬｏｇＬｏｓｓ指 加学习参数的复杂度，如实验３－１表６最后分析所
标，１４５８和３３８６数据集在３个和２个隐层的结构 示，模型需要学习的参数按每层神经元数目的２次
下也能取得较好的性能提升． 方的关系增长．观察发现，当每层节点数从１００增加
到５００时，ＡＵＣ指标逐渐增加，每层为５００个节点
表７ 改变Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ隐层数对性能的影响
时ＡＵＣ指标达到最优，再依次增加每层节点数，
Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ １４５８ ３３８６
隐层数 ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３）
表８ 改变隐层神经元数目对预测性能的影响
０（每层５００个节点）０．７１０４ ６．５５０９ ０．７９９２ ５．９１６２
１（每层５００个节点）０．７１２３ ６．５４２７ ０．８０２６ ５．９０９２ １４５８ ３３８６
隐层神经元数目
２（每层５００个节点）０．７１２３ ６．５３６５ ０．８０４６ ５．９０２１ ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３）
３（每层５００个节点）０．７１２６ ６．５３６１ ０．８０２３ ５．９０７８ 每层１００个节点 ０．７０７４ ６．５４４４ ０．８０００ ５．９０８１
４（每层５００个节点）０．７１２３ ６．５３８９ ０．８００７ ５．９１３６ 每层２００个节点 ０．７０８０ ６．５４３３ ０．８０３１ ５．８９７３
５（每层５００个节点）０．７１１６ ６．５３５４ ０．７９９５ ５．９０８９ 每层３００个节点 ０．７１１４ ６．５３６７ ０．８０３３ ５．８９６０
每层４００个节点 ０．７１２１ ６．５３７３ ０．８０３３ ５．９０９０
每层５００个节点 ０．７１２６ ６．５３６１ ０．８０４６ ５．９０２１
每层６００个节点 ０．７０８２ ６．５４００ ０．７９７１ ５．９１７３
每层７００个节点 ０．７０６０ ６．５５４０ ０．７９４０ ５．９２７７
图 ９ 不同的Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ隐层数对预测性能的提升
基于上述结果，将后续实验ＤＰＳＮ模型的隐层
数进行如下设置：对于１４５８数据集，三个ＤＮＮ的 图１０ 不同的隐层神经元数目对预测性能的提升 １５８２ 计 算 机 学 报 ２０１９年
ＡＵＣ指标反而下降．分析原因如下，随着每个隐层 了预训练的一阶特征权重单元．实验４用于对比在嵌
的节点数增加，模型可以学到更多有效的高阶特征 入层增加一阶特征权重单元对ＤＰＳＮ模型预测性能
组合，因此预测性能提升，然而当５００个节点时，模 的影响，实验结果如表１１所示．结果显示增加一阶特
型的学习能力已经接近极限，再增加隐层节点，这些 征权重单元后的预测性能比不加的性能在ＡＵＣ指标
新增节点学习到的高阶特征组合可能无效，甚至引 上分别提升了１．３６１４％（１４５８）和０．７１４７％（３３８６），
入更多噪声，从而使模型最终的预测性能下降．因此 在ＬｏｇＬｏｓｓ指标上提升了１．５９５０％（１４５８）和提升
实验时选择适中的神经元数目即可，在本文的后续
了０．７３０８％（３３８６）．该结果说明在预测模型的输入
实验中仍然设置每个隐层的神经元数目为５００．
中增加一阶特征的权重确实能有效提升模型的预测
（４）不同激活函数对预测性能的影响
性能．
实验３－４用于分析不同隐层神经元的激活函数
对模型预测性能的影响．根据文献［１７］的分析，ＲｅＬＵ 表１１ 增加一阶特征权重单元对预测性能的影响
和Ｔａｎｈ函数比Ｓｉｇｍｏｉｄ函数更适合于深度模型， 一阶特征 １４５８ ３３８６
权重单元 ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３）
因此本文将比较ＲｅＬＵ和Ｔａｎｈ函数对模型预测性
考虑 ０．７１２６ ６．５３６１ ０．８０４６ ５．９０２１
能的影响．为了简化，融合结构中除最后的ＣＴＲ预 不考虑 ０．７０３０ ６．５８３１ ０．７９２０ ５．９４５６
测输出单元之外的所有神经元的激活函数都设置为
４．３．５ 模型结构对性能的影响
相同的激活函数，这里ＣＴＲ预测输出单元仍然使
在ＤＰＳＮ中，采用了２个ＤＮＮ模型来分别学习
用的是Ｓｉｇｍｏｉｄ函数，实验结果如表９所示．结果显
高阶特征的不同表示，并使用一个Ｓｔａｃｋｉｎｇ Ｎｅｔｗｏｒｋ
示在ＡＵＣ和ＬｏｇＬｏｓｓ指标上，ＲｅＬＵ函数比Ｔａｎｈ
来将２个ＤＮＮ输出的高阶表示进行拼接，从而得
函数的预测性能略好．
到一个整体的预测模型．为了与仅使用单个ＤＮＮ
表９ 不同激活函数对预测性能的影响 学习高阶特征的模型对比，实验５考察了分别只采
１４５８ ３３８６
激活函数 用Ｄｅｅｐ Ｎｅｔｗｏｒｋ和Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ来学习高阶
ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３）
特征的 ＣＴＲ预测模型的性能，实验结果如表１２
ＲｅＬＵ ０．７１２６ ６．５３６１ ０．８０４６ ５．９０２１
Ｔａｎｈ ０．７１１６ ６．５４２５ ０．８００５ ５．９０６５ 和图１１所示．结果显示，预测性能最差的是仅采用
Ｄｅｅｐ Ｎｅｔｗｏｒｋ进行ＣＴＲ预测的模型，这是因为它
（５）嵌入向量维度对预测性能的影响
只考虑了一阶特征相关的信息进行高阶特征组合；
如前分析，嵌入向量的维度Ｄ与模型的学习复
仅基于Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ进行ＣＴＲ预测的模型性
杂度直接相关，决定了每个ＤＮＮ的输入单元数，实
能优于Ｄｅｅｐ Ｎｅｔｗｏｒｋ，因为Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ的模
验３－５的目的是分析嵌入向量维度对模型预测性能
型不仅将一阶特征相关的信息作为输入，而且将二
的影响，希望使用小的维度，获得较好的预测性能，
为此将嵌入向量维度分别设置为｛５，１０，２０｝，实验结
表１２ 不同模型结构对预测性能的影响
果如表１０所示．结果显示嵌入向量维度从５到２０，
１４５８ ３３８６
模型结构
预测性能没有明显提升，且会导致模型需要学习的 ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３）
参数数量有小幅增加，例如１４５８数据集中需要学习
Ｄｅｅｐ Ｎｅｔｗｏｒｋ ０．７０８８ ６．５４０５ ０．７９８９ ５．９１６３
Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ ０．７０９９ ６．５３９２ ０．８０４５ ５．９０８６
的参数个数从２ ９１２ ５０１增加到２ ９９２ ５０１，再增加到 ＤＰＳＮ ０．７１２６ ６．５３６１ ０．８０４６ ５．９０２１
３ １５２ ５０１．分析参数量小幅增加的原因是，嵌入向量
的维度Ｄ只对嵌入层到第一个隐层的权重参数有
影响．
表１０ 嵌入向量维度对预测性能的影响
１４５８ ３３８６
嵌入向量维度
ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３）
维度Ｄ＝５ ０．７０１７ ６．５７２３ ０．８０１５ ５．９３７２
维度Ｄ＝１０ ０．７１２６ ６．５３６１ ０．８０４６ ５．９０２１
维度Ｄ＝２０ ０．７０６９ ６．５４５０ ０．８００２ ５．９２４６
４．３．４ 一阶特征权重单元对预测性能的影响
在ＤＰＳＮ中，一个重要的改进是在嵌入层增加 图１１ 模型结构对预测性能的提升 ７期 刘梦娟等：基于融合结构的在线广告点击率预测模型 １５８３
阶特征（“叉积”）相关的信息也作为输入，因此能够 训练集的总样本数减少为１２５ １５４，样本数太少会导
获得比Ｄｅｅｐ Ｎｅｔｗｏｒｋ更多的信息，由于两个模型 致模型学习欠拟合，从而导致预测误差增加．因此，
的隐层节点数都是相同的，因此可以认为经过 对于不同的数据集，应该根据数据集的实际情况，合
Ｐｒｏｄｕｃｔ Ｎｅｔｗｏｒｋ挖掘的高阶特征组合模式对于 理设计负采样的比例．另一方面，随机负采样会使训
ＣＴＲ预测更为有效． 练集中样本的特征分布与测试集的样本特征分布出
本文提出的考虑两个模型融合的结构 ＤＰＳＮ
现差异，从而使得有些预测模型欠拟合，特别是对于
的性能优于单一结构，在 ＡＵＣ 指标上，比 Ｄｅｅｐ ｉＰｉｎＹｏｕ这样样本数比较少的数据集．因此，在本文
Ｎｅｔｗｏｒｋ模型的性能提升了０．５３７４％（１４５８）和 其它节给出的实验结果均是没有进行负采样的结果．
０．７１６４％（３３８６），在 ＬｏｇＬｏｓｓ指标上分别提升了
０．０６７７％（１４５８）和 ０．２３９７％ （３３８６）．这是因为
ＤＰＳＮ同时考虑了两个ＤＮＮ模型挖掘得到的高阶
特征组合，且进一步挖掘了这两个模型输出的高阶
特征组合之间的交叉信息，从而能够在最终预测时
采用更为有效的高阶特征组合进行预测．综上分析，
可以说明本论文提出的ＤＰＳＮ融合结构确实能够
提升ＣＴＲ预测性能．
４．３．６ 负采样比率对模型预测性能的影响
如４．１节所述ｉＰｉｎＹｏｕ数据集有较大的正负样 图１２ 不同负采样比率下ＤＰＳＮ模型的性能
本不平衡问题，解决这一问题的简单方法是进行负
４．３．７ 与典型ＣＴＲ预测模型的性能对比
采样．实验６用于验证不同的负采样比率对模型预
实验７用于对比ＤＰＳＮ与几种代表性的ＣＴＲ
测性能的影响．图１２分别列出了按照正负样本比率
预测模型的性能．在需要进行特征到嵌入向量映射
｛１∶５０，１∶１００，１∶２００，１∶５００，１∶１０００｝对１４５８数据
的模型（ＦＭ、ＦＮＮ、ＩＰＮＮ、Ｗｉｄｅ ＆Ｄｅｅｐ、ＤｅｅｐＦＭ、
集进行负采样后的预测性能．观察发现，当进行适当 ＤＰＳＮ）中，设置嵌入向量的固定维度为 Ｄ＝１０；在
的负采样后（例如１∶１０００），ＤＰＳＮ模型的ＡＵＣ指 包含 ＤＮＮ 的模型中，隐层节点的激活函数采用
标确实有一定的提升，但是随着负采样比率提高到 ＲｅＬＵ，输出节点的激活函数采用Ｓｉｇｍｏｉｄ．此外，如
１∶５０，ＤＰＳＮ模型的ＬｏｇＬｏｓｓ指标的值将会大幅增 ４．２节所述，还增加了一种基于投票机制融合方案
加，从原始的０．００６增加到０．０１４４．这是由于１４５８ ＦＮＮ＋ＰＮＮ．实验分别基于ｉＰｉｎＹｏｕ和Ｃｒｉｔｅｏ数据
中的正样本的数量非常少（２４５４），负采样后将使得 集完成，实验结果如表１３和表１４所示．
表１３ 典型ＣＴＲ预测模型在ｉＰｉｎＹｏｕ上的性能对比
１４５８ ３３８６ ３３５８ ３４２７
模型
ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３） ＡＵＣ ＬｏｇＬｏｓｓ（１０－３）
ＬＲ ０．７０１７ ６．５５７６ ０．７９０２ ５．９４９３ ０．８１０２ ６．０８３６ ０．７５１５ ５．２９７０
ＦＭ ０．７０３８ ６．５６５１ ０．７９２２ ５．９６０６ ０．８０９１ ６．０６８２ ０．７５５５ ５．２８７５
ＧＢＤＴ＋ＬＲ ０．６９１４ ６．５８５３ ０．７７４９ ５．９７８２ ０．８０３０ ６．１１６８ ０．７２０３ ５．３３９４
ＦＮＮ ０．７０６２ ６．５６１３ ０．７９８６ ５．９１３６ ０．８００５ ６．１２６７ ０．７５８７ ５．２６２４
ＰＮＮ ０．７０６２ ６．５４６６ ０．８０３４ ５．９１５９ ０．８０９１ ６．０５７７ ０．７５８８ ５．２６１４
Ｗｉｄｅ＆Ｄｅｅｐ ０．７０２０ ６．５５６９ ０．７９５８ ５．９１４８ ０．８０８９ ６．０６２７ ０．７５０４ ５．２８６４
ＤｅｅｐＦＭ ０．７００６ ６．５６１５ ０．７９１４ ５．９４８０ ０．８０７４ ６．０７５７ ０．７４９２ ５．３０７８
ＦＮＮ＋ＰＮＮ ０．７０８０ ６．５３８８ ０．８０２２ ５．９０７４ ０．８０９１ ６．０７６６ ０．７５８７ ５．２５４５
ＤＰＳＮ ０．７１２６ ６．５３６１ ０．８０４６ ５．９０２１ ０．８１００ ６．０５７４ ０．７５９３ ５．２６１６
表１４ 典型ＣＴＲ预测模型在Ｃｒｉｔｅｏ上的性能对比 图１３首先比较了三种浅层结构的ＣＴＲ预测模
ＡＵＣ 提升／％ ＬｏｇＬｏｓｓ（１０－３） 提升／％ 型在ｉＰｉｎＹｏｕ数据集上的性能．可以发现ＧＢＤＴ＋
ＬＲ ０．７６５６ ０ ４．７８７ ０
ＬＲ的预测性能是最差的，该模型采用ＧＢＤＴ来进
ＦＭ ０．７８７１ ２．８０８ ４．６３３ ３．２１７
ＦＮＮ ０．８００４ ４．５４５ ４．５０６ ５．８７０ 行自动的有效特征组合筛选，然后将筛选出的组合特
ＰＮＮ ０．８００５ ４．５５９ ４．５０４ ５．９１２
征向量拼接后输入到ＬＲ中，因此模型的预测性能
Ｗｉｄｅ＆Ｄｅｅｐ ０．８００９ ４．６１１ ４．４９９ ６．０１６
ＤｅｅｐＦＭ ０．８００２ ４．５１９ ４．５０３ ５．９３３ 依赖于ＧＢＤＴ对组合特征的筛选能力，在本实验中
ＦＮＮ＋ＰＮＮ ０．８００６ ４．５７２ ４．４９９ ６．０１６
ＤＰＳＮ ０．８０１２ ４．６５０ ４．４９４ ６．１２１
由于内存限制的原因，没有更细粒度的对ＧＢＤＴ进 １５８４ 计 算 机 学 报 ２０１９年
行调优（例如决策子树的数量），因此性能在ｉＰｉｎＹｏｕ 择与原论文不同，导致预测性能略低于单一结构．另
四个数据集上都略低于ＬＲ．ＦＭ 在ＡＵＣ指标上比 一方面，直接采用两种训练好的模型通过投票的方
ＬＲ分别提升了０．２９９％（１４５８）、０．２６２％（３３８６）、 式进行融合的ＦＮＮ＋ＰＮＮ获得了非常好的预测性
０．５４２％（３４２７），这是因为ＬＲ只考虑了一阶特征的 能，例如对于１４５８数据集在 ＡＵＣ上比ＦＮＮ提升
信息作为输入，而ＦＭ 不仅考虑了一阶特征的权重 了０．２６９％，在ＬｏｇＬｏｓｓ指标上提升了０．１３９％．最
信息，而且考虑二阶特征组合的权重信息，因此能获 后，本文提出的ＤＰＳＮ模型在ｉＰｉｎＹｏｕ的四个数据
得较好的结果． 集上获得了最优的性能提升，说明了一阶特征权重
信息和融合结构的设计确实能够挖掘出更多对
ＣＴＲ预测有效的高阶特征组合．
图１３ 三种浅层结构的预测模型的性能对比
图１４展示了ｉＰｉｎＹｏｕ数据集上５种基于深度
学习的预测模型与ＤＰＳＮ模型的性能对比．首先可 图１４ 基于深度学习的预测模型的性能对比
以观察到，单一结构的深度学习模型ＦＮＮ和ＰＮＮ
表１５展示了几种典型ＣＴＲ预测模型在ｉＰｉｎＹｏｕ
的性能都优于浅层结构模型的预测性能，例如在
１４５８和３３８６数据集上需要学习的模型参数的量．
１４５８和３３８６上，ＦＮＮ的ＡＵＣ比ＦＭ提升了０．３４１％
可以发现，由于基于独热编码后的原始特征向量，线
和０．８１０％，ＰＮＮ的ＡＵＣ比ＦＭ提升了０．３４１％和
性ＬＲ的模型参数与特征数一致；ＦＭ 模型虽然仍
１．４１２％．这说明深度学习模型确实在特征的高阶组
然基于原始特征，参数比ＬＲ模型有所增加，但是由
合学习方面具有显著的优势．其次，ＰＮＮ的性能略
于引入向量内积作为特征两两组合的权重，因此有
优于ＦＮＮ，这是因为ＰＮＮ的输入信息不仅考虑了
效避免了对二阶特征组合的权重参数的学习；ＦＮＮ
一阶特征的相关信息，也考虑了二阶特征组合的权
和ＰＮＮ都是深度神经网络，因此模型参数只依赖
重信息，因此能获得比ＦＮＮ 更优的性能．遗憾的
于特征域数目、嵌入向量维度、模型结构，这里对于
是，在ｉＰｉｎＹｏｕ数据集上，基于联合学习的 Ｗｉｄｅ ＆
１４５８和３３８６数据集，这些基本参数都相同，因此需
Ｄｅｅｐ和ＤｅｅｐＦＭ的预测性能都略低于单一结构的
要学习的参数量也是相同的，而ＰＮＮ由于引入了
ＦＮＮ和ＰＮＮ，分析原因可能是 Ｗｉｄｅ ＆Ｄｅｅｐ中增
一个Ｐｒｏｄｕｃｔ层，因此需要学习的参数量比ＦＮＮ有
加了手动特征工程部分，而本文实验中由于无法获
所增加；ＤｅｅｐＦＭ是融合结构，需要学习两个模型的
知手动特征组合的信息，因此直接将线性部分的组
参数，且每个嵌入向量的值也是作为模型参数学习
合特征省略掉；ＤｅｅｐＦＭ 则有可能是优化算法的选
的，因此需要学习的参数量较大；ＤＰＳＮ学习的模型 ７期 刘梦娟等：基于融合结构的在线广告点击率预测模型 １５８５
参数量略低于ＤｅｅｐＦＭ，但是它的嵌入向量和一阶 验３通过调整ＤＰＳＮ模型的超参数对ＤＰＳＮ的预
特征权重需要基于ＦＭ 预训练，如果将预训练参数 测性能进行了全面分析；实验４验证了在嵌入层加
也作为模型参数，则ＤＰＳＮ需要学习的参数量是最 入一阶特征权重信息对ＤＰＳＮ模型预测性能的提
大的． 升；实验５通过单一Ｄｅｅｐ Ｎｅｔｗｏｒｋ结构和Ｐｒｏｄｕｃｔ
Ｎｅｔｗｏｒｋ结构，与ＤＰＳＮ融合结构的性能对比，验
表１５ 不同预测模型的模型参数复杂度
证了ＤＰＳＮ融合结构确实能将两个不同 ＤＮＮ学
ＬＲ ＦＭ ＦＮＮ ＰＮＮ ＤｅｅｐＦＭ ＤＰＳＮ
习到的高阶特征组合进行融合，从而得到更为有
１４５８ ５６０８０３ ６１６８８２３ ５８２００１ ６４２００１ ６７５０８２４ ２９９２５０１
３３８６ ５５６８８４ ６１２５７２５ ５８２００１ ６４２００１ ６７０７７２６ １４８９５０１ 效的高阶特征组合模式；实验６通过不同比率的负
采样实验，分析了负采样对 ＤＰＳＮ 模型性能的影
为了进一步验证ＤＰＳＮ模型的性能，实验７在
响；实验７通过在两个数据集上将目前已有的典型
一个更大的数据集Ｃｒｉｔｅｏ上进行了典型模型的性
ＣＴＲ预测模型与本文提出的ＤＰＳＮ模型的预测性
能对比．表１４中显示的结果基本与ｉＰｉｎＹｏｕ上的实
能进行了对比，从实验的角度验证了ＤＰＳＮ模型的
验结果一致．首先，在浅层结构的模型中，只考虑一
优越性．
阶特征的ＬＲ的性能略低于同时考虑一阶和二阶特
征的ＦＭ；其次，基于深度学习的预测模型的性能略
５ 结束语
优于浅层结构模型的性能；然后，Ｗｉｄｅ ＆Ｄｅｅｐ和基
于投票的融合结构的深度学习模型的性能又进一步
将深度学习模型应用于ＣＴＲ预测已经逐渐成
优于基于单一结构的深度学习模型；最后，本文提出
为一种新的研究趋势．本论文在深入研究已有的深
的ＤＰＳＮ模型确实能够获得目前最优的性能．实验
度学习模型的基础上，提出一种新的融合结构，使得
结果的对比如图１５所示．
可以分别利用两个不同的深度神经网络学习样本特
征的高阶表示，从而捕捉到更多可用信息，提升
ＣＴＲ预测的准确率．论文的主要贡献包括：（１）设计
了一个新嵌入层结构，不仅包括特征的嵌入向量节
点，还包括一阶特征的权重单元，实验４证明了只需
增加很少的参数学习复杂度，即可获得预测性能的
提升；（２）设计了一个新的融合结构，可以巧妙地融
合不同的模型进行特征表示的学习，该结构不仅可
以融合两个深度模型，也可以融合深度模型和浅层
模型，或者两个浅层模型；（３）通过真实广告投放的
数据集对所提出的融合模型进行了性能验证，大量
实验表明本文提出的ＤＰＳＮ模型确实能够有效提
升预测性能，且详细讨论了不同模型参数对预测性
能的影响．
尽管ＣＴＲ预测模型的研究已经引起了无论是
工业界还是学术界大量的关注，遗憾的是，目前
ＣＴＲ预测模型的性能在实际广告投放系统中的表
现仍然不太理想．分析原因包括实际数据与样本数
据分布不一致，正样本太少，新广告投放冷启动等问
图１５ 代表模型在Ｃｒｉｔｅｏ数据集上的性能对比
题．针对正样本太少的问题，目前热门的ＧＡＮ［３１］模
综上所述，本文在第４节通过实验的方式对本文 型可以用来辅助生成正样本；针对新广告投放的冷
提出的ＤＰＳＮ模型的性能进行了全面评价．实验１ 启动问题，一种可行的解决方案是使用迁移学习，在
在ｉＰｉｎＹｏｕ １４５８和３３８６数据集上验证了ＤＰＳＮ模 不同商品的数据集上进行知识的迁移，从而提高预
型的收敛性；实验２通过在基本的ＦＮＮ和ＰＮＮ模 测准确率．深度学习模型也比较适合应用迁移学习，
型中增加一阶特征权重信息作为输入，验证了在嵌 可以减少模型训练的时间与开销，文献［３２］中已经
入层增加预训练的一阶特征权重节点的有效性；实 就ＤＮＮ的可迁移性给出了很好的探索和证明．此 １５８６ 计 算 机 学 报 ２０１９年
外，强化学习在广告投放中的尝试也取得了很好的 ［１１］ Ｈｅ Ｘｉｎｒａｎ，Ｐａｎ Ｊｕｎｆｅｎｇ，Ｊｉｎ Ｏｕ，ｅｔ ａｌ．Ｐｒａｃｔｉｃａｌ ｌｅｓｓｏｎｓ
效果［３３－３４］；强化学习具有一些良好的性质，它可以使 ｆｒｏｍ ｐｒｅｄｉｃｔｉｎｇ ｃｌｉｃｋｓ ｏｎ ａｄｓ ａｔ Ｆａｃｅｂｏｏｋ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ＡＣＭ ＳＩＧＫＤＤ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ
用无标签数据，直接读取实际活动中的用户行为，这
Ｍｉｎｉｎｇ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１４：１－９
种更加高效；而且它可以轻易实现在线学习，不用离
［１２］ Ｋｒｉｚｈｅｖｓｋｙ Ａ，Ｓｕｔｓｋｅｖｅｒ Ｉ，Ｈｉｎｔｏｎ Ｇ Ｅ．ＩｍａｇｅＮｅｔ ｃｌａｓｓｉｆｉ－
线训练再发布预测，提高了效率；此外它可以利用更
ｃａｔｉｏｎ ｗｉｔｈ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
多数据特征，取得更好的广告效果．强化学习已经在 ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ
阿里和百度的广告商品系统中得到了实际运用，并 Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｌａｋｅ Ｔａｈｏｅ，ＵＳＡ，２０１２：１０９７－１１０５
取得了不错的效果①，因此借鉴强化学习的方法用
［１３］ Ｇｒａｖｅｓ Ａ，Ｍｏｈａｍｅｄ Ａ，Ｈｉｎｔｏｎ Ｇ．Ｓｐｅｅｃｈ ｒｅｃｏｇｎｉｔｉｏｎ ｗｉｔｈ
ｄｅｅｐ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ
于ＣＴＲ预测也将是可行的尝试．
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｃｏｕｓｔｉｃｓ，Ｓｐｅｅｃｈ ａｎｄ Ｓｉｇｎａｌ
Ｐｒｏｃｅｓｓｉｎｇ．Ｖａｎｃｏｕｖｅｒ，Ｃａｎａｄａ，２０１３：６６４５－６６４９
参 考 文 献 ［１４］ Ｓｈｅｎ Ｙｅｌｏｎｇ，Ｈｅ Ｘｉａｏｄｏｎｇ，Ｇａｏ Ｊｉａｎｆｅｎｇ，ｅｔ ａｌ．Ａ ｌａｔｅｎｔ
ｓｅｍａｎｔｉｃ ｍｏｄｅｌ ｗｉｔｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ－ｐｏｏｌｉｎｇ ｓｔｒｕｃｔｕｒｅ ｆｏｒ
［１］ Ｃｈａｐａｌｌｅ Ｏ．Ｏｆｆｌｉｎｅ ｅｖａｌｕａｔｉｏｎ ｏｆ ｒｅｓｐｏｎｓｅ ｐｒｅｄｉｃｔｉｏｎ ｉｎ ｉｎｆｏｒｍａｔｉｏｎ ｒｅｔｒｉｅｖａｌ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ
ｏｎｌｉｎｅ ａｄｖｅｒｔｉｓｉｎｇ ａｕｃｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ Ｋｎｏｗｌｅｄｇｅ
Ｃｏｎｆｅｒｅｎｃｅ ｏｆ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｆｌｏｒｅｎｃｅ，Ｉｔａｌｙ，２０１５：
Ｍａｎａｇｅｍｅｎｔ．Ｓｈａｎｇｈａｉ，Ｃｈｉｎａ，２０１４：１０１－１１０
［１５］ Ｑｕ Ｙａｎｒｕ，Ｃａｉ Ｈａｎ，Ｒｅｎ Ｋａｎ，ｅｔ ａｌ．Ｐｒｏｄｕｃｔ－ｂａｓｅｄ ｎｅｕｒａｌ
１８－２２
［２］ Ｃｈａｐａｌｌｅ Ｏ，Ｍａｎａｖｏｇｌｕ Ｅ，Ｒｏｓａｌｅｓ Ｒ．Ｓｉｍｐｌｅ ａｎｄ ｓｃａｌａｂｌｅ ｎｅｔｗｏｒｋｓ ｆｏｒ ｕｓｅｒ ｒｅｓｐｏｎｓｅ ｐｒｅｄｉｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｒｅｓｐｏｎｓｅ ｐｒｅｄｉｃｔｉｏｎ ｆｏｒ ｄｉｓｐｌａｙ ａｄｖｅｒｔｉｓｉｎｇ．Ｊｏｕｒｎａｌ ｏｆ ＡＣＭ
ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｄａｔａ Ｍｉｎｉｎｇ．Ｂａｒｃｅｌｏｎａ，
Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｉｎｔｅｌｌｉｇｅｎｔ Ｓｙｓｔｅｍｓ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，２０１５，
Ｓｐａｉｎ，２０１６：１－６
５（４）：６１ ［１６］ Ｃｈｅｎｇ Ｈ－Ｔ，Ｋｏｃ Ｌ，Ｈａｒｍｓｅｎ Ｊ，ｅｔ ａｌ．Ｗｉｄｅ ＆ｄｅｅｐ ｌｅａｒｎｉｎｇ
［３］ Ｒｉｃｈａｒｄｓｏｎ Ｍ，Ｄｏｍｉｎｏｗｓｋａ Ｅ，Ｒａｇｎｏ Ｒ．Ｐｒｅｄｉｃｔｉｎｇ ｃｌｉｃｋｓ： ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｗｏｒｋｓｈｏｐ ｏｎ
Ｅｓｔｉｍａｔｉｎｇ ｔｈｅ ｃｌｉｃｋ－ｔｈｒｏｕｇｈ ｒａｔｅ ｆｏｒ ｎｅｗ ａｄｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ Ｄｅｅｐ Ｌｅａｒｎｉｎｇ ｆｏｒ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｂｏｓｔｏｎ，ＵＳＡ，
ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｆ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｂａｎｆｆ
２０１６：１－４
Ａｌｂｅｒｔａ，Ｃａｎａｄａ，２００７：８－１２ ［１７］ Ｇｕｏ Ｈｕｉｆｅｎｇ，Ｔａｎｇ Ｒｕｉｍｉｎｇ，Ｙｅ Ｙｕｎｍｉｎｇ，ｅｔ ａｌ．ＤｅｅｐＦＭ：
［４］ ＭｃＭａｈａｎ Ｈ Ｂ，Ｈｏｌｔ Ｇ，Ｓｃｕｌｌｅｙ．Ｄ，ｅｔ ａｌ．Ａｄ ｃｌｉｃｋ ｐｒｅｄｉｃｔｉｏｎ： Ａ ｆａｃｔｏｒｉｚａｔｉｏｎ－ｍａｃｈｉｎｅ ｂａｓｅｄ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｆｏｒ ｃｔｒ ｐｒｅｄｉｃｔｉｏｎ
Ａ ｖｉｅｗ ｆｒｏｍ ｔｈｅ ｔｒｅｎｃｈｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＡＣＭ Ｓｐｅｃｉａｌ ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ
Ｉｎｔｅｒｅｓｔ Ｇｒｏｕｐ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ｉｎ Ｄａｔａ．Ｃｈｉｃａｇｏ
Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｍｅｌｂｏｕｒｎｅ，Ａｕｓｔｒａｌｉａ，２０１７：１－７
Ｉｌｌｉｎｏｉｓ，ＵＳＡ，２０１３：１１－１４ ［１８］ Ｌｅｅ Ｋ－Ｃ，Ｏｒｔｅｎ Ｂ Ｂ，Ｄａｓｄａｎ Ａ，Ｌｉ Ｗｅｎｔｏｎｇ．Ｅｓｔｉｍａｔｉｎｇ
［５］ Ｚｈａｎｇ Ｗｅｉｎａｎ，Ｄｕ Ｔｉａｎｍｉｎｇ，Ｗａｎｇ Ｊｕｎ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ｏｖｅｒ ｃｏｎｖｅｒｓｉｏｎ ｒａｔｅ ｉｎ ｄｉｓｐｌａｙ ａｄｖｅｒｔｉｓｉｎｇ ｆｒｏｍ ｐａｓｔ ｐｅｒｆｏｒｍａｎｃｅ
ｍｕｌｔｉ－ｆｉｅｌｄ ｃａｔｅｇｏｒｉｃａｌ ｄａｔａ：Ａ ｃａｓｅ ｓｔｕｄｙ ｏｎ ｕｓｅｒ ｒｅｓｐｏｎｓｅ ｄａｔａ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＡＣＭ Ｓｐｅｃｉａｌ Ｉｎｔｅｒｅｓｔ Ｇｒｏｕｐ ｏｎ
ｐｒｅｄｉｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｅｕｒｏｐｅａｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ｉｎ Ｄａｔａ．Ｂｅｉｊｉｎｇ，Ｃｈｉｎａ，２０１２：７６８－７７６
Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ｐａｄｕａ，Ｉｔａｌｙ，２０１６：４５－５７ ［１９］ Ｌｉａｏ Ｈａｉｒｅｎ，Ｐｅｎｇ Ｌｉｎｇｘｉａｏ，Ｌｉｕ Ｚｈｅｎｇｃｈｕａｎ，Ｓｈｅｎ Ｘｕｅｈｕａ．
［６］Ｊｕａｎ Ｙｕｃｈｉｎ，Ｚｈｕａｎｇ Ｙｏｎｇ，Ｃｈｉｎ Ｗｅｉ－Ｓｈｅｎｇ，Ｌｉｎ Ｃｈｉｈ－Ｊｅｎ． ｉＰｉｎＹｏｕ ｇｌｏｂａｌ ＲＴＢ ｂｉｄｄｉｎｇ ａｌｇｏｒｉｔｈｍ ｃｏｍｐｅｔｉｔｉｏｎ ｄａｔａｓｅｔ／／
Ｆｉｅｌｄ－ａｗａｒｅ ｆａｃｔｏｒｉｚａｔｉｏｎ ｍａｃｈｉｎｅｓ ｆｏｒ ＣＴＲ ｐｒｅｄｉｃｔｉｏｎ／／ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＡＣＭ ＳＩＧＫＤＤ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｓｓｏｃｉａｔｉｏｎ ｆｏｒ Ｃｏｍｐｕｔｉｎｇ Ｍａｃｈｉｎｅｒｙ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１４：１－６
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１６：４３－５０ ［２０］ Ｎａｉｒ Ｖ，Ｈｉｎｔｏｎ Ｇ Ｅ．Ｒｅｃｔｉｆｉｅｄ ｌｉｎｅａｒ ｕｎｉｔｓ ｉｍｐｒｏｖｅ ｒｅｓｔｒｉｃｔｅｄ
［７］ Ｃｈａｎｇ Ｙｉｎ－Ｗｅｎ，Ｈｓｉｅｈ Ｃｈｏ－Ｊｕｉ，Ｃｈａｎｇ Ｋａｉ－Ｗｅｉ，ｅｔ ａｌ． Ｂｏｌｔｚｍａｎｎ ｍａｃｈｉｎｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ
Ｔｒａｉｎｉｎｇ ａｎｄ ｔｅｓｔｉｎｇ ｌｏｗ－ｄｅｇｒｅｅ ｐｏｌｙｎｏｍｉａｌ ｄａｔａ ｍａｐｐｉｎｇｓ ｖｉａ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｈａｉｆａ，Ｉｓｒａｅｌ，２０１０：８０７－８１４
ｌｉｎｅａｒ ＳＶＭ．Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，２０１０， ［２１］ Ｍａｒｒｅｉｒｏｓ Ａ Ｃ，Ｄａｕｎｉｚｅａｕ Ｊ，Ｋｉｅｂｅｌ Ｓ Ｊ，Ｆｒｉｓｔｏｎ Ｋ Ｊ．
１１（１）：１４７１－１４９０ Ｐｏｐｕｌａｔｉｏｎ ｄｙｎａｍｉｃｓ：Ｖａｒｉａｎｃｅ ａｎｄ ｔｈｅ Ｓｉｇｍｏｉｄ ａｃｔｉｖａｔｉｏｎ
［８］ Ｂｅｃｋ Ｊ Ｅ，Ｗｏｏｌｆ Ｂ Ｐ．Ｈｉｇｈ－ｌｅｖｅｌ ｓｔｕｄｅｎｔ ｍｏｄｅｌｉｎｇ ｗｉｔｈ ｆｕｎｃｔｉｏｎ．ＮｅｕｒｏＩｍａｇｅ，２００８，４２（１）：１４７－１５７
ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ［２２］ Ｘｕ Ｚ，Ｃｈａｎｇ Ｘ，Ｘｕ Ｆ，Ｚｈａｎｇ Ｈ．Ｌ１／２ｒｅｇｕｌａｒｉｚａｔｉｏｎ：Ａ
ｏｎ Ｉｎｔｅｌｌｉｇｅｎｔ Ｔｕｔｏｒｉｎｇ Ｓｙｓｔｅｍｓ．Ｂｅｒｌｉｎ，Ｇｅｒｍａｎｙ，２０００： ｔｈｒｅｓｈｏｌｄｉｎｇ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｔｈｅｏｒｙ ａｎｄ ａ ｆａｓｔ ｓｏｌｖｅｒ．ＩＥＥＥ
５８４－５９３ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ ＆Ｌｅａｒｎｉｎｇ Ｓｙｓｔｅｍｓ，
［９］ Ｏｅｎｔａｒｙｏ Ｒ Ｊ，Ｌｉｍ Ｅｅ－Ｐｅｎｇ，Ｌｏｗ Ｊｉａ－Ｗｅｉ，ｅｔ ａｌ．Ｐｒｅｄｉｃｔｉｎｇ ２０１２，２３（７）：１０１３－１０２７
ｒｅｓｐｏｎｓｅ ｉｎ ｍｏｂｉｌｅ ａｄｖｅｒｔｉｓｉｎｇ ｗｉｔｈ ｈｉｅｒａｒｃｈｉｃａｌ ｉｍｐｏｒｔａｎｃｅ－ ［２３］ Ｋｅｔｋａｒ Ｎ．Ｄｅｅｐ Ｌｅａｒｎｉｎｇ ｗｉｔｈ Ｐｙｔｈｏｎ．Ｂｅｒｋｅｌｅｙ，ＣＡ，
ａｗａｒｅ ｆａｃｔｏｒｉｚａｔｉｏｎ ｍａｃｈｉｎｅ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＡＣＭ ＵＳＡ：Ａｐｒｅｓｓ，２０１７
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ． ［２４］ Ｂｏｔｔｏｕ Ｌ．Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ：Ｔｒｉｃｋｓ ｏｆ ｔｈｅ Ｔｒａｄｅ．Ｂｅｒｌｉｎ，
Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１４：１２３－１３２ Ｇｅｒｍａｎｙ：Ｓｐｒｉｎｇｅｒ，２０１２
［１０］ Ｒｅｎｄｌｅ Ｓ．Ｆａｃｔｏｒｉｚａｔｉｏｎ ｍａｃｈｉｎｅｓ ｗｉｔｈ ｌｉｂＦＭ．ＡＣＭ Ｔｒａｎｓ－
ａｃｔｉｏｎｓ ｏｎ Ｉｎｔｅｌｌｉｇｅｎｔ Ｓｙｓｔｅｍｓ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，２０１２，３（３）： ① 《不一样的技术创新》．ｈｔｔｐｓ：／／ｙｑ．ａｌｉｙｕｎ．ｃｏｍ／ａｒｔｉｃｌｅｓ／
１－２２ ６８６１７ ７期 刘梦娟等：基于融合结构的在线广告点击率预测模型 １５８７
［２５］ Ｂｏｙｄ Ｓ，Ｖａｎｄｅｎｂｅｒｇｈｅ Ｌ．Ｃｏｎｖｅｘ Ｏｐｔｉｍｉｚａｔｉｏｎ．Ｃａｍｂｒｉｄｇｅ， ｓｉｍｐｌｅ ｗａｙ ｔｏ ｐｒｅｖｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｒｏｍ ｏｖｅｒｆｉｔｔｉｎｇ．Ｊｏｕｒｎａｌ
ＵＫ：Ｃａｍｂｒｉｄｇｅ Ｕｎｉｖｅｒｓｉｔｙ Ｐｒｅｓｓ，２００４ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，２０１４，１５（１）：１９２９－１９５８
［２６］ Ｂｏｔｔｏｕ Ｌ，Ｃｕｒｔｉｓ Ｆ Ｅ，Ｎｏｃｅｄａｌ Ｊ．Ｏｐｔｉｍｉｚａｔｉｏｎ ｍｅｔｈｏｄｓ ｆｏｒ ［３１］ Ｇｏｏｄｆｅｌｌｏｗ Ｉ Ｊ，Ａｂａｄｉｅ Ｊ Ｐ，Ｍｉｒｚａ Ｍ，ｅｔ ａｌ．Ｇｅｎｅｒａｔｉｖｅ
ｌａｒｇｅ－ｓｃａｌｅ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ．Ｓｏｃｉｅｔｙ ｆｏｒ Ｉｎｄｕｓｔｒｉａｌ ａｎｄ ａｄｖｅｒｓａｒｉａｌ ｎｅｔｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ
Ａｐｐｌｉｅｄ Ｍａｔｈｅｍａｔｉｃｓ，２０１８，６０（２）：２２３－３１１ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，２０１４：
［２７］Ｊａｐｋｏｗｉｃａ Ｎ，Ｓｔｅｐｈｅｎ Ｓ．Ｔｈｅ ｃｌａｓｓ ｉｍｂａｌａｎｃｅ ｐｒｏｂｌｅｍ：Ａ ２６７２－２６８０
ｓｙｓｔｅｍａｔｉｃ ｓｔｕｄｙ．Ｉｎｔｅｌｌｉｇｅｎｔ Ｄａｔａ Ａｎａｌｙｓｉｓ，２００２，６（５）： ［３２］ Ｙｏｓｉｎｓｋｉ Ｊ，Ｃｌｕｎｅ Ｊ，Ｂｅｎｇｉｏ Ｙ，Ｌｉｐｓｏｎ Ｈ．Ｈｏｗ ｔｒａｎｓｆｅｒａｂｌｅ
４２９－４４９ ａｒｅ ｆｅａｔｕｒｅｓ ｉｎ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
［２８］ Ｇｒａｅｐｅｌ Ｔ，Ｃａｎｄｅｌａ Ｊ Ｑ，Ｂｏｒｃｈｅｒｔ Ｔ，Ｈｅｒｂｒｉｃｈ Ｒ．Ｗｅｂ－ｓｃａｌｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｍｏｎｔｒｅａｌ，
Ｂａｙｅｓｉａｎ ｃｌｉｃｋ－ｔｈｒｏｕｇｈ ｒａｔｅ ｐｒｅｄｉｃｔｉｏｎ ｆｏｒ ｓｐｏｎｓｏｒｅｄ ｓｅａｒｃｈ Ｃａｎａｄａ，２０１４：３３２０－３３２８
ａｄｖｅｒｔｉｓｉｎｇ ｉｎ Ｍｉｃｒｏｓｏｆｔ’ｓ ｂｉｎｇ ｓｅａｒｃｈ ｅｎｇｉｎｅ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ［３３］ Ｋｒａｋｏｖｓｋｙ Ｍ．Ｒｅｉｎｆｏｒｃｅｍｅｎｔ ｒｅｎａｉｓｓａｎｃｅ．Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ
ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｈａｉｆａ， ｏｆ ｔｈｅ ＡＣＭ，２０１６，５９（８）：１２－１４
Ｉｓｒａｅｌ，２０１０：１３－２０ ［３４］ Ｖｏｌｏｄｙｍｙｒ Ｍ，Ｋｏｒａｙ Ｋ，Ｄａｖｉｄ Ｓ，ｅｔ ａｌ．Ｐｌａｙｉｎｇ Ａｔａｒｉ ｗｉｔｈ
［２９］ Ｖｏｖｋ Ｖ．Ｔｈｅ Ｆｕｎｄａｍｅｎｔａｌ Ｎａｔｕｒｅ ｏｆ ｔｈｅ Ｌｏｇ Ｌｏｓｓ Ｆｕｎｃｔｉｏｎ． ｄｅｅｐ ｒｅｉｎｆｏｒｃｅｍｅｎｔ ｌｅａｒｎｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｎｅｕｒａｌ
Ｂｅｒｎ，Ｓｗｉｔｚｅｒｌａｎｄ：Ｓｐｒｉｎｇｅｒ，２０１５，９３００：３０７－３１８ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ Ｃｏｎｆｅｒｅｎｃｅ．Ｌａｋｅ Ｔａｈｏｅ，
［３０］ Ｓｒｉｖａｓｔａｖａ Ｎ，Ｈｉｎｔｏｎ Ｇ，Ｋｒｉｚｈｅｖｓｋｙ Ａ，ｅｔ ａｌ．Ｄｒｏｐｏｕｔ：Ａ ＵＳＡ，２０１３：１－９
ＬＩＵ Ｍｅｎｇ－Ｊｕａｎ，Ｐｈ．Ｄ．，ａｓｓｏｃｉａｔｅ ｌｅａｒｎｉｎｇ．
ｐｒｏｆｅｓｓｏｒ．Ｈｅｒ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ＹＵＥ Ｗｅｉ，Ｍ．Ｓ．ｃａｎｄｉｄａｔｅ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ
ｄａｔａ ｍｉｎｉｎｇ，ｃｏｍｐｕｔａｔｉｏｎａｌ ａｄｖｅｒｔｉｓｉｎｇ， ｉｎｃｌｕｄｅ ｃｏｍｐｕｔａｔｉｏｎａｌ ａｄｖｅｒｔｉｓｉｎｇ ａｎｄ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ．
ａｎｄ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ． ＬＩＵ Ｙａｏ，Ｐｈ．Ｄ．，ａｓｓｏｃｉａｔｅ ｐｒｏｆｅｓｓｏｒ．Ｈｅｒ ｒｅｓｅａｒｃｈ
ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｓｏｃｉａｌ ｎｅｔｗｏｒｋ，ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ａｎｄ ｄａｔａ
ｍｉｎｉｎｇ．
ＱＩＮ Ｚｈｉ－Ｇｕａｎｇ，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ
ＺＥＮＧ Ｇｕｉ－Ｃｈｕａｎ， Ｍ．Ｓ．ｃａｎｄｉｄａｔｅ． Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｃｌｕｄｅ ｄａｔａ ｍｉｎｉｎｇ ａｎｄ ｎｅｔｗｏｒｋ ｓｅｃｕｒｉｔｙ．
ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｃｏｍｐｕｔａｔｉｏｎａｌ ａｄｖｅｒｔｉｓｉｎｇ ａｎｄ ｍａｃｈｉｎｅ
Ｂａｃｋｇｒｏｕｎｄ
Ｉｎ ｒｅｃｅｎｔ ｙｅａｒｓ，ｏｎｌｉｎｅ ａｄｖｅｒｔｉｓｉｎｇ ｈａｓ ｄｅｖｅｌｏｐｅｄ ｉｎｔｏ ａ ｓａｍｐｌｅｓ ｔｈａｔ ａｒｅ ｒｅａｌｌｙ ｃｌｉｃｋｅｄ ｉｎ ｔｈｅ ｄａｔａｓｅｔ ｉｓ ｅｘｔｒｅｍｅｌｙ
ｍｕｌｔｉ－ｂｉｌｌｉｏｎ ｄｏｌｌａｒ ｉｎｄｕｓｔｒｙ．Ａｓ ｏｎｅ ｏｆ ｔｈｅ ｍｏｓｔ ｅｘｃｉｔｉｎｇ ｓｍａｌｌ．
ａｄｖａｎｃｅｓ ｉｎ ｏｎｌｉｎｅ ａｄｖｅｒｔｉｓｉｎｇ，ａｄｖｅｒｔｉｓｉｎｇ ｔａｒｇｅｔｅｄ ｄｅｌｉｖｅｒｙ Ｉｎ ｔｈｉｓ ｐａｐｅｒ，ｗｅ ｆｉｒｓｔｌｙ ｓｔｕｄｙ ｓｅｖｅｒａｌ ｔｙｐｉｃａｌ ＣＴＲ
ｈａｓ ｒｅｃｅｉｖｅｄ ｉｎｃｒｅａｓｉｎｇ ａｔｔｅｎｔｉｏｎ，ｓｉｎｃｅ ｉｔ ｉｍｐｒｏｖｅｓ ｔｈｅ ｅｆｆｉｃｉｅｎｃｙ ｐｒｅｄｉｃｔｉｏｎ ｍｏｄｅｌｓ，ｅｓｐｅｃｉａｌｌｙ ｔｈｅ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｍｏｄｅｌｓ ｂａｓｅｄ
ａｎｄ ｔｒａｎｓｐａｒｅｎｃｙ ｉｎ ｔｈｅ ｏｎｌｉｎｅ ａｄｖｅｒｔｉｓｉｎｇ ｅｃｏｓｙｓｔｅｍ．Ｔｈｅ ｏｎ ｆｕｓｉｏｎ ａｒｃｈｉｔｅｃｔｕｒｅ；ａｎｄ ｔｈｅｎ ａ ｎｅｗ ｃｌｉｃｋ－ｔｈｒｏｕｇｈ ｒａｔｅ
ｐｒｏｂｌｅｍ ｓｔｕｄｉｅｄ ｉｎ ｔｈｉｓ ｐａｐｅｒ ｉｓ ｔｏ ｕｓｅ ｔｈｅ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ｐｒｅｄｉｃｔｉｏｎ ｍｏｄｅｌ ｂａｓｅｄ ｏｎ ａ ｈｙｂｒｉｄ ｎｅｔｗｏｒｋ ｉｓ ｐｒｏｐｏｓｅｄ．Ｔｈｅ
ｍｏｄｅｌｓ，ｅｓｐｅｃｉａｌｌｙ ｔｈｅ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｍｏｄｅｌｓ ｔｏ ｐｒｅｄｉｃｔ ｔｈｅ ｎｅｗ ｍｏｄｅｌ ｃａｎ ｉｎｔｅｇｒａｔｅ ｆｌｅｘｉｂｌｙ ｄｉｆｆｅｒｅｎｔ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ
ｃｌｉｃｋ－ｔｈｒｏｕｇｈ ｒａｔｅｓ（ＣＴＲｓ），ｗｈｉｃｈ ｉｓ ａ ｔｙｐｉｃａｌ ｒｅｇｒｅｓｓｉｏｎ （ＤＮＮｓ）ｔｏ ｌｅａｒｎ ｔｈｅ ｈｉｇｈ－ｏｒｄｅｒ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｏｆ ｏｒｉｇｉｎａｌ
ｐｒｏｂｌｅｍ．Ｄｕｅ ｔｏ ｔｈｅ ｈｕｇｅ ｃｏｍｍｅｒｃｉａｌ ｖａｌｕｅ ｏｆ ＣＴＲ ｐｒｅｄｉｃｔｉｏｎ ｈｉｇｈ－ｄｉｍｅｎｓｉｏｎａｌ ｓｐａｒｓｅ ｆｅａｔｕｒｅｓ ｒｅｓｐｅｃｔｉｖｅｌｙ，ｗｈｉｃｈ ｅｎａｂｌｅｓ
ｉｎ ｏｎｌｉｎｅ ａｄｖｅｒｔｉｓｉｎｇ，ｔｈｅｒｅ ａｒｅ ｅｘｔｅｎｓｉｖｅ ｒｅｓｅａｒｃｈｅｓ ｏｎ ＣＴＲ ｔｈｅ ｐｒｅｄｉｃｔｉｏｎ ｍｏｄｅｌ ｔｏ ｔａｋｅ ａｄｖａｎｔａｇｅ ｏｆ ｍｏｒｅ ａｂｕｎｄａｎｔ
ｐｒｅｄｉｃｔｉｏｎ ｔｈｉｓ ｆｉｅｌｄ．Ｔｈｅ ｍｏｓｔ ｗｉｄｅｌｙ ｕｓｅｄ ｍｏｄｅｌ ｉｓ ｔｏ ｅｓｔａｂｌｉｓｈ ｉｎｆｏｒｍａｔｉｏｎ ｏｆ ｈｉｇｈ－ｏｒｄｅｒ ｆｅａｔｕｒｅ ｉｎｔｅｒａｃｔｉｏｎｓ．Ｗｅ ｅｖａｌｕａｔｅ
ｔｈｅ ＣＴＲ ｅｓｔｉｍａｔｏｒ ｂａｓｅｄ ｏｎ ｌｏｇｉｓｔｉｃ ｒｅｇｒｅｓｓｉｏｎｓ（ＬＲ）；ｉｎ ｔｈｅ ｐｅｒｆｏｒｍａｎｃｅ ｏｆ ｔｈｅ ｐｒｏｐｏｓｅｄ ｍｏｄｅｌ ｂａｓｅｄ ｏｎ ａ ｒｅａｌ－ｗｏｒｌｄ
ａｄｄｉｔｉｏｎ，ｆａｃｔｏｒｉｚａｔｉｏｎ ｍａｃｈｉｎｅ（ＦＭ）ａｎｄ ｆｉｅｌｄ－ａｗａｒｅ ｆａｃｔｏｒｉ－ ｄａｔａｓｅｔ，ａｎｄ ｔｈｅ ｅｘｐｅｒｉｍｅｎｔａｌ ｒｅｓｕｌｔｓ ｄｅｍｏｎｓｔｒａｔｅ ｔｈａｔ ｔｈｅ
ｚａｔｉｏｎ ｍａｃｈｉｎｅ（ＦＦＭ）ｈａｖｅ ａｌｓｏ ａｃｈｉｅｖｅｄ ｇｏｏｄ ｒｅｓｕｌｔｓ ｉｎ ｎｅｗ ｍｏｄｅｌ ｈａｓ ｂｅｔｔｅｒ ｐｅｒｆｏｒｍａｎｃｅ ｔｈａｎ ｍａｊｏｒ ｓｔａｔｅ－ｏｆ－ｔｈｅ－
ＣＴＲ ｐｒｅｄｉｃｔｉｏｎ，ｂｅｃａｕｓｅ ｔｈｅｙ ｃａｎ ｅｘｐｌｏｒｅ ｔｈｅ ｓｏｐｈｉｓｔｉｃａｔｅｄ ａｒｔ ｍｏｄｅｌｓ．Ｔｈｉｓ ｗｏｒｋ ｉｓ ｓｕｐｐｏｒｔｅｄ ｂｙ ｔｈｅ Ｎａｔｉｏｎａｌ Ｎａｔｕｒａｌ
ｆｅａｔｕｒｅ ｉｎｔｅｒａｃｔｉｏｎｓ ｂｙ ｍａｐｐｉｎｇ ｔｈｅｍ ｉｎｔｏ ａ ｌｏｗ ｄｉｍｅｎｓｉｏｎａｌ Ｓｃｉｅｎｃｅ Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｃｈｉｎａ（Ｎｏｓ．６１２０２４４５，６１５０２０８７），
ｓｐａｃｅ．Ｕｎｆｏｒｔｕｎａｔｅｌｙ，ｔｈｅ ｐｅｒｆｏｒｍａｎｃｅ ｏｆ ＣＴＲ ｐｒｅｄｉｃｔｉｏｎ ｉｓ ａｎｄ ｔｈｅ Ｆｕｎｄａｍｅｎｔａｌ Ｒｅｓｅａｒｃｈ Ｆｕｎｄｓ ｆｏｒ ｔｈｅ Ｃｅｎｔｒａｌ Ｕｎｉｖｅｒ－
ｎｏｔ ｉｄｅａｌ ａｔ ｐｒｅｓｅｎｔ，ｗｈｉｃｈ ｉｓ ｂｅｃａｕｓｅ ｕｓｅｒ’ｓ ｃｌｉｃｋ ｂｅｈａｖｉｏｒ ｉｓ ｓｉｔｉｅｓ（Ｎｏ．ＺＹＧＸ２０１６Ｊ０９６）．Ｔｈｅ ａｕｔｈｏｒｓ ｏｆ ｔｈｉｓ ｐａｐｅｒ ｈａｖｅ
ａ ｖｅｒｙ ｃｏｍｐｌｉｃａｔｅｄ ｐｓｙｃｈｏｌｏｇｉｃａｌ ｐｒｏｃｅｓｓ．Ｔｈｅｒｅ’ｒｅ ｍａｎｙ ｐｕｂｌｉｓｈｅｄ ｓｅｖｅｒａｌ ｒｅｌａｔｅｄ ｐａｐｅｒｓ ｏｎ ｔｈｅ ｃｏｎｆｅｒｅｎｃｅｓ ｒｅｃｏｍ－
ｆａｃｔｏｒｓ ａｆｆｅｃｔｉｎｇ ｔｈｅ ｃｌｉｃｋ ｂｅｈａｖｉｏｒ，ａｎｄ ｔｈｅ ｎｕｍｂｅｒ ｏｆ ｐｏｓｉｔｉｖｅ ｍｅｎｄｅｄ ｂｙ ＣＣＦ，ａｎｄ ａｐｐｌｉｅｄ ｆｏｒ ａ ｎｕｍｂｅｒ ｏｆ ｒｅｌａｔｅｄ ｐａｔｅｎｔｓ． --------------------------------------------------------------------------------- TOPIC 专题
大数据与推荐系统
李翠平，蓝梦微，邹本友，王绍卿，赵衎衎
中国人民大学数据工程与知识工程教育部重点实验室 北京 100872
摘要
随着大数据时代的来临，网络中的信息量呈现指数式增长，随之带来了信息过载问题。推荐系统是解决
信息过载最有效的方式之一，大数据推荐系统已经逐渐成为信息领域的研究热点。介绍了推荐系统的产
生及其在大数据时代的发展现状、推荐系统的领域需求和系统架构、大数据环境下推荐系统的挑战及其
关键技术、开源的大数据推荐软件、大数据推荐系统研究面临的问题，最后探讨了大数据推荐系统的未
来发展趋势。
关键词
大数据；推荐系统；协同过滤
doi: 10.11959/j.issn.2096-0271.2015026
Big Data and Recommendation System
Li Cuiping, Lan Mengwei, Zou Benyou, Wang Shaoqing, Zhao Kankan
Key Laboratory of Data Engineering and Knowledge Engineering, Ministry of Education, Renmin
University of China, Beijing 100872, China
Abstract
In big data era, recommendation system is the key means to tackle the issue of “information overload”.
Recommendation system has been widely applied to many domains. The most typical and promising domain is the
e-commence. Recently, with the rapid development of e-commence, recommendation system becomes more and
more important and is promoted as a hot research field. The history and development of recommendation system, its
domain requirements and system architecture, its characteristics and challenges under big data environment, its key
techniques, open source big data recommendation systems were introduced. And at last, the open research problems
and future trends of bid data recommendation system were discussed.
Key words
big data, recommendation system, collaborative filtering
2015026-1 BIG DATA RESEARCH 大数据
苏宁易购等。在这些电子商务平台中，网
站提供的商品数量不计其数，网站中的用
1 推荐系统与网络大数据 户规模也非常巨大。据不完全统计，天猫
商城中的商品数量已经超过了4 000万。
随着科技与信息技术的迅猛发展，社 在如此庞大的电商网站中，用户根据自己
会进入了一个全新的高度信息化的时代， 的购买意图输入关键字查询后，会得到很
互联网无处不在，影响了人类生活的方方 多相似的结果，用户在这些结果中也很难
面面，并彻底改变了人们的生活方式。尤其 区分异同，用户也难于选择合适的物品。
是进入Web 2.0时代以来，随着社会化网络 于是，推荐系统作为能够根据用户兴趣
媒体的异军突起，互联网用户既是网络信 为用户推荐一些用户感兴趣的商品，从而
息的消费者，也是网络内容的生产者，互联 为用户在购物的选择中提供建议的需求
网中的信息量呈指数级增长。由于用户的 非常明显。目前比较成功的电子商务网站
辨别能力有限，在面对庞大且复杂的互联 中，都不同程度地利用推荐系统在用户购
网信息时往往感到无从下手，使得在互联 物的同时，为用户推荐一些商品，从而提
网中找寻有用信息的成本巨大，产生了所 高网站的销售额。
谓的“信息过载”问题。 另一方面，智能手机的发展推动了移
搜索引擎和推荐系统的产生为解决 动互联网的发展。在用户使用移动互联网
“信息过载”问题提供了非常重要的技术 的过程中，其所处的地理位置等信息可以
手段。对于搜索引擎来说，用户在搜索互 非常准确地被获取。基于此，国内外出现
联网中的信息时，需要在搜索引擎中输入 了大量的基于用户位置信息的网站。国外
“查询关键词”，搜索引擎根据用户的输 比较著名的有Meetup和Flickr。国内著名
入，在系统后台进行信息匹配，将与用户 的有豆瓣网和大众点评网。例如，在大众
查询相关的信息展示给用户。但是，如果 点评这种基于位置服务的网站中，用户可
用户无法想到准确描述自己需求的关键 以根据自己的当前位置搜索餐馆、酒店、影
词，此时搜索引擎就无能为力了。和搜索 院、旅游景点等信息服务。同时，可以对当
引擎不同，推荐系统不需要用户提供明确 前位置下的各类信息进行点评，为自己在
的需求，而是通过分析用户的历史行为来 现实世界中的体验打分，分享自己的经验与
对用户的兴趣进行建模，从而主动给用户 感受。当用户使用这类基于位置的网站服
推荐可能满足他们兴趣和需求的信息。因 务时，同样会遭遇“信息过载”问题。推荐
此，搜索引擎和推荐系统对用户来说是两 系统可以根据用户的位置信息为用户推荐
个互补的工具，前者是主动的，而后者是被 当前位置下用户感兴趣的内容，为用户提
动的。 供符合其真正需要的内容，提升用户对网
近几年，电子商务蓬勃发展，推荐系 站的满意度。
统在互联网中的优势地位也越来越明显。 随着社交网络的兴起，用户在互联网
在国际方面，比较著名的电子商务网站有 中的行为不再限于获取信息，更多的是与
Amazon和eBay，其中Amazon平台中采 网络上的其他用户进行互动。国外著名的
用的推荐算法被认为是非常成功的。在国 社交网络有Facebook、LinkedIn、Twitter
内，比较大型的电子商务平台网站有淘宝 等，国内的社交网络有新浪微博、人人网、
网（包括天猫商城）、京东商城、当当网、 腾讯微博等。在社交网站中，用户不再是
2015026-2 TOPIC 专题
单个的个体，而是与网络中的很多人具有 提出了很多有效的算法。近几年，随着社
了错综复杂的关系。社交网络中最重要的 会化网络的发展，推荐系统在工业界广泛
资源就是用户与用户之间的这种关系数 应用并且取得了显著进步。比较著名的推
据。在社交网络中，用户间的关系是不同 荐系统应用有：Amazon和淘宝网的电子商
的，建立关系的因素可能是现实世界中的 务推荐系统、Netflix和MovieLens的电影
亲人、同学、同事、朋友关系，也可能是网 推荐系统、Youtube的视频推荐系统、豆瓣
络中的虚拟朋友，比如都是有着共同爱好 和Last.fm的音乐推荐系统、Google的新
的社交网络成员。在社交网络中，用户与 闻推荐系统以及Facebook和Twitter的好
用户之间的联系反映了用户之间的信任关 友推荐系统。
系，用户不单单是一个个体，用户在社交 推荐系统诞生后，学术界对其关注
网络中的行为或多或少地会受到这些用 也越来越多。从1999年开始，美国计算
户关系的影响。因此，推荐系统在这类社 机学会每年召开电子商务研讨会（ACM
交网站中的研究与应用，应该考虑用户社 Conference on Electronic Commerce，
交关系的影响。 ACM EC），越来越多的与推荐系统相关
的论文发表在ACM EC上。ACM信息检
索专业组（ACM Special Interest Group
2 推荐系统的产生与发展 of Information Retrieval，ACM SIGIR）
在2001年开始把推荐系统作为该会议的
“推荐系统”这个概念是1995年在美 一个独立研究主题。同年召开的人工智能
国人工智能协会（AAAI）上提出的。当时 联合大会（The 17th International Joint
CMU大学的教授Robert Armstrong提出 Conference on Artificial Intelligence）
了这个概念，并推出了推荐系统的原型系 也将推荐系统作为一个单独的主题。最
统——Web Watcher。在同一个会议上， 近的10年间，学术界对推荐系统越来越
美国斯坦福大学的Marko Balabanovic 重视。目前为止，数据库、数据挖掘、人工
等人推出了个性化推荐系统LIRA1。随 智能、机器学习方面的重要国际会议（如
后推荐系统的研究工作开始慢慢壮大。 SIGMOD、VLDB、ICDE、KDD、AAAI、
1996年，Yahoo网站推出了个性化入口My SIGIR、ICDM、WWW、ICML等）都有大量
Yahoo，可以看作第一个正式商用的推荐系 与推荐系统相关的研究成果发表。同时，
统。21世纪以来，推荐系统的研究与应用 第一个以推荐系统命名的国际会议ACM
随着电子商务的快速发展而异军突起，各 Recommender Systems Conference
大电子商务网站都部署了推荐系统，其中 （ACM RecSys）于2007年首次举办。在
Amazon网站的推荐系统比较著名。有报 近几年的数据挖掘及知识发现国际会议
告称，Amazon网站中35%的营业额来自于 （KDD）举办的KDD CUP竞赛中，连续
自身的推荐系统。2006年，美国的DVD租 两年的竞赛主题都是推荐系统。在KDD
赁公司Netflix在网上公开设立了一个推荐 CUP 2011年的竞赛中，两个竞赛题目分别
算法竞赛——Netflix Prize。Netflix公开 为“音乐评分预测”和“识别音乐是否被用
了真实网站中的一部分数据，包含用户对 户评分”。在KDD CUP 2012年的竞赛中，
电影的评分[2]。Netflix竞赛有效地推动了 两个竞赛题目分别为“腾讯微博中的好友
学术界和产业界对推荐算法的研究，期间 推荐”和“计算广告中的点击率预测”。
2015026-3 BIG DATA RESEARCH 大数据
数据建模模块负责对拟推荐的物品数据进
行准备，将其表示成有利于分析的数据形
3 推荐系统的领域需求和系统架构 式，确定要推荐给用户的候选物品，并对物
品进行分类、聚类等预处理。用户建模模
如上所述，推荐系统在很多领域得到 块负责对用户的行为信息进行分析，从而
了广泛的应用，如新闻推荐、微博推荐、图 获得用户的潜在喜好。用户的行为信息包
书推荐、电影推荐、产品推荐、音乐推荐、 括问答、评分、购买、下载、浏览、收藏、停
餐馆推荐、视频推荐等。不同领域的推荐 留时间等。推荐引擎模块利用后台的推荐
系统具有不同的数据稀疏性，对推荐系统 算法，实时地从候选物品集合中筛选出用户
的可扩展性以及推荐结果的相关性、流行 感兴趣的物品，排序后以列表的形式向用户
性、新鲜性、多样性和新颖性具有不同的需 推荐。推荐引擎是推荐系统的核心部分，也
求。不同领域推荐系统的需求对比见表1。 是最耗系统资源和时间的部分。用户接口模
尽管需求不尽相同，一个完整的推荐 块承担展示推荐结果、收集用户反馈等功
系统通常都包括数据建模、用户建模、推 能。用户接口除了应具有布局合理、界面美
荐引擎和用户接口4个部分，如图1所示。 观、使用方便等基本要求外，还应有助于用
户主动提供反馈。主要有两种类型的接口：
Web端（Web-based）和移动端（mobile-
数 据建模 用户建模 用户接口
based）。受篇幅限制，仅对用户建模和推荐




数
数
确
物据
据
定
品准
表
候
分备
示
选
类
推 和荐 聚物
类
品



兴
模
模▲
▲
显
隐趣
型
型性
性反
表
更反
反馈
示
新馈
馈：
；
Web端
引擎这两个重要模块进行详细介绍。
3.1 用户建模
推荐引擎 用户模型反映用户的兴趣偏好。用户
移动端
兴趣的反馈可分为显性反馈和隐性反馈。
 基于内容推荐
 协同过滤推荐
显性反馈包含两种方式：用户定制和用户
 混合推荐
评分。用户定制是指用户对系统所列问题
图1 系统架构 的回答，如年龄、性别、职业等。评分又分
表1 不同领域的推荐系统需求对比
应用领域 数据稀疏性 可扩展性 相关性 流行性 新鲜性 多样性 新颖性
新闻推荐 **** **** **** **** *** **** ***
微薄推荐 **** **** **** *** **** *** ***
图书推荐 *** * **** ** * * *
电影推荐 *** * *** *** *** * ***
产品推荐 *** ** ** *** ** *** *
音乐推荐 *** * *** *** *** *** ***
餐馆推荐 ** * * *** *** *** **
视频推荐 * * *** **** ** * *
注：****强，***较强，**较弱，*弱
2015026-4 TOPIC 专题
为两级评分和多级评分。例如，在Yahoo 根据用户以往喜欢的物品，选择其他类似
News中采用两级评分：喜欢（more like 的物品作为推荐结果[2]。例如，现在有一部
this）和不喜欢（less like this）。多级评 新电影与用户过去看过的某部电影有相同
分可以更详细地描述对某个产品的喜欢程 演员或者题材类似，则用户可能就喜欢这
度，如GroupLens中用户对新闻的喜好程 部新电影。通常使用用户模型的向量特征
度可评价为1~5分。News Dude支持用户的 来描述用户的兴趣爱好，同样对于每个物
4级反馈：感兴趣、不感兴趣、已知道、想了 品进行特征提取，作为物品模型的内容特
解更多，然后进行归一化处理。 征。然后计算用户模型的向量特征和候选
很多时候用户不能够准确地提供个人 物品模型的向量特征两者之间的匹配度，
偏好或者不愿意显性提供个人偏好，更不愿 匹配度较高的候选物品就可作为推荐结果
意经常维护个人的偏好。所以，隐性反馈往 推送给目标用户。
往能够正确地体现用户的偏好以及偏好的 协同过滤技术是由David Goldberg在
变化。常用的隐性反馈信息有：是否点击、 1992年提出的，是目前个性化推荐系统中
停留时间、点击时间、点击地点、是否加入 应用最为成功和广泛的技术。国外著名的
收藏、评论内容（可推测用户的心情）、用 商业网站Amazon，国内比较著名的豆瓣
户的搜索内容、社交网络、流行趋势、点击 网、虾米网等网站，都采用了协同过滤的方
顺序等。在协同过滤推荐方法中，常常把 法。其本质是基于关联分析的技术，即利
用户的隐性反馈转化为用户对产品的评分。 用用户所在群体的共同喜好来向用户进行
例如，Google News中用户阅读过的新闻记 推荐。协同过滤利用了用户的历史行为（偏
为喜欢，评分为1；没有阅读过的评分为0。 好、习惯等）将用户聚类成簇，这种推荐通
Daily Learner系统中用户点击了新闻标题 过计算相似用户，假设被其他相似用户喜
评分为0.8分，阅读完全文则评分上升到 好的物品当前用户也感兴趣。协同过滤的
1分；若用户跳过了系统推荐的新闻，则从 推荐方法通常包括两个步骤：根据用户行
系统预测评分中减去0.2分作为最终评分。 为数据找到和目标用户兴趣相似的用户集
用户的兴趣可分为长期兴趣和短期兴 合（用户所在的群体或簇）；找到这个集合
趣。长期兴趣反映用户的真实兴趣；短期 中用户喜欢的且目标用户没有购买过的物
兴趣常与热点话题相关联且经常改变，从 品推荐给目标用户。
最近的历史行为中学习到的短期兴趣模型 在实际使用中，协同过滤技术面临两
可快速反映用户兴趣的变化。常用的模型 大制约：一是数据稀疏问题，二是冷启动
有向量空间模型、语义网络模型、基于分类 问题。协同过滤需要利用用户和用户或者
器的模型等。由于用户的兴趣常受物品本身 物品与物品之间的关联性进行推荐。最流
周期性、热点事件、突发事件的影响，变化 行的基于内存的协同过滤方法是基于邻居
性很大。所以，需要经常更新用户模型。 关系的方法。该方法首先找出与指定用户
评价历史相近的该用户的邻居，根据这些
邻居的行为来预测结果或者找出与查询物
3.2 推荐引擎
品类似的物品。这样做的前提假设是，如
推荐引擎的基本推荐方法可分为基于 果两个用户在一组物品上有相似的评价，
内容的推荐和基于协同过滤的推荐。 那么他们对其他的物品也将会有相似的评
基于内容的推荐方法的基本原理是， 价；或者如果两物品在一组用户上有相似
2015026-5 BIG DATA RESEARCH 大数据
的评价，那么他们对于其他的用户也将会 助于解决数据稀疏性和计算复杂性问题。
有相似的评价。 贝叶斯的基本思想是给定用户A其他的评
协同过滤算法的关键是找寻用户（物 分和其他用户评分情况下，计算每个可能
品）的最近邻居。当数据稀疏时，用户购买 评分值（比如电影推荐中的1~5分）的条件
过的物品很难重叠，协同推荐的效果就不 概率，然后选择一个最大概率值的评分作
好。改进办法之一是，除了直接邻居之外， 为预测值。基于回归方法的基本思想是先
间接邻居的行为也可以对当前用户的决策 利用线性回归模型学习物品之间评分的关
行为构成影响。另外一些解决稀疏问题的 系，然后根据这些关系预测用户对物品的
方法是可以添加一些缺省值，人为地将数 评分。Slop-one算法[13]在评价矩阵上使用
据变得稠密一些，或者采用迭代补全的方 了线性模型，使之能够快速计算出具有相
法，先补充部分数值，在此基础上再进一 对较好精确度的结果。
步补充其他数值。此外，还有利用迁移学习 最近一类成功的基于模型的方法是
的方法来弥补数据稀疏的问题。但这些方 基于低秩矩阵分解的方法。例如，SVD[11]
法只能在某种程度上部分解决数据稀疏的 和SVD++[12]将评价矩阵分解为3个低秩的
问题，并不能完全克服。在真实应用中，由 矩阵，这3个矩阵的乘积能对原始矩阵进
于数据规模很大，数据稀疏的问题更加突 行某种程度的复原，从而可以评估出缺失
出。数据稀疏性使协同过滤方法的有效性 值。另一种方法是非负矩阵分解[13]，其不
受到制约。甄别出与数据稀疏程度相匹配 同之处在于，矩阵分解的结果不得出现负
的算法，以便能根据具体应用情况做出正 值。基于低秩矩阵分解的方法从评分矩阵
确选择，是非常有价值的研究课题。 中抽取一组潜在的（隐藏的）因子，并通过
常用的协同过滤方法有两类：基于内 这些因子向量描述用户和物品。在电影领
存的方法和基于模型的方法。前者主要是 域，这些自动识别的因子可能对应一部电
内存算法，通过用户与物品之间的关系来导 影的常见标签，比如风格或者类型（戏剧
出结果；后者需要找到一个合适的参数化 片或者动作片），也可能是无法解释的。
的模型，然后通过这个模型来导出结果。 矩阵分解能够对两类变量进行交互关
基于用户的协同过滤[4]鉴别出与查询用 系的预测。Tensor分解模型则能够将这种
户相似的用户，然后将这些用户对物品评分 不同类变量的交互预测扩展到更高的维
的均值作为该用户评分结果的估计值。与 度。然而，如果将因子分解模型应用到一
此类似，基于物品的协同过滤鉴别出与查 个新的任务，针对新问题往往需要在原有
询物品类似的物品，然后将这些物品的评 因子分解基础上推导演化，实现新的模型
分均值作为该物品预测结果的估计值。基 和学习算法。例如SVD++、STE、FPMC、
于邻居的方法随着计算加权平均值方法的 timeSVD++、BPTF等模型，都是针对特
不同而不同。常用的计算加权平均值的算法 定问题在原有因子分解模型基础上做的改
有皮尔逊系数、矢量余弦、MSD。 进。因此，普通的因子分解模型具有较差
基于模型的方法通过适合训练集的 的泛化能力。在模型优化学习算法方面，虽
参数化模型来预测结果。它包括基于聚类 然对基本矩阵分解模型的学习已经有很多
的CF[5~7]、贝叶斯分类器[8,9]、基于回归的 算法，如（随机）梯度下降、交替最小二乘
方法[10]。基于聚类方法的基本思想是将相 法、变分贝叶斯和MCMC（Markov chain
似的用户（或物品）组成聚类，这种技术有 Monto Carlo），但是对于更多的复杂分解
2015026-6 TOPIC 专题
模型而言，最多且最常用的方法是梯度下
降算法。
因子分解机（factorization machine） 4 大数据环境下的推荐系统
是Steffen Rendle于2010年提出的一个
通用的模型[3]。凭借该模型，Rendle在
4.1 特点与挑战
KDD Cup 2012中分别取得Track1第2名
和Track2第3名的成绩。与原有的因子分 虽然推荐系统己经被成功运用于很多
解模型相比，该模型将特征工程的一般性 大型系统及网站，但是在当前大数据的时
与分解模型的优越性融合。它能够通过特 代背景下，推荐系统的应用场景越来越多
征工程来模拟绝大多数的因子分解模型。 样，推荐系统不仅面临数据稀疏、冷启动、
LibFM是因子分解机的开源实现，简单易 兴趣偏见等传统难题，还面临由大数据引
用，不需要太多专业知识，其中包括3类优 发的更多、更复杂的实际问题。例如，用户
化学习算法：随机梯度下降、交替最小二 数目越来越多，海量用户同时访问推荐系
乘法和MCMC。 统所造成的性能压力，使传统的基于单节
这里提到的Tensor分解模型和因子 点 LVS 架构的推荐系统不再适用。同时
分解机都属于上下文感知推荐算法的范 Web 服务器处理系统请求在大数据集下
畴。上下文感知的推荐算法将二维协同扩 变得越来越多，Web服务器响应速度缓慢
展到多维协同。从学科渊源来看，上下文 制约了当前推荐系统为大数据集提供推
感知推荐系统既是一种推荐系统，也是 荐。另外，基于实时模式的推荐在大数据
一种上下文感知应用系统。Adomavicius 集下面临着严峻考验，用户难以忍受超过
和Tuzhilin等人较早指出，把上下文信息 秒级的推荐结果返回时间。传统推荐系统
融入推荐系统将有利于提高推荐精确 的单一数据库存储技术在大数据集下变得
度，并提出被广泛引用的“上下文感知推 不再适用，急需一种对外提供统一接口、
荐系统（context-aware recommender 对内采用多种混合模式存储的存储架构
systems，CARS）”的概念。他们将传统 来满足大数据集下各种数据文件的存储。
的“用户—项目”二维评分效用模型扩展 并且，传统推荐系统在推荐算法上采取的
为包含多种上下文信息的多维评分效用模 是单机节点的计算方式，不能满足大数据
型。Sun等人首先将HOSVD的方法用于网 集下海量用户产生的大数据集上的计算需
页搜索，提出了CubeSVD算法[14]，算法将 求[16]。大数据本身具有的复杂性、不确定
用户的位置信息作为上下文信息，用于搜 性和涌现性也给推荐系统带来诸多新的挑
索引擎的结果排序，取得了比较好的结果。 战，传统推荐系统的时间效率、空间效率
Renle等人提出RTF算法[15]，与HOSVD不 和推荐准确度都遇到严重的瓶颈。
同，RTF算法根据用户的排序进行优化，
可以获得比较好的准确度。
4.2 关键技术
基于内容的推荐方法和基于协同过滤
的推荐方法各有其优缺点。现有的系统大
部分是一种混合系统，它结合不同算法和 4.2.1 采用分布式文件系统管理数据
模型的优点，克服它们的缺点，从而得到了 传统的推荐系统技术主要处理小文件
较好的推荐准确度。 存储和少量数据计算，大多是面向服务器
2015026-7 BIG DATA RESEARCH 大数据
的架构，中心服务器需要收集用户的浏览 规模数据集的操作，分发给一个主节点管
记录、购买记录、评分记录等大量的交互 理下的各个分节点共同完成，然后通过整
信息来为单个用户定制个性化推荐。当数 合各个节点的中间结果，得到最终结果。
据规模过大，数据无法全部载入服务器内 MapReduce 框架负责处理并行编程中分
存时，就算采用外存置换算法和多线程技 布式存储、工作调度、负载均衡、容错均
术，依然会出现I/O上的性能瓶颈，致使任 衡、容错处理以及网络通信等复杂问题，
务执行效率过低，产生推荐结果的时间过 把处理过程高度抽象为两个函数：map和
长。对于面向海量用户和海量数据的推荐 reduce。map负责把任务分解成多个任
系统，基于集中式的中心服务器的推荐系 务，reduce负责把分解后多任务处理的结
统在时间和空间复杂性上无法满足大数据 果汇总起来[16]。例如，2010 年，Zhao等人
背景下推荐系统快速变化的需求[16]。 针对协同过滤算法的计算复杂性在大规模
大数据推荐系统采用基于集群技术的 推荐系统下的局限性，在 Hadoop平台上实
分布式文件系统管理数据。建立一种高并 现了基于物品的协同过滤算法。2011年，
发、可扩展、能处理海量数据的大数据推 针对推荐系统无法在每秒内给大量用户进
荐系统架构是非常关键的，它能为大数据 行推荐的问题，Jiang等人将基于物品的协
集的处理提供强有力的支持。 Hadoop 的 同过滤推荐算法的3个主要计算阶段切分
分布式文件系统（Hadoop distributed file 成4个MapReduce阶段，切分后各阶段可
system，HDFS）架构是其中的典型。与传 以并行运行在集群的各个节点上。同时他
统的文件系统不同，数据文件并非存储在 们还提出了一种 Hadoop平台下的数据分
本地单一节点上，而是通过网络存储在多 区策略，减少了节点间的通信开销，提高了
台节点上。并且文件的位置索引管理一般 推荐系统的推荐效率。
都由一台或几台中心节点负责[16]。客户端
从集群中读写数据时，首先通过中心节点 4.2.3 推荐算法并行化
获取文件的位置，然后与集群中的节点通 很多大型企业所需的推荐算法要处理
信，客户端通过网络从节点读取数据到本 的数据量非常庞大，从TB级别到PB级甚
地或把数据从本地写入节点。在这个过程 至更高，例如腾讯Peacock主题模型分析
中由 HDFS 来管理数据冗余存储、大文件 系统需要进行高达十亿文档、百万词汇、
的切分、中间网络通信、数据出错恢复等， 百万主题的主题模型训练，仅一个百万词
客户端根据 HDFS 提供的接口进行调用即 汇乘以百万主题的矩阵，其数据存储量已
可，非常方便。 达3 TB，如果再考虑十亿文档乘以百万主
题的矩阵，其数据量则高达3 PB[17]。面对
4.2.2 采用基于集群技术的分布式计算框架 如此庞大的数据，若采用传统串行推荐算
集群上实现分布式计算的框架很多， 法，时间开销太大。当数据量较小时，时
Hadoop中的MapReduce 作为推荐算法并 间复杂度高的串行算法能有效运作，但数
行化的依托平台，既是一种分布式的计算 据量极速增加后，这些串行推荐算法的计
框架，也是一种新型的分布式并行计算编 算性能过低，无法应用于实际的推荐系统
程模型，应用于大规模数据的并行处理， 中。因此，面向大数据集的推荐系统从设
是一种常见的开源计算框架。MapReduce 计上就应考虑到算法的分布式并行化技
算法的核心思想是“分而治之”，把对大 术，使得推荐算法能够在海量的、分布式、
2015026-8 TOPIC 专题
异构数据环境下得以高效实现。
5.3 EasyRec
5 开源大数据典型推荐软件 EasyRec3是SourceForge的一个开源
项目。它针对个人用户，提供低门槛的易集
成、易扩展、好管理的推荐系统。该开源产
5.1 Mahout
品包括了数据录入、数据管理、推荐挖掘、
Mahout1是Apache Software 离线分析等功能。它可以同时给多个不同 1
的网站提供推荐服务。需要推荐服务的网 http://mahout.
Foundation（ASF）旗下的一个全新的开
apache.org/
站用户只需配合着发送一些用户行为数据
源项目，其主要目标是提供一些可伸缩的
机器学习领域经典算法的实现，供开发人 到EasyRec，EasyRec则会进行后台的推 2
荐分析，并将推荐结果以XML或JSON的 http://spark.
员在 Apache 许可下免费使用，旨在帮助
apache.org/
格式发送回网站。用户行为数据包括用户
开发人员更加方便、快捷地开发大规模数 docs/0.9.0/api/
据上的应用程序。除了常见的分类、聚类等 看了哪些商品、买了哪些商品、对哪些商品 mllib/index.
html#org.apache.
进行了评分等。EasyRec为网站用户提供
数据挖掘算法外，还包括协同过滤（CF）、
spark.mllib.
了访问EasyRec全部功能的接口，可通过
维缩减（dimensionality reduction）、主 recommendation.
调用这些接口来实现推荐业务。 package
题模型（topic models）等。Mahout集成
了基于Java的推荐系统引擎“Taste”，用
3
于生成个性化推荐“Taste”支持基于用户 http://easyrec.
5.4 Graphlab
org/
的、基于物品的以及基于slope-one的推荐
Graphlab4始于2009年，是由美国 4
系统。在Mahout的推荐类算法中，主要有
https://github.
卡内基梅隆大学开发的一个项目。它基
基于用户的协同过滤（user-based CF)、
com/dato-code/
基于物品的协同过滤（item-based CF）、 于C++语言，主要功能是提供一个基于 PowerGraph
图的高性能分布式计算框架。GraphLab
交替最小二乘法（ALS）、具有隐含反馈的
能够高效地执行与机器学习相关的数
ALS（ALS on implicit feedback）、加权
据依赖性强的迭代型算法，为Boosted
矩阵分解（weighted MF）、SVD++、并行
决策树、深度学习、文本分析等提供了
的随机梯度下降（parallel SGD）等。
可扩展的机器学习算法模块，能对分类
和推荐模型中的参数进行自动调优，和
5.2 Spark MLlib
SPARK、Hadoop、Apache Avro、OBDC
Spark MLlib2对常用的机器学习算法 connectors等进行了集成。由于功能独特，
GraphLab在业界很有名气。针对大规模
进行了实现，包括逻辑回归、支持向量机、
的数据集，采用GraphLab来进行随机游
朴素贝叶斯等分类预测算法，K-means聚
走（random walk）或基于图的推荐算法
类算法，各种梯度下降优化算法以及协同
非常有效。另外，GraphLab还实现了交替
过滤推荐算法。MLlib当前支持的是基于
最小二乘法ALS、随机梯度下降法 SGD、
矩阵分解的协同过滤方法，其函数优化过
SVD++、Weighted-ALS、Sparse-ALS、
程可采用其提供的交替最小二乘法或者梯
非负矩阵分解（non-negative matrix
度下降法来实现，同时支持显性反馈和隐
factorization）等算法。
性反馈信息。
2015026-9 BIG DATA RESEARCH 大数据
5.5 Duine 6.2 数据稀疏问题
Duine框架是一套以Java语言编写的 现有的大多数推荐算法都是基于用
软件库，可以帮助开发者建立预测引擎。 户—物品评分矩阵数据,数据的稀疏性问
Duine提供混合算法配置，即算法可根据 题主要是指用户—物品评分矩阵的稀疏
数据情况，在基于内容的推荐和协同过滤 性，即用户与物品的交互行为太少。一个大
中动态转换。例如在冷启动（比如尚无任 型网站可能拥有上亿数量级的用户和物品,
何评价的时候）条件下，它侧重基于内容的 飙升的用户评分数据总量在面对增长更
分析法，推荐模块主要通过算法，从用户 快的“用户—物品评价矩阵”时,仍然只占
资料和商品信息中提取信息、计算预测值， 极少的一部分,推荐系统研究中的经典数
主要包括以下几种方法：协同过滤法、基于 据集MovieLens的稀疏度仅4.5%，Netflix
实例的推理（用户给出相似评分的商品） 百万大赛中提供的音乐数据集的稀疏度
和GenreLMS（对分类的推理）。Duine具 是1.2%。这些都是已经处理过的数据集，
有一个反馈处理器模块，它以增强预测为 实际上真实数据集的稀疏度都远远低于
目标，利用程序学习和获取用户的显性和 1%。例如，Bibsonomy的稀疏度是0.35%，
隐性反馈，用算法进行处理后用以更新用 Delicious的稀疏度是0.046%，淘宝网数据
户的资料[18]。 的稀疏度甚至仅在0.01%左右[19]。根据经
验，数据集中用户行为数据越多，推荐算法
的精准度越高，性能也越好。若数据集非
6 大数据推荐系统研究面临的问题 常稀疏，只包含极少量的用户行为数据,推
荐算法的准确度会大打折扣，极容易导致
推荐算法的过拟合，影响算法的性能。
6.1 特征提取问题
推荐系统的推荐对象种类丰富,例如
6.3 冷启动问题
新闻、博客等文本类对象，视频、图片、音
乐等多媒体对象以及可以用文本描述的一 冷启动问题是推荐系统所面临的最
些实体对象等。如何对这些推荐对象进行 大问题之一。冷启动问题总的来说可以分
特征提取一直是学术界和工业界的热门研 为3类：系统冷启动问题、新用户问题和新
究课题。对于文本类对象，可以借助信息检 物品问题。系统冷启动问题指的是由于数
索领域己经成熟的文本特征提取技术来提 据过于稀疏，“用户—物品评分矩阵”的密
取特征。对于多媒体对象,由于需要结合多 度太低，导致推荐系统得到的推荐结果准
媒体内容分析领域的相关技术来提取特征, 确性极低。新物品问题是由于新的物品缺
而多媒体内容分析技术目前在学术界和工 少用户对该物品的评分，这类物品很难通
业界还有待完善,因此多媒体对象的特征提 过推荐系统被推荐给用户，用户难以对这
取是推荐系统目前面临的一大难题[19]。此 些物品评分，从而形成恶性循环，导致一些
外,推荐对象特征的区分度对推荐系统的 新物品始终无法有效推荐。新物品问题对
性能有非常重要的影响。目前还缺乏特别 不同的推荐系统影响程度不同：对于用户
有效的提高特征区分度的方法。 可以通过多种方式查找物品的网站，新物
2015026-10 TOPIC 专题
品问题并没有太大影响，如电影推荐系统 分矩阵中增加若干新分值时，系统不用对
等，因为用户可以有多种途径找到电影观 整个矩阵重新计算，而只需要进行少量计
看并评分；而对于一些推荐是主要获取物 算对原模型进行调整，因此大大加快了模
品途径的网站，新物品问题会对推荐系统 型的更新速度。同时，若干文献提出使用
造成严重影响。通常解决这个问题的途径 聚类的方式解决扩展性问题，通过聚类能
是激励或者雇佣少量用户对每一个新物品 有效减少用户和物品规模，但是这样会一
进行评分。新用户问题是目前对现实推荐 定程度地降低推荐精度。在求解模型全局
系统挑战最大的冷启动问题：当一个新的 优化问题上，学者也做了大量工作，希望能
用户使用推荐系统时，他没有对任何项目进 加快收敛速度，例如人们提出了并行的随
行评分，因此系统无法对其进行个性化推 机梯度下降法和交替最小二乘法等。
荐；即使当新用户开始对少量项目进行评分
时，由于评分太少，系统依然无法给出精确
的推荐，这甚至会导致用户因为推荐体验不 7 总结与展望
佳而停止使用推荐系统[20]。当前解决新用
户问题主要是通过结合基于内容和基于用 随着互联网的飞速发展，人们对于个
户特征的方法，掌握用户的统计特征和兴 性化的信息需求已经非常急切，推荐系统
趣特征，在用户只有少量评分甚至没有评 的出现可以很好地解决用户在使用互联网
分时做出比较准确的推荐。 和电子商务网站时的“信息爆炸”问题。本
文主要针对互联网大数据时代推荐系统的
产生和发展现状、领域需求和系统架构、
6.4 可扩展性问题
用户建模和推荐引擎、大数据时代推荐系
扩展性问题是推荐系统面临的又一难 统的特点挑战和关键技术、开源的大数据
题，特别是随着大数据时代的到来，用户 推荐软件、大数据推荐系统研究面临的问
数与物品数飞涨，传统推荐系统会随着问 题等进行了介绍。
题规模的扩大而效率大大降低。花费大量 大数据推荐系统的未来研究方向主要
时间才能得到推荐结果是难以接受的，特 在以下几个方面。
别是对于一些实时性要求较高的在线推荐 ● 从系统推荐到社会推荐，即在推荐
系统。使用基于内存的推荐系统，用户或 的过程中，除了考虑用户的历史行为信息，
者物品间的相似度计算会耗费大量时间； 还需要利用用户的社会网络信息来增强推
使用基于模型的推荐系统，利用机器学习 荐的效果；同时，在进行社会网络上的人与
算法学习模型参数同样会耗费大量时间， 人之间的推荐时，也要综合利用用户的历
这里学习时间主要用在求解全局最优问题 史行为信息，做到社会网络和历史行为信
上。解决扩展性问题，工业界一般采取的 息的互相利用和推荐效果的相互增强。
方法是线下学习、线上使用：先通过离线 ● 从以精确性为中心到综合考虑精确
数据事先算好用户/物品间相似度或者模型 性、多样性和新颖性的评估体系。
参数，然后线上只需要利用这些算好的数 ● 从单一数据源到交叉融合数据平
值进行推荐[20]。但是这并没有从根本上提 台，比如依据用户的跨网站行为数据，解决
高推荐算法的效率，Sarwar等人2002年 某一网站上的冷启动推荐问题。
提出了一种增量SVD协同过滤算法，当评 ● 从高速服务器到并行处理到云计算。
2015026-11 BIG DATA RESEARCH 大数据
● 从静态算法到动态增量算法、自适 [11] Paterek A. Improving regularized singular
value decomposition for collaborative
应算法，从脆弱算法到顽健算法。
filtering. Statistics, 2007: 2~5
[12] Koren Y. Factorization meets the
参考文献 neighborhood: a multifaceted collaborative
filtering model. Proceedings of the 14th
[1] 曾春, 邢春晓, 周立柱. 个性化服务技术综述. ACM SIGKDD Conference on Knowledge
软件学报, 2002(10): 1952~1961 Discovery and Data Mining, Las Vegas,
Zeng C, Xing C X, Zhou L Z. A survey Nevada, USA，2008: 426~434
of personalization technology. Journal of [13] L ee D, Seung H. Algorithms for non-
Software, 2002(10): 1952~1961 negative matrix factorization. Proceedings
[2] B ell R M, Koren Y. Lessons from the Netflix of Neural Information Processing
prize challenge. ACM SIGKDD Explorations Systems, Denver, Colorado, USA, 2000
Newsletter, 2007, 9(2): 75~79 [14] Sun J T, Zeng H J, Liu H, et al. CubeSVD:
[3] R endle S. Factorization machines with a novel approach to personalized
libFM. ACM Transactions on Intelligent Web search. Proceedings of the 14th
Systems & Technology, 2012, 3(3): International Conference on World Wide
451~458 Web, Chiba, Japan, 2005: 382~390
[4] Su X, Khoshgoftaar T M. A survey of [15] S teffen R, Leandro B M, Alexandros N,
collaborative filtering techniques. Advances et al. Learning optimal ranking with tensor
in Artificial Intelligence, 2009: 421425 factorization for tag recommendation.
[5] Chee S H S, Han J, Wang K. Rectree: an Proceedings of the 15th ACM SIGKDD
efficient collaborative filtering method. Conference on Knowledge Discovery and
Proceedings of Data Warehousing and Data Mining, Paris, France, 2009: 727~736
Knowledge Discovery: Third International [16] 王俞翔. 面向大数据集的推荐系统研究（硕士
Conference, Munich, Germany, 2001 学位论文）. 秦皇岛：燕山大学, 2014
[6] Connor M, Herlocker J. Clustering items for Wang Y X. Research on recommender
collaborative filtering. Proceedings of ACM system for big dataset (master
SIGIR Workshop on Recommender Systems, dissertation). Qinhuangdao: Yanshan
New Orleans, Louisiana, USA , 2001 University, 2014
[7] U ngar L H, Foster D P. Clustering [17] 黄 宜华. 大数据机器学习系统研究进展. 大数
methods for collaborative filtering. 据, 2015004
Proceedings of AAAI Workshop on Huang Y H. Research progress on big
Recommendation Systems, Madison, data machine learning system. Big Data
Wisconsin, USA, 1998 Research, 2015004
[8] Miyahara K, Pazzani M J. Collaborative [18] 米可菲, 张勇, 邢春晓等. 面向大数据的开
filtering with the simple bayesian 源推荐系统分析. 计算机与数字工程, 2013,
classifier. Proceedings of the 6th Pacific 41(10): 1563~1566
Rim International Conference on Artificial Feben T, Zhang Y, Xing C X, et al. An
Intelligence, Melbourne, Australia, 2000: analysis of open source recommender
679~689 systems in the big data era. Computer and
[9] Miyahara K, Pazzani M J. Improvement Digital Engineering. 2013, 41(10): 1563~1566
of collaborative filtering with the [19] 孙远帅. 基于大数据的推荐算法研究（硕士学
simple bayesian classifier. IPSJ Journal, 位论文）. 厦门：厦门大学, 2014
2002,43(11): 3429~3437 Sun Y S. Recommendation algorithms in
[10] V ucetic S, Obradovic Z. Collaborative the big data era (master dissertation).
filtering using a regression-based Xiamen: Xiamen University, 2014
approach. Knowledge and Information [20] 刘士琛. 面向推荐系统的关键问题研究及应用
Systems, 2005, 7（1）: 1~22 (博士学位论文). 合肥：中国科学技术大学, 2014
2015026-12 TOPIC 专题
Liu S C. Research on the key issues dissertation). Hefei: University of Science
for the recommender systems (doctor and Technology of China, 2014
作者简介
李翠平，女，中国人民大学信息学院教授、博士生导师，中国计算机学会杰出会员，中国计算机学会大数据
专家委员会、数据库专家委员会委员。目前研究方向为数据仓库、数据挖掘、社会网络分析和社会媒体推荐等。
主持和参与国家自然科学基金、“973”计划、“863”计划等10多项国家级和省部级项目，在国内外重要期刊和国
际会议上发表论文50多篇。
蓝梦微，女，中国人民大学信息学院博士生，CCF学生会员，主要研究领域为推荐系统、数据挖掘、大数据
分析。
邹本友，男，中国人民大学信息学院博士生，CCF学生会员，主要研究领域为推荐系统、数据挖掘、大数据
分析。
王绍卿，男，中国人民大学信息学院博士生，CCF学生会员，主要研究领域为推荐系统、数据挖掘、大数据
分析。
赵衎衎，男，中国人民大学信息学院博士生，CCF学生会员，主要研究领域为推荐系统、数据挖掘、大数据
分析。
收稿日期：2015-08-11
基金项目：国家基础研究发展计划（“973”计划）基金资助项目（No.2014CB340402），国家高技术研究发展计划（“863”计划）基金资
助项目（No.2014AA015204），国家自然科学基金资助项目（No.61272137, No. 61033010, No.61202114），国家社会科学基金资助项目
（No.12&ZD220），国家高等学校学科创新引智计划（“111”计划）基金资助项目
Foundation Items: National Basic Research Program of China (973 Program) (No.2014CB340402), National High Technology
Research and Development Program of China (863 Program) (No.2014AA015204), The National Natural Science Foundation of
China(No.61272137, No.61033010, No.61202114), The National Social Science of Foundation of China (No.12&ZD220)，The Project
of Attracting Talents of Discipline to National Universities (111 Project)
论文引用格式：李翠平, 蓝梦微, 邹本友等. 大数据与推荐系统. 大数据, 2015026
Li C P, Lan M W, Zou B Y, et al. Big data and recommendation system. Big Data Research, 2015026
2015026-13 --------------------------------------------------------------------------------- TOPIC 专题
大数据与推荐系统
李翠平，蓝梦微，邹本友，王绍卿，赵衎衎
中国人民大学数据工程与知识工程教育部重点实验室 北京 100872
摘要
随着大数据时代的来临，网络中的信息量呈现指数式增长，随之带来了信息过载问题。推荐系统是解决
信息过载最有效的方式之一，大数据推荐系统已经逐渐成为信息领域的研究热点。介绍了推荐系统的产
生及其在大数据时代的发展现状、推荐系统的领域需求和系统架构、大数据环境下推荐系统的挑战及其
关键技术、开源的大数据推荐软件、大数据推荐系统研究面临的问题，最后探讨了大数据推荐系统的未
来发展趋势。
关键词
大数据；推荐系统；协同过滤
doi: 10.11959/j.issn.2096-0271.2015026
Big Data and Recommendation System
Li Cuiping, Lan Mengwei, Zou Benyou, Wang Shaoqing, Zhao Kankan
Key Laboratory of Data Engineering and Knowledge Engineering, Ministry of Education, Renmin
University of China, Beijing 100872, China
Abstract
In big data era, recommendation system is the key means to tackle the issue of “information overload”.
Recommendation system has been widely applied to many domains. The most typical and promising domain is the
e-commence. Recently, with the rapid development of e-commence, recommendation system becomes more and
more important and is promoted as a hot research field. The history and development of recommendation system, its
domain requirements and system architecture, its characteristics and challenges under big data environment, its key
techniques, open source big data recommendation systems were introduced. And at last, the open research problems
and future trends of bid data recommendation system were discussed.
Key words
big data, recommendation system, collaborative filtering
2015026-1 BIG DATA RESEARCH 大数据
苏宁易购等。在这些电子商务平台中，网
站提供的商品数量不计其数，网站中的用
1 推荐系统与网络大数据 户规模也非常巨大。据不完全统计，天猫
商城中的商品数量已经超过了4 000万。
随着科技与信息技术的迅猛发展，社 在如此庞大的电商网站中，用户根据自己
会进入了一个全新的高度信息化的时代， 的购买意图输入关键字查询后，会得到很
互联网无处不在，影响了人类生活的方方 多相似的结果，用户在这些结果中也很难
面面，并彻底改变了人们的生活方式。尤其 区分异同，用户也难于选择合适的物品。
是进入Web 2.0时代以来，随着社会化网络 于是，推荐系统作为能够根据用户兴趣
媒体的异军突起，互联网用户既是网络信 为用户推荐一些用户感兴趣的商品，从而
息的消费者，也是网络内容的生产者，互联 为用户在购物的选择中提供建议的需求
网中的信息量呈指数级增长。由于用户的 非常明显。目前比较成功的电子商务网站
辨别能力有限，在面对庞大且复杂的互联 中，都不同程度地利用推荐系统在用户购
网信息时往往感到无从下手，使得在互联 物的同时，为用户推荐一些商品，从而提
网中找寻有用信息的成本巨大，产生了所 高网站的销售额。
谓的“信息过载”问题。 另一方面，智能手机的发展推动了移
搜索引擎和推荐系统的产生为解决 动互联网的发展。在用户使用移动互联网
“信息过载”问题提供了非常重要的技术 的过程中，其所处的地理位置等信息可以
手段。对于搜索引擎来说，用户在搜索互 非常准确地被获取。基于此，国内外出现
联网中的信息时，需要在搜索引擎中输入 了大量的基于用户位置信息的网站。国外
“查询关键词”，搜索引擎根据用户的输 比较著名的有Meetup和Flickr。国内著名
入，在系统后台进行信息匹配，将与用户 的有豆瓣网和大众点评网。例如，在大众
查询相关的信息展示给用户。但是，如果 点评这种基于位置服务的网站中，用户可
用户无法想到准确描述自己需求的关键 以根据自己的当前位置搜索餐馆、酒店、影
词，此时搜索引擎就无能为力了。和搜索 院、旅游景点等信息服务。同时，可以对当
引擎不同，推荐系统不需要用户提供明确 前位置下的各类信息进行点评，为自己在
的需求，而是通过分析用户的历史行为来 现实世界中的体验打分，分享自己的经验与
对用户的兴趣进行建模，从而主动给用户 感受。当用户使用这类基于位置的网站服
推荐可能满足他们兴趣和需求的信息。因 务时，同样会遭遇“信息过载”问题。推荐
此，搜索引擎和推荐系统对用户来说是两 系统可以根据用户的位置信息为用户推荐
个互补的工具，前者是主动的，而后者是被 当前位置下用户感兴趣的内容，为用户提
动的。 供符合其真正需要的内容，提升用户对网
近几年，电子商务蓬勃发展，推荐系 站的满意度。
统在互联网中的优势地位也越来越明显。 随着社交网络的兴起，用户在互联网
在国际方面，比较著名的电子商务网站有 中的行为不再限于获取信息，更多的是与
Amazon和eBay，其中Amazon平台中采 网络上的其他用户进行互动。国外著名的
用的推荐算法被认为是非常成功的。在国 社交网络有Facebook、LinkedIn、Twitter
内，比较大型的电子商务平台网站有淘宝 等，国内的社交网络有新浪微博、人人网、
网（包括天猫商城）、京东商城、当当网、 腾讯微博等。在社交网站中，用户不再是
2015026-2 TOPIC 专题
单个的个体，而是与网络中的很多人具有 提出了很多有效的算法。近几年，随着社
了错综复杂的关系。社交网络中最重要的 会化网络的发展，推荐系统在工业界广泛
资源就是用户与用户之间的这种关系数 应用并且取得了显著进步。比较著名的推
据。在社交网络中，用户间的关系是不同 荐系统应用有：Amazon和淘宝网的电子商
的，建立关系的因素可能是现实世界中的 务推荐系统、Netflix和MovieLens的电影
亲人、同学、同事、朋友关系，也可能是网 推荐系统、Youtube的视频推荐系统、豆瓣
络中的虚拟朋友，比如都是有着共同爱好 和Last.fm的音乐推荐系统、Google的新
的社交网络成员。在社交网络中，用户与 闻推荐系统以及Facebook和Twitter的好
用户之间的联系反映了用户之间的信任关 友推荐系统。
系，用户不单单是一个个体，用户在社交 推荐系统诞生后，学术界对其关注
网络中的行为或多或少地会受到这些用 也越来越多。从1999年开始，美国计算
户关系的影响。因此，推荐系统在这类社 机学会每年召开电子商务研讨会（ACM
交网站中的研究与应用，应该考虑用户社 Conference on Electronic Commerce，
交关系的影响。 ACM EC），越来越多的与推荐系统相关
的论文发表在ACM EC上。ACM信息检
索专业组（ACM Special Interest Group
2 推荐系统的产生与发展 of Information Retrieval，ACM SIGIR）
在2001年开始把推荐系统作为该会议的
“推荐系统”这个概念是1995年在美 一个独立研究主题。同年召开的人工智能
国人工智能协会（AAAI）上提出的。当时 联合大会（The 17th International Joint
CMU大学的教授Robert Armstrong提出 Conference on Artificial Intelligence）
了这个概念，并推出了推荐系统的原型系 也将推荐系统作为一个单独的主题。最
统——Web Watcher。在同一个会议上， 近的10年间，学术界对推荐系统越来越
美国斯坦福大学的Marko Balabanovic 重视。目前为止，数据库、数据挖掘、人工
等人推出了个性化推荐系统LIRA1。随 智能、机器学习方面的重要国际会议（如
后推荐系统的研究工作开始慢慢壮大。 SIGMOD、VLDB、ICDE、KDD、AAAI、
1996年，Yahoo网站推出了个性化入口My SIGIR、ICDM、WWW、ICML等）都有大量
Yahoo，可以看作第一个正式商用的推荐系 与推荐系统相关的研究成果发表。同时，
统。21世纪以来，推荐系统的研究与应用 第一个以推荐系统命名的国际会议ACM
随着电子商务的快速发展而异军突起，各 Recommender Systems Conference
大电子商务网站都部署了推荐系统，其中 （ACM RecSys）于2007年首次举办。在
Amazon网站的推荐系统比较著名。有报 近几年的数据挖掘及知识发现国际会议
告称，Amazon网站中35%的营业额来自于 （KDD）举办的KDD CUP竞赛中，连续
自身的推荐系统。2006年，美国的DVD租 两年的竞赛主题都是推荐系统。在KDD
赁公司Netflix在网上公开设立了一个推荐 CUP 2011年的竞赛中，两个竞赛题目分别
算法竞赛——Netflix Prize。Netflix公开 为“音乐评分预测”和“识别音乐是否被用
了真实网站中的一部分数据，包含用户对 户评分”。在KDD CUP 2012年的竞赛中，
电影的评分[2]。Netflix竞赛有效地推动了 两个竞赛题目分别为“腾讯微博中的好友
学术界和产业界对推荐算法的研究，期间 推荐”和“计算广告中的点击率预测”。
2015026-3 BIG DATA RESEARCH 大数据
数据建模模块负责对拟推荐的物品数据进
行准备，将其表示成有利于分析的数据形
3 推荐系统的领域需求和系统架构 式，确定要推荐给用户的候选物品，并对物
品进行分类、聚类等预处理。用户建模模
如上所述，推荐系统在很多领域得到 块负责对用户的行为信息进行分析，从而
了广泛的应用，如新闻推荐、微博推荐、图 获得用户的潜在喜好。用户的行为信息包
书推荐、电影推荐、产品推荐、音乐推荐、 括问答、评分、购买、下载、浏览、收藏、停
餐馆推荐、视频推荐等。不同领域的推荐 留时间等。推荐引擎模块利用后台的推荐
系统具有不同的数据稀疏性，对推荐系统 算法，实时地从候选物品集合中筛选出用户
的可扩展性以及推荐结果的相关性、流行 感兴趣的物品，排序后以列表的形式向用户
性、新鲜性、多样性和新颖性具有不同的需 推荐。推荐引擎是推荐系统的核心部分，也
求。不同领域推荐系统的需求对比见表1。 是最耗系统资源和时间的部分。用户接口模
尽管需求不尽相同，一个完整的推荐 块承担展示推荐结果、收集用户反馈等功
系统通常都包括数据建模、用户建模、推 能。用户接口除了应具有布局合理、界面美
荐引擎和用户接口4个部分，如图1所示。 观、使用方便等基本要求外，还应有助于用
户主动提供反馈。主要有两种类型的接口：
Web端（Web-based）和移动端（mobile-
数 据建模 用户建模 用户接口
based）。受篇幅限制，仅对用户建模和推荐




数
数
确
物据
据
定
品准
表
候
分备
示
选
类
推 和荐 聚物
类
品



兴
模
模▲
▲
显
隐趣
型
型性
性反
表
更反
反馈
示
新馈
馈：
；
Web端
引擎这两个重要模块进行详细介绍。
3.1 用户建模
推荐引擎 用户模型反映用户的兴趣偏好。用户
移动端
兴趣的反馈可分为显性反馈和隐性反馈。
 基于内容推荐
 协同过滤推荐
显性反馈包含两种方式：用户定制和用户
 混合推荐
评分。用户定制是指用户对系统所列问题
图1 系统架构 的回答，如年龄、性别、职业等。评分又分
表1 不同领域的推荐系统需求对比
应用领域 数据稀疏性 可扩展性 相关性 流行性 新鲜性 多样性 新颖性
新闻推荐 **** **** **** **** *** **** ***
微薄推荐 **** **** **** *** **** *** ***
图书推荐 *** * **** ** * * *
电影推荐 *** * *** *** *** * ***
产品推荐 *** ** ** *** ** *** *
音乐推荐 *** * *** *** *** *** ***
餐馆推荐 ** * * *** *** *** **
视频推荐 * * *** **** ** * *
注：****强，***较强，**较弱，*弱
2015026-4 TOPIC 专题
为两级评分和多级评分。例如，在Yahoo 根据用户以往喜欢的物品，选择其他类似
News中采用两级评分：喜欢（more like 的物品作为推荐结果[2]。例如，现在有一部
this）和不喜欢（less like this）。多级评 新电影与用户过去看过的某部电影有相同
分可以更详细地描述对某个产品的喜欢程 演员或者题材类似，则用户可能就喜欢这
度，如GroupLens中用户对新闻的喜好程 部新电影。通常使用用户模型的向量特征
度可评价为1~5分。News Dude支持用户的 来描述用户的兴趣爱好，同样对于每个物
4级反馈：感兴趣、不感兴趣、已知道、想了 品进行特征提取，作为物品模型的内容特
解更多，然后进行归一化处理。 征。然后计算用户模型的向量特征和候选
很多时候用户不能够准确地提供个人 物品模型的向量特征两者之间的匹配度，
偏好或者不愿意显性提供个人偏好，更不愿 匹配度较高的候选物品就可作为推荐结果
意经常维护个人的偏好。所以，隐性反馈往 推送给目标用户。
往能够正确地体现用户的偏好以及偏好的 协同过滤技术是由David Goldberg在
变化。常用的隐性反馈信息有：是否点击、 1992年提出的，是目前个性化推荐系统中
停留时间、点击时间、点击地点、是否加入 应用最为成功和广泛的技术。国外著名的
收藏、评论内容（可推测用户的心情）、用 商业网站Amazon，国内比较著名的豆瓣
户的搜索内容、社交网络、流行趋势、点击 网、虾米网等网站，都采用了协同过滤的方
顺序等。在协同过滤推荐方法中，常常把 法。其本质是基于关联分析的技术，即利
用户的隐性反馈转化为用户对产品的评分。 用用户所在群体的共同喜好来向用户进行
例如，Google News中用户阅读过的新闻记 推荐。协同过滤利用了用户的历史行为（偏
为喜欢，评分为1；没有阅读过的评分为0。 好、习惯等）将用户聚类成簇，这种推荐通
Daily Learner系统中用户点击了新闻标题 过计算相似用户，假设被其他相似用户喜
评分为0.8分，阅读完全文则评分上升到 好的物品当前用户也感兴趣。协同过滤的
1分；若用户跳过了系统推荐的新闻，则从 推荐方法通常包括两个步骤：根据用户行
系统预测评分中减去0.2分作为最终评分。 为数据找到和目标用户兴趣相似的用户集
用户的兴趣可分为长期兴趣和短期兴 合（用户所在的群体或簇）；找到这个集合
趣。长期兴趣反映用户的真实兴趣；短期 中用户喜欢的且目标用户没有购买过的物
兴趣常与热点话题相关联且经常改变，从 品推荐给目标用户。
最近的历史行为中学习到的短期兴趣模型 在实际使用中，协同过滤技术面临两
可快速反映用户兴趣的变化。常用的模型 大制约：一是数据稀疏问题，二是冷启动
有向量空间模型、语义网络模型、基于分类 问题。协同过滤需要利用用户和用户或者
器的模型等。由于用户的兴趣常受物品本身 物品与物品之间的关联性进行推荐。最流
周期性、热点事件、突发事件的影响，变化 行的基于内存的协同过滤方法是基于邻居
性很大。所以，需要经常更新用户模型。 关系的方法。该方法首先找出与指定用户
评价历史相近的该用户的邻居，根据这些
邻居的行为来预测结果或者找出与查询物
3.2 推荐引擎
品类似的物品。这样做的前提假设是，如
推荐引擎的基本推荐方法可分为基于 果两个用户在一组物品上有相似的评价，
内容的推荐和基于协同过滤的推荐。 那么他们对其他的物品也将会有相似的评
基于内容的推荐方法的基本原理是， 价；或者如果两物品在一组用户上有相似
2015026-5 BIG DATA RESEARCH 大数据
的评价，那么他们对于其他的用户也将会 助于解决数据稀疏性和计算复杂性问题。
有相似的评价。 贝叶斯的基本思想是给定用户A其他的评
协同过滤算法的关键是找寻用户（物 分和其他用户评分情况下，计算每个可能
品）的最近邻居。当数据稀疏时，用户购买 评分值（比如电影推荐中的1~5分）的条件
过的物品很难重叠，协同推荐的效果就不 概率，然后选择一个最大概率值的评分作
好。改进办法之一是，除了直接邻居之外， 为预测值。基于回归方法的基本思想是先
间接邻居的行为也可以对当前用户的决策 利用线性回归模型学习物品之间评分的关
行为构成影响。另外一些解决稀疏问题的 系，然后根据这些关系预测用户对物品的
方法是可以添加一些缺省值，人为地将数 评分。Slop-one算法[13]在评价矩阵上使用
据变得稠密一些，或者采用迭代补全的方 了线性模型，使之能够快速计算出具有相
法，先补充部分数值，在此基础上再进一 对较好精确度的结果。
步补充其他数值。此外，还有利用迁移学习 最近一类成功的基于模型的方法是
的方法来弥补数据稀疏的问题。但这些方 基于低秩矩阵分解的方法。例如，SVD[11]
法只能在某种程度上部分解决数据稀疏的 和SVD++[12]将评价矩阵分解为3个低秩的
问题，并不能完全克服。在真实应用中，由 矩阵，这3个矩阵的乘积能对原始矩阵进
于数据规模很大，数据稀疏的问题更加突 行某种程度的复原，从而可以评估出缺失
出。数据稀疏性使协同过滤方法的有效性 值。另一种方法是非负矩阵分解[13]，其不
受到制约。甄别出与数据稀疏程度相匹配 同之处在于，矩阵分解的结果不得出现负
的算法，以便能根据具体应用情况做出正 值。基于低秩矩阵分解的方法从评分矩阵
确选择，是非常有价值的研究课题。 中抽取一组潜在的（隐藏的）因子，并通过
常用的协同过滤方法有两类：基于内 这些因子向量描述用户和物品。在电影领
存的方法和基于模型的方法。前者主要是 域，这些自动识别的因子可能对应一部电
内存算法，通过用户与物品之间的关系来导 影的常见标签，比如风格或者类型（戏剧
出结果；后者需要找到一个合适的参数化 片或者动作片），也可能是无法解释的。
的模型，然后通过这个模型来导出结果。 矩阵分解能够对两类变量进行交互关
基于用户的协同过滤[4]鉴别出与查询用 系的预测。Tensor分解模型则能够将这种
户相似的用户，然后将这些用户对物品评分 不同类变量的交互预测扩展到更高的维
的均值作为该用户评分结果的估计值。与 度。然而，如果将因子分解模型应用到一
此类似，基于物品的协同过滤鉴别出与查 个新的任务，针对新问题往往需要在原有
询物品类似的物品，然后将这些物品的评 因子分解基础上推导演化，实现新的模型
分均值作为该物品预测结果的估计值。基 和学习算法。例如SVD++、STE、FPMC、
于邻居的方法随着计算加权平均值方法的 timeSVD++、BPTF等模型，都是针对特
不同而不同。常用的计算加权平均值的算法 定问题在原有因子分解模型基础上做的改
有皮尔逊系数、矢量余弦、MSD。 进。因此，普通的因子分解模型具有较差
基于模型的方法通过适合训练集的 的泛化能力。在模型优化学习算法方面，虽
参数化模型来预测结果。它包括基于聚类 然对基本矩阵分解模型的学习已经有很多
的CF[5~7]、贝叶斯分类器[8,9]、基于回归的 算法，如（随机）梯度下降、交替最小二乘
方法[10]。基于聚类方法的基本思想是将相 法、变分贝叶斯和MCMC（Markov chain
似的用户（或物品）组成聚类，这种技术有 Monto Carlo），但是对于更多的复杂分解
2015026-6 TOPIC 专题
模型而言，最多且最常用的方法是梯度下
降算法。
因子分解机（factorization machine） 4 大数据环境下的推荐系统
是Steffen Rendle于2010年提出的一个
通用的模型[3]。凭借该模型，Rendle在
4.1 特点与挑战
KDD Cup 2012中分别取得Track1第2名
和Track2第3名的成绩。与原有的因子分 虽然推荐系统己经被成功运用于很多
解模型相比，该模型将特征工程的一般性 大型系统及网站，但是在当前大数据的时
与分解模型的优越性融合。它能够通过特 代背景下，推荐系统的应用场景越来越多
征工程来模拟绝大多数的因子分解模型。 样，推荐系统不仅面临数据稀疏、冷启动、
LibFM是因子分解机的开源实现，简单易 兴趣偏见等传统难题，还面临由大数据引
用，不需要太多专业知识，其中包括3类优 发的更多、更复杂的实际问题。例如，用户
化学习算法：随机梯度下降、交替最小二 数目越来越多，海量用户同时访问推荐系
乘法和MCMC。 统所造成的性能压力，使传统的基于单节
这里提到的Tensor分解模型和因子 点 LVS 架构的推荐系统不再适用。同时
分解机都属于上下文感知推荐算法的范 Web 服务器处理系统请求在大数据集下
畴。上下文感知的推荐算法将二维协同扩 变得越来越多，Web服务器响应速度缓慢
展到多维协同。从学科渊源来看，上下文 制约了当前推荐系统为大数据集提供推
感知推荐系统既是一种推荐系统，也是 荐。另外，基于实时模式的推荐在大数据
一种上下文感知应用系统。Adomavicius 集下面临着严峻考验，用户难以忍受超过
和Tuzhilin等人较早指出，把上下文信息 秒级的推荐结果返回时间。传统推荐系统
融入推荐系统将有利于提高推荐精确 的单一数据库存储技术在大数据集下变得
度，并提出被广泛引用的“上下文感知推 不再适用，急需一种对外提供统一接口、
荐系统（context-aware recommender 对内采用多种混合模式存储的存储架构
systems，CARS）”的概念。他们将传统 来满足大数据集下各种数据文件的存储。
的“用户—项目”二维评分效用模型扩展 并且，传统推荐系统在推荐算法上采取的
为包含多种上下文信息的多维评分效用模 是单机节点的计算方式，不能满足大数据
型。Sun等人首先将HOSVD的方法用于网 集下海量用户产生的大数据集上的计算需
页搜索，提出了CubeSVD算法[14]，算法将 求[16]。大数据本身具有的复杂性、不确定
用户的位置信息作为上下文信息，用于搜 性和涌现性也给推荐系统带来诸多新的挑
索引擎的结果排序，取得了比较好的结果。 战，传统推荐系统的时间效率、空间效率
Renle等人提出RTF算法[15]，与HOSVD不 和推荐准确度都遇到严重的瓶颈。
同，RTF算法根据用户的排序进行优化，
可以获得比较好的准确度。
4.2 关键技术
基于内容的推荐方法和基于协同过滤
的推荐方法各有其优缺点。现有的系统大
部分是一种混合系统，它结合不同算法和 4.2.1 采用分布式文件系统管理数据
模型的优点，克服它们的缺点，从而得到了 传统的推荐系统技术主要处理小文件
较好的推荐准确度。 存储和少量数据计算，大多是面向服务器
2015026-7 BIG DATA RESEARCH 大数据
的架构，中心服务器需要收集用户的浏览 规模数据集的操作，分发给一个主节点管
记录、购买记录、评分记录等大量的交互 理下的各个分节点共同完成，然后通过整
信息来为单个用户定制个性化推荐。当数 合各个节点的中间结果，得到最终结果。
据规模过大，数据无法全部载入服务器内 MapReduce 框架负责处理并行编程中分
存时，就算采用外存置换算法和多线程技 布式存储、工作调度、负载均衡、容错均
术，依然会出现I/O上的性能瓶颈，致使任 衡、容错处理以及网络通信等复杂问题，
务执行效率过低，产生推荐结果的时间过 把处理过程高度抽象为两个函数：map和
长。对于面向海量用户和海量数据的推荐 reduce。map负责把任务分解成多个任
系统，基于集中式的中心服务器的推荐系 务，reduce负责把分解后多任务处理的结
统在时间和空间复杂性上无法满足大数据 果汇总起来[16]。例如，2010 年，Zhao等人
背景下推荐系统快速变化的需求[16]。 针对协同过滤算法的计算复杂性在大规模
大数据推荐系统采用基于集群技术的 推荐系统下的局限性，在 Hadoop平台上实
分布式文件系统管理数据。建立一种高并 现了基于物品的协同过滤算法。2011年，
发、可扩展、能处理海量数据的大数据推 针对推荐系统无法在每秒内给大量用户进
荐系统架构是非常关键的，它能为大数据 行推荐的问题，Jiang等人将基于物品的协
集的处理提供强有力的支持。 Hadoop 的 同过滤推荐算法的3个主要计算阶段切分
分布式文件系统（Hadoop distributed file 成4个MapReduce阶段，切分后各阶段可
system，HDFS）架构是其中的典型。与传 以并行运行在集群的各个节点上。同时他
统的文件系统不同，数据文件并非存储在 们还提出了一种 Hadoop平台下的数据分
本地单一节点上，而是通过网络存储在多 区策略，减少了节点间的通信开销，提高了
台节点上。并且文件的位置索引管理一般 推荐系统的推荐效率。
都由一台或几台中心节点负责[16]。客户端
从集群中读写数据时，首先通过中心节点 4.2.3 推荐算法并行化
获取文件的位置，然后与集群中的节点通 很多大型企业所需的推荐算法要处理
信，客户端通过网络从节点读取数据到本 的数据量非常庞大，从TB级别到PB级甚
地或把数据从本地写入节点。在这个过程 至更高，例如腾讯Peacock主题模型分析
中由 HDFS 来管理数据冗余存储、大文件 系统需要进行高达十亿文档、百万词汇、
的切分、中间网络通信、数据出错恢复等， 百万主题的主题模型训练，仅一个百万词
客户端根据 HDFS 提供的接口进行调用即 汇乘以百万主题的矩阵，其数据存储量已
可，非常方便。 达3 TB，如果再考虑十亿文档乘以百万主
题的矩阵，其数据量则高达3 PB[17]。面对
4.2.2 采用基于集群技术的分布式计算框架 如此庞大的数据，若采用传统串行推荐算
集群上实现分布式计算的框架很多， 法，时间开销太大。当数据量较小时，时
Hadoop中的MapReduce 作为推荐算法并 间复杂度高的串行算法能有效运作，但数
行化的依托平台，既是一种分布式的计算 据量极速增加后，这些串行推荐算法的计
框架，也是一种新型的分布式并行计算编 算性能过低，无法应用于实际的推荐系统
程模型，应用于大规模数据的并行处理， 中。因此，面向大数据集的推荐系统从设
是一种常见的开源计算框架。MapReduce 计上就应考虑到算法的分布式并行化技
算法的核心思想是“分而治之”，把对大 术，使得推荐算法能够在海量的、分布式、
2015026-8 TOPIC 专题
异构数据环境下得以高效实现。
5.3 EasyRec
5 开源大数据典型推荐软件 EasyRec3是SourceForge的一个开源
项目。它针对个人用户，提供低门槛的易集
成、易扩展、好管理的推荐系统。该开源产
5.1 Mahout
品包括了数据录入、数据管理、推荐挖掘、
Mahout1是Apache Software 离线分析等功能。它可以同时给多个不同 1
的网站提供推荐服务。需要推荐服务的网 http://mahout.
Foundation（ASF）旗下的一个全新的开
apache.org/
站用户只需配合着发送一些用户行为数据
源项目，其主要目标是提供一些可伸缩的
机器学习领域经典算法的实现，供开发人 到EasyRec，EasyRec则会进行后台的推 2
荐分析，并将推荐结果以XML或JSON的 http://spark.
员在 Apache 许可下免费使用，旨在帮助
apache.org/
格式发送回网站。用户行为数据包括用户
开发人员更加方便、快捷地开发大规模数 docs/0.9.0/api/
据上的应用程序。除了常见的分类、聚类等 看了哪些商品、买了哪些商品、对哪些商品 mllib/index.
html#org.apache.
进行了评分等。EasyRec为网站用户提供
数据挖掘算法外，还包括协同过滤（CF）、
spark.mllib.
了访问EasyRec全部功能的接口，可通过
维缩减（dimensionality reduction）、主 recommendation.
调用这些接口来实现推荐业务。 package
题模型（topic models）等。Mahout集成
了基于Java的推荐系统引擎“Taste”，用
3
于生成个性化推荐“Taste”支持基于用户 http://easyrec.
5.4 Graphlab
org/
的、基于物品的以及基于slope-one的推荐
Graphlab4始于2009年，是由美国 4
系统。在Mahout的推荐类算法中，主要有
https://github.
卡内基梅隆大学开发的一个项目。它基
基于用户的协同过滤（user-based CF)、
com/dato-code/
基于物品的协同过滤（item-based CF）、 于C++语言，主要功能是提供一个基于 PowerGraph
图的高性能分布式计算框架。GraphLab
交替最小二乘法（ALS）、具有隐含反馈的
能够高效地执行与机器学习相关的数
ALS（ALS on implicit feedback）、加权
据依赖性强的迭代型算法，为Boosted
矩阵分解（weighted MF）、SVD++、并行
决策树、深度学习、文本分析等提供了
的随机梯度下降（parallel SGD）等。
可扩展的机器学习算法模块，能对分类
和推荐模型中的参数进行自动调优，和
5.2 Spark MLlib
SPARK、Hadoop、Apache Avro、OBDC
Spark MLlib2对常用的机器学习算法 connectors等进行了集成。由于功能独特，
GraphLab在业界很有名气。针对大规模
进行了实现，包括逻辑回归、支持向量机、
的数据集，采用GraphLab来进行随机游
朴素贝叶斯等分类预测算法，K-means聚
走（random walk）或基于图的推荐算法
类算法，各种梯度下降优化算法以及协同
非常有效。另外，GraphLab还实现了交替
过滤推荐算法。MLlib当前支持的是基于
最小二乘法ALS、随机梯度下降法 SGD、
矩阵分解的协同过滤方法，其函数优化过
SVD++、Weighted-ALS、Sparse-ALS、
程可采用其提供的交替最小二乘法或者梯
非负矩阵分解（non-negative matrix
度下降法来实现，同时支持显性反馈和隐
factorization）等算法。
性反馈信息。
2015026-9 BIG DATA RESEARCH 大数据
5.5 Duine 6.2 数据稀疏问题
Duine框架是一套以Java语言编写的 现有的大多数推荐算法都是基于用
软件库，可以帮助开发者建立预测引擎。 户—物品评分矩阵数据,数据的稀疏性问
Duine提供混合算法配置，即算法可根据 题主要是指用户—物品评分矩阵的稀疏
数据情况，在基于内容的推荐和协同过滤 性，即用户与物品的交互行为太少。一个大
中动态转换。例如在冷启动（比如尚无任 型网站可能拥有上亿数量级的用户和物品,
何评价的时候）条件下，它侧重基于内容的 飙升的用户评分数据总量在面对增长更
分析法，推荐模块主要通过算法，从用户 快的“用户—物品评价矩阵”时,仍然只占
资料和商品信息中提取信息、计算预测值， 极少的一部分,推荐系统研究中的经典数
主要包括以下几种方法：协同过滤法、基于 据集MovieLens的稀疏度仅4.5%，Netflix
实例的推理（用户给出相似评分的商品） 百万大赛中提供的音乐数据集的稀疏度
和GenreLMS（对分类的推理）。Duine具 是1.2%。这些都是已经处理过的数据集，
有一个反馈处理器模块，它以增强预测为 实际上真实数据集的稀疏度都远远低于
目标，利用程序学习和获取用户的显性和 1%。例如，Bibsonomy的稀疏度是0.35%，
隐性反馈，用算法进行处理后用以更新用 Delicious的稀疏度是0.046%，淘宝网数据
户的资料[18]。 的稀疏度甚至仅在0.01%左右[19]。根据经
验，数据集中用户行为数据越多，推荐算法
的精准度越高，性能也越好。若数据集非
6 大数据推荐系统研究面临的问题 常稀疏，只包含极少量的用户行为数据,推
荐算法的准确度会大打折扣，极容易导致
推荐算法的过拟合，影响算法的性能。
6.1 特征提取问题
推荐系统的推荐对象种类丰富,例如
6.3 冷启动问题
新闻、博客等文本类对象，视频、图片、音
乐等多媒体对象以及可以用文本描述的一 冷启动问题是推荐系统所面临的最
些实体对象等。如何对这些推荐对象进行 大问题之一。冷启动问题总的来说可以分
特征提取一直是学术界和工业界的热门研 为3类：系统冷启动问题、新用户问题和新
究课题。对于文本类对象，可以借助信息检 物品问题。系统冷启动问题指的是由于数
索领域己经成熟的文本特征提取技术来提 据过于稀疏，“用户—物品评分矩阵”的密
取特征。对于多媒体对象,由于需要结合多 度太低，导致推荐系统得到的推荐结果准
媒体内容分析领域的相关技术来提取特征, 确性极低。新物品问题是由于新的物品缺
而多媒体内容分析技术目前在学术界和工 少用户对该物品的评分，这类物品很难通
业界还有待完善,因此多媒体对象的特征提 过推荐系统被推荐给用户，用户难以对这
取是推荐系统目前面临的一大难题[19]。此 些物品评分，从而形成恶性循环，导致一些
外,推荐对象特征的区分度对推荐系统的 新物品始终无法有效推荐。新物品问题对
性能有非常重要的影响。目前还缺乏特别 不同的推荐系统影响程度不同：对于用户
有效的提高特征区分度的方法。 可以通过多种方式查找物品的网站，新物
2015026-10 TOPIC 专题
品问题并没有太大影响，如电影推荐系统 分矩阵中增加若干新分值时，系统不用对
等，因为用户可以有多种途径找到电影观 整个矩阵重新计算，而只需要进行少量计
看并评分；而对于一些推荐是主要获取物 算对原模型进行调整，因此大大加快了模
品途径的网站，新物品问题会对推荐系统 型的更新速度。同时，若干文献提出使用
造成严重影响。通常解决这个问题的途径 聚类的方式解决扩展性问题，通过聚类能
是激励或者雇佣少量用户对每一个新物品 有效减少用户和物品规模，但是这样会一
进行评分。新用户问题是目前对现实推荐 定程度地降低推荐精度。在求解模型全局
系统挑战最大的冷启动问题：当一个新的 优化问题上，学者也做了大量工作，希望能
用户使用推荐系统时，他没有对任何项目进 加快收敛速度，例如人们提出了并行的随
行评分，因此系统无法对其进行个性化推 机梯度下降法和交替最小二乘法等。
荐；即使当新用户开始对少量项目进行评分
时，由于评分太少，系统依然无法给出精确
的推荐，这甚至会导致用户因为推荐体验不 7 总结与展望
佳而停止使用推荐系统[20]。当前解决新用
户问题主要是通过结合基于内容和基于用 随着互联网的飞速发展，人们对于个
户特征的方法，掌握用户的统计特征和兴 性化的信息需求已经非常急切，推荐系统
趣特征，在用户只有少量评分甚至没有评 的出现可以很好地解决用户在使用互联网
分时做出比较准确的推荐。 和电子商务网站时的“信息爆炸”问题。本
文主要针对互联网大数据时代推荐系统的
产生和发展现状、领域需求和系统架构、
6.4 可扩展性问题
用户建模和推荐引擎、大数据时代推荐系
扩展性问题是推荐系统面临的又一难 统的特点挑战和关键技术、开源的大数据
题，特别是随着大数据时代的到来，用户 推荐软件、大数据推荐系统研究面临的问
数与物品数飞涨，传统推荐系统会随着问 题等进行了介绍。
题规模的扩大而效率大大降低。花费大量 大数据推荐系统的未来研究方向主要
时间才能得到推荐结果是难以接受的，特 在以下几个方面。
别是对于一些实时性要求较高的在线推荐 ● 从系统推荐到社会推荐，即在推荐
系统。使用基于内存的推荐系统，用户或 的过程中，除了考虑用户的历史行为信息，
者物品间的相似度计算会耗费大量时间； 还需要利用用户的社会网络信息来增强推
使用基于模型的推荐系统，利用机器学习 荐的效果；同时，在进行社会网络上的人与
算法学习模型参数同样会耗费大量时间， 人之间的推荐时，也要综合利用用户的历
这里学习时间主要用在求解全局最优问题 史行为信息，做到社会网络和历史行为信
上。解决扩展性问题，工业界一般采取的 息的互相利用和推荐效果的相互增强。
方法是线下学习、线上使用：先通过离线 ● 从以精确性为中心到综合考虑精确
数据事先算好用户/物品间相似度或者模型 性、多样性和新颖性的评估体系。
参数，然后线上只需要利用这些算好的数 ● 从单一数据源到交叉融合数据平
值进行推荐[20]。但是这并没有从根本上提 台，比如依据用户的跨网站行为数据，解决
高推荐算法的效率，Sarwar等人2002年 某一网站上的冷启动推荐问题。
提出了一种增量SVD协同过滤算法，当评 ● 从高速服务器到并行处理到云计算。
2015026-11 BIG DATA RESEARCH 大数据
● 从静态算法到动态增量算法、自适 [11] Paterek A. Improving regularized singular
value decomposition for collaborative
应算法，从脆弱算法到顽健算法。
filtering. Statistics, 2007: 2~5
[12] Koren Y. Factorization meets the
参考文献 neighborhood: a multifaceted collaborative
filtering model. Proceedings of the 14th
[1] 曾春, 邢春晓, 周立柱. 个性化服务技术综述. ACM SIGKDD Conference on Knowledge
软件学报, 2002(10): 1952~1961 Discovery and Data Mining, Las Vegas,
Zeng C, Xing C X, Zhou L Z. A survey Nevada, USA，2008: 426~434
of personalization technology. Journal of [13] L ee D, Seung H. Algorithms for non-
Software, 2002(10): 1952~1961 negative matrix factorization. Proceedings
[2] B ell R M, Koren Y. Lessons from the Netflix of Neural Information Processing
prize challenge. ACM SIGKDD Explorations Systems, Denver, Colorado, USA, 2000
Newsletter, 2007, 9(2): 75~79 [14] Sun J T, Zeng H J, Liu H, et al. CubeSVD:
[3] R endle S. Factorization machines with a novel approach to personalized
libFM. ACM Transactions on Intelligent Web search. Proceedings of the 14th
Systems & Technology, 2012, 3(3): International Conference on World Wide
451~458 Web, Chiba, Japan, 2005: 382~390
[4] Su X, Khoshgoftaar T M. A survey of [15] S teffen R, Leandro B M, Alexandros N,
collaborative filtering techniques. Advances et al. Learning optimal ranking with tensor
in Artificial Intelligence, 2009: 421425 factorization for tag recommendation.
[5] Chee S H S, Han J, Wang K. Rectree: an Proceedings of the 15th ACM SIGKDD
efficient collaborative filtering method. Conference on Knowledge Discovery and
Proceedings of Data Warehousing and Data Mining, Paris, France, 2009: 727~736
Knowledge Discovery: Third International [16] 王俞翔. 面向大数据集的推荐系统研究（硕士
Conference, Munich, Germany, 2001 学位论文）. 秦皇岛：燕山大学, 2014
[6] Connor M, Herlocker J. Clustering items for Wang Y X. Research on recommender
collaborative filtering. Proceedings of ACM system for big dataset (master
SIGIR Workshop on Recommender Systems, dissertation). Qinhuangdao: Yanshan
New Orleans, Louisiana, USA , 2001 University, 2014
[7] U ngar L H, Foster D P. Clustering [17] 黄 宜华. 大数据机器学习系统研究进展. 大数
methods for collaborative filtering. 据, 2015004
Proceedings of AAAI Workshop on Huang Y H. Research progress on big
Recommendation Systems, Madison, data machine learning system. Big Data
Wisconsin, USA, 1998 Research, 2015004
[8] Miyahara K, Pazzani M J. Collaborative [18] 米可菲, 张勇, 邢春晓等. 面向大数据的开
filtering with the simple bayesian 源推荐系统分析. 计算机与数字工程, 2013,
classifier. Proceedings of the 6th Pacific 41(10): 1563~1566
Rim International Conference on Artificial Feben T, Zhang Y, Xing C X, et al. An
Intelligence, Melbourne, Australia, 2000: analysis of open source recommender
679~689 systems in the big data era. Computer and
[9] Miyahara K, Pazzani M J. Improvement Digital Engineering. 2013, 41(10): 1563~1566
of collaborative filtering with the [19] 孙远帅. 基于大数据的推荐算法研究（硕士学
simple bayesian classifier. IPSJ Journal, 位论文）. 厦门：厦门大学, 2014
2002,43(11): 3429~3437 Sun Y S. Recommendation algorithms in
[10] V ucetic S, Obradovic Z. Collaborative the big data era (master dissertation).
filtering using a regression-based Xiamen: Xiamen University, 2014
approach. Knowledge and Information [20] 刘士琛. 面向推荐系统的关键问题研究及应用
Systems, 2005, 7（1）: 1~22 (博士学位论文). 合肥：中国科学技术大学, 2014
2015026-12 TOPIC 专题
Liu S C. Research on the key issues dissertation). Hefei: University of Science
for the recommender systems (doctor and Technology of China, 2014
作者简介
李翠平，女，中国人民大学信息学院教授、博士生导师，中国计算机学会杰出会员，中国计算机学会大数据
专家委员会、数据库专家委员会委员。目前研究方向为数据仓库、数据挖掘、社会网络分析和社会媒体推荐等。
主持和参与国家自然科学基金、“973”计划、“863”计划等10多项国家级和省部级项目，在国内外重要期刊和国
际会议上发表论文50多篇。
蓝梦微，女，中国人民大学信息学院博士生，CCF学生会员，主要研究领域为推荐系统、数据挖掘、大数据
分析。
邹本友，男，中国人民大学信息学院博士生，CCF学生会员，主要研究领域为推荐系统、数据挖掘、大数据
分析。
王绍卿，男，中国人民大学信息学院博士生，CCF学生会员，主要研究领域为推荐系统、数据挖掘、大数据
分析。
赵衎衎，男，中国人民大学信息学院博士生，CCF学生会员，主要研究领域为推荐系统、数据挖掘、大数据
分析。
收稿日期：2015-08-11
基金项目：国家基础研究发展计划（“973”计划）基金资助项目（No.2014CB340402），国家高技术研究发展计划（“863”计划）基金资
助项目（No.2014AA015204），国家自然科学基金资助项目（No.61272137, No. 61033010, No.61202114），国家社会科学基金资助项目
（No.12&ZD220），国家高等学校学科创新引智计划（“111”计划）基金资助项目
Foundation Items: National Basic Research Program of China (973 Program) (No.2014CB340402), National High Technology
Research and Development Program of China (863 Program) (No.2014AA015204), The National Natural Science Foundation of
China(No.61272137, No.61033010, No.61202114), The National Social Science of Foundation of China (No.12&ZD220)，The Project
of Attracting Talents of Discipline to National Universities (111 Project)
论文引用格式：李翠平, 蓝梦微, 邹本友等. 大数据与推荐系统. 大数据, 2015026
Li C P, Lan M W, Zou B Y, et al. Big data and recommendation system. Big Data Research, 2015026
2015026-13 --------------------------------------------------------------------------------- 第４１卷 第１０期 计 算 机 学 报 Ｖｏｌ．４１ Ｎｏ．１０
２０１８年１０月 ＣＨＩＮＥＳＥ ＪＯＵＲＮＡＬ ＯＦ ＣＯＭＰＵＴＥＲＳ Ｏｃｔ．２０１８
大规模复杂信息网络表示学习：概念、方法与挑战
齐金山１），２） 梁 循１） 李志宇１） 陈燕方３） 许 媛１）
１）（中国人民大学信息学院 北京 １００８７２）
２）（淮阴师范学院计算机科学与技术学院 江苏 淮安 ２２３３００）
３）（中国人民大学信息资源管理学院 北京 １００８７２）
摘 要 大数据时代的到来，使得当前的复杂信息网络研究领域面临着三个基础性问题，即网络的动态性、大规模
性以及网络空间的高维性．传统复杂信息网络特征的表示通常以邻接矩阵、出入度、中心性等离散型方式表达，这
种表达方式在现有的大规模动态信息网络的新环境下，其计算效率及准确率都受到了很大的挑战．随着机器学习
算法的不断发展，复杂信息网络的特征表示学习同样也引起了越来越多的关注．与自然语言中的词向量学习的目
标类似，目前较为前沿的大规模复杂网络特征表示学习方法的目标是将网络中任意顶点的结构特征映射到一个低
维度的、连续的实值向量，在进行这种映射的过程中，尽量保留顶点之间的结构特征关系，使大规模网络特征学习
能够有效地应用于各类网络应用中，如网络中的链接预测、顶点分类、个性化推荐、大规模社区发现等．通过对复杂
信息网络特征的学习，不仅能够有效缓解网络数据稀疏性问题，而且把网络中不同类型的异质信息融合为整体，可
以更好地解决某些特定问题．同时，还能够高效地实现语义相关性操作，从而显著提升在大规模，特别是超大规模
的网络中进行相似性顶点匹配的计算效率等．该文主要对近些年来关于复杂信息网络表示学习的方法和研究现状
进行了总结，并提出自己的想法和意见．首先概述了表示学习的发展历史，然后分别阐述了有关大规模复杂信息网
络、网络表示学习等基本概念与理论基础；接着，根据学习模型的不同，对经典的、大规模的、基于内容的、基于融合
的以及异构的网络表示学习模型进行了全面的分析与比较．另外，对当前的网络表示学习方法所采用的实验数据
集、评测指标以及应用场景等也进行了总结概括．最后给出了大规模复杂信息网络表示学习的研究难题以及未来
的研究方向．大规模复杂网络表示学习是一个复杂的问题．当前研究中，大多数学习模型是根据复杂网络的结构或
者内容来进行顶点的特征表示学习．只有融合复杂网络结构特征和内容特征的表示学习才能够更好地反映出一个
网络特征的真实情况，使得学习得到的网络特征表示更具有意义与价值．
关键词 大规模复杂信息网络；网络特征；顶点嵌入；网络表示学习；深度学习；特征学习
中图法分类号 ＴＰ１８ ＤＯＩ号 １０．１１８９７／ＳＰ．Ｊ．１０１６．２０１８．０２３９４
Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ Ｌｅａｒｎｉｎｇ ｏｆ Ｌａｒｇｅ－Ｓｃａｌｅ Ｃｏｍｐｌｅｘ Ｉｎｆｏｒｍａｔｉｏｎ Ｎｅｔｗｏｒｋ：
Ｃｏｎｃｅｐｔｓ，Ｍｅｔｈｏｄｓ ａｎｄ Ｃｈａｌｌｅｎｇｅｓ
ＱＩ Ｊｉｎ－Ｓｈａｎ１），２） ＬＩＡＮＧ Ｘｕｎ１） ＬＩ Ｚｈｉ－Ｙｕ１） ＣＨＥＮ Ｙａｎ－Ｆａｎｇ３） ＸＵ Ｙｕａｎ１）
１）（Ｓｃｈｏｏｌ ｏｆ Ｉｎｆｏｒｍａｔｉｏｎ，Ｒｅｎｍｉｎ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｃｈｉｎａ，Ｂｅｉｊｉｎｇ １００８７２）
２）（Ｓｃｈｏｏｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ ＆Ｔｅｃｈｎｏｌｏｇｙ，Ｈｕａｉｙｉｎ Ｎｏｒｍａｌ Ｕｎｉｖｅｒｓｉｔｙ，Ｈｕａｉ’ａｎ，Ｊｉａｎｇｓｕ ２２３３００）
３）（Ｓｃｈｏｏｌ ｏｆ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｓｏｕｒｃｅ Ｍａｎａｇｅｍｅｎｔ，Ｒｅｎｍｉｎ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｃｈｉｎａ，Ｂｅｉｊｉｎｇ １００８７２）
Ａｂｓｔｒａｃｔ Ｗｉｔｈ ｔｈｅ ａｒｒｉｖａｌ ｏｆ ｔｈｅ ａｇｅ ｏｆ ｂｉｇ ｄａｔａ，ｔｈｅ ｃｕｒｒｅｎｔ ｓｔｕｄｙ ｏｆ ｃｏｍｐｌｅｘ ｉｎｆｏｒｍａｔｉｏｎ
ｎｅｔｗｏｒｋ ｉｓ ｆａｃｉｎｇ ｔｈｒｅｅ ｓｅｖｅｒｅ ｃｈａｌｌｅｎｇｅｓ：ｄｙｎａｍｉｃｉｔｙ，ｌａｒｇｅ ｓｃａｌｅ ａｎｄ ｈｉｇｈ－ｄｉｍｅｎｓｉｏｎａｌｉｔｙ ｏｆ ｔｈｅ
ｎｅｔｗｏｒｋ．Ｔｒａｄｉｔｉｏｎａｌｌｙ，ｔｈｅ ｃｈａｒａｃｔｅｒｉｓｔｉｃｓ ｏｆ ｃｏｍｐｌｅｘ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋｓ ａｒｅ ｒｅｐｒｅｓｅｎｔｅｄ ｉｎ
ｄｉｓｃｒｅｔｅ ｆｏｒｍｓ ｓｕｃｈ ａｓ ａｄｊａｃｅｎｃｙ ｍａｔｒｉｘ，ｉｎ－ｏｕｔ ｄｅｇｒｅｅ ａｎｄ ｃｅｎｔｒａｌｉｔｙ．Ｓｕｃｈ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｈａｖｅ
收稿日期：２０１７－０１－１０；在线出版日期：２０１７－１２－０８．本课题得到国家自然科学基金（７１２７１２１１，７１５３１０１２）资助．齐金山，男，１９７７年生，博
士研究生，主要研究方向为社会计算、数据挖掘．Ｅ－ｍａｉｌ：ｑｉｊｉｎｓｈａｎ＠ｓｉｎａ．ｃｏｍ．ｃｎ．梁 循（通信作者），男，１９６５年生，博士，教授，博士生
导师，中国计算机学会（ＣＣＦ）会员，主要研究领域为神经网络、支持向量机、社会计算．Ｅ－ｍａｉｌ：ｘｕｎ＿＿ｌｉａｎｇ＠１６３．ｃｏｍ．李志宇，男，１９９１年
生，博士研究生，中国计算机学会（ＣＣＦ）会员，主要研究方向为社会计算、自然语言处理、Ｗｅｂ挖掘．陈燕方，女，１９９２年生，博士研究生，
主要研究方向为Ｗｅｂ挖掘、自然语言处理．许 媛，女，１９９３年生，硕士研究生，主要研究方向为社会计算． １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２３９５
ｇｒｅａｔ ｄｉｓａｄｖａｎｔａｇｅｓ ｉｎ ｃｏｍｐｕｔａｔｉｏｎａｌ ｅｆｆｉｃｉｅｎｃｙ ａｎｄ ａｃｃｕｒａｃｙ ｉｎ ｔｈｅ ｎｅｗ ｅｎｖｉｒｏｎｍｅｎｔ ｏｆ ｌａｒｇｅ－ｓｃａｌｅ
ｄｙｎａｍｉｃ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋ．Ｍｅａｎｗｈｉｌｅ，ｗｉｔｈ ｔｈｅ ａｄｖａｎｃｅ ｉｎ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ａｌｇｏｒｉｔｈｍｓ，ｔｈｅ
ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｏｆ ｃｏｍｐｌｅｘ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋ ｒｅｃｅｉｖｅｓ ｍｏｒｅ ａｔｔｅｎｔｉｏｎ．Ｓｉｍｉｌａｒ ｔｏ ｔｈｅ
ｌｅａｒｎｉｎｇ ｏｆ ｗｏｒｄ ｖｅｃｔｏｒｓ ｉｎ ｎａｔｕｒａｌ ｌａｎｇｕａｇｅ ｐｒｏｃｅｓｓｉｎｇ，ｔｈｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｏｆ ｌａｒｇｅ－ｓｃａｌｅ
ｎｅｔｗｏｒｋ ａｉｍｓ ｔｏ ｍａｐ ｔｈｅ ｓｔｒｕｃｔｕｒａｌ ｃｈａｒａｃｔｅｒｉｓｔｉｃｓ ｏｆ ｅａｃｈ ｖｅｒｔｅｘ ｉｎ ｔｈｅ ｎｅｔｗｏｒｋ ｔｏ ａ ｌｏｗ－
ｄｉｍｅｎｓｉｏｎａｌ，ｒｅａｌ－ｖａｌｕｅｄ ｖｅｃｔｏｒ，ｄｕｒｉｎｇ ｗｈｉｃｈ ｔｈｅ ｓｔｒｕｃｔｕｒａｌ ｒｅｌａｔｉｏｎｓｈｉｐ ｏｆ ｖｅｒｔｉｃｅｓ ｉｎ ｔｈｅ
ｎｅｔｗｏｒｋ ｉｓ ｋｅｐｔ ｔｏ ｔｈｅ ｇｒｅａｔｅｓｔ ｅｘｔｅｎｔ，ｓｏ ｔｈａｔ ｖａｒｉｏｕｓ ｔｙｐｅｓ ｏｆ ｎｅｔｗｏｒｋ ａｐｐｌｉｃａｔｉｏｎｓ ｃａｎ ｂｅ
ｅｆｆｅｃｔｉｖｅｌｙ ａｐｐｌｉｅｄ，ｓｕｃｈ ａｓ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ，ｖｅｒｔｅｘ ｃｌａｓｓｉｆｉｃａｔｉｏｎ，ｐｅｒｓｏｎａｌｉｚｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ，
ａｎｄ ｌａｒｇｅ ｓｃａｌｅ ｃｏｍｍｕｎｉｔｙ ｄｉｓｃｏｖｅｒｙ．Ｍｏｒｅ ｐｒｅｃｉｓｅｌｙ，ｔｈｅ ａｄｖａｎｔａｇｅｓ ｏｆ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｉｎ
ｃｏｍｐｌｅｘ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋｓ ａｒｅ ｔｈｒｅｅ－ｆｏｌｄ．Ｆｉｒｓｔ，ｉｔ ｒｅｄｕｃｅｓ ｔｈｅ ｅｆｆｅｃｔ ｏｆ ｄａｔａ ｓｐａｒｓｉｔｙ ｉｎ
ｎｅｔｗｏｒｋｓ．Ｓｅｃｏｎｄ，ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｉｎｆｏｒｍａｔｉｏｎ ｉｓ ｉｎｔｅｇｒａｔｅｄ ｉｎｔｏ ｔｈｅ ｓａｍｅ ｖｅｃｔｏｒ ｓｐａｃｅ ｓｏ ｔｈａｔ
ｓｐｅｃｉｆｉｃ ａｐｐｌｉｃａｔｉｏｎｓ ｃａｎ ｂｅ ａｐｐｌｉｅｄ ｅａｓｉｌｙ．Ｔｈｉｒｄ，ｓｅｍａｎｔｉｃ ｏｐｅｒａｔｉｏｎｓ ｃａｎ ｂｅ ｉｍｐｌｅｍｅｎｔｅｄ ｉｎ ａ
ｗａｙ ｗｈｉｃｈ ｄｒａｍａｔｉｃａｌｌｙ ｉｍｐｒｏｖｅｓ ｔｈｅ ｅｆｆｉｃｉｅｎｃｙ ｏｆ ｎｏｄｅ ｓｉｍｉｌａｒｉｔｙ ｃｏｍｐｕｔｉｎｇ ｉｎ ｌａｒｇｅ－ｓｃａｌｅ
ｎｅｔｗｏｒｋｓ．Ｔｏ ｔｈｉｓ ｅｎｄ，ｔｈｅ ｐａｐｅｒ ｐｒｏｐｏｓｅｓ ａ ｔａｘｏｎｏｍｙ ｏｆ ｂｏｔｈ ｔｈｅ ｃｌａｓｓｉｃｓ ａｎｄ ｔｈｅ ｓｔａｔｅ ｏｆ ｔｈｅ
ａｒｔｓ ｏｎ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｏｆ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋｓ．Ｗｅ ｆｉｒｓｔ ｐｒｏｖｉｄｅ ａ ｈｉｓｔｏｒｉｃａｌ ｏｖｅｒｖｉｅｗ ｏｆ
ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｉｎ ｇｒａｐｈｓ，ｆｏｌｌｏｗｅｄ ｂｙ ｔｈｅ ｅｌａｂｏｒａｔｉｏｎ ｏｆ ｃｏｒｒｅｌａｔｅｄ ｃｏｎｃｅｐｔｓ ａｎｄ ｔｈｅｏｒｉｅｓ，
ａｎｄ ｔｈｅｎ ａ ｃｏｍｐｒｅｈｅｎｓｉｖｅ ａｎａｌｙｓｉｓ ｏｆ ｖａｒｉｏｕｓ ｌｅａｒｎｉｎｇ ｍｏｄｅｌｓ ｉｓ ｐｒｏｐｏｓｅｄ．Ｗｅ ｃｏｎｓｉｄｅｒ ｔｈｅ ｃｌａｓｓｉｃ
ｍｏｄｅｌｓ，ｆｏｒ ｅｘａｍｐｌｅ，ｔｈｅ ｓｐｅｃｔｒａｌ ｍｅｔｈｏｄ ａｎｄ ｏｐｔｉｍｉｚａｔｉｏｎ ｂａｓｅｄ ｍｅｔｈｏｄｓ；ａｎｄ ｍｏｄｅｌｓ ｆｏｒ ｌａｒｇｅ
ｓｃａｌｅ ｎｅｔｗｏｒｋｓ，ｉｎｃｌｕｄｉｎｇ ｔｈｅ ｈｉｇｈ－ｏｒｄｅｒ ｒｅｌａｔｉｏｎｓｈｉｐ ｂａｓｅｄ ｍｏｄｅｌｓ，ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ｍｏｄｅｌｓ ａｎｄ
ｍｏｄｅｌｓ ｗｉｔｈ ｓｃａｌａｂｉｌｉｔｙ．Ｂｏｔｈ ｔｗｏ ｃａｔｅｇｏｒｉｅｓ ｏｆ ｍｏｄｅｌｓ ｆｏｃｕｓ ｏｎ ｔｈｅ ｓｔｒｕｃｔｕｒｅ ｏｆ ｎｅｔｗｏｒｋ．Ｉｎ
ｃｏｎｔｒａｓｔ，ｔｈｅ ｐｒｏｂａｂｉｌｉｔｙ ｂａｓｅｄ ｍｏｄｅｌｓ，ｉ．ｅ．，ｔｈｅ ｔｏｐｉｃ ｍｏｄｅｌｓ，ｗｈｉｃｈ ｌｅａｒｎ ｔｈｅ ｃｏｎｔｅｎｔ ｏｆ
ｄｏｃｕｍｅｎｔｓ ｂｙ ｍｅａｎｓ ｏｆ ｆｉｎｄｉｎｇ ｔｈｅ ｓｔａｔｉｃ ａｎｄ ｄｙｎａｍｉｃ ｐａｔｔｅｒｎｓ，ｃａｎ ｂｅ ａｓｓｏｃｉａｔｅｄ ｔｏ ｔｈｅ ｌｅａｒｎｉｎｇ
ｏｆ ｃｏｎｔｅｎｔｓ ｉｎ ｎｅｔｗｏｒｋｓ，ｅ．ｇ．，ｃｏｎｔｅｎｔ ｗｉｔｈ ｅａｃｈ ｖｅｒｔｅｘ．Ｔｈｅ ｃｏｍｂｉｎａｔｉｏｎ ｏｆ ｔｈｅｓｅ ｔｗｏ ａｓｐｅｃｔｓ，
ｓｕｃｈ ａｓ ｔｈｅ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ ｂａｓｅｄ ｍｏｄｅｌｓ ａｎｄ ｐｒｏｂａｂｉｌｉｓｔｉｃ ｇｒａｐｈｉｃａｌ ｍｏｄｅｌｓ ａｒｅ ａｌｓｏ ｃｏｎｓｉｄｅｒｅｄ．
Ｆｉｎａｌｌｙ ｗｅ ｄｉｓｃｕｓｓ ｍｏｄｅｌｓ ｆｏｒ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｎｅｔｗｏｒｋｓ．Ｗｅ ｃｏｍｐａｒｅ ｄｉｆｆｅｒｅｎｔ ｍｅｔｈｏｄｓ ｆｒｏｍ ｓｅｖｅｒａｌ
ｐｅｒｓｐｅｃｔｉｖｅｓ ｉｎ ｄｅｔａｉｌ ａｎｄ ｄｅｒｉｖｅ ｓｏｍｅ ｃｏｎｃｌｕｓｉｏｎｓ．Ｉｎ ａｄｄｉｔｉｏｎ，ｔｈｅ ｐａｐｅｒ ｐｒｅｓｅｎｔｓ ａ ｓｕｍｍａｒｙ ｏｆ
ｔｈｅ ｅｘｐｅｒｉｍｅｎｔａｌ ｄａｔａ ｓｅｔｓ，ｅｖａｌｕａｔｉｏｎ ｍｅｔｒｉｃｓ ａｎｄ ａｐｐｌｉｃａｔｉｏｎ ｓｃｅｎａｒｉｏｓ ｏｆ ｄｉｆｆｅｒｅｎｔ ｇｒａｐｈ
ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｍｅｔｈｏｄｓ．Ｗｅ ａｌｓｏ ｄｉｓｃｕｓｓ ｔｈｅ ｅｘｉｓｔｉｎｇ ｐｒｏｂｌｅｍｓ ａｎｄ ｆｕｔｕｒｅ ｓｔｕｄｉｅｓ ｉｎ
ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｏｆ ｌａｒｇｅ－ｓｃａｌｅ ｃｏｍｐｌｅｘ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋ．Ｉｎ ｂｒｉｅｆ，ｍｏｓｔ ｅｘｉｓｔｉｎｇ ｗｏｒｋｓ
ｆｏｃｕｓ ｏｎ ｅｉｔｈｅｒ ｔｈｅ ｓｔｒｕｃｔｕｒｅ ｏｒ ｃｏｎｔｅｎｔ ｏｆ ｔｈｅ ｎｅｔｗｏｒｋ ｉｎ ｔｈｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｏｆ ｖｅｒｔｉｃｅｓ．
Ｈｏｗｅｖｅｒ，ｎｅｔｗｏｒｋ ｐｒｏｐｅｒｔｉｅｓ ｓｈｏｕｌｄ ｂｅ ｂｅｔｔｅｒ ｒｅｖｅａｌｅｄ ｂｙ ｃｏｎｓｉｄｅｒｉｎｇ ｂｏｔｈ ｃｈａｒａｃｔｅｒｉｓｔｉｃｓ．
Ｒｏｏｍ ｆｏｒ ｆｕｔｕｒｅ ｉｍｐｒｏｖｅｍｅｎｔｓ ｏｆ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｔｙｐｉｃａｌｌｙ ｌｉｅｓ ｉｎ ｔｈｅ ｆａｕｌｔ ｔｏｌｅｒａｎｃｅ ｏｆ
ｎｅｔｗｏｒｋ ｆｅａｔｕｒｅ ｅｘｔｒａｃｔｉｏｎ，ｔｈｅ ａｄａｐｔｉｖｉｔｙ ｆｏｒ ｄｙｎａｍｉｃ ｎｅｔｗｏｒｋｓ，ｔｈｅ ｃｏｍｂｉｎａｔｉｏｎ ｏｆ ｈｅｔｅｒｏｇｅｎｅｏｕｓ
ｉｎｆｏｒｍａｔｉｏｎ ｉｎ ｎｅｔｗｏｒｋ，ｔｈｅ ｕｎｉｖｅｒｓａｌｉｔｙ ｏｆ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ，ｔｈｅ ｄｉｓｔｒｉｂｕｔｅｄ ｎｅｔｗｏｒｋ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ
ａｎｄ ｆｅａｔｕｒｅ ｌｅａｒｎｉｎｇ ｆｏｒ ｓｐｅｃｉｆｉｃ ｓｕｂ－ｇｒａｐｈ ｓｔｒｕｃｔｕｒｅｓ．
Ｋｅｙｗｏｒｄｓ ｌａｒｇｅ－ｓｃａｌｅ ｃｏｍｐｌｅｘ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋ；ｎｅｔｗｏｒｋ ｆｅａｔｕｒｅｓ；ｖｅｒｔｅｘ ｅｍｂｅｄｄｉｎｇ；
ｎｅｔｗｏｒｋ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ；ｄｅｅｐ ｌｅａｒｎｉｎｇ；ｆｅａｔｕｒｅ ｌｅａｒｎｉｎｇ
链接进行信息或功能的交互．不同于普通网络，大规
１ 引 言 模复杂信息网络顶点的数量已经发展到百万甚至数
十亿，而且包含的数据亦呈现多样化、异质化以及动
大规模复杂信息网络可以看作由顶点（ｎｏｄｅｓ） 态性等特征．其中以社会网络为代表的大规模复杂
和链接（ｌｉｎｋｓ）或边（ｅｄｇｅｓ）所构成的复杂抽象组合， 信息网络在顶点与链接的数量上、包含的内容形式
包含顶点之间通过有向（ｄｉｒｅｃｔｅｄ）或无向（ｕｎｄｉｒｅｃｔｅｄ） 上以及交互关系的种类上都以极快的速度不断更 ２３９６ 计 算 机 学 报 ２０１８年
新．以新浪微博为例，在顶点数量上，截至２０１５年 图嵌入算法（ｇｒａｐｈ ｅｍｂｅｄｄｉｎｇ）如ＳＶＤ［７］、ＬＬＥ［８］、
９月３０日，微博月活跃用户为２．２２亿，相比２０１４年 Ｉｓｏｍａｐ［９］、Ｌａｐｌａｃｉａｎ Ｅｉｇｅｎｍａｐｓ［１０］、ＭＤＳ［１１］等应用
同期增长３３％．在顶点关系上，微博已经从原有的 于网络中，往往需要构造亲和度矩阵，通过特征向量
关注关系进一步演化为转发关系、话题关系、营销关 求解的方式获得顶点的低维表示．Ｌｉ等人［１２］研究了
系和行业关系等多重关系网络的固定或随机组合． 特征学习技术的图结构化输入．在图神经网络的工
在顶点与链接的属性上，用户所发布的内容以及用 作基础上，通过修改使用门控循环单元以及优化技
户参与的形式呈现多样化，不仅包括传统的文本、图 术，然后扩展到输出序列．Ａｈｍｅｄ等人［１３］提出了一
片、音频和视频等多媒体信息，还衍生出微博投票、 种图因式分解技术，通过使用随机梯度下降优化的
微博众筹、微博旅游等多种互动与参与形式①．正是
矩阵分解找到大规模图的低维向量形式．然而在复
由于大规模复杂信息网络原始表达的丰富性和高量 杂信息网络顶点数量急剧增加时，图嵌入算法的计
级，这使得对于网络的表示学习与分析的需求急剧
算复杂度往往是无法承受的．最近，基于深度学习技
增长成为必然． 术在语音识别、计算机视觉和自然语言处理等领域
表示学习（Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ Ｌｅａｒｎｉｎｇ，ＲＬ）是指
取得了很大的成功．在自然语言处理中，文本表示学
通过将符号化的数据编码到低维向量空间中［１］．学
习模型（如词表示学习［１４－１５］和文档的表示学习［１６］）
习数据的表示使得在构建机器学习分类器或其它预
具有算法高效性和可计算性的优点，能够处理大规
测时更容易提取有用的信息，同时这种表示得到的
模的文本数据．因此，借鉴文本表示学习模型的思
结果也可用于作为监督分类器的输入数据．相比传
想，针对大规模复杂信息网络设计有效的网络表示
统的Ｏｎｅ－Ｈｏｔ表示方法［２］，表示学习不仅能够获取
模型已经逐步成为当前的研究热点．相应地，一些
数据之间的相似性，而且同时可以缓解数据的稀疏
重要的研究成果频频出现在《Ｎａｔｕｒｅ》、《Ｓｃｉｅｎｃｅ》、
性（ｓｐａｒｓｉｔｙ）问题．Ｂｅｎｇｉｏ等人［１］指出：表示学习是
ＴＫＤＥ、ＡＡＡＩ、ＫＤＤ等国际重要期刊和会议上．
通过对数据进行表达形式的变化，使其数据所包含
大规模复杂信息网络表示学习主要的作用是用
的信息更加容易被提取和分析，即将原来由人工设
向量表示网络中顶点和链接，具有以下优点：
定的特征工程转换为机器的自我学习过程．与此相
（１）可以有效缓解复杂大规模信息网络数据的
似，知识图谱表示学习从多角度解决知识库中实体
稀疏性问题．网络中各顶点的向量都是稠密的，因此
和关系的建模问题，把实体或关系映射到低维特征
可以对任意顶点之间的语义相关性进行度量．此外，
向量空间中，以实现实体、关系及其之间的复杂语义
通过把网络中的顶点映射到相同的特征空间中，使
的高效表示．Ｂｏｒｄｅｓ等人［３］提出了一种将实体与关
用高出／入度顶点的结构信息用于帮助低出／入度顶
系嵌入到低维向量空间中的ＴｒａｎｓＥ模型．自ＴｒａｎｓＥ
点的结构或语义特征的表示，提供低出／入度顶点的
提出之后，大部分知识表示学习模型是以它为基
语义表示的精准性．
础进行的扩展或改进，如 ＴｒａｎｓＨ［４］、ＴｒａｎｓＲ［５］、
（２）可实现大规模复杂信息网络中异质顶点信
ＴｒａｎｓＤ［６］等模型．同样的，复杂信息网络表示学习
息融合．大规模复杂信息网络中包含大量的不同类
则是通过对网络的结构特征以及内容特征等进行学
型的顶点和关系，这些不同类型的异质信息需要融
习，得到网络的统一表现形式即向量化，并以此为输
合为整体，才能得到更有效应用．通过设计合适的网
入，将其拓展到例如多标签分类、社区发现、隐私保
络特征学习模型，把不同种类的顶点映射到统一的
护系统等应用中．
向量空间里，从而建立统一的特征空间，例如同时基
复杂信息网络的表示学习相比于其它数据类型
于结构或内容，实现异质信息的融合．
的表示学习难度更大．从数据构型上看，复杂信息网
（３）可提升大规模复杂信息网络的相关应用的
络的表示学习涉及到对象关系学习（如顶点离散关
计算效率．基于特征向量的降维算法在处理大规模
系学习、顶点连续关系学习）和对象属性学习（如顶
复杂信息网络时，算法复杂度高、扩展性差．网络表
点属性学习、边属性学习），以及它们之间的交互学
示学习使用向量表示，例如在大规模网络量级的情
习．从数据体量上看，复杂信息网络的表示学习涉及
况下，通过简单的查询和向量相似性计算就能够高
到从１０２到１０９甚至更大的顶点或边集规模．其中每
一个顶点既可以被单独的划分成为一个类，也可以
① ２０１５年微博用户发展报告．ｈｔｔｐ：／／ｗｗｗ．１９９ｉｔ．ｃｏｍ／ａｒｃｈｉｖｅｓ／
和众多的顶点按照社区标签形式划分成多个类．把 ４２２５８３．ｈｔｍｌ．２０１６－２－１７ １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２３９７
效地实现结构／语义的相关性，从而显著提升计算效 网络的研究方法，在当前大规模复杂网络中几乎没
率．同时使得学习得到的向量能够简单而快速的被 有什么用或没有什么实质意义．例如从一个小型网
其它应用所采纳．因此，大规模复杂信息网络表示学 络中移除某个顶点后，剩余的顶点可能成为该网络
习的研究，对帮助我们分析和理解网络，预测用户行 链接中的关键顶点问题．在小型网络中分析这样的
为等具有重大意义． 问题是很有意义的．但在有数以百万计顶点的网络
本文对近年来关于大规模复杂信息网络表示学 中，即使移除任意顶点后也不会对其它顶点产生重
习的方法及研究现状进行归纳，在此基础上提出自 要影响，因此这一问题就显得不再有意义．以往的网
己的看法和建议．首先在第２节给出大规模复杂信 络规模都比较小，仅包含数百个顶点，对其进行研究
息网络表示学习所涉及的有关概念与理论基础；在
分析可以解决一些简单的网络结构问题．现有的大
第３节讨论当前大规模复杂信息网络表示学习的主 规模复杂网络往往包含数以百万计的顶点，很难依
流方法与模型，同时对现有方法之间的优劣进行对
靠个人力量将其描述清楚．对于当前网络的研究方
比分析；第４节则从大规模复杂信息网络学习所涉
法主要是如何挖掘出大规模网络的结构、特征等有
及到的应用场景、数据集与评测指标三个方面，对大
效信息［２０］．
规模复杂网络学习模型的评测进行概述；最后，本文
２．１．２ 大规模复杂信息网络
在第５节和第６节分别讨论当前大规模复杂信息网
随着互联网技术以及大数据的蓬勃发展，使得
络表示学习的研究难点和未来的可能研究方向．
顶点带有丰富信息内容的复杂网络日益增多，同时
网络的规模也在不断地扩大．根据网络顶点所承载
２ 基本概念
信息的不同类型，这些网络可以包括社会网络、科学
家合作网络、引文网络、通讯网络、公路网络和 Ｗｅｂ
２．１ 网络与大规模复杂信息网络
网络等，本文将其统称为复杂信息网络．复杂信息网
２．１．１ 网络
络是一种顶点带有明显多媒体内容（例如：文本、图
网络由一组顶点和连接顶点的边组成．生活中，
像、音频或视频）特征的现实网络．复杂信息网络在
很多系统和组织都可以用网络来刻画，如亲朋好友
宏观上具有网络的结构关系属性，在微观上每个顶
之间的社交网络．关于网络的最早研究可以追溯到
点具有内容属性．同时，随着大数据时代的来临，各
数学中的图论问题．１７３５年欧拉解决了格尼斯堡七
类复杂信息网络的量级还在迅猛增长且呈动态形
桥问题［１７］，从而开创了数学的另一分支－图论．如今
式，其顶点的个数甚至达到几十亿之多．因此，原有
图论成为了专门用来刻画和分析网络性质的一门学
的网络分析方法在如此大规模的甚至超大规模的数
科．在科学界，网络得到了广泛研究，如在社会学领
据面前显得力不从心，所以针对大规模复杂信息网
域中，用顶点来表示行动者，顶点和顶点之间连线则
络的相关研究已经受到了学术界和工业界的广泛
代表行动者之间的关系．同样，网络在经济学、图书
关注．
情报学、心理学等领域中得到较多的应用．人们通过
关于网络的定义最早来源于图论，Ｔａｎｇ等
对网络进行研究，希望能够发现其内在机制、演化规
人［２１］则给出了有关大规模的复杂信息网络的定义：
律以及网络的传播模式等内容．Ｒａｐｏｐｏｒｔ等人［１８］
Ｇ＝（Ｖ，Ｅ，Ｗ）表示一个复杂信息网络，其中Ｖ＝
提出的数学模型强调了网络中度分布的重要性．
｛ｖ，ｖ，…，ｖ ｝代表网络中顶点的集合，每个顶点代
Ｍｉｌｇｒａｍ在１９６９年开展了“小世界”（ｓｍａｌｌ－ｗｏｒｌｄ） １ ２ Ｎ
实验，探索现实社会中信息如何在好友网络之间传
表一个数据对象，Ｅ＝｛ｅ １，ｅ ２，…，ｅ Ｍ｝则是边的集合，
递［１９］．Ｂｕｒｔ于１９９２年提出的结构洞理论，揭示了网 每条边代表两个数据对象之间的关系，Ｗ为一个赋
络中一些对象之间存在直接的关联，而一些对象出
权矩阵，表示关系的强度．根据以上定义并结合之前
现关系间断的情形，即从整体上看，网络出现结构洞 的相关研究，本文给出了大规模的复杂信息网络的
穴．早期的网络研究受到诸多的限制，对数据的收集 另一种形式化定义．
和采样有限，因此传统的网络研究会有准确性低、个 定义１（大规模复杂信息网络）． 给定ｍ种类
人主观性强以及样本规模小等方面的问题［２０］ 型的数据对象集合｛Ｘ ，Ｘ ，…，Ｘ ｝，其中 Ｘ ＝
１ ２ ｍ １
随着计算技术的发展和越来越强大的互联网， ｛ｘ ，ｘ ，…，ｘ ｝，…，Ｘ ＝｛ｘ ，ｘ ，…，ｘ ｝．用
１１ １２ １ ｎ１ ｍ ｍ１ ｍ２ ｍｎｍ
对于网络的研究出现了很多新的方法．以往对小型 Ｇ＝（Ｖ，Ｅ，Ｗ，Ｃ）表示一个大规模的复杂信息网络， ２３９８ 计 算 机 学 报 ２０１８年
ｍ 无监督表示学习是指从未标注数据中学习数据
其中Ｖ＝∪Ｘ表示所有的数据对象组成的顶点集
ｉ
ｉ＝１ 新的特征表示．有关算法通常用来从高维输入数据
合，｜Ｖ｜的大小一般在数十万以上，Ｅ表示Ｖ中任意
中发现有意义的低维数据特征表示，实质上也就是
两个数据对象之间的链接构成的集合，Ｗ与上述定
一种降低维度算法．Ｏ′Ｓｈｅａ等人［２７］提出的无线电
义一样，代表一个赋权矩阵，表示数据对象之间链接
通讯信号的无监督表示学习就属于此类算法．类似
的权重，Ｃ表示所有数据对象的多媒体内容构成的
的代表性算法还包括无监督字典学习［２８］、独立成分
ｍ ｎｉ
集合，Ｃ＝∪Ｄ，Ｄ＝∪ｄ ，ｄ 则表示与顶点ｖ 相 分析［２９］、主成分分析和局部线性嵌入［３０］等．Ｂｅｎｇｉｏ
ｉ ｉ ｉｊ ｉｊ ｉｊ
ｉ＝１ ｊ＝１
关联的数据对象内容．不包含顶点内容的嵌入时Ｃ
等人［１］详细地综述了表示学习的评价准则和主要
为空集，Ｃ＝． 方法，但没有涉及大规模的网络数据的特征表示
若ｍ＝１时，Ｇ为一个同构网络，否则Ｇ为一个 学习．
异构网络．若不考虑数据对象上的多媒体内容Ｃ，则 ２．２．２ 网络表示学习
对网络的分析是基于网络结构形式．
网络表示学习又称为网络特征学习，定义为给
２．２ 表示学习和网络表示学习
定一个复杂信息网络Ｇ＝（Ｖ，Ｅ，Ｗ，Ｃ），Ｇ对应的顶
２．２．１ 表示学习
点特征矩阵Ｘ是一个高度稀疏的矩阵，其维数通常
基于数据的问题通常需要完成数据表示、目标 为｜Ｖ｜×ｍ（ｍ是顶点属性的特征空间大小），对每个
构建以及问题求解三个方面．而解决整个问题的关
顶点ｖ∈Ｖ，低维向量表示学习ｒ ｖ∈Ｒｋ，ｋ实质上远
键则是数据表示，它也决定了后续的计算空间和时 小于｜Ｖ｜，ｒ ｖ表示为一个稠密的实数向量表示．
间复杂度．尤其是随着非结构化数据、半结构化数据 在定义中，复杂信息网络Ｇ的链接关系不限定
以及多媒体数据的急剧增长，如何统一且高效地进 方向，即链接可以是有向链接也可以是无向链接．例
行数据表示就变得非常重要． 如Ｅｎｒｏｎ数据集包含了５０多万封电子邮件．如果
表示学习是机器学习领域中另外一个研究方向 把邮件地址作为顶点，若两封邮件之间有通信往来，
又称为特征学习，其主要任务是自动对原始数据集 则在这两个地址之间建立一条无向链接，这样构成
进行学习从而得到一个新的特征．将新的特征作为 的网络有３６ ６９２个顶点以及３６７ ６６２条链接；又如
不同机器学习算法的输入，免除了低效的人工提取 提供检索计算机方面的重要国际期刊和会议论文的
特征过程．表示学习已经广泛应用于语音识别与信 数据库ＤＢＬＰ，收录了各类刊物达到１４０万种．该检
号处理、多任务和迁移学习、对象识别和自然语言处 索库存在两种类型的网络：作者引用网络和论文引
理等方面．例如，文本表示学习通过对文本的共现情 文网络．作者引用网络记录了一位作者所写的论文
景进行学习，得到词语在低维空间（ｌｏｗ ｄｉｍｅｎｓｉｏｎ） 数以及被其他作者所引用的次数，两者之间就形成
上的向量表示［１４，２２－２３］，这种低维度的向量表示能够 了一条有向连接，同样在论文引用网络中，一篇论文
有效地显示出词语之间的语义关系［１４］，而且更易于 引用了另一篇论文，两者之间也形成了一条有向连
被应用到其它的系统中．由于数据集的不同，可以把 接．除了Ｇ的链接关系不考虑方向性之外，其包含
表示学习分为监督表示学习 （Ｓｕｐｅｒｖｉｓｅｄ Ｒｅｐｒｅｓｅｎ－ 的顶点类型也不做限制．如果Ｇ中的顶点代表的实
ｔａｔｉｏｎ Ｌｅａｒｎｉｎｇ）、无监督表示学习（Ｕｎｓｕｐｅｒｖｉｓｅｄ 体是单一类型，则Ｇ是一个同构网络．大部分已有
Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ Ｌｅａｒｎｉｎｇ）两类． 的网络表示学习模型是基于同构网络而建立的算
监督表示学习是指从已经标注的数据中学习数 法，如参考文献［２１，３１－３２］等．如果Ｇ中的顶点含
据的新特征表示．比如多层神经网络在处理分类或 有多种类型，则Ｇ是一个异构网络．以ＹｏｕＴｕｂｅ社
者回归任务时的隐含层就可以作为输入数据的新的 交网站为例，在该网络中，视频、标签和用户代表不
特征．Ｚｈｕａｎｇ等人［２４］提出的基于深度自编码的迁 同类型的顶点，顶点间又通过相同或不同类型的联
移学习就是一类典型的有监督表示学习．这种深度 系而关联．有关异构网络的表示学习模型研究开展
自编码由两个编码层组成：嵌入层和标签编码层．在 相对较少，已有的研究方法主要把异构网络映射到
嵌入层，源域和目标域之间的嵌入实例的分布采用 同构网络上，采用同构网络上的学习模型来加以实
最小化ＫＬ（Ｋｕｌｌｂａｃｋ－Ｌｅｉｂｌｅｒ）散度．在标签编码层， 现，如参考文献［３３－３５］等，这些方法没有充分利用
源域的标签信息使用ｓｏｆｔｍａｘ回归模型编码．类似 不同的顶点标签或特性之间的相关性，且假定任务
的监督表示学习算法有文献［２５－２６］等． 的本质在现实世界场景中的结果也并不理想．如果 １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２３９９
仅仅获取网络中的结构信息，顶点本身没有提供其 的各种离散属性关系能够清楚地呈现在连续的向量
它内容信息，那么复杂信息网络中的特征矩阵Ｘ只 空间中．
是一个空矩阵，否则Ｘ是非空矩阵． 一个较好的网络表示学习方法应具有以下的
近年来，研究人员广泛地开展了在复杂信息网 特点：
络方面的研究应用，如顶点分类［３６］、标签推荐［３７］、异 ①适应性：真实的复杂信息网络在不断演化，
常检测［３８］以及链接预测［３９］等．这些应用所面临的共 新的网络关系不应要求一遍又一遍重复学习同样的
同问题就是复杂信息网络的数据稀疏性．为了解决 过程．
这一问题，网络表示学习用统一的低维向量空间对 ②社区意识：潜在特征维度之间的距离可以用
每个顶点进行编码和表示，这有助于更好地理解顶 于网络中对应成员之间的社会相似性的度量，这允
点之间的语义关联，并进一步减轻因为数据稀疏性 许在具有同质网络中的泛化作用．
造成的不便［３１］．Ｌｉ等人［４０］进一步阐述了网络表示 ③低维：当标签数据稀缺时，低维模型可以更
学习的主要任务是对复杂信息网络的内容或结构进 好地推广并加速收敛和推断．
行表示．用低维度的连续特征表示原有的高维度离 ④连续：需要潜在表示学习来建模连续空间中
散特征，从而有效地解决网络中存在的稀疏性难题， 的部分社区成员．除了提供社区成员的一种不同视
还可得到网络的不同表示形式，作为其它应用的输 角之外，连续的表示学习在社区之间具有平滑的决
入从而进行下一步的分析，如对原始网络构建拓展 策边界，这使得分类更具鲁棒性．
的研究模型． 在网络中各个相互连结的顶点之间常常存在依
图１展示了使用网络表示学习方法获得原始网 赖关系．以网页分类任务为例，通常把一个网页作为
络Ｋａｒａｔｅ中的社区结构和嵌入向量空间Ｒ２中社区 一个文档，然后对文档进行文本主题提取进而对网
结构之间的对应关系．其中图１（ａ）代表Ｋａｒａｔｅ在模 页进行分类，在这个过程中往往忽视了网页之间的
块度最大化时社区划分结构（通过顶点颜色表示）， 重要链接关系．现实世界的网络存在同质性，网络中
图１（ｂ）显示该原始网络映射到二维向量空间中各 相似的结点可能具有一定的联系，这说明有可能通
顶点的分布，它可以容易地利用机器学习算法进行
过网络中的链接信息获得更好的网络特征表示．在
聚类．以上这种对应关系使得原来网络拓扑结构中 本文中，不加区分的话通常说的网络表示学习是指
用顶点的特征表示来替代网络特征表示．Ｃｈｅｎ等
人［４１］给出了网络表示学习用顶点的特征表示来表
达的优势在于：首先，将表示学习得到的顶点作为机
器学习算法的输入特征，避免因网络数据变化而改
变相应的机器学习方法；其次，直接对网络数据进行
分析相当困难，因为对于数据分析很重要的一些概
念如距离、内积等在网络中很难定义．使用特征表示
网络中的顶点，能够在相应的特征空间中使用各种
计算；最后，大规模网络数据中各顶点之间的链接关
系十分复杂，通过在低维特征空间中进行可视化分
析，能够直观地观察到各顶点之间的关系．
３ 大规模复杂信息网络表示学习
大规模复杂信息网络表示学习能够有效缓解复
杂信息网络的数据稀疏性，实现复杂信息网络异质
信息融合以及显著提升相关拓展应用的高效计算，
因而在理论研究以及具体应用上都具有非常重要的
意义．目前，大规模复杂信息网络表示学习的研究工
图１ 网络表示学习示例图 作主要分为以下几类：包括基于概率的网络内容表 ２４００ 计 算 机 学 报 ２０１８年
示学习、经典的网络表示学习，以及最近提出的大规 距离代替传统的欧式距离，提出了一种用实际输入
模网络结构的表示学习、结构－内容融合的表示学习 数据估计其测地线距离的算法．Ｂｅｌｋｉｎ等人［１０］根据
和异构网络的表示学习．下面详细介绍这些方法． 网络中邻接的顶点在降维后的空间中距离接近，提
３．１ 经典网络表示学习 出了拉普拉斯特征映射（Ｌａｐｌａｃｉａｎ Ｅｉｇｅｎｍａｐｓ）算
本文把图嵌入学习算法应用在复杂信息网络上 法．例如，网络中两个顶点ｉ和ｊ如果很相似，那么
进行的特征学习的这一类算法统称为经典的网络表 ｉ和ｊ在降维后的空间中会非常靠近．Ｌａｐｌａｃｉａｎ
示学习方法．这些方法首先将网络转换成矩阵表示， Ｅｉｇｅｎｍａｐｓ能够反映出数据内在的流形结构，通过
然后通过求解矩阵特征向量的形式，进行降维以获 构建邻接矩阵作为输入，来重构数据流形的局部结
取网络的低维表达．在本文中把经典网络表示学习 构特征，最终选取Ｌａｐｌａｃｉａｎ矩阵的最小的ｔ个非零
分为基于谱方法的网络表示学习和基于最优化的网 特征值对应的特征向量来表示学习到的网络．为了解
络表示学习两类． 决局部模型的数量而不是原始数据点数量比例的问
３．１．１ 基于谱方法的网络表示学习 题，Ｔｅｈ等人［４５］提出了局部线性协调ＬＬＣ（Ｌｏｃａｌｌｙ
基于谱方法的网络表示学习是一种直接从矩阵 Ｌｉｎｅａｒ Ｃｏｏｒｄｉｎａｔｉｏｎ）算法，通过几个局部降维专家
特征值等角度出发进行网络特征学习的一类算法． 学习使得不同的内部表示映射到用于原始数据空间
谱方法可用于获取数据的低维表达［４２］，它们广泛应 的单个且一致的全局坐标系统中．该算法可以应用
用于工程、应用数学、统计学和计算机科学等领域， 于任何专家组，同时，每个专家组会产生高维输入的
以处理“离散”以及“连续”问题．针对网络表示学习， 低维局部表示．与需要修改目标函数的模型不一样，
数据矩阵有可能以显式矩阵（例如邻接矩阵）或隐式 ＬＬＣ算法使用一种有效的特征分解器对训练后的
矩阵（例如文档－词矩阵、超链接结构、对象特征表 模型进行后处理．这也使得它比无模型算法（例如
示、网络路径等）作为其输入．代表性的谱算法有主 Ｉｓｏｍａｐ或ＬＬＥ）更有效．
成分分析ＰＣＡ（Ｐｒｉｎｃｉｐａｌ Ｃｏｍｐｏｎｅｎｔｓ Ａｎａｌｙｓｉｓ）算 为了使得输入图的嵌入是低维表示并且保留图
法［４３］和奇异值分解ＳＶＤ（Ｓｉｎｇｕｌａｒ Ｖａｌｕｅ Ｄｅｃｏｍｐｏ－ 全局拓扑属性，Ｓｈａｗ等人［４６］提出在欧式空间中嵌
ｓｉｔｉｏｎ）算法［７］． 入图的结构保留嵌入方法（Ｓｔｒｕｃｔｕｒｅ Ｐｒｅｓｅｒｖｉｎｇ
如果一个矩阵的行被视为高维空间中的点，其 Ｅｍｂｅｄｄｉｎｇ，ＳＰＥ）．ＳＰＥ被归结为一个半定规划问
中列表示坐标，则ＰＣＡ／ＳＶＤ通常用于减少这些点 题，其学习由一组线性不等式约束的低秩核矩阵，用
的维度，并且解决低维空间中的目标问题．这种映射 于捕获输入图的链接结构．传统的图嵌入算法不能
的计算优势很明显．此外，ＰＣＡ／ＳＶＤ算法通常还 依据作者提出的要求保留图结构，因此产生的可视
能够突出显示数据中的隐含结构．虽然可以把网络 化可能会产生误导或信息不足．ＳＰＥ在图的可视化
转化为邻接矩阵，作为ＰＣＡ／ＳＶＤ的输入以获得顶 和无损压缩方面获得明显改善，优于拉普拉斯特征
点的低维表示，但通常这种表示的质量较差［４４］．本 映射等方法．ＳＰＥ可以仅使用几个维度对图或网络
文除了介绍以上谱算法之外，对其它几个流行的谱 进行合理嵌入，并且将结构保留约束引入降维算法
算法也进行分析讨论． 从而产生高维数据的更准确的学习表示．
与局部降维的聚类方法不同，Ｒｏｗｅｉｓ等人［８］ 然而，ＳＰＥ方法虽然能够保留网络在低维嵌入
提出一种无监督学习的局部线性嵌入算法 ＬＬＥ 时的相邻结构，但是ＳＰＥ算法的复杂度较高，并且
（Ｌｏｃａｌｌｙ Ｌｉｎｅａｒ Ｅｍｂｅｄｄｉｎｇ）．ＬＬＥ将其输入映射到 它被归结为一个半定规划问题，导致对于大规模网
具有较低维度的单个全局坐标系统，并且优化不涉 络的计算代价非常大．因此，Ｔａｌｗａｌｋａｒ等人［４７］研究
及局部最小值问题．通过利用线性重建的局部对称 了基于采样的低秩近似技术，以此解决应用于大密
性，ＬＬＥ能够学习非线性流形的全局结构．ＬＬＥ算 度核矩阵时的效率问题．作者分析了两种常见的近
法以网络的邻接矩阵作为初始数据输入，计算得到 似奇异值分解技术即 Ｎｙｓｔｒｏｍ和Ｃｏｌｕｍｎ采样方
各个顶点的局部重建权值矩阵后，将问题最后归结 法．首先在理论上先对这两种方法进行比较，然后提
为矩阵特征值求解，从而获取顶点的低维向量表示． 供了这些方法对于不同任务适用性的见解，并同时
与此类似，Ｔｅｎｅｎｂａｕｍ等人［９］通过分析高维流 在相关的数据集上进行了一定的对比实验．
形，找到与之对应的低维嵌入，提出了Ｉｓｏｍａｐ算 ３．１．２ 基于最优化的网络表示学习
法．在计算高维流形上顶点之间距离时，使用测地线 这类表示学习算法是指事先设定一个优化目标 １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２４０１
函数，其参数设置为顶点在低维空间的向量形式，对 应的特征向量，Λ代表ｌ个特征值所组成的对角矩
目标函数进行最大化或最小化优化处理，最终得出 阵，即表示为Λ＝ｄｉａｇ（λ，λ，…，λ），则Ｓ的最优值
１ ２ ｌ
网络中的顶点在低维空间的向量表示．例如，Ｃｈｅｎ 为Ｓ＝ＶΛ１／２．最终 ＭＤＳ算法学习到一个矩阵的特
等人［４１］提出了有向图嵌入 ＤＧＥ（Ｄｉｒｅｃｔｅｄ Ｇｒａｐｈ 征向量作为网络的特征表示，进一步采用传统的挖
Ｅｍｂｅｄｄｉｎｇ）算法，其主要利用了转移概率与马尔可 掘算法实施社区的划分．本质上这种方法是从社区
夫随机游走的思想．有向图嵌入算法定义了优化目 发现的角度来表达网络表示学习．
标函数如下： 具体化到特定类型的网络环境，以社会网络为
∑Ｔ （ｉ）∑Ｔ （ｉ，ｊ）（ｙ－ｙ）２ （１） 例，Ｔａｎｇ等人［４９］提出了潜在社会维度的关系学习
Ｖ Ｅ ｉ ｊ
ｉ ｊ，ｉ→ｊ 模型（见图３所示）．该模型首先基于网络信息提取
其中ｙ是嵌入在一维空间中顶点ｉ的坐标，Ｔ （ｉ，ｊ）
ｉ Ｅ 潜在的社会维度，然后利用它们作为判别式学习的
代表两个顶点ｉ和ｊ之间的有向边的重要性，Ｔ （ｉ）则
Ｖ
特征．这些社会维度描述了隐藏在网络中的社会行
用于衡量顶点在图中的重要性．
为者的不同隶属关系，并且随后的判别式学习可以
对目标函数最小化以此获得图在一维空间上的
自动确定哪些关联更好地与类别标签对应．当多个
优化嵌入．嵌入过程中考虑了顶点对的局部关系和
不同的关系与同一网络相关联时，这是一种优选方
顶点的全局相对重要性．如果ＤＧＥ算法应用于无
案．不同社区的权重大小由学习到的网络特征向量
向网络，则该算法等价于 Ｌａｐｌａｃｉａｎ Ｅｉｇｅｎｍａｐｓ算
的不同维度来刻画．模型中的目标函数是期望最大
法．图２给出了ＤＧＥ算法把数据集 ＷｅｂＫＢ降维映
化模块度［５０］，选取模块度矩阵的ｔ个最大的特征向
射到二维空间的效果图，３种不同颜色的顶点由德
量作为网络特征表示［５１］．
克萨斯等大学的２８８３个网页组成．
图３ 潜在社会维度的关系学习模型
在动态与静态关系建模方面，Ｓａｒｋａｒ等人［５２］探
讨了社会网络建模的两个问题，首先提出将一个静
态关系模型推广为一个动态模型，考虑了随着时间
的推移而变化的因素；其次展示了在网络中的顶点
图２ ＷｅｂＫＢ数据降维效果图
数目较多时如何使该动态模型易于从数据中进行表
此外，Ｂｏｒｇ等人［４８］提出的多维量表算法 ＭＤＳ
示学习．该动态模型将每个顶点与ｋ维欧氏潜在空
（Ｍｕｌｔｉ－ｄｉｍｅｎｓｉｏｎａｌ Ｓｃａｌｉｎｇ）将网络的顶点映射到一
间中的数据点相关联．欧氏空间中数据点可以随着
个低维的欧式空间，使得在新空间中可以保持网络顶
时间的推移而移动，但移动的范围有限．如果顶点在
点的相似性．而这个相似性可基于网络连通性计算得
潜在空间中接近，则顶点之间更有可能存在链接．文
到［１１］．在网络表示学习过程中，ＭＤＳ算法的输入数
中通过对潜在空间中的相似度使用合适的核函数、
据为一个距离矩阵Ｐ∈Rｎ×ｎ，其中元素ｐ 代表网络
ｉｊ
低维ｋｄ树以及非线性局部优化的有效共轭梯度更
中顶点ｉ和ｊ之间的距离．用Ｓ∈Rｎ×ｌ表示顶点在ｌ
新规则等来展示如何使模型更易于处理．
维空间的坐标且Ｓ的列是正交的，有如下公式：
基于最优化的网络表示学习在特定的网络分析
ＳＳＴ ≈－１ ２（ Ｉ－ ｎ１ １１Ｔ）（ＰＰ）（ Ｉ－ ｎ１ １１Ｔ） ＝Ｐ珟
任务里也有表达，如在网络信息传播预测中依据用
（２） 户的行为模式来探索信息传播的机制．其实质就是
在式（２）中Ｉ表示单位矩阵，１代表每个元素都 建立一个由用户组成的网络，通过在该网络上建立
是１的一个ｎ维列向量，而表示矩阵按元素进行相 传播模型模拟信息扩散的动态过程．Ｙａｎｇ等人［５３］
乘．Ｓ可通过 ｍｉｎ‖ＳＳＴ－Ｐ珟 ‖２获得，使得Ｐ珟与ＳＳＴ 指出社交媒体是生产和传播实时信息的中心领域，
Ｆ
的差最小．假设Ｖ包含Ｐ珟中的ｌ个最大特征值所对 即使这种信息流传统上被认为是社交网络上的传播 ２４０２ 计 算 机 学 报 ２０１８年
过程，但是基本现象是众多参与者之间的复杂的互 量顶点带来的计算维数灾难问题）．这种低维度的向
动网络的结果．同时作者还提出了一种线性影响模 量表示对大规模（如顶点数以亿计算）的网络中进行
型，这种模型通过预测哪个顶点将影响网络中的其 相关的操作，如聚类、分类、顶点相似性匹配等等都
他顶点来建立传播过程．他们建模一个顶点对于通 具有良好的效率及适应性．同时，在动态性方面，通
过网络的传播速率的全局影响，并且模拟了新感染 过针对性的在顶点特征的学习过程中设计相关的增
顶点的数量作为过去已感染的其他顶点的函数．对 量式局部搜索算法，如ＤＮＰＳ模型［４０］，可以较好地
于每个顶点，估计一个影响函数，用于量化随着时间 解决网络动态增长所带来的重复性特征学习及其衍
的推移有多少被感染的顶点可能受到该顶点的影 生的计算效率较低等问题．
响．线性影响模型准确地模拟了顶点在传播过程中 近些年来，深度学习技术在图像识别、语音处理以
的影响，可靠地预测信息传播的时序动态性，发现各 及自然语言处理等多个领域取得了巨大的成功［５５］，如
个参与者的影响模式根据顶点的类型和信息的主题 在自然语言处理领域里基于神经网络的语义空间模
差异十分显著． 型的文本分布式特征表达的相关模型得到了广泛的
考虑到社交媒体上信息的时序传播主要被视为 研究并取得了很大的进展［５６－５７］，这些模型通过将文
对已知图或近似结构的传播过程，Ｂｏｕｒｉｇａｕｌｔ等 本中词语的语法或者语义特征映射到一个固定维度
人［５４］提出了一个新的解决方案，其目标是学习观察 的连续向量空间中以解决原来方法所存在的词语矩
到的时间动态到连续空间上的映射．参与传播级联 阵所带来的稀疏性问题以及维数灾难性问题［５８］．
的顶点被投影在潜在表示空间中，使得可以使用热 本质上，深度学习技术是一种特征学习方法．不
扩散过程来有效地对信息传播进行建模．这相当于 同于特征工程需要人为地抽取特征，深度学习可以
学习扩散核，其中投影空间中的顶点的邻近度反应 主动学习数据的特征表示．深度学习通过融合低层
了它们在级联中的感染时间的邻近度．与现有方法 特征来实现数据的分布式特征表示．受到深度学习
相比，所提出的方法具有以下独特的特征：其参数直 技术广泛应用于不同领域的启发，针对大规模网络
接从级联样本学习而不需要任何附加信息，因此其 结构特征的表示学习算法相继被提出．其中最具代
不依赖于任何预先存在的传播结构；传播方程的解 表性的网络结构表示学习模型为ＤｅｅｐＷａｌｋ［３１］，该
在投影空间中以封闭形式表示，所以与离散模型相 模型借鉴了神经网络语言模型 Ｗｏｒｄ２Ｖｅｃ［５９］的思
比，用于预测新信息的传播的推理时间大大减少． 想，将文本中词语间的关系转换为复杂信息网络中
以上经典网络表示学习模型往往通过网络的邻 顶点之间的关系．
接矩阵或关联矩阵采用降维分析的学习方法．通常 本文介绍有关复杂信息网络结构表示学习模型
这类学习只适合应用在较小规模静态网络上．在缺 之前，先简要回顾神经网络语言模型的发展过程．
乏网络顶点内在的信息且顶点数量较多的情况下， Ｈｉｎｔｏｎ等人［６０］最早提出了学习分布式表示思想，
经典网络表示学习模型效果不尽理想，并且其复杂 然而利用神经网络语言模型学习词汇的向量表示则
度通常是网络顶点数量的二次方，使得不能有效地 由Ｂｅｎｇｉｏ等人［６１］提出．他们在文中设计了一个多
处理大规模复杂信息网络［２１］． 层神经网络语言模型（Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ Ｌａｎｇｕａｇｅ
为了解决当前大规模复杂信息网络所带来的新 Ｍｏｄｅｌ，ＮＮＬＭ），通过一个可以在文本语料中滑动
特征，包括巨量性、动态性、丰富媒体性等．近年来学 的长度为ｎ的窗口，用前ｎ－１词预测窗口内的当前
者基于深度学习或相关领域的研究启发，提出了一 词的概率．ＮＮＬＭ模型由输入层、投影层、隐含层和
系列的基于网络结构、网络顶点内容属性或两者之 输出层组成，其中输入层为滑动窗口内前ｎ－１个词
间的融合方法，为当前大规模复杂信息网络的特征 的向量表示，把这些向量拼接起来则发生在投影层，
抽取提供了一系列的解决方案． 隐含层则将投影层的输出结果进行非线性变换，最
３．２ 大规模网络结构的表示学习 后每个词在下个位置的出现概率则由输出层显示．
大规模网络结构表示学习方法通过仅考虑网络 求解该模型的方法则使用随机梯度下降和反向传播
顶点之间的链接关系来进行特征抽取，即基于Ｇ＝ 算法．由于输出层ｓｏｆｔｍａｘ函数的计算复杂度和词
（Ｖ，Ｅ，Ｗ）形式，其学习的目的在于从网络数据中学 汇表大小同阶，因此这种前馈神经网络语言模型的
习得到任一个顶点的低维向量表示，用于克服经典 复杂度较高．
网络表示学习无法适应大规模网络的问题（例如，大 在后续的研究中，有相关文献替换或优化处理 １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２４０３
ＮＮＬＭ模型中的Ｓｏｆｔｍａｘ函数，如 Ｍｏｒｉｎ等人［６２］
提出了层次ｓｏｆｔｍａｘ函数，将模型的输出层表示为
一棵哈夫曼树；Ｃｏｌｌｏｂｅｒｔ等人［６３］则直接用ｈｉｎｇｅ
ｌｏｓｓ函数替换原来的函数；Ｇｕｔｍａｎｎ等人［６４］提出
了一种用于降低 ＮＮＬＭ 的时间复杂度的算法．
Ｍｉｋｏｌｏｖ等人提出的词向量训练模型 Ｗｏｒｄ２Ｖｅｃ，由
于去掉了前馈神经网络中的中间层，从而极大地提
升了训练效果．该模型实质上由两个子模型组成：
ＣＢＯＷ和Ｓｋｉｐ－Ｇｒａｍ模型，前者是利用窗口的上下
文来预测中心词，而后者刚好相反，是用窗口的中心
词来预测这个词的上下文．Ｗｏｒｄ２Ｖｅｃ模型可用于
大规模的文本连续性表达学习，在很多应用上取得
了较好的结果．
根据模型学习方式的不同，本文把大规模复杂 图４ ＤｅｅｐＷａｌｋ模型框架
信息网络结构的表示学习模型分为高阶关系建模学 针对 ＤｅｅｐＷａｌｋ模型仅适用于未加权网络，
习、半监督表示学习，以及具有可伸缩性的特性表示 在此之后，Ｔａｎｇ等人［２１］提出了一种适用于不同类
学习． 型网络（例如，无向图、有向图或带权图）的表示学
３．２．１ 基于高阶关系的表示学习 习模型ＬＩＮＥ（Ｌａｒｇｅ－ｓｃａｌｅ Ｉｎｆｏｒｍａｔｉｏｎ Ｎｅｔｗｏｒｋ
高阶关系建模学习是把网络顶点关系的相似性 Ｅｍｂｅｄｄｉｎｇ）．该模型从一阶相似性和二阶相似性两
从一阶拓展到高阶．对各阶关系采用不一样的目标 个方面设置不同的目标函数．一阶相似性定义成网
函数，然后将各阶关系获取的分布式表示进行拼接， 络中两个顶点之间的点对相似性，其值为顶点之间
进而获得顶点特征学习．具有代表性的高阶关系建模 链接的权值（如果点对之间不存在链接，一阶相似性
学习模型包括ＤｅｅｐＷａｌｋ、ＬＩＮＥ、ＧｒａＲｅｐ等模型． 值则为０）．为了对一阶相似性建模，对于每条无向
Ｗｏｒｄ２Ｖｅｃ在训练词向量时，以文本语料作为 链接（ｉ，ｊ），顶点ｉ和ｊ之间的联合概率如下：
输入数据．而网络表示学习则以复杂信息网络作为 ｐ １（ｉ，ｊ）＝１／（１＋ｅｘｐ（－ｉ Ｔ·ｊ）） （３）
数据输入，两者看上去没有任何关联．然而 Ｄｅｅｐ－ 式中ｉ∈Rｄ，ｊ∈Rｄ分别是顶点ｉ和顶点ｊ的低维向
Ｗａｌｋ模型的作者注意到，在训练过程中词语出现的 量表示，顶点ｉ和ｊ的经验联合概率为＾ ｐ （ｉ，ｊ）＝
１
频次与根据原始网络结构进行随机游走时顶点被访 ｗ／Ω，Ω＝ ∑ｗ ，其中ｗ 为链接（ｉ，ｊ）的权值．
ｉｊ ｉｊ ｉｊ
问到的次数两者皆服从幂律分布．因此该文作者将 （ｉ，ｊ）∈Ｅ
网络表示最后通过最小化概率分布ｐ（·，·）与＾
ｐ
１ １
网络中的顶点看作是文本语料中的词汇，把进行随
（·，·）的ＫＬ距离来获得．二阶相似性适用各种类
机游走时获得的游走路径当成语料中的句子，通过
型的网络，其假设如果顶点间共享相似的邻居顶点，
这种方式获得的网络数据就可以作为 Ｗｏｒｄ２Ｖｅｃ的
那么两者就趋于相似．顶点之间的二阶相似性表示
数据输入来达到训练顶点的分布式表达．
为两个顶点在整个网络上的一阶相似性的分布相似
ＤｅｅｐＷａｌｋ模型的框架示意图如图４所示，其
度．在这种情形下，每个顶点ｉ扮演两个角色：顶点
中图４（ａ）显示采用随机游走的方法产生标准的输
本身和其他顶点的特定“上下文”，分别用向量ｉ和
入序列．图４（ｂ）表示使用ＳｋｉｐＧｒａｍ模型对序列建
ｉ′表示这两个角色．二阶相似性模型则定义顶点ｉ和
模得到网络顶点的向量表示，其中W 代表以顶点ｉ
ｉ ｊ的条件概率如下：
为根的随机游走序列，函数Φ把每个顶点映射到一
｜Ｖ｜
个指定的空间向量．而图４（ｃ）代表分层ｓｏｆｔｍａｘ函 ｐ ２（ｊ｜ｉ）＝ｅｘｐ（ｊ′Ｔ·ｉ）∑ｅｘｐ（ｋ′Ｔ·ｉ） （４）
ｋ＝１
数，用于解决顶点高维度输出问题．相比较基准方 顶点ｉ和ｊ的经验条件概率＾ ｐ （ｊ｜ｉ）＝ｗ／ｄ，ｄ表
２ ｉｊ ｉ ｉ
法，ＤｅｅｐＷａｌｋ模型克服了网络训练数据稀疏性这
示顶点ｉ的出度．二阶相似性模型的网络表示则由
一问题，在训练数据较少的情况下也能取得比使用 最小化概率分布ｐ（·，·）与＾ ｐ（·，·）的ＫＬ距离来
１ １
全部数据较好的训练效果．ＤｅｅｐＷａｌｋ模型的提出为 获得．基于这两类相似性，ＬＩＮＥ可以分别学习到一
网络结构特征的向量表示提出了一种新的研究思路． 阶顶点向量和二阶顶点向量，对两种顶点向量进行 ２４０４ 计 算 机 学 报 ２０１８年
拼接，从而获得最终的顶点表示．同时，在训练过程 ｏｆ Ｓｏｃｉａｌ Ｎｅｔｗｏｒｋ Ｅｍｂｅｄｄｉｎｇ）．ＤＮＰＳ模型通过对
中ＬＩＮＥ对于相似性的表示均采用了基于链接的负 不同阶顶点关系构建基于有正负阻尼的顶点共现学
采样优化算法． 习．引入这种学习策略能够有效地把深度特征、广度
相比于ＬＩＮＥ模型中，基于局部的一阶相似性 特征和社区特征等不同顶点特征环境进行统一表示
和二阶相似性的特征提取，Ｃａｏ等人［３２］提出的 学习．同时，在采样模式中使用局部搜索的增量式算
ＧｒａＲｅｐ（Ｇｒａｐｈ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ）模型在ＬＩＮＥ基础 法来更好地适应网络的动态性．由于ＤＮＰＳ模型融
上进行了更高阶相似性关系的建模，以获取网络顶 合了顶点结构特征学习以及复杂信息网络自身特
点的全局特征表示．该模型首先定义一阶概率转移 性，因此它是一个具有动态以及大规模适应性的网
矩阵Ａ＝Ｄ－１Ｓ ，式中矩阵元素ａ 的值是顶点ｉ到ｊ 络表示学习模型．ＤＮＰＳ模型可以看成一种动态逻
ｉｊ
的一阶转移概率，Ｄ为度对角矩阵，Ｓ为邻接矩阵． 辑回归模型，其目标函数的优化采用快速的随机梯
为了学习到顶点对之间关系的全局表示，需要利用 度上升的方法．在大规模的网络数据上体现出
已知的一阶概率转移矩阵来计算ｋ阶概率转移矩 ＤＮＰＳ模型不仅在具有动态变化过程中的结构特征
阵，即通过计算Ａｋ＝Ａ…Ａ获得． 的提取变得可行，而且由此获得的顶点特征表达具
同样的，受到ＳｋｉｐＧｒａｍ 模型的启发，ＧｒａＲｅｐ 备更好的动态鲁棒性．与ＤＮＰＳ模型进行动态顶点
模型采用 Ｇｕｔｍａｎｎ等人［６５］提出的噪声对比估计 的特征学习相似，Ｈａｍｉｌｔｏｎ等人［６７］提出了一种
（Ｎｏｉｓｅ Ｃｏｎｔｒａｓｔｉｖｅ Ｅｓｔｉｍａｔｉｏｎ，ＮＣＥ）方法来定义 ＧｒａｐｈＳＡＧＥ模型，该模型能够基于顶点的属性特
目标函数．优化目标在于最大化（ｉ，ｃ）的出现概率并 征，如文本特征等，对顶点在当前时刻Ｔ下所存在
最小化随机生成的（ｉ，ｃ′）的出现概率，这里的ｉ为当 的未知数据（ｕｎｓｅｅｎ ｄａｔａ）顶点进行特征学习．该方
前顶点，ｃ是ｉ的上下文顶点，ｃ′是随机得到的上下 法同样基于局部的特征采样来对当前顶点的特征进
文顶点．同样使用负采样的方法建模ｋ阶信息，并使 行聚合．
用ＳＶＤ矩阵分解的方法得到网络顶点的向量表示． 相比于局部特征，通过基于社区属性这一重要
ＧｒａＲｅｐ模型考虑了更高阶的上下文信息，在网络结 的全局模式出发，不同于现有的网络表示学习方法
构数据的表示学习中起到了很好的效果．虽然在模 主要考虑从顶点的局部上下文进行学习表示Ｔｕ等
型中使用了复杂度较高的ＳＶＤ矩阵分解的方法，但 人［６８］提出了一种新的社区增强型网络表示学习模
实际中可以使用随机梯度下降的优化方法，因而对 型 ＣＮＲＬ（Ｃｏｍｍｕｎｉｔｙ－ｅｎｈａｎｃｅｄ Ｎｅｔｗｏｒｋ Ｒｅｐｒｅ－
于大规模的网络结构表示学习该模型同样适用． ｓｅｎｔａｔｉｏｎ Ｌｅａｒｎｉｎｇ）．ＣＮＲＬ模型通过引入顶点的社
与借鉴 Ｗｏｒｄ２Ｖｅｃ的学习模式相对比的是， 区信息，学习更具有判别性的网络表示．ＣＮＲＬ对每
Ｎｉｅｐｅｒｔ等人［６６］提出了对任意的网络结构通过卷积 阶顶点关系分别建模，最终发现每个顶点的社区分
神经网络（ＣＮＮ）进行特征抽取的学习框架．与已有 布，同时还学习到顶点以及社区的嵌入．ＣＮＲＬ模型
方法相同的是该模型同样既可以针对有向网络，也 克服了有些网络表示学习方法仅考虑顶点局部信息
可以学习无向网络．作者基于传统图像（图片）特征 的缺陷，并且将所学习的表示应用于网络分析任务
抽取中关于局部关联区域抽取方法的启发，在网络 时，与ＬＩＮＥ模型等相比较有着明显的改进．
中也采用局部关联的方式进行相关操作．该方法与 ３．２．２ 基于半监督的表示学习
传统的基于ｇｒａｐｈ ｋｅｒｎｅｌ的模型相比，具有较好的 半监督表示学习首先对网络的顶点特征学习采
性能．然而，作者在对比方法的选取上却忽视了当前 用无监督方式，学习顶点数据完整的“语义”信息，使
具有较好计算性能的前沿方法，例如ＤｅｅｐＷａｌｋ以 其在后续的监督学习过程中很好的适应训练数据．
及ＬＩＮＥ等方法，这也使得该方法的计算性能在大 这类表示学习在分类预测任务上效果显著．
规模网络环境下的可行性需要进一步的验证并给出 针对网络表示学习应用于机器学习任务如顶点
判定． 分类时通常所缺乏的辨别能力，Ｔｕ等人［６９］提出了
针对ＤｅｅｐＷａｌｋ、ＬＩＮＥ以及ＧｒａＲｅｐ等网络表 一种新 颖 的半监督 模 型 ＭＭＤＷ（Ｍａｘ－Ｍａｒｇｉｎ
示学习的方法多基于静态网络或并没有对复杂信息 ＤｅｅｐＷａｌｋ）．ＭＭＤＷ 是基于矩阵分解的统一网络
网络的特有属性进行修正学习模式，Ｌｉ等人［４０］提出 表示学习框架，通过优化最大间隔分类器以及目标
了基于动态阻尼正负采样的网络结构特征嵌入模型 矩阵因式分解模型来实现．受最大间隔分类器的影
ＤＮＰＳ（Ｄａｍｐｉｎｇ ｂａｓｅｄ Ｎｅｇａｔｉｖｅ－Ｐｏｓｉｔｉｖｅ Ｓａｍｐｌｉｎｇ 响，学习表示不仅包含网络结构，而且具有辨别分类 １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２４０５
的特征．ＭＭＤＷ的学习过程是：首先把原始Ｄｅｅｐ－ Ｎｅｔｗｏｒｋ Ｅｍｂｅｄｄｉｎｇ Ｍｅｔｈｏｄ）．他们首先提出一种
Ｗａｌｋ模型转换为矩阵因素分解形式Ｍ＝ＸＴＹ，为了 半监督深度模型，该模型由多层非线性函数组成，用
得到矩阵Ｘ∈Rｋ×｜Ｖ｜和矩阵Ｙ∈Rｋ×｜Ｖ｜，将式（５） 于捕获高度非线性网络结构．然后利用顶点之间的
ｍｉｎＬ ＝ｍｉｎ‖Ｍ－（ＸＴＹ）‖２ ＋ 一阶相似性和二阶相似性共同保留网络结构，二阶
ＤＷ ２
Ｘ，Ｙ Ｘ，Ｙ
相似性由无监督组件应用来捕获全局网络结构，而
λ （‖Ｘ‖２ ＋‖Ｙ‖２） （５）
２ ２ ２ 一阶相似性被用于监督组件中作为监督信息以保留
最小化，式中因子λ控制正则化这部分的权重．然后 局部网络结构．通过在半监督深度模型中联合优化
训练基于最大间隔分类器并扩大支持向量和分类边 一阶相似性和二阶相似性，ＳＤＮＥ能够将数据映射
界之间的距离．ＭＭＤＷ 模型学习到的顶点表示不 到高度非线性的潜在空间以保留局部和全局网络结
仅能够反映其网络结构，而且还能反映顶点的标签 构并且对于稀疏网络具有鲁棒性．在大规模真实网
信息． 络上实证了ＳＤＮＥ对于多标签分类、链接预测以及
考虑到ＤｅｅｐＷａｌｋ模型中序列的生成方式包括 可视化等应用上效果明显．
宽度优先搜索（ＢＦＳ）和深度优先搜索（ＤＦＳ）的采样 ３．２．３ 基于可伸缩的表示学习
方式所学习到网络结构特征的差异性，Ｇｒｏｖｅｒ等 具有可伸缩性（ｓｃａｌａｂｉｌｉｔｙ）的表示学习是指在
人［７０］提出了用于表示学习网络中顶点连续特征的 网络中以不同层级采样方式对成对顶点进行操作的
半监督模型 Ｎｏｄｅ２Ｖｅｃ模型．该模型学习顶点到低 在线学习方法．这类方法类似于使用采样的高阶过
维特征空间的映射，从而最大化保留顶点的网络邻 渡矩阵，从而使得可扩展到具有数百万个顶点及以
域的可能性．Ｇｒｏｖｅｒ等人发现，ＢＦＳ生成的顶点序 上的大规模网络．
列多集中于网络中的某个局部结构内，生成的序列 为了对多尺度网络进行特征表示学习，Ｄｅｅｐ－
稳定，学到的顶点表达倾向于表示顶点的直接邻居 Ｗａｌｋ模型的提出者Ｐｅｒｏｚｚｉ等人［７２］提出了一种用
结构；而ＤＦＳ能较好地遍历整个网络，学到的顶点 于学习网络中顶点的多尺度表示学习的方法
表达可以反应顶点与其周围顶点的结构关系，但生 Ｗａｌｋｌｅｔｓ．这种方法可以清晰地在连续向量空间中
成的序列不够稳定．作者通过定义一个关于顶点的 对多尺度顶点关系进行编码，以适用于多标签分类
网络邻域的概念并设计一个有偏差的随机游走程 问题．与以往的研究不同的是，由 Ｗａｌｋｌｅｔｓ生成的
序，有效地探索顶点的不同的邻域． 潜在特征是可解析导出．
此外，Ｎｏｄｅ２Ｖｅｃ模型引入ｓｅａｒｃｈ ｂｉａｓ函数，用 Ｗａｌｋｌｅｔｓ通过使用在随机游走过程中观测到
以调整、平衡这两种搜索采样方式．ｓｅａｒｃｈ ｂｉａｓ是一 的顶点之间的偏移量来学习一系列潜在特征表
个阶梯函数α （ｔ，ｘ），根据随机游走的上一遍历记 示，每个潜在特征表示又可用于捕获连续的且更大
ｐｑ
录，调整下一步的转移概率π ＝α （ｔ，ｘ）ｗ ，其中 的关系．各种依赖信息使得同一表示策略在不同尺
ｉｘ ｐｑ ｉｘ
ｗ 是随机游走初始的转移概率值，ｐ和ｑ是ｓｅａｒｃｈ 度顶点关系上均可建模．类似于 ＤｅｅｐＷａｌｋ模型，
ｉｘ
ｂｉａｓ的参数，ｔ是上一遍历的顶点，ｉ是当前顶点，ｘ Ｗａｌｋｌｅｔｓ方法从每个顶点开始进行一系列截断的
是待遍历顶点．在不同的任务中通过调整ｐ和ｑ，可 随机游走．在这些截断的随机游走中的两个顶点的
以获得更好的顶点表达学习．在多标签分类和链路 共现可以建模网络中的扩散速率．然而在采样过程
预测两个应用问题上进行验证，表明了 Ｎｏｄｅ２Ｖｅｃ 中一个至关重要的变化是：选择跳过随机游走中的
模型的有效性． 一些顶点，以这种方式形成从邻接矩阵Ａ的连续更
网络嵌入是学习网络中顶点的低维表示的重要 高的幂中采样的一组关系．在大规模网络上的实验
方法，目的在于捕获和保留网络的结构．现有的网络 验证了 Ｗａｌｋｌｅｔｓ方法对多标签网络分类任务的效
嵌入方法几乎都采用浅层模型．由于隐含的网络结 果优于矩阵分解方法等．
构非常复杂，浅层模型并不能捕获到高度非线性网 同样的，考虑到现有的基于顶点相似性的网络
络结构从而导致产生非最优网络表示结果．因此，如 链接预测方法采用简单的一阶、多阶邻居信息或针
何找到能够有效捕获高度非线性网络结构以及保留 对特定类型的小型网络［７３－７５］，导致这些方法在扩展
结构的全局和局部特性，仍是一个开放且非常重要 性以及大规模网络中的可计算性都受到了严峻的挑
的问题．为了解决这个问题，Ｗａｎｇ等人［７１］提出了一 战．基于此问题，Ｌｉ等人［７６］提出了一个ＬｓＮｅｔ２Ｖｅｃ
种结构深度网络嵌入方法ＳＤＮＥ（Ｓｔｒｕｃｔｕｒａｌ Ｄｅｅｐ （Ｌａｒｇｅ－ｓｃａｌｅ Ｎｅｔｗｏｒｋ ｔｏ Ｖｅｃｔｏｒ）模型对大规模网 ２４０６ 计 算 机 学 报 ２０１８年
络进行链接预测．
ＬｓＮｅｔ２Ｖｅｃ模型首先通过随机游走的方法产
生网络数据集序列从而进行大规模的无监督机器学
习，使得网络中顶点的结构特征信息被映射到一个
连续的、固定维度的实数向量空间上．然后把学习到
的顶点结构特征向量用于迅速计算大规模网络中任
意顶点之间的相似度．图５为ＬｓＮｅｔ２Ｖｅｃ模型的架
构图，由输入层、投影层和输出层组成．其中输入层
的主要功能是按照一定的规则对网络中的顶点采用
图５ ＬｓＮｅｔ２Ｖｅｃ模型架构
随机游走的方法进行遍历得到序列化的格式表示输
表１汇总了当前最新的大规模复杂信息网络结
出，进而重构训练集．投影层则对序列化的训练集根
构表示学习模型，并比较了这些模型的核心思想与
据给定训练窗口大小α在嵌入矩阵Ｍ 中进行搜索，
观点、实验环境以及实验中数据集的规模大小以及
最后将搜索到的向量集合以参数形式传递给聚合函
应用方面等．表中的模型从一定程度上都是受到
数ｆ进行处理．输出层由一棵哈夫曼树构成，选用
Ｗｏｒｄ２Ｖｅｃ模型的启发．其中 ＤｅｅｐＷａｌｋ模型是最
哈夫曼树对网络顶点进行重构存储以此有效降低计
先提出在大规模复杂信息网络中通过训练顶点潜在
算的复杂度．在多个大规模网络数据集上进行验证
向量表示的新方法．其它大多数模型是在 Ｄｅｅｐ－
并与其它链接预测进行对比，证明了ＬｓＮｅｔ２Ｖｅｃ模
Ｗａｌｋ模型的基础上进行扩展和应用，但在模型的表
型预测的效果是非常有效．
示学习能力以及应用范围存在着差别．
表１ 大规模复杂信息网络结构表示学习模型
模型 核心算法与观点 对象 类型＊ 实验规模 实验环境 评测数据集 评测应用 备注
ＤｅｅｐＷａｌｋ［３１］※随机游走产生输入序列 ＵＤ／ 单机，２４Ｃｏｒｅｓ＠２．０ＧＨｚ 顶点的多标 适合大规模
ｎｏｄｅ １１３８４９９ 社交网络
（２０１４） ※基于Ｓｋｉｐ－ｇｒａｍ模型 ＮＷ ＣＰＵ，１２８ＧＢ内存 签分类 网络
ＬＩＮＥ［２１］ ※重构目标函数 Ｄ／ＵＤ／ 单机，４０Ｃｏｒｅｓ＠２．０ＧＨｚ 文本／社交／ 词类比、文档 适合大规模
ｎｏｄｅ １９８５０９８
（２０１５） ※带权边采样算法 Ｗ／ＮＷ ＣＰＵ，１ＴＢ内存 引用网络 分类、可视化 网络
优化部分若
顶点聚类、 使用随机梯
ＧｒａＲｅｐ［３２］ ※学习网络的全局特征
ｎｏｄｅ
Ｗ／ＮＷ
１０３１２
单机，４Ｃｏｒｅｓ＠３．４ＧＨｚ 语言／社交／
顶点分类、 度下降则适
（２０１５） ※优化部分使用ＳＶＤ ／ＵＤ ＣＰＵ，１６ＧＢ内存 引用网络
可视化 合 大 规 模
网络
链接预测、
ＤＮＰＳ［４０］
※基于阻尼衰减的采样算法
单机，６Ｃｏｒｅｓ＠ＩｎｔｅｌＲｉ７－ 社区发现、 适合大规模
（２０１６）
※基于局部搜索增量式学习 ｎｏｄｅ Ｄ／ＵＤ ３２２３５８９
５２８０ｋＣＰＵ，６４ＧＢ内存
社交网络
用户推荐、 网络
※优化部分使用随机梯度上升
标记分类
统一建模局
ＣＮＲＬ［６８］
※基于社区增强型 Ｄｅｅｐ－
Ｗ／ＮＷ
社交网络／ 链接预测、顶
部邻域信息
Ｗａｌｋ模型 ｎｏｄｅ １０３１２ ｎ／ａ 引用网络／ 点分类、社区
（２０１６） ／ＵＤ 和全局社区
※增强型顶点表示 Ｗｅｂ网络 发现、可视化
结构
※基于最大间隔ＤｅｅｐＷａｌｋ
ＭＭＤＷ［６９］ 模型
ｎｏｄｅ Ｄ／ＵＤ ３３１２
单机，４Ｃｏｒｅｓ ＣＰＵ，１６ＧＢ 引用网络／ 顶点分类、可
半监督学习
（２０１６） ※优化部分使用矩阵因式 内存 社交网络 视化
分解的平方损失
Ｎｏｄｅ２Ｖｅｃ［７０］※引入ｓｅａｒｃｈ ｂｉａｓ函数进
单机，６Ｃｏｒｅｓ＠３．４ＧＨｚ
社交网络／ 链接预测、顶 适合大规模
（２０１６）
行有偏差的随机游走 ｎｏｄｅ Ｄ／ＵＤ １００００００
ＣＰＵ，６４ＧＢ内存
生物网络／ 点的多标签 网络半监督
※网络邻域 词共现网络 分类 学习
ＳＤＮＥ［７１］
※半监督深度模型 社交网络／ 顶点的多标 适合大规模
※使用随机梯度下降进行 ｎｏｄｅ Ｄ／ＵＤ １１３８４９９ ｎ／ａ 引用网络／ 签分类、链接 网络／半 监
（２０１６）
参数寻优 语言网络 预测、可视化 督学习
Ｗａｌｋｌｅｔｓ［７２］
※多尺度表示学习
Ｄ／ＵＤ／ 单机，２４Ｃｏｒｅｓ＠２．０ＧＨｚ 社交网络／ 顶点的多标 适合大规模
（２０１６）
※使用随机梯度下降进行 ｎｏｄｅ
ＮＷ
１１３８４９９
ＣＰＵ，３８４ＧＢ内存 引用网络 签分类 网络
参数寻优
公路／社交／
ＬｓＮｅｔ２Ｖｅｃ［７６］※ ※随 使机 用游 随走 机产 梯生 度输 上入 升序 对列
参 ｎｏｄｅ Ｄ／ＵＤ ２３９００００
单机，４Ｃｏｒｅｓ＠２．５ＧＨｚ 引用／通讯／
链接预测
适 网合 络／大 无规模
监
（２０１６） ＣＰＵ，１６ＧＢ内存 购买共现网
数寻优 督学习
络等
＊：Ｄ／ＵＤ：向／无向图；Ｗ／ＮＷ：带权／非带权图；实验规模为作者所采用的实验数据集的最大顶点数；
实验环境：上述表格中部分作者未在论文中提及实验时所使用机器配置情况，笔者通过邮件联系上部分作者，得到了相关的信息，在上述表
格中进行了相应的补充，在此一并致谢． １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２４０７
３．３ 基于概率的网络内容表示学习 的参数学习，得到一组出现在语料库和相关的不同
与ＤｅｅｐＷａｌｋ及其衍生方法进行对比，基于贝 文档的主题集合，识别出作者及相关的主题．在
叶斯公式的概率模型也成为网络内容表示学习的热 ＬＤＡ模型中文档集合的生成过程可描述为：首先从
点之一，即基于Ｇ＝（Ｖ，Ｅ，Ｗ，Ｃ）形式．由于复杂信 狄利克雷分布中抽取每篇文档的主题分布，然后根
息网络中的数据信息除了顶点间的结构关系外，其 据主题分布将文档中的每个词汇选择一个对应的主
顶点自身还可能包含大量有用的属性信息，如互联 题，最后从具有特定主题的词汇多项式分布中，对每
网中网页顶点包含的文本内容、社交网络中每个用 个词汇进行采样．
户发布的文本信息等． 在主题模型ＬＤＡ的基础上，Ｃｈａｎｇ等人［８１］进
基于概率的网络内容表示学习以顶点的内容信 一步提出了关系主题模型 ＲＴＭ（Ｒｅｌａｔｉｏｎａｌ Ｔｏｐｉｃ
息作为输入数据，学习得到网络中的顶点在主题空 Ｍｏｄｅｌ）．这是一种结合网络链接和顶点属性的分层
间上的向量表示．在学习过程中主要采用基于概率 模型．ＲＴＭ模型在建模文档的生成过程时与ＬＤＡ
生成模型方法来实现网络表示学习，即用一个基于 基本一致，不同之处在于前者还建模链接关系的产
概率的生成过程去建模网络数据的生成过程．求解 生．该模型给出假设是：若两个文档顶点之间存在链
这些模型的方法通常采用Ｇｉｂｂｓ采样、变分推断和 接，那么它们在主题上的分布应该理论上更相似．
期望最大化算法等．具体的，概率生成模型方法主要 ＲＴＭ的图模型如图６（ａ）所示，图中每个文档ｄ与
ｉ
用于处理文本数据，通常使用无监督的分级贝叶斯 一个主题分布θ相关联，为了在文档ｄ中产生第ｎ
ｉ ｉ
模型来实现，在不考虑网络结构特征的情况下，将文 个词，它们首先从θ ｉ中选择一个主题ｚ ｉ，ｎ，然后从
本数据与网络中的链接关联起来．其实现主要依赖 ｚ ｉ，ｎ的主题多项式βｚ ｉ，ｎ选择一个词ｗ ｉ，ｎ．θ ｉ和βｚ各自
主题模型，该模型首先假设存在一个概率生成式模 的Ｄｉｒｉｃｈｌｅｔ先验为α和λ．相应地，一对文档ｄ和ｄ
ｉ ｊ
型，将每一个文本关联到多个主题后，最终从文本中 之间的每条链接ｙ 是基于在ｄ和ｄ中出现的主题
ｉｊ ｉ ｊ
提取相应的主题．目前的概率主题模型一般基于这 由链接概率函数生成．文档之间分享共同主题数量
样的思想：将文本看作是由若干主题随机混合，在不 越多，他们之间的链接就越有可能．
同的模型中会有不同的统计假设，并以不同的方法
获得模型参数．本节主要介绍静态模式表示学习和
动态模式表示学习两类框架下的网络内容表示学习
模型．
３．３．１ 静态模式表示学习
在主题模型中，将一个给定词汇的多项式分布
表示成一个主题．主题模型用一个数量较小词汇的
分布对文本进行总结，这些分布被称为“主题”［７７］．
传统的主题生成模型包括 ＰＬＳＡ［７８］（Ｐｒｏｂａｂｉｌｉｔｙ
Ｌａｔｅｎｔ Ｓｅｍａｎｔｉｃ Ａｎａｌｙｓｉｓ）、ＬＤＡ［７９］ （Ｌａｔｅｎｔ
Ｄｉｒｉｃｈｌｅｔ Ａｌｌｏｃａｔｉｏｎ）等．在ＰＬＳＡ模型中，通过用概
率的方式解释了文档的生成过程．该模型是建立在 图６ ＲＴＭ和ＰＬＡＮＥ的图模型比较
ＬＳＡ（Ｌａｔｅｎｔ Ｓｅｍａｎｔｉｃ Ａｎａｌｙｓｉｓ）模型的基础上，用
由于ＰＬＳＡ和ＬＤＡ模型不能明确建模引用文
于克服ＬＳＡ无法解决一词多义从而导致表达词义
档和被引用文档之间的主题关系，Ｎａｌｌａｐａｔｉ等人［８２］
的能力有限的问题，但该模型中的文档概率值与特
提出了Ｌｉｎｋ－ＰＬＳＡ－ＬＤＡ模型，该模型以学术论文
定文档相关联，缺乏有效处理新文档的自然方法．同
引用网络为输入数据，先后分别建模被引用论文集
时随着文档数量的增加，参数估计的数量呈线性增
合和引用论文集合生成过程．图７展示了这种建模
长，这表明模型易于过拟合［８０］．ＬＤＡ模型在ＰＬＳＡ
的过程．为了明确地建模从引用论文集合到被引用
模型的概率分布加上了先验知识，采用分层贝叶斯
论文集合的信息流，他们为被引用论文的内容定义
推断方法求解参数，解决了ＰＬＳＡ存在的过拟合问
了一个使用相同分布Ω的显式生成过程．在这个新
题．在ＬＤＡ模型中，通过允许文档作者确定不同主
的生成过程中，将被引用论文集合当成用词汇填充
题的混合权重，并将其扩展到作者建模．通过对模型
的容器，首先关联整个被引用论文集合的主题混合 ２４０８ 计 算 机 学 报 ２０１８年
分布π，然后将词汇填充到这些容器中． 一是传统的主题建模；二是表示学习，对每个主题和
每个文本顶点都学习其在低维空间上的坐标．
３．３．２ 动态模式表示学习
针对以上主题模型没有考虑到网络文档的时间
戳的重要性，Ｗａｎｇ等人［８５］提出了一个与ＬＤＡ类
似的主题模型ＴＯＴ（Ｔｏｐｉｃｓ Ｏｖｅｒ Ｔｉｍｅ）．该模型不
仅能够捕捉网络数据的低维结构表达，而且还能够
捕获该结构随时间的变化过程．与依赖于马尔科夫
假设或时间离散化的其他研究工作不同的是，文中
的每个主题与在时间戳上的连续分布相关联．对于
图７ Ｌｉｎｋ－ＰＬＳＡ－ＬＤＡ模型 每个生成的文档，主题上的混合分布受到词共现和
可视化是理解复杂和高维数据的有用工具，它 文档的时间戳两者的影响．
除此之外，部分研究人员对信息传播主题提取
使人们能够通过大量数据直观地进行浏览．大多数
可视化方法没有考虑给定数据中的潜在结构，例如 也展开了相关研究．由于大多数信息传播提取工作
在文档数据情况下的主题．为了克服上述局限性，
侧重于个人层面的交互以及网络的结构拓扑［８６－８８］，
Ｉｗａｔａ等人［８３］提出了 ＰＬＳＶ（Ｐｒｏｂａｂｉｌｉｓｔｉｃ Ｌａｔｅｎｔ 虽然这些提取方法获得了较好的效果，但仍然存在
Ｓｅｍａｎｔｉｃ Ｖｉｓｕａｌｉｚａｔｉｏｎ）模型，这是一种基于主题模 如下缺点：首先基于网络结构方法很大程度上忽略
型的离散数据（如文档）的可视化方法．与基于成对 了局部的差异，导致不能捕捉到信息模式的多样性；
距离的常规可视化方法（如多维量表）不同，文中考 高度易变的用户行为通常使得难以准确地揭示个人
虑从可视化空间到文档空间的映射作为文档的生成
层面的传播模式；最后聚合方法未能揭示详细的传
过程．在模型中，假设文档和主题在二维或三维欧氏 播过程．
空间或可视化空间中具有潜在坐标．文档的主题分
针对信息传播提取存在的以上问题，Ｈｕ等
布由文档和可视化空间中的主题之间的距离确定， 人［８９］提出了 ＣＯＬＤ（Ｃｏｍｍｕｎｉｔｙ Ｌｅｖｅｌ Ｄｉｆｆｕｓｉｏｎ）
并且每个词汇依据主题分布从一个主题中提取．可
方法用于提取社区层面的传播，即建模不同社区的
以通过使用 ＥＭ 算法（Ｅｘｐｅｃｔａｔｉｏｎ Ｍａｘｉｍｉｚａｔｉｏｎ 主题的传播模式，将社区和主题作为潜在变量，并为
Ａｌｇｏｒｉｔｈｍ）将模型拟合到给定的一组文档来获得可 观察网络、文本和时间建立一个生成过程，以准确地
视化，即文档的潜在坐标，使具有相似主题的文档被 刻画社区层面的主题传播，同时设计了一种基于抽
紧密地嵌入在一起． 样的推理算法及其并行实现方法．在学习顶点在社
文本网络的嵌入问题是把文本的高维表示嵌入 区空间上的分布的同时，也学习社区在主题空间上
到一个低维空间中，以尽可能保留原始文本数据的 的分布．
属性．得到文本的低维表达具有重要的应用，如文本 ３．４ 结构－内容融合的表示学习
在低维空间的可视化．通过将文本降维表示解释为 表示学习在很多应用方面展示出其有效性，如
二维或三维空间上的坐标，可以产生一个散点图可 图像分类和文本挖掘中．网络表示学习旨在学习网
视化．文档之间的相似性或差异性体现在空间信息 络中每个顶点的分布式向量表示，这也越来越多地
上．除了可视化应用之外，低维表示还可以用于有损 被确认为网络分析的一个重要方面．和以往网络分
压缩或者用于机器学习任务（例如聚类或分类）中的 析关注网络的拓扑结构解决诸如“网络的直径”［９０］、
特征选择．基于以上这些应用，Ｌｅ等人［８４］提出了 “网络如何演化”［９１－９５］、“信息如何在网络上传
ＰＬＡＮＥ（Ｐｒｏｂａｂｉｌｉｓｔｉｃ Ｌａｔｅｎｔ Ｄｏｃｕｍｅｎｔ Ｎｅｔｗｏｒｋ 播”［９６－９７］以及“什么是网络上的社区”［９８－１０３］等问题的
Ｅｍｂｅｄｄｉｎｇ）模型，通过对 ＲＴＭ 模型进行扩展，从 研究方式不同，网络表示学习通过对网络顶点之间
可视化的角度学习到主题和文档顶点的低维表达． 的关系（结构或内容）进行分析，得出网络特征的低
图６（ｂ）为ＰＬＡＮＥ模型表示图，与ＲＴＭ 模型的区 维度表示．大多数网络表示学习方法通过研究网络
别在于ＰＬＡＮＥ模型需要考虑低秩嵌入目标并且基 结构特征进行学习，忽视了在现实中网络顶点包含
于坐标而不是主题分布来建模链接的生成过程． 的丰富信息（文本内容和其它元数据）．
ＰＬＡＮＥ模型的具体生成过程主要涉及两个方面： 以维基百科为例，其文章相互链接形成一个大 １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２４０９
型网络，该网络中的每个顶点即每篇文章包含丰富 Ｄｏｃｕｍｅｎｔ Ｆｒｅｑｕｅｎｃｙ）矩阵采用奇异值分解降维
的文本信息，这些信息对于网络表示学习也可能很 得到．
重要．还有些网络表示学习方法从研究网络内容特
征着手．这些方法通常以文本网络作为输入数据，学
习到的都是网络中的顶点在主题空间上的向量表
示，但没有考虑到网络本身所具有的结构特征．事实
上这些网络结构特征对于提炼和构建主题模型是非
常有用的，甚至有时是发现网络相关主题的必要条
件．例如，两个经常相互合作的研究人员可能正在处
理相同的主题，因此很可能属于同一个研究团体；对
于地理敏感的事件，生活在近邻地方的博主会写相
似的主题；缺少网络结构的考虑也是一些其它文本
挖掘技术（如文档聚类）中的缺陷．因此，融合网络结
图８ ＴＡＤＷ的矩阵分解示意图
构特征和文本内容特征的学习网络表示已经成为当 相比于ＤｅｅｐＷａｌｋ模型，ＴＡＤＷ 方法在计算性
前的重要研究方向．
能上明显占优．在ＤｅｅｐＷａｌｋ模型中因子分解矩阵
为了解决上述问题，一种较为直观学习方法是
Ｍ，每个矩阵元素ｍ ＝ｌｏｇ（［ｅ（Ａ＋Ａ２＋…＋Ａｔ）］／
ｉｊ ｉ ｊ
分别对文本特征以及网络的结构特征进行表示学 ｔ），其中Ａ为一个转换矩阵，［ｅ（Ａ＋Ａ２＋…＋Ａｔ）］
ｉ ｊ
习，例如分别用 Ｗｏｒｄ２Ｖｅｃ以及ＤｅｅｐＷａｌｋ方法，然
表示ｊ出现在ｉ的右侧邻居中的期望次数，当ｔ变大
后把这两种表示学习结合起来．然而，这类方法没有
时，计算准确的Ｍ的时间复杂度为O （｜Ｖ｜３）．Ｄｅｅｐ－
考虑到网络结构和文本信息两者之间的复杂交互，
Ｗａｌｋ使用基于随机游走的抽样方法以避免计算准
因此通常学习得到的特征向量并不理想．另一种有 确的矩阵Ｍ，这样ＤｅｅｐＷａｌｋ采样更多的步数时计
意义的学习方法是：在已有的网络结构表示学习框
算性能会更好，但相反其效率会更低．ＴＡＤＷ 则在
架中同时嵌入文本内容进行学习．目前，结构－内容
速度和精度两者之间进行了折衷即设置因子分解矩
融合表示学习研究工作主要分为基于矩阵因子分解 阵Ｍ＝（Ａ＋Ａ２）／２，这里用Ｍ替换ｌｏｇＭ出于计算效
的方法和基于概率图模型方法． 率，其原因是ｌｏｇＭ具有比Ｍ 更多的非零项，并且具
３．４．１ 基于矩阵因子分解的方法
有平方损失的矩阵分解的复杂性与矩阵Ｍ中的非
基于矩阵因子分解方法将大规模复杂信息网络 零元素的数量成比例［１０６］．由于大多数复杂信息网络
建模为矩阵形式，然后用线性代数或图论的矩阵分
是稀疏的，即O （Ｅ）＝O （Ｖ），ＴＡＤＷ 方法计算矩阵
解法解决表示学习问题． Ｍ的时间复杂度为O （｜Ｖ｜２），如果网络是稠密的，甚
ＤｅｅｐＷａｌｋ模型仅考虑顶点的结构信息，忽视了
至可以直接因式分解矩阵Ａ．求解矩阵Ｅ∈Rｋ×｜Ｖ｜以
顶点具有的丰富的内容信息，于是Ｙａｎｇ等人［１０４］在
及Ｈ∈Rｋ×ｆｔ，使其最小化公式如式（６）所示：
ＤｅｅｐＷａｌｋ模型的基础上通过考虑顶点的内容信息
ｍｉｎ‖Ｍ－ＥＴＨＴ‖２＋λ （‖Ｅ‖２＋‖Ｈ‖２）（６）
提出了 ＴＡＤＷ（Ｔｅｘｔ－Ａｓｓｏｃｉａｔｅｄ ＤｅｅｐＷａｌｋ）方法． Ｗ，Ｈ Ｆ ２ Ｆ Ｆ
该方法将ＤｅｅｐＷａｌｋ中矩阵Ｍ因式分解成三个低 为了优化Ｅ和Ｈ，通过迭代式地最小化Ｅ和
维矩阵的乘积：Ｅ∈Rｋ×｜Ｖ｜、Ｈ∈Rｋ×ｆｔ和Ｔ∈Rｋ×ｆｔ， Ｈ．虽然ＴＡＤＷ可以收敛到局部最小值而不是全局
矩阵元素ｍ 代表顶点ｉ在固定步骤中随机地游走 最小值，但该方法在实验中效果较好．不同于低秩矩
ｉｊ
到顶点ｊ的平均概率的对数，Ｔ作为顶点的文本特 阵分解，ＴＡＤＷ的目标是在网络结构表示学习中融
征矩阵．图８显示了ＴＡＤＷ 方法不同于ＤｅｅｐＷａｌｋ 入文本特征以获得更好的网络表示．由于从ＴＡＤＷ
的矩阵分解示意图，其中图８（ａ）表明ＤｅｅｐＷａｌｋ中 获得的Ｅ和ＨＴ都可以被认为是顶点的低维表示，
矩阵Ｍ被分解为两个矩阵的乘积，连接这两个矩阵 通过将它们连接起来构建用于网络表示的统一的
后作为最终的顶点向量表示，求解方法则采用正则化 ２ｋ维矩阵．ＴＡＤＷ 模型能够有效地融合顶点的内
的低秩矩阵分解［１０５］，而图８（ｂ）则显示ＴＡＤＷ 方法 容信息从而获得更好的网络表示学习．
中通过连接矩阵Ｅ、Ｈ和Ｔ后得到顶点特征矩阵，文 除此之外，针对ＤｅｅｐＷａｌｋ模型的主要缺陷在
本特征矩阵Ｔ由ＴＦ－ＩＤＦ（Ｔｅｒｍ Ｆｒｅｑｕｅｎｃｙ－Ｉｎｖｅｒｓｅ 于忽视现实世界网络中固有的链路稀疏问题［１０７］以 ２４１０ 计 算 机 学 报 ２０１８年
及顶点包含的丰富内容，Ｇａｎｅｓｈ等人［１０８］提出了一 则化的优势．ＮｅｔＰＬＳＡ综合考虑了网络结构和文本
个新颖的Ａｕｔｈｏｒ２Ｖｅｃ模型用于学习低维的作者表 内容来进行网络表示学习，在学习过程中对于网络
示，使得那些具有相似内容和共享类似网络结构的 中的每个顶点的文本主题提取采用ＰＬＳＡ模型，学
作者在向量空间中更相近．Ａｕｔｈｏｒ２Ｖｅｃ模型通过协 者们给出其对数似然函数如下：
同方式融合文本信息与链接信息以用于创建作者表 ｋ
Ｌ（Ｃ）＝∑∑ｃ（ｗ，ｄ）ｌｏｇ∑ｐ（θ｜ｄ）ｐ（ｗ｜θ）（９）
示．Ａｕｔｈｏｒ２Ｖｅｃ模型由内容信息模型（Ｃｏｎｔｅｎｔ－Ｉｎｆｏ
ｄ ｗ ｊ＝１
ｊ ｊ
Ｍｏｄｅｌ）和链接信息模型（Ｌｉｎｋ－Ｉｎｆｏ Ｍｏｄｅｌ）两个子
其中Ｃ为一个聚类，｛｛ｐ（θ ｊ｜ｄ），ｐ（ｗ｜θ ｊ）｝ ｄ，ｗ，ｊ｝为模
型参数，ｄ、ｗ分别代表一个文档和一个词汇集合．
模型组成．内容信息模型以论文的摘要作为文本内
容来进行作者表示，其目标函数定义为
自然的可使用｛ｐ（θ ｊ｜ｖ）｝ ｊ作为顶点ｖ的权重，由
Ｌ＝P［ｒ（ｕ，ｐ）＝ｌ］＝ｓｏｆｔｍａｘ（Ｕ·ｔａｎｈ（Ｗ（×）ｈ×＋
式（１０）计算ｐ（θ ｊ｜ｖ）的值：
Ｃ Ｃ Ｃ Ｃ Ｃ
Ｗ（＋）ｈ＋＋ｂ（ｈ））＋ｂ（ｐ）） （７） ｐ（θ ｊ｜ｖ）＝∑ｐ（θ ｊ｜ｄ）ｐ（ｄ｜ｖ） （１０）
Ｃ Ｃ Ｃ Ｃ ｄ∈Ｄｖ
式中ｒ Ｃ（ｕ，ｐ）表示作者ｕ和论文ｐ之间的关系，ｌ∈ 为了结合网络结构进行表示学习，文中定义了
［１，２］，Ｕ∈R２×ｎｈ，ｂ（ｐ），Ｗ（×） ∈Rｎｈ×ｄ，Ｗ（＋） ∈Rｎｈ×ｄ， 正则化似然函数Ｓ（Ｃ，Ｇ）为式（１１）所示：
ｃ Ｃ Ｃ Ｃ
ｂ（ｈ）为该模型的参数，可通过最大化似然函数获得这 Ｓ（Ｃ，Ｇ）＝－（１－λ）Ｌ（Ｃ）＋λＲ（Ｃ，Ｇ） （１１）
Ｃ
些参数的最优值，ｈ×和ｈ＋则采用Ｚｈｕ等人［１０９］提出
其中Ｌ（Ｃ）由式（６）得到，Ｒ（Ｃ，Ｇ）是定义在网络结
Ｃ Ｃ
构Ｇ上的一个类似于图的调和函数的正则化［１１２］，
的方法获取．与内容信息模型建模过程类似，链接信
用式（１２）所示：
息模型以作者之间的链接来建模并进一步丰富作者
ｋ
表示，其目标函数定义为 Ｒ（Ｃ，Ｇ）＝ １ ∑ｆＴΔｆ （１２）
２ ｊ ｊ
Ｌ ＝P［ｒ（ｕ，ｖ）＝ｌ］＝ｓｏｆｔｍａｘ（Ｕ·ｔａｎｈ（Ｗ（×）ｈ×＋ ｊ＝１
Ｌ Ｌ Ｌ Ｌ Ｌ 这里的ｆ代表每个顶点的第ｊ个主题权重的｜Ｖ｜维
Ｗ Ｌ（＋）ｈ Ｌ＋＋ｂ Ｌ（ｈ））＋ｂ Ｌ（ｐ）） （８） 向量，Δ是ｊ
图拉普拉斯矩阵，有Δ＝Ｄ－Ｗ，其中Ｄ为
式中ｒ（ｕ，ｖ）表示作者ｕ和作者ｖ之间的关系，其
Ｌ 一对角矩阵，其矩阵元素表示为ｄ（ｕ，ｕ）＝∑ｗ ．
ｕｖ
它参数的求解以及优化与内容信息模型方法一样． ｖ
该模型的输出可以概括文本中的主题，将主题映射
通过共享作者嵌入权重来连接这两个子模型，最终
到网络上以及发现主题社区．通过适合的实例化主
Ａｕｔｈｏｒ２Ｖｅｃ模型的总体目标函数，可以写成Ｌ＝
题模型和基于网络的正则化，此模型可以广泛地应
Ｌ ＋Ｌ ．Ａｕｔｈｏｒ２Ｖｅｃ模型学习到的作者嵌入在链
Ｃ Ｌ
用于文本挖掘问题，如主题分析、社区发现和空间文
接预测和聚类效果上优于ＤｅｅｐＷａｌｋ模型．
本挖掘等．
３．４．２ 基于概率图模型的方法
然而，网络中顶点除了结构信息之外，还包含真
基于概率图模型方法是采用贝叶斯图模型方法
实存在的诸多信息，如用户产生的文本信息以及用
对网络顶点之间的联合概率进行建模，学习到每个
户本身的属性信息（性别、学校、地址、职业）．Ｌｉ等
顶点的低维向量表示．例如，Ｃｏｈｎ等人［１１０］提出了将
人［１１３］充分考虑了顶点以上多方面信息，提出了ＭＦＲ
ＰＬＳＡ和 ＰＨＩＴＳ（Ｐｒｏｂａｂｉｌｉｓｔｉｃ Ｈｙｐｅｒｔｅｘｔ－Ｉｎｄｕｃｅｄ
（Ｍｕｌｔｉ－Ｆａｃｅｔｅｄ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ）学习模型．该模型
Ｔｏｐｉｃ Ｓｅａｒｃｈ）结合起来的联合概率模型，用于建模
的目标在于学习得到每个用户、每个属性实体以及
文档集合的内容和互相链接．该模型基于概率因子
每个用户属性关系的低维向量表示．每个用户ｕ用
ｉ
分解，可以识别出文档集合的重要主题以及主题内
一个列表Ｉ＝｛ｔｅｘｔ，Ｇ，Ｒ，Ｍ｝与之相关联，整个模
ｉ ｉ ｉ ｉ ｉ
的权威文档．此外，映射主题之间的关系以便学习构
型最大化Ｉ的出现概率表示为式（１３）所示：
ｉ
建链接内容的预测模型． ｐ（Ｉ｜ｕ：Θ）＝ｐ（ｔｅｘｔ｜ｕ：Θ）×ｐ（Ｇ｜ｕ：Θ）×
ｉ ｉ ｉ ｉ ｕ ｉ ｉ ｕ
通过考虑复杂信息网络结构以及文本主题的 ｐ（Ｒ，Ｍ｜ｕ：Θ，Θ，Θ ） （１３）
ｉ ｉ ｉ ｕ ｒ ｍ
结合方式，Ｍｅｉ等人［１１１］提出了一个基于网络结构
式中Θ、Θ、Θ 分别代表用户、用户属性实体关系
ｕ ｒ ｍ
嵌入的主题：ＴＭＮ（Ｔｏｐｉｃ Ｍｏｄｅｌｉｎｇ ｗｉｔｈ Ｎｅｔｗｏｒｋ 和实体的潜在表示矩阵，Θ表示整个模型的参数空
Ｓｔｒｕｃｔｕｒｅ）的问题，并提出解决这种问题的ＮｅｔＰＬＳＡ 间即｛Θ，Θ，Θ ｝．ｐ（ｔｅｘｔ｜ｖ：Θ）借助于段落向量
ｕ ｒ ｍ ｉ ｉ ｕ
模型，即使用基于网络结构的调和正则化对统计主 （Ｐａｒａｇｒａｐｈ Ｖｅｃｔｏｒ）［１６］的思想使用用户层级的嵌入
题模型进行正则化．所提出的模型结合主题建模和 和邻接词来预测文本中的目标词．计算公式如式（１４）
社交网络结构分析，并利用统计主题模型和离散正 所示： １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２４１１
ｐ（ｔｅｘｔ｜ｖ：Θ）＝ ∑ｌｏｇｐ（ｗ｜ｕ）＋ 要性的参数．随着α值的增加，将更多地考虑网络中
ｉ ｉ ｕ ｉ
ｗ∈ｔｅｘｔｉ 的结构信息即ｎｏｄｅ－ｎｏｄｅ ｌｉｎｋ．使用随机梯度下降
∑ ∑ｌｏｇｐ（ｗ｜ｗ′）（１４） 与学习速率衰减对联合目标函数Ｌ进行优化，梯度
ｗ∈ｔｅｘｔｉｗ′∈ｃ（ｗ）
则使用反向传播计算．
由于式（１４）中后一项词级别的表示可以预先
现有学习方法仅仅关注顶点信息的某一个方面，
学习好，因此只需要使用 ＡＵＣ损失函数的方法对
并且没有利用顶点的标签信息，于是Ｐａｎ等人［１１５］
前一项进行优化．ｐ（Ｇ｜ｖ：Θ）定义为用户ｖ的链接
ｉ ｉ ｕ ｉ 提出了三方深度网络表示模型 ＴｒｉＤＮＲ（Ｔｒｉ－ｐａｒｔｙ
顶点的似然，类似于ＤｅｅｐＷａｌｋ和ＬＩＮＥ模型所使
Ｄｅｅｐ Ｎｅｔｗｏｒｋ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ Ｍｏｄｅｌ），通过使用来
用的ＳｋｉｐＧｒａｍ 方法通过用户顶点来预测其链接
自于网络的顶点结构、顶点内容和顶点标签联合学
的顶点，然后采用ＡＵＣ损失函数的方法进行优化．
习最佳的顶点表示．ＴｒｉＤＮＲ是建立在一种新的耦
ｐ（Ｒ，Ｍ｜ｖ：Θ，Θ，Θ ）则用于预测用户ｕ与属性
ｉ ｉ ｉ ｕ ｒ ｍ ｉ
合深度自然语言模块的基础上，从三个层面进行顶
实体ｍ的关系．ＭＦＲ模型使用随机梯度下降法对
点表示学习：在网络结构层面，通过最大化在随机游
整个模型进行优化处理．
走中给定某一顶点的情况下，观察其周围顶点的概
针对ＴＡＤＷ模型通过矩阵分解将文本特征融合
率，ＴｒｉＤＮＲ获取了顶点间的关系．在顶点内容层
到网络嵌入中，这通常导致计算成本较高，并且ＴＡＤＷ
面，通过最大化给定顶点的词序列的共现关系，
中的文本内容被简单地融合作为无序文本特征而不
ＴｒｉＤＮＲ捕获了顶点－词的相关性．在顶点标签层
是被明确建模，因此也不能很好地捕获更深的语义等
面，通过最大化给定一个类标签的词序列的概率，
问题，Ｓｕｎ等人［１１４］提出了结合网络结构和文本信息
ＴｒｉＤＮＲ建模了标签－词的相关性．以上三方信息被
的内容增强网络嵌入方法ＣＥＮＥ（Ｃｏｎｔｅｎｔ－Ｅｎｈａｎｃｅｄ
一起输入到神经网络模型中以彼此相互增强方式学
Ｎｅｔｗｏｒｋ Ｅｍｂｅｄｄｉｎｇ）．该方法通过将文本内容作为
习网络最佳表示．
特殊类型的顶点来处理，用一个普适性框架来融合
最新的基于网络结构－内容融合学习的表示模
文本建模和结构建模．本文作者描述了一个最小化
型总结如表２所示．这些模型可以看作是基于网络
目标函数的普适性框架：
结构表示学习的拓展，通过在网络结构建模的基础
Ｌ＝ ∑ ｌｏｇｐ（ｕ，ｖ；θ）＋ ∑ ｌｏｇ（１－ｐ（ｕ，ｖ；θ））
ｇ 上有效地融合顶点内容信息获得更好的顶点分布式
（ｕ，ｖ）∈ＳＰ （ｕ，ｖ）∈ＳＮ
（１５） 表示．从顶点内部信息的种类来说，ＴＡＤＷ、ＣＥＮＥ、
式中ＳＰ表示积极顶点对的集合，ＳＮ表示消极顶点
Ａｕｔｈｏｒ２Ｖｅｃ以及ＴｒｉＤＮＲ等模型考虑了顶点自身
对的集合，顶点ｕ和ｖ之间的联合概率ｐ（ｕ，ｖ；θ）表
产生的文本信息．ＴＡＤＷ 能够有效地融合文本信
示为顶点对（ｕ，ｖ）在ＳＰ出现的概率，１－ｐ（ｕ，ｖ；θ） 息，获得比不用文本特征的基于结构表示学习模型、
则与之相反．用该框架分别对ｎｏｄｅ－ｎｏｄｅ ｌｉｎｋ和 只用文本特征的表示学习模型以及简单将两模型所
ｎｏｄｅ－ｃｏｎｔｅｎｔ ｌｉｎｋ建立损失函数Ｌ 和Ｌ ．联合目 得表示串接起来的方法更好的实验效果，但降维时
ｎｎ ｎｃ
标函数定义为Ｌ＝αＬ ＋（１－α）Ｌ ，该函数是上述 采用矩阵因子分解，导致模型复杂度较高．ＣＥＮＥ模
ｎｎ ｎｃ
两个损失函数的加权组合，这里的α∈［０，１］是用于 型把文本当成一类特殊的顶点进行处理，从而学习
平衡ｎｏｄｅ－ｎｏｄｅ ｌｉｎｋ和ｎｏｄｅ－ｃｏｎｔｅｎｔ ｌｉｎｋ两者的重 到更深的语义信息．Ａｕｔｈｏｒ２Ｖｅｃ模型通过融合两类
表２ 结构－内容融合的表示学习模型
模型 核心算法与观点 对象 类型 实验规模 评测数据集 评测应用 备注
ＴＡＤＷ［１０４］ ※随机游走产生输入序列
ｎｏｄｅ Ｄ／ＵＤ ３３１２ 文本网络、引用网络 多标签顶点分类
在ＤｅｅｐＷａｌｋ模型中
（２０１５） ※基于Ｓｋｉｐ－ｇｒａｍ模型 融入文本特征
Ａｕｔｈｏｒ２Ｖｅｃ［１０８］※内容信息模型、链接信息模型 链接预测、聚类、 无监督学习／适合大
ｎｏｄｅ Ｄ １２１２１７１ 引用网络
（２０１６） ※优化使用随机梯度下降 网络可视化 规模网络
ＭＦＲ［１１３］
※学习网络的全局特征
链接预测、社区发 适合大规模网络／类
（２０１５）
※优化部分使用并行随机梯度 ｎｏｄｅ ＵＤ ７５００００００ 社交网络
现、用户属性预测 似于Ｓｋｉｐ－ｇｒａｍ模型
下降
ＣＥＮＥ［１１４］ ※随机梯度下降进行参数寻优
ｎｏｄｅ Ｄ／ＵＤ ６２９８１４ 社交网络、引用网络 顶点分类 适合大规模网络
（２０１６） ※通用框架融合文本、结构建模
融合结构、内容和标
ＴｒｉＤＮＲ［１１５］ ※耦合神经网络模型学习 顶点分类
ｎｏｄｅ Ｄ／ＵＤ ６０７４４ 引用网络、合作网络 签联合学习／适合大
（２０１６） ※随机游走产生输入序列 网络可视化
规模网络 ２４１２ 计 算 机 学 报 ２０１８年
子模型，以无监督的方式学习作者嵌入，取得了优于 为了结合多种类型的关系来度量异构网络中维
ＤｅｅｐＷａｌｋ模型的学习效果．ＴｒｉＤＮＲ模型还考虑了 基百科实体之间的语义相关性，Ｚｈａｏ等人［１１８］提出了
顶点标签信息，从不同网络层级进行学习以获得更 调和矩阵因式分解ＣＭＦ（Ｃｏｏｒｄｉｎａｔｅ Ｍａｔｒｉｘ Ｆａｃｔｏｒｉ－
佳的表示效果．模型 ＭＦＲ考虑了文本信息和顶点 ｚａｔｉｏｎ）模型，该模型构建了同一语义空间中的实体、
自身的属性信息，获得多种关系的低维向量表示．通 类别和词的低维连续表示方法．在ＣＭＦ模型中，学
过对网络结构、内容以及相关属性信息建模到统一 习实体表示矩阵Ｅ ∈R｜Ｅ｜×Ｋ的过程被设想为对实
Ｈ
空间，ＭＦＲ模型学习得到的网络表示不仅可以预测 体－实体系数矩阵Ｘ∈R｜Ｅ｜×｜Ｅ｜的估计．为了结合实体
用户之间的链接关系，同时也可以预测用户本身具 和词之间的关系以及实体和类别之间的关系，又各自
有的属性信息，如性别、地址、职业等． 构建了两个系数矩阵：Ｙ∈R｜Ｃ｜×｜Ｅ｜、Ｚ∈R｜Ｗ｜×｜Ｅ｜，其
３．５ 异构网络的表示学习 中Ｙ由实体表示矩阵Ｅ 和类别表示矩阵Ｅ 的内积
Ｈ Ｃ
异构网络是一种由不同类型的顶点（如用户、内 来估计，Ｚ由实体表示矩阵Ｅ 和词表示矩阵Ｅ 的
Ｈ Ｗ
容和群组等）和关系（如社交或相似关系）所组成的
内积来估计．求解ＣＭＦ模型的目标函数为
网络．例如，Ｆｌｉｃｋｒ网络顶点类型同时包含用户、视
Ｊ＝ ∑ （Ｘ －ＥＥＴ ）２＋
频和标签等，顶点间又通过相同或不同类型的联系 （ｉ，ｊ）∈ＮＸ
ｉｊ Ｈｉ Ｌ
ｊ
而关联．尽管目前在同构网络上的网络表示学习的 ∑ （Ｙ －ＣＥＴ ）２＋
研究已经取得了较大的进展，但在异构网络上，由于 （ｉ，ｊ）∈ＮＹ
ｉｊ Ｈｉ Ｈ
ｊ
其复杂性，使得表示学习仍是一个非常有挑战性的 ∑ （Ｚ －Ｗ ＥＴ ）２＋
ｉｊ Ｈｉ Ｈ
ｊ
研究问题． （ｉ，ｊ）∈ＮＺ
当前，有关异构网络表示学习的文献相对较少． λ（‖Ｅ ‖２ ＋‖Ｅ‖２）＋
Ｈ Ｆ Ｌ Ｆ
Ｔａｎｇ等人［１１６］研究了社交网络中用户交互信息的分 γ（‖Ｃ ‖２ ＋δ‖Ｗ ‖２） （１６）
Ｈ Ｆ Ｈ Ｆ
类任务．针对社交网络由多种关系组成的异构网络，
式中λ、γ、δ为正则化因子，Ｎ 、Ｎ 、Ｎ 分别代表Ｘ、
Ｘ Ｙ Ｚ
而大多数现有方法把这种异构关系当成同构进行处
Ｙ、Ｚ的非零实体．ＣＭＦ模型使用随机梯度下降法对
理，由此无法获得令人满意的分类性能．基于这一问
整个模型进行优化．通过将网络中不同的关系建模
题，他们提出了社会维度的概念来表示用户的潜在
到统一空间，模型学习到的网络表示，不仅可以克服
隶属关系，并构建了一个分类框架ＳｏｃｉｏＤｉｍ（Ｓｏｃｉａｌ
网络稀疏性问题，而且通过引入更多的关联矩阵可
Ｄｉｍｅｎｓｉｏｎｓ）．该框架先提取网络结构的社会维度，
容易地进行扩展．
以准确地捕获用户之间的交互模式，然后学习一个
为了引入标签信息来指导文本表示的学习，Ｔａｎｇ
判别分类器来选择相关的社会维度．通过区分不
等人［１１９］在ＬＩＮＥ模型的基础上针对文本标签预测
同类型的网络关系，ＳｏｃｉｏＤｉｍ 获得了较好的分类
任务提出了半监督表示学习模型ＰＴＥ（Ｐｒｅｄｉｃｔｉｖｅ
性能．
Ｔｅｘｔ Ｅｍｂｅｄｄｉｎｇ）．ＰＴＥ通过将部分标签已知的文
与ＳｏｃｉｏＤｉｍ模型出发点不同，Ｊａｃｏｂ等人［１１７］
档集合数据转换为一个包含文档、词语和标签三类
提出了隐含空间异构模型 ＬＳＨＭ（Ｌａｔｅｎｔ Ｓｐａｃｅ
顶点的异构网络，然后学习不同类型顶点的向量表
Ｈｅｔｅｒｏｇｅｎｅｏｕｓ Ｍｏｄｅｌ）用于处理异构网络的表示学
示．相比无监督表示模型ＬＩＮＥ和段落向量以及有
习．该模型的思想是无论网络中的顶点属于哪种类
监督的神经网络模型ＣＮＮ（Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｎｅｕｒａｌ
型，都可对顶点在同一向量空间学习其低维表示．
Ｎｅｔｗｏｒｋ），ＰＴＥ模型在长文本语料和短文本语料都
ＬＳＨＭ模型针对顶点属性采用一种扩展方式即把
属性也作为一种没有标签的顶点，同时学习各种类
取得了较好的效果；同时ＰＴＥ模型的参数在不同数
型的顶点向量表达和标签的线性分类函数，它的优 据集上表现也更加稳定．
化目标函数涉及两方面：一方面考虑了网络上的平 此外，为了分析具有各种类型的顶点和内容的
滑性，即相邻顶点的标签尽可能相似；另一方面考虑 异构网络特征嵌入的情况，Ｃｈａｎｇ等人［１２０］提出了
了分类函数对已知标签的预测能力．如果只考虑网 一种异构网络嵌入 ＨＮＥ（Ｈｅｔｅｒｏｇｅｎｅｏｕｓ Ｎｅｔｗｏｒｋ
络的平滑性，则ＬＳＨＭ模型就可以用相似度矩阵作 Ｅｍｂｅｄｄｉｎｇ）表示学习算法，将不同的异构对象映射
为输入．该模型可以看成是一种半监督的网络表示 到统一的隐含空间，以便可以直接比较来自不同空
学习模型． 间的对象．图９表示为 ＨＮＥ模型的架构图，ＨＮＥ １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２４１３
将特征学习过程分解为深层结构的多个非线性层， 得最终的嵌入可用于各种数据挖掘任务．尤其是他
高度非线性的多层嵌入函数用于捕获网络中异构数 们实证了异构网络中丰富的内容和链接信息可以通
据之间的复杂交互．他们的目标是创建一个多分辨 过这种方法捕获，使得跨模态数据之间的相似性可
率深度嵌入函数来反映局部和全局网络结构，并使 以度量在同一向量空间中．
图９ ＨＮＥ模型架构
重要．构建和收集数据集是一项耗时且繁琐的工作，
４ 大规模复杂信息网络表示学习的 而且并非所有数据集都是公开和容易获取的．本文
评测 总结了目前网络表示学习模型所使用的一些大规模
数据集，以及包括这些数据集的参考文献，具体信息
本节将从大规模复杂信息网络学习所涉及的 见表３所示．
评测数据集、应用场景与评测指标三个方面展开 从表３可知，在线社会网络（如ＹｏｕＴｕｂｅ、Ｆｌｉｃｋｒ
讨论． 以及Ｂｌｏｇｃａｔａｌｏｇ）和合作网络（如ＤＢＬＰ）是最受欢
４．１ 评测数据集 迎的数据集．由于这些数据集获得斯坦福大学的
网络表示学习方法几乎都需要在真实的数据集 精心维护，所以许多研究人员更喜欢使用这些数
上验证其方法的有效性，因此数据集的构建与选择 据集．然而，同样需要看到当前数据集用在网络表
对于完全地复现和比较不同的网络表示学习方法很 示学习上验证与应用所存在的一些不足：首先，部分
表３ 大规模复杂信息网络表示学习的数据集
大小
类型 数据名称 方向＃ 网络密度 平均度 平均集聚度 参考文献
顶点数 边数
ＹｏｕＴｕｂｅ ＵＤ １．１３Ｅ＋０６ ２．９９Ｅ＋０６ ４．６４Ｅ－０６ ５．２６５ ０．０８１ ［２１，３１，４０，６８，７２，７６］
Ｆａｃｅｂｏｏｋ ＵＤ ４．０４Ｅ＋０３ ８．８２Ｅ＋０４ ４．０２Ｅ－０４ ２５．６４０ ０．６０６ ［７０］
社会 Ｄｉｇｇ Ｄ／ＵＷ ２．８０Ｅ＋０５ １．７３Ｅ＋０６ ２．２１Ｅ－０５ １２．３８５ ０．０６１ ［４０］
网络 Ｆｌｉｃｋｒ Ｄ ２．３０Ｅ＋０６ ３．３１Ｅ＋０７ ６．２５Ｅ－０６ ２８．７８１ ０．０８９ ［２１，３１，４０，７１－７２，１１６－１１７，１２０］
Ｂｌｏｇｃａｔａｌｏｇ ＵＷ １．０３Ｅ＋０４ ３．３４Ｅ＋０５ ６．３Ｅ－０３ ６４．７８０ ０．０３１ ［３１－３２，７０－７１，１１６，１２０］
Ｔｗｉｔｔｅｒ Ｄ／ＵＷ ５．２６Ｅ＋０７ １．９６Ｅ＋０９ ７．１０Ｅ－０７ ７４．６７８ ０．５６５ ［１０５，１２０］
ＤＢＬＰ ＵＤ ３．１７Ｅ＋０５ １．０５Ｅ＋０６ ２．０８Ｅ－０５ ６．６２２ ０．６３２ ［２１，３２，６９，７６，１１４－１１５，１１７，１１９］
引文
ＡｓｔｒｏＰｈ ＵＤ １．８７Ｅ＋０４ １．９８Ｅ＋０５ ５．７１Ｅ－０３ １７．３２３ ０．６３１ ［７０］
网络
ＣｉｔｅＳｅｅｒ Ｄ／ＵＷ ３．８４Ｅ＋０５ １．７５Ｅ＋０６ １．１９Ｅ－０５ ９．１１２ ０．３８５ ［６８，１０８，１１５］
Ｅｎｒｏｎ ＵＤ ３．６７Ｅ＋０４ １．８４Ｅ＋０５ ２．７３Ｅ－０４ １０．０２０ ０．４９７ ［７６］
通讯
ＥｕＡＬＬ Ｄ ２．６５Ｅ＋０５ ４．２０Ｅ＋０５ １．０４Ｅ－０５ ２．７５７ ０．０６７ ［７６］
网络
ｐｅｄｉａＥｎｇｌｉｓｈ Ｄ／ＵＷ ２．３９Ｅ＋０６ ５．０２Ｅ＋０６ ８．７５Ｅ－０７ ４．１９４ ０．０２１ ［１１８］
Ｃａｌｉｆｏｒｎｉａ ＵＤ／ＵＷ １．９７Ｅ＋０６ ２．７７Ｅ＋０６ １．４３Ｅ－０６ ２．８１５ ０．０４６ ［７６］
公路
Ｐｅｎｎｓｙｌｖａｎｉａ ＵＤ １．０９Ｅ＋０６ １．５４Ｅ＋０６ ２．６０Ｅ－０６ ２．８３４ ０．０４７ ［７６］
网络
Ｔｅｘａｓ ＵＤ １．３８Ｅ＋０６ １．９２Ｅ＋０６ ２．０２Ｅ－０６ ２．７８５ ０．０４７ ［７６］
Ｔａｌｋ ｎｅｔｗｏｒｋ Ｄ ２．３９Ｅ＋０６ ５．０２Ｅ＋０６ １．６３Ｅ－０６ ３．８９２ ０．０５３ ［７６］
维基
Ｖｏｔｅ ｎｅｔｗｏｒｋ Ｄ ７．１２Ｅ＋０３ １．０４Ｅ＋０５ ３．９８Ｅ－０３ ２８．３２３ ０．１４１ ［７６］
百科
Ｗｉｋｉｐｅｄｉａ Ｄ／Ｗ １．９９Ｅ＋０６ １．００Ｅ＋０９ １．４９Ｅ－０６ ５０４．２２０ ０．０４３ ［２１，３２，７０，１１９］
＃：Ｄ／ＵＤ／Ｗ／ＵＷ：有向／无向图／加权图／非加权图． ２４１４ 计 算 机 学 报 ２０１８年
数据集包含噪音数据，必须在使用之前进行清洗．例 这些多标签数据如何进行有效分类成为一个有待解
如合作网络面临着作者名的消歧问题，这将导致大 决的课题，同时也吸引了很多研究者的关注．根据样
量的噪音，使得网络与真实世界网络不一致；其次， 本数据拥有标签的多少，可以将分类问题分为单标
在不同数据集上比较相同的度量指标时，它们的性 签分类和多标签分类，然而，这两种分类都面临着
能等级通常不一致或者甚至相差很大，因此有必要 “维数灾难”的问题，尤其在是在大规模网络数据的
构建和维护用于网络表示学习的基准数据集．除了 背景环境下，这种问题更加明显，因此特征的低维度
基准的评测数据集之外，Ｎｉｕ等人［１２１］还设计了一种 表示是有效的解决方案之一．
并行化的图嵌入（Ｇｒａｐｈ Ｅｍｂｅｄｄｉｎｇ）代码库，该代 在网络标签分类应用场景中，网络部分顶点的
码库为当前图嵌入实现效率的对比提供了一个较强 标签是已知的，分类的目的是预测出剩余顶点的标
的基准方案． 签．该问题解决的通常流程是：首先，学习表示出每
４．２ 大规模复杂信息网络表示学习的应用场景和 个顶点的特征向量；然后，利用已知标签的顶点训练
评测指标 分类模型；最后，以未知标签顶点的向量表示作为该
网络表示学习是近两年来在复杂信息网络领域 分类模型的输入，推断出它们的标签类别．
中形成的新兴研究方向之一．通过学习得到良好的 在网络表示学习的过程中，如果利用标签信息，
网络特征表示，不仅仅能够解决目前大规模复杂信 往往可以提高标签分类的性能［１１７，１１９］．同时，网络表
息网络所存在的数据稀疏性以及动态性等问题，更 示学习的半监督分类可能会优于网络表示学习的无
能有效地应用到链接预测、顶点分类、可视化等衍生 监督分类，这是因为前者学习到的网络向量表示是
应用场景中． 和分类预测场景相关的．标签分类的评测指标通常
以链路预测研究为例，其不仅具有广泛的实际 采用汉明损失（Ｈａｍｍｉｎｇ ｌｏｓｓ）、覆盖度（ｃｏｖｅｒａｇｅ）、
应用价值，也具有重要的理论研究意义，特别是对相 １错误率（ｏｎｅ－ｅｒｒｏｒ）、排序损失（ｒａｎｋｉｎｇ ｌｏｓｓ）、分
关领域方面的推动和贡献．随着网络科学的快速发 类准确率（ｃｌａｓｓｉｆｉｃａｔｉｏｎ ａｃｃｕｒａｃｙ）以及平均精度
展，使得链路预测的研究与网络的结构以及演化紧 （ｃｌａｓｓｉｆｉｃａｔｉｏｎ ａｃｃｕｒａｃｙ）等作为评测指标．其中，尤
密联系起来，也从理论上帮助人们认识复杂网络演 其普遍使用分类准确率用于标签分类的性能评测．
化的机制．虽然，针对同一类网络，有很多模型都提 网络表示学习的另一应用场景是对学习到的网
供了可能的演化机制［１２２－１２３］．然而，很多链接预测研 络进行可视化展示［２１，３２，６９，７１］，具体的方法是提取顶
究主要针对特定的网络结构进行详细的分析和设 点的特征向量表示进行降维处理后，将网络中的顶
计，导致预测方法变得较为复杂，也越来越难以适应 点都映射到低维空间上．在可视化过程中需要顶点
大规模的网络结构． 标签信息，标签相同的顶点之间距离应该尽可能小．
现在用于链接预测的网络表示学习方法中，对 常用的高维向量降维算法有ｔ－ＳＮＥ［１１９］、ＰＥ［１２４］等．
于网络中顶点的特征学习不再是进行人工的构建， 例如，Ｔａｎｇ等人［２１］给出了利用ｔ－ＳＮＥ对ＤＢＬＰ数
而是利用顶点在网络中随机游走的方法，把传统网 据集中论文合作网络进行可视化的示例，在展示的
络中顶点的结构特征映射到连续的、维度固定的向 结果中每个顶点代表一个用户，每一种颜色代表一
量空间，从而得到大规模网络中顶点结构特征的分 个研究领域．可视化应用的评测指标则是相同颜色
布式表达．然后基于顶点间相似性预测这一前提假 的顶点在可视化空间中越集中，则表明网络表示学
设，计算不同顶点结构特征向量的相似性估计顶点 习算法的性能越好．信息网络表示学习的不同表现
之间存在链接的可能性．常用的链接预测精确度 形式，不仅可以应用到以上的应用场景中，而且还可
的评测指标主要有ＡＵＣ（Ａｒｅａ Ｕｎｄｅｒ ｔｈｅ Ｒｅｃｅｉｖｅｒ 以拓展到诸如推荐系统、隐私保护系统等其它应
Ｏｐｅｒａｔｉｎｇ Ｃｈａｒａｃｔｅｒｉｓｔｉｃ Ｃｕｒｖｅ）和精确度（ｐｒｅｃｉｓｉｏｎ） 用中．
两类，其中ＡＵＣ是最常用的一种评测指标，主要侧
重于从整体上衡量算法的准确度，而精确度主要考 ５ 研究难点和发展趋势
虑在只有评价部分链接（排序前Ｎ位）预测的准确
率．通过网络表示学习在链接预测应用场景下得到 大规模复杂信息网络存在广泛．对这类复杂网
的评测指标值都有了很大的性能提升，同时具备在 络特征的表示学习与抽取是当前的研究热点之一．
大规模网络上的可计算性［４０，７０，７１，７６，１１３］． 大规模复杂信息网络表示学习的研究对将其应用到
大规模信息网络积累了大量的多标签数据，对 网络顶点分类、推荐系统、链接预测、文本建模和可 １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２４１５
视化处理等方面具有重要的意义．大规模复杂信息 计算性能问题提出了更高的要求，如何根据特定的
网络具有的丰富性、动态变化性、隐私保护与信息残 应用，充分利用丰富信息，通过有效的特征融合后，
缺性、稀疏性等特点使得可见信息的隐含网络特征 发现隐含的有用网络特征表示，对于网络分布式特
学习成为可行但又具有很大的挑战的研究内容．虽 征的研究具有重要意义．
然已有不少的网络表示学习模型的工作被报道，但 （４）网络特征学习模型架构的独立性
是仍然存在许多难以解决的问题以及可进一步研究 复杂信息网络上人类行为的复杂性以及人们在
的方向，概括起来，未来的研究难点和发展趋势主要 网络交流过程中的各种反应和互动的复杂性，使得
包括网络特征提取模型的可容错性研究、动态适应 网络的特征提取工作变得非常困难．复杂信息网络
性研究、可融合性研究、独立架构研究、跨网络研究 存在着这种千差万别，使得研究者很难找到一种适
以及特殊子结构研究． 合各种类型网络的通用网络表示学习框架．不同表
（１）网络特征提取的可容错 示学习在各种网络中的准确性以及适用范围的广泛
由于现有大规模复杂信息网络来源多样化，同 性上也存在着一定的局限性．由于学习过程中只能
时其中所包含的噪音甚至错误数据也越来越多．例 依据一种或几种特征判断来进行网络表示，无法也
如很多用户会对自身的关注或者被关注数据进行隐 不可能将所有的网络特征情况都考虑进去，因此如
藏甚至错误标注；不同网站之间的链接存在恶意引 何对复杂信息网络更好地分析进而设计一个有效的
用或者盗用等情况．因此，针对这种大规模复杂网络 网络表示学习模型是一个很重要的问题，且也是相
中所存在的噪音数据应该如何有效地处理、过滤，甚 当困难的．另外，为了支持分析网络的应用，需要通
至是有效地识别，是当前研究需要考虑的问题之一． 过网络嵌入来保留网络结构，然而网络的真实结构
（２）网络动态变化的适应性 是未知的．顶点的相似性依赖于局部和全局网络结
传统的大规模网络的顶点结构特征学习主要侧 构，因此模型学习如何同时保留局部和全局结构是
重在对静态网络或增长型网络进行特征学习．例如 一个棘手的问题．许多现实世界的网络往往是非常
对新增链接的信息或新增顶点的特征进行学习．然 稀疏，因此仅仅利用非常有限的、观察到的链路来建
而，网络在新增信息的同时，也会伴随着信息的消 立学习模型是不足够达到令人满意的性能．
失．相对于信息的新增，网络顶点或链接的消失机制 （５）跨网络特征分布式表达模型
更加有待探索．作为网络动态结构变化的一部分，如 通常而言，针对单一网络的特征学习模型很难
何学习在高速动态变化环境下，由顶点或边消失而 有效地直接迁移到多个网络特征的并行或跨领域的
引起的特征关系的改变，这种改变与原有的新增顶 学习过程中来．目前，针对单一网络特征的学习还处
点或边之间存在何种关系，值得进一步的讨论． 于解决网络的动态性、大规模等基础问题上．网络分
（３）网络特征的可融合性 布式特征表达的跨领域迁移学习尚处于起步阶段．
大规模复杂信息网络所包含的特征信息不仅仅 针对多个网络之间的关联学习（又称为跨网络匹配
限于现有的结构特征，网络数据还包含多样化和异 问题）缺少现有的探讨．针对这一问题，我们认为应
质化的信息．由于网络上包含不同类型的实体以及 该先从小领域内的跨网络学习研究入手，找出不同
网络的链接关系多样化，针对这一问题网络表示学 的领域网络之间的区别与联系，通过保存共同特征
习的相关研究工作往往进行了简化处理，仅仅考虑 的提取模型，逐步的对现有方法进行改进和重构．
顶点的异构性，很少考虑链接的异构性．最后，由于 （６）特殊子结构的网络特征学习
复杂信息网络数据并不孤立存在，而是与各种数据 现有的众多网络表示学习的方法主要集中在对
类型组合存在，这些交互可以通过它们之间的联系 顶点的表示学习，即通过表示学习得到顶点的低维
明确地或隐含地形成．如对在同一网页内共同出现 度向量化表示形式，但对于网络的其它组件，包括
的图像和文本提供它们之间的明确链接，而文本到 边、多边形（如三角形、四边形）、网络路径等这些特
文本的链接由不同网络文档之间的超链接形成．另 殊子结构的表示学习缺乏探讨．针对网络其它组件
一方面，用户的交互活动可以被视为隐式反馈，其链 分布式特征表示学习的研究，可以进一步提升我们
接不同的网络中的组件．如果用户描述具有类似标 针对网络本身演化本身的认识，从而得出更多可能
签的多个图像，则可以合理地假定在这些图像之间 的应用方向．例如，可以得到包括复杂信息网络的点
存在语义关系．复杂信息网络数据所呈现的以上各 击流（互联网用户行为方面）的分布式特征表达
种特征问题导致了网络结构十分复杂，同时也对于 等等． ２４１６ 计 算 机 学 报 ２０１８年
［４］ Ｗａｎｇ Ｚ，Ｚｈａｎｇ Ｊ，Ｆｅｎｇ Ｊ．Ｋｎｏｗｌｅｄｇｅ ｇｒａｐｈ ｅｍｂｅｄｄｉｎｇ ｂｙ
６ 结束语 ｔｒａｎｓｌａｔｉｎｇ ｏｎ ｈｙｐｅｒｐｌａｎｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２８ｔｈ ＡＡＡＩ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｃａｌｉｆｏｒｎｉａ，ＵＳＡ，
２０１４：１１１２－１１１９
网络表示学习从表现形式上说，是将网络中任
［５］ Ｌｉｎ Ｙ，Ｌｉｕ Ｚ，Ｓｕｎ Ｍ．Ｌｅａｒｎｉｎｇ ｅｎｔｉｔｙ ａｎｄ ｒｅｌａｔｉｏｎ ｅｍｂｅｄ－
意顶点的结构特征映射到一个低维度的、连续的实
ｄｉｎｇｓ ｆｏｒ ｋｎｏｗｌｅｄｇｅ ｇｒａｐｈ ｃｏｍｐｌｅｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
值向量．从本质上讲，又常常使用矩阵分解方法来完
２９ｔｈ ＡＡＡＩ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ａｕｓｔｉｎ
成，但是在实际的优化过程中，又通常伴随着顶点内 Ｔｅｘａｓ，ＵＳＡ，２０１５：２１８１－２１８７
容或属性等性质的融合． ［６］ Ｚｈａｏ Ｊ，Ｘｕ Ｌ，Ｌｉｕ Ｋ．Ｋｎｏｗｌｅｇｅ ｇｒａｐｈ ｅｍｂｅｄｄｉｎｇ ｖｉａ
一般地，由于当前的大规模复杂信息网络数据 ｄｙｎａｍｉｃ ｍａｐｐｉｎｇ ｍａｔｒｉｘ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ５３ｒｄ ｏｆ ｔｈｅ
Ａｓｓｏｃｉａｔｉｏｎ ｆｏｒ Ｃｏｍｐｕｔａｔｉｏｎａｌ Ｌｉｎｇｕｉｓｔｉｃｓ．Ｂｅｉｊｉｎｇ，Ｃｈｉｎａ，
具有的各种特性，使得传统的网络分析方法显得捉
２０１５：６８７－６９６
襟见肘，因此针对大规模复杂信息网络表示学习研
［７］ Ｇｏｌｕｂ Ｇ Ｈ，Ｖａｎ Ｌｏａｎ Ｃ Ｆ． Ｍａｔｒｉｘ Ｃｏｍｐｕｔａｔｉｏｎｓ．
究因此应运而生．大规模学习网络的特征表示具有 Ｂａｌｔｉｍｏｒｅ，Ｍａｒｙｌａｎｄ，ＵＳＡ：ＪＨＵ Ｐｒｅｓｓ，２０１２
重要的实际意义和应用价值． ［８］ Ｒｏｗｅｉｓ Ｓ Ｔ，Ｓａｕｌ Ｌ Ｋ．Ｎｏｎｌｉｎｅａｒ ｄｉｍｅｎｓｉｏｎａｌｉｔｙ ｒｅｄｕｃｔｉｏｎ
首先，学习网络中每个顶点的特征向量表达可 ｂｙ ｌｏｃａｌｌｙ ｌｉｎｅａｒ ｅｍｂｅｄｄｉｎｇ．Ｓｃｉｅｎｃｅ，２０００，２９０（５５００）：
以有效缓解网络数据稀疏性问题．其次，把网络中不 ２３２３－２３２６
同类型的异质信息融合为整体，可以更好地解决特 ［９］ Ｔｅｎｅｎｂａｕｍ Ｊ Ｂ，Ｓｉｌｖａ Ｖ Ｄ，Ｌａｎｇｆｏｒｄ Ｊ Ｃ．Ａ ｇｌｏｂａｌ ｇｅｏｍｅｔｒｉｃ
ｆｒａｍｅｗｏｒｋ ｆｏｒ ｎｏｎｌｉｎｅａｒ ｄｉｍｅｎｓｉｏｎａｌｉｔｙ ｒｅｄｕｃｔｉｏｎ．Ｓｃｉｅｎｃｅ，
定问题．第三，网络的分布式向量表示能够高效地实
２０００，２９０（５５００）：２３１９－２３２３
现语义相关性操作，从而显著提升在大规模，特别是
［１０］ Ｂｅｌｋｉｎ Ｍ，Ｎｉｙｏｇｉ Ｐ．Ｌａｐｌａｃｉａｎ ｅｉｇｅｎｍａｐｓ ａｎｄ ｓｐｅｃｔｒａｌ
超大规模的网络中进行相似性顶点匹配的计算效
ｔｅｃｈｎｉｑｕｅｓ ｆｏｒ ｅｍｂｅｄｄｉｎｇ ａｎｄ ｃｌｕｓｔｅｒｉｎｇ．Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ
率．最后，学习网络的分布式表示使得在网络顶点分 Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ，２００２，１４（６）：５８５－５９１
类、推荐系统等方面应用前景得到了更大的拓展． ［１１］ Ｈｏｆｆ Ｐ Ｄ，Ｈａｎｄｃｏｃｋ Ｍ Ｓ．Ｌａｔｅｎｔ ｓｐａｃｅ ａｐｐｒｏａｃｈｅｓ ｔｏ ｓｏｃｉａｌ
本文概括了近年来关于大规模复杂信息网络表 ｎｅｔｗｏｒｋ ａｎａｌｙｓｉｓ．Ｊｏｕｒｎａｌ ｏｆ ｔｈｅ Ａｍｅｒｉｃａｎ Ｓｔａｔｉｓｔｉｃａｌ Ａｓｓｏｃｉ－
ａｔｉｏｎ，２００２，９７（１２）：１０９０－１０９８
示学习的主要研究模型及其特点．当前研究中，大多
［１２］ Ｌｉ Ｙ，Ｔａｒｌｏｗ Ｄ，Ｂｒｏｃｋｓｃｈｍｉｄｔ Ｍ．Ｇａｔｅｄ ｇｒａｐｈ ｓｅｑｕｅｎｃｅ
数模型是根据复杂信息网络的结构以及根据内容或
ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ４ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ
两者融合来进行顶点的特征表示学习．同时，我们可
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｌｅａｒｎｉｎｇ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ．Ｓａｎ Ｊｕａｎ，Ｐｕｅｒｔｏ
以看到，融合网络结构特征和内容特征的表示学习 Ｒｉｃｏ，２０１５：１－２０
能够更好地反映出一个网络特征的真实情况，使得 ［１３］ Ａｈｍｅｄ Ａ，Ｓｈｅｒｖａｓｈｉｄｚｅ Ｎ，Ｎａｒａｙａｎａｍｕｒｔｈｙ Ｓ．Ｄｉｓｔｒｉｂｕｔｅｄ
其学习得到的网络特征表示更具有意义与价值．除 ｌａｒｇｅ－ｓｃａｌｅ ｎａｔｕｒａｌ ｇｒａｐｈ ｆａｃｔｏｒｉｚａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
此之外，本文还对大规模复杂信息网络表示学习目 ２２ｎｄ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｒｉｏ ｄｅ
Ｊａｎｅｉｒｏ，Ｂｒａｚｉｌ，２０１３：３７－４８
前所面临的研究问题、已有的解决方案以及未来的
［１４］ Ｃｈｅｎ Ｘ，Ｌｉｕ Ｚ，Ｓｕｎ Ｍ．Ａ Ｕｎｉｆｉｅｄ ｍｏｄｅｌ ｆｏｒ ｗｏｒｄ ｓｅｎｓｅ
可行研究方向进行了总结和论述．希望本文对于大
ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ａｎｄ ｄｉｓａｍｂｉｇｕａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１４
规模复杂信息网络表示学习在国内的研究发展提供
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｅｍｐｉｒｉｃａｌ Ｍｅｔｈｏｄｓ ｉｎ Ｎａｔｕｒａｌ Ｌａｎｇｕａｇｅ
一些帮助． Ｐｒｏｃｅｓｓｉｎｇ．Ｄｏｈａ，Ｑａｔａｒ，２０１４：１０２５－１０３５
［１５］ Ｍｉｋｏｌｏｖ Ｔ，Ｓｕｔｓｋｅｖｅｒ Ｉ，Ｃｈｅｎ Ｋ．Ｄｉｓｔｒｉｂｕｔｅｄ ｒｅｐｒｅｓｅｎｔａ－
参 考 文 献 ｔｉｏｎｓ ｏｆ ｗｏｒｄｓ ａｎｄ ｐｈｒａｓｅｓ ａｎｄ ｔｈｅｉｒ ｃｏｍｐｏｓｉｔｉｏｎａｌｉｔｙ．
Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ，２０１３，
２６：３１１１－３１１９
［１］ Ｂｅｎｇｉｏ Ｙ，Ｃｏｕｒｖｉｌｌｅ Ａ，Ｖｉｎｃｅｎｔ Ｐ．Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ：
［１６］ Ｌｅ Ｑ Ｖ，Ｍｉｋｏｌｏｖ Ｔ．Ｄｉｓｔｒｉｂｕｔｅｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｏｆ ｓｅｎｔｅｎｃｅｓ
Ａ ｒｅｖｉｅｗ ａｎｄ ｎｅｗ ｐｅｒｓｐｅｃｔｉｖｅｓ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ
ａｎｄ ｄｏｃｕｍｅｎｔｓ．Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ，２０１４，４：１１８８－１１９６
Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０１３，３５（８）：
［１７］ Ｆｏｒｔｕｎａｔｏ Ｓ．Ｃｏｍｍｕｎｉｔｙ ｄｅｔｅｃｔｉｏｎ ｉｎ ｇｒａｐｈｓ．Ｐｈｙｓｉｃｓ
１７９８－１８２８
［２］ Ｔｕｒｉａｎ Ｊ，Ｒａｔｉｎｏｖ Ｌ，Ｂｅｎｇｉｏ Ｙ．Ｗｏｒｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ：Ａ
Ｒｅｐｏｒｔｓ，２０１０，４８６：７５－１７４．
ｓｉｍｐｌｅ ａｎｄ ｇｅｎｅｒａｌ ｍｅｔｈｏｄ ｆｏｒ ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ｌｅａｒｎｉｎｇ／／ ［１８］ Ｒａｐｏｐｏｒｔ Ａ．Ｃｏｎｔｒｉｂｕｔｉｏｎ ｔｏ ｔｈｅ ｔｈｅｏｒｙ ｏｆ ｒａｎｄｏｍ ａｎｄ ｂｉａｓｅｄ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｍｅｅｔｉｎｇ ｏｆ ｔｈｅ Ａｓｓｏｃｉａｔｉｏｎ ｆｏｒ Ｃｏｍｐｕｔａ－
ｎｅｔｓ．Ｂｕｌｌｅｔｉｎ ｏｆ Ｍａｔｈｅｍａｔｉｃａｌ Ｂｉｏｌｏｇｙ，１９５７，１９（４）：２５７－
ｔｉｏｎａｌ Ｌｉｎｇｕｉｓｔｉｃｓ．Ｕｐｐｓａｌａ，Ｓｗｅｄｅｎ，２０１０：３８４－３９４ ２７７
［３］ Ｂｏｒｄｅｓ Ａ，Ｕｓｕｎｉｅｒ Ｎ，Ｇａｒｃｉａ－Ｄｕｒａｎ Ａ．Ｔｒａｎｓｌａｔｉｎｇ ｅｍｂｅｄ－ ［１９］ Ｔｒａｖｅｒｓ Ｊ，Ｍｉｌｇｒａｍ Ｓ．Ａｎ ｅｘｐｅｒｉｍｅｎｔａｌ ｓｔｕｄｙ ｏｆ ｔｈｅ ｓｍａｌｌ
ｄｉｎｇｓ ｆｏｒ ｍｏｄｅｌｉｎｇ ｍｕｌｔｉ－ｒｅｌａｔｉｏｎａｌ ｄａｔａ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ｗｏｒｌｄ ｐｒｏｂｌｅｍ．Ｓｏｃｉｏｍｅｔｒｙ，１９６９，３２（４）：４２５－４４３
Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ． ［２０］ Ｎｅｗｍａｎ Ｍ Ｅ Ｊ．Ｔｈｅ ｓｔｒｕｃｔｕｒｅ ａｎｄ ｆｕｎｃｔｉｏｎ ｏｆ ｃｏｍｐｌｅｘ
Ｃａｍｂｒｉｄｇｅ，Ｅｎｇｌａｎｄ，２０１３：２７８７－２７９５ ｎｅｔｗｏｒｋｓ．Ｓｉａｍ Ｒｅｖｉｅｗ，２００３，４５（２）：１６７－２５６ １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２４１７
［２１］ Ｔａｎｇ Ｊ，Ｑｕ Ｍ，Ｗａｎｇ Ｍ．Ｌｉｎｅ：Ｌａｒｇｅ－ｓｃａｌｅ ｉｎｆｏｒｍａｔｉｏｎ ｏｆ ｔｈｅ ２１ｓｔ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ
ｎｅｔｗｏｒｋ ｅｍｂｅｄｄｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｋｎｏｗｌｅｄｇｅ Ｍａｎａｇｅｍｅｎｔ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１２：１５６７－
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１５： １５７１
１０６７－１０７７ ［３６］ Ｓｅｎ Ｐ，Ｎａｍａｔａ Ｇ，Ｂｉｌｇｉｃ Ｍ．Ｃｏｌｌｅｃｔｉｖｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｉｎ
［２２］ Ｃｏｌｌｏｂｅｒｔ Ｒ，Ｗｅｓｔｏｎ Ｊ，Ｂｏｔｔｏｕ Ｌ．Ｎａｔｕｒａｌ ｌａｎｇｕａｇｅ ｐｒｏｃｅｓｓｉｎｇ Ｎｅｔｗｏｒｋ ｄａｔａ ａｒｔｉｃｌｅｓ．Ａｉ Ｍａｇａｚｉｎｅ，２００８，２９（３）：９３－１０６
（ａｌｍｏｓｔ）ｆｒｏｍ ｓｃｒａｔｃｈ．Ｔｈｅ Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ ［３７］ Ｔｕ Ｃ，Ｌｉｕ Ｚ，Ｓｕｎ Ｍ．Ｉｎｆｅｒｒｉｎｇ ｃｏｒｒｅｓｐｏｎｄｅｎｃｅｓ ｆｒｏｍ ｍｕｌｔｉｐｌｅ
Ｒｅｓｅａｒｃｈ，２０１１，１２：２４９３－２５３７ ｓｏｕｒｃｅｓ ｆｏｒ ｍｉｃｒｏｂｌｏｇ ｕｓｅｒ ｔａｇｓ．Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ ｉｎ Ｃｏｍｐｕｔｅｒ
［２３］ Ｎｅｅｌａｋａｎｔａｎ Ａ，Ｓｈａｎｋａｒ Ｊ，Ｐａｓｓｏｓ Ａ．Ｅｆｆｉｃｉｅｎｔ ｎｏｎ－ｐａｒａ－ ａｎｄ Ｉｎｆｏｒｍａｔｉｏｎ Ｓｃｉｅｎｃｅ，２０１４，４８９：１－１２
ｍｅｔｒｉｃ ｅｓｔｉｍａｔｉｏｎ ｏｆ ｍｕｌｔｉｐｌｅ ｅｍｂｅｄｄｉｎｇｓ ｐｅｒ ｗｏｒｄ ｉｎ ｖｅｃｔｏｒ ［３８］ Ｂｈｕｙａｎ Ｍ Ｈ，Ｂｈａｔｔａｃｈａｒｙｙａ Ｄ Ｋ，Ｋａｌｉｔａ Ｊ Ｋ．Ｎｅｔｗｏｒｋ
Ｓｐａｃｅ．Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ，ａｒＸｉｖ．ｏｒｇ，２０１５，ｃｓ．ＳＩ：１－１２ ａｎｏｍａｌｙ ｄｅｔｅｃｔｉｏｎ：ｍｅｔｈｏｄｓ，ｓｙｓｔｅｍｓ ａｎｄ ｔｏｏｌｓ．ＩＥＥＥ
［２４］ Ｚｈｕａｎｇ Ｆ，Ｃｈｅｎｇ Ｘ，Ｌｕｏ Ｐ．Ｓｕｐｅｒｖｉｓｅｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ Ｓｕｒｖｅｙｓ ａｎｄ Ｔｕｔｏｒｉａｌｓ，２０１４，１６（１）：３０３－
ｌｅａｒｎｉｎｇ： Ｔｒａｎｓｆｅｒ ｌｅａｒｎｉｎｇ ｗｉｔｈ ｄｅｅｐ ａｕｔｏｅｎｃｏｄｅｒｓ／／ ３３６
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ［３９］ ＬüＬ，Ｚｈｏｕ Ｔ．Ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｉｎ ｃｏｍｐｌｅｘ ｎｅｔｗｏｒｋｓ：Ａ
Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｂｕｅｎｏｓ Ａｉｒｅｓ，Ａｒｇｅｎｔｉｎａ，２０１５： ｓｕｒｖｅｙ．Ｐｈｙｓｉｃａ Ａ Ｓｔａｔｉｓｔｉｃａｌ Ｍｅｃｈａｎｉｃｓ ａｎｄ Ｉｔｓ Ａｐｐｌｉｃａｔｉｏｎｓ，
４１１９－４１２５ ２０１１，３９０（６）：１１５０－１１７０
［２５］ Ｍａｉｒａｌ Ｊ，Ｐｏｎｃｅ Ｊ，Ｓａｐｉｒｏ Ｇ．Ｓｕｐｅｒｖｉｓｅｄ ｄｉｃｔｉｏｎａｒｙ ｌｅａｒｎｉｎｇ／／
［４０］ Ｌｉ Ｚｈｉ－Ｙｕ，Ｌｉａｎｇ Ｘｕｎ，Ｘｕ Ｚｈｉ－Ｍｉｎｇ．ＤＮＰＳ：Ｌｅａｒｎｉｎｇ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２１ｓｔ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ
ｄｉｓｔｒｉｂｕｔｅｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｏｆ ｄｙｎａｍｉｃ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ．Ｃｈｉｎｅｓｅ
Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｖａｎｃｏｕｖｅｒ，Ｃａｎａｄａ，２００８：１－８
Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１６，３９（４２）：１－１９（ｉｎ Ｃｈｉｎｅｓｅ）
［２６］Ｊｉａｎｇ Ｑ，Ｓｈａｏ Ｆ，Ｊｉａｎｇ Ｇ．Ｓｕｐｅｒｖｉｓｅｄ ｄｉｃｔｉｏｎａｒｙ ｌｅａｒｎｉｎｇ ｆｏｒ （李志宇，梁循，徐志明．ＤＮＰＳ：基于阻尼采样的大规模动
ｂｌｉｎｄ ｉｍａｇｅ ｑｕａｌｉｔｙ ａｓｓｅｓｓｍｅｎｔ ｕｓｉｎｇ ｑｕａｌｉｔｙ－ｃｏｎｓｔｒａｉｎｔ ｓｐａｒｓｅ 态社会网络结构特征表示学习．计算机学报，２０１６，３９（４２）：
ｃｏｄｉｎｇ．Ｊｏｕｒｎａｌ ｏｆ Ｖｉｓｕａｌ Ｃｏｍｍｕｎｉｃａｔｉｏｎ ａｎｄ Ｉｍａｇｅ Ｒｅｐｒｅ－ １－１９）
ｓｅｎｔａｔｉｏｎ，２０１５，３３：１２３－１３３
［４１］ Ｃｈｅｎ Ｍ，Ｙａｎｇ Ｑ，Ｔａｎｇ Ｘ．Ｄｉｒｅｃｔｅｄ ｇｒａｐｈ ｅｍｂｅｄｄｉｎｇ／／
［２７］ Ｏ′Ｓｈｅａ Ｔ Ｊ，Ｃｏｒｇａｎ Ｊ，Ｃｌａｎｃｙ Ｔ Ｃ．Ｕｎｓｕｐｅｒｖｉｓｅｄ ｒｅｐｒｅｓｅｎ－
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ
ｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｏｆ ｓｔｒｕｃｔｕｒｅｄ ｒａｄｉｏ ｃｏｍｍｕｎｉｃａｔｉｏｎ ｓｉｇｎａｌｓ／／
Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｈｙｄｅｒａｂａｄ，Ｉｎｄｉａ，２００７：２７０７－２７１２
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １ｓｔ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｗｏｒｋｓｈｏｐ ｏｎ Ｓｅｎｓｉｎｇ，
［４２］ Ｂｒａｎｄ Ｍ，Ｈｕａｎｇ Ｋ．Ａ ｕｎｉｆｙｉｎｇ ｔｈｅｏｒｅｍ ｆｏｒ ｓｐｅｃｔｒａｌ ｅｍｂｅｄ－
Ｐｒｏｃｅｓｓｉｎｇ ａｎｄ Ｌｅａｒｎｉｎｇ ｆｏｒ Ｉｎｔｅｌｌｉｇｅｎｔ Ｍａｃｈｉｎｅｓ．Ａａｌｂｏｒｇ，
ｄｉｎｇ ａｎｄ ｃｌｕｓｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ９ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ
Ｄｅｎｍａｒｋ，２０１６：１－５
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｋｓｈｏｐ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ ａｎｄ Ｓｔａｔｉｓ－
［２８］ Ｓｃｈｌｋｏｐｆ Ｂ，Ｐｌａｔｔ Ｊ，Ｈｏｆｍａｎｎ Ｔ．Ｅｆｆｉｃｉｅｎｔ ｓｐａｒｓｅ ｃｏｄｉｎｇ
ｔｉｃｓ．Ｆｌｏｒｉｄａ，ＵＳＡ，２００３：１－８
ａｌｇｏｒｉｔｈｍｓ．Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ
［４３］Ｊｏｌｌｉｆｆｅ Ｉ．Ｐｒｉｎｃｉｐａｌ Ｃｏｍｐｏｎｅｎｔ Ａｎａｌｙｓｉｓ．Ｈｏｂｏｋｅｎ，Ｎｅｗ
Ｓｙｓｔｅｍｓ，２００６，１９：８０１－８０８
Ｊｅｒｓｅｙ，ＵＳＡ：Ｊｏｈｎ Ｗｉｌｅｙ ａｎｄ Ｓｏｎｓ，Ｌｔｄ，２００２
［２９］ Ｈｙｖｒｉｎｅｎ Ａ，Ｏｊａ Ｅ．Ｉｎｄｅｐｅｎｄｅｎｔ ｃｏｍｐｏｎｅｎｔ ａｎａｌｙｓｉｓ：
［４４］Ｉｖａｎｏｖ Ｏ Ｕ，Ｂａｒｔｕｎｏｖ Ｓ Ｏ．Ｌｅａｒｎｉｎｇ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｉｎ
Ａｌｇｏｒｉｔｈｍｓ ａｎｄ ａｐｐｌｉｃａｔｉｏｎｓ．Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ，２０００，１３（４－
ｄｉｒｅｃｔｅｄ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ４ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ
５）：４１１－４３０
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｎａｌｙｓｉｓ ｏｆ Ｉｍａｇｅｓ，Ｓｏｃｉａｌ Ｎｅｔｗｏｒｋｓ ａｎｄ
［３０］ Ｍａ Ｒ，Ｗａｎｇ Ｊ，Ｓｏｎｇ Ｙ．Ｍｕｌｔｉ－ｍａｎｉｆｏｌｄ ｌｅａｒｎｉｎｇ ｕｓｉｎｇ ｌｏｃａｌｌｙ
Ｔｅｘｔｓ．Ｙｅｋａｔｅｒｉｎｂｕｒｇ，Ｒｕｓｓｉａ，２０１５：１９６－２０７
ｌｉｎｅａｒ ｅｍｂｅｄｄｉｎｇ（ＬＬＥ）ｎｏｎｌｉｎｅａｒ ｄｉｍｅｎｓｉｏｎａｌｉｔｙ ｒｅｄｕｃｔｉｏｎ．
Ｊｏｕｒｎａｌ ｏｆ Ｔｓｉｎｇｈｕａ Ｕｎｉｖｅｒｓｉｔｙ，２００８，４８（４）：５８２－５８５
［４５］ Ｔｅｈ Ｙ Ｗ，Ｒｏｗｅｉｓ Ｓ Ｔ．Ａｕｔｏｍａｔｉｃ ａｌｉｇｎｍｅｎｔ ｏｆ ｈｉｄｄｅｎ
［３１］ Ｐｅｒｏｚｚｉ Ｂ，Ａｌｒｆｏｕ Ｒ，Ｓｋｉｅｎａ Ｓ．Ｄｅｅｐｗａｌｋ：Ｏｎｌｉｎｅ ｌｅａｒｎｉｎｇ ｏｆ
ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｉｎ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａ－
ｓｏｃｉａｌ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０ｔｈ ＡＣＭ ＳＩＧＫＤＤ
ｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍ．Ｃａｍｂｒｉｄｇｅ，ＵＳＡ，２００２，１５：８４１－
８４８
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ
Ｍｉｎｉｎｇ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１４：７０１－７１０ ［４６］ Ｓｈａｗ Ｂ，Ｊｅｂａｒａ Ｔ．Ｓｔｒｕｃｔｕｒｅ ｐｒｅｓｅｒｖｉｎｇ ｅｍｂｅｄｄｉｎｇ／／
［３２］ Ｃａｏ Ｓ，Ｌｕ Ｗ，Ｘｕ Ｑ．Ｇｒａｒｅｐ：Ｌｅａｒｎｉｎｇ ｇｒａｐｈ ｒｅｐｒｅｓｅｎｔａ－ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ
ｔｉｏｎｓ ｗｉｔｈ ｇｌｏｂａｌ ｓｔｒｕｃｔｕｒａｌ ｉｎｆｏｒｍａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｌｅａｒｎｉｎｇ．Ｑｕｅｂｅｃ，Ｃａｎａｄａ，２００９：９３７－９４４
２４ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ ［４７］ Ｔａｌｗａｌｋａｒ Ａ，Ｋｕｍａｒ Ｓ，Ｍｏｈｒｉ Ｍ．Ｌａｒｇｅ－ｓｃａｌｅ ｓｖｄ ａｎｄ
Ｋｎｏｗｌｅｄｇｅ Ｍａｎａｇｅｍｅｎｔ．Ｍｅｌｂｏｕｒｎｅ，Ａｕｓｔｒａｌｉａ，２０１５：８９１－ ｍａｎｉｆｏｌｄ ｌｅａｒｎｉｎｇ．Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，
９００
２０１３，１４（１）：３１２９－３１５２
［３３］ Ａｎｇｅｌｏｖａ Ｒ，Ｋａｓｎｅｃｉ Ｇ，Ｗｅｉｋｕｍ Ｇ．Ｇｒａｆｆｉｔｉ：Ｇｒａｐｈ－ｂａｓｅｄ ［４８］ Ｂｏｒｇ Ｉ，Ｇｒｏｅｎｅｎ Ｐ．Ｍｏｄｅｒｎ ｍｕｌｔｉｄｉｍｅｎｓｉｏｎａｌ ｓｃａｌｉｎｇ：Ｔｈｅｏｒｙ
ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｉｎ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｎｅｔｗｏｒｋｓ．Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ， ａｎｄ ａｐｐｌｉｃａｔｉｏｎｓ．Ｊｏｕｒｎａｌ ｏｆ Ｅｄｕｃａｔｉｏｎａｌ Ｍｅａｓｕｒｅｍｅｎｔ，
２０１２，１５（２）：１３９－１７０ ２００６，４０（３）：２７７－２８０
［３４］Ｊｉ Ｍ，Ｈａｎ Ｊ，Ｄａｎｉｌｅｖｓｋｙ Ｍ．Ｒａｎｋｉｎｇ－ｂａｓｅｄ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｏｆ ［４９］ Ｔａｎｇ Ｌ，Ｌｉｕ Ｈ．Ｒｅｌａｔｉｏｎａｌ ｌｅａｒｎｉｎｇ ｖｉａ ｌａｔｅｎｔ ｓｏｃｉａｌ ｄｉｍｅｎ－
ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ｓｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １５ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ
１７ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｐａｒｉｓ，
Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｃａｌｉｆｏｒｎｉａ，ＵＳＡ，２０１１：１２９８－ Ｆｒａｎｃｅ，２００９：８１７－８２６
１３０６ ［５０］ Ｎｅｗｍａｎ Ｍ Ｅ．Ｍｏｄｕｌａｒｉｔｙ ａｎｄ ｃｏｍｍｕｎｉｔｙ ｓｔｒｕｃｔｕｒｅ ｉｎ
［３５］ Ｋｏｎｇ Ｘ，Ｙｕ Ｐ，Ｄｉｎｇ Ｙ．Ｍｅｔａ ｐａｔｈ－ｂａｓｅｄ ｃｏｌｌｅｃｔｉｖｅ ｃｌａｓｓｉｆｉ－ ｎｅｔｗｏｒｋｓ．Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｎａｔｉｏｎａｌ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ
ｃａｔｉｏｎ ｉｎ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｕｎｉｔｅｄ Ｓｔａｔｅｓ ｏｆ Ａｍｅｒｉｃａ，２００６，１０３（２３）：８５７７－８５８２ ２４１８ 计 算 机 学 报 ２０１８年
［５１］ Ｎｅｗｍａｎ Ｍ Ｅ．Ｆｉｎｄｉｎｇ ｃｏｍｍｕｎｉｔｙ ｓｔｒｕｃｔｕｒｅ ｉｎ ｎｅｔｗｏｒｋｓ ２０１６：２０１４－２０２３
ｕｓｉｎｇ ｔｈｅ ｅｉｇｅｎｖｅｃｔｏｒｓ ｏｆ ｍａｔｒｉｃｅｓ．Ｐｈｙｓｉｃａｌ Ｒｅｖｉｅｗ Ｅ Ｓｔａｔｉｓ－ ［６７］ Ｈａｍｉｌｔｏｎ Ｗ Ｌ，Ｙｉｎｇ Ｒ，Ｌｅｓｋｏｖｅｃ Ｊ．Ｉｎｄｕｃｔｉｖｅ ｒｅｐｒｅｓｅｎｔａ－
ｔｉｃａｌ Ｎｏｎｌｉｎｅａｒ ａｎｄ Ｓｏｆｔ Ｍａｔｔｅｒ Ｐｈｙｓｉｃｓ，２００６，７４（３）：９２－ ｔｉｏｎ ｌｅａｒｎｉｎｇ ｏｎ ｌａｒｇｅ ｇｒａｐｈｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：
１００ １７０６．０２２１６，２０１７．
［５２］ Ｓａｒｋａｒ Ｐ，Ｍｏｏｒｅ Ａ Ｗ．Ｄｙｎａｍｉｃ ｓｏｃｉａｌ ｎｅｔｗｏｒｋ ａｎａｌｙｓｉｓ ［６８］ Ｔｕ Ｃ，Ｗａｎｇ Ｈ，Ｚｅｎｇ Ｘ．Ｃｏｍｍｕｎｉｔｙ－ｅｎｈａｎｃｅｄ ｎｅｔｗｏｒｋ
ｕｓｉｎｇ ｌａｔｅｎｔ ｓｐａｃｅ ｍｏｄｅｌｓ．ＡＣＭ Ｓｉｇｋｄｄ Ｅｘｐｌｏｒａｔｉｏｎｓ Ｎｅｗｓ－ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｆｏｒ ｎｅｔｗｏｒｋ ａｎａｌｙｓｉｓ．ａｒＸｉｖ．ｏｒｇ，
ｌｅｔｔｅｒ，２００５，７（２）：３１－４０ ２０１６，ｃｓ．ＳＩ：１－８
［５３］ Ｙａｎｇ Ｊ，Ｌｅｓｋｏｖｅｃ Ｊ．Ｍｏｄｅｌｉｎｇ Ｉｎｆｏｒｍａｔｉｏｎ ｄｉｆｆｕｓｉｏｎ ｉｎ ［６９］ Ｔｕ Ｃ，Ｚｈａｎｇ Ｗ，Ｌｉｕ Ｚ．Ｍａｘ－ｍａｒｇｉｎ ｄｅｅｐｗａｌｋ：ｄｉｓｃｒｉｍｉｎａ－
ｉｍｐｌｉｃｉｔ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １０ｔｈ ＩＥＥＥ Ｉｎｔｅｒｎａ－ ｔｉｖｅ ｌｅａｒｎｉｎｇ ｏｆ ｎｅｔｗｏｒｋ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓｙｄｎｅｙ，Ａｕｓｔｒａｌｉａ，２０１０： ２５ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．
５９９－６０８ Ｃａｌｉｆｏｒｎｉａ，ＵＳＡ，２０１６：３８８９－３８９５
［５４］ Ｂｏｕｒｉｇａｕｌｔ Ｓ，Ｌａｇｎｉｅｒ Ｃ，Ｌａｍｐｒｉｅｒ Ｓ．Ｌｅａｒｎｉｎｇ ｓｏｃｉａｌ ［７０］ Ｇｒｏｖｅｒ Ａ，Ｌｅｓｋｏｖｅｃ Ｊ．Ｎｏｄｅ２ｖｅｃ：Ｓｃａｌａｂｌｅ ｆｅａｔｕｒｅ ｌｅａｒｎｉｎｇ
ｎｅｔｗｏｒｋ ｅｍｂｅｄｄｉｎｇｓ ｆｏｒ ｐｒｅｄｉｃｔｉｎｇ ｉｎｆｏｒｍａｔｉｏｎ ｄｉｆｆｕｓｉｏｎ／／ ｆｏｒ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２２ｎｄ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒ－
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ７ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ
Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１４：３９３－ Ｍｉｎｉｎｇ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１６：１－１０
４０２ ［７１］ Ｗａｎｇ Ｄ Ｘ，Ｃｕｉ Ｐ，Ｚｈｕ Ｗ．Ｓｔｒｕｃｔｕｒａｌ ｄｅｅｐ ｎｅｔｗｏｒｋ ｅｍｂｅｄ－
［５５］ ＬｅＣｕｎ Ｙ，Ｂｅｎｇｉｏ Ｙ，Ｈｉｎｔｏｎ Ｇ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ．Ｎａｔｕｒｅ， ｄｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２２ｎｄ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ
２０１５，５２１（７５５３）：４３６－４４４ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓａｎ
［５６］ Ｋａｌｃｈｂｒｅｎｎｅｒ Ｎ，Ｇｒｅｆｅｎｓｔｅｔｔｅ Ｅ，Ｂｌｕｎｓｏｍ Ｐ．Ａ ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１６：１２２５－１２３４
ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｆｏｒ ｍｏｄｅｌｌｉｎｇ ｓｅｎｔｅｎｃｅｓ．ａｒＸｉｖ．ｏｒｇ，２０１４， ［７２］ Ｐｅｒｏｚｚｉ Ｂ，Ｋｕｌｋａｒｎｉ Ｖ，Ｓｋｉｅｎａ Ｓ．Ｗａｌｋｌｅｔｓ：Ｍｕｌｔｉｓｃａｌｅ
ｃｓ．ＣＬ：１－１１ ｇｒａｐｈ ｅｍｂｅｄｄｉｎｇｓ ｆｏｒ ｉｎｔｅｒｐｒｅｔａｂｌｅ ｎｅｔｗｏｒｋ ｃｌａｓｓｉｆｉｃａｔｉｏｎ．
［５７］ Ｈｕａｎｇ Ｅ Ｈ，Ｓｏｃｈｅｒ Ｒ，Ｍａｎｎｉｎｇ Ｃ Ｄ．Ｉｍｐｒｏｖｉｎｇ ｗｏｒｄ ａｒＸｉｖ．ｏｒｇ，２０１６，ｃｓ．ＳＩ：１－１６
ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｖｉａ ｇｌｏｂａｌ ｃｏｎｔｅｘｔ ａｎｄ ｍｕｌｔｉｐｌｅ ｗｏｒｄ ｐｒｏｔｏｔｙｐｅｓ／／ ［７３］ Ｌｅｉ Ｃ，Ｒｕａｎ Ｊ．Ａ ｎｏｖｅｌ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ａｌｇｏｒｉｔｈｍ ｆｏｒ ｒｅｃｏｎ－
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ５０ｔｈ Ａｎｎｕａｌ Ｍｅｅｔｉｎｇ ｏｆ ｔｈｅ Ａｓｓｏｃｉａｔｉｏｎ ｓｔｒｕｃｔｉｎｇ ｐｒｏｔｅｉｎ－ｐｒｏｔｅｉｎ ｉｎｔｅｒａｃｔｉｏｎ ｎｅｔｗｏｒｋｓ ｂｙ ｔｏｐｏｌｏｇｉｃａｌ
ｆｏｒ Ｃｏｍｐｕｔａｔｉｏｎａｌ Ｌｉｎｇｕｉｓｔｉｃｓ．Ｓｔｒｏｕｄｓｂｕｒｇ，ＵＳＡ，２０１２： ｓｉｍｉｌａｒｉｔｙ．Ｂｉｏｉｎｆｏｒｍａｔｉｃｓ，２０１３，２９（３）：３５５－３６４
８７３－８８２ ［７４］ Ｆｉｒｅ Ｍ，Ｔｅｎｅｎｂｏｉｍ Ｌ，Ｌｅｓｓｅｒ Ｏ．Ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ ｉｎ ｓｏｃｉａｌ
［５８］ Ｂｅｎｇｉｏ Ｙ，Ｓｃｈｗｅｎｋ Ｈ，Ｓｅｎéｃａｌ Ｊ Ｓ．Ｉｎｎｏｖａｔｉｏｎｓ ｉｎ Ｍａｃｈｉｎｅ ｎｅｔｗｏｒｋｓ ｕｓｉｎｇ ｃｏｍｐｕｔａｔｉｏｎａｌｌｙ ｅｆｆｉｃｉｅｎｔ ｔｏｐｏｌｏｇｉｃａｌ
Ｌｅａｒｎｉｎｇ：Ｎｅｕｒａｌ Ｐｒｏｂａｂｉｌｉｓｔｉｃ Ｌａｎｇｕａｇｅ Ｍｏｄｅｌｓ．Ｂｅｒｌｉｎ， ｆｅａｔｕｒｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｔｈｉｒｄ Ｉｎｔｅｒｎａｔｉｏｎａｌ
Ｇｅｒｍａｎｙ：Ｓｐｒｉｎｇｅｒ，２００６ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｐｒｉｖａｃｙ，Ｓｅｃｕｒｉｔｙ，Ｒｉｓｋ ａｎｄ Ｔｒｕｓｔ．Ｍａｒｙｌａｎｄ，
［５９］ Ｍｉｋｏｌｏｖ Ｔ，Ｃｈｅｎ Ｋ，Ｃｏｒｒａｄｏ Ｇ．Ｅｆｆｉｃｉｅｎｔ ｅｓｔｉｍａｔｉｏｎ ｏｆ ｗｏｒｄ ＵＳＡ，２０１１：７３－８０
ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｉｎ ｖｅｃｔｏｒ ｓｐａｃｅ．ａｒＸｉｖ．ｏｒｇ，２０１３，ｃｓ．ＣＬ： ［７５］ Ｂｒａｎｄｏ Ｍ Ａ，Ｍｏｒｏ Ｍ Ｍ，Ｌｏｐｅｓ Ｇ Ｒ．Ｕｓｉｎｇ ｌｉｎｋ ｓｅｍａｎｔｉｃｓ
１－１２ ｔｏ ｒｅｃｏｍｍｅｎｄ ｃｏｌｌａｂｏｒａｔｉｏｎｓ ｉｎ ａｃａｄｅｍｉｃ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／
［６０］ Ｈｉｎｔｏｎ Ｇ Ｅ．Ｌｅａｒｎｉｎｇ ｄｉｓｔｒｉｂｕｔｅｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｏｆ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２２ｎｄ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ
ｃｏｎｃｅｐｔｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ８ｔｈ Ａｎｎｕａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ｔｈｅ Ｗｉｄｅ Ｗｅｂ．Ｒｉｏ ｄｅ Ｊａｎｅｉｒｏ，Ｂｒａｚｉｌ，２０１３：８３３－８４０
Ｃｏｇｎｉｔｉｖｅ Ｓｃｉｅｎｃｅ Ｓｏｃｉｅｔｙ．Ｍａｓｓ，ＵＳＡ，１９８６：１－１２ ［７６］ Ｌｉ Ｚｈｉ－Ｙｕ，Ｌｉａｎｇ Ｘｕｎ，Ｚｈｏｕ Ｘｉａｏ－Ｐｉｎｇ．Ａ ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ
［６１］ Ｂｅｎｇｉｏ Ｙ，Ｄｕｃｈａｒｍｅ Ｒ．Ａ ｎｅｕｒａｌ ｐｒｏｂａｂｉｌｉｓｔｉｃ ｌａｎｇｕａｇｅ ｍｅｔｈｏｄ ｆｏｒ ｌａｒｇｅ－ｓｃａｌｅ ｎｅｔｗｏｒｋｓ．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，
ｍｏｄｅｌ．Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，２００３，３（６）： ２０１６，３９（４２）：１－１８（ｉｎ Ｃｈｉｎｅｓｅ）
１１３７－１１５５ （李志宇，梁循，周小平．一种大规模网络中基于顶点结构特
［６２］ Ｍｏｒｉｎ Ｆ，Ｂｅｎｇｉｏ Ｙ．Ｈｉｅｒａｒｃｈｉｃａｌ ｐｒｏｂａｂｉｌｉｓｔｉｃ ｎｅｕｒａｌ ｎｅｔ－ 征映射的链接预测方法．计算机学报，２０１６，３９（４２）：１－１８）
ｗｏｒｋ ｌａｎｇｕａｇｅ ｍｏｄｅｌ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ［７７］ Ｓｔｅｙｖｅｒｓ Ｍ，Ｇｒｉｆｆｉｔｈｓ Ｔ．Ｐｒｏｂａｂｉｌｉｓｔｉｃ ｔｏｐｉｃ ｍｏｄｅｌｓ．Ｈａｎｄ－
Ｗｏｒｋｓｈｏｐ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ ａｎｄ Ｓｔａｔｉｓｔｉｃｓ．Ｂａｒｂａｄｏｓ， ｂｏｏｋ ｏｆ Ｌａｔｅｎｔ Ｓｅｍａｎｔｉｃ Ａｎａｌｙｓｉｓ，２００７，４２７（７）：４２４－４４０
２００５：２４６－２５２ ［７８］ Ｈｏｆｍａｎｎ Ｔ． Ｐｒｏｂａｂｉｌｉｓｔｉｃ ｌａｔｅｎｔ ｓｅｍａｎｔｉｃ ｉｎｄｅｘｉｎｇ／／
［６３］ Ｃｏｌｌｏｂｅｒｔ Ｒ，Ｗｅｓｔｏｎ Ｊ．Ａ ｕｎｉｆｉｅｄ ａｒｃｈｉｔｅｃｔｕｒｅ ｆｏｒ ｎａｔｕｒａｌ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２７ｔｈ Ａｎｎｕａｌ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ
ｌａｎｇｕａｇｅ ｐｒｏｃｅｓｓｉｎｇ：Ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｗｉｔｈ ｍｕｌｔｉｔａｓｋ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ
ｌｅａｒｎｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２５ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ Ｒｅｔｒｉｅｖａｌ．Ｓｈｅｆｆｉｅｌｄ，ＵＫ，２００４：５６－７３
ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｈｅｌｓｉｎｋｉ，Ｆｉｎｌａｎｄ，２００８：１６０－１６７ ［７９］ Ｂｌｅｉ Ｄ Ｍ，Ｎｇ Ａ Ｙ，Ｊｏｒｄａｎ Ｍ Ｉ．Ｌａｔｅｎｔ ｄｉｒｉｃｈｌｅｔ ａｌｌｏｃａｔｉｏｎ．
［６４］ Ｇｕｔｍａｎｎ Ｍ，Ｈｙｖｒｉｎｅｎ Ａ．Ｎｏｉｓｅ－ｃｏｎｔｒａｓｔｉｖｅ ｅｓｔｉｍａｔｉｏｎ：Ａ Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，２００３，３：９９３－１０２２
ｎｅｗ ｅｓｔｉｍａｔｉｏｎ ｐｒｉｎｃｉｐｌｅ ｆｏｒ ｕｎｎｏｒｍａｌｉｚｅｄ ｓｔａｔｉｓｔｉｃａｌ ｍｏｄｅｌｓ． ［８０］ Ｂｒａｎｔｓ Ｔ，Ｃｈｅｎ Ｆ，Ｔｓｏｃｈａｎｔａｒｉｄｉｓ Ｉ．Ｔｏｐｉｃ－ｂａｓｅｄ ｄｏｃｕｍｅｎｔ
Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，２０１０，９：２９７－３０４ ｓｅｇｍｅｎｔａｔｉｏｎ ｗｉｔｈ ｐｒｏｂａｂｉｌｉｓｔｉｃ ｌａｔｅｎｔ ｓｅｍａｎｔｉｃ ａｎａｌｙｓｉｓ／／
［６５］ Ｇｕｔｍａｎｎ Ｍ Ｕ，Ｈｙｖ，Ｒｉｎｅｎ Ａ．Ｎｏｉｓｅ－ｃｏｎｔｒａｓｔｉｖｅ ｅｓｔｉｍａｔｉｏｎ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＡＣＭ ＣＩＫＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
ｏｆ ｕｎｎｏｒｍａｌｉｚｅｄ ｓｔａｔｉｓｔｉｃａｌ ｍｏｄｅｌｓ，ｗｉｔｈ ａｐｐｌｉｃａｔｉｏｎｓ ｔｏ ｎａｔｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ ａｎｄ Ｋｎｏｗｌｅｄｇｅ Ｍａｎａｇｅｍｅｎｔ．Ｖｉｒｇｉｎｉａ，ＵＳＡ，
ｉｍａｇｅ ｓｔａｔｉｓｔｉｃｓ．Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ， ２００２：２１１－２１８
２０１２，１３（１）：３０７－３６１ ［８１］ Ｃｈａｎｇ Ｊ，Ｂｌｅｉ Ｄ Ｍ．Ｒｅｌａｔｉｏｎａｌ ｔｏｐｉｃ ｍｏｄｅｌｓ ｆｏｒ ｄｏｃｕｍｅｎｔ
［６６］ Ｎｉｅｐｅｒｔ Ｍ，Ａｈｍｅｄ Ｍ，Ｋｕｔｚｋｏｖ Ｋ．Ｌｅａｒｎｉｎｇ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １２ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ
ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｇｒａｐｈｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３３ｒｄ Ｉｎｔｅｒｎａ－ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ ａｎｄ Ｓｔａｔｉｓｔｉｃｓ．Ｆｌｏｒｉｄａ，ＵＳＡ，２００９：
ｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ， ８１－８８ １０期 齐金山等：大规模复杂信息网络表示学习：概念、方法与挑战 ２４１９
［８２］ Ｎａｌｌａｐａｔｉ Ｒ Ｍ，Ａｈｍｅｄ Ａ，Ｘｉｎｇ Ｅ Ｐ．Ｊｏｉｎｔ ｌａｔｅｎｔ ｔｏｐｉｃ ５２－５８
ｍｏｄｅｌｓ ｆｏｒ ｔｅｘｔ ａｎｄ ｃｉｔａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １４ｔｈ ＡＣＭ ［９５］ Ａｓｕｒ Ｓ，Ｐａｒｔｈａｓａｒａｔｈｙ Ｓ，Ｕｃａｒ Ｄ．Ａｎ ｅｖｅｎｔ－ｂａｓｅｄ ｆｒａｍｅｗｏｒｋ
ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ｆｏｒ ｃｈａｒａｃｔｅｒｉｚｉｎｇ ｔｈｅ ｅｖｏｌｕｔｉｏｎａｒｙ ｂｅｈａｖｉｏｒ ｏｆ ｉｎｔｅｒａｃｔｉｏｎ
ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｎｅｖａｄａ，ＵＳＡ，２００８：５４２－５５０ ｇｒａｐｈｓ．ＡＣＭ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ｆｒｏｍ
［８３］Ｉｗａｔａ Ｔ，Ｙａｍａｄａ Ｔ，Ｕｅｄａ Ｎ．Ｐｒｏｂａｂｉｌｉｓｔｉｃ ｌａｔｅｎｔ ｓｅｍａｎｔｉｃ Ｄａｔａ，２００９，３（４）：１６
ｖｉｓｕａｌｉｚａｔｉｏｎ：Ｔｏｐｉｃ ｍｏｄｅｌ ｆｏｒ ｖｉｓｕａｌｉｚｉｎｇ ｄｏｃｕｍｅｎｔｓ／／ ［９６］ Ｇｒｕｈｌ Ｄ，Ｌｉｂｅｎ－Ｎｏｗｅｌｌ Ｄ，Ｇｕｈａ Ｒ．Ｉｎｆｏｒｍａｔｉｏｎ ｄｉｆｆｕｓｉｏｎ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １４ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ ｔｈｒｏｕｇｈ ｂｌｏｇｓｐａｃｅ．ＡＣＭ ＳＩＧＫＤＤ Ｅｘｐｌｏｒａｔｉｏｎｓ Ｎｅｗｓｌｅｔｔｅｒ，
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｌａｓ ２００４，６（２）：４３－５２
Ｖｅｇａｓ，ＵＳＡ，２００８：３６３－３７１
［９７］ Ｌｅｓｋｏｖｅｃ Ｊ，Ｍｃｇｌｏｈｏｎ Ｍ，Ｆａｌｏｕｔｓｏｓ Ｃ．Ｃａｓｃａｄｉｎｇ ｂｅｈａｖｉｏｒ
［８４］ Ｌｅ Ｔ Ｍ Ｖ，Ｌａｕｗ Ｈ Ｗ．Ｐｒｏｂａｂｉｌｉｓｔｉｃ ｌａｔｅｎｔ ｄｏｃｕｍｅｎｔ
ｉｎ ｌａｒｇｅ ｂｌｏｇ ｇｒａｐｈｓ．ＳＩＡＭ ｏｎ Ｄａｔａ Ｍｉｎｉｎｇ，２００７，１５（１）：
ｎｅｔｗｏｒｋ ｅｍｂｅｄｄｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １４ｔｈ ＩＥＥＥ Ｉｎｔｅｒｎａ－
９：３－９：５６
ｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓｈｅｎｚｈｅｎ，Ｃｈｉｎａ，２０１４：
［９８］ Ｋｌｅｉｎｂｅｒｇ Ｊ．Ｔｈｅ ｓｍａｌｌ－ｗｏｒｌｄ ｐｈｅｎｏｍｅｎｏｎ：Ａｎ ａｌｇｏｒｉｔｈｍｉｃ
２７０－２７９
ｐｅｒｓｐｅｃｔｉｖｅ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３２ｎｄ Ａｎｎｕａｌ ＡＣＭ Ｓｙｍｐｏｓｉｕｍ
［８５］ Ｗａｎｇ Ｘ，Ｍｃｃａｌｌｕｍ Ａ．Ｔｏｐｉｃｓ ｏｖｅｒ ｔｉｍｅ：Ａ ｎｏｎ－Ｍａｒｋｏｖ
ｏｎ Ｔｈｅｏｒｙ ｏｆ Ｃｏｍｐｕｔｉｎｇ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０００：１６３－１７０
ｃｏｎｔｉｎｕｏｕｓ－ｔｉｍｅ ｍｏｄｅｌ ｏｆ ｔｏｐｉｃａｌ ｔｒｅｎｄｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
［９９］ Ｐａｌｌａ Ｇ，Ｄｅｒｅｎｙｉ Ｉ，Ｆａｒｋａｓ Ｉ，Ｖｉｃｓｅｋ Ｔ．Ｕｎｃｏｖｅｒｉｎｇ ｔｈｅ
１２ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ
ｏｖｅｒｌａｐｐｉｎｇ ｃｏｍｍｕｎｉｔｙ ｓｔｒｕｃｔｕｒｅｓ ｏｆ ｃｏｍｐｌｅｘ ｎｅｔｗｏｒｋｓ ｉｎ
Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｐｈｉｌａｄｅｌｐｈｉａ，ＵＳＡ，２００６：
ｎａｔｕｒｅ ａｎｄ ｓｏｃｉｅｔｙ．Ｎａｔｕｒｅ，２００５，４３５（７０４３）：８１４－８１８
４２４－４３３
［８６］ Ｌｉｎ Ｓ，Ｗａｎｇ Ｆ，Ｈｕ Ｑ．Ｅｘｔｒａｃｔｉｎｇ ｓｏｃｉａｌ ｅｖｅｎｔｓ ｆｏｒ ｌｅａｒｎｉｎｇ ［１００］ Ｌａｎｃｉｃｈｉｎｅｔｔｉ Ａ，Ｒａｄｉｃｃｈｉ Ｆ，Ｒａｍａｓｃｏ Ｊ Ｊ．Ｆｉｎｄｉｎｇ ｓｔａｔｉｓｔｉ－
ｂｅｔｔｅｒ ｉｎｆｏｒｍａｔｉｏｎ ｄｉｆｆｕｓｉｏｎ ｍｏｄｅｌｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ｃａｌｌｙ ｓｉｇｎｉｆｉｃａｎｔ ｃｏｍｍｕｎｉｔｉｅｓ ｉｎ ｎｅｔｗｏｒｋｓ．ＰｌｏＳ Ｏｎｅ，２０１１，
６（４）：３３６－３３８
１９ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ
Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｃｈｉｃａｇｏ，ＵＳＡ，２０１３：３６５－３７３ ［１０１］ Ａｈｎ Ｙ Ｙ，Ｂａｇｒｏｗ Ｊ Ｐ，Ｌｅｈｍａｎｎ Ｓ．Ｌｉｎｋ ｃｏｍｍｕｎｉｔｉｅｓ
［８７］ Ｔａｎｇ Ｊ，Ｓｕｎ Ｊ，Ｗａｎｇ Ｃ．Ｓｏｃｉａｌ ｉｎｆｌｕｅｎｃｅ ａｎａｌｙｓｉｓ ｉｎ ｌａｒｇｅ－ ｒｅｖｅａｌ ｍｕｌｔｉｓｃａｌｅ ｃｏｍｐｌｅｘｉｔｙ ｉｎ ｎｅｔｗｏｒｋｓ．Ｎａｔｕｒｅ，２０１０，
ｓｃａｌｅ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １５ｔｈ ＡＣＭ ＳＩＧＫＤＤ ４６６（７３０７）：７６１－７６４
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ ［１０２］ Ｗｈｉｔｅ Ｓ，Ｓｍｙｔｈ Ｐ．Ａ ｓｐｅｃｔｒａｌ ｃｌｕｓｔｅｒｉｎｇ ａｐｐｒｏａｃｈ ｔｏ ｆｉｎｄｉｎｇ
Ｍｉｎｉｎｇ．Ｐａｒｉｓ，Ｆｒａｎｃｅ，２００９：８０７－８１６ ｃｏｍｍｕｎｉｔｉｅｓ ｉｎ ｇｒａｐｈｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２００５ＳＩＡＭ
［８８］ Ｌｏｕ Ｔ，Ｔａｎｇ Ｊ．Ｍｉｎｉｎｇ ｓｔｒｕｃｔｕｒａｌ ｈｏｌｅ ｓｐａｎｎｅｒｓ ｔｈｒｏｕｇｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｄａｔａ Ｍｉｎｉｎｇ．Ｐｈｉｌａｄｅｌｐｈｉａ，
ｉｎｆｏｒｍａｔｉｏｎ ｄｉｆｆｕｓｉｏｎ ｉｎ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＵＳＡ，２００５：２７４－２８５
２２ｎｄ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ．Ｒｉｏ ｄｅ ［１０３］ Ｌａｎｃｉｃｈｉｎｅｔｔｉ Ａ，Ｆｏｒｔｕｎａｔｏ Ｓ，Ｋｅｒｔéｓｚ Ｊ．Ｄｅｔｅｃｔｉｎｇ ｔｈｅ
Ｊａｎｅｉｒｏ，Ｂｒａｚｉｌ，２０１３：８２５－８３６ ｏｖｅｒｌａｐｐｉｎｇ ａｎｄ ｈｉｅｒａｒｃｈｉｃａｌ ｃｏｍｍｕｎｉｔｙ ｓｔｒｕｃｔｕｒｅ ｉｎ ｃｏｍｐｌｅｘ
［８９］ Ｈｕ Ｚ，Ｙａｏ Ｊ，Ｃｕｉ Ｂ．Ｃｏｍｍｕｎｉｔｙ ｌｅｖｅｌ ｄｉｆｆｕｓｉｏｎ ｅｘｔｒａｃｔｉｏｎ／／ ｎｅｔｗｏｒｋｓ．Ｎｅｗ Ｊｏｕｒｎａｌ ｏｆ Ｐｈｙｓｉｃｓ，２００９，１１（３）：１９－４４
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１５ ＡＣＭ ＳＩＧＭＯＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ ［１０４］ Ｙａｎｇ Ｃ，Ｌｉｕ Ｚ Ｙ，Ｚｈａｏ Ｄ Ｌ．Ｎｅｔｗｏｒｋ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｎａｇｅｍｅｎｔ ｏｆ Ｄａｔａ．Ｍｅｌｂｏｕｒｎｅ，Ａｕｓｔｒａｌｉａ， ｗｉｔｈ ｒｉｃｈ ｔｅｘｔ ｉｎｆｏｒｍａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ Ｉｎｔｅｒｎａ－
２０１５：１５５５－１５６９
ｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｂｕｅｎｏｓ
［９０］ Ｌｅｓｋｏｖｅｃ Ｊ，Ｋｌｅｉｎｂｅｒｇ Ｊ，Ｆａｌｏｕｔｓｏｓ Ｃ．Ｇｒａｐｈｓ ｏｖｅｒ ｔｉｍｅ： Ａｉｒｅｓ，Ａｒｇｅｎｔｉｎａ，２０１５：２１１１－２１１７
Ｄｅｎｓｉｆｉｃａｔｉｏｎ ｌａｗｓ，ｓｈｒｉｎｋｉｎｇ ｄｉａｍｅｔｅｒｓ ａｎｄ ｐｏｓｓｉｂｌｅ ［１０５］ Ｚｈａｎｇ Ｚ，Ｚｈａｏ Ｋ，Ｚｈａ Ｈ．Ｉｎｄｕｃｉｂｌｅ ｒｅｇｕｌａｒｉｚａｔｉｏｎ ｆｏｒ
ｅｘｐｌａｎａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １１ｔｈ ＡＣＭ ＳＩＧＫＤＤ
ｌｏｗ－ｒａｎｋ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎｓ ｆｏｒ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ．
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｎｅｕｒｏｃｏｍｐｕｔｉｎｇ，２０１２，９７（１）：５２－６２
Ｍｉｎｉｎｇ．Ｃｈｉｃａｇｏ，ＵＳＡ，２００５：１７７－１８７
［１０６］ Ｙｕ Ｈ Ｆ，Ｊａｉｎ Ｐ，Ｋａｒ Ｐ．Ｌａｒｇｅ－ｓｃａｌｅ ｍｕｌｔｉ－ｌａｂｅｌ ｌｅａｒｎｉｎｇ
［９１］ Ｂａｃｋｓｔｒｏｍ Ｌ，Ｈｕｔｔｅｎｌｏｃｈｅｒ Ｄ，Ｋｌｅｉｎｂｅｒｇ Ｊ．Ｇｒｏｕｐ ｆｏｒｍａｔｉｏｎ
ｗｉｔｈ ｍｉｓｓｉｎｇ ｌａｂｅｌｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ３１ｓｔ Ｉｎｔｅｒｎａｔｉｏｎａｌ
ｉｎ ｌａｒｇｅ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ：Ｍｅｍｂｅｒｓｈｉｐ，ｇｒｏｗｔｈ，ａｎｄ ｅｖｏｌｕｔｉｏｎ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｂｅｉｊｉｎｇ，Ｃｈｉｎａ，２０１３：
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １２ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ
５９３－６０１
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．
［１０７］ Ｌｉｂｅｎ－Ｎｏｗｅｌｌ Ｄ，Ｋｌｅｉｎｂｅｒｇ Ｊ．Ｔｈｅ ｌｉｎｋ－ｐｒｅｄｉｃｔｉｏｎ ｐｒｏｂｌｅｍ
Ｐｈｉｌａｄｅｌｐｈｉａ，ＵＳＡ，２００６：４４－５４
ｆｏｒ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ．Ｊｏｕｒｎａｌ ｏｆ ｔｈｅ Ａｓｓｏｃｉａｔｉｏｎ ｆｏｒ Ｉｎｆｏｒｍａｔｉｏｎ
［９２］ Ｔｏｙｏｄａ Ｍ，Ｋｉｔｓｕｒｅｇａｗａ Ｍ．Ｅｘｔｒａｃｔｉｎｇ ｅｖｏｌｕｔｉｏｎ ｏｆ ｗｅｂ
Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，２００７，５８（７）：１０１９－１０３１
ｃｏｍｍｕｎｉｔｉｅｓ ｆｒｏｍ ａ ｓｅｒｉｅｓ ｏｆ ｗｅｂ ａｒｃｈｉｖｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
［１０８］ Ｇａｎｅｓｈ Ｊ，Ｓｏｕｍｙａｊｉｔ Ｇ，Ｍａｎｉｓｈ Ｇ．Ａｕｔｈｏｒ２ｖｅｃ：Ｌｅａｒｎｉｎｇ
ｔｈｅ １４ｔｈ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｈｙｐｅｒｔｅｘｔ ａｎｄ Ｈｙｐｅｒｍｅｄｉａ．
Ｐｅｎｎｓｙｌｖａｎｉａ，ＵＳＡ，２００３：２８－３７
ａｕｔｈｏｒ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｂｙ ｃｏｍｂｉｎｉｎｇ ｃｏｎｔｅｎｔ ａｎｄ ｌｉｎｋ
［９３］ Ｂｅｒｇｅｒｗｏｌｆ Ｔ Ｙ，Ｓａｉａ Ｊ．Ａ ｆｒａｍｅｗｏｒｋ ｆｏｒ ａｎａｌｙｓｉｓ ｏｆ ｄｙｎａｍｉｃ ｉｎｆｏｒｍａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２５ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｗｏｒｌｄ
ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １２ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｗｉｄｅ Ｗｅｂ Ｃｏｎｆｅｒｅｎｃｅ．Ｍｏｎｔｒéａｌ，Ｃａｎａｄａ，２０１６：１－２
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ ［１０９］ Ｚｈｕ Ｘ，Ｓｏｂｈａｎｉ Ｐ，Ｇｕｏ Ｈ．Ｉｍｐｒｏｖｅｄ ｓｅｍａｎｔｉｃ ｒｅｐｒｅｓｅｎｔａ－
Ｍｉｎｉｎｇ．Ｐｈｉｌａｄｅｌｐｈｉａ，ＵＳＡ，２００６：５２３－５２８ ｔｉｏｎｓ ｆｒｏｍ ｔｒｅｅ－ｓｔｒｕｃｔｕｒｅｄ ｌｏｎｇ ｓｈｏｒｔ－ｔｅｒｍ ｍｅｍｏｒｙ ｎｅｔｗｏｒｋｓ．
［９４］ Ｆａｌｋｏｗｓｋｉ Ｔ，Ｂａｒｔｅｌｈｅｉｍｅｒ Ｊ，Ｓｐｉｌｉｏｐｏｕｌｏｕ Ｍ．Ｍｉｎｉｎｇ ａｎｄ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ，ａｒＸｉｖ．ｏｒｇ，２０１５，ｃｓ．ＳＩ：１－１１
ｖｉｓｕａｌｉｚｉｎｇ ｔｈｅ ｅｖｏｌｕｔｉｏｎ ｏｆ ｓｕｂｇｒｏｕｐｓ ｉｎ ｓｏｃｉａｌ ｎｅｔｗｏｒｋｓ／／ ［１１０］ Ｃｏｈｎ Ｄ．Ｔｈｅ ｍｉｓｓｉｎｇ ｌｉｎｋ—Ａ ｐｒｏｂａｂｉｌｉｓｔｉｃ ｍｏｄｅｌ ｏｆ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２００６ＩＥＥＥ／ＷＩＣ／ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ ｄｏｃｕｍｅｎｔ ｃｏｎｔｅｎｔ ａｎｄ ｈｙｐｅｒｔｅｘｔ ｃｏｎｎｅｃｔｉｖｉｔｙ．Ａｄｖａｎｃｅｓ ｉｎ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｈｏｎｇ Ｋｏｎｇ，Ｃｈｉｎａ，２００６： Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ，２００１，１３：４３０－４３６ ２４２０ 计 算 机 学 报 ２０１８年
［１１１］ Ｍｅｉ Ｑ，Ｃａｉ Ｄ，Ｚｈａｎｇ Ｄ．Ｔｏｐｉｃ ｍｏｄｅｌｉｎｇ ｗｉｔｈ ｎｅｔｗｏｒｋ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｎｅｗ Ｙｏｒｋ，
ｒｅｇｕｌａｒｉｚａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １７ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＵＳＡ，２０１４：３７３－３８２
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ ２００８．Ｂｅｉｊｉｎｇ，Ｃｈｉｎａ， ［１１８］ Ｚｈａｏ Ｙ，Ｌｉｕ Ｚ，Ｓｕｎ Ｍ．Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｆｏｒ ｍｅａｓｕｒｉｎｇ
２００８：１０１－１１０ ｅｎｔｉｔｙ ｒｅｌａｔｅｄｎｅｓｓ ｗｉｔｈ ｒｉｃｈ ｉｎｆｏｒｍａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
［１１２］ Ｚｈｕ Ｘ，Ｇｈａｈｒａｍａｎｉ Ｚ，Ｌａｆｆｅｒｔｙ Ｊ Ｄ．Ｓｅｍｉ－ｓｕｐｅｒｖｉｓｅｄ ２４ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉ－
ｌｅａｒｎｉｎｇ ｕｓｉｎｇ ｇａｕｓｓｉａｎ ｆｉｅｌｄｓ ａｎｄ ｈａｒｍｏｎｉｃ ｆｕｎｃｔｉｏｎｓ／／ ｇｅｎｃｅ．Ｂｕｅｎｏｓ Ａｉｒｅｓ，Ａｒｇｅｎｔｉｎａ，２０１５：１４１２－１４１８
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ［１１９］ Ｔａｎｇ Ｊ，Ｑｕ Ｍ，Ｍｅｉ Ｑ．Ｐｔｅ：Ｐｒｅｄｉｃｔｉｖｅ ｔｅｘｔ ｅｍｂｅｄｄｉｎｇ
ＭａｃｈｉｎｅＬｅａｒｎｉｎｇ．Ｗａｓｈｉｎｇｔｏｎ，ＵＳＡ，２００３：９１２－９１９ ｔｈｒｏｕｇｈ ｌａｒｇｅ－ｓｃａｌｅ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｔｅｘｔ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
［１１３］ Ｌｉ Ｊ，Ｒｉｔｔｅｒ Ａ，Ｄａｎ Ｊ．Ｌｅａｒｎｉｎｇ ｍｕｌｔｉ－ｆａｃｅｔｅｄ ｒｅｐｒｅｓｅｎｔａ－ ｏｆ ｔｈｅ ２１ｓｔ ＡＣＭ ＳＩＧＫＤＤ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ
ｔｉｏｎｓ ｏｆ ｉｎｄｉｖｉｄｕａｌｓ ｆｒｏｍ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｅｖｉｄｅｎｃｅ ｕｓｉｎｇ Ｄｉｓｃｏｖｅｒｙ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓｙｄｎｅｙ，Ａｕｓｔｒａｌｉａ，２０１５：
ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ，ａｒＸｉｖ．ｏｒｇ，２０１５， １１６５－１１７４
ｃｓ．ＳＩ：１－１３ ［１２０］ Ｃｈａｎｇ Ｓ，Ｈａｎ Ｗ，Ｔａｎｇ Ｊ．Ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｎｅｔｗｏｒｋ ｅｍｂｅｄ－
［１１４］ Ｓｕｎ Ｘ，Ｇｕｏ Ｊ，Ｄｉｎｇ Ｘ．Ａ ｇｅｎｅｒａｌ ｆｒａｍｅｗｏｒｋ ｆｏｒ ｃｏｎｔｅｎｔ－ ｄｉｎｇ ｖｉａ ｄｅｅｐ ａｒｃｈｉｔｅｃｔｕｒｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２１ｓｔ ＡＣＭ
ｅｎｈａｎｃｅｄ ｎｅｔｗｏｒｋ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ．ａｒＸｉｖ．ｏｒｇ， ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ
２０１６，ｃｓ．ＳＩ：１－８ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．Ｓｙｄｎｅｙ，Ａｕｓｔｒａｌｉａ，２０１５：１１９－１２８
［１１５］ Ｐａｎ Ｓ，Ｗｕ Ｊ，Ｚｈｕ Ｘ．Ｔｒｉ－ｐａｒｔｙ ｄｅｅｐ ｎｅｔｗｏｒｋ ｒｅｐｒｅｓｅｎｔａ－ ［１２１］ Ｎｉｕ Ｘ Ｆ，Ｌｉ Ｗ Ｊ．ＰａｒａＧｒａｐｈＥ：Ａ ｌｉｂｒａｒｙ ｆｏｒ ｐａｒａｌｌｅｌ
ｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２５ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｋｎｏｗｌｅｄｇｅ ｇｒａｐｈ ｅｍｂｅｄｄｉｎｇ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：
ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２０１６：１８９５－ １７０３．０５６１４，２０１７
１９０１ ［１２２］ Ａｌｂｅｒｔ Ｒ，Ｂａｒａｂｓｉ Ａ Ｌ．Ｓｔａｔｉｓｔｉｃａｌ ｍｅｃｈａｎｉｃｓ ｏｆ ｃｏｍｐｌｅｘ
［１１６］ Ｔａｎｇ Ｌ，Ｌｉｕ Ｈ．Ｌｅｖｅｒａｇｉｎｇ ｓｏｃｉａｌ ｍｅｄｉａ ｎｅｔｗｏｒｋｓ ｆｏｒ ｎｅｔｗｏｒｋｓ．Ｒｅｖｉｅｗ ｏｆ Ｍｏｄｅｒｎ Ｐｈｙｓｉｃｓ，２００２，７４（１）：４７－９７
ｃｌａｓｓｉｆｉｃａｔｉｏｎ．Ｄａｔａ Ｍｉｎｉｎｇ ａｎｄ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ， ［１２３］ Ｄｏｒｏｇｏｖｔｓｅｖ Ｓ Ｎ，Ｍｅｎｄｅｓ Ｊ Ｆ Ｆ．Ｅｖｏｌｕｔｉｏｎ ｏｆ ｎｅｔｗｏｒｋｓ．
２０１１，２３（３）：４４７－４７８ Ａｄｖａｎｃｅｓ ｉｎ Ｐｈｙｓｉｃｓ，２００２，５１（４）：１０７９－１１８７
［１１７］Ｊａｃｏｂ Ｙ，Ｄｅｎｏｙｅｒ Ｌ，Ｇａｌｌｉｎａｒｉ Ｐ．Ｌｅａｒｎｉｎｇ ｌａｔｅｎｔ ｒｅｐｒｅｓｅｎ－ ［１２４］Ｉｗａｔａ Ｔ，Ｓａｉｔｏ Ｋ，Ｕｅｄａ Ｎ．Ｐａｒａｍｅｔｒｉｃ ｅｍｂｅｄｄｉｎｇ ｆｏｒ ｃｌａｓｓ
ｔａｔｉｏｎｓ ｏｆ ｎｏｄｅｓ ｆｏｒ ｃｌａｓｓｉｆｙｉｎｇ ｉｎ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｓｏｃｉａｌ ｖｉｓｕａｌｉｚａｔｉｏｎ．Ｎｅｕｒａｌ Ｃｏｍｐｕｔａｔｉｏｎ，２００７，１９（９）：２５３６－
ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ７ｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ ２５５６
ＱＩ Ｊｉｎ－Ｓｈａｎ，ｂｏｒｎ ｉｎ １９７７，Ｐｈ．Ｄ． ｓｕｐｐｏｒｔ ｖｅｃｔｏｒ ｍａｃｈｉｎｅ ａｎｄ ｓｏｃｉａｌ ｃｏｍｐｕｔｉｎｇ．
ｃａｎｄｉｄａｔｅ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ＬＩ Ｚｈｉ－Ｙｕ，ｂｏｒｎ ｉｎ １９９１，Ｐｈ．Ｄ．ｃａｎｄｉｄａｔｅ．Ｈｉｓ
ｓｏｃｉａｌ ｃｏｍｐｕｔｉｎｇ，ｄａｔａ ｍｉｎｉｎｇ． ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｓｏｃｉａｌ ｃｏｍｐｕｔｉｎｇ，Ｗｅｂ ｍｉｎｉｎｇ ａｎｄ
ｎａｔｕｒａｌ ｌａｎｇｕａｇｅ ｐｒｏｃｅｓｓｉｎｇ．
ＣＨＥＮ Ｙａｎ－Ｆａｎｇ，ｂｏｒｎ ｉｎ １９９２，Ｐｈ．Ｄ．ｃａｎｄｉｄａｔｅ．Ｈｅｒ
ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ Ｗｅｂ ｍｉｎｉｎｇ ａｎｄ ｎａｔｕｒａｌ ｌａｎｇｕａｇｅ
ｐｒｏｃｅｓｓｉｎｇ．
ＬＩＡＮＧ Ｘｕｎ，ｂｏｒｎ ｉｎ １９６５，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ，Ｐｈ．Ｄ． ＸＵ Ｙｕａｎ，ｂｏｒｎ ｉｎ １９９３，Ｍ．Ｓ．ｃａｎｄｉｄａｔｅ．Ｈｅｒ ｒｅｓｅａｒｃｈ
ｓｕｐｅｒｖｉｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ， ｉｎｔｅｒｅｓｔｓ ｆｏｃｕｓ ｏｎ ｓｏｃｉａｌ ｃｏｍｐｕｔｉｎｇ．
Ｂａｃｋｇｒｏｕｎｄ
Ｔｈｅ ｃｏｍｐｌｅｘ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋ ｄａｔａ ｈａｖｅ ｃｈａｒａｃｔｅｒｉｓ－ Ｔｈｉｓ ｐａｐｅｒ ｓｕｍｍａｒｉｚｅｓ ｔｈｅ ｍａｉｎ ｍｏｄｅｌｓ ｏｆ ｒｅｐｒｅｓｅｎｔａ－
ｔｉｃｓ ｏｆ ｌａｒｇｅ ｖｏｌｕｍｅ，ｈｉｇｈ ｓｐａｒｓｉｔｙ，ｈｉｇｈ ｉｎｆｏｒｍａｔｉｏｎ ｆｒａｇｉｌｉｔｙ， ｔｉｏｎ ｌｅａｒｎｉｎｇ ｉｎ ｃｕｒｒｅｎｔ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋｓ，ｍｏｓｔ ｏｆ ｗｈｉｃｈ
ａｎｄ ｈｉｇｈ ｄｙｎａｍｉｃｓ．Ｔｈｅｒｅｆｏｒｅ，ｎｅｔｗｏｒｋ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ａｒｅ ｂａｓｅｄ ｏｎ ｔｈｅ ｉｎｆｏｒｍａｔｉｏｎ ｎｅｔｗｏｒｋ ｌｉｎｋ ａｎａｌｙｓｉｓ（ｎｅｔｗｏｒｋ
ｂｅｃｏｍｅｓ ａ ｈｏｔ ｔｏｐｉｃ ｒｅｃｅｎｔｌｙ ｉｎ ｎｅｔｗｏｒｋ ｍｏｄｅｌｉｎｇ．Ｔｈｅ ｓｔｒｕｃｔｕｒｅ）ａｎｄ ｔｈｅ ｃｏｎｔｅｎｔ ｏｒ ｂｏｔｈ ｆｕｓｉｏｎｓ ｆｏｒ ｖｅｒｔｅｘ ｆｅａｔｕｒｅ
ｄｉｓｔｒｉｂｕｔｅｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｏｆ ｌｅａｒｎｉｎｇ ｎｅｔｗｏｒｋｓ ｈａｓ ａ ｐｒａｃｔｉｃａｌ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ．Ｉｎ ｔｈｅｓｅ ｍｏｄｅｌｓ，ｔｈｅ ｓｔｒｕｃｔｕｒａｌ
ｓｉｇｎｉｆｉｃａｎｃｅ ｖａｌｕｅ ｉｎ ａｐｐｌｉｃａｔｉｏｎｓ．Ｆｏｒ ｅｘａｍｐｌｅ，ｔｈｅ ｅｉｇｅｎｖｅｃｔｏｒ ｆｅａｔｕｒｅｓ ｏｆ ｔｈｅ ｆｕｓｉｏｎ ｎｅｔｗｏｒｋ ａｎｄ ｔｅｘｔ ｃｏｎｔｅｎｔ ｃｈａｒａｃｔｅｒｉｓｔｉｃｓ
ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｏｆ ｅａｃｈ ｖｅｒｔｅｘ ｉｎ ｔｈｅ ｌｅａｒｎｉｎｇ ｎｅｔｗｏｒｋ ｃａｎ ｏｆ ｔｈｅ ｌｅａｒｎｉｎｇ ｒｅｆｌｅｃｔ ａ ｍｏｒｅ ｒｅａｌ ｎｅｔｗｏｒｋ．Ｔｈｅ ｌｅａｒｎｉｎｇ ｎｅｔ－
ｅｆｆｅｃｔｉｖｅｌｙ ａｌｌｅｖｉａｔｅ ｎｅｔｗｏｒｋ ｄａｔａ ｓｐａｒｓｉｔｙ；ｔｈｅ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｗｏｒｋ ｆｅａｔｕｒｅｓ ａｒｅ ｍｏｒｅ ｍｅａｎｉｎｇｆｕｌ．Ｔｈｉｓ ｐａｐｅｒ ａｌｓｏ ｓｕｍｍａｒｉｚｅｓ
ｉｎｆｏｒｍａｔｉｏｎ ｏｆ ｄｉｆｆｅｒｅｎｔ ｔｙｐｅｓ ｉｎ ｔｈｅ ｎｅｔｗｏｒｋ ｃａｎ ｂｅ ａｐｐｌｉｅｄ ｔｈｅ ｋｅｙ ｃｈａｌｌｅｎｇｅｓ，ｅｘｉｓｔｉｎｇ ｓｏｌｕｔｉｏｎｓ ａｎｄ ｆｕｔｕｒｅ ｒｅｓｅａｒｃｈ
ｍｏｒｅ ｅｆｆｅｃｔｉｖｅｌｙ；ｔｈｅ ｄｉｓｔｒｉｂｕｔｅｄ ｖｅｃｔｏｒ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｏｆ ｔｈｅ ｄｉｒｅｃｔｉｏｎｓ ｏｆ ｔｈｅ ｎｅｔｗｏｒｋ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ．Ｂａｓｅｄ ｏｎ
ｎｅｔｗｏｒｋ ｃａｎ ａｃｈｉｅｖｅ ｓｅｍａｎｔｉｃ ｃｏｒｒｅｌａｔｉｏｎ ｏｐｅｒａｔｉｏｎ ｅｆｆｉｃｉｅｎｔｌｙ， ｔｈｅ ａｂｏｖｅ ａｎａｌｙｓｉｓ ａｎｄ ｄｉｓｃｕｓｓｉｏｎｓ，ｔｈｉｓ ｐａｐｅｒ ａｉｍｓ ｔｏ ｐｒｏｖｉｄｅ
ａｎｄ ｉｍｐｒｏｖｅ ｔｈｅ ｃｏｍｐｕｔａｔｉｏｎａｌ ｅｆｆｉｃｉｅｎｃｙ ｓｉｇｎｉｆｉｃａｎｔｌｙ．Ｉｎ ｓｏｍｅ ｕｓｅｆｕｌ ｓｕｇｇｅｓｔｉｏｎｓ ａｎｄ ｉｎｓｐｉｒａｔｉｏｎｓ ｆｏｒ ｔｈｅ ｆｕｔｕｒｅ ｓｔｕｄｙ
ａｄｄｉｔｉｏｎ，ｔｈｅ ｄｉｓｔｒｉｂｕｔｅｄ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｏｆ ｌｅａｒｎｉｎｇ ｎｅｔｗｏｒｋｓ ｉｓ ｏｆ ｏｎ ｎｅｔｗｏｒｋ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｍｏｄｅｌｓ．
ｇｒｅａｔ ｖａｌｕｅ ｉｎ ｔｈｅ ｎｅｔｗｏｒｋ ｖｅｒｔｅｘ ｃｌａｓｓｉｆｉｃａｔｉｏｎ，ｒｅｃｏｍｍｅｎｄａｔｉｏｎ Ｔｈｉｓ ｐａｐｅｒ ｉｓ ｓｕｐｐｏｒｔｅｄ ｂｙ ｔｈｅ Ｎａｔｉｏｎａｌ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ
ｓｙｓｔｅｍ，ｌｉｎｋ ｐｒｅｄｉｃｔｉｏｎ，ｔｅｘｔ ｍｏｄｅｌｉｎｇ ａｎｄ ｖｉｓｕａｌ ｐｒｏｃｅｓｓｉｎｇ． Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｃｈｉｎａ ｕｎｄｅｒ Ｇｒａｎｔ Ｎｏｓ．７１２７１２１１ａｎｄ ７１５３１０１２． --------------------------------------------------------------------------------- 第４１卷第１期 河 北 科 技 大 学 学 报 Ｖｏｌ．４１，Ｎｏ．１
２０２０年２月 Ｊｏｕｒｎａｌ ｏｆ Ｈｅｂｅｉ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ Ｆｅｂ．２０２０

文章编号：１００８－１５４２（２０２０）０１－００７６－１２
推荐系统研究综述
周万珍１，曹 迪１，许云峰１，刘 滨２，３
（１．河北科技大学信息科学与工程学院，河北石家庄 ０５００１８；２．河北科技大学经济管理学院，河北
石家庄 ０５００１８；３．河北科技大学大数据与社会计算研究中心，河北石家庄 ０５００１８）
摘 要：随着互联网技术的快速发展，如何对海量网络信息进行挖掘分析，已成为热点和难点问题。
推荐系统能够帮助用户在没有明确需求或者信息量巨大时解决信息过载的问题，为用户提供精准、
快速的业务（如商品、项目、服务等）信息，成为近年来产业界和学术界共同的兴趣点和研究热点，但
是，目前数据的种类多种多样并且应用场景广泛，在面对这种情况时，推荐系统也会遇到冷启动、稀
疏矩阵等挑战。深度学习是机器学习的一个重要研究领域和分支，近年来发展迅猛。研究人员使
用深度学习方法，在语音识别、图像处理、自然语言处理等领域都取得了很大的突破与成就。目前，
深度学习在推荐领域也得到了许多研究人员的青睐，成为推荐领域的一个新方向。推荐方法中融
合深度学习技术，可以有效解决传统推荐系统中冷启动、稀疏矩阵等问题，提高推荐系统的性能和
推荐精度。
文中主要对传统的推荐方法和当前深度学习技术中神经网络在推荐方法上的应用进行了归
纳，其中传统推荐方法主要分为以下３类：１）基于内容推荐方法主要依据用户与项目之间的特征信
息，用户之间的联系不会影响推荐结果，所以不存在冷启动和稀疏矩阵的问题，但是基于内容推荐
的结果新颖程度低并且面临特征提取的问题。２）协同过滤推荐方法是目前应用最为广泛的一种方
法，不需要有关用户或项目的信息，只基于用户和诸如点击、浏览和评级等项目的交互信息做出准
确的推荐。虽然该方法简单有效但是会出现稀疏矩阵和冷启动的问题。３）混合推荐方法融合了前
２种传统推荐方法的特点，能取得很好的推荐效果，但在处理文本、图像等多源异构辅助信息时仍
面临一些挑战与困难。
依据神经网络基于深度学习的推荐方法主要分为４类：基于深度神经网络（ＤＮＮ）的推荐方
法、基于卷积神经网络（ＣＮＮ）的推荐方法、基于循环神经网络（ＲＮＮ）和长短期记忆神经网络
（ＬＳＴＭ）的推荐方法、基于图神经网络（ＧＮＮ）的推荐方法、将深度学习技术融入到推荐领域，构造
的模型具有以下优势：具有较强的表征能力，可以直接从内容中提取用户和项目特征；具有较强的
抗噪能力，可以轻易地处理含有噪声的数据；可以对动态或者序列数据进行建模；可以更加精准地
学习用户或项目特征；便于对数据进行统一处理，并且可以处理大规模数据。将深度学习技术应用
到推荐领域，可以积极有效地应对传统推荐方法面临的挑战，提高推荐效果。
收稿日期：２０１９－１２－１０；修回日期：２０１９－１２－３１；责任编辑：陈书欣
基金项目：河北省科技支撑计划项目（１７２１０１０４Ｄ，１８２１０１０９Ｄ）；河北省高等学校科学技术研究项目（ＺＤ２０１５０９９）；河北省高层次人才资助
项目（Ａ２０１６００２０１５）
第一作者简介：周万珍（１９６６—），男，河北张家口人，教授，博士，主要从事计算机网络及数据库应用技术方面的研究。
通讯作者：许云峰副教授。Ｅ－ｍａｉｌ：ｈｂｋｄ＿ｘｙｆ＠ｈｅｂｕｓｔ．ｅｄｕ．ｃｎ
刘 滨教授。Ｅ－ｍａｉｌ：ｌｉｕｂｉｎ＠ｈｅｂｕｓｔ．ｅｄｕ．ｃｎ
周万珍，曹迪，许云峰，等．推荐系统研究综述［Ｊ］．河北科技大学学报，２０２０，４１（１）：７６－８７．
ＺＨＯＵ Ｗａｎｚｈｅｎ，ＣＡＯ Ｄｉ，ＸＵ Ｙｕｎｆｅｎｇ，ｅｔ ａｌ．Ａ ｓｕｒｖｅｙ ｏｆ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍｓ［Ｊ］．Ｊｏｕｒｎａｌ ｏｆ Ｈｅｂｅｉ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｓｃｉｅｎｃｅ ａｎｄ
Ｔｅｃｈｎｏｌｏｇｙ，２０２０，４１（１）：７６－８７． 第１期 周万珍，等：推荐系统研究综述 ７７
关键词：计算机神经网络；推荐系统；数据挖掘；深度学习；信息过载
中图分类号：ＴＰ３１１．１３ 文献标识码：Ａ ｄｏｉ：１０．７５３５／ｈｂｋｄ．２０２０ｙｘ０１００９
Ａ ｓｕｒｖｅｙ ｏｆ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍｓ
ＺＨＯＵ Ｗａｎｚｈｅｎ１，ＣＡＯ Ｄｉ １，ＸＵ Ｙｕｎｆｅｎｇ１，ＬＩＵ Ｂｉｎ２，３
（１．Ｓｃｈｏｏｌ ｏｆ Ｉｎｆｏｒｍａｔｉｏｎ Ｓｃｉｅｎｃｅ ａｎｄ Ｅｎｇｉｎｅｅｒｉｎｇ，Ｈｅｂｅｉ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，Ｓｈｉｊｉａｚｈｕａｎｇ，Ｈｅｂｅｉ ０５００１８，
Ｃｈｉｎａ；２．Ｓｃｈｏｏｌ ｏｆ Ｅｃｏｎｏｍｉｃｓ ａｎｄ Ｍａｎａｇｅｍｅｎｔ，Ｈｅｂｅｉ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，Ｓｈｉｊｉａｚｈｕａｎｇ，Ｈｅｂｅｉ ０５００１８，
Ｃｈｉｎａ；３．Ｂｉｇ Ｄａｔａ ａｎｄ Ｓｏｃｉａｌ Ｃｏｍｐｕｔｉｎｇ Ｒｅｓｅａｒｃｈ Ｃｅｎｔｅｒ，Ｈｅｂｅｉ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，Ｓｈｉｊｉａｚｈｕａｎｇ，Ｈｅｂｅｉ
０５００１８，Ｃｈｉｎａ）
Ａｂｓｔｒａｃｔ：Ｗｉｔｈ ｔｈｅ ｒａｐｉｄ ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ ｔｈｅ ｉｎｔｅｒｎｅｔ，ｈｏｗ ｔｏ ｍｉｎｅ ａｎｄ ａｎａｌｙｚｅ ｍａｓｓｉｖｅ ｎｅｔｗｏｒｋ ｉｎｆｏｒｍａｔｉｏｎ ｈａｓ ｂｅｃｏｍｅ ａ
ｒｅｃｏｇｎｉｚｅｄ ｈｏｔ ａｎｄ ｄｉｆｆｉｃｕｌｔ ｐｒｏｂｌｅｍ．Ａｍｏｎｇ ｔｈｅｍ，ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ ｃａｎ ｐｒｏｖｉｄｅ ｕｓｅｒｓ ｗｉｔｈ ａｃｃｕｒａｔｅ ａｎｄ ｆａｓｔ ｂｕｓｉ－
ｎｅｓｓ（ｃｏｍｍｏｄｉｔｉｅｓ，ｐｒｏｊｅｃｔｓ，ｓｅｒｖｉｃｅｓ，ｅｔｃ．）ｉｎｆｏｒｍａｔｉｏｎ，ｗｈｉｃｈ ｉｓ ｔｈｅ ｃｏｍｍｏｎ ｉｎｔｅｒｅｓｔ ａｎｄ ｒｅｓｅａｒｃｈ ｈｏｔｓｐｏｔ ｏｆ ｉｎｄｕｓｔｒｙ ａｎｄ
ａｃａｄｅｍｉａ ｉｎ ｒｅｃｅｎｔ ｙｅａｒｓ．Ａ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ ｃａｎ ｈｅｌｐ ｕｓｅｒｓ ｔｏ ｓｏｌｖｅ ｔｈｅ ｐｒｏｂｌｅｍ ｏｆ ｉｎｆｏｒｍａｔｉｏｎ ｏｖｅｒｌｏａｄ ｗｈｅｎ ｔｈｅｒｅ ｉｓ
ｎｏ ｃｌｅａｒ ｄｅｍａｎｄ ｏｒ ａ ｌａｒｇｅ ａｍｏｕｎｔ ｏｆ ｉｎｆｏｒｍａｔｉｏｎ．Ｈｏｗｅｖｅｒ，ａｔ ｐｒｅｓｅｎｔ，ｔｈｅ ｔｙｐｅｓ ｏｆ ｄａｔａ ａｒｅ ｄｉｖｅｒｓｅ ａｎｄ ｔｈｅ ａｐｐｌｉｃａｔｉｏｎ ｓｃｅ－
ｎａｒｉｏｓ ａｒｅ ｅｘｔｅｎｓｉｖｅ．Ｗｈｅｎ ｆａｃｅｄ ｗｉｔｈ ｔｈｉｓ ｓｉｔｕａｔｉｏｎ，ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ ａｌｓｏ ｅｎｃｏｕｎｔｅｒｓ ｃｈａｌｌｅｎｇｅｓ ｓｕｃｈ ａｓ ｃｏｌｄ ｓｔａｒｔ
ａｎｄ ｓｐａｒｓｅ ｍａｔｒｉｘ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ｉｓ ａｎ ｉｍｐｏｒｔａｎｔ ｒｅｓｅａｒｃｈ ｆｉｅｌｄ ａｎｄ ｔｈｅ ｍｏｓｔ ｉｍｐｏｒｔａｎｔ ｂｒａｎｃｈ ｏｆ ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ．Ｉｎ ｒｅｃｅｎｔ
ｙｅａｒｓ，ｄｅｅｐ ｌｅａｒｎｉｎｇ ｈａｓ ｄｅｖｅｌｏｐｅｄ ｒａｐｉｄｌｙ．Ｒｅｓｅａｒｃｈｅｒｓ ｈａｖｅ ｍａｄｅ ｇｒｅａｔ ｂｒｅａｋｔｈｒｏｕｇｈｓ ａｎｄ ａｃｈｉｅｖｅｍｅｎｔｓ ｉｎ ｓｐｅｅｃｈ ｒｅｃｏｇｎｉ－
ｔｉｏｎ，ｉｍａｇｅ ｐｒｏｃｅｓｓｉｎｇ，ｎａｔｕｒａｌ ｌａｎｇｕａｇｅ ｐｒｏｃｅｓｓｉｎｇ ａｎｄ ｏｔｈｅｒ ｆｉｅｌｄｓ ｂｙ ｕｓｉｎｇ ｄｅｅｐ ｌｅａｒｎｉｎｇ．Ａｔ ｐｒｅｓｅｎｔ，ｄｅｅｐ ｌｅａｒｎｉｎｇ ｈａｓ ａｌｓｏ
ｂｅｅｎ ｆａｖｏｒｅｄ ｂｙ ａ ｌａｒｇｅ ｎｕｍｂｅｒ ｏｆ ｒｅｓｅａｒｃｈｅｒｓ ｉｎ ｔｈｅ ｆｉｅｌｄ ｏｆ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｎｄ ｈａｓ ｂｅｃｏｍｅ ａ ｎｅｗ ｄｉｒｅｃｔｉｏｎ．Ｉｎｃｏｒｐｏｒａｔｉｎｇ
ｄｅｅｐ ｌｅａｒｎｉｎｇ ｔｅｃｈｎｏｌｏｇｙ ｉｎｔｏ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄ ｃａｎ ｅｆｆｅｃｔｉｖｅｌｙ ｓｏｌｖｅ ｔｈｅ ｐｒｏｂｌｅｍｓ ｏｆ ｃｏｌｄ ｓｔａｒｔ ａｎｄ ｓｐａｒｓｅ ｍａｔｒｉｘ ｉｎ
ｔｒａｄｉｔｉｏｎａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍｓ，ａｎｄ ｉｍｐｒｏｖｅ ｔｈｅ ｐｅｒｆｏｒｍａｎｃｅ ａｎｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｃｃｕｒａｃｙ ｏｆ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓ－
ｔｅｍ．
Ｔｈｉｓ ｐａｐｅｒ ｍａｉｎｌｙ ｓｕｍｍａｒｉｚｅｓ ｔｈｅ ａｐｐｌｉｃａｔｉｏｎ ｏｆ ｔｒａｄｉｔｉｏｎａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄｓ ａｎｄ ｔｈｅ ａｐｐｌｉｃａｔｉｏｎ ｏｆ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ
ｉｎ ｃｕｒｒｅｎｔ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｔｅｃｈｎｏｌｏｇｙ ｉｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄｓ，ａｍｏｎｇ ｗｈｉｃｈ ｔｈｅ ｔｒａｄｉｔｉｏｎａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄｓ ｃａｎ ｂｅ
ｄｉｖｉｄｅｄ ｉｎｔｏ ｔｈｅ ｆｏｌｌｏｗｉｎｇ ｔｈｒｅｅ ｃａｔｅｇｏｒｉｅｓ：１）Ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄｓ ｉｓ ｍａｉｎｌｙ ｂａｓｅｄ ｏｎ ｔｈｅ ｆｅａｔｕｒｅ ｉｎｆｏｒｍａ－
ｔｉｏｎ ｂｅｔｗｅｅｎ ｔｈｅ ｕｓｅｒ ａｎｄ ｔｈｅ ｐｒｏｊｅｃｔ．Ｔｈｅ ｃｏｎｎｅｃｔｉｏｎ ｂｅｔｗｅｅｎ ｕｓｅｒｓ ｗｉｌｌ ｎｏｔ ａｆｆｅｃｔ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｒｅｓｕｌｔ，ｓｏ ｔｈｅｒｅ ｉｓ ｎｏ
ｐｒｏｂｌｅｍ ｏｆ ｃｏｌｄ ｓｔａｒｔ ａｎｄ ｓｐａｒｓｅ ｍａｔｒｉｘ，ｂｕｔ ｔｈｅ ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｒｅｓｕｌｔｓ ａｒｅ ｌｏｗ ｉｎ ｎｏｖｅｌｔｙ ａｎｄ ｆａｃｅ ｔｈｅ ｐｒｏｂｌｅｍ
ｏｆ ｆｅａｔｕｒｅ ｅｘｔｒａｃｔｉｏｎ．２）Ｔｈｅ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄ ｉｓ ｔｈｅ ｍｏｓｔ ｗｉｄｅｌｙ ｕｓｅｄ ｍｅｔｈｏｄ ｔｈａｔ ｄｏｅｓ ｎｏｔ
ｒｅｑｕｉｒｅ ｉｎｆｏｒｍａｔｉｏｎ ａｂｏｕｔ ｕｓｅｒｓ ｏｒ ｉｔｅｍｓ，ｂｕｔ ｏｎｌｙ ｍａｋｅｓ ａｃｃｕｒａｔｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ ｂａｓｅｄ ｏｎ ｔｈｅ ｕｓｅｒ＇ｓ ｉｎｔｅｒａｃｔｉｏｎｓ ｗｉｔｈ ｉｔｅｍｓ
ｓｕｃｈ ａｓ ｃｌｉｃｋｓ，ｖｉｅｗｓ，ａｎｄ ｒａｔｉｎｇｓ．Ａｌｔｈｏｕｇｈ ｔｈｉｓ ｍｅｔｈｏｄ ｉｓ ｓｉｍｐｌｅ ａｎｄ ｅｆｆｅｃｔｉｖｅ，ｓｐａｒｓｅ ｍａｔｒｉｘ ａｎｄ ｃｏｌｄ ｓｔａｒｔ ｐｒｏｂｌｅｍｓ ｗｉｌｌ
ｏｃｃｕｒ．３）Ｔｈｅ ｈｙｂｒｉｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄ ｃｏｍｂｉｎｅｓ ｔｈｅ ｃｈａｒａｃｔｅｒｉｓｔｉｃｓ ｏｆ ｔｈｅ ｆｉｒｓｔ ｔｗｏ ｔｒａｄｉｔｉｏｎａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄｓ
ａｎｄ ｃａｎ ａｃｈｉｅｖｅ ｇｏｏｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｅｆｆｅｃｔ．Ｈｏｗｅｖｅｒ，ｔｈｉｓ ｍｅｔｈｏｄ ｓｔｉｌｌ ｆａｃｅｓ ｓｏｍｅ ｃｈａｌｌｅｎｇｅｓ ａｎｄ ｄｉｆｆｉｃｕｌｔｉｅｓ ｉｎ ｐｒｏｃｅｓｓｉｎｇ
ｍｕｌｔｉ－ｓｏｕｒｃｅ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ａｕｘｉｌｉａｒｙ ｉｎｆｏｒｍａｔｉｏｎ ｓｕｃｈ ａｓ ｔｅｘｔ ａｎｄ ｉｍａｇｅｓ．
Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄｓ ｂａｓｅｄ ｏｎ ｄｅｅｐ ｌｅａｒｎｉｎｇ ａｒｅ ｍａｉｎｌｙ ｃｌａｓｓｉｆｉｅｄ ａｃｃｏｒｄｉｎｇ ｔｏ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｃａｔｅｇｏｒｉｅｓ，ｗｈｉｃｈ ａｒｅ
ｄｉｖｉｄｅｄ ｉｎｔｏ ｔｈｅ ｆｏｌｌｏｗｉｎｇ ｆｏｕｒ ｃａｔｅｇｏｒｉｅｓ：Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄｓ ｂａｓｅｄ ｏｎ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ（ＤＮＮ）；ｒｅｃｏｍｍｅｎｄａｔｉｏｎ
ｍｅｔｈｏｄｓ ｂａｓｅｄ ｏｎ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ（ＣＮＮ）；ｒｅｃｏｍｍｅｎｄｅｄ ｍｅｔｈｏｄｓ ｂａｓｅｄ ｏｎ ｃｙｃｌｉｃ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ（ＲＮＮ）ａｎｄ
ｌｏｎｇ ａｎｄ ｓｈｏｒｔ ｔｅｒｍ ｍｅｍｏｒｙ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ（ＬＳＴＭ）；ａｎｄ ｒｅｃｏｍｍｅｎｄｅｄ ｍｅｔｈｏｄｓ ｂａｓｅｄ ｏｎ ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ（ＧＮＮ）．
Ｉｎｃｏｒｐｏｒａｔｉｎｇ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｔｅｃｈｎｏｌｏｇｙ ｉｎｔｏ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｆｉｅｌｄ，ｔｈｅ ｃｏｎｓｔｒｕｃｔｅｄ ｍｏｄｅｌ ｈａｓ ｔｈｅ ｆｏｌｌｏｗｉｎｇ ｆｉｖｅ ａｄｖａｎｔａｇｅｓ：
ｉｔ ｈａｓ ｓｔｒｏｎｇ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ａｂｉｌｉｔｙ，ａｎｄ ｃａｎ ｄｉｒｅｃｔｌｙ ｅｘｔｒａｃｔ ｔｈｅ ｃｈａｒａｃｔｅｒｉｓｔｉｃｓ ｏｆ ｕｓｅｒｓ ａｎｄ ｉｔｅｍｓ ｆｒｏｍ ｔｈｅ ｃｏｎｔｅｎｔ；ｗｉｔｈ ｓｔｒｏｎｇ
ａｎｔｉ－ｎｏｉｓｅ ａｂｉｌｉｔｙ，ｉｔ ｃａｎ ｅａｓｉｌｙ ｐｒｏｃｅｓｓ ｄａｔａ ｗｉｔｈ ｎｏｉｓｅ；ｉｎ ｄｅｅｐ ｌｅａｒｎｉｎｇ，ｃｙｃｌｉｃ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｃａｎ ｍｏｄｅｌ ｄｙｎａｍｉｃ ｏｒ ｓｅｑｕｅｎｔｉａｌ
ｄａｔａ；ｉｔ ｃａｎ ｌｅａｒｎ ｕｓｅｒ ｏｒ ｐｒｏｊｅｃｔ ｃｈａｒａｃｔｅｒｉｓｔｉｃｓ ｍｏｒｅ ａｃｃｕｒａｔｅｌｙ；ａｎｄ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆａｃｉｌｉｔａｔｅｓ ｔｈｅ ｕｎｉｆｉｅｄ ｐｒｏｃｅｓｓｉｎｇ ｏｆ ｄａｔａ ａｎｄ
ｃａｎ ｐｒｏｃｅｓｓ ｌａｒｇｅ－ｓｃａｌｅ ｄａｔａ．Ａｐｐｌｙｉｎｇ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｔｅｃｈｎｏｌｏｇｙ ｔｏ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｆｉｅｌｄ ｃａｎ ｅｆｆｅｃｔｉｖｅｌｙ ｏｖｅｒｃｏｍｅ ｔｈｅ ｃｈａｌ－
ｌｅｎｇｅｓ ｆａｃｅｄ ｂｙ ｔｒａｄｉｔｉｏｎａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｅｔｈｏｄｓ ａｎｄ ｉｍｐｒｏｖｅ ｔｈｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｅｆｆｅｃｔ．
Ｋｅｙｗｏｒｄｓ：ｃｏｍｐｕｔｅｒ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ；ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ；ｄａｔａ ｍｉｎｉｎｇ；ｄｅｅｐ ｌｅａｒｎｉｎｇ；ｉｎｆｏｒｍａｔｉｏｎ ｏｖｅｒｌｏａｄ ７８ 河 北 科 技 大 学 学 报 ２０２０年
当前，互联网中的数据规模增速日趋加快，每天新增的数据量高达２．５×１０１８字节，人类已经步入内容过
载、数据噪声泛滥的时代，可以通过各种途径获得更加丰富的信息，微博、微信等各种社交工具和自媒体给用
户带来了更加便捷的信息获取渠道，与此同时，信息超负荷也成为了人们遇到的困难。
推荐系统作为一种筛选信息的工具，存在于海量数据挖掘基础之上，可以有效解决信息过载问题，通过
以个性化的方式提供满足用户需求的内容。此外，推荐系统作为用户和信息之间的联系，不仅可以帮助用户
发现自己需要的信息，还可以让信息展现在对其感兴趣的用户面前，从而实现信息生产者和信息消费者的互
利双赢。目前，推荐系统已经成为产业界和学术界关注、研究的热点问题，应用领域十分广泛，在电子商务、
社交网络、视频音乐推荐［１－２］等领域都有所应用［３］。例如亚马逊网站、京东、淘宝网站为用户推荐商品［４－５］，
ＭｏｖｉｅＬｅｎｓ推荐电影的功能［６－７］等。
传统的推荐方法主要分为基于内容的推荐方法、协同过滤的推荐方法以及混合推荐方法，虽然传统的推
荐方法可以实现推荐任务，并且融合多源异构辅助信息（多源异构信息：包含用户行为信息和个性化需求信
息的图像、文本等）的混合推荐方法在一定程度上可以缓解冷启动、稀疏矩阵的问题，但是辅助信息往往具有
多模态、数据异构、大规模、数据稀疏和分布不均匀等复杂特征，在处理存在融合多源异构信息的数据时混合
推荐方法仍然面临着严峻挑战［８－９］。
目前，深度学习在数据挖掘［１０］、自然语言处理［１１］、图像识别［１２］、推荐以及其他相关领域都得到了应用。
其中，基于深度学习的推荐系统克服了传统模型的障碍，实现了高质量推荐。深度学习能够有效挖掘用户和
项目间的非线性关系，并能够将更复杂的抽象编码为更高层次的数据表示；此外，它从大量可访问的数据源
（如上下文、文本和可视信息［１３］）捕获数据本身内部的复杂关系［１４］。本文对深度神经网络（ＤＮＮ）、卷积神经
网络（ＣＮＮ）、循环神经网络（ＲＮＮ）、长短期记忆神经网络（ＬＳＴＭ）以及图神经网络（ＧＮＮ）在推荐系统领域
的应用进行分析和归纳。
１ 传统的推荐系统
在２０世纪９０年代，推荐系统发展成为一门独
立的学科，推荐系统的核心部分是推荐算法，推荐算
法根据用户与项目之间的关系帮助用户发现其感兴
趣的项目。文献［１５］给出了推荐算法的定义：定义
函数ｓ来计算一个项目ｉ∈Ｉ（Ｉ代表所有项目的集
合），推荐给某一位用户ｕ∈Ｕ（Ｕ代表所有用户的
集合）的可能性Ｐ，推荐算法就是通过计算Ｐ来为
用户找到其最感兴趣的项目ｉ′∈Ｉ，即
ｕ∈Ｕ，ｉ′ ＝ａｒｇｍａｘｓ（ｕ，ｉ），ｉ∈Ｉ 。 （１）
ｕ
传统的推荐方法主要分为３类［１６］：基于内容的
推荐（ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ）方法［１７］、基于
协同过滤的推荐方法（ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｒｅｃｏｍ－ 图１ 推荐系统分类
ｍｅｎｄａｔｉｏｎ）［１８－１９］和混合推荐方法（ｈｙｂｒｉｄ ｒｅｃｏｍ－ Ｆｉｇ．１ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｓｙｓｔｅｍ ｃｌａｓｓｉｆｉｃａｔｉｏｎ
ｍｅｎｄａｔｉｏｎ）［２０］，如图１所示。
１．１ 基于内容的推荐
基于内容的推荐方法是最早被使用的推荐算法，来自于信息获取领域［２１］。基于内容的推荐方法的思想
非常简单，就是向用户推荐与他们过去兴趣相似的项目。首先分析用户感兴趣的项目信息，推荐流程如图２
所示。
基于内容的推荐建立在项目信息基础上做出推荐，需要从关于内容特征描述的事例中得到用户的兴趣
资料，然后根据用户偏好和项目特征信息产生推荐结果。这种方法的优点是能对具有小众口味的用户产生
有效推荐，在一些特定的场景下表现良好；对于新添加的项目，系统只需要提取新项目的特征即可产生推荐
结果，不存在项目冷启动的问题，其缺点在于十分依赖于项目所标记的属性特征，对标记特征要求较高。此
外，该方法无法衡量待推荐项目品质的优劣，推荐失败的概率也很高。 第１期 周万珍，等：推荐系统研究综述 ７９
１．２ 基于协同过滤的推荐
ＧＯＬＤＢＥＲＧ等［２２］在１９９２年提出协同过滤
推荐方法，又称为社会过滤，是指筛选出特定用户
感兴趣的项目集合，根据这些项目集合挖掘用户
的潜在需求，辅助用户做决定［２３］。在推荐领域，
协同过滤推荐算法是研究的主流方向，也是目前
使用最广泛的推荐方法。
用户的历史行为数据是基于协同过滤推荐算
法生成推荐项的来源，协同过滤是建立在这样的
假设基础上的，如果用户Ｘ和Ｙ对ｔ个项目进行
相似的评分，或者有相似的行为，那么用户就会对
其他项目进行类似的评分或行为［２４］。基于协同
过滤的推荐方法主要分为基于用户（ｕｓｅｒ－ｂａｓｅｄ）
的协同过滤和基于项目（ｉｔｅｍ－ｂａｓｅｄ）的协同过
滤［２５－２７］。基于用户的协同过滤，首先根据用户偏
图２ 基于内容的推荐流程
好计算用户之间的相似度，找出与目标用户相似
Ｆｉｇ．２ Ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｐｒｏｃｅｓｓ
度高的用户，然后预测出目标用户对相似用户感
兴趣物品的评分，最后将评分最高的若干个物品
推荐给用户。基于项目的协同过滤与基于用户的协同过滤类似，通过计算物品之间的相似度来进行推荐。
计算已购买物品ｉ和待推荐物品ｊ之间相似度的基本思想是：首先提取出对２个物品共同做出评分的用户，
如果这些用户对２个物品ｉ和ｊ的评分相近，那么２个物品相似度就高，反之则相似度就低，之后将相似度
高的待推荐物品放入推荐列表。协同过滤算法的基础思想如图３所示。由于在淘宝等电商网站中用户数量
总是远多于商品的数量，因此在实际应用中基于物品的协同过滤比基于用户的协同过滤更受欢迎。协同过
滤推荐方法使用方便、简单，只依据用户的历史评分数据计算用户之间的相似度即可，但是在很多情况下常
常遇到评分数据不足造成稀疏矩阵的问题和新用户没有项目评分数据的冷启动问题。
图３ 协同过滤算法的基础思想
Ｆｉｇ．３ Ｂａｓｉｃ ｉｄｅａ ｏｆ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ａｌｇｏｒｉｔｈｍ
１．３ 混合推荐
任何推荐方法都有着自身独特的优点，但是在一些场景中单独使用一种方法时，推荐结果并不理想，通
过将多种推荐方法相结合进行混合推荐能够实现取长补短，提高推荐系统的性能。在实际场景中使用的推 ８０ 河 北 科 技 大 学 学 报 ２０２０年
荐方法大部分都是将２种或２种以上的推荐方法混合而得到的，尽管从理论上有很多种混合推荐方法，但在
某一具体问题中并不是每种方法的混合都有效，因此如何将２种或２种以上的方法进行混合，产生更为有效
的推荐也是推荐系统中一个重要的研究方向。混合推荐技术可以克服传统推荐方法的大多数限制，将它们
组合起来以获得更好的推荐结果。混合推荐方法有很多，如加权型、切换型、交叉型、特征组合型、瀑布型、特
征递增型、元层次型［２４］等。
推荐系统以用户与项目的交互关系作为依据来发掘用户的偏好来实现推荐功能。但是当用户和项目的
数据量增大时，用户与项目之间的评分矩阵会出现越来越稀疏的现象，协同过滤的方法面临数据稀疏的问
题，而基于内容的推荐方法只能实现浅层模型捕捉特征，而且人工设计特征对浅层模型的影响巨大，会极大
限制方法的可扩展性和推荐效果。虽然混合推荐方法可以有效解决以上问题，但是在面对多模态辅助信息
时，混合推荐方法依然面临着严峻挑战。
２ 深度学习在推荐系统上的应用
近年来，深度学习在推荐系统领域上发展迅速，在推荐系统中深度学习技术将用户的潜在特征和项目的
潜在特征提取出来，基于这些潜在特征表示为用户产生推荐项目，完成推荐任务。深度学习技术中的神经网
络不仅能学习用户或项目的潜在特征表示，而且可以学习用户与项目之间复杂的非线性交互特征，深入地分
析用户偏好，解决传统推荐方法中的一些问题，更好地实现推荐［２５］。
２．１ 基于ＤＮＮ的推荐
深度神经网络（ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ，ＤＮＮ）可以理解为有很多隐藏层的神经网络，又被称为深度前馈
网络（ＤＦＮ），多层感知机（ｍｕｌｔｉ－ｌａｙｅｒ ｐｅｒｃｅｐｔｒｏｎ，ＭＬＰ）。ＤＮＮ被提出来之后在计算机视觉［２８－２９］、图像分
类［３０－３１］、自然语言处理［３２］等领域都得到了广泛的应用，同样在推动推荐系统领域的发展上ＤＮＮ也发挥了很
大的作用［３３］。
ＣＯＶＩＮＧＴＯＮ 等［３４］ 考 虑 到
Ｙｏｕｔｏｂｅ网站视频的数据规模大、数
据新鲜度高、视频数据噪音较大的特
点，提出使用ＤＮＮ实现高效的推荐，
系统架构如图４所示。系统分为候选
集生成和排序２个阶段，这２个阶段
分别使用了１个ＤＮＮ模型。候选集
生成阶段使用 Ｃａｎｄｉｄａｔｅ Ｇｅｎｅｒａｔｉｏｎ
Ｍｏｄｅｌ负责基于用户画像及场景数据
从海量的视频库（百万级别）中将相关
图４ ＣＯＶＩＮＧＴＯＮ等［３４］提出的模型架构
度最高的资源检索出来，作为候选集。
Ｆｉｇ．４ Ｍｏｄｅｌ ａｒｃｈｉｔｅｃｔｕｒｅ ｐｒｏｐｏｓｅｄ ｂｙ ＣＯＶＩＮＧＴＯＮ ｅｔ ａｌ．［３４］
在候选集生成阶段作者将推荐任务转
化为１个超级多分类问题，即在ｔ时刻用户Ｕ在场景Ｃ下观看的视频ω 属于视频库Ｖ中的ｉ类，其中每一
ｔ
个视频ｉ可以视作为１个类别，其分类模型公式如式（２）所示：
ｅｖｉ ｕ
Ｐ（ω ＝ｉ｜Ｕ，Ｃ）＝ 。 （２）
ｔ
∑ ｅｖｊｕ
ｊ∈Ｖ
使用ＤＮＮ的一个关键优点是，ＤＮＮ的输入可以方便地处理离散和连续变量。笔者将用户观看历史和
搜索历史通过嵌入的方式映射为１个稠密的向量，用户场景信息以及用户画像信息，比如年龄、性别等离散
特征也被归一化到［０，１］作为ＤＮＮ的输入。排序阶段Ｒａｎｋｉｎｇ Ｍｏｄｅｌ负责基于更加精细的特征对候选集
（百级别）进行排序，最终呈现给用户的只是很少的一部分数据。对生成的候选集进一步做细粒度的排序时，
可以参考更多维度的特征，集成多个来自候选集的打分，将它们集合在一起综合一个分数排序，最终完成视
频推荐。此外，在排序阶段的ＤＮＮ结构与候选集生成阶段类似，并基于逻辑回归对每一个视频进行独立打
分。但是Ｃａｎｄｉｄａｔｅ Ｇｅｎｅｒａｔｉｏｎ Ｍｏｄｅｌ网络在分类训练时是用户向量和视频向量的点乘计算，在查询的时 第１期 周万珍，等：推荐系统研究综述 ８１
候是用户向量和视频向量的距离运算，那么相关运算不能确定是否能完全反映相似性，学习出来的用户向量
和视频向量可能会有一定的分布偏差。
ＺＨＡＮＧ等［３５］提出一种协同过滤推荐算法与ＤＮＮ相结合的模型，该模型由特征表示模块和评分预测
模块组成，如图５所示。首先，该模型改进传统的矩阵分解算法，使用二次多项式回归模型捕捉潜在特征表
示，使模型得到的潜在特征表示更加精准，然后将这些潜在特征输入到ＤＮＮ中，预测评分。该模型能有效
提高推荐的性能。
图５ 协同过滤推荐算法与ＤＮＮ相结合的模型［３５］
Ｆｉｇ．５ Ａ ｍｏｄｅｌ ｃｏｍｂｉｎｉｎｇ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｌｇｏｒｉｔｈｍ ｗｉｔｈ ＤＮＮ［３５］
２．２ 基于ＣＮＮ的推荐
卷积神经网络（ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ，ＣＮＮ）是深度学习中经典并且广泛得到应用的神经网
络。使用ＣＮＮ构建的模型训练复杂度较低，而且训练参数的数目相较于其他网络来说也较少，主要是由于
ＣＮＮ可以实现共享权值、局部连接等操作，除此之外ＣＮＮ的容错能力和鲁棒性也比较强［３６］，是一种易于训
练和优化的网络结构。将ＣＮＮ应用到推荐系统中，可以明显提高推荐的精准度。
ＴＡＮＧ等［３７］提出一种基于卷积的序列嵌入模型———Ｃａｓｅｒ模型，模型结构如图６所示。Ｃａｓｅｒ模型解
决了Ｔｏｐ－Ｎ顺序推荐中在一个序列里最近的项对其下一个项有较大影响的这一问题，是在时间和潜在空间
中将一组最近的物品序列嵌入到一张“图像”中，并利用卷积滤波器来学习作为图像的局部特征的序列模
式［３８－３９］，这种方法为提取长期兴趣和序列模式提供了一种统一而又简洁的网络结构。该模型主要分为嵌入
查找层（ｅｍｂｅｄｄｉｎｇ ｌｏｏｋ－ｕｐ）、卷积层（ｃｏｎｖｏｌｕｔｉｏｎａｌ ｌａｙｅｒｓ）、全连接层（ｆｕｌｌｙ－ｃｏｎｎｅｃｔｅｄ ｌａｙｅｒｓ）。嵌入查找层
图６ Ｃａｓｅｒ模型［３７］
Ｆｉｇ．６ Ｃａｓｅｒ ｍｏｄｅｌ［３７］ ８２ 河 北 科 技 大 学 学 报 ２０２０年
将前Ｌ项物品在潜在空间的表示连接起来，作为用户ｕ在当前时刻ｔ的序列矩阵表示Ｅ（ｕ，ｔ）∈ＲＬ×ｄ。除了
物品的表示之外，本文还为用户ｕ提供了一个用户的潜在表示Ｐ ∈Ｒｄ，它表示潜在空间中的用户特性。卷
ｕ
积层包括水平卷积和垂直卷积两部分，Ｃａｓｅｒ模型将前Ｌ项物品在潜在空间的表示看作一张“图像”，利用卷
积滤波器对其进行序列模式的搜索和学习。水平滤波器可以被训练来提取具有多个联合大小的联合级模
式，滤波器由上到下滑动；垂直滤波器通过对前几项物品的潜在表示的加权和来捕获点级序列模式，滤波器
从左到右滑动。在全连接层中，将这２个卷积层的输出串联起来，并将它们和Ｐ 输入到１个全连接的神经
ｕ
网络中，以获得更高层次和更抽象的特征。该模型通过将最近的行为建模为时间和潜在维度之间的“图像”，
并使用卷积滤波器来学习序列模式，从而解决了Ｔｏｐ－Ｎ序列推荐的问题。但是由于ｕｓｅｒｅｍｂｅｄｄｉｎｇ和ｉｔｅ－
ｍｅｍｂｅｄｄｉｎｇ在Ｃａｓｅｒ模型中是分开训练的，在捕捉ｕｓｅｒ与ｉｔｅｍｓ的交互信息时有问题，且与下文中的Ｃｏｎ－
ｖＭＦ模型相比没有引入上下文的信息。
ＫＩＭ等［４０］提出了一种新颖的上下文感知推荐模型，将卷积神经网络（ＣＮＮ）集成到概率矩阵分解
（ＰＭＦ）中的卷积矩阵分解（ＣｏｎｖＭＦ）。ＣｏｎｖＭＦ捕获文档的上下文信息，并进一步提高评分预测精度。文
中实验结果证明ＣｏｎｖＭＦ模型可以很好地处理上下文信息的稀疏性问题。ＴＵＡＮ等［４１］提出一种三维卷积
神经网络对不同类型和性质的数据进行建模，并对所有输入数据进行字符级编码，利用会话点击和内容功能
（例如项目描述和项目类别）进行预测推荐，模型如图７所示。ＯＯＲＤ等［４２］提出利用潜在因素模型实现音乐
自动化推荐，该模型在无法从使用数据中获得潜在因素时，从音乐音频中预测这些潜在因素。使用深度卷积
神经网络对音频信号的袋形表示进行了传统方法的比较，并对一百万首歌曲数据集的预测进行了定量和定
性评估。
图７ ＴＵＡＮ等［４１］提出的模型架构
Ｆｉｇ．７ Ｍｏｄｅｌ ａｒｃｈｉｔｅｃｔｕｒｅ ｐｒｏｐｏｓｅｄ ｂｙ ＴＵＡＮ ｅｔ ａｌ．［４１］
２．３ 基于ＲＮＮ和ＬＳＴＭ的推荐
循环神经网络（ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ，ＲＮＮ）是一种可以处理序列数据的神经网络。大多数ＲＮＮ
可以处理可变长度的序列，ＲＮＮ的诞生解决了传统神经网络在处理序列信息方面的局限性。对于ＲＮＮ输
入层中的每一个输入数据，ＲＮＮ内部进行相同的计算，同时每一步的计算都与前一步的计算相关。在推荐
系统中，用户的历史交互记录可以抽象为序列数据，利用ＲＮＮ可以挖掘出用户的兴趣喜好等随时间变换的
变化趋势［４３］。
ＬＩＵ等［４４］在基于ＲＮＮ的基础上提出了一个新模型，称为上下文感知递归神经网络（ＣＡ－ＲＮＮ），模型
如图８所示。ＣＡ－ＲＮＮ代替在常规ＲＮＮ模型中使用常量输入矩阵和过渡矩阵，引入了上下文感知的输入
矩阵和上下文感知的转移矩阵，使ＲＮＮ每一层的矩阵参数随着输入上下文和转移上下文的不同而变化。
其中自适应上下文特定的输入矩阵捕获用户行为的外部情况（如时间、位置、天气等）。自适应上下文特定的
转换矩阵可以捕获历史序列中相邻行为之间的时间间隔长度而影响全局序列特征的转换。ＣＡ－ＲＮＮ模型 第１期 周万珍，等：推荐系统研究综述 ８３
可以建模丰富的上下文信息和序列信息，提高了推荐效果。
图８ ＣＡ－ＲＮＮ模型架构［４４］
Ｆｉｇ．８ ＣＡ－ＲＮＮ ｍｏｄｅｌ ａｒｃｈｉｔｅｃｔｕｒｅ［４４］
ＭＡＮＯＴＵＭＲＵＫＳＡ等［４５］提出了一种新颖的情境注意力循环架构（ＣＡＲＡ），用来解决不同类型的上
下文对用户的偏好具有不同影响的问题，模型架构如图９所示。该架构利用反馈序列和与该序列相关联的
上下文信息来捕获用户的动态偏好。该循环架构包含２种类型的门控机制，一种是上下文注意门，控制普通
上下文对用户的上下文偏好的影响；另一种基于时间和地理的门，根据转换上下文控制来自前一次签入的隐
藏状态的影响。
长短期记忆神经网络（ｌｏｎｇ ｓｈｏｒｔ ｔｅｒｍ
ｍｅｍｏｒｙ，ＬＳＴＭ）属于循环神经网络，是
ＲＮＮ的一种。ＬＳＴＭ 和 ＲＮＮ 一样，通过
重复神经网络模块的链式形式来对序列数
据进行学习，同时为了避免ＲＮＮ的梯度爆
炸和梯度弥散问题，ＬＳＴＭ 通过在ＲＮＮ的
重复模块中添加遗忘门、输入门和输出门来
增加长序列的记忆问题［４６］。ＹＡＮＧ 等［４７］
图９ ＣＡＲＡ模型架构［４５］
提出了一种基于长短期记忆（ＬＳＴＭ）的上
Ｆｉｇ．９ ＣＡＲＡ ｍｏｄｅｌ ａｒｃｈｉｔｅｃｔｕｒｅ［４５］
下文感知引用推荐模型来为用户推荐相关
和适当的科学论文引文，该模型首先基于
ＬＳＴＭ分别学习引文上下文和科学论文的分布式表示，然后基于引文上下文和科学论文的分布式表示来度
量相关性，最后将具有较高相关性分数的科学论文选为推荐列表。该模型使个性化的上下文感知引用推荐
成为可能，提出了一种基于神经记忆网络和外部记忆的流媒体推荐模型，以统一的方式捕获和存储长期稳定
兴趣和短期动态兴趣。
２．４ 基于ＧＮＮ的推荐方法
图神经网络（ＧＮＮ）是一种连接模型，通过图的节点之间的消息传递来捕捉图的依赖关系，使用图结构
表示输入的神经网络，目标是学习图中各节点的状态信息（包含邻接信息）［４８］。基于ＧＮＮ的推荐系统将项
目和用户作为节点，项目与项目间、用户与用户间、用户与项目间以及内容信息间的关系作为节点的状态信
息，进而实现推荐。基于ＧＮＮ的推荐方法能够提供高质量的推荐结果［４９］。
ＹＩＮＧ等［５０］提出一种可伸缩的图卷积网络（ＧＣＮ）算法———ＰｉｎＳａｇｅ，ＰｉｎＳａｇｅ模型采用局部卷积，降低
了模型在训练计算时的复杂度。将ＧＮＮ扩展到具有数十亿项和数亿用户的 ｗｅｂ级推荐任务，结合了高效
的随机游走和图卷积来生成节点（即项）的嵌入，并且这些嵌入结合了图结构和节点特征信息。该模型证明
了图卷积方法对生产推荐系统的影响，提高了推荐性能。ＰｉｎＳａｇｅ模型结构如图１０所示。 ８４ 河 北 科 技 大 学 学 报 ２０２０年
图１０ ＰｉｎＳａｇｅ模型结构［５０］
Ｆｉｇ．１０ ＰｉｎＳａｇｅ ｍｏｄｅｌ ｓｔｒｕｃｔｕｒｅ［５０］
ＷＡＮＧ等［５１］提出了ＫＧＮＮ－ＬＳ（ｎｏｗｌｅｄｇｅ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓｗｉｔｈ ｌａｂｅｌ ｓｍｏｏｔｈｎｅｓｓ ｒｅｇｕ－
ｌａｒｉｚａｔｉｏｎ），这是一个端到端框架，可以通过在Ｋｎｏｗｌｅｄｇｅ Ｇｒａｐｈ（ＫＧ）上挖掘项目与项目之间的相关属性来
有效地捕获项目之间的相关性。为了自动发现ＫＧ的高阶结构信息和语义信息，从ＫＧ中每个实体的邻居
处抽样作为它们的接收域，然后在计算给定实体的表示时将邻域信息与偏差结合起来，可以将接收域扩展到
多个跃点，以对高阶邻近信息进行建模并捕获用户的潜在长期兴趣。此外，作者以小批量方式实现了
ＫＧＣＮ模型，这也使得ＫＧＣＮ模型可以在大型数据集和ＫＧ上运行，ＫＧＮＮ－ＬＳ模型结构如图１１所示。
图１１ ＫＧＮＮ－ＬＳ模型结构［５１］
Ｆｉｇ．１１ ＫＧＮＮ－ＬＳ ｍｏｄｅｌ ｓｔｒｕｃｔｕｒｅ［５１］
ＺＨＡＮＧ等［５２］提出了一种新的层叠和重构的图卷积网络（ＳＴＡＲ－ＧＣＮ）结构来学习节点表示，提高推荐
系统的性能，特别是提高了冷启动情况下的推荐效果。ＳＴＡＲ－ＧＣＮ采用一组ＧＣＮ编码器－解码器，结合中
间监控来提高最终预测性能，将低维用户和项目潜在因素作为输入，以抑制模型空间复杂度。此外，ＳＴＡＲ－
ＧＣＮ可以通过重构掩码输入节点嵌入来生成新节点的节点嵌入，这基本上解决了冷启动问题。ＳＴＡＲ－
ＧＣＮ模型结构如图１２所示。
图卷积神经网络一般很难设置比较深的层数去更好地学习节点的表征形式，虽然ＳＴＡＲ－ＧＣＮ通过堆 第１期 周万珍，等：推荐系统研究综述 ８５
叠或重构编码解码块，但也并不能设置较深的 ＧＣＮ 层
数。使用ＧＣＮ学习到更深层次的特征，仍然是需要考虑
的问题。
深度学习技术拥有强大的提取数据集本质特征的功
能，可以有效捕获用户、项目之间深层次特征和非线性关
系，将复杂抽象的编码用简单易懂的数据表示。此外，深
度学习可以从大量可访问的数据源中（如上下文、文本和
可视信息）捕捉到数据内部之间的复杂关系。在推荐系统
中加入深度学习技术，可解决传统推荐方法存在的冷启
动、稀疏矩阵和多模态辅助信息问题，提高推荐系统的性 图１２ ＳＴＡＲ－ＧＣＮ模型结构［５２］
能，快速实现更高质量的推荐。 Ｆｉｇ．１２ ＳＴＡＲ－ＧＣＮ ｍｏｄｅｌ ｓｔｒｕｃｔｕｒｅ［５２］
３ 结 语
随着深度学习技术的广泛应用，当前工业界和学术界的研究热点之一就是研究基于深度学习的推荐方
法。将深度学习应用到推荐系统上，可使推荐系统的性能得到提升。但是深度学习在推荐系统上的应用还
处于初期阶段，仍然面临一些挑战。例如：使用深度学习模型实现高质量推荐时，往往因网络模型复杂，使得
训练所需要的时间和空间成本较高；训练效果好的模型需要大量的样本数据；深度学习模型大部分被封装起
来，可解释性较弱。本文主要对传统的推荐方法和当前基于神经网络的推荐方法进行了归纳，但对推荐领域
方法的介绍还不够全面，未来会进行更为深入的学习和探讨。
参考文献／Ｒｅｆｅｒｅｎｃｅｓ：
［１］ ＰＩＣＨＬ Ｍ，ＺＡＮＧＥＲＬＥ Ｅ，ＳＰＥＣＨＴ Ｇ．Ｉｍｐｒｏｖｉｎｇ ｃｏｎｔｅｘｔ－ａｗａｒｅ ｍｕｓｉｃ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ：Ｂｅｙｏｎｄ ｔｈｅ ｐｒｅ－ｆｉｌｔｅｒｉｎｇ ａｐｐｒｏａｃｈ［Ｃ］／／
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２０１７ＡＣＭ ｏｎ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍｕｌｔｉｍｅｄｉａ Ｒｅｔｒｉｅｖａｌ．Ｂｕｃｈａｒｅｓｔ：ＡＣＭ，２０１７：２０１－２０８．
［２］ ＳＣＨＥＤＬ Ｍ，ＫＮＥＥＳ Ｐ，ＧＯＵＹＯＮ Ｆ．Ｎｅｗ ｐａｔｈｓ ｉｎ ｍｕｓｉｃ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｒｅｓｅａｒｃｈ［Ｃ］／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｅｌｅｖｅｎｔｈ ＡＣＭ Ｃｏｎ－
ｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｃｏｍｏ：ＡＣＭ，２０１７：３９２－３９３．
［３］ 黄立威，江碧涛，吕守业，等．基于深度学习的推荐系统研究综述［Ｊ］．计算机学报，２０１８，４１（７）：１６１９－１６４７．
ＨＵＡＮＧ Ｌｉｗｅｉ，ＪＩＡＮＧ Ｂｉｔａｏ，ＬＶ Ｓｈｏｕｙｅ，ｅｔ ａｌ．Ｓｕｒｖｅｙ ｏｎ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ［Ｊ］．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，
２０１８，４１（７）：１６１９－１６４７．
［４］ 洪亮，任秋圜，梁树贤．国内电子商务网站推荐系统信息服务质量比较研究———以淘宝、京东、亚马逊为例［Ｊ］．图书情报工作，２０１６，６０
（２３）：９７－１１０．
ＨＯＮＧ Ｌｉａｎｇ，ＲＥＮ Ｑｉｕｙｕａｎ，ＬＩＡＮＧ Ｓｈｕｘｉａｎ．Ａ ｃｏｍｐａｒａｔｉｖｅ ｓｔｕｄｙ ｏｆ ｉｎｆｏｒｍａｔｉｏｎ ｓｅｒｖｉｃｅ ｑｕａｌｉｔｙ ｏｆ Ｅ－ｃｏｍｍｅｒｃｅ ｓｉｔｅｓ′ｒｅｃｏｍｍｅｎｄｅｒ
ｓｙｓｔｅｍｓ－Ｔａｋｅ Ｔａｏｂａｏ，Ｊｉｎｇｄｏｎｇ ａｎｄ Ａｍａｚｏｎ ａｓ ｅｘａｍｐｌｅｓ［Ｊ］．Ｌｉｂｒａｒｙ ａｎｄ Ｉｎｆｏｒｍａｔｉｏｎ Ｓｅｒｖｉｃｅ，２０１６，６０（２３）：９７－１１０．
［５］ ＴＥＫＩＮ Ｃ，ＺＨＡＮＧ Ｓ，ｖａｎ ｄｅｒ ＳＣＨＡＡＲ Ｍ．Ｄｉｓｔｒｉｂｕｔｅｄ ｏｎｌｉｎｅ ｌｅａｒｎｉｎｇ ｉｎ ｓｏｃｉａｌ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ［Ｊ］．ＩＥＥＥ Ｊｏｕｒｎａｌ ｏｆ Ｓｅｌｅｃｔｅｄ
Ｔｏｐｉｃｓ ｉｎ Ｓｉｇｎａｌ Ｐｒｏｃｅｓｓｉｎｇ，２０１４，８（４）：６３８－６５２．
［６］ ＭＩＬＬＥＲ Ｂ Ｎ，ＡＬＢＥＲＴ Ｉ，ＬＡＭ Ｓ Ｋ，ｅｔ ａｌ．ＭｏｖｉｅＬｅｎｓ ｕｎｐｌｕｇｇｅｄ：Ｅｘｐｅｒｉｅｎｃｅｓ ｗｉｔｈ ａｎ ｏｃｃａｓｉｏｎａｌｌｙ ｃｏｎｎｅｃｔｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ
［Ｃ］／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ８ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｎｔｅｌｌｉｇｅｎｔ Ｕｓｅｒ Ｉｎｔｅｒｆａｃｅｓ．Ｍｉａｍｉ：ＡＣＭ，２００３：２６３－２６６．
［７］ ＬＩ Ｚｈｉ，ＺＨＡＯ Ｈｏｎｇｋｅ，ＬＩＵ Ｑｉ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ ｆｒｏｍ ｈｉｓｔｏｒｙ ａｎｄ ｐｒｅｓｅｎｔ：Ｎｅｘｔ－ｉｔｅｍ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｖｉａ ｄｉｓｃｒｉｍｉｎａｔｉｖｅｌｙ ｅｘｐｌｏｉｔｉｎｇ
ｕｓｅｒ ｂｅｈａｖｉｏｒｓ［Ｃ］／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ＆Ｄａｔａ Ｍｉｎｉｎｇ．［Ｓ．ｌ］：
［ｓ．ｎ．］，２０１８：１７３４－１７４３．
［８］ ＴＳＡＩ Ｃ Ｈ，ＢＲＵＳＩＬＯＶＳＫＹ Ｐ，ＲＡＨＤＡＲＩ Ｂ．Ｅｘｐｌｏｒｉｎｇ ｕｓｅｒ－ｃｏｎｔｒｏｌｌｅｄ ｈｙｂｒｉｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｉｎ ａ ｃｏｎｆｅｒｅｎｃｅ ｃｏｎｔｅｘｔ［Ｃ］／／ＩＵＩ Ｗｏｒｋ－
ｓｈｏｐｓ’１９．Ｌｏｓ Ａｎｇｅｌｅｓ：［ｓ．ｎ．］，２０１９：１－６．
［９］ ＱＩＡＮ Ｙ，ＺＨＡＮＧ Ｙ，ＭＡ Ｘ，ｅｔ ａｌ．ＥＡＲＳ：Ｅｍｏｔｉｏｎ－ａｗａｒｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ ｂａｓｅｄ ｏｎ ｈｙｂｒｉｄ ｉｎｆｏｒｍａｔｉｏｎ ｆｕｓｉｏｎ［Ｊ］．Ｉｎｆｏｒｍａｔｉｏｎ
Ｆｕｓｉｏｎ，２０１９，４６：１４１－１４６．
［１０］朱龙霞，肖明美，栗涛，等．基于时间序列分析的火电机组运行优化研究［Ｊ］．河北工业科技，２０１７，３４（２）：１２５－１２９．
ＺＨＵ Ｌｏｎｇｘｉａ，ＸＩＡＯ Ｍｉｎｇｍｅｉ，ＬＩ Ｔａｏ，ｅｔ ａｌ．Ｒｅｓｅａｒｃｈ ｏｆ ｏｐｅｒａｔｉｏｎ ｏｐｔｉｍｉｚａｔｉｏｎ ｏｆ ｔｈｅｒｍａｌ ｐｏｗｅｒ ｕｎｉｔ ｂａｓｅｄ ｏｎ ｔｉｍｅ ｓｅｒｉｅｓ ａｎａｌｙｓｉｓ［Ｊ］．
Ｈｅｂｅｉ Ｊｏｕｒａｌ ｏｆ Ｉｎｄｕｓｔｒｉａｌ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｏｌｏｇｙ，２０１７，３４（２）：１２５－１２９．
［１１］ＳＨＡＷ Ｐ，ＵＳＺＫＯＲＥＩＴ Ｊ，ＶＡＳＷＡＮＩ Ａ．Ｓｅｌｆ－ａｔｔｅｎｔｉｏｎ ｗｉｔｈ ｒｅｌａｔｉｖｅ ｐｏｓｉｔｉｏｎ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ［Ｊ］．Ｃｏｍｐｕｔａｔｉｏｎ ａｎｄ Ｌａｎｇｕａｇｅ，２０１８： ８６ 河 北 科 技 大 学 学 报 ２０２０年
ａｒＸｉｖ：１８０３．０２１５５．
［１２］甄然，于佳兴，赵国花，等．基于卷积神经网络的无人机识别方法仿真研究［Ｊ］．河北科技大学学报，２０１９，４０（５）：３９７－４０３．
ＺＨＥＮ Ｒａｎ，ＹＵ Ｊｉａｘｉｎｇ，ＺＨＡＯ Ｇｕｏｈｕａ，ｅｔ ａｌ．Ｓｉｍｕｌａｔｉｏｎ ｒｅｓｅａｒｃｈ ｏｎ ＵＡＶ ｒｅｃｏｇｎｉｔｉｏｎ ｍｅｔｈｏｄ ｂａｓｅｄ ｏｎ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ
［Ｊ］．Ｊｏｕｒｎａｌ ｏｆ Ｈｅｂｅｉ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｏｌｏｇｙ，２０１９，４０（５）：３９７－４０３．
［１３］杨彦波，刘滨，祁明月．信息可视化研究综述［Ｊ］．河北科技大学学报，２０１４，３５（１）：９１－１０２．
ＹＡＮＧ Ｙａｎｂｏ，ＬＩＵ Ｂｉｎ，ＱＩ Ｍｉｎｇｙｕｅ．Ｒｅｖｉｅｗ ｏｆ ｉｎｆｏｒｍａｔｉｏｎ ｖｉｓｕａｌｉｚａｔｉｏｎ［Ｊ］．Ｊｏｕｒｎａｌ ｏｆ Ｈｅｂｅｉ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｏｌｏｇｙ，
２０１４，３５（１）：９１－１０２．
［１４］ＺＨＡＮＧ Ｓｈｕａｉ，ＹＡＯ Ｌｉａｎ，ＳＵＮ Ａｉｘｉｎ，ｅｔ ａｌ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍ：Ａ ｓｕｒｖｅｙ ａｎｄ ｎｅｗ ｐｅｒｓｐｅｃｔｉｖｅｓ［Ｊ］．ＡＣＭ Ｃｏｍ－
ｐｕｔｉｎｇ Ｓｕｒｖｅｙｓ，２０１８，１（１）：ＤＯＩ：１０．１１４５／３２８５０２９．
［１５］ＡＤＯＭＡＶＩＣＩＵＳ Ｇ，ＴＵＺＨＩＬＩＮ Ａ．Ｔｏｗａｒｄ ｔｈｅ ｎｅｘｔ ｇｅｎｅｒａｔｉｏｎ ｏｆ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ：Ａ ｓｕｒｖｅｙ ｏｆ ｔｈｅ ｓｔａｔｅ－ｏｆ－ｔｈｅ－ａｒｔ ａｎｄ ｐｏｓｓｉｂｌｅ
ｅｘｔｅｎｓｉｏｎｓ［Ｊ］．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｋｎｏｗｌｅｄｇｅ ＆Ｄａｔａ Ｅｎｇｉｎｅｅｒｉｎｇ，２００５，１７（６）：７３４－７４９．
［１６］ＶＥＲＢＥＲＴ Ｋ，ＭＡＮＯＵＳＥＬＩＳ Ｎ，ＯＣＨＯＡ Ｘ，ｅｔ ａｌ．Ｃｏｎｔｅｘｔ－ａｗａｒｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ ｆｏｒ ｌｅａｒｎｉｎｇ：Ａ ｓｕｒｖｅｙ ａｎｄ ｆｕｔｕｒｅ ｃｈａｌｌｅｎｇｅｓ
［Ｊ］．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｌｅａｒｎｉｎｇ Ｔｅｃｈｎｏｌｏｇｉｅｓ，２０１２，５（４）：３１８－３３５．
［１７］ＰＡＺＺＡＮＩ Ｍ Ｊ，ＢＩＬＬＳＵＳ Ｄ．Ｃｏｎｔｅｎｔ－ｂａｓｅｄ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ Ｓｙｓｔｅｍｓ［Ｍ］．Ｈｅｉｄｅｌｂｅｒｇ：Ｌｅｃｔｕｒｅ Ｎｏｔｅｓ ｉｎ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ，２００７．
［１８］ＮＡＫＡＭＵＲＡ Ａ．Ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｕｓｉｎｇ ｗｅｉｇｈｔｅｄ ｍａｊｏｒｉｔｙ ｐｒｅｄｉｃｔｉｏｎ ａｌｇｏｒｉｔｈｍｓ［Ｃ］／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １５ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒ－
ｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．［Ｓｌ．．］：［ｓ．ｎ．］，１９９８：３９５－４０３．
［１９］ＲＩＣＨ Ｅ．Ｕｓｅｒ ｍｏｄｅｌｉｎｇ ｖｉａ ｓｔｅｒｅｏｔｙｐｅｓ［Ｊ］．Ｃｏｇｎｉｔｉｖｅ Ｓｃｉｅｎｃｅ，１９７９，３（４）：３２９－３５４．
［２０］ＢＡＬＡＢＡＮＯＶＩＣ Ｍ，ＳＨＯＨＡＭ Ｙ．Ｆａｂ：Ｃｏｎｔｅｎｔ－ｂａｓｅｄ，ｃｏｌｌａｂｏｒａｔｉｖｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｊ］．Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ ｏｆ ｔｈｅ ＡＣＭ，１９９７，４０（３）：
６６－７２．
［２１］刘玮．电子商务系统中的信息推荐方法研究［Ｊ］．情报科学，２００６，２４（２）：３００－３０３．
ＬＩＵ Ｗｅｉ．Ｒｅｓｅａｒｃｈ ｏｎ ｉｎｆｏｒｍａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｉｎ Ｅ－ｃｏｍｍｅｒｃｅ ｓｙｓｔｅｍｓ［Ｊ］．Ｉｎｆｏｒｍａｔｉｏｎ Ｓｃｉｅｎｃｅ，２００６，２４（２）：３００－３０３．
［２２］ＧＯＬＤＢＥＲＧ Ｄ，ＮＩＣＨＯＬＳ Ｄ，ＯＫＩ Ｂ Ｍ，ｅｔ ａｌ．Ｕｓｉｎｇ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｔｏ ｗｅａｖｅ ａｎ ｉｎｆｏｒｍａｔｉｏｎ ｔａｐｅｓｔｒｙ［Ｊ］．Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ ｏｆ ｔｈｅ
ＡＣＭ，１９９２，３５（１２）：６１－７０．
［２３］李宇琦，陈维政，闫宏飞，等．基于网络表示学习的个性化商品推荐［Ｊ］．计算机学报，２０１９，４２（８）：１７６７－１７７８．
ＬＩ Ｙｕｑｉ，ＣＨＥＮ Ｗｅｉｚｈｅｎｇ，ＹＡＮ Ｈｏｎｇｆｅｉ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ ｇｒａｐｈ－ｂａｓｅｄ ｅｍｂｅｄｄｉｎｇ ｆｏｒ ｐｅｒｓｏｎａｌｉｚｅｄ ｐｒｏｄｕｃｔ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ．［Ｊ］．Ｃｈｉｎｅｓｅ
Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１９，４２（８）：１７６７－１７７８．
［２４］周春华，沈建京，李艳，等．经典推荐算法研究综述［Ｊ］．计算机科学与应用，２０１９，９（９）：１８０３－１８１７．
ＺＨＯＵ Ｃｈｕｎｈｕａ，ＳＨＥＮ Ｊｉａｎｊｉｎｇ，ＬＩ Ｙａｎ，ｅｔ ａｌ．Ｒｅｖｉｅｗ ｏｆ ｃｈａｓｓｉｃａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｌｇｏｒｉｔｈｍｓ［Ｊ］．Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ ａｎｄ Ａｐｐｌｉｃａｔｉｏｎ，
２０１９，９（９）：１８０３－１８１７．
［２５］陈楠楠．基于深度学习的推荐系统方法研究［Ｄ］．桂林：桂林电子科技大学，２０１９．
ＣＨＥＮ Ｎａｎｎａｎ．Ｒｅｓｅａｒｃｈ ｏｎ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ Ｓｙｓｔｅｍ Ｂａｓｅｄ ｏｎ Ｄｅｅｐ Ｌｅａｒｎｉｎｇ［Ｄ］．Ｇｕｉｌｉｎ：Ｇｕｉｌｉｎ Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｅｌｅｃｔｒｏｎｉｃ Ｔｅｃｈｎｏｌｏｇｙ，
２０１９．
［２６］ＳＡＲＷＡＲ Ｂ Ｍ，ＫＡＲＹＰＩＳ Ｇ，ＫＯＮＳＴＡＮ Ｊ Ａ，ｅｔ ａｌ．Ｉｔｅｍ－ｂａｓｅｄ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ａｌｇｏｒｉｔｈｍｓ［Ｊ］．Ｉｎｔｅｒｎａｔｉｏｎａｌ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ，２００１，１：２８５－２９５．
［２７］ＡＭＢＵＬＧＥＫＡＲ Ｈ Ｐ，ＰＡＴＨＡＫ Ｍ Ｋ，ＫＯＫＡＲＥ Ｍ Ｂ．Ａ ｓｕｒｖｅｙ ｏｎ ｃｏｌｌａｂｏｒａｔｉｖｅ ｆｉｌｔｅｒｉｎｇ：Ｔａｓｋｓ，ａｐｐｒｏａｃｈｅｓ ａｎｄ ａｐｐｌｉｃａｔｉｏｎｓ［Ｃ］／／
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｅｔｈｉｃａｌ Ｈａｃｋｉｎｇ Ｃｏｎｆｅｒｅｎｃｅ ２０１８．Ｓｉｎｇａｐｏｒｅ：Ｓｐｒｉｎｇｅｒ，２０１９：２８９－３００．
［２８］ＣＡＮＺＩＡＮＩ Ａ，ＰＡＳＺＫＥ Ａ，ＣＵＬＵＲＣＩＥＬＬＯ Ｅ．Ａｎ ａｎａｌｙｓｉｓ ｏｆ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｍｏｄｅｌｓ ｆｏｒ ｐｒａｃｔｉｃａｌ ａｐｐｌｉｃａｔｉｏｎｓ［Ｊ］．Ｃｏｍｐｕｔｅｒ
Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ，２０１６：ａｒＸｉｖ：１６０５．０７６７８．
［２９］ＥＲＨＡＮ Ｄ，ＳＺＥＧＥＤＹ Ｃ，ＴＯＳＨＥＶ Ａ，ｅｔ ａｌ．Ｓｃａｌａｂｌｅ ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ ｕｓｉｎｇ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ［Ｃ］／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎ－
ｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．［Ｓｌ．．］：［ｓ．ｎ．］，２０１４：２１４７－２１５４．
［３０］ＣＩＲＥＳＡＮ Ｄ，ＭＥＩＥＲ Ｕ．Ｍｕｌｔｉ－ｃｏｌｕｍｎ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｏｆｆｌｉｎｅ ｈａｎｄｗｒｉｔｔｅｎ Ｃｈｉｎｅｓｅ ｃｈａｒａｃｔｅｒ ｃｌａｓｓｉｆｉｃａｔｉｏｎ［Ｃ］／／２０１５Ｉｎｔｅｒｎａ－
ｔｉｏｎａｌ Ｊｏｉｎｔ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ（ＩＪＣＮＮ）．Ｋｉｌｌａｒｎｅｙ：ＩＥＥＥ，２０１５：１－６．
［３１］ＳＬＡＤＯＪＥＶＩＣ Ｓ，ＡＲＳＥＮＯＶＩＣ Ｍ，ＡＮＤＥＲＬＡ Ａ，ｅｔ ａｌ．Ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｂａｓｅｄ ｒｅｃｏｇｎｉｔｉｏｎ ｏｆ ｐｌａｎｔ ｄｉｓｅａｓｅｓ ｂｙ ｌｅａｆ ｉｍａｇｅ ｃｌａｓｓｉｆｉ－
ｃａｔｉｏｎ［Ｊ］．Ｃｏｍｐｕｔａｔｉｏｎａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ ａｎｄ Ｎｅｕｒｏｓｃｉｅｎｃｅ，２０１６（６）：１－１１．
［３２］ＮＯＶＯＳＥＬＯＶ Ｓ，ＳＨＵＬＩＰＡ Ａ，ＫＲＥＭＮＥＶ Ｉ，ｅｔ ａｌ．Ｏｎ ｄｅｅｐ ｓｐｅａｋｅｒ ｅｍｂｅｄｄｉｎｇｓ ｆｏｒ ｔｅｘｔ－ｉｎｄｅｐｅｎｄｅｎｔ ｓｐｅａｋｅｒ ｒｅｃｏｇｎｉｔｉｏｎ［Ｃ］／／Ｏｄｙｓ－
ｓｅｙ ２０１８Ｔｈｅ Ｓｐｅａｋｅｒ ａｎｄ Ｌａｎｇｕａｇｅ Ｒｅｃｏｇｎｉｔｉｏｎ Ｗｏｒｋｓｈｏｐ．［Ｓｌ．．］：［ｓ．ｎ．］，２０１８：１－８．
［３３］ＭＩＩＫＫＵＬＡＩＮＥＮ Ｒ，ＬＩＡＮＧ Ｊ，ＭＥＹＥＲＳＯＮ Ｅ，ｅｔ ａｌ．Ｅｖｏｌｖｉｎｇ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ［Ｊ］．Ｎｅｕｒａｌ ａｎｄ Ｅｖｏｌｕｔｉｏｎａｒｙ Ｃｏｍｐｕｔｉｎｇ，２０１７：
ａｒＸｉｖ：１７０３．００５４８．
［３４］ＣＯＶＩＮＧＴＯＮ Ｐ，ＡＤＡＭＳ Ｊ，ＳＡＲＧＩＮ Ｅ．Ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｙｏｕｔｕｂｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎｓ［Ｃ］／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ １０ｔｈ ＡＣＭ Ｃｏｎ－
ｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｂｏｓｔｏｎ：ＡＣＭ，２０１６：１９１－１９８．
［３５］ＺＨＡＮＧ Ｌｉｂｏ，ＬＵＯ Ｔｉｅｊｉａｎ，ＺＨＡＮＧ Ｆｅｉ，ｅｔ ａｌ．Ａ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｍｏｄｅｌ ｂａｓｅｄ ｏｎ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ［Ｊ］．ＩＥＥＥ Ａｃｃｅｓｓ，２０１８，６：
９４５４－９４６３． 第１期 周万珍，等：推荐系统研究综述 ８７
［３６］周飞燕，金林鹏，董军．卷积神经网络研究综述［Ｊ］．计算机学报，２０１７，４０（６）：１２２９－１２５１．
ＺＨＯＵ Ｆｅｉｙａｎ，ＪＩＮ Ｌｉｎｐｅｎｇ，ＤＯＮＧ Ｊｕｎ．Ｒｅｖｉｅｗ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ［Ｊ］．Ｃｈｉｎｅｓｅ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒｓ，２０１７，４０（６）：１２２９－
１２５１．
［３７］ＴＡＮＧ Ｊｉａｘｉ，ＷＡＮＧ Ｋｅ．Ｐｅｒｓｏｎａｌｉｚｅｄ ｔｏｐ－Ｎ ｓｅｑｕｅｎｔｉａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｖｉａ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｓｅｑｕｅｎｃｅ ｅｍｂｅｄｄｉｎｇ［Ｃ］／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｅｌｅｖｅｎｔｈ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｗｅｂ Ｓｅａｒｃｈ ａｎｄ Ｄａｔａ Ｍｉｎｉｎｇ．［Ｓｌ．．］：［ｓ．ｎ．］，２０１８：５６５－５７３．
［３８］ＫＡＲＰＡＴＨＹ Ａ，ＴＯＤＥＲＩＣＩ Ｇ，ＳＨＥＴＴＹ Ｓ，ｅｔ ａｌ．Ｌａｒｇｅ－ｓｃａｌｅ ｖｉｄｅｏ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｗｉｔｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ［Ｃ］／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｏｆ ｔｈｅ ＩＥＥＥ ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．［Ｓｌ．．］：［ｓ．ｎ．］，２０１４：１７２５－１７３２．
［３９］ＫＲＩＺＨＥＶＳＫＹ Ａ，ＳＵＴＳＫＥＶＥＲ Ｉ，ＨＩＮＴＯＮ Ｇ Ｅ．Ｉｍａｇｅｎｅｔ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｗｉｔｈ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ［Ｃ］／／Ａｄｖａｎｃｅｓ ｉｎ
Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．［Ｓｌ．．］：［ｓ．ｎ．］，２０１２：１０９７－１１０５．
［４０］ＫＩＭ Ｄ，ＰＡＲＫ Ｃ，ＯＨ Ｊ，ｅｔ ａｌ．Ｃｏｎｖｏｌｕｔｉｏｎａｌ ｍａｔｒｉｘ ｆａｃｔｏｒｉｚａｔｉｏｎ ｆｏｒ ｄｏｃｕｍｅｎｔ ｃｏｎｔｅｘｔ－ａｗａｒｅ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｃ］／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
１０ｔｈ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｂｏｓｔｏｎ：ＡＣＭ，２０１６：２３３－２４０．
［４１］ＴＵＡＮ Ｔ Ｘ，ＰＨＵＯＮＧ Ｔ Ｍ．３Ｄｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｓｅｓｓｉｏｎ－ｂａｓｅｄ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ ｗｉｔｈ ｃｏｎｔｅｎｔ ｆｅａｔｕｒｅｓ［Ｃ］／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｅｌｅｖｅｎｔｈ ＡＣＭ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｃｏｍｍｅｎｄｅｒ Ｓｙｓｔｅｍｓ．Ｃｏｍｏ：ＡＣＭ，２０１７：１３８－１４６．
［４２］ｖａｎ ｄｅｎ ＯＯＲＤ Ａ，ＤＩＥＬＥＭＡＮ Ｓ，ＳＣＨＲＡＵＷＥＮ Ｂ．Ｄｅｅｐ ｃｏｎｔｅｎｔ－ｂａｓｅｄ ｍｕｓｉｃ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｃ］／／Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ
Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．［Ｓｌ．．］：［ｓ．ｎ．］，２０１３：２６４３－２６５１．
［４３］李光．基于循环神经网络的推荐算法研究［Ｄ］．哈尔滨：哈尔滨工程大学，２０１７．
ＬＩ Ｇｕａｎｇ．Ｒｅｓｅａｒｃｈ ｏｎ Ｒｅｃｏｍｍｅｎｄａｔｉｏｎ Ａｌｇｏｒｉｔｈｍ Ｂａｓｅｄ ｏｎ Ｒｅｃｕｒｒｅｎｔ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ［Ｄ］．Ｈａｒｂｉｎ：Ｈａｒｂｉｎ Ｅｎｇｉｎｅｅｒｉｎｇ Ｕｎｉｖｅｒｓｉｔｙ，
２０１７．
［４４］ＬＩＵ Ｑｉａｎｇ，ＷＵ Ｓｈｕ，ＷＡＮＧ Ｄｉｙｉ，ｅｔ ａｌ．Ｃｏｎｔｅｘｔ－ａｗａｒｅ ｓｅｑｕｅｎｔｉａｌ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｃ］／／２０１６ＩＥＥＥ １６ｔｈ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
Ｄａｔａ Ｍｉｎｉｎｇ（ＩＣＤＭ）．Ｂａｒｃｅｌｏｎａ：ＩＥＥＥ，２０１６：１０５３－１０５８．
［４５］ＭＡＮＯＴＵＭＲＵＫＳＡ Ｊ，ＭＡＣＤＯＮＡＬＤ Ｃ，ＯＵＮＩＳ Ｉ．Ａ ｃｏｎｔｅｘｔｕａｌ ａｔｔｅｎｔｉｏｎ ｒｅｃｕｒｒｅｎｔ ａｒｃｈｉｔｅｃｔｕｒｅ ｆｏｒ ｃｏｎｔｅｘｔ－ａｗａｒｅ ｖｅｎｕｅ ｒｅｃｏｍｍｅｎ－
ｄａｔｉｏｎ［Ｃ］／／Ｔｈｅ ４１ｓｔ Ｉｎｔｅｒｎａｔｉｏｎａｌ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ＆Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ａｎｎ Ａｒｂｏｒ：ＡＣＭ，
２０１８：５５５－５６４．
［４６］王立，张谧．基于ＬＳＴＭ的ＰＯＩ个性化推荐框架［Ｊ］．计算机系统应用，２０１８，２７（１２）：５６－６１．
ＷＡＮＧ Ｌｉ，ＺＨＡＮＧ Ｍｉ．ＬＳＴＭ－Ｂａｓｅｄ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｆｒａｍｅｗｏｒｋ ｆｏｒ ｎｅｘｔ ＰＯＩ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｊ］．Ｃｏｍｐｕｔｅｒ Ｓｙｓｔｅｍｓ ＆Ａｐｐｌｉｃａｔｉｏｎｓ，
２０１８，２７（１２）：５６－６１．
［４７］ＹＡＮＧ Ｌｉｂｉｎ，ＺＨＥＮＧ Ｙｕ，ＣＡＩ Ｘｉａｏｙａｎ，ｅｔ ａｌ．Ａ ＬＳＴＭ ｂａｓｅｄ ｍｏｄｅｌ ｆｏｒ ｐｅｒｓｏｎａｌｉｚｅｄ ｃｏｎｔｅｘｔ－ａｗａｒｅ ｃｉｔａｔｉｏｎ ｒｅｃｏｍｍｅｎｄａｔｉｏｎ［Ｊ］．ＩＥＥＥ
Ａｃｃｅｓｓ，２０１８，６：５９６１８－５９６２７．
［４８］ＺＨＯＵ Ｊｉｅ，ＣＵＩ Ｇａｎｑｕ，ＺＨＡＮＧ Ｚｈｅｎｇｙａｎ，ｅｔ ａｌ．Ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ：Ａ ｒｅｖｉｅｗ ｏｆ ｍｅｔｈｏｄｓ ａｎｄ ａｐｐｌｉｃａｔｉｏｎｓ［Ｊ］．Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ，
２０１８：ａｒＸｉｖ：１８１２．０８４３４．
［４９］ＷＵ Ｚｏｎｇｈａｎ，ＰＡＮ Ｓｈｉｒｕｉ，ＣＨＥＮ Ｆｅｎｇｗｅｎ，ｅｔ ａｌ．Ａ ｃｏｍｐｒｅｈｅｎｓｉｖｅ ｓｕｒｖｅｙ ｏｎ ｇｒａｐｈ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ［Ｊ］．Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ，２０１９：
ａｒＸｉｖ：１９０１．００５９６．
［５０］ＹＩＮＧ Ｒｅｘ，ＨＥ Ｒｕｉｎｉｎｇ，ＣＨＥＮ Ｋａｉｆｅｎｇ，ｅｔ ａｌ．Ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｗｅｂ－ｓｃａｌｅ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ［Ｃ］／／Ｐｒｏｃｅｅｄ－
ｉｎｇｓ ｏｆ ｔｈｅ ２４ｔｈ ＡＣＭ ＳＩＧＫＤＤ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｋｎｏｗｌｅｄｇｅ Ｄｉｓｃｏｖｅｒｙ ＆Ｄａｔａ Ｍｉｎｉｎｇ．Ｌｏｎｄｏｎ：ＡＣＭ：２０１８：９７４－９８３．
［５１］ＷＡＮＧ Ｈｏｎｇｗｅｉ，ＺＨＡＯ Ｍｉａｏ，ＺＨＡＮＧ Ｍｅｎｇｄｉ，ｅｔ ａｌ．Ｋｎｏｗｌｅｄｇｅ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｒｅｃｏｍｍｅｎｄｅｒ ｓｙｓｔｅｍｓ［Ｃ］／／Ｔｈｅ
Ｗｏｒｌｄ Ｗｉｄｅ Ｗｅｂ Ｃｏｎｆｅｒｅｎｃｅ．Ｓａｎ Ｆｒａｎｃｉｓｃｏ：ＡＣＭ，２０１９：３３０７－３３１３．
［５２］ＺＨＡＮＧ Ｊｉａｎｉ，ＳＨＩ Ｘｉｎｇｊｉａｎ，ＺＨＡＯ Ｓｈｅｎｇｌｉｎ，ｅｔ ａｌ．ＳＴＡＲ－ＧＣＮ：Ｓｔａｃｋｅｄ ａｎｄ ｒｅｃｏｎｓｔｒｕｃｔｅｄ ｇｒａｐｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｒｅｃｏｍ－
ｍｅｎｄｅｒ ｓｙｓｔｅｍｓ［Ｊ］．Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ，２０１９：ａｒＸｉｖ：１９０５．１３１２９． --------------------------------------------------------------------------------- JournalofComputerApplications ISSN1001-9081 2022-06-10
计算机应用 ：
,2022,42(6):1898-1913 CODENJYIIDU http//www.joca.cn
文章编号： - （ ） - - ： -
1001 9081 2022 06 1898 16 DOI 10.11772/j.issn.1001 9081.2021040607
推荐系统综述
于 蒙，何文涛，周绪川 ，崔梦天，吴克奇，周文杰
*
（计算机系统国家民委重点实验室（西南民族大学），成都 ）
610041
（ 通信作者电子邮箱 ）
∗ xczhou@swun.edu.cn
摘 要：随着网络应用的不断发展，网络资源呈指数型增长，信息过载现象日益严重，如何高效获取符合需求的资
源成为困扰人们的问题之一。推荐系统能对海量信息进行有效过滤，为用户推荐符合其需求的资源。对推荐系统的
研究现状进行详细介绍，包括基于内容的推荐、协同过滤推荐和混合推荐这三种传统推荐方式，并重点分析了基于卷
积神经网络（ ）、深度神经网络（ ）、循环神经网络（ ）和图神经网络（ ）这四种常见的深度学习推荐模
CNN DNN RNN GNN
型的研究进展；归纳整理了推荐领域常用的数据集，同时分析对比了传统推荐算法和基于深度学习的推荐算法的差
异。最后，总结了实际应用中具有代表性的推荐模型，讨论了推荐系统面临的挑战和未来的研究方向。
关键词：推荐算法；协同过滤；深度学习；卷积神经网络；深度神经网络；循环神经网络；图神经网络
中图分类号： 文献标志码：
TP391 A
Review of recommendation system
， ， ， ， ，
*
YUMeng HEWentao ZHOUXuchuan CUIMengtian WUKeqi ZHOUWenjie
（TheKeyLaboratoryforComputerSystemsofStateEthnicAffairsCommission （SouthwestMinzuUniversity），ChengduSichuan ，China）
610041
Abstract: ，
With the continuous development of network applications network resources are growing exponentially and
，
informationoverloadisbecomingincreasinglyserious sohowtoefficientlyobtaintheresourcesthatmeettheuserneedshas
become one of the problems that bothering people. Recommendation system can effectively filter mass information and
recommend the resources that meet the users needs. The research status of the recommendation system was introduced in
， - ，
detail including three traditional recommendation methods of content based recommendation collaborative filtering
，
recommendation and hybrid recommendation and the research progress of four common deep learning recommendation
（ ）， （ ）， （ ）
modelsbasedonConvolutionalNeuralNetwork CNN DeepNeuralNetwork DNN RecurrentNeuralNetwork RNN
（ ）
and Graph Neural Network GNN were analyzed in focus. The commonly used datasets in recommendation field were
， -
summarized and the differences between the traditional recommendation algorithms and the deep learning based
，
recommendation algorithms were analyzed and compared. Finally the representative recommendation models in practical
，
applications were summarized and the challenges and the future research directions of recommendation system were
discussed.
Key words:
recommendation algorithm; collaborative filtering; deep learning; Convolutional Neural Network (CNN);
DeepNeuralNetwork(DNN); RecurrentNeuralNetwork(RNN); GraphNeuralNetwork(GNN)
引言 资源，缓解信息过载（ ）［ 2］的问题。推荐
0 Information Overload
技术经过不断的发展和更新，已经在教育、音乐、电子商务、
近年来，网络应用尤其是移动应用的快速发展，使得人
社交网络等领域广泛应用。协同过滤算法被提出后，推荐系
们能够方便地浏览大量的网络信息资源，如何为用户从海量
统逐渐成为一个新的研究热点，同时也面临着数据稀疏问题
的信息资源中推荐符合其需求的资源（如商品、电影、书籍
（用户对推荐项目的评分数量太少）和冷启动问题（新的推荐
等）成了目前研究者们关注的问题之一。推荐系统 项目和新用户无评分数据）。深度学习（ ， ）
DeepLearning DL
（ ， ）［ 1］可以有效地对信息进行过滤 是具备识别、分析、计算的机器学习算法，为缓解数据稀疏和
RecommendationSystem RS
和筛选，帮助用户以个性化的方式来检索符合其需求的信息 冷启动问题带来了新的机遇， 年以来，深度学习已经在
2015
收稿日期： ；修回日期： ；录用日期： 。 基金项目：国家自然科学基金资助项目（ ）；四川省科
2021-04-19 2021-07-14 2021-07-20 12050410248
技计划项目（ ）；西南民族大学研究生创新型科研项目（ ）。
2021YFH0120 CX2020SZ04
作者简介：于蒙（ —），女，宁夏固原人，硕士研究生， 会员，主要研究方向：推荐系统、信息过滤、数据挖掘； 何文涛（ —），男，湖
1995 CCF 1996
南永州人，硕士研究生，主要研究方向：深度学习、数据挖掘； 周绪川（ —），男，重庆人，教授，博士， 会员，主要研究方向：数据挖掘、深
1972 CCF
度学习； 崔梦天（ —），女，内蒙古乌兰浩特人，教授，博士，主要研究方向：智能信息处理； 吴克奇（ —），男，湖北孝感人，硕士研究生，
1972 1997
主要研究方向：推荐系统； 周文杰（ —），男，四川广安人，硕士研究生，主要研究方向：数据挖掘。
1997 第 期 于蒙等：推荐系统综述
6 1899
语义挖掘、人脸识别、语音识别等领域广泛应用，深度学习模 基于内容过滤的推荐技术
1.1
型的逐渐成熟也为推荐系统的发展带来了新的机遇。 推荐系统最早被应用在电子商务网站，它通常根据用户
2016
年的 推荐系统年会上， 等［ 3］指出将深度学习和推 的购买行为记录或购买评价来向用户推荐与其需求偏好相
ACM Song
荐系统融合作为推荐系统未来研究的重点，由此，国内外的 似的物品［ 15］。文献［ ］中提出了一种基于上下文内容的方
16
学者和研究机构针对这一问题开展了大量的研究。 年 法来匹配和排序服务，认为上下文是用来描述一个给定文本
2017
以来，机器学习方向的顶级会议（如： 、 、 等） 的相关的语言术语集。该方法通过解析服务的底层文档提
ICML NIPS COLT
中有关深度学习的个性化推荐文章逐年增加。 年，文 取作为文本术语的令牌，并使用字符串匹配函数来匹配这些
2019
献［］的研究认为深度学习能够从数据中自动学习特征的不 令牌的本体。文献［ ］中提出了一种匹配用户查询和服务
4 17
同层次表达和抽象，是解决传统推荐技术出现的冷启动、数 描述以及相关上下文信息的服务发现方法。该方法将上下
据稀疏等问题的有效策略。 文提供者提供的上下文信息、服务提供者提供的服务描述和
用户提供的服务请求三者用本体建模，然后将这三条信息逐
传统的推荐算法
1 个匹配。文献［ ］中提出了一个 服务上下文分类，然
18 Web
推荐系统是数据挖掘、预测算法［ 5］、机器学习等多种学 后使用本体来定义这个分类。上下文由一个两级机制建模，
科结合而成的一个新的研究领域。文献［］中最早对推荐系 该机制涵盖了上下文规范和服务策略，提供了一个对等体系
6
统给出定义，指出在日常生活中无论是了解的事件还是未知 结构来完全匹配 服务上下文策略，源服务的每个上下文
Web
的事件，时刻需要人们做出决策，面对熟悉的事情，人们常常 都由候选服务的策略匹配。
可以依赖过去的经验做出合理的决策，然而，在面对未知的 总之，基于内容过滤的推荐（ ）技术的核心思想是：以
CB
事情时，人们则需要他人的口头建议、书评、影评、推荐等来 用户历史的选择记录或偏好记录作为参考推荐，挖掘其他未
进行判断，文献中认为推荐系统的意义是能够为推荐项目和 知的记录中与参考推荐关联性高的项目作为系统推荐的内
用户建立适当的匹配关系。文献［］中则认为推荐系统是为 容。通过用户的显式反馈（如评价、认可度、喜欢 不喜欢）和
7 \
不同用户从大量的项目中匹配符合其兴趣偏好但是未被用 隐式反馈（如浏览时间、点击次数、搜索次数、停留时间等）获
户观察到的项目，它认为推荐系统正在成为一个具有重大经 取用户在某段时间内的交互记录，然后学习这些记录中用户
济影响的重要业务。 的偏好并将其标记为特征；接着计算用户偏好与待测推荐对
推荐系统从本质上来说是对人的某种行为的模拟，它通 象在内容上的相似度（或匹配度）；最后将待测推荐对象与用
过推荐算法对特定的数据信息进行分析处理，然后将处理后 户偏好的相似度进行排序，从而为用户选择出符合其兴趣偏
的结果推荐给有相关需求的用户［ 8］。推荐算法是推荐系统 好的推荐对象。计算相似度是一个关键部分，会直接影响推
的核心，它能根据用户的历史购买需求、行为记录或者相似 荐的策略。计算相似度的方式有多种，常用式（）计算相
2
偏好进行建模，从而发现符合用户偏好的需求，并将之推荐 似度［ 19］：
给用户。推荐系统的形式化定义［ 9- 10］如下： u( p，c) score( userprofile，content) （）
= 2
定义 推荐系统。设P表示所有用户的集合，C为用
其中：p表示用户，c表示推荐内容，userprofile表示p偏好的内
1
户可推荐的对象的集合。实际问题中，P、C都是规模非常大
容，content表示系统为用户推荐的内容。score用来计算用户
的集合。函数f表示用户p对c的喜爱度，即f：P C R，其
× → 偏好和推荐内容的相似值，最终用效用函数u 来定义，根据
()
中R表示非负实数的有限序列，将让函数f取得最大值的推
u的值来排序，数值越大排序越靠前。
荐对象c C推荐给用户。如式（）所示： score有多种计算方式，通常使用向量夹角余弦的距离计
′ ∈ ( ) 1
∀p ∈ P，c p′ = argmcaCx f p，c （ 1） 算方式：
∈
k
c 表示最符合用户p偏好的推荐对象。因此，在为用户选择
最p′
感兴趣的对象之前，推荐系统必须利用已知的用户认可度
u( p，c)
=
cos(
w p，w
c)
=
∑i =1w i，pw i，c
（ 3）
去完成未知的推荐对象认可度的预测，这是推荐系统外推的 k k
w2i，p w2i，c
过程。近年来，从不同的角度给推荐技术分类，不同的学者 ∑i ∑i
=1 =1
赋予推荐系统不同的内涵，目前传统的推荐系统分为三 其中：w 表示userprofile的特征向量；w 表示content的关键词
p c
类［ 11］：基于内容过滤的推荐（ - ， 向量权重。
Content Based recommendation
）［ 12］、基 于 协 同 过 滤 的 推 荐（ 对计算得的u值进行排序，u值越大，说明推荐的对象越
CB Collaborative Filtering
， ）［ 13］ 和 混 合 推 荐 （ 符合用户的喜好。例如为用户推荐电影时，系统会学习用户
recommendation CF Hybrid
）［ 14］，如图 所示。 的历史观看记录并分析，然后找到这些电影的共性，预测出
Recommendation 1
用户感兴趣的电影类型，然后从海量的电影清单中选择出与
用户偏好相似的电影。用户偏好记录的特征标记和推荐内
容是 的关键，用户评价对基于内容的推荐系统影响
CB
图 传统推荐系统分类 较小［ 20］。
1
系统框架如图 所示，包含数据挖掘处理部分和自适
Fig. 1 Classificationoftraditionalrecommendationsystems CB 2 计算机应用 第 卷
1900 42
应推荐部分，对用户来说这两部分都是隐藏的。数据挖掘部 文献［ ］中通过分析用户矩阵来确定这些用户与用户
27
分主要是通过建立向量空间模型对用户的偏好特征进行分 以及不同用户与其感兴趣的项目之间的差异，从而根据差异
析和提取；自适应推荐部分的主要作用就是将用户偏好的相 有针对性地为用户推荐合适的项目。然而基于用户的推荐
似度排序，自动生成推荐列表，将推荐列表通过 服务器 过程并不能依赖相似的用户都了解对方，于是，文献［ ］中
Web 28
推荐给用户。 提出了一种基于匿名合作的协同过滤算法，专门用于解决为
不同用户推荐新闻和电影的问题。基于用户的协同过滤算
法虽然能够发现用户隐藏的兴趣点和偏好，但该技术存在严
重的冷启动问题。在实际问题中，推荐系统中的用户种类不
是一成不变的，当有新的用户类型出现时，系统中缺少该类
用户的偏好记录，那么推荐系统就无法对该类用户提供符合
其需求的推荐。为了解决协同过滤所面临的冷启动问题，文
图 系统框架 献［ ］中将传统的协同过滤算法和神经网络算法相结合。
2 CB 29
神经网络算法是深度学习算法中的一种，能够分析并计算用
Fig. 2 FrameworkofCB
协同过滤推荐 户与项目之间的复杂的非线性关系，效率较高。文献［ ］中
1.2 29
协同过滤推荐（ ）算法的核心是通过分析评分矩阵 的混合模型关注到了推荐对象的典型性和多样性，在韩国国
CF
（通常是用户对项目的评分）来得到用户、项目之间的依赖关 民健康营养调查数据的应用中经过评估，结果表明它确实能
系，并进一步预测新用户与项目之间的关联关系。 算法 提高推荐效果。
CF
是最早被研究和讨论的推荐技术之一，它有效地推动了个性
化推荐的发展。 年，文献［ ］中利用传统的协同过滤
1992 21
技术解决了垃圾邮件分类问题；亚马逊（ ）是目前较
Amazon
大的网络购物平台之一，主要利用 算法为用户推荐商品；
CF
在其主页上也使用 算法为用户推荐喜爱的电视
Netflix CF 图 基于用户的协同过滤推荐
节目。 4
-
如今协同过滤技术被广泛应用在音乐推荐、电影推荐、 Fig.4 Userbasedcollaborativefilteringrecommendation
基于模型的推荐
电子商务等领域［ 22］， 主要分为基于内存（ - ） 1.2.2
CF Memory Based 基于模型的推荐算法是通过训练数学模型来预测用户
的推荐和基于模型（ - ）的推荐。
Model Based
对未交互项目的评分情况，通常包括概率矩阵分解
基于内存的推荐
1.2.1
基于内存的协同过滤推荐通过用户 项（ - ）的评
（
Probabilistic Matrix
Factorization， PMF）［ 30］和奇异值分解
价矩阵寻找相似用户和相似项目［ 23- 24］之间- 的相Us 似er 度Ite ，m 进而为 （ SingularValueDecomposition， SVD）［ 31］。 PMF和 SVD的主要
思路是先对用户与项目的历史交互数据记录建立适当的模
新用户构建相似度矩阵，预测用户感兴趣的项目。通过寻找
型，然后产生符合用户需求的推荐列表，其中应用较为广泛
相似项目进行的推荐称为基于项目的推荐；通过寻找相似用
户进行的推荐称为基于用户的推荐。 的是基于矩阵分解的推荐。
基于项目的协同过滤技术主要挖掘并分析的是不同推 模型一般认为用户和推荐项目的交互行为仅仅由
PMF
荐项目间隐藏的关系而不是用户之间的关系［ 25］，项目间的 几个潜在的影响其兴趣偏好的因素决定，将高阶评分矩阵
相似性计算是该技术的关键［ 26］，其推荐过程如图 3。该过程 R n ×m分解为两个低维的矩阵E 、Q，如式（ 4）所示：
可以理解为：若有 个不同用户 、，且他们都对物品 、表 R ETQ （）
2 A B 1 3 ≈ 4
示出较高的喜爱，那么我们可以认为 、物品存在某种相 其中：E e，e，…，e 表示低维用户特征矩阵，e表示用户
1 3 ={ 1 2 n} i
似。当系统中出现的新用户 并选择了物品 时，那么系统 i的k维特征向量；Q q，q，…，q 代表低维的推荐项目特
C 1 ={ 1 2 n}
便会自动将与物品 相似度高的物品 推荐给他。 征矩阵。
1 3
在实际推荐问题中，为了降低预测评分和实际评分之间
的差值，得到更准确的推荐列表，一般将预测评分与实际评
分之间误差的平方作为损失函数，如式（）所示。
5
( ) n m ( )
图
3
基于项目的协同过滤推荐
f R，U，V
=
1
2∑i =1∑j
=1I
i，j
R
ij -
E iTQ
j
2
+
- γ γ
Fig.3 Itembasedcollaborativefilteringrecommendation p‖E‖2 q‖Q‖2 （）
基于用户的推荐过程如图 所示，经过评价矩阵计算， + 5
4 2 F 2 F
认为用户 A与 B相似，在物品选择时，若用户 A选择了物品 其中：I ij表示一个示性函数，当I ij = 1时，代表用户u i对推荐
、、，用户 选择了物品 、，那么在物品推荐时可以认为 项目S已经评分了，否则就表示用户没有对推荐项目进行评
i
1 2 3 B 1 3
用户 的选择和用户 相似，因此推荐系统可以将物品 推 分；γ γ 代表着惩罚因子，是为了防止出现过拟合现象添加
B A 2
p、q
荐给用户 。 的正则化项，γ γ 的值决定正则化程度，其值越大表示正则
B p、q 第 期 于蒙等：推荐系统综述
6 1901
化的程度越大；‖E‖ 和‖Q‖ 代表着矩阵范数，一般利用随机 由于社会环境的复杂化，系统为用户生成的推荐常常不
F F
能满足用户变化的兴趣爱好，大部分用户经常会接受来自身
梯度下降法对目标函数进行优化处理，对原高阶评分矩阵
边朋友的推荐，两个用户之间的相似性常常受到商品的流行
R 的缺失值进行预测。。
n m
× 程度、用户偏好、社会关系等诸多因素的影响，因此文献［ ］
年，文献［ ］中利用用户对推荐项目的评分差异 34
2016 32 中提出了一种结合用户社交网络的矩阵分解模型，如图 所
建模，建立了成对概率矩阵分解（ 5
PairwiseProbabilisticMatrix 示。该模型首先为用户设计了一种基于粒子群优化
， ）模型。该模型能够自动学习用户对交
Factorization PPMF （ ， ）算法的 均值聚类算法
Particle Swarm Optimization PSO K
互过的项目的偏好程度，有效地降低了倒序排名的平均值，
（ - ， ）对用户进行聚类，然后将用户社
K HarmonicMeans KHM
而不是降低协同过滤推荐的预测评分和实际评分之间的差
交网络中用户的社交关系引入到相似计算模型中，利用矩阵
值，解决了传统推荐问题中数据稀疏的问题。 年，文献 分解技术计算出用户偏好的项目。这种办法有效地缓解了
2020
［ ］中在 模型的基础上，通过基于图的方式计算了概 推荐系统中常遇到的冷启动和数据稀疏的问题；然而，当训
33 PPMF
率矩阵的先验分布，提高了 模型的推荐准确率。 练数据过大时，训练的复杂度也随之提高。
PPMF
图 基于社交网络的推荐系统框架
5
Fig. 5 Recommendationsystemframeworkbasedonsocialnetwork
传统的矩阵分解算法中 的应用也较为广泛，与 解决了因只有显式反馈信息而缺少隐式反馈信息的推荐冷
SVD PMF
不同的是， 是将用户 项目的评分矩阵通过降维、分解、 启动问题。之后，文献［ - ］的作者又将时间因子作为辅
SVD - 37 38
计算成 个低阶矩阵乘积，对这 个低阶矩阵进行训练最后 助信息融合到了 中，提出了 模型。该模型
3 3 SVD++ timeSVD++
还原回初始的矩阵。 年，文献［ ］在优化 模型的 提高了用户近期隐示反馈行为的权重，而对用户的早期的反
2006 35 SVD
基础上提出了 模型，如图 所示。该模型首先把评 馈信息的权重进行了衰减，近似地实现了动态的推荐目的。
FunkSVD 6
分矩阵R 分解成两个低阶的用户矩阵U和推荐项目矩阵 混合推荐
m ×n 1.3
V，用户和推荐项目都映射到一个K维空间，这K维空间对应 基于内容的推荐技术在处理规模较大的信息内容时，常
着K个隐因子，用户对推荐项目的评分受这K个隐因子的影 常因为耗时久而造成信息时效性降低；协同过滤技术在面对
响。其优化函数如式（）所示： 新项目时容易遇到冷启动问题；而混合推荐技术是保留不同
6
( ) ( ) 推荐技术优点而避免其缺点的一种推荐方式，将不同的算法
mU*，iVn*∑R
ui -
U uTV
i
2
+
λ EV iE2
+
EU uE2 （ 6）
融入到推荐系统中即混合推荐［ 39- 40］。目前的混合推荐主要
其中：目标用户u的特征向量为U；第i个推荐项目的特征向 分为前融合、后融合、中融合。
u
量用V表示；矩阵中隐变量的数量用K表示；项目的预测评 ）前融合：指将多个推荐算法融合到一个模型中，如在
i
1
分和真实评分之间的误差用式（）中的第一项来计算；式（） 商品推荐过程中，根据用户历史购买记录将其感兴趣的商品
6 6
中的第二项是为了避免过拟合而设置的正则项。 特征提取出来作为推荐模型的输入，由混合模型中的推荐算
法通过自适应学习产生推荐结果。该混合推荐技术从本质
上来说是数据库中所有不同用户特征的融合。如文献［ ］
41
中将层次聚类算法和集成相似度算法结合，构建了一种准确
度和多样性相结合的混合推荐模型，在对推荐效果影响较小
图 模型 的情况下，通过调整混合模型的权重因子，可以达到推荐多
6 FunkSVD
样性且准确的目的。
Fig. 6 FunkSVDmodel
为了解决用户本身特质对用户 项目评分矩阵的影响， ）中融合：该混合推荐技术一般先以某种推荐算法为参
- 2
文献［ ］的研究以 模型为基础，提出了一种带偏置项 照，再将推荐效果与混合其他推荐算法的技术对比。如以基
36 SVD
的奇异值分解（ ， ） 于内容的推荐为主框架，然后在该款框架中混合协同过滤推
Bias Singular Value Decomposition BiasSVD
模型。 年，文献［ - ］对 模型进行了改进，提 荐能够有效解决冷启动问题。从混合本质上来说，该融合是
2010 37 38 BiasSVD
出了融合用户 项目的隐式反馈信息的 模型，该模型 对不同模型的融合。如文献［ ］的研究以深度学习算法作
- SVD++ 42 计算机应用 第 卷
1902 42
为框架，将深度学习与改进的机器学习模型相结合，从多个 一个新的研究方向。深度学习技术除了能够发现用户行为
角度学习项目和用户之间的交互，提出了一种称为深度度量 记录隐藏的潜在特征表示，还能捕获用户与用户、用户与项
因子分解学习（ ， ）的 目、项目与项目之间的非线性关系的交互特征，为系统的性
DeepMetricFactorizationLearning DMFL
混合推荐模型。该混合推荐模型的泛化能力较好，能全面地 能（如召回率、精度等）提高带来了更多机会，能够克服传统
反映用户的偏好。文献［ ］中提出了一种基于潜在因子模 推荐技术中遇到的一些障碍，从而实现更精确的推荐。
43
型（ ， ）和基于图的个人排名（ 基于深度神经网络的推荐
LatentFactorModel LFM Personal 2.1
， ）算法相结合的混合推荐算法，与单独使用 算法 深度神经网络（ ， ）是深度学习
Rank PR PR DeepNeuralNetwork DNN
相比，该混合模型的准确率和正确率表现更优。 模型中的一种［ 49- 51］，也可以叫作多层神经网络或多层感知机
）后融合：这种方法对推荐结果十分看重，主要通过比 （ - ， ）。目前，在个性化推荐问题中
3 Multi LayerPerceptron MLP
较不同推荐算法的推荐效果从而得到可靠性较高的推荐对 引入深度神经网络技术的趋势越来越明显［ 52- 57］。
象序列，最后将这个序列推荐给用户。 文献［ ］中首次将深度神经网络模型融入到视频推荐
49
在实际问题中，将不同的推荐算法相互结合从而得到效 领域，并在 视频网站进行了仿真实验，推荐流程如
YouTube
果更好的推荐是混合推荐技术的优势之一。目前 、 图 所示。
Amazon 7
［ 44］、微软［ 45］等公司通过使用混合推荐技术在商品、广
Google
告、新闻等个性化推荐方面取得了巨大的成功。
以上推荐技术都属于传统的推荐技术，近年来，用户历
史偏好记录的生成内容（如特征标签、位置、交友记录、评论
记录）越来越多样化，传统的推荐技术已经无法满足用户的
多样需求，因此产生了大量新的推荐算法，如：用户在社交网
图 视频推荐过程
络中分享或者获取各种资源时，只希望将自己的兴趣或喜好 7 YouTube
公开给相似的用户，并不希望将个人信息等隐私信息公开。 Fig. 7 YouTubevideorecommendationprocess
保护用户隐私的推荐逐渐成为学者们关注的问题［ 46- 47］。文 YouTube视频网站的特点是注册用户多、视频更新速度
快、视频时长不一、数量多，传统的推荐算法很难为用户推荐
献［ ］中提出了一种基于用户行为来保护用户好友隐私的
48
符合其偏好的视频内容。图 的推荐过程分为候选集生成
算法，将该算法用于集中管理和分布管理相结合的混合社交 7
和视频排序两个阶段。候选集生成阶段可以视为一个视频
网络中，能够让用户在实现兴趣偏好共享的同时又不暴露用
筛选的过程，即根据用户的观看记录从已有的视频中选择和
户的隐私信息。
用户观看历史记录相似的视频集合作为下次推荐的候选视
表 对上述三种不同的传统推荐技术的优缺点进行了
1
频。候选集生成阶段将视频推荐问题视为一个多分类问题，
总结和对比。
利用深度神经网络对用户和视频建模，通过预测函数P来计
表 传统推荐技术优缺点对比
1
算在C情况下，用户U在t时刻观看视频类型i的概率，i是所
Tab. 1 Comparisonofadvantagesanddisadvantagesoftraditional
有视频集合V中的某一类。分类预测公式如下所示：
recommendationtechniques
( )
推荐技术 优点 缺点
P w
t =
i|U，C
=
eviu
∑j
Vevju （ 7）
∈
解决冷启动问题 缺少特征提取的方法
1. 1. 排序阶段则是从不同特征维度对视频进行分析，通过加
可解释性强 易忽略推荐对象的典型性
CB 2. 2. 权的逻辑回归输出层获得用户点击某类视频的概率预测。
易实现 安全性差
3. 3. 预测值与用户感兴趣的视频类型越相似，其得分就越高，最
适合小规模推荐 存在冷启动问题
1. 1. 终选取得分最高的几十个视频作为推荐结果。仿真结果显
简单易操作 无法处理运算复杂的推荐
CF 2. 2.
易建模 缺乏可解释性 示，文献［ ］提出的推荐模型的召回速率和效率较高，能对
3. 3. 49
克服了数据稀疏 缺少高效的混合模式 百万级规模的视频数据集进行训练。
混合 1. 1.
弥补不同技术缺点 难以建立数学模型 但该模型仍存在以下不足：）面对海量的视频数据，该
推荐 2. 2. 1
适合用户多的推荐 推荐过程较复杂 模型只对数据进行了简单的清洗，在后续研究中可以尝试引
3. 3.
入注意力机制，从而对视频的权重进行分配，对用户关注较
基于深度学习的推荐技术
2 多的视频赋予更高权重，对用户关注较少的视频赋予较低权
深度学习算法强大之处在于能够像人类一样学习并处 重；）视频网站往往存在恶意视频（如广告等），在后续视频
2
理复杂问题，面对规模复杂的数据能从多种维度来分析并计 推荐研究中，可以尝试建立一种安全机制先对恶意视频进行
算线性或者非线性的特征序列，能从海量的数据中自动地学 拦截，从而更精确地捕获到用户的潜在偏好，不仅能提高用
习符合用户需求的特征，已经成功地应用在图像识别、语音 户的使用率，还能提高推荐的效果。
识别、自然语言处理等领域并取得了良好的效果，因此越来 文献［ ］中提出了一个深广（ ）模型来解决
50 Wide&Deep
越多的研究者也尝试将深度学习应用在推荐系统中，如何把 大规模的在线推荐问题，该模型是由单层的 部分和多
Wide
深度学习技术与推荐技术有效结合并深入研究已经成为了 层的 部分相结合的一个模型，如图 所示。
Deep 8 第 期 于蒙等：推荐系统综述
6 1903
部分是式（）的广义线性模型，y是模型的预测值， 长序列信息。 和 属于 的改进版本，它们的关
Wide 8 LSTM GRU RNN
x为特征向量，w是模型的参数，b为预测的偏差值。这部分 键是可以捕捉到序列比较长的n元信息序列，最大优势是能
的作用是让推荐模型具有较强的记忆能力。 够为前后有关联的序列信息建模，已经在新闻推荐［ 54］、文字
y wTx b （） 翻译［ 55］、语音识别［ 56］等领域得到了广泛的应用。
= + 8
部分是深度神经网络，该部分模型对嵌入的向量 模型最早由文献［ ］提出，它可以学习较长序列
Deep LSTM 57
进行抽象和初始化。接着，将抽象好的特征向量传递到隐藏 信息之间的交互关系。从此，该模型不断地被研究者们改进
层，每个隐藏层执行以下计算： 和优化。文献［ ］中认为传统的协同过滤技术无法为用户
54
a(l +1) f w(l) a(l) b(l) （） 提供动态的个性化推荐，因此，将用户的行为记录抽象成有
= ( + ) 9
其中：l是训练的层数；f是激活函数，通常使用 函数； 关联的数据序列，使用降噪自编码器（ - ， ）构
ReLU Auto Encoder AE
a(l) b(l) w(l)分别是第l层的激活、偏置和模型权重矩阵。 建的深层网络来学习新闻文本的特征； 用来训练输入
RNN
、 、
序列（用户特征和浏览记录）。后来，日本雅虎（ ）团队
部分的作用是让模型有更好的泛化能力， 和
Yahoo
Deep Wide
尝试将该文献中提到的推荐模型应用到手机端新闻主页中，
结合使得该模型不仅能够快速学习并处理大量的特征
Deep
整个推荐流程大致分为 步：）将用户的历史浏览记录作为
属性，还具有强大的表达能力。在 （一个拥有超
5 1
Googleplay
的训练数据生成用户的偏好模型；）利用一定的相似
过 亿活跃用户和超过 万个应用程序的移动应用商店） RNN 2
10 100
度计算规则计算出和用户偏好相符的新闻集合作为候选集；
上的实验结果表明，该模型明显增加了 的下载量，达到
APP
）利用模型中的排序算法对新闻候选集排序；）对重复的新
了更精确的推荐目的。 3 4
闻内容进行去重；）在适当时插入广告（如果需要）。经过实
模型主要利用 部分学习目标用户的 5
Wide&Deep Wide
验和评估发现， 模型需要设置的参数少而且能够为用
特征，利用 部分来泛化相似的推荐项目，能对 千亿个 GRU
Deep 5
户推荐更准确的新闻信息。文献［ ］中则提出了一个多元
样本进行训练，有效缓解数据稀疏问题，而且还可用于分类、 58
递归神经网络（ - ， -
回归、查找等问题；它的不足是需要人为的特征工程。 Multi view Recurrent Neural Network MV
）模型，该模型能够将视频、文本、图片等信息整合，将不
RNN
同的多视图特征进行组合作为输入项，然后在模型的隐藏层
用一个单独且统一的结构来处理输入信息，动态有序地捕获
用户的兴趣。
基于知识图谱和 的推荐
2.2.1 RNN
近年来互联网在多个领域快速发展，使得知识图谱从提
图 模型 升搜索引擎的质量逐渐发展到了推荐领域。 年，
8 Wide&Deep 2012 Google
公司为了提升用户使用搜索引擎时的搜索体验，提出了知识
Fig. 8 Wide&Deepmodel
文献［ ］中提出了一种融合 和矩阵分解的推荐模 图谱的概念，知识图谱是用结构化网络对客观世界实体之间
51 DNN
型，能快速地为用户项建立其生成交互函数时所需要的非线 关系的一种描述，能够用形式化的方法表示现实生活中事物
性模型。相比单一的矩阵分解算法，该模型进一步提高了评 间的相互关系。文献［ ］中结合知识图谱和 模型建立
59 RNN
分预测准确性结果，提高了推荐性能；但该模型并没有从多 了一种能实时捕捉到用户兴趣点变化的序列化推荐模型。
种维度提取用户的偏好，泛化能力较差。为了解决这个问 该模型将在线音乐平台的异构数据分为图形数据、文本数据
题，文献［ ］中提出了一种基于 的深度混合推荐模型。 和视觉数据三大类，用知识图谱将这三类异构数据的关系嵌
52 DNN
该模型将用户和项目信息输入到了改进的机器学习模型中 入到实体中，再将结果作为输入嵌入到模型中；在解码阶段，
进行训练，从多维度更深入地学习用户和推荐项目的交互关 和前馈层被用来获取序列中的信息，分析计算每个候
RNN
系。该模型对用户和项目的特征学习部分由 个并行的 选项的分数，最后预测推荐。该模型尝试将多源异构数据同
2
组成，目的是为了提取静态项目的潜在特征和动态用 时输入到模型中，提升了推荐的效率；但该模型只尝试了在
DNN
户的潜在特征。这种将多个深度学习模型和机器学习模型 音乐推荐方面的应用，因为它对异构数据具有较好的融合能
相互融合的推荐模型，能较为准确地预测用户的偏好情况， 力，未来可以尝试将其应用到视频、文本、社交网络推荐中，
提高推荐的性能。未来的研究中，可以尝试在推荐模型中融 增强模型的可扩展性。
合多个深度学习模型和机器学习模型，提高推荐的泛化 因为文献［ ］中提出的模型无法记忆时间过长的序列，
59
能力。 所以文献［ ］提出了一个基于记忆的网络结构来长时间地
60
基于循环神经网络的推荐 保存用户个人信息和偏好。该结构可分为 和 两个
2.2 Key Value
循环神经网络（ ， ）［ 53］包括 模块，其中： 模块用来存储推荐项目的信息，从本质上来
RecurrentNeuralNetwork RNN Key
双向循环神经网络和长短期记忆（ ， 说这部分其实是知识图谱通过翻译嵌入（
LongShortTermMemory Translating
）网络。在深度神经网络中，模型训练好之后在输入层 ， ）来获取实体和关系的表征信息； 模
LSTM Embedding TransE Value
给定一个x，在输出层就能得到特定的y，但只适合于前后输 块存储用户的特征和偏好情况，在 对时间节点的信息
RNN
入完全没有关系的序列。在推荐方面，通常使用 和门 迭代时，该模块能对 进行实时的记忆和更新，这一步
LSTM TransE
控循环单元（ ， ）处理推荐问题中的 充分利用了知识图谱中的信息。该网络结构有效地提升了
GatedRecurrentUnit GRU 计算机应用 第 卷
1904 42
模型记忆过长序列的效率和推荐效果。 ）对用户社交网络中朋友的偏好情况进行表示。
2 RNN
综上所述，在推荐方面充分合理地利用知识图谱能提升 模型不仅可以对用户的历史浏览行为记录进行建模，也能对
推荐性能，尤其对于缓解数据稀疏和冷启动问题具有明显的 用户社交网络中朋友们的历史浏览行为进行建模，朋友k的
效果；但这也仅适用于数据积累较为成熟的系统，当面对数 短期偏好情况用输出向量ssk表示，长期偏好情况用输出向量
据积累较少的新系统时，往往会出现推荐准确率低、推荐效 slk表示，最后将两种输出向量ssk和slk连接得到S k，S k就是朋友
果差的问题。因此，如何利用知识图谱对新系统产生较好的 k的整体偏好。
推荐，将是未来研究的一个重点。 ）动态的图注意力机制建模。首先，为用户建立一个图
3
基于注意力机制的 推荐方法 网络，网络中的每个节点代表着用户与社交网络中朋友的图
2.2.2 RNN
注意力机制能够根据用户的偏好差异为推荐项目的潜 网络，如式（ ）所示：
10 ( ( ))
重
上在 来，特
不
说征
关
其划
注
工分
无
作区
关
原域
部
理， 分赋 是，予 利其大 用原部
注理
意分
类
力似用 的人户 概脑都 率的关 分注注 布意的 ，力区 捕机域 捉制较 对，高 输从的
本
出权
质
有
a(ul k) =
j
N∑(ue )xp
{u}ef xph ((u fl )， (h h(k (ul l)
)，h(kl ))) （ 10）
∈ ∪
关键影响的输入。
其中：h(ul )代表用户的长期偏好；h(kl )代表朋友的长期偏好；a(ul
k)
近年来，文献［ - ］等的研究将注意力机制和深度学 代表用户和朋友之间相差的注意力分数。
61 63
）为用户产生推荐序列。将用户的偏好h 和合并后的
习模型融合，推动了推荐系统的发展。文献［ ］中将动态的 4 n
61
朋友偏好hl连接就可以得到融合了用户朋友偏好的用户偏
图注意力机制模型和 模型结合混合应用于社区推荐， u
RNN
好表示h ，如式（ ）所示：
该研究认为用户的偏好受社交平台朋友的偏好影响，图注意 n 11
h W
[ h：h(l)]
（ ）
力机制模型能够动态地捕获用户朋友长短期偏好变化对用 n = 2 n u 11
户产生的影响，其模型如图 所示。该模型的推荐过程 其中：W 代表的是一个线性变换。之后 函数计算出
9 2 softmax
如下： 项目y被用户喜欢的概率，如式（ ）所示：
12 ( )
1）为用户的偏好情况建立模型。这一步主要是由
RNN
p(
y|iu ， ，iu
)
{Sk，k N( u)} exp
h  Tnz
y （ ）
模型来完成， 模型为用户的历史浏览行为记录建模，动 T +1， 1 … T +1，n T ∈ = I ( ) 12
态地捕获到用R 户NN
u n的偏好h n。 ∑j =1exp
h  Tnz
j
图 动态图注意力网络社会推荐模型
9
Fig. 9 Socialrecommendationmodelviadynamicgraphattentionnetwork
所有推荐项目的嵌入用z 表示，推荐项目的总体数量用 荐的性能；但是该模型并没有考虑用户信息和微博标签文本
y
I表示，Sk表示用户社交网络的第k个朋友在历史时刻为T的 长度问题等对推荐结果的影响。针对这一问题，文献［ ］中
T 65
会话，iu 表示用户社交网络中第k个用户在会话T中消费 提出了一种基于注意力机制的语句时态增强模型，该模型对
T，Nk，T
的第N 个项目。 微博特征从词级和语句级两方面进行分析和刻画，把时间信
k，T
文献［ ］中提出的模型充分利用了用户的社交关系，捕 息融合在语句集注意力层，充分降低了微博标签数据中噪声
63
捉了用户的朋友的偏好；然而，该模型对用户和朋友的特征 数据对分类器的影响。因此，该模型除了解决微博话题标签
提取不够精准，没有考虑到用户和推荐项目之间长期的依赖 推荐问题，还能用于解决文本识别、语言翻译和动态推荐等
关系。因此，在后续的研究中可以尝试将用户和推荐项目之 问题。然而， 模型只能处理单一的欧几里得空间数据，
LSTM
间长期的依赖关系融合到模型中。 无法处理较为复杂的非欧空间数据。
为了解决微博话题标签的时序数据问题，文献［ ］中构 文献［ ］中提出了双重注意力网络学习双重社会效应
64 66
建了一种基于主题注意力机制的 模型，该模型考虑到 的推荐模型。该模型的双重注意力机制包括根据用户自己
LSTM
了时间因子，将时序特征融入到了模型中，有效地提升了推 分配的注意力权重建模和通过上下文感知动态的注意力建 第 期 于蒙等：推荐系统综述
6 1905
模两个方面，通过双重建模有效地把用户的社会效应传递到 和图像统一的特征表示，将异构用户图像网络转换为同质的
了推荐项目领域，缓解了传统推荐系统常常遇到的数据稀疏 低维数据，这样的转换有助于系统通过相似性向用户推荐图
性问题。该模型对社会影响的有效表示能从多个维度学习， 像。该模型能处理大型、稀疏和多样化的视觉图像。
但是模型的复杂度也增加了。 针对文本推荐方面，文献［ ］的研究认为用户对项目的
72
卷积神经网络 评级矩阵如果过于稀疏，则会影响推荐质量，为此提出了一
2.3
卷积神经网络（ ， ）［ 67］的 种混合推荐模型。该推荐模型基于上下文感知和卷积矩阵
ConvolutionalNeuralNetwork CNN
最大特点是具有表征学习能力，是包含深度卷积计算的前馈
因式分解，将 集成在概率矩阵分解中，能有效捕获上下
CNN
神经网络，它的核心是隐含层和卷积层的相互连接，常见的
文信息，从而填补稀疏的用户评级矩阵，提高推荐的准确率。
三种性能较好的
CNN
模型有 VGGNet［ 68］、
GoogLeNet
和
文献［ - ］的研究针对的都是某一个特定的目标用
ResNet［ 69］。
2014
年提出的
VGGNet
模型取得了
ILSVRC
户，但实际7 问0 题72
中的推荐场景往往更复杂，有时需要为特定
（ ）分类组的
ImageNetLargeScaleVisualRecognitionChallenge 的群组产生推荐列表，因此，未来的研究可尝试将 和社
亚军和图像识别组的冠军； 年提出的 模型在 CNN
2017 ResNet 交关系、时间、文本等辅助信息相结合来进行群组推荐。
比赛中获得了冠军。 模型有 层网络结
ILSVRC ResNet 152 年，文献［ ］中提出了一种基于注意力机制的
构，将残差网络作为 的基本结构，这样做可以减少因网 2016 73
CNN 的新浪微博话题推荐模型，该模型设置了两个注意力通
络结构过深造成的梯度爆炸问题。与其他的深度学习模型 CNN
道（全局和局部），提高了推荐的准确率；但是该模型使用的
相比， 模型能够自动捕捉用户的潜在特征，发现潜在的
CNN 数据都是文本类型，忽略了图像等其他形式的话题类型。为
规律，目前已广泛应用在图像识别、自然语言处理、目标分类
了解决这个问题， 年，文献［ ］中提出了协同注意力机
等不同领域的推荐系统中［ 69- 71］。 2017 74
制模型，充分考虑了文本、图像等与微博话题标签依赖关系，
在音乐推荐方面，文献［ ］中探讨了如何有效地缓解音
70 因此推荐性能优于仅考虑文本的推荐。
乐推荐中新音乐冷启动问题，并提出了一种融合深度卷积神
文献［ ］的研究认为传统的推荐在提取评论文本信息
经网络的推荐模型，通过收集用户的历史收听记录和浏览过 75
方面有所欠缺，于是提出了一种基于注意力机制的深度协作
的音频数据，将这些数据投影到一个共有的隐空间中，从而
学习用户和音频的隐表示。对于新的音乐，该研究利用深度 神 经 网 络（
deep Cooperative Neural Network based on
卷积神经网络对新音频中的隐表示进行提取，从而在这个共 ， ）模型，其中注意力机制的作用是为文本矩
Attention ACoNN
有的空间中计算新音频和用户的相似度。经过实验和分析， 阵的权重重新赋值，并行的 模型则充分挖掘用户和文
CNN
该方法缓解了新音乐冷启动问题，提高了推荐的准确性。 本的信息以获取潜在的隐含特征。 模型的推荐流程
ACoNN
在图像推荐方面，文献［ ］中利用 模型学习用户 如图 所示。
71 CNN 10
图 模型的推荐流程
10 ACoNN
Fig. 10 RecommendationflowofACoNNmodel
具体描述如下： ）利用 模型对词向量矩阵进行卷积、池化和全连
3 CNN
）将用户矩阵M 和文本信息矩阵M 利用词嵌入模型 接，从而得到用户和项目的输出向量output 与output。
1 u i u i
输入到输入层。sim k代表户矩阵M u中的词向量wu k与全部用 4）连接output u与output i为用户 -项矩阵构造特征向量
户评论文本向量wu 之间的相似度，如式（ ）所示：
d
((1：n
) ( ))
13 z；接着给向量z融合因子分解机，用最小化损失函数训练向
sim wu ，wu （ ） 量z，如式（ ）所示：
k =∑k cos k 1：n 13 15 ( )
=1 ■z■ ■z■ ■z■
）归一化处理式（ ）得到的相似度系数，计算注意力机 J w y w w z w z z （ ）
制层2 的每个词向量注意1 力3 权重，如式（ ）所示： ( i)= real - 0 +∑i =1 i i +∑i =1j∑ =i +1 ij i j 15
14
n 其中：y 代表用户对推荐项目的真实评分；w 代表全局的偏
a simk simk （ ） real 0
k = e ∑k =1e 14 置量；w i代表的是第i个分量的权重值，z i和z j分别代表向量z 计算机应用 第 卷
1906 42
的第i和第j个分量；w 代表的是z 和z的交互值。 方面地融合辅助信息，提高推荐模型的准确率和新颖性。
i，j i j
相比别的深度学习模型，该模型的优点是数据在训练阶 文献［ ］提出了一种基于信任机制的社交网络推荐模
80
段设置的参数比较少、模型的复杂度较低，充分利用了注意 型，该模型将神经网络集成到 模型中，用不同的神经网
PMF
力机制能够捕捉权重较大信息的特点，以及 模型对权 络的节点表示不同的用户，通过 最近邻（ -
CNN K K Nearest
值能够共享、对局部连接的优势，结合了注意力机制的 ， ）算法将用户特征和神经网络联系在一起形
CNN Neighbor KNN
模型在提取特征时对重点特征的提取效率有了很大的提升， 成图结构。但是该模型只考虑了单一的 联系用户特征
KNN
因此，推荐项目的准确率也有了较大的改善；但是该模型无 和神经网络，未来的研究可以尝试多种方法联系用户特征和
法对用户动态的偏好进行实时推荐。 神经网络，尽可能从多方面考虑用户的特征。
文献［ - ］的研究将注意力机制和 模型相融合， 文献［ ］中通过 的节点来学习用户对特定推荐项
74 75 CNN 81 GNN
尽管提升了推荐的效果，但是当数据规模足够大时，数据稀 目的置信度加权参数，该加权参数代表节点用户与推荐项目
疏性问题仍然会逐渐显露。跨领域推荐是解决数据稀疏问 之间相交互的可能性。引入置信度加权参数是为了帮助用
题的一个重要的方法，多个领域的辅助信息可以为目标领域 户模拟高阶信息，使得每个用户可以收集邻域节点间的高阶
的推荐服务，通过输入辅助信息，模型可以学习到目标用户 信息。对于比较稀疏的用户-项目矩阵，可以通过随机游走
的潜在隐含特征，从而提升推荐的效果，因此，在后续研究中
的方式对矩阵进行填充，缓解数据稀疏和冷启动问题。但该
可以考虑将 和注意力机制融合到跨领域推荐任务中。
推荐方式仅考虑了用户项目之间历史交互的置信度参数，并
CNN
基于图神经网络的推荐
没有考虑推荐系统所收集到的数据对加权参数的影响。
2.4
图神经网络（ ， ）借鉴 和
基于会话的图卷积神经网络推荐
Graph Neural Network GNN RNN
2.4.2
的思想，是一种重新定义和设计的用于处理非欧氏空间
CNN 近年来，匿名用户推荐问题逐渐成为推荐领域的一个重
数据的深度学习算法。在实际的生活中，电子商务、推荐系
要研究方向，采用 模型解决该类问题已经取得了不错
GNN
统、动作识别等领域的数据抽象出来都是节点之间链接不固
的进展；但是， 无法精确地捕获到用户会话间潜在的依
定的图谱，这些图谱不具备规则的空间结构，而 模型可 GNN
GNN 赖信息。文献［ ］中提出了一种基于会话的图卷积神经网
以对该类数据进行高效的建模，精确地捕获到数据之间潜在 82
络（ - ，
的联系。文献［ ］中针对电子商务领域出现的问题，提出了 Group constrained Convolutional Recurrent Neural network
76 ）模型。该模型利用多层的图卷积模型能精确地捕
一种分层二分图神经网络的模型。该模型首先将多个 GCRNN
GNN 获到用户会话图信息，利用递归神经网络层则能进一步捕获
模型进行叠加，并在多个交替模块上使用聚类算法，聚类算
会话间的时序图来获得用户偏好的变化情况，而且递归神经
法能够有效捕获到分层模块中推荐项目和用户的信息，进而
网络层还能精确地捕获到会话之间的交互信息。因此，
有效地捕捉到用户的潜在偏好，提高推荐的准确率；但该模
模型能精确地捕获到会话间丰富的潜在隐含信息，
型利用的是用户某段时间内静态的交互记录，这与用户变化 GCRNN
从而提升推荐的准确性；然而， 模型并不能为用户产
的偏好情况相矛盾。因此，文献［ ］中建立了一种融合时间 GCRNN
77 生动态的推荐列表，降低了模型的实效性，因此在今后的研
关注机制的图卷积推荐模型，图卷积神经层对用户在整个实
究中可以考虑将用户的点击项作为辅助信息融合到模型中
际场景中的角色进行抽象，能大致反映出用户的短期偏好特
以产生更有效的推荐列表。
征，文献［ ］提出了一种卷积 模型（
78 LSTM Convolutional 用户的兴趣是动态变化的，为了给用户产生实时推荐列
， ）来增强模型的鲁棒性，为了捕获
LSTMNetwork ConvLSTM 表，文献［ ］提出了一种基于会话的图卷积递归神经网络模
到用户动态的偏好变化情况，模型首先融合了侧重分层学习 83
型，模型的整体框架如图 所示。预测推荐项目的过程可
和神经元排序的神经网络结构，最终通过学习模型捕获到的 11
分为三步：
局部用户偏好的时空信息产生推荐序列。
）对会话序列构建会话图，I i，i，i ，i 代表会话
基于 的图神经网络推荐 1 ={ 1 2 3… n}
2.4.1 PMF 列表，s i ，i ，i ， ，i 代表按照时间戳进行排序的用
传统的矩阵分解模型具有很好的灵活性和可扩展性，但 =[ s， 1 s， 2 s， 3 … s，t]
户会话列表，i 代表用户在t时刻在会话s中的点击项，为用
是仍然无法解决冷启动和数据稀疏的问题，于是，文献［ ］ s，t
79 户的每个会话列表构建有向图G S，E ，用户点击项i
中提出了一种融合 和 的推荐模型。该模型首先将 S =( S S) s，t
PMF GNN 作为会话图的节点，i 作为会话图的边，在用户会话列表s
社交网络图和用户项目图这两个图内在联系起来，然后对图 s，t
中，将节点向量作为 模型的输入，目的是节点向量能够
进行建模，捕获用户在社会空间中的潜在特征向量和项目空 RNN
被更新。接着，有向图G S，E 被输入到嵌入层后，i 被
间上的潜在特征向量；接着，将捕获到的特征向量进行相互 S =( S S) s，t
映射到G中，为了处理节点和会话图的收敛问题，文献［ ］
串联，充分地学习目标用户的特征向量，将捕获到的特征向 83
中对G S，E 进行了卷积操作，如式（ ）所示：
量集成在 模型中，产生项目的评分和推荐列表。在真 S =( S S) 16
PMF
实的数据集 和 上的实验结果表示，该模型是有
h θ∗g
=
Uh θUTg （ 16）
Epinions Ciao ( )
效的，其均方根误差和平均绝对误差均有降低。但该模型只 其中：h θ = diag θ 代表的是进行卷积操作时的滤波器；g代
是将社交网络图作为辅助信息融合到模型中，在实际生活 表的是会话图；U代表的是特征向量矩阵；A代表的是邻接矩
中，用户和项目之间的交互信息还体现在其他方面，例如，推 阵（若节点之间存在边，则A ，否则为 ）。在建立图卷
i，j = 1 0
荐项目的丰富属性与用户偏好的依赖性。未来可以考虑多 积模型时，获得会话图中的结构信息，利用多项式获取K阶 第 期 于蒙等：推荐系统综述
6 1907
近似，K的阶数代表着有向图G S，E 中每个节点在传 权重；最后使用 获得会话时序信息并对用户进行推荐，
S =( S S) RNN
播时的作用范围。 以提高推荐的泛化能力。但该模型并没有研究会话点击序
）为了处理获取过程中遇到的梯度问题，选用 模 列长度对推荐效果的影响，另外用户的长短期兴趣信息也可
2 GRU
型来获取节点向量，最终输出的h的计算公式如（ ）（ ） 以尝试作为补充信息，从而进一步研究它对推荐的影响。
i 17 ~ 20
所示：
( )
z σ W Uh （ ）
i = z + z i -1 17
( )
r σ W Uh （ ）
i = ( z +) r i -1 18
( ( ))
h  i = π - θ tanh W h + U h r ⊙s i -1 （ 19）
2
h z s z h （ ）
i =(1 - i)⊙ i -1 + i⊙ i 20 ()
其中：W 、W 和U 、U、U 为训练模型过程中得到的参数；σ
Z h Z r h
代表 函数； 是代表乘法的运算符；z和r是 网
sigmoid ⊙ i i GRU
络中的重置门与更新门，经过 编码，每个会话就被编码
GRU
成一个个的嵌入序列H = h，h，h，…，h ，将嵌入向量经
{ 1 2 3 n} 图 基于会话的图卷积神经网络推荐框架
过线性变化 [变得到嵌
]
入向量h s如式（ 21）所示。 11
-
h W h ；h （ ） Fig. 11 Sessionbasedgraphconvolutionalneuralnetwork
s = s g l 21
recommendationframework
）计算每个会话中点击项的得分z，如式（ ）所示：
3 ˉi 22 对非欧几里得数据有其强大的提取和表示能力，这
z
ˉ=
hTsh
i
（ 22）
是
GNN
模型的优势之一。在现有的研究中，基于 的推
其中：h h 分别代表点击项和会话的嵌入向量。接着计算 GNN GNN
、i s 荐还存在以下问题：）本节中介绍的模型的输入都是单一的
会话被点击的概率，这一步是通过 层来完成的，如式 1
softmax 数据类型，然而在现实生活中，数据的形式有文本、音频、图
（ ）所示。
23 片等，如何对异构数据进行统一的输入是目前 推荐面
y z （ ） GNN
ˉ= softmax(ˉ) 23 临的问题；）目前文献中所用到的 模型都是图的节点
预测出的y的值越大，则代表下一次被点击的可能性越 2 GNN
不为空的情况，然而在现实生活中，会存在节点对象没有存
大，那么通过对得到的y排序，将y值大的会话依次推荐给
放任何数据的情况，目前相关算法难以处理该类情况。
用户。
随着 计算能力的提高，深度学习在大数据分析及
近年来基于会话的匿名推荐多关注的是用户的点击序 GPU
个性化推荐中的应用越来越广泛。深度学习模型将用户的
列，但对于一个完整的推荐过程来说，其他信息（如推荐项目
的种类和名称等）往往被忽略。为了解决上述问题，文献 显式数据、隐式数据、用户画像等多源异构数据作为输入融
［ ］中提出了一种基于会话的多粒度图神经网络推荐模型。 入到推荐过程中，通过辅助数据分析用户和推荐项目隐藏的
84
该研究认为种类是推荐项目的一个重要特征属性，对推荐项 特征，从而建立预测模型，可有效地缓解数据稀疏和冷启动
目有聚合的作用，因此通过 获取推荐项目和用户的种 问题，达到提升推荐准确率和推荐质量的目的。表 归纳比
GNN 2
类嵌入信息；接着，通过注意力机制捕获用户对项目分配的 较了深度学习模型在不同推荐系统中差异。
表 不同的深度学习模型的文献总结及优点
2
Tab. 2 Literaturesummaryandadvantagesofdifferentdeeplearningmodels
模型 辅助数据类型 主要优点 主要难点 文献
从多维度学习行为记录特征
视频、标签、用户 1. 如何使推荐结果更新颖
数据稀疏问题得到了有效解决 1. ［ - ］
DNN 和项目特征 2. 如何建立并且实现非线性特征的推荐模型 4952
缓解新用户面临的冷启动问题 2.
3.
动态地为用户推荐商品
1. 多源异构数据特征如何有效表达
用户和项目特征 时效性强 1. ［ - ］
RNN 2. 如何为用户和项目的特征动态建模 5366
可解释性强 2.
3.
有效地利用了辅助信息 如何提高推荐模型的训练效率、响应时间以及
图像、视频、 1. 1.
对用户的隐藏特征进行了挖掘 可扩展性 ［ - ］
CNN 音乐、文本 2. 6775
提高了推荐的新颖性 如何建立融入辅助信息的深度学习推荐模型
3. 2.
能充分地挖掘节点信息之间的交互信息
会话、文本； 1. 如何有效地捕获到图节点的信息传递
提高了图节点之间的敏感度 1. ［ - ］
GNN 用户-项目特征 2. 数据规模较大时，难以进行实时推荐 7683
可以在图领域对数据特征进行提取。 2.
3.
近年来，随着抖音、快手等短视频平台的快速发展，推荐 与显、隐式反馈信息结合，并将多源异构数据融合到推荐系
系统成为了更加流行的研究热点。目前，深度学习模型因能 统中，从而有效缓解了传统推荐所面临的冷启动和数据稀疏 计算机应用 第 卷
1908 42
等问题，提高了推荐效果，其优点主要表现在：）当遇到非结 于在视频、图片等领域的推荐模型，应尽可能设计复杂度较
1
构化的数据（如图片、视频）时，数据隐含的特征信息仍然能 低高效的模型。 ）融合深度学习模型的推荐算法类似于一
2
通过深度学习其强大的表示学习能力被提取到。 ）对原始
2 个黑盒，尤其在类似社交网络推荐的问题时，对于基于目标
数据的类型无要求，异构的数据均可以作为输入，从而进一
用户的社交网络推荐问题，深度学习模型往往都是个性化的
步地获取目标用户的特征。然而，在不同的应用领域，融合
推荐，很少有文献对此类推荐尝试群组推荐，未来对此方面
深度学习模型的推荐算法仍然存在以下不足：）深度学习模
1
的改进研究可以尝试建立群组推荐。表 列举了不同深度
型虽然在 视频、 地图等实际应用中取得了不 3
YouTube Google
错的效果，但由于视频、图片均属于非结构化的数据，且大量 模型在不同的推荐领域所需要的数据类型及未来改进
的非结构化数据训练起来复杂度极高且耗时。因此，未来对 重点。
表 深度学习在不同推荐领域改进方向的比较
3
Tab. 3 Comparisonofimprovementdirectionsofdeeplearningindifferentrecommendationfields
应用方向 深度学习模型 数据类型 优点 未来改进方向
对大规模的非线性数据进行处
视频、 用户的隐、显式反馈信息， 1. 建立复杂度较低且高效的模型
、 、 理和计算 1.
图片 AM CNN 项目内容、用户生成内容、 对异构数据能进行统一的处理（如可以同
、 等 不存在新项目或者新用户冷启 2.
推荐 RNN GNN 用户-项目的评分矩阵 2. 时输入视频、图片）
动问题
用户-项目的评分矩阵、用 能动态地为用户进行有效推荐 将用户对音乐的情感表达作为特征属性融
音乐 1. 1.
、 等 户画像、社会化标注、项目 不存在新项目或者新用户冷启 合到推荐模型中
推荐 CNN RNN 2.
数据、用户特征 动问题 跨平台获取用户在不同情境下的音乐偏好
2.
目标用户的社会关系图、 获取用户短期新闻偏好变化，从而动态地
新闻 、 、 新闻推荐的时效性高 1.
MLP RNN 用户的隐显式反馈信息、 1. 为用户推荐具有时效性的新闻
推荐 、 等 有效地解决数据稀疏的问题
CNN GCN 知识图谱等 2. 建立机制对虚假、垃圾新闻进行有效屏蔽
2.
用户隐私和安全的保护，需推荐系统建立
社交 目标用户的社会关系图、 能对社交网络中社交信息的权 1.
、 、 1. 相应的隐私保护机制
网络 RNN RNN 知识图谱、时间数据、位置 重进行重新分配
、 等 建立对推荐新颖性、可靠性、安全性评价指
推荐 CNN GCN 数据等 能跨平台捕获用户的社交网络 2.
2. 标的评估方法
常用数据集 ）新闻推荐［ 88］。 数据集是从微软新闻网站提取
3 4 MIND
的匿名行为日志的新闻推荐数据集，有 和 -
推荐模型及其推荐效果要想获得公认、客观的评价，权 MIND MIND small
两个版本。 数据集包含了 名用户所浏览过
威的数据集和统一的评价指标必不可少，本章主要介绍电影 MIND 1000000
的 篇新闻，包含了用户 条行为日志；
推荐、电子商务推荐、音乐推荐、新闻推荐领域一些公开的数 161031 24155470
- 数据集则包含了 名用户浏览过的
据集以及近年来一些典型推荐模型的性能指标的对比。表 MIND small 50000 93698
篇新闻以及 条用户的行为日志。 数据集是
归纳整理了近年来有关推荐问题研究中所用到的公开数 230117 Adressa
4 由挪威新闻出版社和挪威科技大学共同收集和发布的，不过
据集。
因其新闻内容多为挪威语，因此应用常常受限。
1）电影推荐［ 85］。 MovieLens数据集是由明尼苏达大学发
）文本推荐［ 89］。 数据集是美国最大的点评网站内
布的一个包含多个用户对多部电影评级的数据集，包含了用 5 Yelp
部整理得到的数据集，常用于教育、研究和学术； -
户个人信息和有关电影的相关数据，因数据集的大小不同， Goodbooks
数据集来自 网站，包含用户的文本评论，图书
目前包括 、 、 三个 10k goodreads
MovieLens1M MovieLens10M MovieLens20M 的标签，被用户评论过的书的详细信息（作者、年份、书的类
版本。
型等）。 和 - 数据集常用于基于用户评论
2）电子商务［ 86］。 Epinions数据集包含了 139738个商 的文本推Y 荐el 、p 图书G 推ood 荐bo 等ok 领s 1 域0k
。
品、 个匿名用户，这些商品至少被评价过一次，共有
49290 应用及比较
条评价记录，该数据集被广泛应用在商品推荐领域。
4
664824
数据集由 公司内部团队收集数据并创建，包 传统推荐算法中的 是最早被提出且发展最好的推荐
Amazon Amazon CF
含了商品的类别、数量、标价、用户的点击次数、浏览记录、购 算法。近年来，以 为主的改进算法不断涌现，如基于
CF PFM
买情况等。 的协同过滤、融合时间因素的协同过滤、基于知识图谱的协
）音乐推荐［ 87］。 数据集是由马德里自治大学的 同过滤、基于信任因子的协同过滤等，这些算法都取得了令
3 Last.fm
研究小组创建并发布的，于 年在第二届推荐系统信息 人满意的推荐效果。相比 ， 更多地是作为辅助算法，
2011 CF CB
异构与融合国际研讨会正式公开发布，音乐推荐算法的模型 包括特征提取和产生推荐列表两个过程，很容易造成推
CB
常常通过这个数据集进行仿真实验，也有研究学者将此数据 荐性能低的问题。混合推荐算法是各种推荐算法的组合，能
集用于新闻推荐，以验证算法的通用性。 够让不同的推荐算法相互弥补不足，能有效地缓解数据稀疏 第 期 于蒙等：推荐系统综述
6 1909
的问题。目前，基于深度学习的推荐的核心是将不同的深度 学习的推荐通过融入辅助信息能有效地缓解传统推荐技术
学习模型与 或 组合，其推荐过程可分为两步：）让深 的数据稀疏和冷启动等问题。现有研究大多根据具体的辅
CF CB 1
度学习模型学习用户或项目隐含的潜在特征，并和 结合
CF 助信息而选取不同的深度学习模型，在以后的研究中可以尝
构建优化函数对参数进行训练；）从完成训练的模型中获取
2 试针对所有的辅助信息建立一个统一的混合推荐模型。
最终的隐向量，接着完成向用户推荐的过程。
表 整理了不同推荐技术在电影、音乐、新闻、社交网
在面对复杂庞大的数据时，传统推荐算法常常无法快速 5
建模且表示性较差，而深度学习可以对复杂问题分层处理， 络、视频和广告等六个典型领域中的应用，并列举了这六个
能快速发现每一层数据之间潜在的规律和联系。基于深度 领域中代表性的推荐模型、需要的数据信息以及模型特点。
表 常用公开数据集归纳统计信息
4
Tab.4 Summarizationandstatisticsofcommonlyusedopendatasets
数据集的类型及名称 用户数量 项目数量 评论数量 稀疏度 获取链接
/%
：
MovieLens1M 6040 3883 1000209 4.26 https //grouplens.org/datasets/movielens/
电影推荐 ：
MovieLens10M 71567 9164 10000054 1.3 https //grouplens.org/datasets/movielens/
：
MovieLens20M 138493 27278 20000263 0.52 https //grouplens.org/datasets/movielens/
：
电子商务 Epinions 49290 139738 664824 0.011 http //www.trustlet.org/wiki/Epinions_datasets
：
Amazon 5786 26573 14280000 0.002 http //jmcauley.ucsd.edu/data/amazon/
音乐推荐 ： -
Last.fm 1892 17632 92834 0.28 https //grouplens.org/datasets/hetrec2011/
- ：
新闻推荐 Mindsmall 50000 93698 230117 0.056 https //msnews.github.io
：
Mind 1000000 161013 24155470 0.012 https //msnews.github.io
：
文本推荐 Yelp 2189457 1162119 8635403 0.043 https //www.yelp.com/dataset
- ： -
Goodbooks10k 865456 10000 6000000 0.12 https //github.com/zygmuntz/goodbooks10k
表 推荐技术在不同领域的应用
5
Tab.5 Applicationsofrecommendedtechniquesindifferentfields
应用 推荐
代表性模型 数据信息类型 模型特点
领域 技术
用户信息、电影 超关系数据翻译嵌入模型（ - ， ）
电影 ， TranslatingembeddingforHyperRelationaldata TransHR
DNN ［ 90］ 信息、观看时间、 更关注电影之间的关系，它将电影之间的关系嵌入到关系空间中，电影之间的多种向
推荐 TransHR
CF 评分 量关系能得到保留，但也因此增加了模型的空间复杂度
整合性格情绪专注的模型（ ， ）是
， 音乐信息、歌手 PersonalityandEmotionIntegratedAttentivemodel PEIA
音乐 CNN ［ 91］； 将用户的人格和情感结合的模型，充分利用了用户的兴趣偏好变化和社交数据；
， PEIA 信息、听歌时长、
推荐 GRU 潜在因素模型［ 92］ 潜在因素模型通过人的听觉效应特征学习用户潜在偏好的音频，处理的音频被输入
点击数据
CB 到 模型中，缓解了冷启动问题
CNN
个性化注意力的神经网络新闻推荐（
NeuralnewsrecommendationwithPersonalized
， ）模型主要关注不同用户对同一篇新闻的感兴趣程度，从而利用模型中
新闻 ， ［ 93］； 新闻信息、 Attention NPA
LSTM NPA 的注意力机制部分对用户的兴趣建模；
推荐 ［ 94］ 时间、位置
GRU LSTUR 长短期用户表示（ - ， ）模型融合了用户偏
LongandShortTermUserRepresentation LSTUR
好和时序兴趣，能动态为用户产生新闻推荐
， 神经社会协作分级（ ， ）模型是将 和 结
社交 MLP 用户信息、时间、 NeuralSocialCollaborativeRanking NSCR MLP CF
， ［ 95］ 合的一种深度协同过滤推荐算法，其输入是用户特征信息，经过 预测用户潜在偏
网络 CF NSCR 位置等环境信息 MLP
好
MF
视频 视频 播放量、点击 文献［ ］中将 融入到了视频推荐中，将推荐过程分为候选集生成阶段和视频排
YouTube 49 DNN
推荐 MLP 推荐过程［ 49］ 次数、访问日志 序阶段，传统的推荐方法很难为用户推荐符合其偏好的视频
自适应个性化的网络广告推荐模型（ ，
Adaptivepersonalizationofwebadvertising
）通过用户对广告的响应时间和对广告的评论信息捕获用户的潜在偏好；
广告 ［ 96］； 网页信息、文本 AdROSA
， AdROSA 基于深度学习的人脸广告推荐模型（
推荐 CF DL ［ 97］ 数据、面部信息 FaceBasedAdvertisementRecommendationSystem
FBARS ， ）的关键是实现对人脸的三维特征提取，然后将特征提取结
withdeeplearning FBARS
果以三维数组的形式传入深度学习推荐模块
推荐系统面临的挑战和研究趋势 得了令人满意的推荐效果，但仍面临以下挑战，未来可以尝
5
试在以下这些方面进行研究：
推荐系统旨在从海量的推荐对象中帮助用户发现符合
）通过动态信息为用户推荐项目。大部分文献中所提
其偏好的推荐项。本文分析了四类不同的推荐系统，包括基 1
于内容的推荐技术、基于协同过滤的推荐技术、混合推荐技 到的推荐技术都是通过静态信息（假定用户的行为记录不改
术以及基于深度学习的推荐系统，虽然这些推荐技术已经取 变）对用户推荐商品。然而，在实际生活中，用户的喜好会随 计算机应用 第 卷
1910 42
着时间、空间以及内和外部环境的变化而变化，因此，未来对 ， （）： - （ ，
2020 47 7 4755. LIU J L LI X G. Techniques for
用户偏好建模时可以考虑动态的推荐算法。文献［ ］中通 ： ［］ ， ，
98 （rec ）o ：mme -nda ）tionsystem asurvey J . ComputerScience 2020 47
过建立深度递归神经网络模型，使得用户每打开一个新的 7 4755.
， ， -
页面，都会刷新推荐结果，从而实现实时动态推荐服务。 [3] SONGY ELKAHKYAM HEXD. Multiratedeeplearningfor
Web ［］
类似地，文献［ ］中通过建立基于递归神经网络的协作序列 temporal recommendation C // Proceedings of the 39th
99
InternationalACMSIGIRConferenceonResearchandDevelopment
模型，能够准确地捕获用户上下文状态隐藏的特征向量，为 ： ， ： -
inInformationRetrieval. NewYork ACM 2016 909912.
用户动态地推荐项目。然而，目前动态实时地为用户推荐方 ， ， ，
[4] ZHANG S YAO L N SUN A X et al. Deep learning based
面的研究较少，如何根据用户的偏好变化动态地为用户推荐 ： ［］
recommender system a survey and new perspectives J . ACM
， ， （）：
项目，仍是未来推荐系统研究的热点之一。 ComputingSurveys 2020 52 1 No.5.
， ， - ，
）推荐系统安全性有待提高。大规模的在线网站吸引 [5] GOODWIN P KEITH ORD J ÖLLER LE et al.
2 ：
了海量用户的加入，尤其是社交网站的发展，精确地为用户 Principles of Forecasting A Handbook for Researchers and
［ ］ ， ： ， ： -
Practitioners M . Boston MA KluwerAcademic 2001 6170.
推荐感兴趣的项目成了各个网站吸引用户手段之一，而只有 ， ［］
[6] RESNICK P VARIAN H R. Recommender systems J .
对用户的多维度（特征）信息的挖掘才能更容易找到符合其 ， ， （）： -
CommunicationsoftheACM 1997 40 3 5658.
偏好的推荐对象。事实上，用户在期望推荐系统推荐感兴趣 ， ，
[7] SUNMX LEBANONG KIDWELLP. Estimatingprobabilitiesin
［］
的商品时，并不希望个人的其他隐私被公开，目前的研究都 recommendationsystems C //Proceedingsofthe14thInternational
：
是通过数据扭曲和数据模糊的算法扰乱用户的信息。这种 Conference on Artificial Intelligence and Statistics. New York
， ： -
数据扰乱虽对用户的个人隐私做到了保护，但也会导致提取 JMLR.org 2011 734742.
， ， ，
[8] LIU H Y HE J WANG T T et al. Combining user preferences
到的用户信息并不准确，大大降低了推荐的准确性，因此，接 ［］
and user opinions for accurate recommendation J . Electronic
下来可以着重研究一种既能保护用户隐私又可以提高推荐 ， ， （）： -
CommerceResearchandApplications 2013 12 1 1423.
准确性的方法。 ，
[9] ADOMAVICIUS G TUZHILIN A. Toward the next generation of
）缺少提取用户偏好特征的方法。目前的推荐系统推 recommender systems： a survey of the state- of- the- art and possible
3 ［］
荐对象更多的是依赖用户对推荐项目的评分或者反馈信息， extensions J . IEEE Transactions on Knowledge and Data
， ， （）： -
而忽略了用户和推荐对象本身的特征，目前研究缺少适当的 Engineering 2005 17 6 734749.
建模方法对用户和推荐项目的特征、线性和非线性关系进行 [10] HA S H. Helping online customers decide though Web
［］ ， ， （）：
personalization J . IEEE Intelligent Systems 2002 17 6
多维的提取。因此，接下来的研究中需引入更多样的方式来 -
3443.
提取用户和推荐对象的特征。 ， ， ， -
[11] VERBERT K MANOUSELIS N OCHOA X et al. Context
）评价推荐系统的性能指标单一。现有的研究在衡量 ：
aware recommender systems for learning a survey and future
4 ［］ ，
推荐系统性能时，它们多关注的是推荐结果是否准确以及准 challenges J . IEEE Transactions on Learning Technologies
，（）： -
确率是多少，它们认为准确率是衡量推荐系统好坏的最关键 2012 5 4 318335.
， -
指标。推荐的准确率高，则认为这个推荐系统是好的；反之， [12] MOONEYRJ ROYL. Contentbasedbookrecommendingusing
［］
learning for text categorization C // Proceedings of the 5th ACM
则不是一个好的推荐。但是，用户在真正使用这些应用程序 ： ， ：
Conference on Digital Libraries. New York ACM 2000
时，不仅希望系统可以精确地推荐感兴趣的项目，也期待出 -
195204.
现更加多样且新颖的推荐。因此，在未来研究中推荐项目的 ， ，
[13] BREESEJS HECKERMAND KADIEC. Empiricalanalysisof
［］
新颖性、多样性都应该作为推荐系统的评价指标。 predictivealgorithmsforcollaborativefiltering C //Proceedingsof
the14thConferenceonUncertaintyinArtificialIntelligence. San
结语 ： ， ： -
6 Francisco MorganKaufmannPublishersInc. 1998 4352.
， ： - ，
随着深度学习、数据挖掘、预测算法等技术的不断成熟， [14] BALABANOVIĆ M SHOHAM Y. Fab contentbased
［］ ，
collaborative recommendation J . Communications of the ACM
提高推荐系统的准确率、安全性、隐私性将成为未来研究的 ， （）： -
1997 40 3 6672.
热点。本文深入分析了传统推荐方法以及融入了不同深度 ， ， -
[15] LIULW LECUEF MEHANDJIEVN. Semanticcontentbased
学习模型的推荐方法，整理总结了不同推荐领域常用的数据 ［］
recommendation of software services using context J . ACM
， ，（）：
集，对比了传统推荐模型和基于深度学习模型的区别，尝试 TransactionsontheWeb 2013 7 3 No.17.
， -
对推荐系统现存问题进行了总结并对推荐系统的未来发展 [16] SEGEVA TOCHE. ContextbasedmatchingandrankingofWeb
［］
方向做了展望，希望能对推荐系统领域或深度学习领域感兴 services for composition J . IEEE Transactions on Services
， ，（）： -
Computing 2009 2 3 210222.
趣的研究人员提供有益的帮助。 ， ， ， -
[17] BROENS T POKRAEV S SINDEREN M van et al. Context
参考文献（ ） ， - ［］
References aware ontologybased service discovery C // Proceedings of the
周惠宏，柳益君，张尉青，等 推荐技术在电子商务中的运用综 ，
[1] . 2004EuropeanSymposiumonAmbientIntelligence LNCS3295.
述［］计算机应用研究， ， （）：- （ ， ： ， ： -
J . 2004 21 1 812. ZHOUHH LIU Berlin Springer 2004 7283.
， ， ， -
YJ ZHANGWQ etal. Asurveyofrecommendersystemapplied [18] MEDJAHEDB ATIFY. ContextbasedmatchingforWebservice
- ［］ ， ， ［］ ， ，
inEcommerce J . ApplicationResearchofComputers 2004 21 composition J . Distributed and Parallel Databases 2007 21
（）：- ） （）：-
1 812. 1 537.
刘君良，李晓光 个性化推荐系统技术进展［］ 计算机科学， 许海玲，吴潇，李晓东，等 互联网推荐系统比较研究［］ 软件
[2] . J . [19] . J . 第 期 于蒙等：推荐系统综述
6 1911
学报， ， （）： - （ ， ， ， 荐算法［］ 计算机应用与软件， ， （ ）： -
2009 20 2 350362. XUHL WUX LIXD etal. J . 2019 36 12 245250.
［］ （ ， ，
Comparative research on Internet recommendation systems J . WANG Y NI J MA G. Recommendation algorithm based on
， ， （）： - ） ［］
JournalofSoftware 2009 20 2 350362. FunkSVD matrix decomposition and similarity matrix J .
黄立威，江碧涛，吕守业，等 基于深度学习的推荐系统研究综 ， ， （ ）： - ）
[20] . ComputerApplicationsandSoftware 2019 36 12 245250.
述［］计算机学报， ， （）： - （ ， ，
J . 2018 41 7 16191647. HUANGLW [36] DEEP K THAKUR M. A new crossover operator for real coded
， ， ［］ ，
JIANG B T LYU S Y et al. Comparison study of Internet genetic algorithms J . Applied Mathematics and Computation
［］ ， ， ， （）： -
recommendationsystem J . ChineseJournalofComputers 2018 2007 188 1 895911.
（）： - ） ［］
41 7 16191647. [37] KOREN Y. Collaborative filtering with temporal dynamics C //
， ， ，
[21] GOLDBERG D NICHOLS D OKI B M et al. Using Proceedingsofthe15thACMSIGKDDInternationalConferenceon
［］ ： ， ：
collaborative filtering to weave an information tapestry J . KnowledgeDiscoveryandDataMining. NewYork ACM 2009
， ， （ ）： - -
CommunicationsoftheACM 1992 35 12 6170. 447456.
， ， ， - ：
[22] CAIY LEUNGHF LIQ etal. Typicalitybasedcollaborative [38] KOREN Y. Factor in the neighbors scalable and accurate
［］ ［］
filtering recommendation J . IEEE Transactions on Knowledge collaborative filtering J . ACM Transactions on Knowledge
， ， （）： - ， ，（）：
andDataEngineering 2014 26 3 766779. DiscoveryfromData 2010 4 1 No.1.
， - -N ， - ， ，
[23] DESHPANDE M KARYPIS G. Itembased top [39] DECAMPOSLM FERNÁNDEZLUNAJM HUETEJF etal.
［］ - ：
recommendationalgorithms J . ACMTransactionsonInformation Combining contentbased and collaborative recommendations a
， ， （）： - ［］
Systems 2004 22 1 143177. hybrid approach based on Bayesian networks J . International
： ， ， （）： -
[24] KOREN Y. Factorization meets the neighborhood a multifaceted JournalofApproximateReasoning 2010 51 7 785799.
［］ ， -
collaborative filtering model C // Proceedings of the 14th ACM [40] PAZZANIMJ. Aframeworkforcollaborative contentbasedand
［］ ， ，
SIGKDD International Conference on Knowledge Discovery and demographicfiltering J . ArtificialIntelligenceReview 1999 13
： ， ： - （ ）： -
DataMining. NewYork ACM 2008 426434. 5/6 393408.
， ， - ， ，
[25] MA W M SHI J F ZHAO R D. Normalizing itembased [41] ZHANG H GE D C ZHANG S Y. Hybrid recommendation
-
collaborative filter using contextaware scaled baseline predictor systembasedonsemanticinterestcommunityandtrustedneighbors
［］ ， ， ： ［］ ， ， （）： -
J . Mathematical Problems in Engineering 2017 2017 J . Multimedia Tools and Applications 2018 77 4 4187
No.6562371. 4202.
周万珍，曹迪，许云峰，等 推荐系统研究综述［］ 河北科技大 ， ， ，
[26] . J . [42] HUANG Z H YU C NI J et al. An efficient hybrid
学学报， ， （）： - （ ， ， ， ［］
2020 41 1 7687. ZHOUWZ CAOD XUYF et recommendation model with deep neural networks J . IEEE
［］ ， ，： -
al. A survey of recommender systems J . Journal of Hebei Access 2019 7 137900137912.
， ， （）： - ） ， ， ，
UniversityofScienceandTechnology 2020 41 1 7687 [43] HU J J LIU L Z ZHANG C Y et al. Hybrid recommendation
， ， ， - ［］
[27] SARWAR B KARYPIS G KONSTAN J et al. Itembased algorithm based on latent factor model and PersonalRank J .
［］ ， ， （）： -
collaborative filtering recommendation algorithms C // JournalofInternetTechnology 2018 19 3 919926.
， ， ，
Proceedings of the 10th International Conference on World Wide [44] CHENSJ QINZ WILSONZ etal. Improvingrecommendation
： ， ： - ［］
Web. NewYork ACM 2001 285295. quality in Google Drive C // Proceedings of the 26th ACM
， ， ， ：
[28] RESNICK P IACOVOU N SUCHAK M et al. GroupLens an SIGKDD International Conference on Knowledge Discovery. New
［］ ： ， ： -
open architecture for collaborative filtering of netnews C // York ACM 2020 29002908.
， ， ， ： -
Proceedingsofthe1994ACMConferenceonComputerSupported [45] SHANY HOENSTR JIAOJ etal. Deepcrossing webscale
： ， ： - ［］
CooperativeWork. NewYork ACM 1994 175186. modeling without manually crafted combinatorial features C //
， -
[29] YOO H CHUNG K. Deep learningbased evolutionary Proceedings of the 22nd ACM SIGKDD International Conference
［］ ： ，
recommendationmodelforheterogeneousbigdataintegration J . on Knowledge Discovery and Data Mining. New York ACM
， ， ： -
KSIITransactionsonInternetandInformationSystems 2020 14 2016 255262.
（）： - ， ， ，
9 37303744. [46] HOENSTR BLANTONM STEELEA etal. Reliablemedical
， ［］
[30] SALAKHUTDINOV R MNIH A. Probabilistic matrix recommendation systems with patient privacy J . ACM
［］ ， ，（）：
factorization C // Proceedings of the 20th International TransactionsonIntelligentSystemsandTechnology 2010 4 4
，
ConferenceonNeuralInformationProcessingSystems. RedHook No.67.
： ， ： - ， ， ，
NY CurranAssociatesInc. 2007 12571264. [47] FANG L J KIM H LeFEVRE K et al. A privacy
- ［ ］ （ - - ）［ - - ］ ［］
[31] FUNK S. FunkSVD EB/OL . 20061211 20201101 . recommendation wizard for users of social networking sites C //
：
http //sifter.org/simon/journal/20061211.html. Proceedings of the 17th ACM Conference on Computer and
， ： ， ： -
[32] LI G OU W H. Pairwise probabilistic matrix factorization for CommunicationsSecurity. NewYork ACM 2010 630632.
［］ ， 蒋伟 推荐系统若干关键技术研究［ ］ 成都：电子科技大学，
implicit feedback collaborative filtering J . Neurocomputing [48] . D .
， ： - ： - （（
2016 204 1725. 2018 1020. JIANGW. Researchonsomekeytechnologiesof
， ， ， ［ ］ ：
[33] STRAHL J PELTONEN J MAMITSUKA H et al. Scalable recommender systems D . Chengdu University of Electronic
- ［］ ， ： - ）
probabilistic matrix factorization with graphbased priors C // ScienceandTechnologyofChina 2018 1020.
， ，
Proceedings of the 34th AAAI Conference on Artificial [49] COVINGTON P ADAMS J SARGIN E. Deep neural networks
， ： ， ： - ［］
Intelligence. PaloAlto CA AAAIPress 2020 58515858. forYouTuberecommendations C //Proceedingsofthe10thACM
： ， ：
[34] XUCH. Anovelrecommendationmethodbasedonsocialnetwork Conference on Recommender Systems. New York ACM 2016
［］ -
using matrix factorization technique J . Information Processing 191198.
， ， （）： - ， ， ，
andManagement 2018 54 3 463474. [50] CHENG H T KOC L HARMSEN J et al. Wide & Deep
王运，倪静，马刚 基于 矩阵分解和相似度矩阵的推 ［］
[35] . FunkSVD learning for recommender systems C // Proceedings of the 1st 计算机应用 第 卷
1912 42
［ ］： ，
Workshop on Deep Learning for Recommender Systems. New Papers. S. l. The COLING 2016 Organizing Committee
： ， ：- ： -
York ACM 2016 710. 2016 30193029.
， ，
[51] XU X. Matrix factorization recommendation algorithm based on [65] DEY K SHRIVASTAVA R KAUSHIK S. Topical stance
［］ ： -
deep neural network C // Proceedings of the 2nd International detection for Twitter a twophase LSTM model using attention
［］
Conference on Information Systems and Computer Aided C // Proceedings of the 2018 European Conference on
： ， ： - ： ， ： -
Education. Piscataway IEEE 2019 320323. InformationRetrieval. Cham Springer 2018 529536.
， ， ， ， ， ，
[52] ZHANG L LUO T ZHANG F etal. A recommendation model [66] WU Q T ZHANG H R GAO X F et al. Dual graph attention
［］ ， ，： -
basedondeepneuralnetwork J . IEEEAccess 2018 6 9454 networks for deep latent representation of multifaceted social
［］
9463. effects in recommender systems C // Proceedings of the 2019
， ， ： ， ： -
[53] RUMELHART D E HINTON G E WILLIAMS R J. Learning World Wide Web Conference. New York ACM 2019 2091
- ［］ ， ，
representationsbybackpropagatingerrors J . Nature 1986 323 2102.
（ ）： - ， ， ， -
6088 533536. [67] LeCUN Y BOTTOU L BENGIO Y et al. Gradientbased
， ， ， - ［］
[54] OKURA S TAGAMI Y ONO S et al. Embeddingbased news learning applied to document recognition J . Proceedings of the
［］ ， ， （ ）： -
recommendationformillionsofusers C //Proceedingsofthe23rd IEEE 1998 86 11 22782324.
，
ACM SIGKDD International Conference on Knowledge Discovery [68] SIMONYAN K ZISSERMAN A. Very deep convolutional
： ， ： - - ［ ］（ - -
andDataMining. NewYork ACM 2017 19331942. networks for largescale image recognition EB/OL . 201504
， ， ）［ - - ］ ：
[55] SUTSKEVER I VINYALS O LE Q V. Sequence to sequence 10 20210220 .https //arxiv.org/pdf/1409.1556.pdf.
［］ ， ， ，
learning with neural networks C // Proceedings of the 27th [69] HUANG G LIU Z MAATEN L van der et al. Densely
［］
International Conference on Neural Information Processing connected convolutional networks C // Proceedings of the 2017
： ， ： -
Systems. Cambridge MITPress 2014 31043112. IEEE Conference on Computer Vision and Pattern Recognition.
， ， ， - - ： ， ： -
[56] ZHANG Y PEZESHKI M BRAKEL P et al. Towards endto Piscataway IEEE 2017 47004708.
， ，
end speech recognition with deep convolutional neural networks [70] OORD A van den DIELEMAN S SCHRAUWEN B. Deep
［］ ［ ］： - ［］
C //ProceedingsoftheInterSpeech2016. S.l. International contentbasedmusicrecommendation C //Proceedingsofthe26th
， ： -
SpeechCommunicationAssociation 2016 410414. International Conference on Neural Information Processing
， - ， ： ， ： -
[57] HOCHREITER S SCHMIDHUBER J. Long shortterm memory Systems. Red Hook NY Curran Associates Inc. 2013 2643
［］ ， ，（）： -
J . NeuralComputation 1997 9 8 17351780. 2651.
， ， ， - ： - ， ， ，
[58] CUI Q WU S LIU Q et al. MVRNN a multiview recurrent [71] GENG X ZHANG H W BIAN JW etal. Learningimageand
［］ ［］
neural network for sequential recommendation J . IEEE user features for recommendation in social networks C //
， ， （）：
TransactionsonKnowledgeandDataEngineering 2020 32 2 Proceedings of the 2015 IEEE International Conference on
- ： ， ： -
317331. ComputerVision. Piscataway IEEE 2015 42744282.
， ， ， ， ， ，
[59] HUANG J ZHAO W X DOU H j et al. Improving sequential [72] KIMD PARKC OHJ etal. Convolutionalmatrixfactorization
- ［］ - ［］
recommendation with knowledgeenhanced memorynetworks C // for document contextaware recommendation C // Proceedings of
：
Proceedings of the 41st International ACM SIGIR Conference on the10thACMConferenceonRecommenderSystems. NewYork
： ， ： -
Research and Development in Information Retrieval. New York ACM 2016 233240.
， ： - ， -
ACM 2018 505514. [73] GONGYY ZHANGQ. Hashtagrecommendationusingattention
， ， ， - ［］
[60] LINQK NIUYQ ZHUYF etal. Heterogeneousknowledge based convolutional neural network C // Proceedings of the 25th
-
based attentive neural networks for shortterm music International Joint Conference on Artificial Intelligence.
［］ ， ，： - ： ， ： -
recommendations J . IEEEAccess 2018 6 5899059000. California ijcai.org 2016 27822788.
， ， ， - ， ， ，
[61] SONGWP XIAOZP WANGYF etal. Sessionbasedsocial [74] ZHANG Q WANG J W HUANG H R et al. Hashtag
［］ -
recommendation via dynamic graph attention networks C // recommendation for multimodal microblog using coattention
［］
Proceedings of the 12th ACM International Conference on Web network C // Proceedings of the 26th International Joint
： ， ： - ： ， ：
SearchandDataMining. NewYork ACM 2019 555563. ConferenceonArtificialIntelligence. California ijcai.org 2017
张昕，刘思远，徐雁翎 结合注意力机制的知识感知推荐算法 -
[62] . 34203426.
［ ］ 计算机工程与应用 （ - - ）［ - - ］ 黄文明，卫万成，张健，等 基于注意力机制与评论文本深度模
J/OL . . 20210331 20210411 . [75] .
： 型的推荐方法［］ 计算机工程， ， （）： -
https //kns. cnki. net/kcms/detail/11.2127. TP. 20210330.1708. J . 2019 45 9 176182.
（ ， ， - （ ， ， ，
026. html. ZHANG X LIU S Y XU Y L. Knowledgeaware HUANG W M WEI W C ZHANG J et al. Recommendation
［
recommendation algorithm combined with attention mechanism J/ methodbasedonattentionmechanismandreviewtextdeepmodel
］ （ - - ） ［］ ， ， （）： - ）
OL . Computer Engineering and Applications. 20210331 J . ComputerEngineering 2019 45 9 176182.
［ - - ］ ： ， ， ，
20210411 . https //kns. cnki. net/kcms/detail/11.2127. TP. [76] LI Z SHEN X JIAO Y H et al. Hierarchical bipartite graph
） ： - -
20210330.1708.026.html. neural networks towards largescale ecommerce applications
任柯舟，彭甫镕，郭鑫，等 动态融合社交信息的社会化推荐 ［］
[63] . C // Proceedings of the IEEE 36th International Conference on
［］ 计算机应用， ， （ ）： - （ ， ： ， ： -
J . 2021 41 10 28062812. REN K Z DataEngineering. Piscataway IEEE 2020 16771688.
， ， ， ： -
PENG F R GUO X et al. Social recommendation based on [77] ZHANG M G YANG Z Y. GACOforRec sessionbased graph
［］ ［］
dynamicintegrationofsocialinformation J . JournalofComputer convolutional neural networks recommendation model J . IEEE
， ， （ ）： - ） ， ，： -
Applications 2021 41 10 28062812. Access 2019 7 114077114085.
， ， ， ， ， ，
[64] LI Y LIU T JIANG J et al. Hashtag recommendation with [78] SHI X J CHEN Z R WANG H et al. Convolutional LSTM
- ［］ ：
topical attentionbased LSTM C // Proceedings of the 26th network amachinelearningapproachforprecipitationnowcasting
： ［］
International Conference on Computational Linguistics Technical C // Proceedings of the 28th International Conference on Neural 第 期 于蒙等：推荐系统综述
6 1913
： ， ：
Information Processing Systems. Cambridge MIT Press 2015 integrated attentive model for music recommendation on social
- ［］
802810. mediaplatforms C //Proceedingsofthe34thAAAIConferenceon
王英博，孙永荻 基于 的矩阵分解推荐算法［］ 计算机工 ， ： ， ：
[79] . GNN J . Artificial Intelligence. Palo Alto CA AAAI Press 2020
程与应用， ， （ ）： - （ ， -
2021 57 19 129134. WANG Y B SUN Y D. 206213.
- ［］ ，
GNNbased matrix factorization recommendation algorithm J . [92] LIU C L CHEN Y C. Background music recommendation based
， ， （ ）： ［］ - ， ，
Computer Engineering and Applications 2021 57 19 onlatentfactorsandmoods J . KnowledgeBasedSystems 2018
- ） ： - ）
129134. 159 158170.
， ， ， ， ， ， ：
[80] DENGSG HUANGLT XU GD etal. Ondeeplearningfor [93] WU C H WU F Z AN M X et al. NPA neural news
- ［］ ［］
trustaware recommendations in social networks J . IEEE recommendation with personalized attention C // Proceedings of
， ，
TransactionsonNeuralNetworksandLearningSystems 2017 28 the 25th ACM SIGKDD International Conference on Knowledge
（）： - ： ， ： -
5 11641177. DiscoveryandDataMining. NewYork ACM 2019 25762584.
， ， ， - ： - ， ， ，
[81] YANGJH CHENCM WANGCJ etal. HOPRec highorder [94] ANMX WUFZ WUCH etal. Neuralnewsrecommendation
［］ - - ［］
proximity for implicit recommendation C // Proceedings of the withlongandshortterm userrepresentations C //Proceedingsof
：
12th ACM Conference on Recommender Systems. New York the 57th Annual Meeting of the Association for Computational
， ： - ， ：
ACM 2018 140144. Linguistics. Stroudsburg PA Association for Computational
， ： - ， ： -
[82] LIN S D RUNGER G C. GCRNN groupconstrained Linguistics 2019 336345.
［］ ， ， ， ：
convolutionalrecurrentneuralnetwork J . IEEE Transactionson [95] WANG X HE X N NIE L Q et al. Item silk road
， ， （ ）： - ［］
Neural Networks and Learning Systems 2018 29 10 4709 recommendingitemsfrominformationdomainstosocialusers C //
4718. Proceedings of the 40th International ACM SIGIR Conference on
曹万平，周刚，陈黎，等 基于会话的图卷积递归神经网络推荐 ：
[83] . Research and Development in Information Retrieval. New York
模型［］ 四川大学学报（自然科学版）， ， （）： - ， ： -
J . 2021 58 2 6672. ACM 2017 185194.
（ ， ， ， - ， —
CAO W P ZHOU G CHEN L et al. Sessionbased graph [96] KAZIENKO P ADAMSKI M. AdROSA adaptive
［］ ，
convolutional recurrent neural networks recommendation model personalization of web advertising J . Information Sciences
［］ （ ）， ， （ ）： -
J . Journal of Sichuan University Natural Science Edition 2007 177 11 22692295.
， （）： - ） ， ， ，
2021 58 2 6672. [97] YAOXZ CHENYY LIAOR etal. Facebasedadvertisement
任俊伟，曾诚，肖丝雨，等 基于会话的多粒度图神经网络推荐 ： ［］
[84] . recommendation with deep learning a case study C //
模型［］ 计算机应用， ， （ ）： - （ ，
J . 2021 41 11 31643170. RENJW Proceedings of the 2017 International Conference on Smart
， ， - ， ： ，
ZENGC XIAOSY etal. Sessionbasedrecommendationmodel ComputingandCommunication LNISA10699. Cham Springer
- ［］ ： -
of multigranular graph neural network J . Journal of Computer 2018 96102.
， ， （ ）： - ） ， ， ，
Applications 2021 41 11 31643170. [98] WUS RENWC YUCC etal. Personalrecommendationusing
， ： ［］
[85] HARPERFM KONSTANJA. TheMovieLensdatasets history deeprecurrentneuralnetworksinNetEase C //Proceedingsofthe
［］
and context J . ACM Transactions on Interactive Intelligent IEEE 32nd International Conference on Data Engineering.
， ，（）： ： ， ： -
Systems 2016 5 4 No.19. Piscataway IEEE 2016 12181229.
， ， ， ，
[86] CHIA P H PITSILIS G. Exploring the use of explicit trust links [99] WUS RENWC YUCC etal. Personalrecommendationusing
： ［］ ［］
forfilteringrecommenders astudyonEpinions.com J . Journal deeprecurrentneuralnetworksinNetEase C //Proceedingsofthe
， ， ： -
ofInformationProcessing 2011 19 332344. IEEE 32nd International Conference on Data Engineering.
， ， ： ， ： -
[87] CANTADORI BRUSILOVSKYP KUFLIKT. Secondworkshop Piscataway IEEE 2016 12181229.
on information heterogeneity and fusion in recommender systems
（ ）［］
HetRec2011 C // Proceedings of the 5th ACM Conference on This work is partially supported by National Natural Science
： ， ： - （ ），
RecommenderSystems. NewYork ACM 2011 387388. FoundationofChina 12050410248 ScienceandTechnologyProgram
， ， ， ： - （ ），
[88] WUFZ QIAOY CHENJH etal. MIND alargescaledataset of Sichuan Province 2021YFH0120 Southwest Minzu University
［］ （ ）
for news recommendation C // Proceedings of the 58th Annual GraduateInnovativeResearchProject CX2020SZ04 .
Meeting of the Association for Computational Linguistics. YU Meng， ，
， ： ， born in 1995 M. S. candidate. Her research interests
Strou ：dsburg - PA Association for Computational Linguistics includerecommendationsystem， informationfiltering， datamining.
2020 35973606. HEWentao， ，
， ， ， bornin1996 M.S.candidate.Hisresearchinterests
[89] KRONMUELLER M CHANG D J HU H Q et al. A graph
，
database of Yelp Dataset Challenge 2018 and using cypher for includedeeplearning datamining.
［］ ZHOU Xuchuan， ， ，
basic statistics and graph pattern exploration C // Proceedings of born in 1972 Ph. D. professor. His research
，
the2018IEEEInternationalSymposiumonSignalProcessingand interestsincludedatamining deeplearning.
： ， ： - CUI Mengtian， ， ，
InformationTechnology. Piscataway IEEE 2018 135140. born in 1972 Ph. D. professor. Her research
， ， ，
[90] ZHOU M ZHANG C H HAN X et al. Knowledge graph interestsincludeintelligentinformationprocessing.
- ［］ WU Keqi， ，
completionforhyperrelationaldata C //Proceedingsofthe2016 born in 1997 M. S. candidate. His research interests
International Conference on Big Data Computing and includerecommendationsystem.
， ： ， ： - ZHOU Wenjie， ，
Communications LNISA9784. Cham Springer 2016 236246. born in 1997 M. S. candidate. His research
， ， ， ：
[91] SHEN T C JIA J LI Y et al. PEIA personality and emotion interestsincludedatamining. --------------------------------------------------------------------------------- 2021年2月 昆明理工大学学报 (社会科学版) Feb.2021
第1期 第21卷 Journal of Kunming University of Science and Technology (Social Sciences) No.1，Vol.21
doi: 10.16112/j. cnki.53 －1160/c.2021.01.013
数字化生存中的信息过载及其空间治理
管其平
(安徽大学 社会与政治学院，安徽 合肥230601)
摘 要: 当今社会呈现出的社会表象是一个与农业社会、工业社会都有所不同的新社会形态———网
络社会，其直接意蕴是一个全新时空场域的诞生———网络场域，并塑造了一种常态化的生活方式———数
字化生存。随着网络技术对日常生活的深度介入，信息过载已成为数字化生存中客观的、不以个人意志
为转移的社会事实，其主要呈现为信息量的无上限与质的无下限，信息样态的碎片化与嵌入性，信息表
象的狂欢化与无序化。基于此，有效应对信息过载需完善网络法律道德体系、营造有序的数字生存秩序，
完善网络空间智能基础设施、建立智能信息管理系统，完善网络空间文化建设，提高网络受众媒介素养，
充分整合网络社会资源，推动多元治理主体合作共治等举措加以综合应对。
关键词: 网络场域; 数字化生存; 信息过载; 空间治理; 网络文化
中图分类号: G237.5 文献标志码: A 文章编号: 1671－1254 (2021) 01－0099－09
Information Overload and Space Governance in Digital Survival
GUAN Qiping
(School of Social and Political Sciences，Anhui University，Hefei230601，Anhui，China)
Abstract: The present society displays a new social form，i．e． the network society，different from that of
the agricultural society and the industrial society． The implication of the network society is the birth of a brand
new space－time field，that is，the network field，and shapes a normal lifestyle known as digital survival． With
the deeper involvement of network technology in daily life，information overload has become an objective social
reality in digital survival that does not rely on personal wills． It mainly presents as an unlimited upper limit for
information quantity and an unlimited lower limit for qualitative information with the characteristics of fragmenta-
tion and embedding，carnivalization and disorder of information representation． Thereafter，to deal with informa-
tion overload effectively，it is necessary to improve the network legal ethics system，create an orderly digital sur-
vival order，improve the network space intelligent infrastructure，establish an intelligent information management
system，and improve the network space culture construction and the network audience media literacy． We shall
fully integrate the network social resources and take comprehensive measures to promote cooperation and co －
governance of multiple governance subjects so as to achieve successful respond to the problem of information o-
verload．
Key words: network field，digital survival，information overload，space governance，network culture
互联网犹如柴米油盐一样成为当下人们日常 这直接引起了以个体为代表的诸多社会系统的组
不可或缺的生活必需品，其构筑的全新时空场 成要素以虚拟化的方式呈现在网络之中。基于
景，给社会生活的时空维度带来了革命性变化， 此，社会成员才得以在网络空间中进行更为多
收稿日期: 2020－08－16
基金项目: 教育部重大项目“中国网络社会的现实基础、本土特色与运行模式研究”(19JJD840003); 安徽省合肥
市重大项目“城乡社区治理创新研究”(2019FCFN0398)
作者简介: 管其平 (1993—)，男，博士研究生，主要从事社会管理与社会政策研究。 ·100· 昆明理工大学学报 (社会科学版) 第21卷
元、复杂的社会性活动。依据中国互联网信息中 程。也即是在这一过程中，场域逐渐摆脱了政
心 ( CNNIC) 第45 次 《中国互联网络发展状况 治、经济等外部因素束缚获得独立性，成为支配
统计报告》调查，截至2020 年3 月，我国网民 场域中行动者进行数字化活动的规则。于此而
规模为9.04 亿，互联网普及率达64.5%。其中， 言，依托互联网构筑而成的网络场域成了一种具
手机网民规模为 8.97 亿［1］。换言之，随着移动 有多重社会关系及位置关系的社会共同体。因
式智能终端的普及愈加深化了日常生活的数字 此，网络场域之所以能够作为数字化生存的承载
化。但是，生活时空情景的变化也给社会公众带 者，主要得益于网络场域的客观性、社会性及能
来了众多烦恼。如今，我们每天都被形式各样的 动性。
信息所包围，长时间处于一种信息过载的生活状 1. 网络场域自身的客观性属性。网络场域一
态，这不得不引起我们的重视。所谓信息过载， 经形成之后便作为一种社会事实独立于人的意识
这里是指社会公众在数字化生活中被大量无序、 之外，且其作为一种力量在隐约制约个人的数字
重复及劣质信息包围，超出了个人自身以及社会 化行为，更有个体将数字化生活之中的规则作为
系统已有的承受能力，并对自身及社会的有序运 现实社会实践的准则。此外，基于各种社会关系
行产生了一系列潜在影响。基于此，剖析信息过 的社会互动是维持网络场域活力的动力，而网络
载的生成逻辑及其社会表象，探析消解信息过载 场域中社会关系具有客观性。这些社会关系既有
的有效策略，不仅是实现网络空间治理体系与治 来于已有的现实社会关系，也有经过网络 “他
理能力现代化的应有之义，也是满足公众对美好 者”或者场域自身智能性推荐的社会关系。诸如
数字化生活需求的必然之举。 以微信、微信群为代表的熟人场域及以 QQ 群、
淘宝群为代表的半熟人场域。无论是基于何种形
一、数字化生存: 社会生活的基本形式之一
式以何种方式呈现的社会关系都是一种客观性存
信息交流方式的变化实际就是人类生存方式 在的社会事实。
的变化［2］。网络场域极大改变了已有的生存方式 2. 网络场域自身的社会性属性。人类日常
与生存状态，构筑了一种新的生活方式———数字 的社会实践都带有深刻的社会属性，数字化生存
化生存。总的来看，数字化生存作为与现实生活 作为人类的一种生活方式，也带有浓厚的社会
相异的生活方式以网络场域为基本载体。因此， 性。一方面，网络已把诸多社会实践、社会情景
解读数字化生存中的信息过载，首先要分析承载 以虚拟符号化的方式呈现在网络场域中，带有深
数字化生存的网络场域，其次要探析数字化生存 刻的人化特性，进而以数字的方式反映社会现
作为一种新的生活方式所具有的特殊性，在此基 象、社会个体及群体的行为及思想。另一方面，
础上才能深刻透析信息过载及其有效的空间治理 网络场域包含着众多形式的分场域，比如聊天场
策略。 域、娱乐场域、工作场域等等，每一个分场域都
( 一) 网络场域: 数字化生存的承载者 包含着社会实践与社会关系。这些 “分场域”成
互联网塑造的网络场域如同一块巨大的磁铁 为社会成员进行实践的场所，各种数字行为是社
对社会公众呈现出强大的吸引力。何为场域，皮 会成员在网络场域之中不断适应与重构数字化社
埃尔·布尔迪厄曾云: “一个场域可以被定义为 会生活的结果。
在各个位置之间存在的客观关系的一个网络 3. 网络场域自身的能动性属性。网络场域之
( network) ，或一个构型 ( configuration) 。”［3］换言 间及场域内部存在着剧烈的斗争性，而这种斗争
之，场域最核心的本质即是不同行动者占据的位 性也代表着网络营造的自由环境并不代表每个人
置关系的不同，这些位置关系包含由不同社会成 占据网络资源的平等。资源的占有也往往由于现
员依据自身资源而建构的各种社会性支配关系、 实中身份的不同而不同，这种差异性塑造并加剧
对应关系等等。基于此，场域呈现出的社会网络 了网络场域的能动性，进一步推动了数字化生存
关系也是个体通过实践寻找并确定社会位置的过 的深入发展。在场域斗争之中那些拥有较多资源 第1期 管其平: 数字化生存中的信息过载及其空间治理 ·101·
的场域个体往往更容易占据有利的地位，而获得 2. 从社会生活的空间维度看。空间是标定社
成功。诸如抖音、快手场域中的 “网红异变”， 会成员社会位置的一种维度。在前现代社会，对
游戏场域中为胜利进行的 “王冠争夺”等等。同 存在社交距离的两个社会成员来说，其无法同时
时，在网络场域中社会个体需要通过符码及数字 占据一个空间，并在同一个空间中进行相关的社
重新构造自身的场域形象。只有深入了解场域中 会行为。换言之， “没有两个人体能够同时占据
的 “活动规则”，才能有效地掌握并参与场域内 同一空间。”［7］但是，数字化生存则改变了这种状
的互动、娱乐等活动。可以说，网络场域成了数
况。互动双方只需要进入同一个网络场域，便能
字化生存中 “一切数字社会关系的总和”。
实现同在性。此外，通过移动式智能终端，社会
( 二) 数字化生存: 一种常态化的新体验
成员可以同时打开多个场域进行视频互动，数字
数字化生存正在日益成为后现代的日常生活
化群体中的每一个成员都具有 “分身术”。可以
状态，人们熟悉的生活和体制正在深刻地变
说，地理空间塑造的社交距离已不再是阻隔社会
化［4］。较之现有的社会生活，不仅人们的生活方
互动的障碍，即便是社会关系也从已有的地域性
式发生着深刻的时空转向，而且用以维系社会运
生活空间之中 “脱域”出来。此外，地理性的位
转的规则与秩序也发生了时空转向。从结构功能
置空间也因为互联网数字技术的升入融合介入被
主义来看，社会本来就是一个始终处于变化之中
转换成流动空间。比如，在数字化的生活体验
的社会事物。因此， “社会不是坚实的结晶体，
中，可以通过相关软件进行空间定位，并能够实
而是一个能够变化并且经常处于变化过程中的有
时共享及发送位置。
机体。”［5］社会事实表明，社会的变化是基于时间
3. 从社会生活的实践维度来看。数字化生存
与空间的变化，而这种变化只能以实践方式得以
作为一种新的生活体验，其典型特征是实践方式
呈现。而在此过程之中，时间、空间及实践本身
由传统的现实实践步入虚拟实践。传统生活中的
也成了衡量人类生存方式变化与否的重要维度。
社会实践活动以自然界存在的客观物质为基础。
质言之，人类生存与发展离不开时间、空间以及
其实践的主体、实践的客体以及实践的中介清晰
实践三个基本要素。或者说，人类的生存与发展
明确。而数字化生存实践方式是以互联网为基
( 包括社会自身的发展) ，也即是在特定的时间与
础，以网络、虚拟现实技术为中介，实践的客体
空间中进行社会实践的过程。
逻辑化为网络空间中的符号、数字，实践中介则
尼古拉·尼葛洛庞蒂指出，数字化生存是指
变为键盘、鼠标等硬件设施。首先，现实生活实
人们在数字化的生存活动空间里，运用数字技术
践中的实践主体的身份是稳定、清楚的。实践活
( 信息技术) 顺利地进行信息传播、交流、学习、
动的主体是处在一定物理空间之中的社会活动，
工作等活动的过程［6］。数字化生存作为一种常态
且具有一定的现实性和有限性。而数字化生存中
化的新体验，则体现为数字化活动的时间、空间
的实践主体的身份具有非不确定及匿名的，虚拟
及实践形式的变化。
实践是处于网络场域之中的无边界的社会性活
1. 从社会生活的时间维度看。时间是社会成
员参与社会实践所遵循的基本维度，其由社会本
动，且其具有跨时空性及虚拟性。同时，数字化
身赋予又与社会成员自身意识有关。基于传统社 生存的虚拟实践客体已经不再是现实中常规的经
会开展的社会互动时间属性是线性的，由此人与 验性对象，而是存在于网络场域中的一种对现实
人的交往是一种在场交往。但是，数字化生存中 进行仿真、拟象的虚拟性经验对象。此外，虚拟
社会互动的时间是多维的且能被自由分割，由此 实践的工具已经变成了信息化的技术工具，人们
引起的交往则变成了一种在场、缺场及转场同在 的社会关系通过虚拟实践在社交平台、通讯工具
的形式。数字化生存只需遵守场域自身的规则， 中复制并得以延伸，并借助虚拟实践的方式，以
点击相应的登录、切换就可以实现自我的缺场及 各种各样的符号及数字作为中介衍生了更多的社
转场的自由切换。 会关系。 ·102· 昆明理工大学学报 (社会科学版) 第21卷
弹幕实现连通以实现信息的最大整合。此外，信
二、数字化生存中信息过载的生成逻辑
息能够以各种各样方式呈现出来、信息的内容更
信息过载的过程不仅是数字化生存进一步深 加丰富多彩，形式愈加多样。
化的过程，也是信息借助虚拟实践不断裂变、重 3. 网络使信息发布的门槛降低，信息的融合
组与革新的过程; 同时，信息过载作为一种社会 性增强。据调查显示，截至2019 年12 月，我国
事实，其产生、裂变及演化有着自身特定的逻辑 的网页数达到2978 亿个，域名总数为5094 万个，
与规律。总的来看，信息过载是社会成员借助网 IPv4 地址数量为38751 万个，已有 APP 数量367
络场域的独特属性进行虚拟实践的一种社会 万个［1］。新闻网站、APP应用、论坛贴吧、短视
产物。 频及直播平台大量存在于我们生活中，这不仅增
( 一) 网络技术的诞生与革新是信息过载的 加了社会成员获取信息的途径，也增加了社会成
关键 员发布信息的途径; 同时，云计算及智能技术在
网络不仅是塑造数字化生存的关键力量，也 网络中的应用使网页、公众号不仅能主动性把信
是一场关乎信息生产、传播的颠覆性革命。没有 息推送到个体眼前，而且使信息可以通过简单的
信息传播工具，仅仅依靠社会成员口头方式传 点击或转发在不同场域之间进行传播，实现最大
播，很难形成信息实时动态更新的现象，更不用 的信息融合效应，不同APP应用程序之间信息能
说信息过载。质言之，信息传播方式的革新是信 够通过转发、链接等方式实现共享。
息过载得以形成的关键。 ( 二) 网络场域的时空特性是信息过载的助
1. 网络使既往的信息权力发生重组，实现 推者
了信息权力的泛社会化。传统社会中，受社会 数字化生存中的信息过载现象与互联网引起
阶层分化的影响，社会成员拥有的信息权及话 的信息时空情景的变化息息相关，正是时空情景
语权存在显著性差异。社会中的小部分精英群 的变化引起信息本身的特性发生了异化。从现象
体不但掌握了社会大部分话语权，也通过话语 学来看，时间是在空间的变化过程中呈现的时
权直接或间接掌握着信息权，处于社会中层及 间，空间则是在时间的过程中展开的空间，时间
底层的群体往往只是单纯的信息接收者及接受 与空间不可分离。网络场域最大的特性之一便是
者，其呈现的是一种 “传—受”关系。但是， 其对传统时空分解而产生的时空流动性。这种时
网络则打破了阶层分化对信息权利的束缚，其 空的流动性特性使得信息的传播时间及传播空间
塑造的自由平等的话语情景使得信息获取及传 发生了重组，不仅显性地拉近了信息传播的时间
播不关乎个人身份、年龄、职业阶层的限制。 与空间之间的距离，而且使得人们愈加便捷的时
如今，社会成员只需要简单地信息注册就能够 时获取信息。
成为数字化群体中的一员，并能够借助网络接 1. 信息过载的一个重要原因是信息能够在瞬
受信息及发布信息。因此，在数字化生存的时 时间内进行聚集。前现代社会由于地域限制人的
空情景中 “人人都是传者”。 流动性较低，信息传递速率较慢，信息经过很长
2. 网络使信息传播的形式及内容愈加多元 的时间才能传达到其他区域。信息生成与传播的
化。前现代社会语境之下信息生产与发布模式明 具有想对的固定性与稳定性。与之相反，进入网
显滞后。社会成员通过报纸、广播等传统媒介获 络场域，时间与空间对信息的束缚得以缓解。使
取信息及传播信息的渠道也非常有限。信息只能 用智能手机，信息瞬间就可以传递到任何地方。
在一个较为有限的范围之内进行传播，信息的接 信息时间被 “压缩”了，信息的 “历时态”空
触点与传播圈较为狭窄。与此相对，互联网时代 前变短。这就使信息具有了流动性与不确定性。
信息传播媒介演变成了新兴网络媒体。信息不但 在这种时空情境之下信息变成了一种立体、叠加
可以借助微信群、朋友圈、抖音及其他网络平台 式的，信息能够通过互联网在极短的时间内传送
实现实时传播，而且信息能够通过回复、留言、 到地球上的任何一个地方。 第1期 管其平: 数字化生存中的信息过载及其空间治理 ·103·
2. 信息过载是一种过去、现在及未来信息同 的一种社会认同。或者说，一种集体无意识，个
在的信息属性。前现代社会，过往的信息很难再 体享受着匿名性给其带来的认同感，不再过多地
次成为社会公众谈论的话题，也很能经过现有的 考虑其自身行为可能带来的后果，由此带来的是
时间进行生动的再现。但是，在网络场域之中， 多元价值观的并存、理行意识的丧失。
我们能够依靠网络为我们设定的社会时间节点，
三、数字化生存中信息过载的社会表象
随时找到我们需要的信息，并且，过去、现在及
未来信息能够同时呈现在一个场域之中，随时可 互联网营造的虚拟使信息的生产及传播能力
以实现以往信息的再社会化。 远远超过了社会成员接受与处理信息的能力。数
(三) 网络场域的匿名性是信息过载的驱动力 字化生活的时空特性、虚拟性、自由性及开放性
数字化生存中的信息过载离不开网络匿名性 给信息过载提供了天然的环境，而这直接导致了
的推波助澜。匿名性是指数字化生存中社会成员 数字化生存中的信息过载现象，其主要表现为信
真实身份的不可知及非确定性。网络场域的匿名 息量的无上限及质的无下限、信息样态的碎片化
性犹如给数字化生存中的成员系上了 “安全带”， 与嵌入性、信息表象的狂欢化及无序化。
为其释放压力、 “为所欲为”提供了天然土壤， ( 一) 信息量的无上限与质的无下限
正所谓 “我的空间我做主”。 获取信息是社会成员在数字化生存中进行交
1. 从社会认识论的角度理解，信息过载是一 流互动并借此占据相关资源的一种方式。数字化
种人为构建的社会性产物，因为信息的生成、发 生存中的信息过载首先呈现为信息量的无上限。
布及传播是人为社会实践的结果。传统社会生活 从目前来看，数字化生存中的信息来源主要有官
场域之中，社会成员的信息发布总是受到社会关 方、市场及个体自媒体三大来源，我们的数字化
系、社会制度等社会结构性要素的制约。相反， 生活体验就在这些信息的交汇、碰撞中日复一日
网络场域为社会公众创造了丰富多彩的精神性、 地进行。
情感性的网络群组及网络社区。不同个体、群体 1. 在数字化虚拟实践中，只需输入相关的关
之间利用匿名性在这样的精神性社会空间扮演着 键词，我们就能够搜索到与我们想要信息相关的
日常生活世界难以或根本无法实现的社会角色， 内容，并且其形式及来源多种多样; 同时，各个
即便是熟人关系组成的网络场域，也能够通过场 分场域能够实时推送大量信息，往往一条信息还
域的技术特性。比如，匿名聊天这一功能实现匿 未看完，另一条相同版本的信息就会推送，造成
名性在场。社会个体在匿名性营造的氛围中满足 信息的涡轮式聚集。此外，以各种搞笑、戏谑等
精神之需的同时也促使信息的泛滥。 为主要形式存在的短视频可谓是非常繁多，这些
2. 网络塑造的匿名性很好地隐匿了个人的心 视频的时长大都在几十秒、一分钟，但其包含的
理顾虑。社会成员在匿名性的掩盖之下能够较为 信息量并非一定比长时段的视频所包含的信息量
自由发布与传播信息，包括不文明言论，甚至造 小。在数字化生活中，每天数百万记录和分享个
谣传谣，借助社会事件进行猜测性报道直接造成 体生活等短视频在网络场域中生产与传播，成为
大量重复信息、垃圾信息及虚假信息产生和蔓 一种视觉性的信息过载。
延。此外，在精细化的社会分工和高度流动性社 2. 与信息量的无上限相伴的则是信息质的无
会的影响之下，数字化生存中的每一个成员即是 下限。社会成员能够在碎片化的时间内获得急需
信息的生产者也是信息的消费者及传播者。在这 的信息是保证数字化生活质量的保证，而在大量
种事实之下，匿名性可以使私人空间与公共空间 信息中隐喻的是大量重复、无序乃至直接对个人
的的叠加与融合进而引起 “抱团”极化的心理表 与社会产生危害的信息。一方面，各种市场自媒
象。不同的网络群体或网络社区的成员往往对于 体为吸引流量、通过低俗原创演变成流量收割
自身所属场域的话语具有极强的认同性，不仅造 机，通过 “标题党”“夸大信息”等众多形式各
成了群体观点的极化，甚者固化为场域之中群体 样的方法吸引流量; 同时，为获得利益肆无忌惮 ·104· 昆明理工大学学报 (社会科学版) 第21卷
的炮制各种题材的虚假信息，宣扬庸俗、媚俗的 性。首先，信息从 “单一性嵌入”到 “系统性嵌
内容，使信息变得低俗愚昧，经过数字化成员的 入”。信息并非单一的信息本身，还是嵌入了众
传播愈加 “扑朔迷离”，使公众深陷 “劣迹信息 多信息的复合体。诸如视频信息、文字信息及网
洪流之中”。大量的淫秽色情信息泛滥。我们可 页信息中大都带有各种广告信息，如果点开某一
以深刻地体会到在数字化生活中充斥着大量带有 信息链接等，会发现信息之中还有另外一种类型
性暗示、性挑逗及性欲望等词汇的信息，部分涉 的信息。其次，信息从 “双向性嵌入”到 “多重
黄信息居然能够自动推荐到云盘、进而传递淫秽 性嵌入”。网络场域已经使信息的传播传出了传
图片和视频。此外，很多色情信息还隐匿于正常 统时空情景之下稳定的单向传播，实现了多方互
的信息之中，如果不小心点开相关信息，就会瞬 动式传播与互动。在信息传播过程中，信息往往
时间推送大量色情信息。另一方面，信息的同质 会不断被人 “夹带私货”，越传越离谱，直到偏
化及无序性。数字化生活中的很多信息都是同一 离了信息本身所要表达的主题。最后，从 “形式
个信息在不同自媒体中的不同表述。例如，官方 性嵌入”到 “实质性嵌入”，数字化生存虽然是
媒体报道的周某 “这辈子都不可能打工的” “里 在网络场域中进行的一种虚拟化的生活方式，但
面的人个个都是人才，说话又好听，超喜欢在里 衍生出的是人际过载及健康过载。个体在大量信
面”。随后被不同的自媒体制作成各种版本，但 息筛选的过程中造成情绪焦虑、烦躁及认知负
信息的内容并没有什么改变，仅仅是同一信息的 荷。可以说，信息过载不仅是一种真实存在于数
不同呈现; 同时，于数字生活而言，有效的信息 字化生活中的社会现象，其已经作为一种社会问
需要在感性领悟的基础上加以理性的思辨才能作 题深深地影响到人们的心理、精神的健康，是一
出客观的价值判断和评价。但是，在快速的数字 种实质性嵌入日常生活的社会事实。
化生活之中，人们很难理性地认识某种信息，对 ( 三) 信息的狂欢化与无序化
相关信息的转发及评论往往来自于自身的直觉思 网络场域为数字化生活提供了一个具有全民
维。正如勒庞所言: “聚众淹没了成员的理性和 性、仪式性与颠覆性的狂欢空间。哈伊尔·巴赫
自我意识，取而代之的是一种 ‘集体心智’，即 金认为狂欢的前提是两种世界与两种生活的划
所有个人的情感和观念都朝向同一个方向，他们 分。第一种是有着较为严格等级存在的秩序世
有意识的人格特性消失殆尽。”［8］ 界，人们的生活受到较为严重的束缚。第二种则
( 二) 信息的碎片化与嵌入性 是在民间广场进行的，能够打破官方的秩序世界
信息的碎片化与嵌入性主要表现为信息时间 的狂欢场所。在这种空间之中，人们的生活能够
的碎片性和信息内容的复合性。相比前现代社会 较为自由地开展。而网络场域则是一个打破官方
生活时间的整体性及系统性，数字化生活已经将 秩序人人都可参与没有等级的空间。如今，数字
我们生活分成了无数的碎片时间，这也直接造成 化生存中娱乐成为一种基本心理需求，屡露自我
了人们接受信息的碎片化。 的 “风采”也形成了一种社会共识。
1. 信息来源时间的碎片化。现今网页、微博 1. 网络场域的体验是一种宏观与微观相结合
及微信等大都在朝着精简方向发展。通过人工智 的超真实”与 “拟像”体验。尤其是在诸多
能技术在个体的碎片化时间快速的推送相关信 “分场域”之中，形成了一个一个超共享的方式，
息，尽可能在较短的时间内快速吸引个体的眼 现在微博、抖音甚至一些游戏，可以将未来的画
球。无论你是在上下班的路上，还是在排队吃 面以一种非常逼真地形式呈现在人们面前，同
饭、等车的时间，信息都恨不得榨干你最后一点 时，也能够将已过去的时间通过符码的形式逼真
时间。此外，基于短、精及快的理念，信息呈现 地呈现与展示，提供了 “超真实”的氛围与体
出小型化、简短化; 同时，很多信息往往是以偏 验，给社会成员提供了一种狂欢的情景。信息狂
概全、以点带面。 欢的行为方式是不断的制造、发布及转发各类信
2. 信息内容的嵌入性体现为信息的复合性属 息，信息过载的实质也就成了信息狂欢。 第1期 管其平: 数字化生存中的信息过载及其空间治理 ·105·
2. 数字化生存中的信息狂欢蕴含着反抗与颠 积极推动关乎互联网场域的基础性及专门性法律
覆的意味，是公众的一场集体性信息表演，更多 的制定，建立有利于网络空间良序运行的长效法
情况下不再以获取信息以及传达社会事实为导 律、法规机制。一方面，通过法律对网络信息发
向，而是如何借助信息进行表演和娱乐，并就此 布、传播进行严格的管理和监督，对市场自媒体
表达自身的社会意愿，具有狂欢节似的仪式。数 及大型互联网企业进行严格的管理，从源头上抑
字化生活中，社会个体试图通过点赞、转发及评 制大量冗余信息的产生，创造清朗有序的网络信
论信息占有自己的独立场域。这些数字化的单元 息环境。另一方面，在日常的数字化实践中我们
行动追求的是一种仪式化的快感宣泄，其最终的 每个人都能感受到某些信息已经影响到个人的心
意图则是抒发自身的不满以对抗现有的规则约 理健康甚至危及到个人的权益。但是，作为数字
束。而欲要实现信息狂欢则需要信息舆论的引导 化生存中的一员，又很少进行举报、揭发。这一
者，也即是数字化生活中的 “意见领袖”。其主 方面与现有缺乏网络举报渠道有关，另一方面也
要包含两方面含义: 一是在现实生活之中就具备 与社会成员法制意识淡薄有关。借此，应拓宽各
较强的影响力，诸如专家、明星; 二是在信息的 种垃圾信息、色情信息等不良信息的举报渠道，
传播过程中，由于某个个体或者某个组织的观点 发挥网民的监督作用，利用网络加强法制宣传，
极为符合公众的心理预期而形成的 “意见领袖”。 提升网民的网络维权意识。
“意见领袖”可以通过领袖贴让更多 “追随者” 2. 数字化生存是跨越时空的流动性体验，这
进行跟帖，也直接导致个体随着舆论的主流风 使建立在农业及工业基础上的道德体系已经无法
向，跟风跑化身 “键盘侠”，把志同道合、价值 有效适应高度流动性的数字化生存。因此，有效
观相近的人聚集在一起，情绪被放大，网络变成 应对信息过载需构建与数字化生存相适应的数字
了人们情绪的垃圾桶，造成大井喷式的信息表达 道德价值体系。以传统社会道德为基础，建立完
与信息传播，其直接结果则是信息的无序化。 整系统的调节和约束个体行为的道德准则以及行
为规范体系，充分发挥网络道德秩序的规范作
四、数字化生存中信息过载的空间治理
用，进而提高社会成员的道德水平、道德水准、
空间治理作为社会治理的一种方式，强调把 道德素养，以此减少乃至杜绝肆意乱发、转发虚
空间作为一种重要的治理工具与治理资源。数字 假信息、垃圾信息的行为。此外，还需要将法治
化生存的活动空间以网络场域维系的社会性空间 与德治充分融合。道德是法律发挥作用的力量基
为基础，其社会实践活动主要是围绕网络空间而 础，法律是保证道德规范的规范性力量，没有有
展开的。借此，应以网络空间为切入点，探索建 效的法制，德治难以发挥作用，没有法治德治也
立复合式治理模式来应对数字化生存中信息过载 很难发挥作用，通过网络途径形成法德合力，更
问题。 好维护网络场域数字化生存的社会秩序。
( 一) 完善网络法律道德体系、营造有序的 ( 二) 完善网络空间智能设施、建立智能信
数字生存秩序 息管理系统
信息不仅是社会交流与社会互动的基础，也 数字化生存场域自身的特点和规律，决定了
是社会制度与社会秩序存在的结构性因素，有效 网络场域信息过载治理与现实社会治理逻辑和模
的社会规范是信息合理有序存在的重要基础。如 式有很大不同。传统社会的治理逻辑和治理模式
前所述，数字生存与现实生存一样都是人类实践 是建立在一个较为稳定及确定性的社会情境之
的结果。因此，要有效应对数字化生存中的信息 中，但是，数字化生存的情境是一个充满不确定
过载问题，应规范作为数字化生存承载体的网络 性的网络场域。因此，信息过载的治理逻辑与治
场域。 理模式需要充分发挥智能技术的作用。虽然智能
1. 应充分发挥法律、道德对网络实践的制约 技术在网络场域中的深度融合会带来诸如隐私泄
与规范作用。政府作为信息过载治理的主体，要 露、数据鸿沟等问题，也给信息的生产及传播带 ·106· 昆明理工大学学报 (社会科学版) 第21卷
来了更大的不确定性，但是，我们不能否认智能 播程度与范围。数字化生存中的大量垃圾信息、
技术作为一种治理资源与治理工具在面对现代流 重复性信息大都与各类的非主流文化相关。
动性、不确定性生活中的重要性。依托人工智能 1. 作为社会发展的公权力部门，需要加强主
建立智能化的信息管理系统是一种较为有效的技 流文化意识形态的宣传与引导，用社会主义核心
术方式。 价值观引导网络思潮，传递网络正能量，充分利
1. 完善网络空间智能设施的建设，建立智能 用碎片化时间以网络讲坛、网络课堂等方式充实
化信息系统对信息实现精准分类与高效整合。网 网络场域，防止数字化生存的过分娱乐化。此
络场域中各种以新闻、八卦及社会事件等为主题 外，还可以采取微电影、短视频及随手拍等方式
的消息大都可以通过技术实现多渠道、多方式地 搭建网络文化平台，组织与网络文化有关的主题
收集，并对其进行高效的辨别、归类、精练，实 比赛、讲座、论坛，提高网络文化的吸引力和影
现信息的有效整合与有效聚合。目前，在日常的 响力，进而营造良好的网络生态环境及文化氛
数字化生存体验中，个人可以依据感兴趣与不感 围，建设共同精神家园。
兴趣进行选择，当选择对此类信息不感兴趣，那 2. 在开展网络文化建设的同时，建立适合数
么系统就不会再在你浏览这个网页的时候推送类 字化生存的价值体系，重塑数字化生存中的价值
似的信息。与之相反，当选择对此类信息不感性 话语及价值格局。传统文化价值观是建立在传统
的时候，系统会连续在你浏览这个网页的时候推 社会形态的基础之上，现实中应该遵循的价值观
送类似的信息，这背后隐喻着智能技术在精简及 由于数字化生存的虚拟性难以有效发挥作用。在
整合信息中的作用。 结合传统社会价值观的基础上立足于网络空间，
2. 智能化信息系统可以通过算法推荐推算个 使网络空间中存在的一些价值观也能在现实中得
体的信息爱好。我们在使用手机进行软件下载时 以运行; 同时，在信息与噪音同时超负荷的当
通常都会提示我们是否接受消息的提醒; 同时， 下，人们被情绪所推动从而片面地做出自己的选
个体可以在下载相关软件的时候会自动给弹出相 择。通过这种文化价值体系使自愿地加以遵守、
关提示。诸如某浏览器在下载安装之后，会自动 文明互动，理性表达不篡改标题、自采自编、关
弹出相关政治、经济、社会、娱乐、文化及八卦 联炒作、转载发布不明来源信息等，整合为现代
等为主体的关键词，社会成员可以有选择地点击 意义上的文化共同体，保持批判性思维，多做一
其中的关键词，以此来决定使用中会呈现哪些信 步思考，凝聚社会共识，使社会公众适应数字化
息。但这样的技术还未能够大面积地应用，也没 生存，提升数字化生存能力。
有形成较为系统的智能系统，应以此为基础在更 ( 四) 充分整合网络社会资源，推动多元治
广的范围内进行运用。 理主体合作共治
3. 智能信息系统可以对信息进行智能过滤， 数字化生存中的信息过载是多种因素共同塑
对信息内容进行较为全方的甄别。一方面，通过 造的结果，单纯依靠政府等公权力的力量难以有
建立分类信息的关键词数据敏感库可以有效过滤 效应对这种复杂因素形成的社会问题。因此，在
相关信息，如网络色情信息关键词、网络暴力信 数字化生存之中要充分整合国际力量资源构建以
息关键词等信息库; 另一方面，通过智能信息系 政府、社会组织为主体的网络协同基本导向的治
统可以建立覆盖新闻、论坛、博客、微博、微 理机制。
信、视频等信息对冲过滤机制，在复杂的信息之 1. 充分发挥网络社会组织的积极作用。社会
中实现社会信息的有效对接，让智能系统做好网 组织作为连接国家与社会承接政府服务的机构，
络信息的 “把关人”。 是应对信息过载的一个必要方式。网络社会组织
( 三) 完善网络空间文化建设，提高网络受 的成员来源较广泛，专业性强，其可以结合不同
众媒介素养 群体特点和优势，开展不同的实践活动。比如，
社会成员媒介素养的高低直接关系信息的传 建立网络专业人士咨询团队，常态化的开展社会 第1期 管其平: 数字化生存中的信息过载及其空间治理 ·107·
公益活动，在网络场域中营造一种理性的氛围。 确定性的风险相伴而生。信息过载也并非简单的
总之，应对信息过载要积极整合专业性网络组 社会现象，还是一个重要的社会问题。随着互联
织，为网络组织的发展提供充分的空间，支持网 网、大数据及云计算等新技术的兴起，将会进一
络社会组织发挥传播优势和作用。 步深化数字化生存的内涵及特征，刷新我们对数
2. 通过完善官方自媒体、市场自媒体以及民 字化生存的认知与理解。在未来，人类与数字的
间自媒体之间合作，加强网络新媒体阵地建设。 交织更加密切，如何对依托网络场域而存在的一
人民网、光明网等官方主流媒体应是人们数字化 系列社会问题进行有效治理，是未来需要深入研
生存获取信息的主要渠道。但是，在日常的数字 究的议题。这也是未来人们适应数字化生活并提
化生活体验中却并没有占据一个重要的地位，这 高数字化生存能力的重要基础。
种情况导致社会个体在面对相关重大事件时候不
知如何获取权威信息，没有权威信息就容易造成
参考文献:
虚假信息大肆泛滥，加之人们对重大事件的关注
［1］中国互联网络信息中心 (CNNIC) . 第45次《中国互
造成信息瞬时间过载。此外，企业也是社会治理
联网络发展状况统计报告》 ［EB/OL］. (2020－04－
多元化参与的主体。企业作为数字化生存的参与
27) ［2020－07－04］.http: //www.cac.gov.cn/2020－
建设者，要创新自律方式，重视自身的社会责
04/27/c_ 1589535470378587.html.
任。通过行业自律组织制定完善的行业自律公
［2］严耕，陆俊. 网络伦理 ［M］. 北京: 北京出版社，
约，规范自身行为，把信息过载作为要企业发展
1998: 15.
的一个工作予以关注，杜绝流量造假、操纵账号 ［3］皮埃尔·布尔迪厄. 实践与反思 ［M］. 李猛，李
等行为，完善数字化基础设施辅助政府在信息治 康，译. 北京: 中央编译出版社，1998: 134.
理、管控等方面存在薄弱板块。 ［4］麦永雄. 赛博空间与文艺理论研究的新视野 ［J］.
3. 信息过载还需要全球性合作。网络早已使 文艺研究，2006 (6): 29－30.
［5］马克思，恩格斯 . 马克思恩格斯选集: 第 2 卷
地球成为一个共同体，时空压缩背景之下没有国
［M］.北京: 人民出版社，1995: 101.
家能够独善其身。数字化生存体验中，我们可以
［6］尼古拉·尼葛洛庞蒂. 数字化生存 ［M］. 胡泳，
很方便地使用国外的网站、国外开发的 App 应用
范海燕，译. 北京: 电子工业出版社，2017: 160.
程序，在这些场域之中存在着大量的信息，且国
［7］ T.HAGEＲSTAND.Space，time and human conditions
外与国内之间的网络场域也相互连通，但由于服
［J］.DonParkes and Nigel Thrift.Times. Spaces and
务器的设置，无法对一些信息行为进行监管与处
Places，1975 (1): 247－248.
理。因此，在地球村背景之下，要积极整合国际 ［8］凯斯·桑斯坦. 网络共和国: 网络社会中的民主问
资源与国际力量因对信息过载。 题 ［M］. 黄维明，译 . 上海: 上海人民出版社，
2003: 51.
五、结语
通过分析可以看出，社会发展总是与各种不 --------------------------------------------------------------------------------- 第４２卷 第３期 计 算 机 学 报 Ｖｏｌ．４２ Ｎｏ．３
２０１９年３月 ＣＨＩＮＥＳＥ ＪＯＵＲＮＡＬ ＯＦ ＣＯＭＰＵＴＥＲＳ Ｍａｒ．２０１９
深度卷积神经网络的发展及其在
计算机视觉领域的应用
张 顺１） 龚怡宏２） 王进军２）
１）（西北工业大学电子与信息学院 西安 ７１００７２）
２）（西安交通大学人工智能与机器人研究所 西安 ７１００４９）
摘 要 作为类脑计算领域的一个重要研究成果，深度卷积神经网络已经广泛应用到计算机视觉、自然语言处理、
信息检索、语音识别、语义理解等多个领域，在工业界和学术界掀起了神经网络研究的浪潮，促进了人工智能的发
展．卷积神经网络直接以原始数据作为输入，从大量训练数据中自动学习特征的表示．卷积神经网络具有局部连
接、权值共享和池化操作等特性，可以有效降低网络复杂度，减少训练参数的数目，使模型对平移、扭曲、缩放具有
一定程度的不变性．目前，深度卷积神经网络主要是通过增加网络的层数，使用更大规模的训练数据集，以及改进
现有神经网络的网络结构或训练学习算法等方法，来模拟人脑复杂的层次化认知规律，拉近与人脑视觉系统的差
距，使机器获得“抽象概念”的能力．深度卷积神经网络在图像分类、目标检测、人脸识别、行人再识别等多个计算机视
觉任务中都取得了巨大成功．该文首先回顾了卷积神经网络的发展历史，简单介绍了Ｍ－Ｐ神经元模型、Ｈｕｂｅｌ－Ｗｉｅｓｅｌ
模型、神经认知机、用于手写识别的ＬｅＮｅｔ以及用于ＩｍａｇｅＮｅｔ图像分类比赛的深度卷积神经网络．然后详细分析
了深度卷积神经网络的工作原理，介绍了卷积层、采样层、全连接层的数学表示及各自发挥的作用．接着该文重点
从以下三个方面介绍卷积神经网络的代表性成果，并通过实例展示各种技术方法对图像分类精度的提升效果．从
增加网络层数方面，讨论并分析了ＡｌｅｘＮｅｔ、ＺＦ－Ｎｅｔ、ＶＧＧ、ＧｏｏｇＬｅＮｅｔ和ＲｅｓＮｅｔ等经典卷积神经网络的结构；从
增加数据集规模方面，介绍了人工增加标注样本的难点以及使用数据扩增技术对神经网络性能提升的作用；从改
进训练方法方面，介绍了包括Ｌ２正则化、Ｄｒｏｐｏｕｔ、ＤｒｏｐＣｏｎｎｅｃｔ、Ｍａｘｏｕｔ等常用的正则化技术，Ｓｉｇｍｏｉｄ函数、ｔａｎｈ
函数以及ＲｅＬＵ函数、ＬＲｅＬＵ函数、ＰＲｅＬＵ函数等常用的神经元激活函数，ｓｏｆｔｍａｘ损失、ｈｉｎｇｅ损失、ｃｏｎｔｒａｓｔｉｖｅ
损失、ｔｒｉｐｌｅｔ损失等不同损失函数，以及ｂａｔｃｈ ｎｏｒｍａｌｉｚａｔｉｏｎ技术的基本思想．针对计算机视觉领域，该文重点介绍
了卷积神经网络在图像分类、目标检测、人脸识别、行人再识别、图像语义分割、图片标题生成、图像超分辨率、人体
动作识别以及图像检索等方面的最新研究进展．从人类视觉认知机制出发，分析了视觉信息分层处理和“大范围优
先”视觉认知过程的相关理论成果和对当前计算模型的一些理论启示．最后提出了未来基于深度卷积神经网络的
类脑智能研究待解决的问题与挑战．
关键词 类脑智能；神经网络；深度学习；计算机视觉；视觉认知
中图法分类号 ＴＰ１８ ＤＯＩ号 １０．１１８９７／ＳＰ．Ｊ．１０１６．２０１９．００４５３
Ｔｈｅ Ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ Ｄｅｅｐ Ｃｏｎｖｏｌｕｔｉｏｎ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ ａｎｄ
Ｉｔｓ Ａｐｐｌｉｃａｔｉｏｎｓ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ
ＺＨＡＮＧ Ｓｈｕｎ１） ＧＯＮＧ Ｙｉ－Ｈｏｎｇ２） ＷＡＮＧ Ｊｉｎ－Ｊｕｎ２）
１）（Ｓｃｈｏｏｌ ｏｆ Ｅｌｅｃｔｒｏｎｉｃｓ ａｎｄ Ｉｎｆｏｒｍａｔｉｏｎ，Ｎｏｒｔｈｗｅｓｔｅｒｎ Ｐｏｌｙｔｅｃｈｎｉｃａｌ Ｕｎｉｖｅｒｓｉｔｙ，Ｘｉ’ａｎ ７１００７２）
２）（Ｉｎｓｔｉｔｕｔｅ ｏｆ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ ａｎｄ Ｒｏｂｏｔｉｃｓ，Ｘｉ’ａｎ Ｊｉａｏｔｏｎｇ Ｕｎｉｖｅｒｓｉｔｙ，Ｘｉ’ａｎ ７１００４９）
Ａｂｓｔｒａｃｔ Ａｓ ｔｈｅ ｉｍｐｏｒｔａｎｔ ｒｅｓｅａｒｃｈ ａｃｈｉｅｖｅｍｅｎｔ，ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｈａｖｅ ｂｅｅｎ
ｗｉｄｅｌｙ ａｐｐｌｉｅｄ ｔｏ ｖａｒｉｏｕｓ ｆｉｅｌｄｓ ｓｕｃｈ ａｓ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ，ｎａｔｕｒａｌ ｌａｎｇｕａｇｅ ｐｒｏｃｅｓｓｉｎｇ，ｉｎｆｏｒｍａｔｉｏｎ
ｒｅｔｒｉｅｖａｌ，ｓｐｅｅｃｈ ｒｅｃｏｇｎｉｔｉｏｎ，ｓｅｍａｎｔｉｃ ｕｎｄｅｒｓｔａｎｄｉｎｇ，ａｎｄ ｈａｖｅ ａｔｔｒａｃｔｅｄ ａ ｗａｖｅ ｏｆ ｎｅｕｒａｌ
收稿日期：２０１６－０６－２２；在线出版日期：２０１７－０９－１８．本课题得到国家“九七三”重点基础研究发展规划项目基金（２０１５ＣＢ３５１７０５）、国家自然
科学基金重点项目（６１３３２０１８）、国家自然科学基金青年科学基金项目（６１７０３３４４）、中央高校基本科研业务费专项资金（３１０２０１７ＯＱＤ０２１）资
助．张 顺，男，１９８７年生，博士，助理教授，主要研究方向为计算机视觉和机器学习．Ｅ－ｍａｉｌ：ｓｚｈａｎｇ＠ｎｗｐｕ．ｅｄｕ．ｃｎ．龚怡宏，男，１９６３年
生，博士，教授，博士生导师，“国家千人计划”专家，主要研究领域为多媒体内容分析、机器学习和模式识别．王进军，男，１９７７年生，博士，
教授，博士生导师，中国计算机学会（ＣＣＦ）会员，主要研究领域为模式识别、机器学习和多媒体计算．
书书书 ４５４ 计 算 机 学 报 ２０１９年
ｎｅｔｗｏｒｋｓ ｒｅｓｅａｒｃｈ ｆｒｏｍ ｂｏｔｈ ａｃａｄｅｍｉａ ａｎｄ ｉｎｄｕｓｔｒｙ ａｎｄ ｈａｖｅ ｃｏｎｔｒｉｂｕｔｅｄ ｔｏ ｔｈｅ ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ
ａｒｔｉｆｉｃｉａｌ ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｔｈｅ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｄｉｒｅｃｔｌｙ ｔｒｅａｔ ｔｈｅ ｏｒｉｇｉｎａｌ ｄａｔａ ａｓ ｉｎｐｕｔ，
ａｕｔｏｍａｔｉｃａｌｌｙ ｌｅａｒｎ ｔｈｅ ｆｅａｔｕｒｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｆｒｏｍ ａ ｌａｒｇｅ ｎｕｍｂｅｒ ｏｆ ｔｒａｉｎｉｎｇ ｄａｔａ．Ｔｈｅ
ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｈａｖｅ ｔｈｅ ｃｈａｒａｃｔｅｒｉｓｔｉｃｓ ｏｆ ｌｏｃａｌ ｃｏｎｎｅｃｔｉｏｎ，ｗｅｉｇｈｔ ｓｈａｒｉｎｇ ａｎｄ
ｐｏｏｌｉｎｇ ｏｐｅｒａｔｉｏｎ，ｗｈｉｃｈ ｃａｎ ｅｆｆｅｃｔｉｖｅｌｙ ｄｅｃｒｅａｓｅ ｔｈｅ ｎｅｔｗｏｒｋ ｃｏｍｐｌｅｘｉｔｙ ａｎｄ ｒｅｄｕｃｅ ｔｈｅ ｎｕｍｂｅｒ
ｏｆ ｔｒａｉｎｉｎｇ ｐａｒａｍｅｔｅｒｓ，ｓｏ ｔｈａｔ ｔｈｅ ｍｏｄｅｌ ｈａｓ ｓｏｍｅ ｃｅｒｔａｉｎ ｉｎｖａｒｉａｎｃｅ ｔｏ ｔｒａｎｓｌａｔｉｏｎ，ｄｉｓｔｏｒｔｉｏｎ
ａｎｄ ｓｃａｌｅ．Ｃｕｒｒｅｎｔｌｙ，ｍａｎｙ ａｐｐｒｏａｃｈｅｓ ｏｆ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ，ｉｎｃｌｕｄｉｎｇ ｔｈｅ ｉｎｃｒｅａｓｅ ｏｆ ｓｉｚｅ
ａｎｄ ｃｏｍｐｌｅｘｉｔｙ ｏｆ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ，ｔｈｅ ｕｓｅ ｏｆ ｌａｒｇｅｒ ｓｅｔｓ ｏｆ ｔｒａｉｎｉｎｇ ｄａｔａ，ｔｈｅ ｉｍｐｒｏｖｅｍｅｎｔ ｏｆ
ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｒｃｈｉｔｅｃｔｕｒｅ ａｎｄ ｔｒａｉｎｉｎｇ ｍｅｔｈｏｄｓ，ｅｔｃ．，ｈａｖｅ ｂｅｅｎ ｐｒｏｐｏｓｅｄ ｔｏ ｓｉｍｕｌａｔｅ ｔｈｅ
ｃｏｍｐｌｅｘ ｈｉｅｒａｒｃｈｉｃａｌ ｃｏｇｎｉｔｉｖｅ ａｔｔｒｉｂｕｔｅｓ ｏｆ ｈｕｍａｎ ｂｒａｉｎ ａｎｄ ｐｕｌｌ ｃｌｏｓｅ ｔｈｅ ｇａｐ ｂｅｔｗｅｅｎ ｔｈｅ
ｈｕｍａｎ ｂｒａｉｎ ａｎｄ ｖｉｓｕａｌ ｓｙｓｔｅｍ，ｓｏ ｔｈａｔ ｔｈｅ ｍａｃｈｉｎｅ ｈａｓ ｔｈｅ ｃａｐａｂｉｌｉｔｙ ｔｏ ｃａｐｔｕｒｅ“ａｂｓｔｒａｃｔｉｏｎ
ｃｏｎｃｅｐｔｓ”．Ｔｈｅ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｈａｖｅ ｂｅｅｎ ａ ｇｒｅａｔ ｓｕｃｃｅｓｓ ｉｎ ｍａｎｙ ｃｏｍｐｕｔｅｒ
ｖｉｓｉｏｎ ｔａｓｋｓ，ｓｕｃｈ ａｓ ｉｍａｇｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ，ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ，ｆａｃｅ ｒｅｃｏｇｎｉｔｉｏｎ，ａｎｄ ｐｅｒｓｏｎ ｒｅ－ｉｄｅｎｔｉｆｉｃａｔｉｏｎ．
Ｉｎ ｔｈｉｓ ｐａｐｅｒ，ｗｅ ｆｉｒｓｔ ｒｅｖｉｅｗ ｔｈｅ ｈｉｓｔｏｒｙ ｏｆ ｔｈｅ ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ，
ａｎｄ ｂｒｉｅｆｌｙ ｉｎｔｒｏｄｕｃｅ Ｍ－Ｐ ｎｅｕｒｏｎ ｍｏｄｅｌ，Ｈｕｂｅｌ－Ｗｉｅｓｅｌ ｍｏｄｅｌ，Ｎｅｏｃｏｇｎｉｔｒｏｎ，ＬｅＮｅｔ ｆｏｒ
ｈａｎｄｗｒｉｔｉｎｇ ｒｅｃｏｇｎｉｔｉｏｎ，ａｎｄ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｆｏｒ ｉｍａｇｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｉｎ ｔｈｅ
ＩｍａｇｅＮｅｔ ｃｏｍｐｅｔｉｔｉｏｎ．Ｔｈｅｎ ｗｅ ｈａｖｅ ａ ｄｅｔａｉｌｅｄ ａｎａｌｙｓｉｓ ｏｆ ｔｈｅ ｆｕｎｄａｍｅｎｔａｌ ｐｒｉｎｃｉｐｌｅ ｏｆ ｄｅｅｐ
ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ，ａｎｄ ｉｎｔｒｏｄｕｃｅ ｔｈｅ ｍａｔｈｅｍａｔｉｃａｌ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ａｎｄ ｔｈｅ ｒｅｓｐｅｃｔｉｖｅ
ｆｕｎｃｔｉｏｎｓ ｏｆ ｔｈｅ ｃｏｎｖｏｌｕｔｉｏｎ ｌａｙｅｒ，ｔｈｅ ｐｏｏｌｉｎｇ ｌａｙｅｒ ａｎｄ ｔｈｅ ｆｕｌｌｙ ｃｏｎｎｅｃｔｅｄ ｌａｙｅｒ．Ｂｅｓｉｄｅｓ，ｔｈｉｓ
ｐａｐｅｒ ｆｏｃｕｓｅｓ ｏｎ ｔｈｅ ｒｅｐｒｅｓｅｎｔａｔｉｖｅ ｗｏｒｋｓ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｏｎ ｔｈｅ ｆｏｌｌｏｗｉｎｇ ｔｈｒｅｅ
ａｓｐｅｃｔｓ，ａｎｄ ｄｅｍｏｎｓｔｒａｔｅｓ ｖａｒｉｏｕｓ ｔｅｃｈｎｉｃａｌ ｍｅｔｈｏｄｓ ｉｎ ｉｍｐｒｏｖｉｎｇ ｔｈｅ ａｃｃｕｒａｃｙ ｏｆ ｉｍａｇｅ
ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｕｓｉｎｇ ｅｘａｍｐｌｅｓ．Ｉｎ ｔｈｅ ａｓｐｅｃｔ ｏｆ ｉｎｃｒｅａｓｉｎｇ ｔｈｅ ｎｕｍｂｅｒ ｏｆ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ’ｌａｙｅｒｓ，
ｔｈｅ ａｒｃｈｉｔｅｃｔｕｒｅｓ ｏｆ ｃｌａｓｓｉｃａｌ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｓｕｃｈ ａｓ ＡｌｅｘＮｅｔ，ＺＦ－Ｎｅｔ，ＶＧＧ，
ＧｏｏｇＬｅＮｅｔ ａｎｄ ＲｅｓＮｅｔ ａｒｅ ｄｉｓｃｕｓｓｅｄ ａｎｄ ａｎａｌｙｚｅｄ．Ｉｎ ｔｈｅ ａｓｐｅｃｔ ｏｆ ｉｎｃｒｅａｓｉｎｇ ｔｈｅ ａｍｏｕｎｔ ｏｆ
ｄａｔａ，ｗｅ ｉｎｔｒｏｄｕｃｅ ｔｈｅ ｄｉｆｆｉｃｕｌｔｉｅｓ ｏｆ ｉｎｃｒｅａｓｉｎｇ ｔｈｅ ｎｕｍｂｅｒ ｏｆ ａｎｎｏｔａｔｅｄ ｓａｍｐｌｅｓ ｂｙ ｍａｎｕａｌ ｗａｙ，
ａｎｄ ｔｈｅ ｅｆｆｅｃｔ ｉｎ ｉｍｐｒｏｖｉｎｇ ｔｈｅ ｐｅｒｆｏｒｍａｎｃｅ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｂｙ ｄａｔａ ａｕｇｍｅｎｔａｔｉｏｎ．
Ｉｎ ｔｈｅ ａｓｐｅｃｔ ｏｆ ｉｍｐｒｏｖｉｎｇ ｔｒａｉｎｉｎｇ ｍｅｔｈｏｄｓ，ｗｅ ｉｎｔｒｏｄｕｃｅ ｔｈｅ ｇｅｎｅｒａｌｉｚｅｄ ｒｅｇｕｌａｒｉｚａｔｉｏｎ
ｔｅｃｈｎｉｑｕｅｓ ｓｕｃｈ ａｓ ｔｈｅ Ｌ２ｒｅｇｕｌａｒｉｚａｔｉｏｎ，Ｄｒｏｐｏｕｔ，ＤｒｏｐＣｏｎｎｅｃｔ ａｎｄ Ｍａｘｏｕｔ，ｓｅｖｅｒａｌ ｆｒｅｑｕｅｎｔｌｙ－ｕｓｅｄ
ｎｅｕｒｏｎ ａｃｔｉｖａｔｉｏｎ ｆｕｎｃｔｉｏｎｓ ｓｕｃｈ ａｓ ｔｈｅ ｓｉｇｍｏｉｄ ｆｕｎｃｔｉｏｎ，ｔｈｅ ｔａｎｈ ｆｕｎｃｔｉｏｎ，ｔｈｅ ＲｅＬＵ ｆｕｎｃｔｉｏｎ，
ｔｈｅ ＬＲｅＬＵ ｆｕｎｃｔｉｏｎ，ａｎｄ ｔｈｅ ＰＲｅＬＵ ｆｕｎｃｔｉｏｎ，ｓｅｖｅｒａｌ ｄｉｆｆｅｒｅｎｔ ｌｏｓｓ ｆｕｎｃｔｉｏｎｓ ｓｕｃｈ ａｓ ｔｈｅ ｓｏｆｔｍａｘ
ｌｏｓｓ，ｔｈｅ ｈｉｎｇｅ ｌｏｓｓ，ｔｈｅ ｃｏｎｔｒａｓｔｉｖｅ ｌｏｓｓ ａｎｄ ｔｈｅ ｔｒｉｐｌｅｔ ｌｏｓｓ，ａｎｄ ｔｈｅ ｂａｓｉｃ ｉｄｅａ ｏｆ ｔｈｅ ｂａｔｃｈ
ｎｏｒｍａｌｉｚａｔｉｏｎ ｔｅｃｈｎｉｑｕｅ．Ｉｎ ｔｈｅ ｆｉｅｌｄ ｏｆ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ，ｔｈｉｓ ｐａｐｅｒ ｆｏｃｕｓｅｓ ｏｎ ｔｈｅ ｍｏｒｅ ｒｅｃｅｎｔ
ｒｅｓｅａｒｃｈ ｐｒｏｇｒｅｓｓ ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｉｎ ｉｍａｇｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ，ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ，ｆａｃｅ
ｒｅｃｏｇｎｉｔｉｏｎ，ｐｅｄｅｓｔｒｉａｎ ｒｅｃｏｇｎｉｔｉｏｎ，ｉｍａｇｅ ｓｅｍａｎｔｉｃ ｓｅｇｍｅｎｔａｔｉｏｎ，ｉｍａｇｅ ｃａｐｔｉｏｎｉｎｇ，ｉｍａｇｅ ｓｕｐｅｒ
ｒｅｓｏｌｕｔｉｏｎ，ｈｕｍａｎ ａｃｔｉｏｎ ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｉｍａｇｅ ｒｅｔｒｉｅｖａｌ．Ｆｒｏｍ ｔｈｅ ｐｒｏｓｐｅｃｔｉｖｅ ｏｆ ｔｈｅ ｈｕｍａｎ
ｖｉｓｕａｌ ｃｏｇｎｉｔｉｖｅ ｍｅｃｈａｎｉｓｍ，ｗｅ ａｎａｌｙｚｅ ｔｈｅ ｒｅｌｅｖａｎｔ ｔｈｅｏｒｅｔｉｃａｌ ａｃｈｉｅｖｅｍｅｎｔｓ ｏｆ ｈｉｅｒａｒｃｈｉｃａｌ
ｐｒｏｃｅｓｓｉｎｇ ｉｎ ｔｈｅ ｖｉｓｕａｌ ｓｙｓｔｅｍ ａｎｄ“ｇｌｏｂａｌ ｆｉｒｓｔ”ｖｉｓｕａｌ ａｎｄ ｃｏｇｎｉｔｉｖｅ ｐｒｏｃｅｓｓ，ａｎｄ ｓｏｍｅ ｔｈｅｏｒｅｔｉｃａｌ
ｉｍｐｌｉｃａｔｉｏｎｓ ｆｏｒ ｔｈｅ ｃｕｒｒｅｎｔ ｃｏｍｐｕｔａｔｉｏｎａｌ ｍｏｄｅｌｓ．Ｆｉｎａｌｌｙ，ｓｏｍｅ ｒｅｍａｉｎｅｄ ｐｒｏｂｌｅｍｓ ａｎｄ ｃｈａｌｌｅｎｇｅｓ
ｏｆ ｔｈｅ ｂｒａｉｎ－ｌｉｋｅ ｉｎｔｅｌｌｉｇｅｎｃｅ ｒｅｓｅａｒｃｈ ｂａｓｅｄ ｏｎ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ａｒｅ ｃｏｎｃｌｕｄｅｄ．
Ｋｅｙｗｏｒｄｓ ｂｒａｉｎ－ｌｉｋｅ ｉｎｔｅｌｌｉｇｅｎｃｅ；ｎｅｕｒａｌ ｎｅｔｗｏｒｋ；ｄｅｅｐ ｌｅａｒｎｉｎｇ；ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ；ｖｉｓｕａｌ ｃｏｇｎｉｔｉｏｎ
认知，是科学家们长期探索与追求的一大科学梦想．
１ 引 言 几十年来，脑神经科学和心理学等领域在人脑结构
及认知机理等方面的许多研究成果都被转化为人工
让机器以类似人脑的方式进行快速学习与准确 智能领域的计算模型，极大地促进了后者的发展与 ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４５５
进步．人工神经网络正是在这种背景下被提出的．它 １９８４年日本学者Ｆｕｋｕｓｈｉｍａ在Ｈｕｂｅｌ和Ｗｉｅｓｅｌ
是利用计算模型模拟大脑神经系统的结构和功能， 的感受野概念基础上，提出了神经认知机（Ｎｅｏｃｏｇ－
运用大量的简单运算单元，由人工方式建立起来的 ｎｉｔｒｏｎ）［２－３］模型．神经认知机模型由多种类型的细胞
神经网络系统．人工神经网络的诞生及发展是类脑 单元组成，其中最重要的两个细胞单元称为Ｓ细胞和
计算领域的一个最为重要的研究成果． Ｃ细胞．Ｓ细胞的功能是提取局部特征（如边缘或角
从２０世纪４０年代最早提出的 Ｍ－Ｐ神经元模 等），类似Ｈｕｂｅｌ－Ｗｉｅｓｅｌ模型的简单细胞．Ｃ细胞对
型和Ｈｅｂｂ学习规则开始，人工神经网络领域已提 应Ｈｕｂｅｌ－Ｗｉｅｓｅｌ模型的复杂细胞，对Ｓ细胞的输入
出了上百种神经网络模型，其中具有代表性的网络 进行一些处理，如图像较小的位移或轻微变形等．
包括感知机、反传网络、自组织映射网络、Ｈｏｐｆｉｅｌｄ 神经认知机可以看作是卷积神经网络的雏形，
网络、玻尔兹曼机、适应谐振理论等，并在诸如手写 而卷积神经网络是神经认知机的推广形式．卷积
体识别、语音识别、图像识别和自然语音处理等技术 神经网络是一个卷积层（Ｃｏｎｖｏｌｕｔｉｏｎ Ｌａｙｅｒ）与降采
领域取得了成功的应用． 样层（Ｓａｍｐｌｉｎｇ Ｌａｙｅｒ）交替出现的多层神经网络，每
当前，卷积神经网络（Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｎｅｕｒａｌ Ｎｅｔ－ 层由多个二维特征平面组成（称为特征图，Ｆｅａｔｕｒｅ
ｗｏｒｋｓ，ＣＮＮ）是得到广泛应用的一种人工神经网络， Ｍａｐ）．构成卷积层ｘ的每个神经元负责对输入图像
也是首个真正被成功训练的深层神经网络．Ｈｕｂｅｌ （假定ｘ＝１）或者（ｘ－１）降采样层的某个特征图的
和 Ｗｉｅｓｅｌ在１９６２年通过对猫的视觉皮层细胞进行 特定区域施行卷积运算，而降采样层ｙ的每个神经
深入研究，提出了高级动物视觉系统的认知机理模 元则负责对（ｙ－１）卷积层的某个特征图的特定区
型［１］．该模型提出高级动物视觉神经网络由简单细 域进行最大池化（只保留该区域神经元的最大输出
胞和复杂细胞构成（如图１所示）．神经网络底层的 值）操作．卷积层与降采样层的神经元分别用来模拟
简单细胞的感受野只对应视网膜的某个特定区域， Ｈｕｂｅｌ－Ｗｉｅｓｅｌ模型中的简单细胞和复杂细胞，而卷
并只对该区域中特定方向的边界线产生反应．复杂 积层中同一个特征图的神经元都是共享一个卷积
细胞通过对特定取向性的简单细胞进行聚类，拥有 核，负责提取同一种图像特征，对应某种特定取向的
较大感受野，并获得具有一定不变性的特征．上层简 简单细胞．
单细胞对共生概率较高的复杂细胞进行聚类，产生 ２０世纪９０年代初期，纽约大学的ＬｅＣｕｎ等人
更为复杂的边界特征．通过简单细胞和复杂细胞的 提出了多层卷积神经网络并成功应用于手写数字识
逐层交替出现，视觉神经网络获得了提取高度抽象 别中，所提出的ＬｅＮｅｔ［４－５］系列都达到商用水平，被
性及不变性图像特征的能力． 当时美国邮政局和许多大银行用来识别信封上的手
写邮政编码及支票上面的手写数字．卷积神经网络
起初只能训练不太深的网络，虽然在小规模问题上
能取得较好的效果，然而随着网络深度和宽度的增
加，在大规模图像数据集上卷积神经网络的识别效
果不佳，因此在被提出后的很长一段时间里并未被
重视．此后二十年中，许多研究人员对深度神经网络
提出了深层结构的优化和训练学习方法的改进，深
度卷积神经网络（Ｄｅｅｐ ＣＮＮ）的性能得到了大幅提
升．２０１２年，Ｈｉｎｔｏｎ团队在ＩｍａｇｅＮｅｔ图像分类比
赛中获得压倒性胜利，将１０００类图像的Ｔｏｐ－５分类
错误率从２６．１７２％降低到１５．３１５％［６］．在这一年，
Ｄｅｅｐ ＣＮＮ还被用于解决Ｄｒｕｇ Ａｃｔｉｖｉｔｙ预测问题，
并获得当时最好成绩．至此，神经网络的研究进入了
一个崭新的时代，开启了神经网络研究的热潮．
与其它神经网络相比，卷积神经网络这种基于
高级动物视觉通路的网络结构极大减少了神经元间
图１ 人脑视觉通道神经网络 的连接和权重数量，这不但减轻了神经网络的过拟 ４５６ 计 算 机 学 报 ２０１９年
合问题，而且也降低了训练多隐层网络的难度．即使 用；第４节分析人类视觉认知机制的特点和带给当
是训练一个深度达一、二十层的网络，使用误差反向 前计算模型的一些理论启示；最后对未来的研究方
传播（Ｂａｃｋ Ｐｒｏｐａｇａｔｉｏｎ，ＢＰ）［７－８］算法也能达到收 向做出展望．
敛［９－１１］，这是其它神经网络所望尘莫及的．
当前，Ｄｅｅｐ ＣＮＮ相对传统机器学习算法的优 ２ 卷积神经网络及其相关技术
势不断扩大，传统学习方法在多个领域无法与深
度学习抗衡，比如手写体识别、图像分类、图像语 卷积神经网络是由用于特征提取的卷积层和用
义理解、语音识别和自然语言理解等技术领域．神 于特征处理的亚采样层交叠组成的多层神经网络．
经网络能够重新焕发青春的原因有几个方面．首 典型的卷积神经网络结构［１２］如图２所示，网络输入
先，丰富的网络图像和大规模有标注的数据集在 是一个手写数字图像，输出是其识别结果，输入图像
很大程度上缓解了训练过拟合的问题，如ＩｍａｇｅＮｅｔ 经过若干个“卷积”和“采样”加工后，在全连接层网
数据集包含了２１ ８４１个图像类别，共计１４ １９７ １２２幅 络实现与输出目标之间的映射．通常卷积神经网络
图片．其次，计算机硬件的飞速发展提供了强大的计 中，每一层神经元节点只与其邻近上下层局部感受
算能力，使得训练大规模神经网络成为可能．单个 野内的神经元节点连接 ．这种局部连接观点与
ＧＰＵ（Ｇｒａｐｈｉｃｓ Ｐｒｏｃｅｓｓｉｎｇ Ｕｎｉｔ，图形处理器）芯片可 Ｈｕｂｅｌ、Ｗｉｅｓｅｌ从猫科动物的视觉系统中发现的
以集成上千个运算核心，对以高阶矩阵运算为主的神 局部感知观点相一致．图２中的输入图像的大小为
经网络提供高并行计算．此外，神经网络的模型设计 ３２×３２像素，含Ｒ、Ｇ、Ｂ三个通道．卷积层Ｃ１使用
和训练方法都取得了长足的进步．例如，为了改进神 大小为５×５的多个卷积核对输入图像的各个通道
经网络的训练，研究人员提出了深层结构的优化和训 做卷积滤波，采取图像的局部特征，得到和卷积核数
练学习方法的改进，包括使用ＲｅＬＵ激活函数，使用 量相同、大小为２８×２８的特征图．然后将这些特征
ｄｒｏｐｏｕｔ进行网络训练，使用ｂａｔｃｈ ｎｏｒｍａｌｉｚａｔｉｏｎ技 图按一定的方式组合起来，作为卷积层的输出．图中
术归一化特征的数据分布等． 原特征图经过采样层Ｓ２后，尺寸被缩减至１４×１４，
神经网络的研究与人类视觉的研究密切相关， 其中特征图上每个神经元与上一层中对应特征映射
为了进一步提高神经网络的性能，通过借鉴人脑视 的２×２邻域相连，并据此计算输出．卷积神经网络
觉系统的最新研究成果为卷积神经网络的研究寻找 中的卷积层中的神经元是模拟 Ｈｕｂｅｌ－Ｗｉｅｓｅｌ模型
下一个突破口，已成为越来越受到学术界关注的研 中的简单细胞，降采样层的神经元模拟复杂细胞，而
究方向．通过对人脑视觉通路的深入研究，从视觉神 特征图上的神经元共享同一个卷积核，对应某种
经网络的结构、各层的视觉信息表达、以及高层网络 特定取向的简单细胞．进行若干个卷积—采样操
的视觉认知机理中获得科学启示，结合数学、统计与 作，可以得到尺寸很小但数量很多的特征图．将特
工程等相关技术，能制作出更加接近人脑环境理解 征图按一定方式展开，拼接为一维向量输入全连
和认知能力的机器视觉系统． 接层中，然后经过若干全连接层和输出层连接完成
本文第２节系统性地介绍卷积神经网络的结构 识别任务．
及原理，并对新近发展起来的提升卷积神经网络性 卷积神经网络的卷积层由若干个特征图组成，
能的技术方法进行阐述和讨论；第３节介绍卷积神 每个特征图上的所有神经元共享同一个卷积核的参
经网络在目标检测、图像语义分割、图片标题生成、 数，由卷积核对前一层输入图像做卷积运算得到．卷
人脸识别、行人再识别、图像超分辨率等领域的应 积核中每一个元素都作为权值参数，同输入图像相
图２ 卷积神经网络的典型结构［１２］ ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４５７
应区块的像素值相乘，然后将各项乘积求和，并经过 享相同的连接权，这样可以大幅减少需要训练的参
激活函数得到输出像素．虽然在形式上表现为多通 数数目．对于一个含ｍ个样本的训练集，其损失函
道特征图的三阶张量卷积操作，但实质上等同于将 数可以使用交叉熵表示为
多个输入信号加权求和后作用于一个神经元，然后 １ ｍ
Ｊ＝－ ∑ｌｏｇ（Ｐ（Ｙ＝ｙ（ｉ）｜ｘ（ｉ），ｗ，ｂ）） （５）
激活输出的过程．第ｌ层的第ｊ个特征图矩阵ｘｌ可 ｍ
ｉ＝１
ｊ
在测试时，卷积神经网络的预测值为
能由前一层若干个特征图卷积加权得到，一般可以
表示为 ｙ ｐｒｅｄ＝ａｒｇ ｍａｘＰ（Ｙ＝ｉ｜ｘ，ｗ，ｂ） （６）
ｉ
ｘｌ＝ｆ（∑ｘｌ－１＊ｋｌ＋ｂｌ） （１）
近年来，卷积神经网络在越来越多的领域超越
ｊ ｉ ｉｊ ｊ
ｉ∈Ｎ
ｊ
传统模式识别与机器学习算法，取得顶级的性能与
其中，ｆ为神经元激活函数；Ｎ ｊ代表输入特征图的
精度．这些成果主要是通过：（１）增加神经网络层
组合，＊表示卷积运算，ｋ ｉｌ ｊ为卷积核矩阵，ｂｌ ｊ为偏置 数，（２）加大训练样本的数量，（３）改进训练学习算
矩阵．常用的神经元激活函数有ｓｉｇｍｏｉｄ函数、ｔａｎｈ
法这三方面的技术手段来实现的．本节将主要从以
函数、ＲｅＬＵ函数等．
上三个方面来介绍深度神经网络研究方面的代表性
采样层也称为“池化”层，其作用是基于局部相
成果，并通过实例展示各种技术手段对神经网络图
关性原理进行池化采样，从而在减少数据量的同时
像分类精度的提升效果．
保留有用信息．采样过程可以表示为
２．１ 增加网络层数
ｘｌ ｊ＝ｆ （ｄｏｗｎ（ｘｌ ｊ－１）） （２） 在给定带标签数据集的前提下，提升深度神经
其中，ｄｏｗｎ（·）表示采样函数，常用的有最大值采样
网络识别精度的一种直接方法是增加网络层数［１０］．
函数和均值采样函数．最大值采样函数是把区块中
２０１２年，在ＩｍａｇｅＮｅｔ ＩＬＳＶＲＣ挑战赛的大规
元素的最大值作为函数输出，提取特征平面的局部
模图像分类任务中，Ｋｒｉｚｈｅｖｓｋｙ等人搭建了一个
最大响应，通常用于低层特征提取，对输入的特征图
８层的卷积神经网络（简称ＡｌｅｘＮｅｔ［６］），最终Ｔｏｐ－５
选取最显著的特征．均值采样函数是计算区块元素
分类错误率达到１５．３１５％，抛离第二名用传统机器
的算术平均值作为函数输出，提取特征平面局部响
学习方法得到的结果———２６．１７２％分类错误率———
应的均值．采样过程与卷积过程类似，使用一种不带
１０多个百分点．ＡｌｅｘＮｅｔ使用了５个卷积层（另外
权参数的采样函数，从输入特征图的左上角开始按
包括３个ｐｏｏｌｉｎｇ层和２个ｎｏｒｍ层）、３个全连接
一定步长向右（或向下）滑动，对窗口相应区块的像
层，总共６０Ｍ个参数．
素进行采样后输出．
具体的网络参数配置如图３所示．每个输入图片
卷积神经网络在卷积层和采样层后，通常会连
都被缩放为２５６×２５６大小，并从中随机截取２２４×
接一个或多个全连接层．全连接层的结构和全连接
２２４大小的方形区块，以ＲＧＢ三个颜色维度输入．
神经网络的隐层结构相同，全连接层的每个神经元
由于当时 ＧＰＵ的性能限制，Ｋｒｉｚｈｅｖｓｋｙ等人在两
都会与下一层的每个神经元相连．第ｌ层全连接层
个ＧＰＵ上并行处理ＡｌｅｘＮｅｔ，故图３中隐藏层显示
特征向量ｘｌ可以如下表示：
为两路同时计算．前５层是卷积层，以第一层为例，
ｘｌ＝ｆ（ｗｌｘｌ－１＋ｂｌ） （３）
产生９６个５５×５５节点的特征图（Ｆｅａｔｕｒｅ Ｍａｐ），每
其中，ｗｌ是权值矩阵，ｂｌ是偏置向量．
个特征图由大小为１１×１１，步长为４的卷积核构
当模型的最后输出层为逻辑回归层时，卷积神
成．卷积滤波后，通过ＲｅＬＵ激活函数得到卷积层
经网络输出的每个节点表示输入图片属于某一类别
的输出激励后，经过局部响应归一化和最大池化下
ｉ的概率：
采样操作，输出给下一个卷积层．网络在五层卷积层
Ｐ（Ｙ＝ｉ｜ｘ，ｗ，ｂ）＝ｓｏｆｔｍａｘ（ｗｘ＋ｂ）
ｉ 的基础上加上一个三层的全连接网络来做分类器，
ｅ ｗｉｘ＋ｂｉ
＝ （４） 对高维卷积特征进行分类得到类别标签．全连接网
∑ｅ ｗ ｊｘ＋ｂｉ 络最终输出维数为１０００的神经元响应，对应于待分
ｊ
式中，ｗ为最后一层的权参数，ｂ为相应偏置参数． 类图像的１０００个类别．
卷积神经网络可以使用ＢＰ算法进行训练，但 在２０１３年的ＩｍａｇｅＮｅｔ ＩＬＳＶＲＣ比赛中，排名
在训练中，卷积层中每个特征图的所有神经元都共 前２０的小组使用的都是深度学习算法，其中Ｚｅｉｌｅｒ ４５８ 计 算 机 学 报 ２０１９年
图３ ＡｌｅｘＮｅｔ模型结构［６］
和Ｆｅｒｇｕｓ以其自主设计开发的ＺＦ－Ｎｅｔ① 赢得了冠军， 网络配置
在不用额外训练数据的情况下，Ｔｏｐ－５分类错误率达到 Ａ Ａ－ＬＲＮ Ｂ Ｃ Ｄ Ｅ
１１层 １１层 １３层 １６层 １６层 １９层
了１１．７４３％．ＺＦ－Ｎｅｔ所采用的深度神经网络框架几乎和
输入（２２４×２２４ＲＧＢ图）
ＡｌｅｘＮｅｔ一样，区别仅仅是把第一个卷积层的卷积核尺 ｃｏｎｖ３－６４ ｃｏｎｖ３－６４ ｃｏｎｖ３－６４ ｃｏｎｖ３－６４ ｃｏｎｖ３－６４ ｃｏｎｖ３－６４
ＬＲＮ ｃｏｎｖ３－６４ ｃｏｎｖ３－６４ ｃｏｎｖ３－６４ ｃｏｎｖ３－６４
寸从１１×１１修改为７×７，步长从４缩小为２，由此输出特
最大池化
征图的尺寸增大为１１０×１１０，相当于增加了网络的宽度．
ｃｏｎｖ３－１２８ｃｏｎｖ３－１２８ｃｏｎｖ３－１２８ｃｏｎｖ３－１２８ｃｏｎｖ３－１２８ｃｏｎｖ３－１２８
在２０１４年的ＩｍａｇｅＮｅｔ ＩＬＳＶＲＣ竞赛上，牛津 ｃｏｎｖ３－１２８ ｃｏｎｖ３－１２８ｃｏｎｖ３－１２８ｃｏｎｖ３－１２８
最大池化
大学的Ｓｉｍｏｎｙａｎ和Ｚｉｓｓｅｒｍａｎ设计的ＶＧＧ（Ｖｉｓｕａｌ
ｃｏｎｖ３－２５６ｃｏｎｖ３－２５６ｃｏｎｖ３－２５６ｃｏｎｖ３－２５６ｃｏｎｖ３－２５６ｃｏｎｖ３－２５６
Ｇｅｏｍｅｔｒｙ Ｇｒｏｕｐ）网络［９］获得了定位任务第一名和 ｃｏｎｖ３－２５６ｃｏｎｖ３－２５６ｃｏｎｖ３－２５６ｃｏｎｖ３－２５６ｃｏｎｖ３－２５６ｃｏｎｖ３－２５６
ｃｏｎｖ１－２５６ ｃｏｎｖ３－２５６ ｃｏｎｖ３－２５６
分类任务第二名．ＶＧＧ主要通过增加网络的深度提 ｃｏｎｖ３－２５６
高网络性能．ＶＧＧ由８个部分构成，它们是５个卷 最大池化
ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２
积组、２个全连接特征层和１个全连接分类层．每个
ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２
卷积组由１～４个卷积层串联构成，所有卷积层都使 ｃｏｎｖ１－５１２ ｃｏｎｖ３－５１２ ｃｏｎｖ３－５１２
ｃｏｎｖ３－５１２
用了３×３的小尺寸卷积核．多个３×３卷积层可看
最大池化
作是大尺寸卷积层的分解，如两个３×３卷积层的有 ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２
ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２ｃｏｎｖ３－５１２
效卷积核大小是５×５，三个３×３卷积层的有效卷
ｃｏｎｖ１－５１２ ｃｏｎｖ３－５１２ ｃｏｎｖ３－５１２
积核大小是７×７．这样做的好处是，多个小尺寸卷 ｃｏｎｖ３－５１２
最大池化
积层比一个大尺寸卷积层有更少的参数，且能在不
全连接层－４０９６
影响视野域的情况下增加映射函数的非线性，使网 全连接层－４０９６
全连接层－４０９６
络更加具有判别性．根据每个卷积组内卷积层层数
Ｓｏｆｔ－ｍａｘ
的不同，ＶＧＧ给出了 Ａ～Ｅ五种配置方法（如图４
图４ ＶＧＧ网络结构的不同配置（从左到右）．卷积层参数
所示），网络层数从１１层增加到１９层，对应的网络
表示为“ｃｏｎｖ〈卷积核大小〉－〈通道数〉”［９］
参数从１３３Ｍ 增加到１４４Ｍ．论文的试验测试结果
成计算资源的浪费．
表明，随着网络层数的不断加深，ＶＧＧ网络的准确
Ｇｏｏｇｌｅ公司的Ｓｚｅｇｅｄｙ等人开发设计的 Ｇｏｏｇ－
率在１６层时达到性能瓶颈，之后趋于饱和．
ＬｅＮｅｔ［１０］网络模型使用新颖的Ｉｎｃｅｐｔｉｏｎ结构作为基
虽然增加深度神经网络深度能一定程度提升网
本模块进行级联，实现了在提升网络深度的同时
络的性能，但这种方法有两个瓶颈．一方面是大的网
大大减少网络参数，并且充分利用了计算资源，提高
络结构需要学习更多的参数，容易造成网络对训练
了算法的计算效率．他们在２０１４年参加ＩｍａｇｅＮｅｔ
数据集的过拟合．另一方面，层数多的网络需要更多
ＩＬＳＶＲＣ挑战赛，并获得了图像分类任务的冠军．
的计算资源．例如两个相互连接的卷积层同时增加
ＧｏｏｇＬｅＮｅｔ由多个Ｉｎｃｅｐｔｉｏｎ基本模块级联组
特征维度，计算量呈平方增长；如果额外增加的神经
元没有得到有效的利用（很多权值接近零），就会造
① ｈｔｔｐ：／／ｗｗｗ．ｃｌａｒｉｆａｉ．ｃｏｍ ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４５９
成，网络达到２２层的深度．Ｉｎｃｅｐｔｉｏｎ结构如图５所 度是ＶＧＧ网络深度的８倍，但网络的参数量却要
示，其主要思想是以３个不同尺寸的卷积核对前一 比ＶＧＧ网络要少．
个输入层提取不同尺度的特征信息，然后融合这些 虽然ＲｅＬＵ、ＰＲｅＬＵ、ｂａｔｃｈ ｎｏｒｍａｌｉｚａｔｉｏｎ等一
特征信息并传递给下一层．Ｉｎｃｅｐｔｉｏｎ拥有１×１， 系列方法的提出，解决了深度神经网络训练的梯度
３×３和５×５的卷积核，其中１×１的卷积核较前一 消失或爆炸以及特征分布不均匀等问题，但在训练
层有较低的维度，主要用于数据降维，在传递给后面 很深的网络时，随着网络深度的增加，所增加后续层
的３×３和５×５卷积层时降低了它们的卷积计算
的训练和测试的错误率反而增加．深度残差网络借
量，避免了由于增加网络规模所带来的巨大计算量．
鉴了ｈｉｇｈｗａｙ网络的思想，在构造网络时增加了捷
通过对４个通道的特征融合，下一层可以从不同尺
径连接，使后续层的输出不是传统神经网络中输入
度上提取到更有用的特征．
的映射，而是输入的映射和输入的叠加，如图６所
示．网络要优化的是图６中的残差函数Ｆ（ｘ）．
图５ Ｉｎｃｅｐｔｉｏｎ模型结构
然而，很深的网络结构给预测误差的反向传播 图６ 残差网络的学习模块
带来了困难，因为从顶层传到底层的误差已经变得
表１罗列了当前的顶级深度卷积神经网络、它
很小，难以驱动底层参数的更新．ＧｏｏｇＬｅＮｅｔ采取
们的网络构成、参数量及其在ＩｍａｇｅＮｅｔ验证集上
的策略是将监督信号直接加到多个中间层，这意味
的图像分类精度．从表中的数据可以看出，增加网络
着中间和低层的特征表示也需要能够准确对训练数
层数的确能够提升图像分类的精度，当ＧｏｏｇＬｅＮｅｔ
据分类． 从２２层［１０］增加到３１层［１３］（复杂度增加４１％）时，
与ＡｌｅｘＮｅｔ及ＺＦ－Ｎｅｔ网络模型对比，ＧｏｏｇＬｅＮｅｔ
网络参数量从６．８Ｍ增加到８Ｍ（增加１８％），图像
删除了倒数两个全连接层．一般而言，全连接层含有
分类Ｔｏｐ－５错误率由７．９％下降到５．８２％．微软亚
整个网络的绝大多数参数，却只占用很小的计算资 洲研究院何恺明等人提出的 ＭＳＲＡ 模型［１４］与
源，反之亦然．如在ＡｌｅｘＮｅｔ中，前五层卷积层只拥 ＧｏｏｇＬｅＮｅｔ同为２２层网络，但前者的参数量是后者
有网络５％的参数，但却消耗了整个网络９５％的计
表１ 顶级深度神经网络的网络构成、参数量及
算量．而后三层全连接层占有网络９５％的学习参
在ＩｍａｇｅＮｅｔ验证集上的分类错误率
数，却只需要５％的计算量．这造成了学习参数和计
Ｔｏｐ－１ Ｔｏｐ－５
模型 构成 参数量／Ｍ
算资源利用的极度不平衡．通过去除全连接层， 错误率／％ 错误率／％
ＡｌｅｘＮｅｔ ８层
ＧｏｏｇＬｅＮｅｔ虽然增加了网络的深度，但整个网络的
２０１２［６］ （５ｃｏｎｖ＋３ｆｃ）
～６０ ４０．７ １５．３
参数只有６Ｍ，而且还消除了上述学习参数与计算资
８层
ＺＦ－Ｎｅｔ ～６０ ３７．５ １６．０
源间的不平衡现象，达到充分利用计算资源的目的．
（５ｃｏｎｖ＋３ｆｃ）
１９层
最近，在２０１５ＩｍａｇｅＮｅｔ计算机识别挑战赛中， ＶＧＧ［９］
（１６ｃｏｎｖ＋３ｆｃ）
～１４４ ２４．４ ７．１
微软亚洲研究院何恺明等人提出的残差网络 ＧｏｏｇＬｅＮｅｔ［１０］ ２２层 ～６．８ － ７．９
（Ｒｅｓｉｄｕａｌ Ｎｅｔｗｏｒｋｓ，ＲｅｓＮｅｔ）［１１］获得图像分类、图像 Ｇ Ｍｏ ｏｏ ｄｇ ｅｌＬｅ ［１３－ ］ＢＮ
３１层 ～８ ２１．９９ ５．８２
定位以及图像检测三个主要项目的冠军，在同一年
ＭＳＲＡ［１４］ ２２层 ～２００ ２１．５９ ５．７１
的微软ＣＯＣＯ比赛上获得检测和分割的冠军．在 ＲｅｓＮｅｔ［１１］ １５２层 ～２２ １９．３８ ４．４９
ＩｍａｇｅＮｅｔ比赛上，所使用的１５２层深度残差网络深 ４６０ 计 算 机 学 报 ２０１９年
的２９倍，Ｔｏｐ－５错误率下降了约２．２％．残差网络在 Ｓｕｎ等人开发的ＤｅｅｐＩＤ，从一张人脸图像中截取出
图像分类任务上的Ｔｏｐ－５错误率降低到了４．４９％． 不同大小的图像块作为样本训练了６０个神经网络，
２．２ 增加训练数据集规模 极大地增加了训练数据的数量．Ｓｉｍａｒｄ等人［２０］对
在训练上述如此巨大的神经网络时，如果没有 ＭＮＩＳＴ［１２］中的训练样本做了各种变种扩增来提高
充分的训练数据，模型将极有可能陷入过拟合．出现 模型性能．ＧｏｏｇＬｅＮｅｔ和ＶＧＧ网络在ＩｍａｇｅＮｅｔ比
过拟合时，直观的表现如图７所示．随着训练过程的 赛中都使用了多尺度图像训练集的方法：训练不同
进行，模型复杂度增加，在训练集上的错误率渐渐减 输入图片尺度下（例如５１２×５１２，２５６×２５６）的多个
小，但是在验证集上的错误率却渐渐增大．过拟合出 模型，最后综合评估所有模型的输出结果．另外还有
现的原因一般有两点：一是训练样本数量太少，得到 调整图片亮度、饱和度、对比度、偏色等方法．
的网络参数不能准确模拟数据的分布；二是由于模
型复杂度过高，训练样本数据里的噪音干扰过大，使
模型过分拟合了噪音数据，反而忽略了正确样本数
据．因此，模型虽然对训练数据拟合非常好，但是对
于训练集外的数据拟合效果却非常差．
图８ 数据集扩增
表２揭示了使用数据扩增技术后对神经网络性
能提升的作用．
表２ ＣＩＦＡＲ－１０测试集上的分类错误率［２１］
图７ 过拟合示意图 错误率／％ 错误率／％
方法
（无数据扩充） （数据扩充）
避免过拟合问题最简单直接的方法就是增加训
ＣＮＮ＋Ｓｐｅａｒｍｉｎｔ １４．９８ ９．５
练样本的数量．在ＬＦＷ 数据集上的人脸验证任务 Ｃｏｎｖ．ｍａｘｏｕｔ＋Ｄｒｏｐｏｕｔ １１．６８ ９．３８
ＮＩＮ＋Ｄｒｏｐｏｕｔ １０．４１ ８．８１
中，ＤｅｅｐＩＤ［１５－１７］、ＤｅｅｐＦａｃｅ［１８］、ＦａｃｅＮｅｔ［１９］等模型都
已接近或达到了人类的识别精度．这些模型都利用 ２．３ 正则化
了从互联网下载的海量带标签人脸图像进行监督式 训练大型卷积神经网络除了增大训练数据集
预训练（Ｐｒｅ－ｔｒａｉｎ）．比如ＤｅｅｐＩＤ使用了１０Ｋ类的 外，还经常使用正则化方法①来防止过拟合问题．发
外部人脸数据集，ＦａｃｅＮｅｔ则使用了近８Ｍ 个不同 生过拟合的模型一般在某些很小的区间里，函数值
类别．训练好的深度神经网络通常作为特征提取器 的变化很剧烈．这就意味着函数的参数值偏大，使某
再应用在特定的人脸验证数据库上进行人脸验证． 些小区间里的导数值（绝对值）非常大．正则化是通
然而，收集更多的数据意味着需要耗费更多的 过约束参数的范数使其不要过大，以此降低模型的
人力、物力和财力，而且构建高质量的数据集往往还 复杂度，从而减小噪声输入的扰动，可以在一定程度
需要相关的专业知识，因而单纯增加标注样本的方 上减少过拟合情况．
法并不可行． Ｌ ２正则化是最常用的一种正则化技术，又称权
另一种简单获取更多数据的方式被称为数据扩 重衰减（ｗｅｉｇｈｔ ｄｅｃａｙ），它是在原始的损失函数Ｃ
０
增（Ｄａｔａ Ａｕｇｍｅｎｔａｔｉｏｎ），它通过对原始图片施行各 后面再加上一个正则化项：
种变换来得到更多的数据，例如：将原始图片旋转一 Ｃ＝Ｃ ＋λ ∑ ｗ ２ （７）
０ ２ ２
个小角度、添加随机噪声、带弹性的形变和截取原始 ｗ
正则化项是所有网络权重ｗ的平方和．λ（λ＞０）是
图片的一部分等．图８展示了一种常用的数据集扩
正则项系数，用来权衡正则项与Ｃ 的比重．另外系
增方法：从一张２５６×２５６大小的输入图像中，按照 ０
２２４×２２４固定大小从不同位置截取出多个图像块，
① ｈｔｔｐ：／／ｎｅｕｒａｌｎｅｔｗｏｒｋｓａｎｄｄｅｅｐｌｅａｒｎｉｎｇ．ｃｏｍ．Ｃｈａｐｔｅｒ ３，Ｉｍｐｒｏ－
再通过水平翻转生成大量训练图片．香港中文大学 ｖｉｎｇ ｔｈｅ ｗａｙ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｌｅａｒｎ ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４６１
数１／２，主要是为了后面求导数计算方便． ｒ＝ａ（（Ｍ．×Ｗ）ｖ） （１１）
通过对式（７）求导，有 两者的区别从图９中可以看出．
Ｃ Ｃ
烄 ＝ ０＋λｗ
ｗ ｗ
（８）
烅
Ｃ Ｃ
＝ ０
烆ｂ ｂ
从上式可以发现Ｌ正则化项对偏置ｂ的更新没有
２
影响，但是对于权重ｗ的更新有影响：
ｗ→ｗ－ηＣ ０－ηλｗ＝（１－ηλ）ｗ－ηＣ ０ （９）
ｗ ｗ
在不使用Ｌ 正则化时，求导结果中ｗ前系数
２
为１．使用Ｌ ２正则化后，ｗ前面系数为１－ηλ，因为η
和λ都是正的，所以１－ηλ＜１，它的效果是减小ｗ，
这也就是权重衰减的由来．当ｗ为正时，更新后的
ｗ变小；当ｗ为负时，更新后的ｗ变大．因此它的效
果就是让ｗ向０靠，使网络中的权重尽可能为０，也
就相当于减小了网络的权重，降低了网络复杂度，防
止过拟合．
Ｌ正则化是通过修改代价函数来实现的，而
２
Ｄｒｏｐｏｕｔ［２２－２３］则是通过修改神经网络本身来实现
的，它是训练网络时常用的一种技巧．Ｄｒｏｐｏｕｔ是在
图９ Ｄｒｏｐｏｕｔ和ＤｒｏｐＣｏｎｎｅｃｔ网络对比
训练过程中以１－ｐ（ｐ一般取０．５）的概率将隐层节
Ｍａｘｏｕｔ其实是一种激活函数形式．一般情况
点的输出值清０，而用ＢＰ算法更新权值时，不再更
下，如果激活函数采用ＲｅＬＵ函数，在前向传播过
新与该节点相连的权值．如图９（ａ）所示，考虑一个
程中，第ｉ个隐层节点的输出表达式为
全连接层，ｖ表示ｎ×１维的输入向量，Ｗ表示ｄ×ｎ
ｈ（ｘ）＝ｍａｘ（ｘＴＷ ＋ｂ，０） （１２）
维的网络权重，ａ（ｘ）是一个满足ａ（０）＝０的激活函 ｉ …ｉ ｉ
其中Ｗ是２维的，Ｗ 表示Ｗ中的第ｉ列向量．对于
数．Ｍ是个ｄ×１的列向量，其每个元素服从概率为 …ｉ
Ｍａｘｏｕｔ激活函数，如图１０所示，其隐层节点的输出
ｐ的伯努利分布．该层的输出ｒ可由以下公式计算
表达式为
得到
ｈ（ｘ）＝ｍａｘｚ （１３）
ｒ＝Ｍ．×ａ（Ｗｖ ） （１０） ｉ ｉｊ
ｊ∈［１，ｋ］
运用了Ｄｒｏｐｏｕｔ的训练过程，相当于训练了指 ｚ ｉｊ＝ｘＴＷ …ｉｊ＋ｂ
ｉｊ
（１４）
数界别的只有半数隐层单元的神经网络 （简称为 其中Ｗ∈Ｒｄ×ｍ×ｋ，ｄ表示输入层节点的个数，ｍ表
“半数网络”），每一个这样的半数网络，都可以给出 示隐层节点的个数，ｋ表示子隐层节点的个数．这ｋ
一个分类结果，神经网络最终的结果是对这些半数 个子隐层节点都是线性输出的，而隐层节点的输出
网络进行平均或者集成．Ｄｒｏｐｏｕｔ可以有效提高网 取这ｋ个子隐层节点输出值中最大的那个值．因为
络的性能，并能防止过拟合． 激活函数中有了 ｍａｘ操作，所以整个 Ｍａｘｏｕｔ网络
ＤｒｏｐＣｏｎｎｅｃｔ［２４］和 Ｍａｘｏｕｔ［２５］，都可以提高深
度神经网络的泛化能力，两者是对Ｄｒｏｐｏｕｔ的改进．
ＤｒｏｐＣｏｎｎｅｃｔ与Ｄｒｏｐｏｕｔ的不同之处是，它不是随机
将隐层节点的输出清０，而是将节点中的每个与其
相连的输入权值以（１－ｐ）的概率清０（ＤｒｏｐＣｏｎｎｅｃｔ
是对权重作用，而Ｄｒｏｐｏｕｔ是对神经元输出作用，如
图９所示）．
ＤｒｏｐＣｏｎｎｅｃｔ表达式如下：
图１０ Ｍａｘｏｕｔ网络示意图 ４６２ 计 算 机 学 报 ２０１９年
是一种非线性的变换．Ｍａｘｏｕｔ具有非常强的拟合 计算等），ＲｅＬＵ函数则是通过非常简单的阈值化的
能力，它可以拟合任意的凸函数． 激活对参数进行稀疏化．由于 ＲｅＬＵ 函数的线性、
表３给出了不同正则化方式在ＣＩＦＡＲ－１０和 非饱和性，与ｓｉｇｍｏｉｄ和ｔａｎｈ函数相比，ＲｅＬＵ函数
ＣＩＦＡＲ－１００数据集上分类结果的比较． 能明显加快卷积神经网络的收敛速度．文献［６］指
出，相比ｔａｎｈ函数，使用ＲｅＬＵ函数时的收敛速度
表３ 不同正则化方式在ＣＩＦＡＲ－１０和ＣＩＦＡＲ－１００
可以加快６倍，如图１１（ｂ）所示．
数据集上的分类错误率［２３，２５］
Ｍｅｔｈｏｄ ＣＩＦＡＲ－１０ ＣＩＦＡＲ－１００
Ｗｉｔｈｏｕｔ Ｄｒｏｐｏｕｔ １５．６０ ４３．４８
Ｄｒｏｐｏｕｔ ｉｎ ｆｃ ｌａｙｅｒｓ １４．３２ ４１．２６
Ｄｒｏｐｏｕｔ ｉｎ ａｌｌ ｌａｙｅｒｓ １２．６１ ３７．２０
Ｄｒｏｐｏｕｔ＋Ｍａｘｏｕｔ １１．６８ ３８．５７
ＤｒｏｐＣｏｎｎｅｃｔ １１．１０ －
２．４ 其他改进训练学习方法
卷积神经网络中改进训练学习的方法除了使用
正则化外，还有改进激活函数、定义不同损失函数、
使用ｂａｔｃｈ ｎｏｒｍａｌｉｚａｔｉｏｎ等常用技术．
深层神经网络中的激活函数通常使用非线性函
数，通过非线性的组合可以逼近任何函数．在式（１）
中，常用的神经元激活函数有Ｓｉｇｍｏｉｄ函数，ｔａｎｈ
函数，ＲｅＬＵ、ＬＲｅＬＵ和ＰＲｅＬＵ函数等．Ｓｉｇｍｏｉｄ函
数是一种非线性激活函数，数学形式为ｆ（ｘ）＝
１
．Ｓｉｇｍｏｉｄ函数将神经元的输出信号映射到
１＋ｅ－ｘ
［０，１］之间．对于深层卷积神经网络，Ｓｉｇｍｏｉｄ函数
反向传播时，很容易出现梯度消失的问题．这是由于
在Ｓｉｇｍｏｉｄ饱和区，函数的梯度接近于０，反向传播
中计算的梯度也会接近于０．这样在参数更新过程
中，传到前几层的梯度几乎为０，网络参数几乎不会
再更新．另外，Ｓｉｇｍｏｉｄ函数的输出值始终在０和１ 图１１ ＲｅＬＵ激活函数［６］
之间，这会导致后一层的神经元以当前层输出的
在ＲｅＬＵ函数训练过程中，当流过一个ＲｅＬＵ
非０均值数据作为输入．虽然使用ｂａｔｃｈ进行训练
神经元的梯度较大时，可能导致该神经元的权重参数
能一定程度缓解非０均值这一问题，但仍给深度
不会再次更新．如果神经元出现以上所述的“死亡”
网络的训练造成不便．Ｔａｎｈ激活函数的数学形式为
情况，那这些神经元的梯度将永远是零．如果训练时
ｅｘ－ｅ－ｘ
ｆ（ｘ）＝ ，它将神经元的输出信号映射到 学习率设置过高，可能导致高达４０％的网络处在
ｅｘ＋ｅ－ｘ
“死亡”中，这部分神经元在整个训练过程中从未
［－１，１］范围内．Ｔａｎｈ函数的输出是０均值的，在实
被激活过．通过合理设置学习率可以有效降低这一
际应用中，ｔａｎｈ函数比ｓｉｇｍｏｉｄ函数好，但也存在梯
现象．
度消失问题，会导致训练效率低下．
为了避免ＲｅＬＵ神经单元在训练时可能会“死亡”
ＲｅＬＵ（Ｒｅｃｔｉｆｉｅｄ Ｌｉｎｅａｒ Ｕｎｉｔｓ，修正线性单元）
现象，ＬＲｅＬＵ（Ｌｅａｋｙ Ｒｅｃｔｉｆｉｅｄ Ｌｉｎｅａｒ Ｕｎｉｔ）激活函
函数是近几年深度学习领域非常流行的一种神经元
数使神经元在整个训练过程中能持续得到更新．
激活函数，数学形式为ｆ（ｘ）＝ｍａｘ（０，ｘ），函数曲线
ＬＲｅＬＵ激活函数的表达式如下：
如图１１（ａ）所示．ＲｅＬＵ函数在ｘ＞０时的梯度恒等
｛ｘ， ｘ＞０
于１，因此在反向传播过程中，前几层网络的参数 ｆ（ｘ）＝ （１５）
αｘ， ｘ０
也能得到快速更新，缓解了梯度消失问题．另外，
其中，α通常取一个很小的固定值，如α＝０．０１．
ｓｉｇｍｏｉｄ和ｔａｎｈ函数都需要较大的计算量（如指数 ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４６３
ＰＲｅＬＵ（Ｐａｒａｍｅｔｒｉｃ Ｒｅｃｔｉｆｉｅｄ Ｌｉｎｅａｒ Ｕｎｉｔ）激 为１，否则值取－１．注意到，当ｐ＝１，上式为标准的
活函数是带一个自适应参数的ＲｅＬＵ函数．ＰＲｅＬＵ ｈｉｎｇｅ损失（或称为Ｌ －Ｌｏｓｓ）；当ｐ＝２，上式为平
１
的表达式与式（１５）相同，但ＰＲｅＬＵ的α是个随机 方ｈｉｎｇｅ损失 （或称为Ｌ－Ｌｏｓｓ）．与标准ｈｉｎｇｅ损
２
变量，训练时它在给定范围随机取值．当α＝０时， 失函数对比，平方ｈｉｎｇｅ损失函数对损失值的惩罚
ＰＲｅＬＵ相当于ＲｅＬＵ；当α取一个很小的值时，相 要更大．
当于ＬＲｅＬＵ． Ｃｏｎｔｒａｓｔｉｖｅ损失函数常用于训练Ｓｉａｍｅｓｅ网
面对特定的任务，选择合适的损失函数非常关
络．Ｓｉａｍｅｓｅ网络是由结构相同且共享权值的两个
键．常用的损失函数有ｓｏｆｔｍａｘ函数、ｈｉｎｇｅ损失函 卷积神经网络组成，输入是一对图像，如图１２（ａ）所
数、ｃｏｎｔｒａｓｔｉｖｅ损失函数、ｔｒｉｐｌｅｔ损失函数等．在本
示．假设（ｘ，ｘ）是一对输入图像，ｆ（ｘ）和ｆ（ｘ）是
１ ２ １ ２
节开头已介绍过ｓｏｆｔｍａｘ函数，这里重点介绍其他
输入图像在卷积神经网络最高隐藏层提取的特征向
三种损失函数．
量．Ｃｏｎｔｒａｓｔｉｖｅ损失函数的主要目的是在特征空间
Ｈｉｎｇｅ损失函数的数学形式如下：
上拉近同一类别样本之间的距离，并增大不同类别
ｍ
１
Ｌ＝ ∑［ｍａｘ（０，１－δ（Ｙ＝ｙ（ｉ））ｗＴｘ（ｉ））］ｐ （１６） 样本之间的距离．
ｍ
ｉ＝１
式中，当卷积神经网络分类正确时，δ（Ｙ＝ｙ（ｉ））值
图１２ Ｓｉａｍｅｓｅ网络和Ｔｒｉｐｌｅｔ网络的结构示意图（Ｓｉａｍｅｓｅ网络包含两个架构相同且参数共
享的ＣＮＮ模型，以一对图像作为输入，使用ｃｏｎｓｔｒａｓｔｉｖｅ损失函数进行训练．Ｔｒｉｐｌｅｔ
网络包含三个相等的ＣＮＮ，以图像三元组作为输入，使用的损失函数为ｔｒｉｐｌｅｔ损失
函数）
Ｃｏｎｔｒａｓｔｉｖｅ损失函数的定义如下： １ ｍ
Ｌ＝ ∑ｍａｘ［０，Ｄ（ｘａ，ｘｐ）－Ｄ（ｘａ，ｘｎ）＋τ］（１８）
ｍ ２ｍ
Ｌ＝
１
∑ｙ·Ｄ（ｘ，ｘ）＋
ｉ＝１
２ｍ
ｉ＝１
１ ２ 由上式可见，ｔｒｉｐｌｅｔ损失函数是优化输入图像在特
（１－ｙ）ｍａｘ［０，τ－Ｄ（ｘ １，ｘ ２）］ （１７）
征空间上的欧式平方距离，使不同类别的图像ｘｎ远
式中，图像对（ｘ １，ｘ ２）的相似性直接用特征空间上的
离图像对（ｘａ，ｘｐ）并大于一个阈值τ．
欧式平方距离度量：Ｄ（ｘ １，ｘ ２）＝ ｆ（ｘ １）－ｆ（ｘ ２）２．
深度卷积神经网络的训练是一个非常复杂的学
当（ｘ １，ｘ ２）属于同一类别时，ｙ取值为１，需要减小 习过程．随机梯度下降法由于其简单、高效的特点成
欧式平方距离Ｄ（ｘ １，ｘ ２）才能降低损失．相反，当 为训练深度网络的主流方法，但是它需要研究人员
（ｘ，ｘ）属于不同类别时，ｙ取值为０，需要增大 手动微调网络参数，如学习率、模型初始参数、权重
１ ２
Ｄ（ｘ １，ｘ ２）直到大于阈值τ． 衰减参数、Ｄｒｏｐｏｕｔ比例等，这些参数的选择对深度
Ｔｒｉｐｌｅｔ网络由结构相同且共享权值的三个卷 卷积神经网络的训练结果至关重要．在训练神经网
积神经网络组成，如图１２（ｂ）所示．Ｔｒｉｐｌｅｔ网络的输 络的过程中，每一层网络的参数在不断更新，会导致
入是三元组（ｘａ，ｘｐ，ｘｎ），由两张来自同一个类别的 下一层输入的数据分布情况发生改变，而且数据分
图像（ｘａ，ｘｐ）和一张来自不同类别的图像组成ｘｎ． 布的变化随着网络深度的增大而变大．那么神经网
Ｔｒｉｐｌｅｔ损失函数是最小化下式： 络需要在每次迭代时都去学习适应不同的分布，这 ４６４ 计 算 机 学 报 ２０１９年
样将会大大降低神经网络的训练速度．神经网络的 别的目标分类结果．图片标题生成也是建立于图片
隐层在训练过程中发生数据分布改变这一现象，称 的语义理解上，要求自动产生自然语言对图片的目
为ｉｎｔｅｒｎａｌ ｃｏｖａｒｉａｔｅ ｓｈｉｆｔ． 标及目标间关系进行描述．相比于图像分类和目标
Ｂａｔｃｈ Ｎｏｒｍａｌｉｚａｔｉｏｎ的基本思想，通过预处理 检测关注于多类或单类物体目标的区分或定位，人
操作，让每个隐层的所有节点的激活输入分布归一 脸识别和行人再识别任务则分别聚焦于人脸和行人
化到均值为０方差为１的标准正态分布，并且均值 的身份辨识．另外一种任务———图像超分辨率，能够
和方差都在当前迭代的 ｍｉｎｉ－ｂａｔｃｈ样本中计算得 提供更清晰的图像以及更多的图像细节，为高层视
到．假设某个ｍｉｎｉ－ｂａｔｃｈ的样本数目为ｍ，网络某个 觉任务提供更好的输入．
隐层神经元为ｘ，ｘ在 ｍｉｎｉ－ｂａｔｃｈ中ｍ个取值表示 本节将重点介绍卷积神经网络在图像分类、目
为｛ｘ １，…，ｘ ｍ｝．神经元ｘ在ｍｉｎｉ－ｂａｔｃｈ中的均值μＢ 标检测、人脸识别、行人再识别、超分辨率、人体动作
和方差σ２表示如下： 识别以及图像检索的最新研究进展．
Ｂ
１ ｍ ３．１ 图像分类
μＢ← ｍ∑ｘ
ｉ
（１９）
图像分类是计算机视觉领域的一个重要应用，
ｉ＝１
１ ｍ 主要是指对给定的一幅图片，使计算机根据图片中
σ２ Ｂ← ｍ∑（ｘ ｉ－μＢ）２ （２０）
ｉ＝１ 的内容将其分类到合适的类别，分配一个语义类别
该神经元经过Ｂａｔｃｈ Ｎｏｒｍａｌｉｚａｔｉｏｎ操作后得
标记．深度卷积神经网络在图像分类中最重要的进
到的归一化值｛ｘ，…，ｘ ｝，表示如下：
１ ｍ 展体现在ＩｍａｇｅＮｅｔ ＩＬＳＶＲＣ挑战中的图像分类任
ｘ＾←ｘ ｉ－μＢ
（２１） 务上，前一节针对这类任务重点介绍了几种网络模
ｉ
槡σ Ｂ２＋ε 型，如 ＡｌｅｘＮｅｔ［６］、ＺＦ－Ｎｅｔ、ＧｏｏｇＬｅＮｅｔ［１０］、ＶＧＧ［９］
其中，ε是极小的正数，防止除零操作．
和ＲｅｓＮｅｔ［１１］等，这里不再赘述．
如果单纯应用以上归一化公式，对网络隐层的
除ＩｍａｇｅＮｅｔ图像数据集之外，图像分类常用
输出数据做归一化，可能会影响此隐层的特征表达
的数据集还有Ｃａｌｔｅｃｈ－１０１［２６］，Ｃａｌｔｅｃｈ－２５６①，Ｔｉｎｙ－
能力．举例说明，如果该隐层学习到的特征数据本身
Ｉｍａｇｅ［２７］，ＳＵＮ［２８］等．表４列举了一些在图像分类
分布在Ｓｉｇｍｏｉｄ函数的两侧非线性区，经归一化处
领域常用的数据集及其重要信息．
理后，特征数据变换到了Ｓｉｇｍｏｉｄ函数中间的线性
区域，这就破坏了特征数据分布．为了不改变归一化 表４ 图像分类领域常用数据集
后特征的表达能力，在归一化操作后需要执行线性 名称 包含类别数量 图片数量
Ｃａｌｔｅｃｈ１０１［２６］ １０１ ９１４６
变换：
Ｃａｌｔｅｃｈ２５６ ２５６ ３０６０７
ｙ ｉ←γｘ＾ ｉ＋β （２２） ＴｉｎｙＩｍａｇｅ［２７］ ７５０６２ ７９３０２０１７
ＳＵＮ［２８］ ８９９ １３０５１９
其中，尺度参数γ和平移参数β用于恢复原始特征
ＩｍａｇｅＮｅｔ［２９］ ２１８４１ １４１９７１２２
的数据分布．
３．２ 目标检测
３ 卷积神经网络的应用 目标检测（Ｏｂｊｅｃｔ Ｄｅｔｅｃｔｉｏｎ）是计算机视觉领
域的一项基本任务，主要是定位图像中特定物体出
卷积神经网络是近十几年来类脑计算领域取得 现的区域并判定目标类别．与图像分类相比，目标检
的一个重大研究成果，它在计算机视觉、语音识别、 测更加关注图像的局部区域和特定的物体类别集
自然语言处理、多媒体等诸多领域都取得了巨大成 合，被视为更加复杂的图像识别问题．
功．在计算机视觉领域的各类任务中，图像分类任务 传统的目标检测算法大多采用滑动窗口的方式，
是根据图像信息中反映的不同特征，把不同类别的 使用手工设计的特征，如常用的特征描述子Ｈａａｒ［３０］、
目标（如鸟、人、车、飞机等）区分开来，即给每幅图片 ＳＩＦＴ（Ｓｃａｌｅ－Ｉｎｖａｒｉａｎｔ Ｆｅａｔｕｒｅ Ｔｒａｎｓｆｏｒｍ）［３１］、ＰＣＡ－
分配一个语义类别标记，而目标检测是定位出某类
目标在图像中出现的区域．与图像分类任务要建立 ① Ｇｒｉｆｆｉｎ Ｇ，Ｈｏｌｕｂ Ａ，Ｐｅｒｏｎａ Ｐ．Ｃａｌｔｅｃｈ－２５６ｏｂｊｅｃｔ ｃａｔｅｇｏｒｙ
ｄａｔａｓｅｔ．Ｃａｌｉｆｏｒｎｉａ Ｉｎｓｔｉｔｕｔｅ ｏｆ Ｔｅｃｈｎｏｌｏｇｙ，２００７．ｈｔｔｐ：／／
图像级理解不同，图像语义理解要得到图像像素级 ａｕｔｈｏｒｓ．ｌｉｂｒａｒｙ．ｃａｌｔｅｃｈ．ｅｄｕ／７６９４ ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４６５
ＳＩＦＴ［３２］、ＳＵＲＦ（Ｓｐｅｅｄｅｄ Ｕｐ Ｒｏｂｕｓｔ Ｆｅａｔｕｒｅ）［３３］ 输入图像上提取若干候选窗，利用深度卷积神经网
等，对每类物体单独训练一个浅层分类器．早在 络从候选窗提取深度特征，然后利用ＳＶＭ 等线性
２００１年，Ｖｉｏｌａ和Ｊｏｎｅｓ［３４］提出目标检测领域最具 分类器基于特征将候选窗分为目标和背景，最后使
影响力的目标检测算法，能实时处理目标检测同时 用非极大值抑制方法舍弃部分候选窗，得到目标物
具有很高检测率，成功应用于人脸检测．算法使用 体的定位结果．候选窗方法能够高效地在图像候选
ＡｄａＢｏｏｓｔ［３５］算法框架，提取目标Ｈａａｒ－ｌｉｋｅ［３６］特征， 区域内进行识别，更为灵活地处理物体长宽比的变
然后采用滑动窗口搜索策略实现准确有效的定位． 化，从而获得较高的检测正确率．
Ｄａｌａｌ等人［３７］以图像的梯度方向直方图（Ｈｉｓｔｏｇｒａｍ 基于选择性搜索策略和ＣＮＮ的目标检测算法
ｏｆ Ｏｒｉｅｎｔｅｄ Ｇｒａｄｉｅｎｔ，ＨＯＧ）作为特征，使用支撑向 在目标检测上取得很好的效果，远远超越了传统机
量机（Ｓｕｐｐｏｒｔｅｄ Ｖｅｃｔｏｒ Ｍａｃｈｉｎｅ，ＳＶＭ）［３８－４０］作为 器学习算法．但是这种检测算法遇到了速度瓶颈，由
分类器进行行人检测．由于自然界的大部分物体存 于选择性搜索方法是使用传统的图分割方式生成，
在非刚体形变，Ｆｅｌｚｅｎｓｚｗａｌｂ等人［４１］提出了多尺度 一幅图像约需要２ｓ才能完成候选窗的搜索，这极大
形变部件模型（Ｄｅｆｏｒｍａｂｌｅ Ｐａｒｔ Ｍｏｄｅｌ，ＤＰＭ）． 限制了算法的训练和测试时间．针对这一问题，Ｒｅｎ
ＤＰＭ继承了使用 ＨＯＧ特征和ＳＶＭ 分类器的优 等人［５０］提出的Ｆａｓｔｅｒ Ｒ－ＣＮＮ目标检测方法采用
点．ＤＰＭ目标检测器由一个根滤波器和一些部件滤 深度卷积神经网络替代传统的选择性搜索策略．
波器组成，组件间的形变通过隐变量进行推理．由于 Ｆａｓｔｅｒ Ｒ－ＣＮＮ中加入了一种生成候选区域的ＲＰＮ
目标模板分辨率固定，算法采用滑动窗口策略在不 （Ｒｅｇｉｏｎ Ｐｒｏｐｏｓａｌ Ｎｅｔｗｏｒｋ）网络，和目标检测网
同尺度和宽高比图像上搜索目标．后续工作采用不 络共享卷积层特征，大大节省了生成候选窗的时
同策略加速了ＤＰＭ的穷尽搜索策略． 间．ＲＰＮ对其输入的候选窗进行属于背景还是前景
传统目标检测算法主要依靠设计者的先验知 的判断以及检测框位置的修正（Ｂｏｕｎｄｉｎｇ Ｂｏｘ
识，抽取样本中手工设计的特征．为了方便手工调参 Ｒｅｇｒｅｓｓｉｏｎ），其输出的检测框输入给检测网络，做最
数，特征设计中只能出现少量的参数．另一方面，面 终的分类和更精准的检测框位置修正．Ｆａｓｔｅｒ Ｒ－ＣＮＮ
对难度较高的检测任务，浅层分类器由于模型深度 使用ＶＧＧ－１６网络模型在 Ｋ４０ＧＰＵ 上进行目标
不够，所需要的参数和训练样本会呈指数增加．与 检测任务时，运行速度能到５帧每秒，在ＰＡＳＣＡＬ
传统目标检测算法比较，深度卷积神经网络可以 ＶＯＣ ２００７上ｍＡＰ（ｍｅａｎ Ａｖｅｒａｇｅｄ Ｐｒｅｃｉｓｉｏｎ）达到
从大数据的丰富内在信息中自动学习包含上万参 ７３．２％，在ＶＯＣ ２０１２上也达到了７０．４％．图１４所示
数的特征表示，同时，深度模型使特征学习过程更 是Ｆａｓｔｅｒ Ｒ－ＣＮＮ的检测效果．
有效率．
随着２０１２年深度卷积神经网络在图像分类任
务上取得重大突破，众多学者开始利用Ｄｅｅｐ ＣＮＮ
取代浅层分类器解决目标检测问题，也带动了目标
检测精度的提升［４２－４３］．其中较有影响力的工作包括
Ｒ－ＣＮＮ［４４］，Ｄｅｅｐ ＭｕｌｔｉＢｏｘ［４５］，Ｏｖｅｒｆｅａｔ［４６］，Ｆａｓｔ
ＲＣＮＮ［４７］和ＳＰＰ－Ｎｅｔ［４８］．最具代表性的是Ｇｉｒｓｈｉｃｋ
等人在Ｒ－ＣＮＮ中提出的基于 Ｒｅｇｉｏｎ Ｐｒｏｐｏｓａｌ的
深度学习目标检测框架．如图１３所示，Ｒ－ＣＮＮ算法
首先采用选择性搜索（Ｓｅｌｅｃｔｉｖｅ Ｓｅａｒｃｈ）［４９］策略在
图１４ Ｆａｓｔｅｒ Ｒ－ＣＮＮ的检测效果［５０］
除了基于Ｒｅｇｉｏｎ Ｐｒｏｐｏｓａｌ的深度学习目标检
测算法，还有直接使用Ｄｅｅｐ ＣＮＮ进行ｅｎｄ－ｔｏ－ｅｎｄ
定位的目标检测技术，如 ＹＯＬＯ［５１］，ＤｅｎｓｅＢｏｘ［５２］
图１３ Ｒ－ＣＮＮ目标检测算法的流程图［４４］ 等，在人脸、车辆、行人等目标检测任务上取得了很 ４６６ 计 算 机 学 报 ２０１９年
好的效果．此类检测技术对需要检测的图像通常可 特征，几乎能实现实时的图像语义分割．
以直接计算出目标的类别和位置．图１５展示的是 随着深度卷积神经网络在图像检测、分类等多个
ＤｅｎｓｅＢｏｘ在ＫＩＴＴＩ数据集的车辆检测结果． 任务上成功应用，目前己经有不少研究人员将Ｄｅｅｐ
ＣＮＮ应用到图像语义分割领域［６３－６５］，如Ｆａｒａｂｅｔ等
人［６３］使用多尺度卷积神经网络从不同大小的像素
和超像素学习目标特征，极大地提升了语义分割
效果，在 ＰＡＳＣＡＬ ＶＯＣ２０１２分割数据集上达到
６２．２％的ＩＯＵ精度．Ｌｏｎｇ等人［６６］在ＣＶＰＲ ２０１５上
图１５ ＤｅｎｓｅＢｏｘ在ＫＩＴＴＩ数据集的车辆检测结果［５２］
提出的全卷积网络（Ｆｕｌｌｙ Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｎｅｔｗｏｒｋ，
３．３ 图像语义分割 ＦＣＮ）能够端到端（ｅｎｄ ｔｏ ｅｎｄ）的得到每个像素的目
在过去几年中，随着计算机视觉、机器学习等领 标分类结果．与经典的ＣＮＮ输入固定大小图像、卷
域研究的不断深入，研究人员逐渐将目光投向对 积层之后使用全连接层得到固定长度的特征向量不
图像本身更为精准的理解与分析．图像语义分割 同，ＦＣＮ可以接受任意尺寸的输入图像，且全部使
（Ｉｍａｇｅ Ｓｅｍａｎｔｉｃ Ｓｅｇｍｅｎｔａｔｉｏｎ）问题正是为了满足 用卷积层．ＦＣＮ采用反卷积层对最后一个卷积层的
这一要求提出的，它通过解析训练图像的内容，在 特征图进行上采样，使特征图恢复到输入图像相同
分割图像的同时获得图像的所有分割区域甚至每 的尺寸，从而可以对每个像素都产生了一个语义预
个像素的语义类别，从而获得图像基于内容的标 测．在此过程中保留了原始输入图像中的空间信息，
注．图像语义分割不仅需要对图像分割区域的边 最后在上采样的特征图上逐像素计算ｓｏｆｔｍａｘ分类
界做出精准识别，而且要求对分割区域的目标类 的损失．图１６是用于语义分割所采用的全卷积网络
别进行准确识别．精准的图像语义分割不仅能够有 （ＦＣＮ）的结构示意图．
效降低后续的图像分析与识别、语义检索等高层次
任务处理的数据量，同时又能保留图像的结构化信
息［５３］．图像语义分割常用的数据集有 ＭＳＲＣｖ２①、
ＰＡＳＣＡＬＶＯＣ２０１２［５４］、Ｍｉｃｒｏｓｏｆｔ ＣＯＣＯ［５５］、ＰＡＳＣＡＬ－
ＣＯＮＴＥＸＴ［５６］、Ｓｉｆｔ Ｆｌｏｗ［５７］等．图像语义分割常用
的评价指标是计算预测的语义类别和正确的语义类
别像素点的重合度（Ｉｎｔｅｒｓｅｃｔｉｏｎ Ｏｖｅｒ Ｕｎｉｏｎ，ＩＯＵ），
重合度越高说明模型的准确度越高．
传统的图像语义分割方法通常包含三个部
分：第一部分主要进行图像的底层分割，将图像划
图１６ 全卷积网络的结构示意图［６６］
分成多个子区域；第二部分提取子区域的底层特
ＦＣＮ虽然在图像语义分割方面取得不错的效果，
征，如颜色、纹理、形状等；第三部分学习从底层特
但缺少对图像空间、边缘信息的约束，导致最后的图
征到高层语义空间的映射，根据学习好的映射模
像分割结果比较粗糙．Ｃｈｅｎ等人提出的ＤｅｅｐＬａｂ［６７］
型标注图像，识别出图像区域乃至每个像素的语
应用文献［６８］中提出的全连接ＣＲＦ模型，对ＦＣＮ
义类别．主要代表性工作如Ｓｈｏｔｔｏｎ等人［５３］提出的
的输出结果作进一步的细粒度处理，在ＰＡＳＣＡＬ
ＴｅｘｔｏｎＢｏｏｓｔ方法使用提升决策树分类器，在所有
ＶＯＣ２０１２分割数据集上达到７１．６％的ＩＯＵ精度．
图像像素构成的条件随机场（Ｃｏｎｄｉｔｉｏｎａｌ Ｒａｎｄｏｍ
Ｚｈｅｎｇ等人［６９］提出的ＣＲＦ－ＲＮＮ将全连接ＣＲＦ的
Ｆｉｅｌｄ，ＣＲＦ）中，以纹理布局滤波器学习每个像素的
学习、推理过程看成是个递归神经网络（Ｒｅｃｕｒｒｅｎｔ
单点势能，像素语义标注间具有平滑性约束，通过最
Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ，ＲＮＮ），并且嵌入到ＦＣＮ模型中，
小化随机场能量，得到像素级语义标注．其后的许多
工作对条件随机场的势能函数提出了不同的改进方
法［５８－６２］．比如Ｓｈｏｔｔｏｎ等人［６２］提出的ＴｅｘｔｏｎＦｏｒｅｓｔ ① Ｃｒｉｍｉｎｉｓｉ Ｔ Ｍ Ａ，Ｗｉｎｎ Ｊ．Ｍｉｃｒｏｓｏｆｔ ｒｅｓｅａｒｃｈ ｃａｍｂｒｉｄｇｅ
ｏｂｊｅｃｔ ｒｅｃｏｇｎｉｔｉｏｎ ｉｍａｇｅ ｄａｔａｓｅｔ，ｖｅｒｓｉｏｎ ２．０．ｈｔｔｐ：／／ｒｅｓｅａｒｃｈ．
方法使用了一种基于随机森林（Ｒａｎｄｏｍ Ｆｏｒｅｓｔ）的 ｍｉｃｒｏｓｏｆｔ．ｃｏｍ／ｅｎ－ｕｓ／ｐｒｏｊｅｃｔｓ／ｏｂｊｅｃｔｃｌａｓｓｒｅｃｏｇｎｉｔｉｏｎ，２００４ ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４６７
完成了端到端的训练、预测．该方法相较于ＦＣＮ，可
以较好地解决图像边缘信息丢失的问题，对边界分割
精度有很大的提升．该方法在ＰＡＳＣＡＬ ＶＯＣ２０１２分
割数据集上的平均ＩＯＵ精度达到７４．７％．图１７是
ＣＲＦ－ＲＮＮ与ＦＣＮ、ＤｅｅｐＬａｂ在ＰＡＳＣＡＬ ＶＯＣ２０１２
分割数据集上的语义分割结果展示．
图１８ Ｐｉｎｈｅｉｒｏ等人提出的基于图像标签的
弱监督语义分割算法［７２］
３．４ 图片标题生成
图片标题生成（Ｉｍａｇｅ Ｃａｐｔｉｏｎｉｎｇ）技术，指自
动产生自然语言来描述一副图片的内容．随着深
度学习和自然语言理解领域相关技术的突破，图
片标题生成技术在２０１４～２０１６年获得了迅猛的发
展．在２０１５年微软ＣＯＣＯ图片标注竞赛中，来自微
软［７３－７４］、谷歌［７５］、多伦多大学和蒙特利尔大学［７６］、
加州大学伯克利分校［７７－７８］等研究机构的最新工作都
取得了令人惊叹的成绩．目前谷歌（基于ＣＮＮ视觉
特征和ＲＮＮ语言模型）和微软（基于区域的单词检
图１７ 在ＰＡＳＣＡＬ ＶＯＣ２０１２分割数据集上ＣＲＦ－ＲＮＮ与
测和最大熵语言模型）在技术和性能方面处于领先
ＦＣＮ、ＤｅｅｐＬａｂ的语义分割结果比较［６９］ 地位［７９］．
一部分图片描述工作使用流程化方法来描述图
为了训练能识别图像分割区域甚至每个像素的
目标分类器，大多数图像语义分割方法需要使用大量
片内容．Ｆａｎｇ等人［７３］将图片描述过程分为三步，如
精确的像素级标注数据作为训练数据．然而，因为标
图１９所示．首先利用多示例学习（Ｍｕｌｔｉｐｌｅ Ｉｎｓｔａｎｃｅ
注工作非常耗时，这类数据非常有限．根据Ｍｉｃｒｏｓｏｆｔ
Ｌｅａｒｎｉｎｇ，ＭＩＬ）方法，根据图片各个部分提取的
ＣＯＣＯ数据［５５］标注经验，精确标注每个像素点的耗
ＣＮＮ特征产生相对应的名词、动词和形容词；然后
使用最大熵语言模型（Ｍａｘｉｍｕｍ Ｅｎｔｒｏｐｙ Ｌａｎｇｕａｇｅ
时平均是标注目标检测框的１５倍．为了克服像素级
Ｍｏｄｅｌ，ＭＥＬＭ）产生图片标题；最后使用最小错误
标注的约束，部分科研工作者考虑设计新的语义分
割算法．Ｄａｉ等人［７０］提出的ＢｏｘＳｕｐ是以图像检测 率训练（Ｍｉｎｉｍｕｍ Ｅｒｒｏｒ Ｒａｔｅ Ｔｒａｉｎｉｎｇ，ＭＥＲＴ）对
所产生的可能性最高的几组句子进行打分并排序．
框的标注信息作为监督信号．ＢｏｘＳｕｐ首先使用非监
督的候选区域生成方法产生初步分割结果，然后进
Ｋｉｒｏｓ等人［８０］利用 ＣＮＮ 和 ＬＳＴＭ（Ｌｏｎｇ Ｓｈｏｒｔ－
Ｔｅｍ Ｍｅｍｏｒｙ ｎｅｔｗｏｒｋ）对图片进行编码，然后利用
一步使用检测框和ＦＣＮ得到的基于像素点的监督
信息．Ｂｅａｒｍａｎ等人［７１］使用了表示物体的点作为监 论文中提出的ＳＣ－ＮＬＭ（Ｓｔｒｕｃｔｕｒｅ－Ｃｏｎｔｅｎｔ Ｎｅｕｒａｌ
督信号，通过利用上述监督信息设计惩罚函数，约束
Ｌａｎｇｕａｇｅ Ｍｏｄｅｌ）预测句子结构来实现解码．
与以上使用流程化的方法不同，另一部分图片
训练ＦＣＮ的损失函数．Ｐｉｎｈｅｉｒｏ等人［７２］提出了一
种基于图像标签的弱监督语义分割算法，在训练过
描述工作使用端到端方法．Ｖｉｎｙａｌｓ等人［７５］受机器
翻译技术的启发，利用ＣＮＮ模型提取图片特征，
程中设计ＣＮＮ 网络使关键像素点被赋予较大权
再利用ＲＮＮ模型生成图片标题，如图２０和图２１
值，从而实现图像中各像素更为准确的标注（如图
１８所示）．
所示．Ｋａｒｐａｔｈｙ等人［７７］和 Ｍａｏ等人［８１］提出利用 ４６８ 计 算 机 学 报 ２０１９年
ｍＲＮＮ（Ｍｕｌｔｉｍｏｄａｌ Ｒｅｃｕｒｒｅｎｔ Ｎｅｕｒａｌ Ｎｅｔｏｗｒｋ）模
型生成图片标题．不同于将图片和文字映射到同一
空间，Ｃｈｅｎ等人［８２］在图片和文字描述之间直接建
立双向映射关系．Ｄｏｎａｈｕｅ等人［７８］提出的ＬＲＣＮｓ
（Ｌｏｎｇ－ｔｅｒｍ Ｒｅｃｕｒｒｅｎｔ Ｃｏｎｖｏｌｕｔｉｏｎａｌ Ｎｅｔｗｏｒｋｓ）模
型直接在可变长度的图像序列输入和可变长度的文
字输出之间建立映射关系．Ｘｕ等人［７６］提出将视觉
注意模型融合进ＬＳＴＭ模型，从而在单词生成过程
中能更好关注图像中的显著目标．最近，Ｊｉａ等人［８３］
则利用ｇＬＳＴＭ（Ｇｕｉｄｉｎｇ Ｌｏｎｇ Ｓｈｏｒｔ－ｔｅｒｍ Ｍｅｍｏｒｙ）
模型，在ＬＳＴＭ模型的基础上引入外部的语义信息
生成图像标题．
表５给出了不同图像标题生成方法在生成图像
标题性能的结果比较，评价指标采用了ＢＬＥＵ 量
度［８４］．从表４中我们看到Ｈａｒｄ－Ａｔｔｅｎｔｉｏｎ和ｇＬＳＴＭ
在 ＭＳＣＯＣＯ数据上达到最好的性能．
表５ 不同图片标题生成方法在ＭＳＣＯＣＯ上的性能比较
方法 Ｂ＠１ Ｂ＠２ Ｂ＠３ Ｂ＠４
Ｍｕｌｔｉｍｏｄａｌ ＲＮＮ［７７］ ６２．５ ４５．０ ３２．１ ２３．０
Ｇｏｏｇｌｅ ＮＩＣ［７５］ ６６．６ ４６．１ ３２．９ ２４．６
ＬＲＣＮ－ＣａｆｆｅＮｅｔ［７８］ ６２．８ ４４．２ ３０．４
ｍ＿ＲＮＮ［８４］ ６７．０ ４９．０ ３５．０ ２５．０
Ｓｏｆｔ－Ａｔｔｅｎｔｉｏｎ［７６］ ７０．７ ４９．２ ３４．４ ２４．３
Ｈａｒｄ－Ａｔｔｅｎｔｉｏｎ［７６］ ７１．８ ５０．４ ３５．７ ２５．０
ｇＬＳＴＭ［８３］ ６７．０ ４９．１ ３５．８ ２６．４
３．５ 人脸识别
计算机视觉领域一个重要的挑战问题是人脸识
别．人脸识别包含两种任务，人脸验证和人脸辨识．
人脸验证的任务是判断两张人脸照片是否属于同一
个人，属于二分类问题，随机猜的正确率是５０％．人
脸辨识的任务是将一张未知人脸图像分为 Ｎ个身
份类别之一，这是个多分类问题，随机猜的正确率是
１／Ｎ．人脸辨识更具有挑战性，其难度随着类别数的
增多而增大．人脸识别的最大挑战是如何辨别由于
光线、姿态和表情等因素引起的类内变化，以及由于
身份类别不同产生的类间变化．这两种变化分布极
为复杂且都是非线性的，传统的线性模型无法将它
们有效区分开．卷积神经网络可以通过多层的非
线性变换，尽可能多地去掉类内变化，同时保留类间
变化．
ＬＦＷ（Ｌａｂｅｌｅｄ Ｆａｃｅｓ ｉｎ ｔｈｅ Ｗｉｌｄ）［８５］是当今最
著名的人脸验证公开测试集，它是从互联网上收集
了五千多个名人的人脸照片，用于评估算法在非可
控条件下的人脸验证性能（如图２２所示）．在ＬＦＷ
测试集上，人眼的正确率是９７．５３％［８６］，而非深度学 ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４６９
习算法的最高正确率是９６．３３％［８７］，而目前深度学 ＬＦＷ达到了９９．４７％的识别率．ＦａｃｅＮｅｔ［１９］提出了
习可以达到９９．４７％的验证率［１９］．目前，许多人脸识 使用Ｔｒｉｐｌｅｔ网络结果学习人脸特征，输入样本以
别算法都是在包含大量人脸类别的离线数据集上， 两张同类图片和一张不同类图片的方式，在最后
以人脸辨识的任务通过神经网络模型学习人脸特 一层隐藏层直接使用欧氏距离来度量输入图像之
征，得到的特征再应用于人脸验证任务． 间的相似度．ＦａｃｅＮｅｔ在ＬＦＷ 数据集上验证精度
达到９９．６３％．
３．６ 行人再识别
行人目标是监控视频中最为常见也最为关注的
目标，对多个监控视频环境下行人目标的检索问题
常称为行人再识别（Ｐｅｒｓｏｎ Ｒｅ－ｉｄｅｎｔｉｆｉｃａｔｉｏｎ）问题．
在可控的环境下，依靠人脸、虹膜等生物特征进行人
再识别已经是较为成熟的技术．然而，监控视频的环
境通常非常复杂而且含有很多不可控因素（如低分辨
图２２ ＬＦＷ人脸数据集［８５］
率、遮挡、运动模糊、复杂背景等），其获取的行人图像
２０１３年，Ｓｕｎ等人［８８］采用人脸确认任务作为监 质量通常很差，因此较难提取到鲁棒的人脸特征．因
督信号，利用卷积神经网络学习人脸特征，在ＬＦＷ 此，绝大部分研究人员通过行人穿的衣服和携带的物
上取得了９２．５２％的识别率．这一结果虽然与后续 品等外貌特征来实现行人再识别．由于不同监控视频
的深度学习方法相比较低，但也超过了大多数非深 下的行人存在尺度、视角及光照等差异，可能导致不
度学习的算法．在ＣＶＰＲ ２０１４上发表的ＤｅｅｐＩＤ［１５］ 同监控视频中，不同行人目标的外貌特征比同一个行
和ＤｅｅｐＦａｃｅ［８９］，采用人脸辨识作为监督信号，在 人目标的外貌特征更相近．随着视频监控领域应用需
ＬＦＷ上取得了９７．４５％和９７．３５％的识别率．他们 求的增长，许多研究人员对行人再识别技术进行了深
利用卷积神经网络预测输入人脸图片的类别，选取 入研究．目前广泛使用的公开数据库有 ＶＩＰｅＲ［９１］、
最高的隐含层作为人脸特征（如图２３所示）．在训练 ＥＴＨ－Ｚ［９２］、ＣＵＨＫ［９３］、ＰＲＩＤ２０１１［９４］、ｉ－ＬＩＤＳ［９５］等．
过程中，神经网络需要区分大量的人脸类别（例如在 已有的行人再识别算法大致分为两类：基于距
ＤｅｅｐＩＤ中要区分１０００类人脸），因此人脸特征包含 离度量学习的方法和基于特征描述的方法．基于距
了丰富的人脸类间变化信息，而且有很强的泛化 离度量学习的方法是学习度量行人目标特征分布的
能力． 距离函数，即不同行人目标的特征距离值较大，而同
一个行人目标的特征距离值较小．基于特征描述的
方法是设计可靠、鲁棒、具有判别性的行人图像特
征，即能够有效区分不同的行人目标，且能不受尺
度、视角及光照等变化的影响．
随着Ｄｅｅｐ ＣＮＮ在计算机视觉与图像识别领
域成功应用，近年来许多学者利用 Ｄｅｅｐ ＣＮＮ 来
解决行人再识别的问题，并且在公开的数据集上
图２３ ＤｅｅｐＩＤ网络结构［１５］ 取得了最好的测试结果．例如，Ｄｉｎｇ等人［９６］提出
ＤｅｅｐＩＤ２［１６］联合使用人脸确认和人脸辨识作为 了一种三通路的网络结构，利用Ｔｒｉｐｌｅｔ Ｌｏｓｓ监督
监督信号，得到的人脸特征在保持类间变化的同时 网络的学习过程，在小数据集上取得了很好的效
最小化类内变化，从而将ＬＦＷ 上的人脸识别率提 果．ＤｅｅｐＲｅＩＤ［９７］提出了一种Ｆｉｌｔｅｒ Ｐａｉｒｉｎｇ Ｎｅｕｒａｌ
高到９９．１５％．利用 Ｔｉｔａｎ ＧＰＵ，ＤｅｅｐＩＤ２提取一幅 Ｎｅｔｗｏｒｋ（ＦＰＮＮ）来处理图像未对准、光度和几何变
人脸图像的特征只需要３５ｍｓ，而且可以离线进行． 换、遮挡和复杂背景等问题，提高了算法的鲁棒性．
经过ＰＣＡ压缩最终得到８０维的特征向量，可以用于 ｍＦｉｌｔｅｒ［９８］使用局部图像块匹配的方法学习局部特
快速人脸在线比对．在后续的工作中，ＤｅｅｐＩＤ２＋［９０］ 征，增强了特征之间的判别能力．Ａｈｍｅｄ等人［９９］提
对ＤｅｅｐＩＤ２通过加大网络结构，增加训练数据，以 出了一种改进的深度网络结构，网络输入一对行人
及在每一层都加入监督信息进行了进一步改进，在 的图像，输出两张图像的相似性．Ｙｉ等人［１００］通过一 ４７０ 计 算 机 学 报 ２０１９年
个Ｓｉａｍｅｓｅ网络学习两张图像的相似性，在每个通 Ｓｅｔ５［１０８］、Ｓｅｔ１４［１０９］上进行测试．图像超分辨率通常
道中每张输入图像被等分成三份来训练网络，训练 通过客观评价指标比如ＰＳＮＲ，ＳＳＩＭ来衡量算法
好的网络具有很强的泛化能力．Ｃｈｅｎｇ等人［１０１］在 优劣．由于客观评价指标有时无法很好和人的主观
ＣＶＰＲ ２０１６上提出利用深度卷积神经网络分别从 评价项一致，人对图片的主观评价往往更加重要．
全局和局部两个不同的角度对行人的特征进行学习 ２０１４年，Ｄｏｎｇ等人［１１０］首次提出了使用深度卷
（如图２４所示），学习得到的模型对光照、视角、分辨 积神经网络学习低分辨率图像和高分辨率图像之间
力等影响因素具有很强的鲁棒性．该研究成果在业 端对端的映射关系，进行图像超分辨率．该工作方
界公布的标准数据集的测试中取得了最好的结果， 法利用深度卷积网络强大的非线性学习能力，设
例如：在ＰＲＩＤ２０１１数据集上领先最好结果４．１个 计了包含三个卷积层的深度卷积网络，通过输入大
百分点，在ＶＩＰｅＲ数据集上领先最好结果７．２８个 量的数据样本来训练模型，进而得到比较理想的高
百分点，在ｉ－ＬＩＤＳ数据集上领先最好结果８．３个百 分辨率图像，具有更好的主观效果．在当时与最好算
分点． 法相比（放大三倍时），精度在ｓｅｔ５上ＰＳＮＲ提高了
０．４７ｄｂ，在ｓｅｔ１４上ＰＳＮＲ上提升了０．３３ｄｂ．之后
Ｄｏｎｇ等人［１１１］进一步证明加大数据量、增加训练时
间，可以有效改善训练的模型，算法ＰＳＮＲ进一步
提高０．３ｄｂ．
针对深度卷积神经网络训练慢、时间长的问题，
Ｌｉａｎｇ等人［１１２］提出了结合图像的先验知识对图像
超分辨率映射的学习过程施加约束，监督超分辨率
映射的学习过程．该方法是在原有超分辨率网络引
入了一个额外的特征提取层（见图２５），通过提取学
习图像的先验信息（梯度）来指导高分辨率图像的重
建过程．加入图像先验特征大大加速了网络的学习
过程（将近１０倍的提速），并得到了更好的图像的超
分辨率结果．２０１５年 Ｗａｎｇ等人［１１３］将稀疏先验引
入深度卷积神经网络的设计中，利用将深度卷积神
经网络级联的方法，重新提升了超分辨率结果（相比
最好结果０．１ｄｂ的提升），同时拥有更好的收敛速
度．在主观评价试验中，该方法也得到了压倒性的
优势．
３．８ 人体动作识别
图２４ Ｃｈｅｎｇ等人提出的多通道Ｄｅｅｐ ＣＮＮ网络结构［１０１］
基于视觉的人体动作识别是当前计算机视觉领
３．７ 图像超分辨率 域的一个热点问题，其主要目标是通过对摄像机获
指从一幅低分辨率图像或图像序列恢复出高分 取的视频数据进行处理和分析，识别并理解视频中
辨率的图像或图像系列．更高的图像分辨率，更精细 人的动作和行为．基于视觉的人体动作识别过程通
的细节意味着图像提供的信息越丰富．在军事侦察、 常包含以下三个步骤：首先从图像序列中检测运动
医学诊断等许多实际应用中，高分辨率的图像显得 信息并提取图像底层特征；其次是对人的动作或行
尤为重要．从低分辨率图像复原高分辨率图像是一 为模式进行建模；最后建立图像底层视觉特征和动
个欠定的病态问题．对于这一病态问题，通常采用 作行为类别等高层语义信息之间的对应关系．
引入各种先验（比如光滑先验、梯度先验等等）来 按照对时序信息的使用程度，基于视觉的人体
约束图像超分辨过程．宽泛地可以将已有方法分为 动作识别方法可以划分为两类：时空特征方法和时
三类，基于插值［１０２］、基于重建［１０３－１０４］和基于学习的 序推理方法．基于时空特征的人体动作识别方法在
方法［１０５－１０７．基于超分辨率算法会在自然图像数据集 视频序列中提取有效的动作特征，这类方法主要解 ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４７１
图２５ 结合图像先验的超分辨率多通道深度卷积神经网络结构［１１２］
决简单动作的识别，可以分为基于局部特征［１１４－１１６］、
征．ＰＣＮＮ对所有静态图像的外观特征和光流特征
基于时空体模型［１１７－１１８］和基于时空轨迹特征［１１９－１２０］ 进行聚合，生成整个动作的外观和光流特征描述．
等方法．基于时序推理的人体动作识别方法在简单 Ｋａｒｐａｔｈｙ等人［１３４］利用局部时空信息构建一个多尺
行为识别结果基础上考虑到简单行为之间的时序 度的卷积神经网络，以提取视频中人体的动作信息．
关联，可以分为统计模型方法［１２１－１２２］和句法模型方
如图２６所示，网络输入是两路不同尺度大小的视
法［１２３－１２５］．目前国内外有多个公开人体动作数据库
频：原始分辨率的视频和对视频中心裁切的高分辨
用于验证不同动作识别算法的性能，常用的有：
率视频．两路视频经过相同的卷积层、正则层和采样
Ｗｅｉｚｍａｎ［１２６］、ＫＴＨ［１２７］、Ｈｏｌｌｙｗｏｏｄ［１２８］、ＵＣＦ１０１［１２９］和
层后，最后合并成两个全连接层．该方法在ＵＣＦ１０１
ＨＭＤＢ－５１［１３０］等．
动作识别数据集提高了近２０个百分点．Ｓｉｍｏｎｙａｎ
利用卷积神经网络学习到的图像特征具有一定
等人［１３５］提出的人体动作识别方法使用双路卷积神
的语义信息，近几年被广泛应用于人体动作识别这
经网络的架构，分别处理静态帧图像和多帧图像．其
一任务中．Ｊｉ等人［１３１］提出了一种３ＤＣＮＮ人体动
中，静态帧图像使用单帧图像信息以提取动作在图
作识别方法，通过执行三维卷积计算，在相邻连续图
像的空间信息，多帧图像使用多帧图像的光流信息
像序列上从时间和空间两个维度提取动作特征．３Ｄ
ＣＮＮ以多个通道从输入图像帧采集特征信息，最后
合并多个通道的特征信息形成最终的动作特征 ．
Ｖａｒｏｌ等人［１３２］提出了Ｌｏｎｇ－ｔｅｒｍ Ｔｅｍｐｏｒａｌ Ｃｏｎｖｏ－
ｌｕｔｉｏｎｓ（ＬＴＣ）操作，与ＣＮＮ结合能在更长时间窗
口内使用３ＤＣＮＮ，进一步提高了动作识别的性能．
Ｃｈｅｒｏｎ等人［１３３］提出一种基于静态图像姿态（Ｐｏｓｅ－
ｂａｓｅｄ ＣＮＮ，ＰＣＮＮ）的人体动作识别方法．该方法
在视频序列中跟踪人体及人体每个部位，并在每张
静态图像中提取每个人体部位的外观特征和光流特 图２６ 双通道多尺度深度卷积神经网络结构［１３４］ ４７２ 计 算 机 学 报 ２０１９年
以提取动作的时间信息．两路图像数据都经过深度 的结构框图如图２７所示．Ｌａｉ等人［１４５］提出的图像
卷积神经网络提取特征，然后使用ＳＶＭ 分类器识 检索方法同样利用深度卷积神经网络同时进行特征
别具体动作． 学习和哈希编码．该方法设计了一种分离编码模块，
３．９ 图像检索 将图像特征划分为几个部分，每个部分负责学习哈
随着数码相机、手机等数字化设备的广泛普及， 希码中的一位．网络使用ｔｒｉｐｌｅｔ损失函数进行学
存储技术和网络共享技术的快速发展，网络上的图 习．Ｌｉｕ等人［１４６］提出的快速图像检索算法利用图像
像资源以爆炸性速度快增长．图像检索研究的热点 对的监督信息，提出了一种正则项对深度卷积神经
问题就是如何从大规模图像数据库中准确、快速地 网络进行约束，使神经网络的输出接近二值编码，增
检索到相同或相似主题的图像数据． 加了图像检索效率．
图像检索通常划分为两个方向：基于文本的图像
检索（Ｔｅｘｔ Ｂａｓｅｄ Ｉｍａｇｅ Ｒｅｔｒｉｅｖａｌ，ＴＢＩＲ）［１３６－１３８］和基
于内容的图像检索（Ｃｏｎｔｅｎｔ Ｂａｓｅｄ Ｉｍａｇｅ Ｒｅｔｒｉｅｖａｌ，
ＣＢＩＲ）［１３９－１４１］．ＴＢＩＲ简称“以字搜图”，其目标是在
图像数据库中查询与检索关键字相关的图像．目前
谷歌、雅虎、百度等搜索引擎主要采用的是ＴＢＩＲ技
术，该技术需要事先对大规模图像数据库中的每张
图像进行关键词标注，因此依赖于高精度的图像自
动标注算法．ＣＢＩＲ简称“以图搜图”，是直接利用图
像的视觉特征进行分析和检索图像，其重点是对检
索图像与数据库中图像进行相似性匹配．ＣＢＩＲ技
图２７ ＤＳＲＨ图像检索方法的流程示意图［１４４］
术的特点是利用图像自由的客观视觉特性，不需要
人工进行干预，利用计算机可以对图像特征进行自
４ 视觉认知的理论启示
动提取和存储．目前出现了许多基于ＣＢＩＲ技术的
检索引擎，如Ｐｉｃｉｔｕｐ、ＴｉｎＥｙｅ、谷歌的按图搜索、百
人类视觉系统是至今为止所知的功能最强大和
度识图等．
传统的 ＣＢＩＲ方法采用手动设计的特征（如
完善的生物视觉系统，是人脑感知外部环境的最主
ＳＩＦＴ、ＳＵＲＦ、ＨＯＧ、ＧＩＳＴ等）和利用词袋（Ｂａｇ－ｏｆ－
要方式，人类获取外部世界的信息约７０％来源于视
Ｗｏｒｄｓ，ＢｏＷ）模型表示图像，并使用向量之间的距
觉．利用非凡的脑信息处理能力，人类能够快速高效
离计算图像间的相似性，从而得到初步检索结果．近
地从客观世界的杂乱场景中抽取有效信息，分析感
几年，许多新的ＣＢＩＲ方法利用卷积神经网络学习
兴趣的目标或区域，形成对视觉场景内容的高度理
更具有表达能力的图像特征．
解和认知．神经网络的研究与人类视觉的研究密切
Ｘｉａ等人提出了一种名为ＣＮＮＨ（Ｃｏｎｖｏｌｕｔｉｏｎａｌ
相关，借鉴人类视觉认知机制的相关计算理论，是未
Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋ Ｈａｓｈｉｎｇ）的有监督深度哈希算 来研究提升神经网络性能的一个方向．
法［１４２］．ＣＮＮＨ利用训练图像之间的相似性分解相 ４．１ 视觉信息分层处理
似性矩阵，得到训练图像的二值编码，进而利用卷积 １９５８年，约翰霍普金斯大学的Ｈｕｂｅｌ和 Ｗｉｅｓｅｌ
神经网络对所获得的二值编码进行拟合，同时学习
研究发现，在初级视皮层中存在两种细胞：简单细
得到更鲁棒的图像特征．Ｗａｎ等人［１４３］同样利用卷 胞和复杂细胞，这两种细胞承担不同层次的视觉
积神经网络进行特征学习用于解决图像检索问题，
感知功能［１］．他们的研究还发现，视觉系统的信息处
作者评价了不同卷积神经网络学习策略对图像检索
理———可视皮层是分级的［１４７］．视觉信号传递到初
性能的影响．文献 ［１４４］提出了一种称为 ＤＳＲＨ 级视皮层（Ｖ１区）之后，低级的 Ｖ１区提取边缘特
（Ｄｅｅｐ Ｓｅｍａｎｔｉｃ Ｒａｎｋｉｎｇ Ｈａｓｈｉｎｇ）的方法，将图像
征，到第二视区（Ｖ２）提取目标的局部形状或者目标
的部件，再继续向更高级的视觉皮层传递并获取图
检索任务转化为解决图像相关性排序问题 ．在
ＤＳＲＨ中，深度卷积神经网络用于学习图像的特征
像的整体形状．高层特征是对低层特征的聚类，高层
表示，同时将所学到的特征映射到哈希码．ＤＳＲＨ
的特征表示较于低层特征更为复杂、抽象，且更能表 ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４７３
现语义信息或者目标类别，因而人脑能够理解十分 取样层，学习的图像特征越具有不变性．然而，人脑
复杂和抽象的内容． 视觉认知过程比ＣＮＮ要复杂得多，而前者的许多
除了 Ｈｕｂｅｌ－Ｗｉｅｓｅｌ模 型 的 发 现，Ｍｉｓｈｋｉｎ， 特性ＣＮＮ多不具备［１５１，１５５－１５６］．
Ｕｎｇｅｒｌｅｉｄｅｒ和 Ｍａｃｋｏ于１９８３年在猴子的纹状体 ４．２ “大范围优先”的视觉认知过程
皮层上发现视觉信息在皮层的逐级传递中可以大体 基于以上生理学事实，以Ｔｒｅｉｓｍａｎ的特征整合
分成两个通路，而 Ｖ１皮层是两条通路的发源 理论［１５７］以及 Ｍａｒｒ的计算视觉理论［１５８］为代表的
地［１４８－１５０］．这两条通路一条通向腹侧，被称为腹侧通 “局部优先”观点，认为视觉图像起初被分解为基本
路（Ｖｅｎｔｒａｌ Ｓｔｒｅａｍ，如图２８所示［１５１］），沿着大脑皮 的成分和单元，然后单个并行处理，最后整合到一起
层的枕颞叶分布，包括纹状体皮层、前纹状体皮层和 对整个图像内容进行识别，即视觉认知过程是先识
下颞叶．另一条通向背侧，被称为背侧通路（Ｄｏｒｓａｌ 别局部而后识别整体内容．然而越来越多的研究表
Ｓｔｒｅａｍ），沿着枕顶叶分布，包括纹状体皮层、前纹状 明，视觉认知过程始于视觉系统的顶层区域，遵循先
体皮层和下顶叶．背侧通路主要负责处理视觉刺激 整体后局部的顺序．
的位置、运动、三维结构等信息，而腹侧通路则负责 与当时流行的从局部到整体的“局部优先”思想
提取不变性特征，实现对物体及场景种类的识别．研 相反，Ｎａｖｏｎ于１９７７年提出了著名的“大范围优先”
究结果进一步表明，腹侧通路主要由 Ｖ１、Ｖ２、Ｖ４、 理论［１５９］．Ｎａｖｏｎ使用复合刺激来描述图形的整体
ＩＴ这四层脑区构成．ＩＴ脑区又可以进一步分割为 和局部性质，每个复合刺激是由许多小字母组成的
ＰＩＴ、ＣＩＴ及ＡＩＴ三个子层（参见图２８）．视觉刺激 大字母图形，如图２９中的Ａ和Ｄ是大字母和小字
通过人眼中的视网膜被转换成神经信号，通过ＬＧＮ 母形状一致，而Ｂ和Ｃ则形状不一致．Ｎａｖｏｎ将小
细胞进行简单的预处理后到达腹侧通路的 Ｖ１层． 字母的性质描述为图形的局部性质，大字母的性质
经过Ｖ１到ＩＴ脑区的逐层处理，由视网膜传来的原 描述为整体性质．在视觉辨别实验中，被试需要辨别
始神经信号被逐渐转换成具有高度抽象度及区分能 大字母和小字母是 Ｈ 还是Ｓ．实验发现，被试辨别
力的图像特征．一般认为，ＩＴ层中的图像特征表达 大字母的反应时（Ｒｅａｃｔｉｏｎ Ｔｉｍｅ，ＲＴ）明显比小字
对物体的位移、旋转、大小、姿态、视角、光照等变化， 母的ＲＴ短，而被试在辨别小字母时当大小字母一
已经拥有相当程度的不变性，已经具备准确、快速地 致时ＲＴ较短，不一致时则ＲＴ较长（大字母对小字
识别物体及场景类别的能力［１５２－１５４］．视觉皮层分为 母有干扰作用）；相反，小字母对辨别大字母的ＲＴ
腹侧和背侧两条通路的理论，曾是早期认知科学领 几乎不不造成影响．根据以上实验结果，Ｎａｖｏｎ认为
域的一大成就． 视知觉系统首先处理大范围整体性质，然后再加工
局部性质．后来的心理学家对强调整体性质的大
范围优先性理论进行了深入的研究并对其进一步
完善．
图２８ 人脑腹侧通路［１５１］
基于Ｈｕｂｅｌ－Ｗｉｅｓｅｌ模型实现的卷积神经网络
图２９ Ｎａｖｏｎ使用的复合刺激图形［１５９］
基本模拟人类视觉系统的信息分层处理方式．卷积
层、取样层分别对应一种简单细胞、复杂细胞；越是 “大范围优先”理论认为人脑视觉认知总是遵循
上层的卷积层，学习的图像特征越复杂；越是上层的 先整体后局部的顺序．当一幅图呈现给被试时，被试 ４７４ 计 算 机 学 报 ２０１９年
最初（１００ｍｓ以内）所认知的只是图像的全局内容， 现，在视觉系统中，拓扑性质差异被最先检测出来，
如图像中有无物体出现，物体的类别等．这个认知过 其次是射影和仿射性质，最后才是几何性质最不稳
程称作Ｓｐｒｅａｄ Ａｔｔｅｎｔｉｏｎ，负责对图像全局内容的 定的欧氏性质被检测出来［１６７］．
识别．被试对图像细节的认知一般发生在２５０ｍｓ以 ２００２年，Ｈｏｃｈｓｔｅｉｎ和 Ａｈｉｓｓａｒ提出了一种视
后，根据认知任务的难易度，需要不断移动眼球，这 觉认知学习的自下而上和自上而下的双信息处理过
时对图像全局的认知度会大幅下降．这个认知过程 程［１６８－１６９］，如图３１所示．他们认为在采集到视觉信
称作Ｆｏｃｕｓｅｄ Ａｔｔｅｎｔｉｏｎ．那么视觉系统是对图像全 号后，视觉系统一开始进行自下而上的多层分级的
局认知后是如何再进行局部认知呢？是否在全局认 视觉信息处理，这一过程是无意识的、自动发生的．
知脑区上层存在更高层级脑区负责局部认知？ 视觉的全局认知发生在视觉系统的高级区域（如
１９８２年，我国学者陈霖在《Ｓｃｉｅｎｃｅ》杂志上发表 图２８中ＩＴ脑区），它是利用从Ｖ１、Ｖ２、再到Ｖ４的
了题为《视知觉的拓扑结构》论文［１６０］，首次创新性 逐层特征提取所取得的、具有高度抽象性及不变性
提出了“大范围优先”的拓扑知觉理论，并在此后的 特征来实现的．ＩＴ层的特征具有高度抽象性以及语
３０年时间里，用令人信服的实验不断完善和论证 义或者类别表达能力，但不具有输入图像的局部细
这一理论，使之被越来越多的认知科学研究者所 节表达，因而只适用于视觉的全局认知．当视觉系统
接受．陈霖认为，在初期阶段视知觉系统对大范围 需要进行局部细节认知时，高级区域沿自上而下的
的拓扑性质更敏感，而不是局部特性．陈霖用论文 信息通路逐层展开认知，并且认知过程是以先拓扑
和实验［１６１－１６３］解释了视觉系统的一个基本功能是
性质、射影性质、再到仿射性质、欧式性质的顺序进
感知拓扑性质，并且揭示了图形知觉从大范围到
行的．这个理论解释了上述拓扑知觉试验中，为什么
局部的几何层次感知顺序，其代表性成果发表在
拓扑性质差异被最先检测出来，其次是射影性质和
２００３年《Ｓｃｉｅｎｃｅ》［１６４］，２００７年《ＰＮＡＳ》［１６５］，２０１０年
仿射性质，最后才是欧氏性质被检测出来这个视觉系
《ＰＮＡＳ》［１６６］等期刊上．
统的认知特性．他们发现，这个理论在解释大量研究
支持拓扑知觉理论的其中一个实验是如图３０
结果时（包括似是而非的研究数据）被证明很有用．
所示的四选一实验［１６３］．按几何学的不变性分类，图
中Ａ、Ｂ、Ｃ、Ｄ分别代表了反映欧氏性质、仿射性质、
射影性质以及拓扑性质的差异的四种不同刺激．每
个刺激由四个象限组成，每个象限中只包含一种形
状的小图形，其中三个象限中的图形形状一致，而第
四个象限中的图形与其他三个不一致．被试要求在
保证正确的前提下快速找出形状不一样的象限位
置．通过比较检测这些性质的反应时，我们可以发
图３１ 人脑在视觉认知过程中自下而上和自上而下
的双向信息处理通道［１６８］
５ 展 望
人工神经网络是由基本的数学计算单元及其交
互联接构成的一种网络计算结构，用来模拟人脑中
信息的处理过程，让机器通过学习训练机制主动获
取数据中所蕴含的规律．本文围绕其中的一种学习
模型———深度卷积神经网路，介绍了现阶段提升深
度卷积网络性能的技术方法和在计算机视觉领域内
图３０ 四选一实验的反应时（ＲＴ）结果，对拓扑差异的
识别时间要短于非拓扑差异的识别时间［１６３］ 的应用，并分析了人脑视觉机制的特点和对当前计 ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４７５
算模型的一些理论启示． （４）优化神经网络模型，降低计算复杂度
尽管当前深度卷积网络较传统机器学习方法有 当前神经网络模型依赖于高性能的ＧＰＵ进行
了很大的提高，但不可忽略的是，它们与人脑视觉系 计算，而对某些特定任务需要ＧＰＵ集群进行并行
统还是有非常大的差距，从根本上并没有解决视觉 加速计算，这对硬件平台提出了更高的要求．另外，
认知的根本问题．未来基于深度卷积神经网络的类 较高的计算复杂度也限制了神经网络模型在嵌入式
脑智能研究仍有许多亟待解决的问题与挑战： 产品上的集成开发．研究低能耗、高精度的神经网络
（１）借鉴视觉认知的研究成果，改进神经网络 模型是当前产业化过程的当务之急．
的模型结构 （５）研究卷积神经网络的迁移和泛化能力
借鉴人脑视觉系统的特性去研究和改进已有神 当前卷积神经网络模型通常在某类数据集上训
经网络的结构，让机器获得更高层次的类脑智能，是 练，在同一数据集上测试性能表现良好，然而在其他
未来研究的其中一个重要研究方向．现有的神经网 数据集尤其是互联网大规模数据上的性能则会大幅
络都是借鉴人类视觉系统自下而上对图像进行全局
下降．研究迁移学习和在线学习，对神经网络模型进
内容识别的特性，对输入图像进行特征提取的过程 行不断的迁移和更新，增强神经网络的泛化能力是
均为一个单向过程，但人脑对于输入图像的特征提 未来的一个研究方向．
取和认知过程是一个包含自下而上和自上而下的双
参 考 文 献
向迭代过程．如何模拟人脑视觉系统自上而下识别
图像局部细节的特性［１６８－１７０］，改善现有神经网络结
构，以提高检测、定位、分割等任务的精度，值得进一 ［１］ Ｈｕｂｅｌ Ｄ Ｈ，Ｗｉｅｓｅｌ Ｔ Ｎ．Ｒｅｃｅｐｔｉｖｅ ｆｉｅｌｄｓ，ｂｉｎｏｃｕｌａｒ ｉｎｔｅｒａｃｔｉｏｎ
ａｎｄ ｆｕｎｃｔｉｏｎａｌ ａｒｃｈｉｔｅｃｔｕｒｅ ｉｎ ｔｈｅ ｃａｔ’ｓ ｖｉｓｕａｌ ｃｏｒｔｅｘ．Ｔｈｅ
步研究．
Ｊｏｕｒｎａｌ ｏｆ Ｐｈｙｓｉｏｌｏｇｙ，１９６２，１６０（１）：１０６－１５４
（２）基于无监督式特征学习的研究
［２］ Ｆｕｋｕｓｈｉｍａ Ｋ，Ｍｉｙａｋｅ Ｓ，Ｉｔｏ Ｔ．Ｎｅｏｃｏｇｎｉｔｒｏｎ：Ａ ｎｅｕｒａｌ
迄今为止，深度学习中的监督式特征学习取得 ｎｅｔｗｏｒｋ ｍｏｄｅｌ ｆｏｒ ａ ｍｅｃｈａｎｉｓｍ ｏｆ ｖｉｓｕａｌ ｐａｔｔｅｒｎ ｒｅｃｏｇｎｉｔｉｏｎ．
了非常大的成功，但是监督式特征学习算法的训练 ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｓｙｓｔｅｍｓ，Ｍａｎ，ａｎｄ Ｃｙｂｅｒｎｅｔｉｃｓ，
过程往往依赖于百万级以上的标注数据，通常需要
１９８３，１３（５）：８２６－８３４
［３］ Ｆｕｋｕｓｈｉｍａ Ｋ．Ｎｅｏｃｏｇｎｉｔｒｏｎ：Ａ ｓｅｌｆ－ｏｒｇａｎｉｚｉｎｇ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ
花费很多的人力物力完成数据标注．然而，在人类和
ｍｏｄｅｌ ｆｏｒ ａ ｍｅｃｈａｎｉｓｍ ｏｆ ｐａｔｔｅｒｎ ｒｅｃｏｇｎｉｔｉｏｎ ｕｎａｆｆｅｃｔｅｄ
动物的学习过程中，无监督式学习一直占主导作用： ｂｙ ｓｈｉｆｔ ｉｎ ｐｏｓｉｔｉｏｎ．Ｂｉｏｏｌｏｇｉｃａｌ Ｃｙｂｅｒｎｅｔｉｃｓ，１９８０，３６（４）：
我们通过观察和亲身体验来发现世界，而并不需要 １９３－２０２
其他人告诉我们每一件事物的名称． ［４］ ＬｅＣｕｎ Ｙ，Ｊａｃｋｅｌ Ｌ，Ｂｏｔｔｏｕ Ｌ，ｅｔ ａｌ．Ｃｏｍｐａｒｉｓｏｎ ｏｆ ｌｅａｒｎｉｎｇ
ａｌｇｏｒｉｔｈｍｓ ｆｏｒ ｈａｎｄｗｒｉｔｔｅｎ ｄｉｇｉｔ ｒｅｃｏｇｎｉｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
近几年，虽然众多研究人员开始关注无监督学
ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ａｒｔｉｆｉｃｉａｌ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ．
习这一领域，有关无监督特征学习算法的研究取得
Ｐａｒｉｓ，Ｆｒａｎｃｅ，１９９５，６０：５３－６０
了一定的成果，但其对特征进行高效表达的能力相 ［５］ ＬｅＣｕｎ Ｙ，Ｊａｃｋｅｌ Ｌ Ｄ，Ｂｏｔｔｏｕ Ｌ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ ａｌｇｏｒｉｔｈｍｓ
对于监督式特征学习算法仍差距尚远．如何才能使 ｆｏｒ ｃｌａｓｓｉｆｉｃａｔｉｏｎ：Ａ ｃｏｍｐａｒｉｓｏｎ ｏｎ ｈａｎｄｗｒｉｔｔｅｎ ｄｉｇｉｔ ｒｅｃｏｇｎｉｔｉｏｎ
机器具备像人类和动物一样仅仅通过观察世界就能
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ：ｔｈｅ Ｓｔａｔｉｓｔｉｃａｌ
Ｍｅｃｈａｎｉｃｓ Ｐｅｒｓｐｅｃｔｉｖｅ．Ｐｏｈａｎｇ，Ｋｏｒｅａ，１９９５：２６１－２７６
获取常识的无监督学习能力，成为未来的一个重要
［６］ Ｋｒｉｚｈｅｖｓｋｙ Ａ，Ｓｕｔｓｋｅｖｅｒ Ｉ，Ｈｉｎｔｏｎ Ｇ Ｅ．ＩｍａｇｅＮｅｔ ｃｌａｓｓｉｆｉ－
发展方向［１７１］．
ｃａｔｉｏｎ ｗｉｔｈ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
（３）利用海量增加的数据进一步提高卷积神经 ｏｆ ｔｈｅ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ，Ｌａｋｅ Ｔａｈｏｅ，
网络的特征学习能力 ＵＳＡ，２０１２：１０９７－１１０５
［７］ Ｒｕｍｅｌｈａｒｔ Ｄ Ｅ，Ｈｉｎｔｏｎ Ｇ Ｅ，Ｗｉｌｌｉａｍｓ Ｒ Ｊ．Ｌｅａｒｎｉｎｇ
深度学习取得成功的一大关键因素是网络上海
ｉｎｔｅｒｎａｌ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｂｙ ｅｒｒｏｒ ｐｒｏｐａｇａｔｉｏｎ．Ｕｎｉｖｅｒｓｉｔｙ ｏｆ
量可用的数据．当前，在工程应用及生物神经领域存
Ｃａｌｉｆｏｒｎｉａ Ｓａｎ Ｄｉｅｇｏ，ＵＳＡ：Ｔｅｃｈｎｉｃａｌ Ｒｅｐｏｒｔ ＩＣＳ－８５０６，
在有指数增长的海量复杂数据，以文字、图片、视频、
１９８５
音频、基金数据等不同模态呈现出来，具有绝然不同 ［８］ Ｒｕｍｅｌｈａｒｔ Ｄ Ｅ，Ｈｉｎｔｏｎ Ｇ Ｅ，Ｗｉｌｌｉａｍｓ Ｒ Ｊ．Ｌｅａｒｎｉｎｇ
的数据分布．这对神经网络模型的训练复杂度、参数 ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ ｂｙ ｂａｃｋ－ｐｒｏｐａｇａｔｉｎｇ ｅｒｒｏｒｓ．Ｎａｔｕｒｅ，１９８６，
３２３：５３３－５３６
选取、结构设计、时间复杂度等方面的平衡都带来了
［９］ Ｓｉｍｏｎｙａｎ Ｋ，Ｚｉｓｓｅｒｍａｎ Ａ．Ｖｅｒｙ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ
新的挑战．因此，如何充分利用大数据来设计更具有
ｆｏｒ ｌａｒｇｅ－ｓｃａｌｅ ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：
特征表达能力的神经网络模型，还值得进一步研究． １４０９．１５５６，２０１４ ４７６ 计 算 机 学 报 ２０１９年
［１０］ Ｓｚｅｇｅｄｙ Ｃ，Ｌｉｕ Ｗ，Ｊｉａ Ｙ，ｅｔ ａｌ．Ｇｏｉｎｇ ｄｅｅｐｅｒ ｗｉｔｈ ｃｏｎｖｏｌｕｔｉｏｎｓ／／ ［２４］ Ｗａｎ Ｌ，Ｚｅｉｌｅｒ Ｍ，Ｚｈａｎｇ Ｓ，ｅｔ ａｌ．Ｒｅｇｕｌａｒｉｚａｔｉｏｎ ｏｆ ｎｅｕｒａｌ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ ｎｅｔｗｏｒｋｓ ｕｓｉｎｇ ＤｒｏｐＣｏｎｎｅｃｔ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ
Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：１－９ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ａｔｌａｎｔａ，ＵＳＡ，２０１３：
［１１］ Ｈｅ Ｋ，Ｚｈａｎｇ Ｘ，Ｒｅｎ Ｓ，Ｓｕｎ Ｊ．Ｄｅｅｐ ｒｅｓｉｄｕａｌ ｌｅａｒｎｉｎｇ ｆｏｒ １０５８－１０６６
ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ［２５］ Ｇｏｏｄｆｅｌｌｏｗ Ｉ Ｊ，Ｗａｒｄｅ－Ｆａｒｌｅｙ Ｄ，Ｍｉｒｚａ Ｍ，ｅｔ ａｌ．Ｍａｘｏｕｔ
Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｌａｓ Ｖｅｇａｓ，ＵＳＡ， ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
２０１６：７７０－７７８ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ａｔｌａｎｔａ，ＵＳＡ，２０１３：１３１９－１３２７
［１２］ ＬｅＣｕｎ Ｙ，Ｂｏｔｔｏｕ Ｌ，Ｂｅｎｇｉｏ Ｙ，Ｈａｆｆｎｅｒ Ｐ．Ｇｒａｄｉｅｎｔ－ｂａｓｅｄ ［２６］ Ｌｉ Ｆｅｉ－Ｆｅｉ，Ｆｅｒｇｕｓ Ｒ，Ｐｅｒｏｎａ Ｐ．Ｌｅａｒｎｉｎｇ ｇｅｎｅｒａｔｉｖｅ ｖｉｓｕａｌ
ｍｏｄｅｌｓ ｆｒｏｍ ｆｅｗ ｔｒａｉｎｉｎｇ ｅｘａｍｐｌｅｓ：Ａｎ ｉｎｃｒｅｍｅｎｔａｌ Ｂａｙｅｓｉａｎ
ｌｅａｒｎｉｎｇ ａｐｐｌｉｅｄ ｔｏ ｄｏｃｕｍｅｎｔ ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ＩＥＥＥ，１９９８，８６（１１）：２２７８－２３２４ ａｐｐｒｏａｃｈ ｔｅｓｔｅｄ ｏｎ １０１ｏｂｊｅｃｔ ｃａｔｅｇｏｒｉｅｓ．Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ
ａｎｄ Ｉｍａｇｅ Ｕｎｄｅｒｓｔａｎｄｉｎｇ，２００７，１０６（１）：５９－７０
［１３］Ｉｏｆｆｅ Ｓ，Ｓｚｅｇｅｄｙ Ｃ．Ｂａｔｃｈ ｎｏｒｍａｌｉｚａｔｉｏｎ：Ａｃｃｅｌｅｒａｔｉｎｇ ｄｅｅｐ
［２７］ Ｔｏｒｒａｌｂａ Ａ，Ｆｅｒｇｕｓ Ｒ，Ｆｒｅｅｍａｎ Ｗ Ｔ．８０ｍｉｌｌｉｏｎ ｔｉｎｙ ｉｍａｇｅｓ：
ｎｅｔｗｏｒｋ ｔｒａｉｎｉｎｇ ｂｙ ｒｅｄｕｃｉｎｇ ｉｎｔｅｒｎａｌ ｃｏｖａｒｉａｔｅ ｓｈｉｆｔ／／
Ａ ｌａｒｇｅ ｄａｔａ ｓｅｔ ｆｏｒ ｎｏｎｐａｒａｍｅｔｒｉｃ ｏｂｊｅｃｔ ａｎｄ ｓｃｅｎｅ ｒｅｃｏｇｎｉｔｉｏｎ．
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ
ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，
Ｌｅａｒｎｉｎｇ．Ｌｉｌｌｅ，Ｆｒａｎｃｅ，２０１５：４４８－４５６
２００８，３０（１１）：１９５８－１９７０
［１４］ Ｈｅ Ｋ，Ｚｈａｎｇ Ｘ，Ｒｅｎ Ｓ，Ｓｕｎ Ｊ．Ｄｅｌｖｉｎｇ ｄｅｅｐ ｉｎｔｏ ｒｅｃｔｉｆｉｅｒｓ：
［２８］ Ｘｉａｏ Ｊ，Ｈａｙｓ Ｊ，Ｅｈｉｎｇｅｒ Ｋ Ａ，ｅｔ ａｌ．Ｓｕｎ ｄａｔａｂａｓｅ：Ｌａｒｇｅ－
Ｓｕｒｐａｓｓｉｎｇ ｈｕｍａｎ－ｌｅｖｅｌ ｐｅｒｆｏｒｍａｎｃｅ ｏｎ ｉｍａｇｅｎｅｔ ｃｌａｓｓｉｆｉｃａｔｉｏｎ／／
ｓｃａｌｅ ｓｃｅｎｅ ｒｅｃｏｇｎｉｔｉｏｎ ｆｒｏｍ ａｂｂｅｙ ｔｏ ｚｏｏ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ
ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
Ｖｉｓｉｏｎ．Ｓａｎｔｉａｇｏ，Ｃｈｉｌｅ，２０１５：１０２６－１０３４
Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ，２０１０：３４８５－３４９２
［１５］ Ｓｕｎ Ｙ，Ｗａｎｇ Ｘ，Ｔａｎｇ Ｘ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆａｃｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ［２９］ Ｄｅｎｇ Ｊ，Ｄｏｎｇ Ｗ，Ｓｏｃｈｅｒ Ｒ，ｅｔ ａｌ．ＩｍａｇｅＮｅｔ：Ａ ｌａｒｇｅ－ｓｃａｌｅ
ｆｒｏｍ ｐｒｅｄｉｃｔｉｎｇ １０，０００ｃｌａｓｓｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ ｈｉｅｒａｒｃｈｉｃａｌ ｉｍａｇｅ ｄａｔａｂａｓｅ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ． ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｍｉａｍｉ，ＵＳＡ，
Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４：１８９１－１８９８
２００９：２４８－２５５
［１６］ Ｓｕｎ Ｙ，Ｃｈｅｎ Ｙ，Ｗａｎｇ Ｘ，Ｔａｎｇ Ｘ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆａｃｅ ｒｅｐｒｅ－ ［３０］ Ｐａｐａｇｅｏｒｇｉｏｕ Ｃ Ｐ，Ｏｒｅｎ Ｍ，Ｐｏｇｇｉｏ Ｔ．Ａ ｇｅｎｅｒａｌ ｆｒａｍｅｗｏｒｋ
ｓｅｎｔａｔｉｏｎ ｂｙ ｊｏｉｎｔ ｉｄｅｎｔｉｆｉｃａｔｉｏｎ－ｖｅｒｉｆｉｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｆｏｒ ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ
ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ， ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｂｏｍｂａｙ，Ｉｎｄｉａ，１９９８：５５５－５６２
Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，２０１４：１９８８－１９９６ ［３１］ Ｌｏｗｅ Ｄ Ｇ．Ｄｉｓｔｉｎｃｔｉｖｅ ｉｍａｇｅ ｆｅａｔｕｒｅｓ ｆｒｏｍ ｓｃａｌｅ－ｉｎｖａｒｉａｎｔ
［１７］ Ｓｕｎ Ｙ，Ｌｉａｎｇ Ｄ，Ｗａｎｇ Ｘ，Ｔａｎｇ Ｘ．ＤｅｅｐｉＤ３：Ｆａｃｅ ｒｅｃｏｇｎｉｔｉｏｎ ｋｅｙｐｏｉｎｔｓ．Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ，２００４，
ｗｉｔｈ ｖｅｒｙ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ： ６０（２）：９１－１１０
１５０２．００８７３，２０１５ ［３２］ Ｋｅ Ｙ，Ｓｕｋｔｈａｎｋａｒ Ｒ．ＰＣＡ－ＳＩＦＴ：Ａ ｍｏｒｅ ｄｉｓｔｉｎｃｔｉｖｅ
［１８］ Ｔａｉｇｍａｎ Ｙ，Ｙａｎｇ Ｍ，Ｒａｎｚａｔｏ Ｍ Ａ，ｅｔ ａｌ．ＤｅｅｐＦａｃｅ： ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｆｏｒ ｌｏｃａｌ ｉｍａｇｅ ｄｅｓｃｒｉｐｔｏｒｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｃｌｏｓｉｎｇ ｔｈｅ ｇａｐ ｔｏ ｈｕｍａｎ－ｌｅｖｅｌ ｐｅｒｆｏｒｍａｎｃｅ ｉｎ ｆａｃｅ ｖｅｒｉｆｉｃａｔｉｏｎ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ Ｗａｓｈｉｎｇｔｏｎ，ＵＳＡ，２００４：５０６－５１３
ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４：１７０１－１７０８ ［３３］ Ｂａｙ Ｈ，Ｔｕｙｔｅｌａａｒｓ Ｔ，Ｖａｎ Ｇｏｏｌ Ｌ．ＳＵＲＦ：Ｓｐｅｅｄｅｄ ｕｐ
ｒｏｂｕｓｔ ｆｅａｔｕｒｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｅｕｒｏｐｅａｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｆ
［１９］ Ｓｃｈｒｏｆｆ Ｆ，Ｋａｌｅｎｉｃｈｅｎｋｏ Ｄ，Ｐｈｉｌｂｉｎ Ｊ．ＦａｃｅＮｅｔ：Ａ ｕｎｉｆｉｅｄ
Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｇｒａｚ，Ａｕｓｔｒｉａ，２００６：４０４－４１７
ｅｍｂｅｄｄｉｎｇ ｆｏｒ ｆａｃｅ ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｃｌｕｓｔｅｒｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ
［３４］ Ｖｉｏｌａ Ｐ，Ｊｏｎｅｓ Ｍ．Ｒａｐｉｄ ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ ｕｓｉｎｇ ａ ｂｏｏｓｔｅｄ
ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
ｃａｓｃａｄｅ ｏｆ ｓｉｍｐｌｅ ｆｅａｔｕｒｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：８１５－８２３
ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｋａｕａｉ，ＵＳＡ，
［２０］ Ｓｉｍａｒｄ Ｐ Ｙ，Ｓｔｅｉｎｋｒａｕｓ Ｄ，Ｐｌａｔｔ Ｊ Ｃ．Ｂｅｓｔ ｐｒａｃｔｉｃｅｓ ｆｏｒ
２００１：５１１－５１８
ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ａｐｐｌｉｅｄ ｔｏ ｖｉｓｕａｌ ｄｏｃｕｍｅｎｔ
［３５］ Ｆｒｅｕｎｄ Ｙ，Ｓｃｈａｐｉｒｅ Ｒ Ｅ．Ａ ｄｅｃｉｓｉｏｎ－ｔｈｅｏｒｅｔｉｃ ｇｅｎｅｒａｌｉｚａｔｉｏｎ
ａｎａｌｙｓｉｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
ｏｆ ｏｎ－ｌｉｎｅ ｌｅａｒｎｉｎｇ ａｎｄ ａｎ ａｐｐｌｉｃａｔｉｏｎ ｔｏ ｂｏｏｓｔｉｎｇ．Ｊｏｕｒｎａｌ ｏｆ
Ｄｏｃｕｍｅｎｔ Ａｎａｌｙｓｉｓ ａｎｄ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｅｄｉｎｂｕｒｇｈ，ＵＫ，２００３：
Ｃｏｍｐｕｔｅｒ ａｎｄ Ｓｙｓｔｅｍ Ｓｃｉｅｎｃｅｓ，１９９７，５５（１）：１１９－１３９
９５８
［３６］ Ｌｉｅｎｈａｒｔ Ｒ，Ｍａｙｄｔ Ｊ．Ａｎ ｅｘｔｅｎｄｅｄ ｓｅｔ ｏｆ Ｈａａｒ－ｌｉｋｅ ｆｅａｔｕｒｅｓ
［２１］ Ｌｉｎ Ｍ，Ｃｈｅｎ Ｑ，Ｙａｎ Ｓ．Ｎｅｔｗｏｒｋ ｉｎ ｎｅｔｗｏｒｋ．ａｒＸｉｖ：
ｆｏｒ ｒａｐｉｄ ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ
１３１２．４４００，２０１３
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｍａｇｅ Ｐｒｏｃｅｓｓｉｎｇ．Ｒｏｃｈｅｓｔｅｒ，ＵＳＡ，２００２：
［２２］ Ｈｉｎｔｏｎ Ｇ Ｅ，Ｓｒｉｖａｓｔａｖａ Ｎ，Ｋｒｉｚｈｅｖｓｋｙ Ａ，ｅｔ ａｌ．Ｉｍｐｒｏｖｉｎｇ ９００－９０３
ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｂｙ ｐｒｅｖｅｎｔｉｎｇ ｃｏａｄａｐｔａｔｉｏｎ ｏｆ ｆｅａｔｕｒｅ ［３７］ Ｄａｌａｌ Ｎ，Ｔｒｉｇｇｓ Ｂ．Ｈｉｓｔｏｇｒａｍｓ ｏｆ ｏｒｉｅｎｔｅｄ ｇｒａｄｉｅｎｔｓ ｆｏｒ
ｄｅｔｅｃｔｏｒｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１２０７．０５８０，２０１２ ｈｕｍａｎ ｄｅｔｅｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
［２３］ Ｓｒｉｖａｓｔａｖａ Ｎ，Ｈｉｎｔｏｎ Ｇ，Ｋｒｉｚｈｅｖｓｋｙ Ａ，ｅｔ ａｌ．Ｄｒｏｐｏｕｔ：Ａ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｓａｎ Ｄｉｅｇｏ，ＵＳＡ，
ｓｉｍｐｌｅ ｗａｙ ｔｏ ｐｒｅｖｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｒｏｍ ｏｖｅｒｆｉｔｔｉｎｇ． ２００５：８８６－８９３
Ｔｈｅ Ｊｏｕｒｎａｌ ｏｆ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ Ｒｅｓｅａｒｃｈ，２０１４，１５（１）： ［３８］ Ｃｏｒｔｅｓ Ｃ，Ｖａｐｎｉｋ Ｖ．Ｓｕｐｐｏｒｔ－ｖｅｃｔｏｒ ｎｅｔｗｏｒｋｓ．Ｍａｃｈｉｎｅ
１９２９－１９５８ Ｌｅａｒｎｉｎｇ，１９９５，２０（３）：２７３－２９７ ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４７７
［３９］ Ｌｉｎ Ｃ．Ｆ，Ｗａｎｇ Ｓ Ｄ．Ｆｕｚｚｙ ｓｕｐｐｏｒｔ ｖｅｃｔｏｒ ｍａｃｈｉｎｅｓ．ＩＥＥＥ ［５４］ Ｅｖｅｒｉｎｇｈａｍ Ｍ，Ｅｓｌａｍｉ Ｓ Ｍ Ａ，Ｖａｎ Ｇｏｏｌ Ｌ，ｅｔ ａｌ．Ｔｈｅ
Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｎｅｕｒａｌ Ｎｅｔｗｏｒｋｓ，２００２，１３（２）：４６４－４７１ ｐａｓｃａｌ ｖｉｓｕａｌ ｏｂｊｅｃｔ ｃｌａｓｓｅｓ ｃｈａｌｌｅｎｇｅ：Ａ ｒｅｔｒｏｓｐｅｃｔｉｖｅ．
［４０］ Ｓｕｙｋｅｎｓ Ｊ Ａ Ｋ，Ｖａｎｄｅｗａｌｌｅ Ｊ．Ｌｅａｓｔ ｓｑｕａｒｅｓ ｓｕｐｐｏｒｔ ｖｅｃｔｏｒ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ，２０１５，１１１（１）：
ｍａｃｈｉｎｅ ｃｌａｓｓｉｆｉｅｒｓ．Ｎｅｕｒａｌ Ｐｒｏｃｅｓｓｉｎｇ Ｌｅｔｔｅｒｓ，１９９９，９（３）： ９８－１３６
２９３－３００ ［５５］ Ｌｉｎ Ｔ－Ｙ，Ｍａｉｒｅ Ｍ，Ｂｅｌｏｎｇｉｅ Ｓ，ｅｔ ａｌ．Ｍｉｃｒｏｓｏｆｔ ＣＯＣＯ：
［４１］ Ｆｅｌｚｅｎｓｚｗａｌｂ Ｐ Ｆ，Ｇｉｒｓｈｉｃｋ Ｒ Ｂ，ＭｃＡｌｌｅｓｔｅｒ Ｄ，ｅｔ ａｌ．Ｏｂｊｅｃｔ
Ｃｏｍｍｏｎ ｏｂｊｅｃｔｓ ｉｎ ｃｏｎｔｅｘｔ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｅｕｒｏｐｅａｎ
ｄｅｔｅｃｔｉｏｎ ｗｉｔｈ ｄｉｓｃｒｉｍｉｎａｔｉｖｅｌｙ ｔｒａｉｎｅｄ ｐａｒｔ－ｂａｓｅｄ ｍｏｄｅｌｓ．
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｚｕｒｉｃｈ，Ｓｗｉｔｚｅｒｌａｎｄ，２０１４：
ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ
７４０－７５５
Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０１０，３２（９）：１６２７－１６４５
［５６］ Ｍｏｔｔａｇｈｉ Ｒ，Ｃｈｅｎ Ｘ，Ｌｉｕ Ｘ，ｅｔ ａｌ．Ｔｈｅ ｒｏｌｅ ｏｆ ｃｏｎｔｅｘｔ ｆｏｒ
［４２］ Ｓｚｅｇｅｄｙ Ｃ，Ｔｏｓｈｅｖ Ａ，Ｅｒｈａｎ Ｄ．Ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ
ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ ａｎｄ ｓｅｍａｎｔｉｃ ｓｅｇｍｅｎｔａｔｉｏｎ ｉｎ ｔｈｅ ｗｉｌｄ／／
ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ
Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｌａｋｅ Ｔａｈｏｅ，ＵＳＡ，２０１３：
Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４：８９１－８９８
２５５３－２５６１
［４３］ Ｅｒｈａｎ Ｄ，Ｓｚｅｇｅｄｙ Ｃ，Ｔｏｓｈｅｖ Ａ，ｅｔ ａｌ．Ｓｃａｌａｂｌｅ ｏｂｊｅｃｔ ［５７］ Ｌｉｕ Ｃ，Ｙｕｅｎ Ｊ，Ｔｏｒｒａｌｂａ Ａ．Ｎｏｎｐａｒａｍｅｔｒｉｃ ｓｃｅｎｅ ｐａｒｓｉｎｇ：
ｄｅｔｅｃｔｉｏｎ ｕｓｉｎｇ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｌａｂｅｌ ｔｒａｎｓｆｅｒ ｖｉａ ｄｅｎｓｅ ｓｃｅｎｅ ａｌｉｇｎｍｅｎｔ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ． ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４：２１４７－２１５４ Ｍｉａｍｉ，ＵＳＡ，２００９：１９７２－１９７９
［４４］ Ｇｉｒｓｈｉｃｋ Ｒ，Ｄｏｎａｈｕｅ Ｊ，Ｄａｒｒｅｌｌ Ｔ，ｅｔ ａｌ．Ｒｉｃｈ ｆｅａｔｕｒｅ ｈｉｅｒａｒｃｈｉｅｓ ［５８］ Ｌｕｃｃｈｉ Ａ，Ｌｉ Ｙ，Ｓｍｉｔｈ Ｋ，Ｆｕａ Ｐ．Ｓｔｒｕｃｔｕｒｅｄ ｉｍａｇｅ ｓｅｇｍｅｎ－
ｆｏｒ ａｃｃｕｒａｔｅ ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ ａｎｄ ｓｅｍａｎｔｉｃ ｓｅｇｍｅｎｔａｔｉｏｎ／／ ｔａｔｉｏｎ ｕｓｉｎｇ ｋｅｒｎｅｌｉｚｅｄ ｆｅａｔｕｒｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｅｕｒｏｐｅａｎ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｆｌｏｒｅｎｃｅ，Ｉｔａｌｙ，２０１２：
Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４：５８０－５８７ ４００－４１３
［４５］ Ｅｒｈａｎ Ｄ，Ｓｚｅｇｅｄｙ Ｃ，Ｔｏｓｈｅｖ Ａ，Ａｎｇｕｅｌｏｖ Ｄ．Ｓｃａｌａｂｌｅ ［５９］ Ｔｉｇｈｅ Ｊ，Ｌａｚｅｂｎｉｋ Ｓ．ＳｕｐｅｒＰａｒｓｉｎｇ：Ｓｃａｌａｂｌｅ ｎｏｎｐａｒａｍｅｔｒｉｃ
ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ ｕｓｉｎｇ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｉｍａｇｅ ｐａｒｓｉｎｇ ｗｉｔｈ ｓｕｐｅｒｐｉｘｅｌｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｅｕｒｏｐｅａｎ
ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｈｅｒａｋｌｉｏｎ，Ｇｒｅｅｃｅ，２０１０：
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４：２１５５－２１６２
３５２－３６５
［４６］ Ｓｅｒｍａｎｅｔ Ｐ，Ｅｉｇｅｎ Ｄ，Ｚｈａｎｇ Ｘ，ｅｔ ａｌ．ＯｖｅｒＦｅａｔ：Ｉｎｔｅｇｒａｔｅｄ
［６０］ Ｇｏｕｌｄ Ｓ，Ｒｏｄｇｅｒｓ Ｊ，Ｃｏｈｅｎ Ｄ，ｅｔ ａｌ．Ｍｕｌｔｉ－ｃｌａｓｓ ｓｅｇｍｅｎｔａｔｉｏｎ
ｒｅｃｏｇｎｉｔｉｏｎ，ｌｏｃａｌｉｚａｔｉｏｎ ａｎｄ ｄｅｔｅｃｔｉｏｎ ｕｓｉｎｇ ｃｏｎｖｏｌｕｔｉｏｎａｌ
ｗｉｔｈ ｒｅｌａｔｉｖｅ ｌｏｃａｔｉｏｎ ｐｒｉｏｒ．Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ
ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１３１２．６２２９，２０１３
Ｖｉｓｉｏｎ，２００８，８０（３）：３００－３１６
［４７］ Ｇｉｒｓｈｉｃｋ Ｒ． Ｆａｓｔ Ｒ－ＣＮＮ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｓａｎｔｉａｇｏ， ［６１］ Ｌａｄｉｃｋｙ Ｌ，Ｒｕｓｓｅｌｌ Ｃ，Ｋｏｈｌｉ Ｐ，Ｔｏｒｒ Ｐ Ｈ Ｓ．Ａｓｓｏｃｉａｔｉｖｅ
Ｃｈｉｌｅ，２０１５：１４４０－１４４８ ｈｉｅｒａｒｃｈｉｃａｌ ＣＲＦｓ ｆｏｒ ｏｂｊｅｃｔ ｃｌａｓｓ ｉｍａｇｅ ｓｅｇｍｅｎｔａｔｉｏｎ／／
［４８］ Ｈｅ Ｋ，Ｚｈａｎｇ Ｘ，Ｒｅｎ Ｓ，Ｓｕｎ Ｊ．Ｓｐａｔｉａｌ ｐｙｒａｍｉｄ ｐｏｏｌｉｎｇ ｉｎ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ
ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ．ＩＥＥＥ
Ｖｉｓｉｏｎ．Ｋｙｏｔｏ，Ｊａｐａｎ，２００９：７３９－７４６
Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ， ［６２］ Ｓｈｏｔｔｏｎ Ｊ，Ｊｏｈｎｓｏｎ Ｍ，Ｃｉｐｏｌｌａ Ｒ．Ｓｅｍａｎｔｉｃ ｔｅｘｔｏｎ ｆｏｒｅｓｔｓ
２０１５，３７（９）：１９０４－１９１６ ｆｏｒ ｉｍａｇｅ ｃａｔｅｇｏｒｉｚａｔｉｏｎ ａｎｄ ｓｅｇｍｅｎｔａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
［４９］ Ｕｉｊｌｉｎｇｓ Ｊ Ｒ，ｖａｎ ｄｅ Ｓａｎｄｅ Ｋ Ｅ，Ｇｅｖｅｒｓ Ｔ，Ｓｍｅｕｌｄｅｒｓ Ａ Ｗ． ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
Ｓｅｌｅｃｔｉｖｅ ｓｅａｒｃｈ ｆｏｒ ｏｂｊｅｃｔ ｒｅｃｏｇｎｉｔｉｏｎ．Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｕｒｎａｌ Ｒｅｃｏｇｎｉｔｉｏｎ．Ａｎｃｈｏｒａｇｅ，ＵＳＡ，２００８：１－８
ｏｆ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ，２０１３，１０４（２）：１５４－１７１ ［６３］ Ｆａｒａｂｅｔ Ｃ，Ｃｏｕｐｒｉｅ Ｃ，Ｎａｊｍａｎ Ｌ，Ｌｅ－Ｃｕｎ Ｙ．Ｌｅａｒｎｉｎｇ
［５０］ Ｒｅｎ Ｓ，Ｈｅ Ｋ，Ｇｉｒｓｈｉｃｋ Ｒ，Ｓｕｎ Ｊ．Ｆａｓｔｅｒ Ｒ－ＣＮＮ：Ｔｏｗａｒｄｓ
ｈｉｅｒａｒｃｈｉｃａｌ ｆｅａｔｕｒｅｓ ｆｏｒ ｓｃｅｎｅ ｌａｂｅｌｉｎｇ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ
ｒｅａｌ－ｔｉｍｅ ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ ｗｉｔｈ ｒｅｇｉｏｎ ｐｒｏｐｏｓａｌ ｎｅｔｗｏｒｋｓ／／ ｏｎ Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０１３，３５（８）：
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ
１９１５－１９２９
Ｓｙｓｔｅｍｓ．Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，２０１５：９１－９９
［６４］ Ｍｏｓｔａｊａｂｉ Ｍ，Ｙａｄｏｌｌａｈｐｏｕｒ Ｐ，Ｓｈａｋｈｎａｒｏｖｉｃｈ Ｇ．Ｆｅｅｄｆｏｒｗａｒｄ
［５１］ Ｒｅｄｍｏｎ Ｊ，Ｄｉｖｖａｌａ Ｓ，Ｇｉｒｓｈｉｃｋ Ｒ，Ｆａｒｈａｄｉ Ａ．Ｙｏｕ ｏｎｌｙ ｌｏｏｋ
ｓｅｍａｎｔｉｃ ｓｅｇｍｅｎｔａｔｉｏｎ ｗｉｔｈ ｚｏｏｍ－ｏｕｔ ｆｅａｔｕｒｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｏｎｃｅ：Ｕｎｉｆｉｅｄ，ｒｅａｌ－ｔｉｍｅ ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：３３７６－３３８５
Ｌａｓ Ｖｅｇａｓ，ＵＳＡ，２０１６：７７９－７８８
［５２］ Ｈｕａｎｇ Ｌ，Ｙａｎｇ Ｙ，Ｄｅｎｇ Ｙ，Ｙｕ Ｙ．ＤｅｎｓｅＢｏｘ：Ｕｎｉｆｙｉｎｇ ［６５］ Ｐｉｎｈｅｉｒｏ Ｐ Ｈ，Ｃｏｌｌｏｂｅｒｔ Ｒ．Ｒｅｃｕｒｒｅｎｔ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ
ｌａｎｄｍａｒｋ ｌｏｃａｌｉｚａｔｉｏｎ ｗｉｔｈ ｅｎｄ ｔｏ ｅｎｄ ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ．ａｒＸｉｖ
ｎｅｔｗｏｒｋｓ ｆｏｒ ｓｃｅｎｅ ｌａｂｅｌｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ
ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１５０９．０４８７４，２０１５ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｂｅｉｊｉｎｇ，Ｃｈｉｎａ，２０１４：
［５３］ Ｓｈｏｔｔｏｎ Ｊ，Ｗｉｎｎ Ｊ，Ｒｏｔｈｅｒ Ｃ，Ｃｒｉｍｉｎｉｓｉ Ａ．ＴｅｘｔｏｎＢｏｏｓｔ： ８２－９０
Ｊｏｉｎｔ ａｐｐｅａｒａｎｃｅ，ｓｈａｐｅ ａｎｄ ｃｏｎｔｅｘｔ ｍｏｄｅｌｉｎｇ ｆｏｒ ｍｕｌｔｉ－ｃｌａｓｓ ［６６］ Ｌｏｎｇ Ｊ，Ｓｈｅｌｈａｍｅｒ Ｅ，Ｄａｒｒｅｌｌ Ｔ．Ｆｕｌｌｙ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ
ｏｂｊｅｃｔ ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｓｅｇｍｅｎｔａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ｆｏｒ ｓｅｍａｎｔｉｃ ｓｅｇｍｅｎｔａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ
Ｅｕｒｏｐｅａｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｇｒａｚ，Ａｕｓｔｒｉａ， ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｂｏｓｔｏｎ，ＵＳＡ，
２００６：１－１５ ２０１５：３４３１－３４４０ ４７８ 计 算 机 学 报 ２０１９年
［６７］ Ｃｈｅｎ Ｌ－Ｃ，Ｐａｐａｎｄｒｅｏｕ Ｇ，Ｋｏｋｋｉｎｏｓ Ｉ，ｅｔ ａｌ．Ｓｅｍａｎｔｉｃ ｉｍａｇｅ （蒋树强，闵巍庆，王树徽．面向智能交互的图像识别技术综
ｓｅｇｍｅｎｔａｔｉｏｎ ｗｉｔｈ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｓ ａｎｄ ｆｕｌｌｙ ｃｏｎｎｅｃｔｅｄ 述与展望．计算机研究与发展，２０１６，５３（１）：１１３－１２２）
ＣＲＦｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｌｅａｒｎｉｎｇ ［８０］ Ｋｉｒｏｓ Ｒ，Ｓａｌａｋｈｕｔｄｉｎｏｖ Ｒ，Ｚｅｍｅｌ Ｒ Ｓ．Ｕｎｉｆｙｉｎｇ ｖｉｓｕａｌ－
Ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ．Ｓａｎ Ｄｉｅｇｏ，ＵＳＡ，２０１５：１－１４ ｓｅｍａｎｔｉｃ ｅｍｂｅｄｄｉｎｇｓ ｗｉｔｈ ｍｕｌｔｉｍｏｄａｌ ｎｅｕｒａｌ ｌａｎｇｕａｇｅ
［６８］ Ｋｒｈｅｎｂüｈｌ Ｐ，Ｋｏｌｔｕｎ Ｖ．Ｅｆｆｉｃｉｅｎｔ ｉｎｆｅｒｅｎｃｅ ｉｎ ｆｕｌｌｙ ｃｏｎｎｅｃｔｅｄ ｍｏｄｅｌｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１４１１．２５３９，２０１４
ＣＲＦｓ ｗｉｔｈ Ｇａｕｓｓｉａｎ ｅｄｇｅ ｐｏｔｅｎｔｉａｌｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ［８１］ Ｍａｏ Ｊ，Ｘｕ Ｗ，Ｙａｎｇ Ｙ，ｅｔ ａｌ．Ｅｘｐｌａｉｎ ｉｍａｇｅｓ ｗｉｔｈ ｍｕｌｔｉｍｏｄａｌ
Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｇｒａｎａｄａ， ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１４１０．１０９０，
Ｓｐａｉｎ，２０１１：１０９－１１７
２０１４
［６９］ Ｚｈｅｎｇ Ｓ，Ｊａｙａｓｕｍａｎａ Ｓ，Ｒｏｍｅｒａ－Ｐａｒｅｄｅｓ Ｂ，ｅｔ ａｌ．Ｃｏｎｄｉｔｉｏｎａｌ ［８２］ Ｃｈｅｎ Ｘ，Ｌａｗｒｅｎｃｅ Ｚｉｔｎｉｃｋ Ｃ．Ｍｉｎｄ’ｓ ｅｙｅ：Ａ ｒｅｃｕｒｒｅｎｔ ｖｉｓｕａｌ
ｒａｎｄｏｍ ｆｉｅｌｄｓ ａｓ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｆｏｒ ｉｍａｇｅ ｃａｐｔｉｏｎ ｇｅｎｅｒａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．
ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
Ｓａｎｔｉａｇｏ，Ｃｈｉｌｅ，２０１５：１５２９－１５３７
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：２４２２－２４３１
［７０］ Ｄａｉ Ｊ，Ｈｅ Ｋ，Ｓｕｎ Ｊ．ＢｏｘＳｕｐ：Ｅｘｐｌｏｉｔｉｎｇ ｂｏｕｎｄｉｎｇ ｂｏｘｅｓ ｔｏ
［８３］Ｊｉａ Ｘ，Ｇａｖｖｅｓ Ｅ，Ｆｅｒｎａｎｄｏ Ｂ，Ｔｕｙｔｅｌａａｒｓ Ｔ．Ｇｕｉｄｉｎｇ
ｓｕｐｅｒｖｉｓｅ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｓｅｍａｎｔｉｃ ｓｅｇｍｅｎｔａｔｉｏｎ
ｌｏｎｇ－ｓｈｏｒｔ ｔｅｒｍ ｍｅｍｏｒｙ ｆｏｒ ｉｍａｇｅ ｃａｐｔｉｏｎ ｇｅｎｅｒａｔｉｏｎ．ａｒＸｉｖ
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
ｐｒｅｐｒｉｎｔ ａｒＸｉｖ：１５０９．０４９４２，２０１５
Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｓａｎｔｉａｇｏ，Ｃｈｉｌｅ，２０１５：１６３５－１６４３
［８４］ Ｍａｏ Ｊ，Ｘｕ Ｗ，Ｙａｎｇ Ｙ，ｅｔ ａｌ．Ｄｅｅｐ ｃａｐｔｉｏｎｉｎｇ ｗｉｔｈ ｍｕｌｔｉ－
［７１］ Ｂｅａｒｍａｎ Ａ，Ｒｕｓｓａｋｏｖｓｋｙ Ｏ，Ｆｅｒｒａｒｉ Ｖ，Ｌｉ Ｆｅｉ－Ｆｅｉ．Ｗｈａｔ’ｓ
ｍｏｄａｌ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ（ｍ－ＲＮＮ）．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ
ｔｈｅ ｐｏｉｎｔ：Ｓｅｍａｎｔｉｃ ｓｅｇｍｅｎｔａｔｉｏｎ ｗｉｔｈ ｐｏｉｎｔ ｓｕｐｅｒｖｉｓｉｏｎ／／
ａｒＸｉｖ：１４１２．６６３２，２０１４
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｅｕｒｏｐｅａｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ
［８５］ Ｈｕａｎｇ Ｇ Ｂ，Ｒａｍｅｓｈ Ｍ，Ｂｅｒｇ Ｔ，ｅｔ ａｌ．Ｌａｂｅｌｅｄ ｆａｃｅｓ ｉｎ ｔｈｅ
Ｖｉｓｉｏｎ．Ａｍｓｔｅｒｄａｍ，Ｔｈｅ Ｎｅｔｈｅｒｌａｎｄｓ，２０１６：５４９－５６５
ｗｉｌｄ：Ａ ｄａｔａｂａｓｅ ｆｏｒ ｓｔｕｄｙｉｎｇ ｆａｃｅ ｒｅｃｏｇｎｉｔｉｏｎ ｉｎ ｕｎｃｏｎｓｔｒａｉｎｅｄ
［７２］ Ｐｉｎｈｅｉｒｏ Ｐ Ｏ，Ｃｏｌｌｏｂｅｒｔ Ｒ．Ｆｒｏｍ ｉｍａｇｅ－ｌｅｖｅｌ ｔｏ ｐｉｘｅｌ－ｌｅｖｅｌ
ｅｎｖｉｒｏｎｍｅｎｔｓ．Ｕｎｉｖｅｒｓｉｔｙ ｏｆ Ｍａｓｓａｃｈｕｓｅｔｔｓ，Ａｍｈｅｒｓｔ，ＵＳＡ：
ｌａｂｅｌｉｎｇ ｗｉｔｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
Ｔｅｃｈｎｉｃａｌ Ｒｅｐｏｒｔ ０７－４９，２００７
ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
［８６］ Ｋｕｍａｒ Ｎ，Ｂｅｒｇ Ａ Ｃ，Ｂｅｌｈｕｍｅｕｒ Ｐ Ｎ，ｅｔ ａｌ．Ａｔｔｒｉｂｕｔｅ ａｎｄ
Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：１７１３－１７２１
ｓｉｍｉｌｅ ｃｌａｓｓｉｆｉｅｒｓ ｆｏｒ ｆａｃｅ ｖｅｒｉｆｉｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
［７３］ Ｆａｎｇ Ｈ，Ｇｕｐｔａ Ｓ，Ｉａｎｄｏｌａ Ｆ，ｅｔ ａｌ．Ｆｒｏｍ ｃａｐｔｉｏｎｓ ｔｏ ｖｉｓｕａｌ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｋｙｏｔｏ，Ｊａｐａｎ，
ｃｏｎｃｅｐｔｓ ａｎｄ ｂａｃｋ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
２００９：３６５－３７２
Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｂｏｓｔｏｎ，ＵＳＡ，
２０１５：１４７３－１４８２
［８７］ Ｃｈｅｎ Ｄ，Ｃａｏ Ｘ，Ｗｅｎ Ｆ，ｅｔ ａｌ．Ｂｌｅｓｓｉｎｇ ｏｆ ｄｉｍｅｎｓｉｏｎａｌｉｔｙ：
Ｈｉｇｈ－ｄｉｍｅｎｓｉｏｎａｌ ｆｅａｔｕｒｅ ａｎｄ ｉｔｓ ｅｆｆｉｃｉｅｎｔ ｃｏｍｐｒｅｓｓｉｏｎ ｆｏｒ
［７４］ Ｄｅｖｌｉｎ Ｊ，Ｃｈｅｎｇ Ｈ，Ｆａｎｇ Ｈ，ｅｔ ａｌ．Ｌａｎｇｕａｇｅ ｍｏｄｅｌｓ ｆｏｒ
ｆａｃｅ ｖｅｒｉｆｉｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
ｉｍａｇｅ ｃａｐｔｉｏｎｉｎｇ：Ｔｈｅ ｑｕｉｒｋｓ ａｎｄ ｗｈａｔ ｗｏｒｋｓ．ａｒＸｉｖ ｐｒｅｐｒｉｎｔ
Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｏｒｔｌａｎｄ，ＵＳＡ，
ａｒＸｉｖ：１５０５．０１８０９，２０１５
２０１３：３０２５－３０３２
［７５］ Ｖｉｎｙａｌｓ Ｏ，Ｔｏｓｈｅｖ Ａ，Ｂｅｎｇｉｏ Ｓ，Ｅｒｈａｎ Ｄ．Ｓｈｏｗ ａｎｄ ｔｅｌｌ：Ａ
ｎｅｕｒａｌ ｉｍａｇｅ ｃａｐｔｉｏｎ ｇｅｎｅｒａｔｏｒ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ ［８８］ Ｓｕｎ Ｙ，Ｗａｎｇ Ｘ，Ｔａｎｇ Ｘ．Ｈｙｂｒｉｄ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆｏｒ ｆａｃｅ
ｖｅｒｉｆｉｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：３１５６－３１６４ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｓｙｄｎｅｙ，Ａｕｓｔｒａｌｉａ，２０１３：１４８９－１４９６
［７６］ Ｘｕ Ｋ，Ｂａ Ｊ，Ｋｉｒｏｓ Ｒ，ｅｔ ａｌ．Ｓｈｏｗ，ａｔｔｅｎｄ ａｎｄ ｔｅｌｌ：Ｎｅｕｒａｌ ［８９］ Ｔａｉｇｍａｎ Ｙ，Ｙａｎｇ Ｍ，Ｒａｎｚａｔｏ Ｍ，ｅｔ ａｌ．ＤｅｅｐＦａｃｅ：Ｃｌｏｓｉｎｇ
ｉｍａｇｅ ｃａｐｔｉｏｎ ｇｅｎｅｒａｔｉｏｎ ｗｉｔｈ ｖｉｓｕａｌ ａｔｔｅｎｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｔｈｅ ｇａｐ ｔｏ ｈｕｍａｎ－ｌｅｖｅｌ ｐｅｒｆｏｒｍａｎｃｅ ｉｎ ｆａｃｅ ｖｅｒｉｆｉｃａｔｉｏｎ／／
ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｌｉｌｌｅ， Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ
Ｆｒａｎｃｅ，２０１５：２０４８－２０５７ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４：１７０１－１７０８
［７７］ Ｋａｒｐａｔｈｙ Ａ，Ｌｉ Ｆｅｉ－Ｆｅｉ．Ｄｅｅｐ ｖｉｓｕａｌ－ｓｅｍａｎｔｉｃ ａｌｉｇｎｍｅｎｔｓ ｆｏｒ ［９０］ Ｓｕｎ Ｙ，Ｗａｎｇ Ｘ，Ｔａｎｇ Ｘ．Ｄｅｅｐｌｙ ｌｅａｒｎｅｄ ｆａｃｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ
ｇｅｎｅｒａｔｉｎｇ ｉｍａｇｅ ｄｅｓｃｒｉｐｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ ａｒｅ ｓｐａｒｓｅ，ｓｅｌｅｃｔｉｖｅ，ａｎｄ ｒｏｂｕｓｔ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ． Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：３１２８－３１３７ Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：２８９２－２９００
［７８］ Ｄｏｎａｈｕｅ Ｊ，Ａｎｎｅ Ｈｅｎｄｒｉｃｋｓ Ｌ，Ｇｕａｄａｒｒａｍａ Ｓ，ｅｔ ａｌ．Ｌｏｎｇ－ ［９１］ Ｇｒａｙ Ｄ，Ｂｒｅｎｎａｎ Ｓ，Ｔａｏ Ｈ．Ｅｖａｌｕａｔｉｎｇ ａｐｐｅａｒａｎｃｅ ｍｏｄｅｌｓ
ｔｅｒｍ ｒｅｃｕｒｒｅｎｔ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ ｆｏｒ ｒｅｃｏｇｎｉｔｉｏｎ，ｒｅａｃｑｕｉｓｉｔｉｏｎ，ａｎｄ ｔｒａｃｋｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
ａｎｄ ｄｅｓｃｒｉｐｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｗｏｒｋｓｈｏｐ ｏｎ Ｐｅｒｆｏｒｍａｎｃｅ Ｅｖａｌｕａｔｉｏｎ
Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｂｏｓｔｏｎ，ＵＳＡ， ｆｏｒ Ｔｒａｃｋｉｎｇ ａｎｄ Ｓｕｒｖｅｉｌｌａｎｃｅ（ＰＥＴＳ）．Ｒｉｏ ｄｅ Ｊａｎｅｉｒｏ，Ｂｒａｚｉｌ，
２０１５：２６２５－２６３４ ２００７：１－７
［７９］Ｊｉａｎｇ Ｓｈｕ－Ｑｉａｎｇ，Ｍｉｎ Ｗｅｉ－Ｑｉｎｇ，Ｗａｎｇ Ｓｈｕ－Ｈｕｉ．Ｓｕｒｖｅｙ ａｎｄ ［９２］ Ｓｃｈｗａｒｔｚ Ｗ Ｒ，Ｄａｖｉｓ Ｌ Ｓ．Ｌｅａｒｎｉｎｇ ｄｉｓｃｒｉｍｉｎａｔｉｖｅ ａｐｐｅａｒａｎｃｅ－
ｐｒｏｓｐｅｃｔ ｏｆ ｉｎｔｅｌｌｉｇｅｎｔ ｉｎｔｅｒａｃｔｉｏｎ－ｏｒｉｅｎｔｅｄ ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ ｂａｓｅｄ ｍｏｄｅｌｓ ｕｓｉｎｇ ｐａｒｔｉａｌ ｌｅａｓｔ ｓｑｕａｒｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｔｅｃｈｎｉｑｕｅｓ．Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ， Ｂｒａｚｉｌｉａｎ Ｓｙｍｐｏｓｉｕｍ ｏｎ Ｃｏｍｐｕｔｅｒ Ｇｒａｐｈｉｃｓ ａｎｄ Ｉｍａｇｅ
２０１６，５３（１）：１１３－１２２（ｉｎ Ｃｈｉｎｅｓｅ） Ｐｒｏｃｅｓｓｉｎｇ．Ｒｉｏ ｄｅ Ｊａｎｅｉｒｏ，Ｂｒａｚｉｌ，２００９：３２２－２３９ ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４７９
［９３］ Ｌｉ Ｗ，Ｚｈａｏ Ｒ，Ｗａｎｇ Ｘ．Ｈｕｍａｎ ｒｅｉｄｅｎｔｉｆｉｃａｔｉｏｎ ｗｉｔｈ ｔｒａｎｓ－ ［１０７］ Ｌｉａｎｇ Ｙ，Ｗａｎｇ Ｊ，Ｚｈａｎｇ Ｓ，Ｇｏｎｇ Ｙ．Ｉｎｃｏｒｐｏｒａｔｉｎｇ ｉｍａｇｅ
ｆｅｒｒｅｄ ｍｅｔｒｉｃ ｌｅａｒｎｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ａｓｉａｎ Ｃｏｎｆｅｒｅｎｃｅ ｄｅｇｅｎｅｒａｔｉｏｎ ｍｏｄｅｌｉｎｇ ｗｉｔｈ ｍｕｌｔｉ－ｔａｓｋ ｌｅａｒｎｉｎｇ ｆｏｒ ｉｍａｇｅ
ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｄａｅｊｅｏｎ，Ｋｏｒｅａ，２０１２：３１－４４ ｓｕｐｅｒ－ｒｅｓｏｌｕｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ
［９４］ Ｈｉｒｚｅｒ Ｍ，Ｂｅｌｅｚｎａｉ Ｃ，Ｒｏｔｈ Ｐ Ｍ，Ｂｉｓｃｈｏｆ Ｈ．Ｐｅｒｓｏｎ ｏｆ Ｉｍａｇｅ Ｐｒｏｃｅｓｓｉｎｇ．Ｑｕｅｂｅｃ Ｃｉｔｙ，Ｃａｎａｄａ，２０１５：２１１０－
ｒｅ－ｉｄｅｎｔｉｆｉｃａｔｉｏｎ ｂｙ ｄｅｓｃｒｉｐｔｉｖｅ ａｎｄ ｄｉｓｃｒｉｍｉｎａｔｉｖｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ２１１４
／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｓｃａｎｄｉｎａｖｉａｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｉｍａｇｅ ［１０８］ Ｂｅｖｉｌａｃｑｕａ Ｍ，Ｒｏｕｍｙ Ａ，Ｇｕｉｌｌｅｍｏｔ Ｃ，Ｍｏｒｅｌ Ｍ－Ｌ Ａ．
Ａｎａｌｙｓｉｓ．Ｙｓｔａｄ，Ｓｗｅｄｅｎ，２０１１：９１－１０２ Ｌｏｗ－ｃｏｍｐｌｅｘｉｔｙ ｓｉｎｇｌｅ－ｉｍａｇｅ ｓｕｐｅｒ－ｒｅｓｏｌｕｔｉｏｎ ｂａｓｅｄ ｏｎ
［９５］ ＨＯＳＤ Ｂｒａｎｃｈ．Ｉｍａｇｅｒｙ ｌｉｂｒａｒｙ ｆｏｒ ｉｎｔｅｌｌｉｇｅｎｔ ｄｅｔｅｃｔｉｏｎ ｓｙｓｔｅｍｓ ｎｏｎｎｅｇａｔｉｖｅ ｎｅｉｇｈｂｏｒ ｅｍｂｅｄｄｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｂｒｉｔｉｓｈ
（ｉ－ＬＩＤＳ）／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｓｔｉｔｕｔｉｏｎ ｏｆ Ｅｎｇｉｎｅｅｒｉｎｇ ａｎｄ Ｍａｃｈｉｎｅ Ｖｉｓｏｎ Ｃｏｎｆｅｒｅｎｃｅ．Ｇｕｉｌｄｆｏｒｄ，Ｅｎｇｌａｎｄ，２０１２：
Ｔｅｃｈｎｏｌｏｇｙ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｒｉｍｅ ａｎｄ Ｓｅｃｕｒｉｔｙ．Ｌｏｎｄｏｎ， １－１０
ＵＫ，２００６：４４５－４４８ ［１０９］ Ｚｅｙｄｅ Ｒ，Ｅｌａｄ Ｍ，Ｐｒｏｔｔｅｒ Ｍ．Ｏｎ ｓｉｎｇｌｅ ｉｍａｇｅ ｓｃａｌｅ－ｕｐ
［９６］ Ｄｉｎｇ Ｓ，Ｌｉｎ Ｌ，Ｗａｎｇ Ｇ，Ｃｈａｏ Ｈ．Ｄｅｅｐ ｆｅａｔｕｒｅ ｌｅａｒｎｉｎｇ ｕｓｉｎｇ ｓｐａｒｓｅ－ｒｅｐｒｅｓｅｎｔａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａ－
ｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｕｒｖｅｓ ａｎｄ Ｓｕｒｆａｃｅｓ．Ｂｅｒｌｉｎ，Ｇｅｒｍａｎ，
ｗｉｔｈ ｒｅｌａｔｉｖｅ ｄｉｓｔａｎｃｅ ｃｏｍｐａｒｉｓｏｎ ｆｏｒ ｐｅｒｓｏｎ ｒｅ－ｉｄｅｎｔｉｆｉｃａｔｉｏｎ．
Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ，２０１５，４８（１０）：２９９３－３００３
２０１０：７１１－７３０
［９７］ Ｌｉ Ｗ，Ｚｈａｏ Ｒ，Ｘｉａｏ Ｔ，Ｗａｎｇ Ｘ．ＤｅｅｐＲｅＩＤ：Ｄｅｅｐ ｆｉｌｔｅｒ
［１１０］ Ｄｏｎｇ Ｃ，Ｌｏｙ Ｃ Ｃ，Ｈｅ Ｋ，Ｔａｎｇ Ｘ．Ｌｅａｒｎｉｎｇ ａ ｄｅｅｐ ｃｏｎｖｏ－
ｐａｉｒｉｎｇ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｆｏｒ ｐｅｒｓｏｎ ｒｅ－ｉｄｅｎｔｉｆｉｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋ ｆｏｒ ｉｍａｇｅ ｓｕｐｅｒ－ｒｅｓｏｌｕｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
ｔｈｅ Ｅｕｒｏｐｅａｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｚｕｒｉｃｈ，
ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４：１５２－１５９
Ｓｗｉｔｚｅｒｌａｎｄ，２０１４：１８４－１９９
［１１１］ Ｄｏｎｇ Ｃ，Ｌｏｙ Ｃ Ｃ，Ｈｅ Ｋ，Ｔａｎｇ Ｘ．Ｉｍａｇｅ ｓｕｐｅｒ－ｒｅｓｏｌｕｔｉｏｎ
［９８］ Ｚｈａｏ Ｒ，Ｏｕｙａｎｇ Ｗ，Ｗａｎｇ Ｘ．Ｌｅａｒｎｉｎｇ ｍｉｄ－ｌｅｖｅｌ ｆｉｌｔｅｒｓ ｆｏｒ
ｕｓｉｎｇ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ
ｐｅｒｓｏｎ ｒｅ－ｉｄｅｎｔｉｆｉｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ
Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０１５，３８（２）：
ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｃｏｌｕｍｂｕｓ，
２９５－３０７
ＵＳＡ，２０１４：１４４－１５１
［１１２］ Ｌｉａｎｇ Ｙ，Ｗａｎｇ Ｊ，Ｇｏｎｇ Ｙ，Ｚｈｅｎｇ Ｎ．Ｉｎｃｏｒｐｏｒａｔｉｎｇ ｉｍａｇｅ
［９９］ Ａｈｍｅｄ Ｅ，Ｊｏｎｅｓ Ｍ，Ｍａｒｋｓ Ｔ Ｋ．Ａｎ ｉｍｐｒｏｖｅｄ ｄｅｅｐ ｌｅａｒｎｉｎｇ
ｐｒｉｏｒｓ ｗｉｔｈ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｉｍａｇｅ
ａｒｃｈｉｔｅｃｔｕｒｅ ｆｏｒ ｐｅｒｓｏｎ ｒｅ－ｉｄｅｎｔｉｆｉｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｓｕｐｅｒ－ｒｅｓｏｌｕｔｉｏｎ．Ｎｅｕｒｏｃｏｍｐｕｔｉｎｇ，２０１６，１９４：３４０－３４７
ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
［１１３］ Ｗａｎｇ Ｚ，Ｌｉｕ Ｄ，Ｙａｎｇ Ｊ，ｅｔ ａｌ．Ｄｅｅｐ ｎｅｔｗｏｒｋｓ ｆｏｒ ｉｍａｇｅ
Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：５：２５
ｓｕｐｅｒ－ｒｅｓｏｌｕｔｉｏｎ ｗｉｔｈ ｓｐａｒｓｅ ｐｒｉｏｒ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
［１００］ Ｙｉ Ｄ，Ｌｅｉ Ｚ，Ｌｉａｏ Ｓ，Ｌｉ Ｓ Ｚ．Ｄｅｅｐ ｍｅｔｒｉｃ ｌｅａｒｎｉｎｇ ｆｏｒ ｐｅｒｓｏｎ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｓａｎｔｉａｇｏ，
ｒｅ－ｉｄｅｎｔｉｆｉｃａｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ
Ｃｈｉｌｅ，２０１５：３７０－３７８
ｏｎ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｓｔｏｃｋｈｏｌｍ，Ｓｗｅｄｅｎ，２０１４：３４－３９
［１１４］ Ｗｉｌｌｅｍｓ Ｇ，Ｔｕｙｔｅｌａａｒｓ Ｔ，Ｖａｎ Ｇｏｏｌ Ｌ．Ａｎ ｅｆｆｉｃｉｅｎｔ ｄｅｎｓｅ
［１０１］ Ｃｈｅｎｇ Ｄ，Ｇｏｎｇ Ｙ，Ｚｈｏｕ Ｓ，Ｗａｎｇ Ｊ．Ｐｅｒｓｏｎ ｒｅ－ｉｄｅｎｔｉｆｉｃａｔｉｏｎ
ａｎｄ ｓｃａｌｅ－ｉｎｖａｒｉａｎｔ ｓｐａｔｉｏ－ｔｅｍｐｏｒａｌ ｉｎｔｅｒｅｓｔ ｐｏｉｎｔ ｄｅｔｅｃｔｏｒ／／
ｂｙ ａｎ ｍｕｌｔｉ－ｃｈａｎｎｅｌ ｐａｒｔｓ－ｂａｓｅｄ ＣＮＮ ｗｉｔｈ ｉｍｐｒｏｖｅｄ ｔｒｉｐｌｅｔ
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｅｕｒｏｐｅａｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ
ｌｏｓｓ ｆｕｎｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
Ｖｉｓｉｏｎ．Ｍａｒｓｅｉｌｌｅ，Ｆｒａｎｃｅ，２００８：６５０－６６３
Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｌａｓ Ｖｅｇａｓ，
［１１５］ Ｅｖｅｒｔｓ Ｉ，ｖａｎ Ｇｅｍｅｒｔ Ｊ Ｃ，Ｇｅｖｅｒｓ Ｔ．Ｅｖａｌｕａｔｉｏｎ ｏｆ ｃｏｌｏｒ
ＵＳＡ，２０１６：１３３５－１３４４
ｓｔｉｐｓ ｆｏｒ ｈｕｍａｎ ａｃｔｉｏｎ ｒｅｃｏｇｎｉｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ
［１０２］ Ｋｅｙｓ Ｒ．Ｃｕｂｉｃ ｃｏｎｖｏｌｕｔｉｏｎ ｉｎｔｅｒｐｏｌａｔｉｏｎ ｆｏｒ ｄｉｇｉｔａｌ ｉｍａｇｅ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
ｐｒｏｃｅｓｓｉｎｇ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ａｃｏｕｓｔｉｃｓ，Ｓｐｅｅｃｈ ａｎｄ Ｐｏｒｔｌａｎｄ，ＵＳＡ，２０１３：２８５０－２８５７
Ｓｉｇｎａｌ Ｐｒｏｃｅｓｓｉｎｇ，１９８１，２９（６）：１１５３－１１６０
［１１６］ Ｙｕａｎ Ｃ，Ｌｉ Ｘ，Ｈｕ Ｗ，ｅｔ ａｌ．３ＤＲ ｔｒａｎｓｆｏｒｍ ｏｎ ｓｐａｔｉｏ－
［１０３］Ｉｒａｎｉ Ｍ，Ｐｅｌｅｇ Ｓ．Ｍｏｔｉｏｎ ａｎａｌｙｓｉｓ ｆｏｒ ｉｍａｇｅ ｅｎｈａｎｃｅｍｅｎｔ： ｔｅｍｐｏｒａｌ ｉｎｔｅｒｅｓｔ ｐｏｉｎｔｓ ｆｏｒ ａｃｔｉｏｎ ｒｅｃｏｇｎｉｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ
Ｒｅｓｏｌｕｔｉｏｎ，ｏｃｃｌｕｓｉｏｎ，ａｎｄ ｔｒａｎｓｐａｒｅｎｃｙ．Ｊｏｕｒｎａｌ ｏｆ Ｖｉｓｕａｌ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
Ｃｏｍｍｕｎｉｃａｔｉｏｎ ａｎｄ Ｉｍａｇｅ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ，１９９３，４（４）： Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｏｒｔｌａｎｄ，ＵＳＡ，２０１３：７２４－７３０
３２４－３３５ ［１１７］ Ｋｅ Ｙ，Ｓｕｋｔｈａｎｋａｒ Ｒ，Ｈｅｂｅｒｔ Ｍ．Ｓｐａｔｉｏ－ｔｅｍｐｏｒａｌ ｓｈａｐｅ
［１０４］ Ａｌｙ Ｈ Ａ，Ｄｕｂｏｉｓ Ｅ．Ｉｍａｇｅ ｕｐ－ｓａｍｐｌｉｎｇ ｕｓｉｎｇ ｔｏｔａｌ－ｖａｒｉａｔｉｏｎ ａｎｄ ｆｌｏｗ ｃｏｒｒｅｌａｔｉｏｎ ｆｏｒ ａｃｔｉｏｎ ｒｅｃｏｇｎｉｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
ｒｅｇｕｌａｒｉｚａｔｉｏｎ ｗｉｔｈ ａ ｎｅｗ ｏｂｓｅｒｖａｔｉｏｎ ｍｏｄｅｌ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
ｏｎ Ｉｍａｇｅ Ｐｒｏｃｅｓｓｉｎｇ，２０１５，１４（１０）：１６４７－１６５９ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｍｉｎｎｅａｐｏｌｉｓ，ＵＳＡ，２００７：１－８
［１０５］ Ｆｒｅｅｍａｎ Ｗ Ｔ，Ｐａｓｚｔｏｒ Ｅ Ｃ，Ｃａｒｍｉｃｈａｅｌ Ｏ Ｔ．Ｌｅａｒｎｉｎｇ ［１１８］ Ｂｏｂｉｃｋ Ａ Ｆ，Ｄａｖｉｓ Ｊ Ｗ．Ｔｈｅ ｒｅｃｏｇｎｉｔｉｏｎ ｏｆ ｈｕｍａｎ ｍｏｖｅｍｅｎｔ
ｌｏｗ－ｌｅｖｅｌ ｖｉｓｉｏｎ．Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ， ｕｓｉｎｇ ｔｅｍｐｏｒａｌ ｔｅｍｐｌａｔｅｓ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｐａｔｔｅｒｎ
２０００，４０（１）：２５－４７ Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２００１，２３（３）：２５７－２６７
［１０６］ Ｙａｎｇ Ｊ，Ｗｒｉｇｈｔ Ｊ，Ｈｕａｎｇ Ｔ，Ｍａ Ｙ．Ｉｍａｇｅ ｓｕｐｅｒ－ｒｅｓｏｌｕｔｉｏｎ ［１１９］ Ｌｖ Ｆ，Ｎｅｖａｔｉａ Ｒ．Ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｓｅｇｍｅｎｔａｔｉｏｎ ｏｆ ３－Ｄ
ａｓ ｓｐａｒｓｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｏｆ ｒａｗ ｉｍａｇｅ ｐａｔｃｈｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｈｕｍａｎ ａｃｔｉｏｎ ｕｓｉｎｇ ＨＭＭ ａｎｄ ｍｕｌｔｉ－ｃｌａｓｓ ＡｄａＢｏｏｓｔ／／
ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｅｕｒｏｐｅａｎ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ
Ｒｅｃｏｇｎｉｔｉｏｎ．Ａｎｃｈｏｒａｇｅ，ＵＳＡ，２００８：１－８ Ｖｉｓｉｏｎ．Ｇｒａｚ，Ａｕｓｔｒｉａ，２００６：３５９－３７２ ４８０ 计 算 机 学 报 ２０１９年
［１２０］ Ｗａｎｇ Ｈ，Ｋｌｓｅｒ Ａ，Ｓｃｈｍｉｄ Ｃ，ｅｔ ａｌ．Ｄｅｎｓｅ ｔｒａｊｅｃｔｏｒｉｅｓ ａｎｄ ［１３４］ Ｋａｒｐａｔｈｙ Ａ，Ｔｏｄｅｒｉｃｉ Ｇ，Ｓｈｅｔｔｙ Ｓ，ｅｔ ａｌ．Ｌａｒｇｅ－ｓｃａｌｅ ｖｉｄｅｏ
ｍｏｔｉｏｎ ｂｏｕｎｄａｒｙ ｄｅｓｃｒｉｐｔｏｒｓ ｆｏｒ ａｃｔｉｏｎ ｒｅｃｏｇｎｉｔｉｏｎ．Ｉｎｔｅｒｎａ－ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｗｉｔｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｔｉｏｎａｌ Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ，２０１３，１０３（１）：６０－７９ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
［１２１］ Ｔｒａｎ Ｓ Ｄ，Ｄａｖｉｓ Ｌ Ｓ．Ｅｖｅｎｔ ｍｏｄｅｌｉｎｇ ａｎｄ ｒｅｃｏｇｎｉｔｉｏｎ ｕｓｉｎｇ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４：１７２５－１７３２
Ｍａｒｋｏｖ ｌｏｇｉｃ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｅｕｒｏｐｅａｎ ［１３５］ Ｓｉｍｏｎｙａｎ Ｋ，Ｚｉｓｓｅｒｍａｎ Ａ．Ｔｗｏ－ｓｔｒｅａｍ ｃｏｎｖｏｌｕｔｉｏｎａｌ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｍａｒｓｅｉｌｌｅ，Ｆｒａｎｃｅ，２００８： ｎｅｔｗｏｒｋｓ ｆｏｒ ａｃｔｉｏｎ ｒｅｃｏｇｎｉｔｉｏｎ ｉｎ ｖｉｄｅｏｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
６１０－６２３ ｔｈｅ Ａｄｖａｎｃｅｓ ｉｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．
［１２２］ Ｄａｍｅｎ Ｄ，Ｈｏｇｇ Ｄ．Ｒｅｃｏｇｎｉｚｉｎｇ ｌｉｎｋｅｄ ｅｖｅｎｔｓ：Ｓｅａｒｃｈｉｎｇ Ｍｏｎｔｒｅａｌ，Ｃａｎａｄａ，２０１４：５６８－５７６
ｔｈｅ ｓｐａｃｅ ｏｆ ｆｅａｓｉｂｌｅ ｅｘｐｌａｎａｔｉｏｎｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ ［１３６］ Ｌｉｕ Ｙ，Ｘｕ Ｄ，Ｔｓａｎｇ Ｉ，Ｌｕｏ Ｊ．Ｕｓｉｎｇ ｌａｒｇｅ－ｓｃａｌｅ ｗｅｂ ｄａｔａ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ． ｔｏ ｆａｃｉｌｉｔａｔｅ ｔｅｘｔｕａｌ ｑｕｅｒｙ ｂａｓｅｄ ｒｅｔｒｉｅｖａｌ ｏｆ ｃｏｎｓｕｍｅｒ ｐｈｏｔｏｓ／／
Ｍｉａｍｉ，ＵＳＡ，２００９：９２７－９３４ Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ
［１２３］Ｉｖａｎｏｖ Ｙ Ａ，Ｂｏｂｉｃｋ Ａ Ｆ．Ｒｅｃｏｇｎｉｔｉｏｎ ｏｆ ｖｉｓｕａｌ ａｃｔｉｖｉｔｉｅｓ Ｍｕｌｔｉｍｅｄｉａ．Ｂｅｉｊｉｎｇ，Ｃｈｉｎａ，２００９：５５－６４
ａｎｄ ｉｎｔｅｒａｃｔｉｏｎｓ ｂｙ ｓｔｏｃｈａｓｔｉｃ ｐａｒｓｉｎｇ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ
［１３７］Ｊｅｏｎ Ｊ，Ｌａｖｒｅｎｋｏ Ｖ，Ｍａｎｍａｔｈａ Ｒ．Ａｕｔｏｍａｔｉｃ ｉｍａｇｅ ａｎｎｏ－
ｏｎ Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０００，２２（８）： ｔａｔｉｏｎ ａｎｄ ｒｅｔｒｉｅｖａｌ ｕｓｉｎｇ ｃｒｏｓｓ－ｍｅｄｉａ ｒｅｌｅｖａｎｃｅ ｍｏｄｅｌｓ／／
８５２－８７２
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＡＣＭ ＳＩＧＩＲ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｒｅｓｅａｒｃｈ ａｎｄ
［１２４］Ｊｏｏ Ｓ Ｗ，Ｃｈｅｌｌａｐｐａ Ｒ．Ａｔｔｒｉｂｕｔｅ ｇｒａｍｍａｒ－ｂａｓｅｄ ｅｖｅｎｔ Ｄｅｖｅｌｏｐｍｅｎｔ ｉｎ Ｉｎｆｏｒｍａｔｉｏｎ Ｒｅｔｒｉｅｖａｌ．Ｔｏｒｏｎｔｏ，Ｃａｎａｄａ，
ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ａｎｏｍａｌｙ ｄｅｔｅｃｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ
２００３：１１９－１２６
［１３８］ Ｆｅｒｇｕｓ Ｒ，Ｌｉ Ｆｅｉ－Ｆｅｉ，Ｐｅｒｏｎａ Ｐ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ ｏｂｊｅｃｔ
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ
Ｗｏｒｋｓｈｏｐｓ．Ｎｅｗ Ｙｏｒｋ，ＵＳＡ，２００６：１０７－１０７
ｃａｔｅｇｏｒｉｅｓ ｆｒｏｍ Ｇｏｏｇｌｅ’ｓ ｉｍａｇｅ ｓｅａｒｃｈ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｂｅｉｊｉｎｇ，
［１２５］ Ｚｈａｎｇ Ｚ，Ｔａｎ Ｔ，Ｈｕａｎｇ Ｋ．Ａｎ ｅｘｔｅｎｄｅｄ ｇｒａｍｍａｒ ｓｙｓｔｅｍ
Ｃｈｉｎａ，２００５：１８１６－１８２３
ｆｏｒ ｌｅａｒｎｉｎｇ ａｎｄ ｒｅｃｏｇｎｉｚｉｎｇ ｃｏｍｐｌｅｘ ｖｉｓｕａｌ ｅｖｅｎｔｓ．ＩＥＥＥ
［１３９］ Ｚｈｅｎｇ Ｙ，Ｚｈａｎｇ Ｙ，Ｌａｒｏｃｈｅｌｌｅ Ｈ．Ｔｏｐｉｃ ｍｏｄｅｌｉｎｇ ｏｆ ｍｕｌｔｉ－
Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，
ｍｏｄａｌ ｄａｔａ：Ａｎ ａｕｔｏｒｅｇｒｅｓｓｉｖｅ ａｐｐｒｏａｃｈ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
２０１１，３３（２）：２４０－２５５
ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
［１２６］ Ｇｏｒｅｌｉｃｋ Ｌ，Ｂｌａｎｋ Ｍ，Ｓｈｅｃｈｔｍａｎ Ｅ，ｅｔ ａｌ．Ａｃｔｉｏｎｓ ａｓ
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｃｏｌｕｍｂｕｓ，ＵＳＡ，２０１４：１３７０－１３７７
ｓｐａｃｅ－ｔｉｍｅ ｓｈａｐｅｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔｅｒｎａｔｉｏｎａｌ
［１４０］ Ｎｉｂｌａｃｋ Ｗ，Ｂａｒｂｅｒ Ｒ，Ｅｑｕｉｔｚ Ｗ，ｅｔ ａｌ．Ｔｈｅ ＱＢＩＣ ｐｒｏｊｅｃｔ：
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｂｅｉｊｉｎｇ，Ｃｈｉｎａ，２００５：
Ｑｕｅｒｙｉｎｇ ｉｍａｇｅｓ ｂｙ ｃｏｎｔｅｎｔ ｕｓｉｎｇ ｃｏｌｏｒ，ｔｅｘｔｕｒｅ，ａｎｄ
１３９５－１４０２
ｓｈａｐｅ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＳ＆Ｔ／ＳＰＩＥ’ｓ Ｓｙｍｐｏｓｉｕｍ ｏｎ
［１２７］ Ｓｃｈｕｌｄｔ Ｃ，Ｌａｐｔｅｖ Ｉ，Ｃａｐｕｔｏ Ｂ．Ｒｅｃｏｇｎｉｚｉｎｇ ｈｕｍａｎ ａｃｔｉｏｎｓ：
Ｅｌｅｃｔｒｏｎｉｃ Ｉｍａｇｉｎｇ：Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ．Ｓａｎ Ｊｏｓｅ，
Ａ ｌｏｃａｌ ＳＶＭ ａｐｐｒｏａｃｈ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ
ＵＳＡ，１９９３：１７３－１８１
Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｃａｍｂｒｉｄｇｅ，ＵＫ，２００４：
［１４１］ Ｂａｃｈ Ｊ，Ｆｕｌｌｅｒ Ｃ，Ｇｕｐｔａ Ａ，ｅｔ ａｌ．Ｖｉｒａｇｅ ｉｍａｇｅ ｓｅａｒｃｈ ｅｎｇｉｎｅ：
３２－３６
Ａｎ ｏｐｅｎ ｆｒａｍｅｗｏｒｋ ｆｏｒ ｉｍａｇｅ ｍａｎａｇｅｍｅｎｔ．Ｅｌｅｃｔｒｏｎｉｃ
［１２８］ Ｍａｒｓｚａｌｅｋ Ｍ，Ｌａｐｔｅｖ Ｉ，Ｓｃｈｍｉｄ Ｃ．Ａｃｔｉｏｎｓ ｉｎ ｃｏｎｔｅｘｔ／／
Ｉｍａｇｉｎｇ：Ｓｃｉｅｎｃｅ＆Ｔｅｃｈｎｏｌｏｇｙ，１９９６，２６７０（１）：７６－８７
Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ
［１４２］ Ｘｉａ Ｒ，Ｐａｎ Ｙ，Ｌａｉ Ｈ，ｅｔ ａｌ．Ｓｕｐｅｒｖｉｓｅｄ ｈａｓｈｉｎｇ ｆｏｒ ｉｍａｇｅ
ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｍｉａｍｉ，ＵＳＡ，２００９：２９２９－２９３６
ｒｅｔｒｉｅｖａｌ ｖｉａ ｉｍａｇｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
［１２９］ Ｓｏｏｍｒｏ Ｋ，Ｚａｍｉｒ Ａ Ｒ，Ｓｈａｈ Ｍ．ＵＣＦ１０１：Ａ ｄａｔａｓｅｔ ｏｆ １０１
ｔｈｅ Ａｓｓｏｃｉａｔｉｏｎ ｆｏｒ ｔｈｅ Ａｄｖａｎｃｅｍｅｎｔ ｏｆ Ａｒｔｉｆｉｃｉａｌ Ｉｎｔｅｌｌｉｇｅｎｃｅ．
ｈｕｍａｎ ａｃｔｉｏｎｓ ｃｌａｓｓｅｓ ｆｒｏｍ ｖｉｄｅｏｓ ｉｎ ｔｈｅ ｗｉｌｄ．ａｒＸｉｖ：
Ｑｕéｂｅｃ Ｃｉｔｙ，Ｃａｎａｄａ，２０１４：２１５６－２１６２
１２１２．０４０２．２０１２ ［１４３］ Ｗａｎ Ｊ，Ｗａｎｇ Ｄ，Ｈｏｉ Ｓ Ｃ，ｅｔ ａｌ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆｏｒ ｃｏｎｔｅｎｔ－
［１３０］ Ｋｕｅｈｎｅ Ｈ，Ｊｈｕａｎｇ Ｈ，Ｇａｒｒｏｔｅ Ｅ，ｅｔ ａｌ．ＨＭＤＢ：Ａ ｌａｒｇｅ ｂａｓｅｄ ｉｍａｇｅ ｒｅｔｒｉｅｖａｌ：Ａ ｃｏｍｐｒｅｈｅｎｓｉｖｅ ｓｔｕｄｙ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｖｉｄｅｏ ｄａｔａｂａｓｅ ｆｏｒ ｈｕｍａｎ ｍｏｔｉｏｎ ｒｅｃｏｇｎｉｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｏｆ ｔｈｅ ＡＣＭ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｍｕｌｔｉｍｅｄｉａ．Ｏｒｌａｎ－
ｏｆ ｔｈｅ Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｂａｒｃｅｌｏｎａ， ｄｏ，ＵＳＡ，２０１４：１５７－１６６
Ｓｐａｉｎ，２０１１：２５５６－２５６３ ［１４４］ Ｚｈａｏ Ｆ，Ｈｕａｎｇ Ｙ，Ｗａｎｇ Ｌ，Ｔａｎ Ｔ．Ｄｅｅｐ ｓｅｍａｎｔｉｃ ｒａｎｋｉｎｇ
［１３１］Ｊｉ Ｓ，Ｘｕ Ｗ，Ｙａｎｇ Ｍ，Ｙｕ Ｋ．３Ｄｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｂａｓｅｄ ｈａｓｈｉｎｇ ｆｏｒ ｍｕｌｔｉ－ｌａｂｅｌ ｉｍａｇｅ ｒｅｔｒｉｅｖａｌ／／Ｐｒｏｃｅｅｄｉｎｇｓ
ｎｅｔｗｏｒｋｓ ｆｏｒ ｈｕｍａｎ ａｃｔｉｏｎ ｒｅｃｏｇｎｉｔｉｏｎ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
ｏｎ Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０１３，３５（１）： Ｒｅｃｏｇｎｉｔｉｏｎ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：１５５６－１５６４
２２１－２３１ ［１４５］ Ｌａｉ Ｈ，Ｐａｎ Ｙ，Ｌｉｕ Ｙ，Ｙａｎ Ｓ．Ｓｉｍｕｌｔａｎｅｏｕｓ ｆｅａｔｕｒｅ ｌｅａｒｎｉｎｇ
［１３２］ Ｖａｒｏｌ Ｇ，Ｌａｐｔｅｖ Ｉ，Ｓｃｈｍｉｄ Ｃ．Ｌｏｎｇ－ｔｅｒｍ ｔｅｍｐｏｒａｌ ｃｏｎｖｏｌｕ－ ａｎｄ ｈａｓｈ ｃｏｄｉｎｇ ｗｉｔｈ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ
ｔｉｏｎｓ ｆｏｒ ａｃｔｉｏｎ ｒｅｃｏｇｎｉｔｉｏｎ．ＩＥＥＥ Ｔｒａｎｓａｃｔｉｏｎｓ ｏｎ Ｐａｔｔｅｒｎ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
Ａｎａｌｙｓｉｓ ａｎｄ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０１７，ＰＰ（９９）：１－８ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｂｏｓｔｏｎ，ＵＳＡ，２０１５：３２７０－３２７８
［１３３］ Ｃｈｅｒｏｎ Ｇ，Ｌａｐｔｅｖ Ｉ，Ｓｃｈｍｉｄ Ｃ．Ｐ－ＣＮＮ：Ｐｏｓｅ－ｂａｓｅｄ ＣＮＮ ［１４６］ Ｌｉｕ Ｈ，Ｗａｎｇ Ｒ，Ｓｈａｎ Ｓ，Ｃｈｅｎ Ｘ．Ｄｅｅｐ ｓｕｐｅｒｖｉｓｅｄ ｈａｓｈｉｎｇ
ｆｅａｔｕｒｅｓ ｆｏｒ ａｃｔｉｏｎ ｒｅｃｏｇｎｉｔｉｏｎ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ ｆｏｒ ｆａｓｔ ｉｍａｇｅ ｒｅｔｒｉｅｖａｌ／／Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆｅｒｅｎｃｅ
Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｃｏｎｆｅｒｅｎｃｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｓａｎｔｉａｇｏ， ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｌａｓ Ｖｅｇａｓ，
Ｃｈｉｌｅ，２０１５：３２１８－３２２６ ＵＳＡ，２０１６：２０６４－２０７２ ３期 张 顺等：深度卷积神经网络的发展及其在计算机视觉领域的应用 ４８１
［１４７］ Ｈｕｂｅｌ Ｄ Ｈ，Ｗｉｅｓｅｌ Ｔ Ｎ．Ｒｅｃｅｐｔｉｖｅ ｆｉｅｌｄｓ ｏｆ ｓｉｎｇｌｅ ｎｅｕｒｏｎｓ ［１６０］ Ｃｈｅｎ Ｌ．Ｔｏｐｏｌｏｇｉｃａｌ ｓｔｒｕｃｔｕｒｅ ｉｎ ｖｉｓｕａｌ ｐｅｒｃｅｐｔｉｏｎ．Ｓｃｉｅｎｃｅ，
ｉｎ ｔｈｅ ｃａｔ’ｓ ｓｔｒｉａｔｅ ｃｏｒｔｅｘ．Ｔｈｅ Ｊｏｕｒｎａｌ ｏｆ Ｐｈｙｓｉｏｌｏｇｙ， １９８２，２１８：６９９－７００
１９５９，１４８（３）：５７４－５９１ ［１６１］ Ｃｈｅｎ Ｌ，Ｚｈａｎｇ Ｓ Ｗ，Ｓｒｉｎｉｖａｓａｎ Ｍ．Ｇｌｏｂａｌ ｐｅｒｃｅｐｔｉｏｎ ｉｎ
［１４８］ Ｕｎｇｅｒｌｅｉｄｅｒ Ｌ Ｇ，Ｊａｍｅｓ Ｖ Ｈ．“Ｗｈａｔ”ａｎｄ“ｗｈｅｒｅ”ｉｎ ｔｈｅ ｓｍａｌｌ ｂｒａｉｎｓ：Ｔｏｐｏｌｏｇｉｃａｌ ｐａｔｔｅｒｎ ｒｅｃｏｇｎｉｔｉｏｎ ｉｎ ｈｏｎｅｙｂｅｅｓ．
ｈｕｍａｎ ｂｒａｉｎ．Ｃｕｒｒｅｎｔ Ｏｐｉｎｉｏｎ ｉｎ Ｎｅｕｒｏｂｉｏｌｏｇｙ，１９９４， Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｎａｔｉｏｎａｌ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅ ｏｆ ｔｈｅ
４（２）：１５７－１６５ ＵＳＡ，２００３，１００（１１）：６８８４－６８８９
［１４９］ Ｕｎｇｅｒｌｅｉｄｅｒ Ｌ Ｇ，Ｓｕｓａｎ Ｍ Ｃ，Ｊａｍｅｓ Ｖ Ｈ．Ａ ｎｅｕｒａｌ ｓｙｓｔｅｍ ［１６２］ Ｚｈｕｏ Ｙ，Ｚｈｏｕ Ｔ Ｇ，Ｒａｏ Ｈ Ｙ，ｅｔ ａｌ．Ｃｏｎｔｒｉｂｕｔｉｏｎｓ ｏｆ ｔｈｅ
ｆｏｒ ｈｕｍａｎ ｖｉｓｕａｌ ｗｏｒｋｉｎｇ ｍｅｍｏｒｙ．Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ ｖｉｓｕａｌ ｖｅｎｔｒａｌ ｐａｔｈｗａｙ ｔｏ ｌｏｎｇ－ｒａｎｇｅ ａｐｐａｒｅｎｔ ｍｏｔｉｏｎ．
Ｎａｔｉｏｎａｌ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ，１９９８，９５（３）：８８３－８９０ Ｓｃｉｅｎｃｅ，２００３，２９９：４１７－４２０
［１５０］ Ｕｎｇｅｒｌｅｉｄｅｒ Ｌ Ｇ．Ｆｕｎｃｔｉｏｎａｌ ｂｒａｉｎ ｉｍａｇｉｎｇ ｓｔｕｄｉｅｓ ｏｆ ｃｏｒｔｉｃａｌ ［１６３］ Ｃｈｅｎ Ｌ．Ｔｈｅ ｔｏｐｏｌｏｇｉｃａｌ ａｐｐｒｏａｃｈ ｔｏ ｐｅｒｃｅｐｔｕａｌ ｏｒｇａｎｉｚａｔｉｏｎ．
ｍｅｃｈａｎｉｓｍｓ ｆｏｒ ｍｅｍｏｒｙ．Ｓｃｉｅｎｃｅ，１９９５，２７０（５２３７）：７６９－ Ｖｉｓｕａｌ Ｃｏｇｎｉｔｉｏｎ，２００５，１２：５５３－６３７
７７５ ［１６４］ Ｚｈｕｏ Ｙ，Ｚｈｏｕ Ｔ Ｇ，Ｒａｏ Ｈ Ｙ，ｅｔ ａｌ．Ｃｏｎｔｒｉｂｕｔｉｏｎｓ ｏｆ ｔｈｅ
［１５１］ ＤｉＣａｒｌｏ Ｊ Ｊ，Ｚｏｃｃｏｌａｎ Ｄ，Ｒｕｓｔ Ｎ Ｃ．Ｈｏｗ ｄｏｅｓ ｔｈｅ ｂｒａｉｎ ｖｉｓｕａｌ ｖｅｎｔｒａｌ ｐａｔｈｗａｙ ｔｏ ｌｏｎｇ－ｒａｎｇｅ ａｐｐａｒｅｎｔ ｍｏｔｉｏｎ．
ｓｏｌｖｅ ｖｉｓｕａｌ ｏｂｊｅｃｔ ｒｅｃｏｇｎｉｔｉｏｎ？Ｎｅｕｒｏｎ，２０１２，７３（３）：４１５－ Ｓｃｉｅｎｃｅ，２００３，２９９：４１７－４２０
４３４ ［１６５］ Ｗａｎｇ Ｂ，Ｚｈｏｕ Ｔ Ｇ，Ｚｈｕｏ Ｙ，Ｃｈｅｎ Ｌ．Ｇｌｏｂａｌ ｔｏｐｏｌｏｇｉｃａｌ
［１５２］ Ｐｏｇｇｉｏ Ｔ，Ｕｌｌｍａｎ Ｓ．Ｖｉｓｉｏｎ：Ａｒｅ ｍｏｄｅｌｓ ｏｆ ｏｂｊｅｃｔ ｒｅｃｏｇｎｉｔｉｏｎ ｄｏｍｉｎａｎｃｅ ｉｎ ｔｈｅ ｌｅｆｔ ｈｅｍｉｓｐｈｅｒｅ．Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ
ｃａｔｃｈｉｎｇ ｕｐ ｗｉｔｈ ｔｈｅ ｂｒａｉｎ？Ａｎｎａｌｓ ｏｆ ｔｈｅ Ｎｅｗ Ｙｏｒｋ Ａｃａｄｅｍｙ Ｎａｔｉｏｎａｌ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ，２００７，１０４：２１０１４－２１０１９
ｏｆ Ｓｃｉｅｎｃｅｓ，２０１３，１３０５（１）：７２－８２ ［１６６］ Ｚｈｏｕ Ｋ，Ｈｕａｎ Ｌ，Ｚｈｏｕ Ｔ Ｇ，ｅｔ ａｌ．Ｔｏｐｏｌｏｇｉｃａｌ ｃｈａｎｇｅ
［１５３］ Ｐｏｇｇｉｏ Ｔ，Ｓｅｒｒｅ Ｔ．Ｍｏｄｅｌｓ ｏｆ ｖｉｓｕａｌ ｃｏｒｔｅｘ．Ｓｃｈｏｌａｒｐｅｄｉａ， ｄｉｓｔｕｒｂｓ ｏｂｊｅｃｔ ｃｏｎｔｉｎｕｉｔｙ ｉｎ ａｔｔｅｎｔｉｖｅ ｔｒａｃｋｉｎｇ．Ｐｒｏｃｅｅｄｉｎｇｓ
２０１３，８（４）：３５１６ ｏｆ ｔｈｅ Ｎａｔｉｏｎａｌ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ，２０１０，１０７（５０）：
［１５４］ Ａｎｓｅｌｍｉ Ｆ，Ｐｏｇｇｉｏ Ｔ Ａ．Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｌｅａｒｎｉｎｇ ｉｎ ｓｅｎｓｏｒｙ ２１９２０－２１９２４
ｃｏｒｔｅｘ：Ａ ｔｈｅｏｒｙ．Ｃｅｎｔｅｒ ｆｏｒ Ｂｒａｉｎｓ，Ｍｉｎｄｓ ａｎｄ Ｍａｃｈｉｎｅｓ ［１６７］ Ｈａｎ Ｓｈｉ－Ｈｕｉ，Ｃｈｅｎ Ｌｉｎ．Ｔｈｅ ｒｅｌａｔｉｏｎｓｈｉｐ ｏｆ ｇｌｏｂａｌ ｆｅａｔｕｒｅ
（ＣＢＭＭ），２０１４，２６：１－５６ ａｎｄ ｌｏｃａｌ ｆｅａｔｕｒｅ—Ｇｌｏｂａｌ ｐｒｅｃｅｄｅｎｃｅ．Ｄｙｎａｍｉｃ Ｐｓｙｃｈｏｌｏｇｙ，
［１５５］ Ｕｌｌｍａｎ Ｓ，Ｈｕｍｐｈｒｅｙｓ Ｇ Ｗ．Ｈｉｇｈ－Ｌｅｖｅｌ Ｖｉｓｉｏｎ：Ｏｂｊｅｃｔ １９９６，４（１）：３６－４１（ｉｎ Ｃｈｉｎｅｓｅ）
Ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ Ｖｉｓｕａｌ Ｃｏｇｎｉｔｉｏｎ．Ｃａｍｂｒｉｄｇｅ，ＵＳＡ：ＭＩＴ （韩世辉，陈霖．整体性质和局部性质的关系———大范围优
Ｐｒｅｓｓ，１９９６ 先性．心理学动态，１９９６，４（１）：３６－４１）
［１５６］ Ｐｉｎｔｏ Ｎ，Ｃｏｘ Ｄ Ｄ，ＤｉＣａｒｌｏ Ｊ Ｊ．Ｗｈｙ ｉｓ ｒｅａｌ－ｗｏｒｌｄ ｖｉｓｕａｌ ［１６８］ Ｈｏｃｈｓｔｅｉｎ Ｓ，Ａｈｉｓｓａｒ Ｍ．Ｖｉｅｗ ｆｒｏｍ ｔｈｅ ｔｏｐ：Ｈｉｅｒａｒｃｈｉｅｓ
ｏｂｊｅｃｔ ｒｅｃｏｇｎｉｔｉｏｎ ｈａｒｄ？ＰＬｏＳ Ｃｏｍｐｕｔａｔｉｏｎａｌ Ｂｉｏｌｏｇｙ， ａｎｄ ｒｅｖｅｒｓｅ ｈｉｅｒａｒｃｈｉｅｓ ｉｎ ｔｈｅ ｖｉｓｕａｌ ｓｙｓｔｅｍ．Ｎｅｕｒｏｎ，２００２，
２００８，４（１）：ｅ２７ ３６（５）：７９１－８０４
［１５７］ Ｔｒｅｉｓｍａｎ Ａ Ｍ，Ｇｅｌａｄｅ Ｇ．Ａ ｆｅａｔｕｒｅ－ｉｎｔｅｇｒａｔｉｏｎ ｔｈｅｏｒｙ ｏｆ ［１６９］ Ａｈｉｓｓａｒ Ｍ，Ｈｏｃｈｓｔｅｉｎ Ｓ．Ｔｈｅ ｒｅｖｅｒｓｅ ｈｉｅｒａｒｃｈｙ ｔｈｅｏｒｙ ｏｆ
ａｔｔｅｎｔｉｏｎ．Ｃｏｇｎｉｔｉｖｅ Ｐｓｙｃｈｏｌｏｇｙ，１９８０，１２（１）：９７－１３６ ｖｉｓｕａｌ ｐｅｒｃｅｐｔｕａｌ ｌｅａｒｎｉｎｇ．Ｔｒｅｎｄｓ ｉｎ Ｃｏｇｎｉｔｉｖｅ Ｓｃｉｅｎｃｅｓ，
［１５８］ Ｍａｒｒ Ｄ．Ｖｉｓｉｏｎ：Ａ ｃｏｍｐｕｔａｔｉｏｎａｌ Ｉｎｖｅｓｔｉｇａｔｉｏｎ Ｉｎｔｏ ｔｈｅ ２００４，８（１０）：４５７－４６４
Ｈｕｍａｎ Ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ａｎｄ Ｐｒｏｃｅｓｓｉｎｇ ｏｆ Ｖｉｓｕａｌ Ｉｎｆｏｒｍａｔｉｏｎ． ［１７０］ Ｂａｒ Ｍ．Ａ ｃｏｒｔｉｃａｌ ｍｅｃｈａｎｉｓｍ ｆｏｒ ｔｒｉｇｇｅｒｉｎｇ ｔｏｐ－ｄｏｗｎ
Ｓａｎ Ｆｒａｎｃｉｓｃｏ，ＵＳＡ：Ｗ．Ｈ．Ｆｒｅｅｍａｎ ａｎｄ Ｃｏｍｐａｎｙ，１９８２ ｆａｃｉｌｉｔａｔｉｏｎ ｉｎ ｖｉｓｕａｌ ｏｂｊｅｃｔ ｒｅｃｏｇｎｉｔｉｏｎ．Ｊｏｕｒｎａｌ ｏｆ Ｃｏｇｎｉｔｉｖｅ
［１５９］ Ｎａｖｏｎ Ｄ．Ｆｏｒｅｓｔ ｂｅｆｏｒｅ ｔｒｅｅｓ：Ｔｈｅ ｐｒｅｃｅｄｅｎｃｅ ｏｆ ｇｌｏｂａｌ ｎｅｕｒｏｓｃｉｅｎｃｅ，２００３，１５（４）：６００－６０９
ｆｅａｔｕｒｅｓ ｉｎ ｖｉｓｕａｌ ｐｅｒｃｅｐｔｉｏｎ．Ｃｏｇｎｉｔｉｖｅ Ｐｓｙｃｈｏｌｏｇｙ，１９７７， ［１７１］ ＬｅＣｕｎ Ｙ，Ｂｅｎｇｉｏ Ｙ，Ｈｉｎｔｏｎ Ｇ．Ｄｅｅｐ ｌｅａｒｎｉｎｇ．Ｎａｔｕｒｅ，
９（３）：３５３－３８３ ２０１５，５２１（７５５３）：４３６－４４４
ＺＨＡＮＧ Ｓｈｕｎ，ｂｏｒｎ ｉｎ １９８７，Ｐｈ．Ｄ．， ＧＯＮＧ Ｙｉ－Ｈｏｎｇ，ｂｏｒｎ ｉｎ １９６３，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ，
ａｓｓｉｓｔａｎｔ ｐｒｏｆｅｓｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ Ｐｈ．Ｄ．ｓｕｐｅｒｖｉｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｍｕｌｔｉｍｅｄｉａ
ｉｎｃｌｕｄｅ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ ａｎｄ ｍａｃｈｉｎｅ ｃｏｎｔｅｎｔ ａｎａｌｙｓｉｓ，ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ａｎｄ ｐａｔｔｅｒｎ ｒｅｃｏｇｎｉｔｉｏｎ
ｌｅａｒｎｉｎｇ． ＷＡＮＧ Ｊｉｎ－Ｊｕｎ，ｂｏｒｎ ｉｎ １９７７，Ｐｈ．Ｄ．，ｐｒｏｆｅｓｓｏｒ，Ｐｈ．
Ｄ．ｓｕｐｅｒｖｉｓｏｒ．Ｈｉｓ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｐａｔｔｅｒｎ ｒｅｃｏｇｎｉ－
ｔｉｏｎ，ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ ａｎｄ ｍｕｌｔｉｍｅｄｉａ ｃｏｍｐｕｔｉｎｇ． ４８２ 计 算 机 学 报 ２０１９年
Ｂａｃｋｇｒｏｕｎｄ
Ｂｅｎｅｆｉｔｅｄ ｂｙ ｔｈｅ ｒａｐｉｄ ｇｒｏｗｔｈ ｉｎ ｔｈｅ ａｍｏｕｎｔ ｏｆ ｔｈｅ Ｐｒｏｇｒａｍ（９７３Ｐｒｏｇｒａｍ）ｏｆ Ｃｈｉｎａ ｕｎｄｅｒ Ｇｒａｎｔ Ｎｏ．２０１５ＣＢ３５１７０５，
ａｎｎｏｔａｔｅｄ ｄａｔａ ａｎｄ ｔｈｅ ｒｅｃｅｎｔ ｉｍｐｒｏｖｅｍｅｎｔｓ ｉｎ ｔｈｅ ｓｔｒｅｎｇｔｈｓ ｔｈｅ Ｓｔａｔｅ Ｋｅｙ Ｐｒｏｇｒａｍ ｏｆ Ｎａｔｉｏｎａｌ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ Ｆｏｕｎｄａｔｉｏｎ
ｏｆ ｇｒａｐｈｉｃｓ ｐｒｏｃｅｓｓｏｒ ｕｎｉｔｓ（ＧＰＵｓ），ｔｈｅ ｒｅｓｅａｒｃｈ ｏｎ ｃｏｎｖｏ－ ｏｆ Ｃｈｉｎａ ｕｎｄｅｒ Ｇｒａｎｔ Ｎｏ．６１３３２０１８，ｔｈｅ Ｙｏｕｔｈ Ｐｒｏｇｒａｍ ｏｆ
ｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｈａｓ ｂｅｅｎ ｗｉｄｅｌｙ ａｐｐｌｉｅｄ ｔｏ ｍａｎｙ Ｎａｔｉｏｎａｌ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｃｈｉｎａ ｕｎｄｅｒ Ｇｒａｎｔ
ｆｉｅｌｄｓ ｏｆ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ ａｎｄ ｐａｔｔｅｒｎ ｒｅｃｏｇｎｉｔｉｏｎ，ａｎｄ ｈａｖｅ Ｎｏ．６１７０３３４４，ａｎｄ ｔｈｅ Ｆｕｎｄａｍｅｎｔａｌ Ｒｅｓｅａｒｃｈ Ｆｕｎｄｓ ｆｏｒ ｔｈｅ
ａｔｔｒａｃｔｅｄ ｈｕｇｅ ａｔｔｅｎｔｉｏｎｓ ｆｒｏｍ ｂｏｔｈ ａｃａｄｅｍｉａ ａｎｄ ｉｎｄｕｓｔｒｙ． Ｃｅｎｔｒａｌ Ｕｎｉｖｅｒｓｉｔｉｅｓ ｕｎｄｅｒ Ｇｒａｎｔ Ｎｏ．３１０２０１７ＯＱＤ０２１．Ｏｕｒ
Ｔｈｉｓ ｐａｐｅｒ ａｉｍｓ ｔｏ ｐｒｅｓｅｎｔ ａ ｃｏｍｐｒｅｈｅｎｓｉｖｅ ｉｎｔｒｏｄｕｃｔｉｏｎ ｏｆ ｒｅｓｅａｒｃｈ ｔｅａｍ ｈａｓ ｂｅｅｎ ｗｏｒｋｉｎｇ ｏｎ ｈａｎｄｌｉｎｇ ｖａｒｉｏｕｓ ｔａｓｋｓ
ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ａｎｄ ｉｔｓ ａｐｐｌｉｃａｔｉｏｎｓ ｉｎ ｔｈｅ （ｓｕｃｈ ａｓ ｉｍａｇｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ，ｏｂｊｅｃｔ ｄｅｔｅｃｔｉｏｎ ａｎｄ ｒｅｃｏｇｎｉｔｉｏｎ，
ｆｉｅｌｄ ｏｆ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｗｅ ｆｉｒｓｔ ｉｎｔｒｏｄｕｃｅ ｔｈｅ ｗｏｒｋｉｎｇ ｆａｃｅ ｖｅｒｉｆｉｃａｔｉｏｎ ａｎｄ ｒｅｃｏｇｎｉｔｉｏｎ，ｐｅｒｓｏｎ ｒｅｃｏｇｎｉｔｉｏｎ，ｓｕｐｅｒ
ｐｒｉｎｃｉｐｌｅ ｏｆ ｔｈｅ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ．Ｔｈｅｎ ｗｅ ｌｉｓｔ ｒｅｓｏｌｕｔｉｏｎ，ｅｔｃ．）ｉｎ ｔｈｅ ｆｉｅｌｄ ｏｆ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ｗｉｔｈ ｔｈｅ
ｍａｎｙ ｇｅｎｅｒａｌ ａｐｐｒｏａｃｈｅｓ ｔｈａｔ ａｒｅ ｐｒｏｐｏｓｅｄ ｔｏ ｉｍｐｒｏｖｅ ｔｈｅ ｔｅｃｈｎｉｑｕｅｓ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｆｏｒ ｙｅａｒｓ．Ｗｏｒｋｓ ｒｅｌａｔｅｄ ｔｏ ｔｈｅｓｅ
ｐｅｒｆｏｒｍａｎｃｅ ｏｆ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ，ｉｎｃｌｕｄｉｎｇ ｔｈｅ ｉｎｃｒｅａｓｅ ｐｒｏｊｅｃｔｓ ｈａｖｅ ｂｅｅｎ ｐｕｂｌｉｓｈｅｄ ｉｎ ｉｎｔｅｒｎａｔｉｏｎａｌ ｊｏｕｒｎａｌｓ ａｎｄ
ｏｆ ｓｉｚｅ ａｎｄ ｃｏｍｐｌｅｘｉｔｙ ｏｆ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ，ｔｈｅ ｕｓｅ ｏｆ ｌａｒｇｅｒ ｃｏｎｆｅｒｅｎｃｅｓ，ｓｕｃｈ ａｓ ＴＮＮ，ＩＪＣＶ，ＴＩＰ，ＩＪＣＡＩ，ＣＶＰＲ，
ｓｅｔｓ ｏｆ ｔｒａｉｎｉｎｇ ｄａｔａ，ｔｈｅ ｉｍｐｒｏｖｅｍｅｎｔｓ ｏｆ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ＥＣＣＶ，ｅｔｃ．Ｔｈｅ ｔｅｃｈｎｉｑｕｅ ｏｆ ｄｅｅｐ ｌｅａｒｎｉｎｇ ｈａｓ ｂｅｅｎ ｗｉｄｅｌｙ
ｔｒａｉｎｉｎｇ ｍｅｔｈｏｄｓ，ｅｔｃ．Ｂｅｓｉｄｅｓ，ｗｅ ｓｈｏｗ ｍａｎｙ ａｐｐｌｉｃａｔｉｏｎｓ ａｐｐｌｉｅｄ ｉｎ ｖａｒｉｏｕｓ ｆｉｌｅｄｓ，ａｎｄ ｉｔｓ ｐｏｗｅｒ ｃａｐａｂｉｌｉｔｙ ｏｆ ｌｅａｒｎｉｎｇ
ｏｆ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｉｎ ｔｈｅ ｆｉｅｌｄ ｏｆ ｃｏｍｐｕｔｅｒ ｆｅａｔｕｒｅｓ ｉｓ ｅｘｐｌｏｉｔｅｄ ｂｙ ｕｓ ｔｏ ｌｅａｒｎ ｄｉｓｃｒｉｍｉｎａｔｉｖｅ ｆｅａｔｕｒｅｓ ｆｏｒ
ｖｉｓｉｏｎ．Ｂａｓｅｄ ｏｎ ｔｈｅ ａｂｏｖｅ ａｎａｌｙｓｉｓ，ｗｅ ａｌｓｏ ｐｏｉｎｔ ｏｕｔ ｉｔｓ ｄｉｆｆｅｒｅｎｔ ｏｂｊｅｃｔｓ ｉｎ ｉｍａｇｅｓ ｏｒ ｖｉｄｅｏｓ．Ｔｈｉｓ ｒｅｖｉｅｗ ｐａｐｅｒ ｃａｎ
ｐｏｓｓｉｂｌｅ ｆｕｔｕｒｅ ｄｉｒｅｃｔｉｏｎｓ ｆｒｏｍ ｔｈｅ ｈｕｍａｎ ｖｉｓｕａｌ ｃｏｇｎｉｔｉｖｅ ｈｅｌｐ ｕｓ ｔｏ ｇｅｔ ａ ｕｎｄｅｒｓｔａｎｄｉｎｇ ｏｆ ｔｈｅ ｆｕｎｄａｍｅｎｔａｌ ｓｙｓｔｅｍ，
ｍｅｃｈａｎｉｓｍ． ｇｅｎｅｒａｌｌｙ ｕｓｅｄ ｔｒａｉｎｉｎｇ ｔｅｃｈｎｉｑｕｅｓ，ａｎｄ ｒｅｃｅｎｔ ｄｅｖｅｌｏｐｍｅｎｔｓ ｏｆ
Ｔｈｉｓ ｗｏｒｋ ｉｓ ｓｕｐｐｏｒｔｅｄ ｂｙ ｔｈｅ Ｎａｔｉｏｎａｌ Ｂａｓｉｃ Ｒｅｓｅａｒｃｈ ｔｈｅ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ． --------------------------------------------------------------------------------- 18 2023，59（4） ComputerEngineeringandApplications计算机工程与应用
知识图谱增强的图神经网络推荐研究进展
吴国栋，王雪妮，刘玉良
安徽农业大学 信息与计算机学院，合肥 230036
摘 要：已有推荐方法主要基于用户与项目的历史交互行为，未充分运用用户及项目相关特征信息，推荐效果并不
理想。知识图谱（knowledge graph，KG）增强的图神经网络（graph neural network，GNN）推荐，是以用户与项目交
互行为构建的交互图为基础，引入同为图结构的知识图谱，并运用图神经网络技术进行处理，从而实现个性化推
荐。深入探讨了现有知识图谱增强的图神经网络推荐研究进展。首先在对图神经网络推荐和知识图谱推荐进行探
讨的基础上，从项目知识图谱和协同知识图谱视角，深入分析了当前知识图谱增强的图神经网络推荐取得的相关研
究成果；然后从大规模动态知识图谱处理、用户对项目属性的偏好挖掘、知识图谱的图嵌入学习等方面，指出了已有
知识图谱增强的图神经网络推荐研究存在的主要问题；最后从动态时序知识图谱增强的GNN推荐、元学习的知识
图谱增强GNN推荐、多模态知识图谱增强的GNN推荐、知识图谱增强的GNN跨领域推荐等方面，展望了知识图谱
增强的图神经网络推荐未来主要研究方向。
关键词：知识图谱；图神经网络；推荐系统；项目知识图谱；协同知识图谱
文献标志码：A 中图分类号：TP391 doi：10.3778/j.issn.1002-8331.2205-0268
ResearchAdvancesonGraphNeuralNetworkRecommendationofKnowledgeGraphEnhancement
WUGuodong,WANGXueni,LIUYuliang
SchoolofInformationandComputer,AnhuiAgriculturalUniversity,Hefei230036,China
Abstract：The existing recommendation methods are mainly based on the users’historical interaction behavior, and the
user and item-related feature information are not fully utilized, resulting in the effect of the recommendation is not ideal.
The graph neural network（GNN）recommendation enhanced by knowledge graph（KG）is based on the interaction graph
constructed by user and item interaction behavior, and the knowledge graph with the same graph structure is introduced
and processed by the graph neural network technology, so as to realize personalized recommendation. In this paper, the
research progress of graph neural network recommendation enhanced by existing knowledge graph is discussed. Firstly,
on the basis of the discussion of graph neural network recommendation and knowledge graph recommendation, the rele-
vant research results of graph neural network recommendation enhanced by the current knowledge graph are deeply analyzed
from theaspectsofitem knowledgegraph and collaborativeknowledgegraph.Then,themain problemsin thegraph neural
network recommendation research based on the existing knowledge graph enhancement are pointed out from the aspects
of large-scale dynamic knowledge graph processing, user preference mining for item attributes, knowledge graph embed-
ding learning problem and so on. Finally, the main research directions of GNN recommendation enhanced by knowledge
graph in the future are predicted from the following aspects：GNN recommendation enhanced by knowledge graph in dynamic
sequentialsequence,GNNrecommendationenhancedbyknowledgegraphinmeta-learning,GNNrecommendationenhanced
bymulti-modelknowledgegraph,GNNcross-domainrecommendationenhancedbyknowledgegraphandsoon.
Key words：knowledge graph; graph neural network; recommendation system; item knowledge graph; collaborative
knowledgegraph
随着信息时代的到来，人们从网络上获取信息变得 载[1]，用户难以从海量信息中快速找到感兴趣的内容。
越来越便利。然而信息的爆炸式增长也带来了信息过 推荐系统通过从用户的历史行为中挖掘偏好特征，并推
基金项目：国家自然科学基金（31671589）；安徽省自然科学基金（2108085MF209）；安徽省科技重大专项（202103b06020013）。
作者简介：吴国栋（1972—），男，博士，副教授，CCF会员，研究方向为深度学习、推荐系统，E-mail：8978850@qq.com；王雪妮（1996—），
女，硕士研究生，研究方向为深度学习、推荐系统；刘玉良（1997—），男，硕士研究生，研究方向为深度学习、推荐系统。
收稿日期：2022-05-13 修回日期：2022-10-18 文章编号：1002-8331（2023）04-0018-12 吴国栋，等：知识图谱增强的图神经网络推荐研究进展 2023，59（4） 19
荐可能感兴趣的项目，以提升用户消费体验，使信息过 提出了一种线性残差网络，在对图卷积网络去除非线性
载问题得到了有效缓解。传统的推荐算法可分为协同 变换后，构建残差网络结构，以解决多层图卷积容易导
过滤推荐[2]、基于内容的推荐[3]和混合推荐[4]。相较于传 致的过平滑问题[17]。文献[18]提出了一种考虑高阶特征
统的推荐技术，基于深度学习的推荐方法[5]主要是通过 交互的图卷积网络模型，并将GCN的排序信息提取为
为用户和项目学习其嵌入表示，并基于这种嵌入表示， 二值化协同过滤，提高了在线推荐效果。文献[19]不但
来预测用户与项目的交互概率。 在用户-项目交互图上执行图卷积，还将引入注意力机
作为深度学习技术在图领域的扩展，近年来图神经 制的GCN用在用户-用户社交图上，丰富了用户的嵌入
网络（graph neural network，GNN）[6]被运用于推荐系统 表示，从而进行更准确的评分预测。文献[20]着重解决
的研究中。GNN核心思想是通过传播邻居信息来学习 堆叠多层GCN带来的过平滑问题，通过一个无监督子
目标节点的嵌入表示，对处理图结构数据有着天然优 图生成模块，将兴趣相似的用户及与其交互的项目，构
势。然而，单一的用户-项目交互信息已不足以发挥图 建成子图，并在子图内部执行高阶图卷积，以避免从高
神经网络的学习能力，很多算法仍然面临交互数据稀疏 阶邻居传播负面信息到节点，缓解过平滑问题。文献[21]
以及冷启动等问题，这就需要除用户历史行为外的辅助 也采用了图卷积网络作为编码器，通过重建掩码输入
信息，来帮助推荐模型缓解这些问题。 节点，生成新节点的嵌入，以缓解推荐过程中的冷启动
知识图谱（knowledge graph，KG）[7]是一种反映多 问题。
种关系的有向异质图结构，其中节点对应实体，边对应 尽管图神经网络对挖掘推荐系统中用户偏好与项
关系，以一种三元组[8]的形式表示。知识图谱中蕴含了 目特征具有一定优势，然而单一的用户-项目历史交互
丰富的属性信息，通过不同类型的关系将这些信息与实 信息存在一定的局限性，且交互数据较稀疏时容易导致
体相联系，将知识图谱引入图神经网络推荐研究，借助 冷启动等问题。
知识图谱中物品间丰富的语义关联，以便更好进行物品 1.2 知识图谱推荐
的特征表示，在有效提升推荐准确性的同时，还有助于 传统的推荐方法大多只使用了用户与项目的交互
推荐结果的可解释性。 信息，容易面临数据的稀疏性和冷启动等问题。知识图
按照是否有用户节点加入，可以将知识图谱分为项 谱的引入可以为推荐系统提供项目间丰富的语义相关
目知识图谱和协同知识图谱[9]，与已有知识图谱推荐[10] 性，有助于挖掘它们之间的潜在联系，且不同类型的关
或图神经网络推荐[11]等综述不同，本文以知识图谱的不 系有助于扩展用户兴趣，增加推荐项目的多样性，使用
同类型为视角，探讨知识图谱增强的图神经网络推荐相 这些信息可以进行更加合理的个性化推荐。知识图谱
关研究。其中，基于项目知识图谱增强的模型将用户- 通常用G ={(h,r,t)|h,t∈E,r∈R}的形式表示，其中三元
项目交互图与项目知识图谱分离开，知识图谱中的实体 组(h,r,t)表示头实体h与尾实体t 由关系r 连接，E 和
不直接参与用户嵌入表示的学习；而协同知识图谱则是 R分别表示实体集合和关系集合，在此之上进行知识图
将两图融合，用户嵌入表示的学习也依赖于知识图谱中 谱表示学习[22]。
的实体。本文是探讨两者融合的推荐模型及其相关研 已有知识图谱推荐研究，大多是为项目建立知识
究，既考虑到图神经网络在图结构数据处理上的优势， 图谱，如文献[23]提出了一种协同知识库嵌入（collabor-
又丰富了知识图谱的语义表示。这类模型输入上可以 ative knowledge base embedding，CKE）模型，模型基于
利用的信息更丰富，在处理过程中对图结构数据信息的 正则化的方法，利用嵌入和深度学习技术从项目知识图
挖掘也更加全面细致，提供更精细的节点特征表示。 谱中提取语义表示。文献[24]提出了一种面向知识图
谱增强推荐的多任务特征学习方法（multi-task learning
1 图神经网络推荐与知识图谱推荐 for KG enhanced recommendation，MKR），模型将知识
1.1 图神经网络推荐 图谱嵌入任务和推荐任务通过交叉压缩单元相关联，使
图神经网络（GNN）作为一种处理图结构的深度学 得推荐系统中的项目表示与知识图谱中的实体表示可
习模型，在推荐系统研究中有着一定的优势[12]。现有 以相互补充。文献[25]提出了一种基于异构网络嵌入
GNN推荐的研究，大多基于图卷积网络（graph convolu- 的推荐方法（HIN embedding based recommendation，
tional network，GCN）[13]范畴。文献[14]利用图卷积网 HERec），模型使用基于元路径的随机游走策略，从异质
络作为编码器，并结合双线性解码来构建图自编码器， 信息网络中采样节点序列，用于网络嵌入表示学习。学
以进行用户-项目评分矩阵的补全。文献[15]对图卷积 习节点嵌入时，首先通过一组融合函数进行转换，然后
网络进行简化，去除了特征变换和非线性变换，构建一 集成到扩展矩阵分解（matrix factorization，MF）[26]模型
种轻量级的图卷积方式来传播用户和项目的嵌入，并堆 中，对扩展矩阵分解模型和融合函数进行联合优化，以
叠多层图卷积网络以捕获高阶邻居的特征信息。文献[16] 完成评分预测任务。文献[27]提出了一个将知识图谱 20 2023，59（4） ComputerEngineeringandApplications计算机工程与应用
融合到推荐系统中、端到端的框架（RippleNet）。该方法 处理，通过充分运用关系信息，来发挥知识图谱在推荐
沿着知识图谱中的关系，自动、迭代地扩展用户潜在兴 系统中的作用。
趣，以刺激用户偏好在知识实体集合上的传播。 为了缓解协同过滤推荐中数据稀疏性和冷启动等
知识图谱的引入，为推荐模型提供了更多的信息来 问题，利用用户和项目属性构建知识图。根据知识图中
源，这些信息可以辅助学习用户或项目的特征，以缓解 连接关系所包含的丰富语义信息，增加推荐多样性和精
数据稀疏、冷启动等问题。作为一种图结构数据，图神 确度。Wang等人在文献[28]提出了一种知识图谱卷积
经网络也可学习知识图谱的图嵌入，图神经网络以传播 网络（knowledge graph convolutional networks，KGCN）
邻居信息来学习节点特征，使得知识图谱的处理不再依 以挖掘项目间的关联属性，捕获项目与项目之间的关
赖手工特征工程，同时为挖掘知识图谱的高阶结构信息 系，进而得到KG的高阶结构信息和语义信息。KGCN
和语义信息提供一种端到端的训练方式。因此，图神经 模型首先为用户、项目和关系初始化嵌入表示，针对目
网络技术与知识图谱相结合，可以有效提升推荐系统的 标用户为其历史交互过的项目实体抽取固定大小的邻
性能。 域，并在其上执行图卷积操作，将邻域实体信息传播到
本文将从基于项目知识图谱增强的图神经网络推 当前实体。传播过程中，邻居实体根据连接关系对目标
荐和基于协同知识图谱增强的图神经网络推荐两个角 用户的影响因子进行加权，见式（1）：
度，探讨已有知识图谱增强的图神经网络推荐相关研 vu = ∑ π  u e （1）
N(v) rv,e
究，如图1所示。 e∈N(v)
式中，N(v)表示实体v的邻居实体集合，r v,e表示实体
知识图谱增强的图 v 与e 的关系，π  u 表示归一化后的关系 r 对目标用
神经网络推荐研究
rv,e v,e
户u的影响因子。计算方式见式（2）、式（3）：
πu =uTr （2）
基于项目知识图谱 基于协同知识图谱
rv,e v,e
增强的图神经网络 增强的图神经网络 exp(πu )
推荐研究 推荐研究 π  =
rv,e
（3）
∑ exp(πu )
rv,e'
e'∈N(v)
引入 之后，得到用户的初始嵌入表示和项目传播更新后
引入 引入 引入 引入
知识 引入
关系 标签 路径 其他 的嵌入表示，预测用户u是否对他之前未交互的项目v
图谱 注意
感知 优化 信息 方法
上下 力的 有潜在的兴趣。模型在MovieLens-20M、Book-Crossing
的推 的推 的推 的推
文的 推荐
荐 荐 荐 荐 和Last.FM三个包含知识图谱的数据集上，将GNN应用
推荐
在知识图谱嵌入学习上进行推荐，取得了很好的效果。
图1 已有知识图谱增强的图神经网络推荐研究
KGCN是较早将项目知识图谱与图神经网络结合，
Fig.1 Research on recommenders based on graph nerual
network enhanced with knowledge graph 并用于推荐任务中的模型。该模型重点在于对知识图
谱中实体间关系的编码，考虑关系对用户的影响，在图
2 基于项目知识图谱增强的图神经网络推荐研究 卷积网络的处理时，细化项目的特征表示，捕获了知识
项目知识图谱是指依据项目属性构建的知识图谱， 图中的高阶结构和语义信息。KGCN也从异质知识
图谱中包含项目实体、关系和属性，不包括用户实体。 图谱方面提供了一个新的视角，帮助提升推荐效果。
基于项目知识图谱增强的图神经网络推荐模型将项目 KGCN的提出，对研究关系感知的知识图谱增强图神经
知识图谱与用户-项目交互图相分离，且重点研究在其 网络推荐起着重要推动作用，后续相关研究大多都采用
上运用图神经网络传播属性信息，以学习项目的嵌入表 了这种考虑实体间关系的图卷积网络思想。在考虑关
示。已有基于项目知识图谱增强的图神经网络推荐研 系感知的同时，还可以加入其他类型的影响因子，实体
究主要包括引入关系感知的推荐、引入标签优化的推 表示中根据用户偏好，影响邻居节点聚合的权重，可在
荐、引入知识图谱上下文的推荐等几个方面。 聚合时得到更精准的表示，以优化图的表示学习，提高
2.1 引入关系感知的推荐 推荐的准确率。
知识图谱通过关系将实体与实体联系起来，不同的 利用知识图谱进行推荐的方法之一是知识图谱嵌
关系代表着不同的信息，可通过头实体和关系推导出尾 入，一些常用的嵌入方法都侧重于对语义关联进行建
实体。用户喜欢一个项目可能是因为该项目包含了某 模。在图嵌入中，当有新节点加入时，需要重新学习整
种重要的关系，所以对项目知识图谱中关系的处理至关 个图的表示，往往缺乏一定的归纳能力。因此，刘欢等
重要。文献[28-30]着重关注实体与实体间关系信息的 人在文献[29]提出了一种基于知识图谱驱动的端到端 吴国栋，等：知识图谱增强的图神经网络推荐研究进展 2023，59（4） 21
图神经网络模型（knowledge graph driven learning net- 2.2 引入标签优化的推荐
work，KGLN），其核心思想是通过知识图谱中实体间的 在推荐相关的数据集中，往往只有用户交互项目的
邻近关系，来驱动模型进行用户和项目直接的表示学 记录，称之为正样本，而推荐算法的训练还需要负样本
习。当新节点加入时，可以共享参数，直接获得节点的 的参与。常用解决方法是在用户没有交互过的项目集
特征表示。相较于KGCN，该模型不仅考虑了关系对于 中进行采样作为负样本数据，然而这种方式过于简单，
目标用户的影响因子，也考虑了不同实体节点对当前项 没有交互过的项目不代表用户不喜欢，因此存在一定的
目的影响因子，来衡量用户对物品的偏好。在模型中找 不合理性。如果用户用标签来描述对项目的看法，标签
到与实体相关的邻居实体，对实体的邻居节点进行特征 可看作是用户和项目之间联系的纽带，也是反映用户兴
聚合，并加入影响因子形成聚合的结果。KGLN引用了 趣的重要数据来源。文献[32-34]重点对样本的标签进
评分函数g计算影响因子，计算方式见式（4）： 行优化，采用相关算法预测样本标签来使标签类别达到
πv=g(v,e) （4） 平衡，以提升推荐效果。
e
其中，e为当前实体v的邻居节点特征，表示所有邻居 为了提供更好的归纳偏置，Wang等人在文献[32]
实体e对当前实体v的影响程度。得到影响因子后进 提出了KGCN-LS（knowledge-aware graph neural net-
行归一化处理，再通过均匀随机采样邻居节点，计算出 works with label smoothness regularization）模型。通
每个节点的影响因子，然后对项目v的邻居节点进行建 过应用一个可训练的模型KGCN，来计算针对目标用户
模，计算方式如式（5）： 的项目嵌入，以识别知识图谱中关系对于给定目标用户
vu = ∑ (π  u e+π  ve) （5） 的重要性，并将知识图谱转换为针对目标用户的加权
N(v) rv,e e
e∈N(v) 图，然后利用图神经网络计算个性化的项目嵌入。除此
其中，r 表示实体v与e的关系，π  u 表示归一化后的
v,e rv,e 之外，KGCN-LS重点引入标签平滑性假设，假定知识图
关系r v,e对目标用户u的影响因子。之后，聚合来自邻 谱中的相邻项目可能具有相似的用户相关性标签，通过
居的信息来更新自身，并通过堆叠多层KGLN的方式， 引入标签平滑来提供边权值的正则化项。KGCN-LS使
使项目节点获得来自其多阶邻居实体的信息。最后，结 用标签传播算法，预测项目节点的标签值，并将标签预
合项目嵌入表示与用户嵌入表示进行用户对项目的偏 测损失也作为模型的优化任务。标签预测损失定义见
好预测。模型基于MovieLens-1M（https：//grouplens. 式（6）：
org/datasets/movielens!）和Book-Crossing（http：//www2. R(A)=∑R(A u)=∑∑ J(y uv,l  u(v)) （6）
informatik.uni-freiburg.de/~cziegler/BX）数据集进行了实 u u v
 
验，对比其他基准方法，又考虑到不同聚合器以及不同
其中，J 是交叉熵损失函数，y uv是真实相关标签，l u(v)
感受野深度，KGLN模型取得了不错的效果。 是预测标签。之后在反向传播的过程中将该损失也
KGLN模型通过引入关系感知的同时，还考虑了不 加入优化任务，从而起到正则项的作用。模型基于
同邻居实体对当前项目的影响因子，根据邻居节点特征 MovieLens-20M、Book-Crossing、Last.FM（https：//grouplens.
的权重来聚合，相较于KGCN可以更加细致地学习项目 org/datasets/hetrec-2011/）和Dianping-Food数据集进行
节点特征，提高了推荐结果的精确度。KGLN考虑的知 实验，验证了KGCN-LS引入标签平滑正则项的有效
识图谱是静态的，然而用户的个人偏好会随着时间的改 性，以及在召回率指标上的效果提升。此外还通过调
变而改变的。 整MovieLens-20M的训练集大小，验证了KGCN-LS对
上述知识图谱增强的推荐研究中，大多是构建项目 缓解数据稀疏性和冷启动问题也有一定的效果。
知识图谱，对用户节点嵌入的学习较为简单。丰富用户 相较于KGCN模型，KGCN-LS将GNN结构扩展到
信息的一个方式就是通过引入用户的社交信息。用户 知识图，同时捕获项目之间的语义关系以及个性化的用
社交好友的偏好，在一定程度上也能反映当前用户的偏 户偏好和兴趣。此外该模型在KGCN基础上加入标签
好，这对学习用户节点的特征很有帮助，通过社交网络 平滑度正则项，通过聚合和优化使没有被发现的相关项
中的联系，还有助于缓解用户冷启动问题。Tien等人在 目具有更多被推荐的概率。
文献[30]提出了一种融入社交关系来学习用户嵌入的 Zhao等人在文献[33]提出了一种改进的、带标签平
模型。模型首先从用户空间和知识图谱空间中学习项 滑正则化的知识感知图神经网络iKGNN-LS模型。该
目嵌入表示，之后利用一个多层感知机，融合用户空间 模型对KGNN-LS进行了两个改进：一是引入实体对目
和知识图谱空间中捕获的信息，并利用一个NeuMF 标用户的影响因子计算函数，根据用户对关系和实体的
（neural matrix factorization）[31]网络层进行评分预测。 个性化偏好共同确定边的权重。二是使用最大池化代
模型采用RMSprop优化算法，在Ciao、MovieLens-1M和 替求和池化，来进行邻域的聚合。通过在三个真实数据
Last.FM数据集上取得了良好的效果。 集上的Top-N推荐实验，证明了这两项改进的有效性。 22 2023，59（4） ComputerEngineeringandApplications计算机工程与应用
如果直接将用户未产生交互的项目作为负样本，会 的有偏随机游走方法，用于聚合实体的非局部上下文信
存在一定的偏差。因此，Togashi等人提出了一种通过 息。首先在项目知识图谱上以一定的概率进行随机游
在知识图谱中使用伪标签的方式，来缓解冷启动问题的 走采样，得到高阶邻居节点，再进行Top-K排序获得游
KGPL（KG-aware recommender based on GNNs and 走过程中概率最大的几个节点。然后利用一个GRU单
pseudo-labelling）[34]模型。KGPL模型通过半监督学习 元对排序后的邻居序列进行处理，得到非局部图上下文
预测未观测到的样本标签，以缓解数据稀疏性问题。该 表示，计算方式见式（9）、式（10）所示：
模型中，作者利用广度优先搜索算法，计算与目标用户 e =GRU(e ,e ,⋯,e ) （9）
cg x1 x2 xn
有交互的项目到与目标用户无交互项目的路径个数。 cg =tanh[(e ||e )W +b ] （10）
h cg 2 2
由于冷启动项目相较于流行项目，更容易被采样作为负
其中，e 是使用GRU模块聚合非局部邻居信息，e 和
样本，此时的伪标签采样会影响模型的效果。因此对负
cg h
g
e 组成形成头实体h的非局部上下文嵌入c 。将局部
样本的采样则是基于项目流行度的采样。此外，该文献 cg
中还引入了co-training方法[35]，以提升KGPL优化过程 图上下文表示和非局部图上下文表示通过一个门控层
的健壮性。 得到项目的知识图谱上下文嵌入表示，计算方式如式（11）
KGPL通过引入伪标签和改进的负采样来解决样 所示：
本标签不均衡问题，缓解了冷启动和数据稀疏问题。但 c =σ(ω)⊙cl +(1-σ(ω))⊙cg （11）
h h h
是，引入标签平滑正则化，为模型带来了额外的计算成本。 式中，ω是一个可学习参数，σ(∗)是sigmoid函数，⊙是
2.3 引入知识图谱上下文的推荐 点积。在得到项目的知识图谱上下文嵌入表示后，模型
在图结构数据中，节点的邻居有阶数之分，其中一 通过在交互图传播项目节点信息，来学习用户的嵌入表
阶邻居最接近当前节点，所包含的信息也最重要，而高 示，并在该部分中引入特定的图形注意力机制，以区分
阶邻居虽远离当前节点，但包含的信息也不可忽略。图 不同历史交互项目对用户的重要性，捕获用户对实体的
神经网络在捕获高阶信息的过程中，往往只是简单地进 个性化偏好。CGAT通过对知识图谱中的高阶邻居进
行信息聚合，容易导致过平滑问题，而在知识图谱中同 行随机游走采样，更全面地捕获了知识图谱中所含的信
样需要考虑这个问题，文献[36-37]通过引入知识图谱上 息，一定程度上避免了采用图卷积带来的过平滑问题，
下文的学习模块，来处理高阶邻居信息，在充分利用邻 取得了较好的推荐效果。
居信息的同时，避免使用图卷积网络带来的过平滑问题。 在MovieLens-1M、Book-Crossing、Last.FM数据集
Yang等人在文献[36]提出了引入知识图谱上下文 上和其他模型的实验进行了比较，结果表明CGAT在不
（contextualized graph attention network，CGAT）模型。 同数据集上都取得了较好的性能。如在HR@20方面，
该模型主要包含局部图上下文、非局部图上下文和交互 CGAT优于CFKG、RippleNet、MKP、KGNN-LS和KGAT，
图上下文三个模块。根据用户特定的图注意力机制，获 分别为26.07%、21.32%、22.29%、21.92%和9.56%。这
取实体的局部上下文信息，考虑用户对实体的个性化偏 也说明CGAT在知识图谱上下文进行推荐的效果显著。
好，采用随机游走的方法提取实体的非局部上下文。E 孙伟等人提出一种基于知识图谱上下文矩阵补全
为实体集合，R为关系集合，D为实体-关系-实体三元 的图注意力编码器框架[37]。该框架中，为区分不同邻居
组(h,r,t)，h表示三元组的头部实体，r 表示关系实体， 的重要性，通过一个图注意力编码器来学习用户和项目
t表示尾部实体。在学习项目的局部图上下文表示过程 的嵌入表示。之后，在项目知识图谱上对知识图谱上下
文进行建模（同CGAT），并与项目的嵌入表示相融合，
中，传递来自于项目实体直接相连的非项目实体信息，
得到项目的最终嵌入表示。最后对用户嵌入表示和项
并引入注意力机制来区分这些非项目实体的重要性，计
算方式见式（7）、式（8）所示： 目的最终嵌入表示，利用双线性解码器来预测用户对项
e =α (h,r,t)e （7） 目的交互。此模型在三个数据集上与其他基准进行实
cl t
验，验证了该模型的可行性和优越性。但模型还可以进
cl=tanh[(e ||e )W +b] （8）
h cl 1 1
一步考虑采用不同的聚合方法，聚合用户相关历史项目
其中，α (h,r,t)描述了邻居实体t∈cl对头实体h的重要
和目标项目之间不同的偏好，结合上下文信息，并加入
性，e 表示头实体h对应的所选邻居实体的线性加和，
cl 注意力机制，以提高推荐的精确度。
聚合头实体h的嵌入向量e h和它的局部邻域嵌入向量 在上述对已有项目知识图谱增强的图神经网络推
e cl，形成了h的局部上下文嵌入cl。 荐研究分析基础上，表1从主要文献与内容、方法及优
在非局部图上下文表示的学习过程中，CGAT采用 点等方面，对基于项目知识图谱增强的图神经网络推荐
基于门控循环单元（gated recurrent unit，GRU）[38]模块 研究进行了小结。 吴国栋，等：知识图谱增强的图神经网络推荐研究进展 2023，59（4） 23
表1 基于项目知识图谱的推荐研究小结
Table 1 Summary of recommendation research based on project knowledge graph
类别 文献 主要内容 方法 主要优点
传播属性实体信息时，可以区分不同实
[28] 关系信息捕获 计算关系对目标用户的影响因子
体的重要性
考虑属性实体和关系对 更具细粒度地区分不同属性实体的重
引入关系感知的推荐 [29] 计算属性实体对项目的影响因子
项目的影响 要性
利用GNN从社交图中捕获到的嵌入与从知识
[30] 考虑用户的社交信息 利用更过信息，缓解用户冷启动问题
图谱中捕获到的信息嵌入相融合
[32] 样本标签预测 引入标签平滑提供边权值的正则化项 缓解了样本标签不平衡问题
考虑实体对目标用户的影响从而引用了影响
引入标签优化的推荐 [33] 改进的KGNN-LS 提升了推荐效果
因子，使用最大池化进行聚合
[34] 样本标签预测 使用半监督学习方式来预测观测到的样本标签 缓解了冷启动和数据稀疏问题
捕获局部上下文和非局 使用特定的图注意力机制获取局部上下文，采 更全面捕获知识图谱中所含信息，以及
[36]
引入知识图谱上下文 部上下文的信息 用随机游走获取非局部上下文 缓解了多层图卷积带来的过平滑问题
的推荐 结合图自编码器框架，图注意力编码器学习用户项目嵌入表示，双线
[37] 提升了推荐效果
捕获高阶邻居信息 性解码器预测用户对项目的交互
3 基于协同知识图谱增强的图神经网络推荐研究 el-1= ∑α (h,r,t)el-1 （13）
Nh t
协同知识图谱（collaborative knowledge graph，CKG）[10] (h,r,t)
对头实体e 进行信息聚合更新后，再对多层图注意
是指将用户-项目交互图与项目知识图谱相融合。在这 t
力网络得到的用户和项目实体嵌入表示进行拼接，作为
一类模型中，实体不仅包含项目实体，还包含了用户实
用户和项目的最终嵌入表示。此外，KGAT还将各个实
体。因此，不仅需要考虑项目嵌入表示的学习，也需要
体和关系的嵌入表示进行了规范化，如式（14）：
关注对用户嵌入表示的学习。已有基于协同知识图谱
g(h,r,t)=‖W e +e -W e ‖2 （14）
增强的图神经网络推荐研究主要包括引入注意力机制 r h r r t 2
的推荐、引入路径信息的推荐以及引入其他方法（如多 并将损失加入反向传播的优化任务中。模型基于Amazon-
视图网络、自适应目标-行为关系图网络等）的推荐等几 book、Last.FM和Yelp2018三个数据集与其他几个主流
个方面。 模型进行了对比实验，结果表明KGAT在Recall和
3.1 引入注意力机制的推荐 NDCG指标上均优于其他模型。模型的整体结构如图2
在图结构数据中，不同邻居节点相对于当前节点的 所示。
相关性是不同的，而在图卷积网络的聚合过程中，简单 荣沛等人在文献[40]提出了基于知识图谱和图注
聚合来自邻居节点的信息并不能对不同邻居节点加以 意力网络的推荐算法（knowledge graph and graph at-
区分。将注意力机制引入到基于协同知识图谱增强的 tention network，KG-GAT）。该模型在预处理层中将用
图神经网络推荐中，可以学习不同邻居节点的重要 户、实体和关系嵌入到统一的低维向量空间中。然后在
性，从而重点聚合来自相关性更高的邻居节点信息。文 注意力嵌入层中，利用实体注意力机制学习不同近邻实
献[39-42]使用图注意力网络进行聚合更新，以在协同知 体的权重，并利用语义注意力机制区分不同路径的重要
识图谱上区分各节点之间的重要程度。 性，避免不相关实体的信息。最后在预测层中预测用
Wang等人在文献[39]提出了一种知识图谱注意力 户-项目的交互概率。该模型的优点在于考虑运用了知
网络（knowledge graph attention network，KGAT）。该 识图谱中的关系，探索用户潜在偏好时存在的不相关实
模型以端到端方式建模了知识图谱中的高阶邻居，发掘 体问题，提高了推荐的准确性和可解释性。
高阶信息，增强用户与项目的交互来预测用户偏好的问 基于GCN的推荐大多数关注同构图或用户-物品
题，递归地从邻居节点更新当前节点的表示，并在信息 二部图，未能充分利用异构图中实体间复杂而丰富的语
传播过程中引入注意力机制来区分不同邻居的权重。 义。Yang等人在文献[41]提出了一种采用层次图注意
注意力嵌入传播层由信息传播、知识感知注意力、信息 力网络结合知识图谱的可解释推荐模型（hierarchical
聚合三部分组成。其中，实体邻居e 对头实体e 的注 attention graph convolutional network incorporating knowl-
t h
意力得分计算见式（12）： edge graph for explainable recommendation，HAGERec）。
α(h,r,t)=(W e)Ttanh(W e +r) （12） 该模型从高阶连接结构中挖掘用户的潜在偏好信息，设
r t r h
其中，α(h,r,t)为注意力得分，再进行归一化处理。对实 计了一种双向实体传播策略和分层注意力机制。首先，
体e 的高阶邻域信息定义为式（13）： HAGERec在消息传递过程中采用GCN建模实体的局
h 24 2023，59（4） ComputerEngineeringandApplications计算机工程与应用
l=3
u(3)
l=2 1
l=1 u 1(2) 连接
u(0) 注意力嵌入传播 u(1)
1 1
u(0)
1
u 1 u 4 u 5 u 2 u 3
v 1 v 2 v 3 v 4 y  u1i3
l=3
e 1 e 2 e 3 l=2 v 1(3)
v(0)
l=1
注意力嵌入传播
v(1v )1(2)
连接
3 1
v(0)
1
图2 KGAT整体框架图
Fig.2 KGAT overall frame diagram
部结构，合并实体的邻居信息。为了充分挖掘多跳连接 机制可以区分实体和其邻居实体的不同关系权重，更能
提高RS，设计一个扁平化操作，进一步使关系下的连接 突出用户的个性化偏好。注意力得分的引入反映了人
有序，更好地区分不同的连接。之后在实体传播过程， 类天生的注意力机制特点，使得推荐系统更加接近用户
通过双向实体传播策略获得用户和项目的聚合表示。 真实的思考过程。之后可以深入研究针对不同问题的
由于每个实体都有不同关系的邻居，为区分实体与邻居 更为高效的注意力机制，使用户-项目之间的关系权重
之间的不同关系，提出一种层次注意力机制，自适应地 更加细粒度化，以进一步提升推荐效果。
挖掘和调整每个用户-项目对之间的协作信号，并将其 3.2 引入路径信息的推荐
分为邻居级注意力和预测级注意力。再将每个邻居实 现有处理知识图谱的方法大多是提取用户-项目链
体的注意力评分作为与中心实体之间的相似度，并对相 接对，或者在整个知识图谱上传播节点的特征，并没有
似度低的邻居实体进行筛选。同时，对大小固定的相关 考虑不同的路径信息。文献[43-44]考虑不同路径对节
邻居实体进行采样，从而节省计算和存储开销。 点特征学习的影响，以充分挖掘图结构信息，提升推荐
相比较以往的知识图谱推荐方法，HAGERec利用 效果。
了KG和GCN的优势缓解了稀疏性的问题，利用分层机 Wang等人在文献[43]提出了KGIN（knowledge graph-
based intent network）模型。该模型利用辅助的项目知
制来采样邻居实体，通过高阶连通性实现了模型的可解
释性。在4个公共数据集进行实验，验证了该模型的可
识来探讨用户-项目交互背后的意图。首先，模型根据
不同的路径为用户意图建模，如式（15）所示：
行性和可解释性。
exp(w )
Qu等人在文献[42]提出了一种知识增强的邻域交 α(r,p)= rp （15）
∑exp(w )
互模型（knowledge-enhanced neighborhood interaction， r'p
r'∈R
KNI）。该模型将用户-项目的交互扩展到它们的邻居，
式中，α(r,p)是关系r 的注意力得分，w 是可训练的权
rp
并引入知识图谱来增加局部联通性，提出一个统一的邻
重参数，每个关系r 的嵌入都分配一个注意力得分以量
域交互（NI）模型。具体来说，模型使用一个双注意力网
化意图 p中每个路径的重要性。对用户意图建模后，模
络直接对局部结构进行预测，而不是将它们压缩到用
型引入了独立性约束，以表达意图之间的显著差异，进
户-项目嵌入表示中，并利用图神经网络整合高阶邻域
而获得更好的可解释性。再对路径关系信息进行聚合，
信息。最后，利用用户的邻域信息和项目的邻域信息进
得到用户嵌入表示如式（16）所示：
行预测。 u(l)= 1 ∑ β(u,p)h ⊙v(l-1) （16）
该模型在4个真实数据集上进行了评估，并与8个 | Nu|
(p,v)∈Nu
p
基于特征、基于元路径和基于图的模型进行了对比实 其中，β(u,p)是意图 p 的注意力得分。对于给定的用
验。结果表明，KNI模型在预测点击率方面的AUC值，
户，不同的意图具有不同的动机激发用户的行为，故引
比其他几个主流模型提高1.1%~8.4%，在Top-N推荐方 入注意力得分来区分意图 p的重要性。对项目的嵌入
面也远超其他几个模型。 更新可表示如式（17）所示：
在推荐系统中加入注意力机制，可以有效地获取用 v(l)= 1 ∑ r⊙e(l-1) （17）
| | i
户重点偏好，优化推荐模型。现阶段研究中融入注意力 Nv (r,ei)∈Nv 吴国栋，等：知识图谱增强的图神经网络推荐研究进展 2023，59（4） 25
在l 层之后，获得用户和项目不同层的表示，将路 现有与知识图谱结合的推荐方法中考虑项目之间
径的意图感知关系和知识图谱关系汇总为最终表示，再 的连接性的同时，不能捕获用户项目之间显式的长期语
预测用户与该项目交互的可能性。文献在三个基准数 义。因此，Lyu等人在文献[48]提出了一种既捕获用户
据集上的实验结果表明，KGIN取得了显著的效果。进 和项目之间的显式长范围语义信息，又考虑项目之间各
一步的分析表明，KGIN通过识别意图和关系路径，在意 种连接性的推荐模型（rule learning and graph neural
图的粒度上揭示用户项目关系，关系路径感知聚合中集 networks for recommendation，RGRec）。该模型结合了
成了来自多跳路径的关系信息以细化表示，为推荐结果 规则学习和图神经网络进行推荐，首先将项目映射到知
提供了有效性和可解释性。 识图谱中的相应实体，并将用户添加为新实体。然后，
大多数的KG用于推荐系统中的主要思路集中于 自动学习规则，捕获长范围语义信息，并通过聚合捕获
两种方法：一是集中于用户和项目之间的线性路径联 实体之间的连通性，更好地编码各种信息。RGRec提出
系，但不能够有效地挖掘整个KG的语义信息和拓扑结 了利用知识图谱嵌入进行规则过滤的策略，这是一种更
构信息。二是通过传递用户的偏好，再得到用户的嵌入 精确的方法计算规则的置信度，还可以运用规则学习对
表示，传播的过程反而容易引入噪音。因此，Sha等人 规则权重进行预训练。最后在三个真实的数据集上进
在文献[44]提出了AKGE（attentive knowledge graph 行实验，RGRec模型较于KGCN、KGAT、RKGE模型分
embedding）模型。该模型特点在于同时关注知识图谱 别获得2.8%~11.9%（Last.FM），1.9%~20.1%（MovieLens-
对应的语义信息和拓扑信息。设计了一种距离感知路 1M），3.7%~13.8%（Dianping-Food）的性能提升，验证了
径采样策略，对于给定的两个实体，仅保留最后的 K 条 RGRec的有效性，与只使用其中某一种方法相比，规则
最短路径，并进行路径装配构建子图。随后，在构建的 学习和GNN的结合，使推荐性能取得了实质性的改进。
子图上，将图中各个实体的嵌入和其对应的类型嵌入进 为充分提取知识图谱中隐含的结构信息，并考虑目
行拼接，利用关系感知传播计算邻居实体的临时隐藏状 标用户和项目在嵌入传播过程中的相互影响，Feng等人
态，再通过注意力机制将上一步得到的邻居实体进行加 在文献[49]提出了一种自适应目标-行为关系图网络模
权聚合，运用门控机制更新实体信息。最后，通过一个 型（adaptive target-behavior relational graph network，
多层感知机（multi-layer perceptron，MLP）预测用户是 ATBRG）。该模型为了自适应地提取知识图谱中目标
否会对项目进行交互。模型的优点是在构造的特定子 用户-项目对的有效关系子图，提出了图连接和图剪枝
图上进行传播，能更有效地构建子图，以及提取有效的、 技术。首先，分别对目标项目和用户历史交互项目在知
高质量的交互信息，缓解了基于整个知识图谱的传播而 识图谱上的多阶邻居进行探索。在这些实体集中，对出
容易引起的噪声问题。最后通过MovieLens-1M、Last.FM、 现在多个实体集中的实体进行连接，对只属于一个实体
Yelp三个真实数据集上的实验，评估了AKGE模型的性 集的实体进行修剪。然后，构建自适应的目标-行为关
能，表明AKGE明显优于其他主流模型。 系图，用来描述用户行为和目标项目之间的结构关系。
引入路径信息的推荐，充分运用了知识图谱中的结 模型考虑了知识图谱的结构关系，设计了基于注意力机
构信息，以及用户和项目之间的多种关系，增加推荐的 制的关系感知提取层，对每个用户行为和目标项目的关
可行性。 系图进行结构化知识聚合。在两个真实世界的数据集
3.3 引入其他方法的推荐 上进行了实验，证明了ATBRG有效性。
Tai等人在文献[45]提出了一种多视图网络（multi- 在知识图谱中，项目的众多属性导致具有大量的邻
view item network，MVIN）。该模型包含用户-实体和 居实体，若聚合邻域中的所有实体节点的信息则不仅带
实体-实体交互模块。为了丰富用户-实体交互，模型首 来信息的过平滑问题，也会使计算成本增加。一种普遍
先学习基于知识图谱增强的用户表示，用户-实体交互 的解决方式是对邻域中的邻居进行随机采样，只聚合一
模块对每个实体的关系和信息的重要性进行了描述。 部分邻居节点信息。然而这种随机无差别的采样方式，
为了细化实体-实体交互，提出了一个混合层来进一步 并不能很好地区分不同邻居节点的重要性，可能会丢失
改进图卷积网络聚合实体嵌入的方式，并允许MVIN从 关键邻居的信息。针对这一问题，梁顺攀等人在文献[50]
各种层级邻域特征中捕获聚合更新后信息。此外，为了 提出了一种基于关系紧密度的重要性采样方法。该方
保持计算效率和使用整个邻域的信息，还采用了分阶段 法通过计算目标节点与邻居节点的关系紧密度，来采样
训练策略[46]和采样策略[30，47]，以更好地利用知识图谱中 更重要的邻居，以避免无差别采样的随机性，同时引入
的信息。最后评估了MVIN模型在MovieLens-1M、LFM- 池化层训练，得到不同邻居节点对目标节点的差异化权
1b、Amazon-book三个真实数据集上的性能，结果表明， 值。该文献提出的推荐算法在五个真实数据集上进行
对于点击率（click through rate，CTR）预测和Top-N推 评估，对比其他基于知识图的推荐算法，在AUC和召回
荐，MVIN的性能明显优于其他主流模型。 率指标均有提升。 26 2023，59（4） ComputerEngineeringandApplications计算机工程与应用
表2 基于协同知识图谱推荐研究小结
Table 2 Summary of recommendation based on collaborative knowledge graph
类别 文献 主要内容 方法 主要优点
区分不同邻居的重要性，建模高 引入注意力机制来区分不同尾实体 细化了各个邻居节点的影响，用户和项
[39]
阶邻居，发掘高阶邻居信息 的重要性 目的嵌入刻画更加细致
考虑注意力机制区分不同路径 引入语义注意力机制区分不同路径 避免不相关实体带来的影响，使推荐效
[40]
的重要性 的重要性 果更准确
引入注意力机制的推荐
引入层次注意力机制，捕获高阶邻居
[41] 考虑高阶邻居信息 缓解多层卷积带来的过平滑问题
信息
使用双注意力网络来整合高阶邻域 丰富了节点的连通性，捕获交互图背后
[42] 考虑用户-项目的邻域信息
信息 更复杂的结构模式
依据不同的用户到项目路径来为用 可以有效识别用户意图和关系路径，为
[43] 考虑用户-项目交互背后的意图
户意图建模 推荐结果提供可解释性
引入路径信息的推荐
考虑不同路径的信息，挖掘用 引入距离感知路径采样策略，采样的 利用路径进行子图的划分，缓解了在整
[44]
户-项目对之间的高阶子图 路径构建子图，并在子图上进行传播 个知识图谱上传播而引起的噪声问题
引入用户-属性实体交互，改进图卷
[45] 考虑多视图下的项目属性 有效增强了用户表示，提升推荐效果
积网络聚合实体嵌入的方式
捕获了用户和项目之间的显示长范围
考虑获得用户-项目之间的语义
[48] 将规则学习与图神经网络结合 语义信息以及实体之间的连通性，更好
信息和项目之间的各种连接性
引入其他方法的推荐 地编码各种信息
考虑用户-项目有效关系子图的
[49] 引入图连接和图剪枝技术构建子图 充分提取知识图谱中隐含的结构信息
构建
通过计算关系紧密度，选择对目标节 采样更加相似的邻居，避免了不相干的
[50] 考虑采样邻居节点的方法
点更重要的邻域 节点参与计算
在对已有协同知识图谱增强的图神经网络推荐相 谱也使得模型的复杂度增高，而且多数模型需要堆叠多
关研究进行分析的基础上，表2从主要文献与内容、方 层图卷积运算，即便引入注意力机制，也为模型带来了
法及优点等方面对基于协同知识图谱增强的图神经网 大量的待学习参数，使得训练成本增大。
络推荐研究进行了小结。 4.2 用户对项目属性偏好挖掘问题
从表2可以看出，基于项目知识图谱增强分为引入 将知识图谱运用于个性化推荐的相关研究中，一定
关系感知、引入标签优化和引入知识图谱上下文的推 程度上提高了推荐结果的可解释性，即用户与某个项目
荐，可以有效缓解数据稀疏性和冷启动问题，利用邻居 产生交互的原因，可能是用户喜欢该项目的某个或某些
信息获得更加细致的特征表示，但同时存在模型单一、 属性。但已有推荐模型只是简单地通过关系，聚合来自
算法复杂性高等问题。基于协同过滤知识图谱增强分 属性节点的信息，并没有考虑到用户对项目属性的偏好
随着时间而变化，也存在用户的长短期兴趣变化问题。
为引入注意力机制、引入路径信息和引入其他方法的推
如文献[52]探讨了图神经网络推荐中用户的长短期兴
荐，其优点在于区分不同邻居节点的重要性，充分挖掘
趣，但仅局限于在用户-项目交互图上用户对项目的偏
图结构信息，提升模型性能，但算法的复杂度高，难以为
好，并没有考虑到在知识图谱上用户对项目属性的长短
用户推荐多样的兴趣项目。
期偏好。
4.3 用户知识图谱处理问题
4 知识图谱增强的图神经网络推荐研究存在的
推荐模型需要有一定的用户-项目历史交互数据，
主要问题
对于一个新用户或项目而言，其交互数据较少，很难学
4.1 大规模动态知识图谱处理问题
习其偏好特征，这就使得模型容易面临冷启动问题。本
现实生活中，知识图谱会随着时间的推移不断变
文所探讨的知识图谱增强的图神经网络推荐研究中一
化，图谱中新的关系不断出现，旧的关系不断失效。文
般是对项目构建知识图谱，或是将用户节点加入构建协
献[51]通过设计不同时间步长的动态图，来学习节点的
同知识图谱，主要运用项目的属性信息来缓解项目冷启
嵌入表示，但其考虑的仅是小规模知识图谱。随着时间 动问题，而较少涉及到对用户知识图谱的处理，模型仍
及求解问题复杂性的增加，知识图谱规模也会变得很 然容易面临用户冷启动问题。文献[33]通过引入社交
大，现有研究很少考虑到这种大规模、动态知识图谱情 网络对部分新用户建模，但社交关系仅为相似用户间的
形。尽管对大规模知识图谱可使用各种采样策略，但这 一种辅助信息，难以从中较好地学习用户对项目或项目
可能导致模型的适应性较差，学习效果降低，进而影响 属性的偏好信息，关键还是在于需要引入用户知识图谱
模型最终的推荐性能。同时，处理动态、大规模知识图 并对其进行处理。 吴国栋，等：知识图谱增强的图神经网络推荐研究进展 2023，59（4） 27
4.4 知识图谱的图嵌入学习问题 中抽取有利的信息补全知识图谱。同样，知识图谱的融
知识图谱嵌入是将实体和关系嵌入到低维向量空 入也可以增强多模态数据处理的能力，增强多模态学习
间，同时保留知识图谱的结构和语义信息。在知识图谱 模型的可解释性。如何利用这种不同模态数据，实现多
嵌入学习中，不同的模型从不同的角度把相应的语义信
模态知识图谱[55]的构建，以提升知识图谱增强的图神经
息嵌入知识图谱的向量表示中。在各种嵌入方法中，针 网络推荐效果，也将是未来本领域一个重要的研究方向。
对不同实体应用不同的向量表示，不同的关系也应拥有 5.4 知识图谱增强的GNN跨领域推荐
不同的语义空间，因此在处理复杂关系上存在一定问 已有知识图谱增强的图神经网络推荐研究，大多集
题。在实体和关系的交互过程中，可以融入附加信息来 中在单个领域内，常常面临数据稀疏性和冷启动等问
进一步改进任务，比如关系路径。如果使用大量路径来 题，并且仅限于向目标用户推荐单个领域内的项目，并
提高模型的性能，那么对模型的复杂度也是个严峻的挑 不能实现真正意义上的个性化。研究基于知识图谱增
战。在融入附加信息过程中，由于增加了节点的属性特 强的GNN跨领域推荐，通过分析各领域的关系数据，探
征，需要考虑节点的异质性和多模态性，从而需要用合 索关系对用户自身行为的相关性，找到相关的关系数据
适的嵌入方法进行学习。 来表征自身。解决不同领域的异构性和数据不平衡性，
将不同领域的知识、信息融合到一起的问题，来实现多
5 知识图谱增强的图神经网络推荐的主要研究 个领域内信息共享，互为补充，使得知识图谱内容更加
丰富，可以在一定程度上缓解推荐过程中的数据稀疏性
方向
和冷启动问题。
5.1 动态时序知识图谱增强的GNN推荐
为增加模型的适应性，同时也为更好地全面获取整
6 结束语
个演化过程和捕获所有动态知识，在引入知识图谱数据
随着人工智能和推荐技术的发展，越来越多的学者
的同时加入时间维度信息，利用时序分析技术和图深度
开始关注知识图谱增强的图神经网络推荐。知识图谱
学习技术，在动态过程中能准确地捕捉节点和边的所有
拥有丰富的辅助信息，图神经网络在处理图结构数据方
变化的动态性，分析知识图谱结构随时间的变化和发展
面具有天然的优势，基于知识图谱的图神经网络推荐，
趋势，从而有效获取图谱中的关键信息，对提升知识图
不仅有助于提升推荐模型的性能，还有助于缓解数据稀
谱增强的GNN推荐性能具有重要意义。但利用动态时
疏性和冷启动等问题。本文从项目知识图谱增强和协
序信息也意味着模型复杂度的增高，最重要的是时序信
同知识图谱增强两个视角，对知识图谱增强的图神经网
息的处理方式。因此，如何处理这种动态时序知识图谱
络推荐研究进行了深入探讨，分析了不同研究模型的特
来增强图神经网络推荐是未来研究的一个重要方向。
点，指出了现有知识图谱增强的图神经网络推荐研究在
5.2 基于元学习的知识图谱增强GNN推荐
大规模动态知识图谱处理、用户对项目属性偏好挖掘等
元学习[53]又被称为“学会学习”（learn to learn）或
方面存在的问题。最后，对知识图谱增强的图神经网络
“学习如何学习”。元学习主要思想是通过以前任务中
推荐未来主要研究方向，如动态时序知识图谱增强的
学习的先验知识，来指导新场景任务的学习，以此达到
GNN推荐、基于元学习的知识图谱增强GNN推荐等进
自主学习的目的。文献[54]提出了一个元关系学习框
行了展望。希望本文能对基于知识图谱及其图神经网
架（meta relational learning，MetaR），融合了元学习和
络的个性化推荐系统研究提供一定的借鉴作用。
知识图谱嵌入的方法，通过转移特定元信息，从而解决
知识图谱少样本连接预测的问题，元学习同样也是解决
参考文献：
深度学习系统中样本缺乏问题的重要框架.如果将元学
[1] XIONG H，LIU Z.A situation information integrated per-
习思想融入知识图谱增强的图神经网络推荐研究中，可 sonalized travel package recommendation approach based
以通过新项目的少量示例样本，实现较为复杂知识图谱 on TD-LDA model[C]//2015 International Conference on
表示学习和有效的知识获取，进而完成高效的GNN推 Behavioral，Economic and Socio-Cultural Computing，Nan-
荐任务，对提高已有推荐模型学习的泛化性、降低模型 jing，2015：32-37.
的训练成本具有一定的现实意义。 [2] QING Y X.An intelligent E-commerce recommendation algo-
rithm based on collaborative filtering technology[C]//2014
5.3 多模态知识图谱增强的GNN推荐
7th International Conference on Intelligent Computation
现有知识图谱增强的GNN推荐模型中，构建知识
Technology and Automation，Changsha，2014：80-83.
图谱所用的信息均是项目的一些属性，并没有考虑图
[3] SHU J，SHEN X，LIU H，et al.A content-based recommen-
像、音频、视频等数据。多模态知识图谱则是在传统知
dation algorithm for learning resources[J].Multimedia Sys-
识图谱中构建了多种模态，不同模态包含同一对象不同
tems，2018，24（2）：163-173.
方面的知识，对于项目可能包含了丰富的图片信息、结 [4] ADOMAVICIUS G，TUZHILIN A，Toward the next gen-
构化的属性描述和图谱数据以及文本信息描述，可以从 eration of recommender systems：a survey of the state-of- 28 2023，59（4） ComputerEngineeringandApplications计算机工程与应用
the-art and possible extensions[J].IEEE Transactions on [19] FAN W，MA Y，LI Q，et al.Graph neural networks for
Knowledge and Data Engineering，2005，17（6）：734-749. social recommendation[C]//2019 World Wide Web Con-
[5] 黄立威，江碧涛，吕守业，等.基于深度学习的推荐系统研 ference，2019：417-426.
究综述[J].计算机学报，2018，41（7）：1619-1647. [20] LIU F，CHENG Z，ZHU L，et al.Interest-aware message-
HUANG L W，JIANG B T，LV S Y，et al.Survey on deep passing GCN for recommendation[C]//Proceedings of the
learning based recommender systems[J].Chinese Journal of Web Conference 2021，2021：1296-1305.
Computers，2018，41（7）：1619-1647. [21] ZHANG J，SHI X，ZHAO S，et al.Star-GCN：stacked and
[6] GORI M，MONFARDINI G，SCARSELLI F.A new model reconstructed graph convolutional networks for recom-
for learning in graph domains[C]//2005 IEEE International mender systems[C]//Proceedings of the 28th International
Joint Conference on Neural Networks，2005：729-734. Joint Conference on Artificial Intelligence，2019：4264-4270.
[7] LIU Q，LI Y，DUAN H，et al.Knowledge graph construc- [22] 张祎，孟小峰.InterTris：三元交互的领域知识图谱表示学
tion techniques[J].Journal of Computer Research and Devel-
习[J].计算机学报，2021，44（8）：1535-1548.
opment，2016，53（3）：582-600.
ZHANG Y，MENG X F.InterTris：Specific domain knowl-
edge graph representation learning by Interaction among
[8] WANG Q，MAO Z D，WANG B，et al.Knowledge graph
triple elements[J].Chinese Journal of Computers，2021，
embedding：a survey of approaches and applications[J].
44（8）：1535-1548.
IEEE Transactions on Knowledge and Data Engineering，
[23] ZHANG F，YUAN N J，LIAN D，et al.Collaborative knowl-
2017，29（12）：2724-2743.
edge base embedding for recommender systems[C]//Pro-
[9] CATHERINE R，COHEN W.Personalized recommendations
ceedings of the 22nd ACM SIGKDD International Con-
using knowledge graphs：a probabilistic logic programming
ference on Knowledge Discovery and Data Mining，2016：
approach[C]//Proceedings of the 10th ACM Conference
353-362.
on Recommender Systems，2016：325-332.
[24] WANG H，ZHANG F，XIE X，et al.DKN：deep knowledge-
[10] GUO Q Y，ZHUANG F Z，QIN C，et al.A survey on
aware network for news recommendation[C]//Proceedings
knowledge graph-based recommender systems[J].IEEE Trans-
of the 2018 World Wide Web Conference，2018：1835-1844.
actions on Knowledge and Data Engineering，2022，34（8）：
[25] SHI C，HU B，ZHAO W X，et al.Heterogeneous infor-
3549-3568.
mation network embedding for recommendation[J].IEEE
[11] WU S，SUN F，ZHANG W，et al.Graph neural networks
Transactions on Knowledge and Data Engineering，2018，
in recommender systems：a survey[J].arXiv：2011.02260，2020.
31（2）：357-370.
[12] CHENG H T，KOC L，HARMSEN J，et al.Wide & deep
[26] MNIH A，SALAKHUTDINOV R R.Probabilistic matrix
learning for recommender systems[C]//Proceedings of the
factorization[C]//Advances in Neural Information Process-
1st Workshop on Deep Learning for Recommender Sys-
ing Systems，2008：1257-1264.
tems，2016：7-10.
[27] WANG H，ZHANG F，WANG J，et al.RippleNet：propa-
[13] KIPF T N，WELLING M.Semi-supervised classification
gating user preferences on the knowledge graph for rec-
with graph convolutional networks[J].arXiv：1609.02907，
ommender systems[C]//Proceedings of the 27th ACM
2017.
International Conference on Information and Knowledge
[14] BERG R，KIPF T N，WELLING M.Graph convolutional
Management，2018：417-426.
matrix completion[J].arXiv：1706.02263，2017.
[28] WANG H，ZHAO M，XIE X，et al.Knowledge graph con-
[15] HE X，DENG K，WANG X，et al.LightGCN：simplifying
volutionalnetworksforrecommendersystems[C]//2019World
and powering graph convolution network for recommen- Wide Web Conference，2019：3307-3313.
dation[C]//Proceedings of the 43rd International ACM [29] 刘欢，李晓戈，胡立坤，等.基于知识图谱驱动的图神经网
SIGIR Conference on Research and Development in Infor- 络推荐模型[J].计算机应用，2021，41（7）：1865-1870.
mation Retrieval，2020：639-648. LIU F，LI X G，HU L K，et al.Knowledge graph driven
[16] CHENL，WU L，HONG R，et al.Revisiting graph based recommendation model of graph neural network[J].Jour-
collaborative filtering：a linear residual graph convolu- nal of Computer Applications，2021，41（7）：1865-1870.
tional network approach[C]//Proceedings of the 34th AAAI [30] TIEN D N，VAN H P.Graph neural network combined
Conference on Artificial Intelligence，2020：27-34. knowledge graph for recommendation system[C]//Inter-
[17] LI Q，HAN Z，WU X M.Deeper insights into graph con- national Conference on Computational Data and Social
volutional networks for semi-supervised learning[C]//Pro- Networks.Cham：Springer，2020：59-70.
ceedings of the 32nd AAAI Conference on Artificial Intel- [31] HE X，LIAO L，ZHANG H，et al.Neural collaborative fil-
ligence，2018. tering[C]//Proceedings of the 26th International Confer-
[18] WANG H，LIAN D，GE Y.Binarized collaborative filtering ence on World Wide Web，2017：173-182.
with distilling graph convolutional networks[J].arXiv：1906. [32] WANG H，ZHANG F，ZHANG M，et al.Knowledge-aware
01829，2019. graph neural networks with label smoothness regular- 吴国栋，等：知识图谱增强的图神经网络推荐研究进展 2023，59（4） 29
ization for recommender systems[C]//Proceedings of the 1910.08288，2019.
25th ACM SIGKDD International Conference on Knowl- [45] TAI C Y，WU M R，CHU Y W，et al.MVIN：learning
edge Discovery and Data Mining，2019：968-977. multiview items for recommendation[C]//Proceedings of
[33] ZHAO B，XU Z，TANG Y，et al.Effective knowledge-aware the 43rd InternationalACM SIGIR Conference on Research
recommendation via graph convolutional networks[C]// and Development in Information Retrieval，2020：99-108.
International Conference on Web Information Systems and [46] BARSHAN E，FIEGUTH P.Stage-wise training：an improved
Applications.Cham：Springer，2020：96-107. feature learning strategy for deep models[C]//Proceedings
[34] TOGASHI R，OTANI M，SATOH S.Alleviating cold-start of the 1st Workshop on Feature Extraction：Modern Ques-
problems in recommendation through pseudo-labelling tions and Challenges，2015：49-59.
over knowledge graph[C]//Proceedings of the 14th ACM [47] YING R，HE R，CHEN K，et al.Graph convolutional neu-
International Conference on Web Search and Data Min- ral networks for web-scale recommender systems[C]//Pro-
ing，2021：931-939. ceedings of the 24th ACM SIGKDD International Con-
[35] BLUM A，MITCHELL T.Combining labeled and unlabeled ference on Knowledge Discovery and Data Mining，2018：
data with co-training[C]//Proceedings of the 11th Annual 974-983.
Conference on Computational Learning Theory，1998：92-100. [48] LYU X，LI G，HUANG J，et al.Rule-guided graph neural net-
[36] LIU Y，YANG S，XU Y，et al.Contextualized graph atten- works for recommender systems[C]//International Semantic
tion network for recommendation with item knowledge Web Conference.Cham：Springer，2020：384-401.
graph[J].IEEE Transactions on Knowledge and Data Engi- [49] FENG Y，HU B，LV F，et al.ATBRG：adaptive target-
neering，2023，35（1）：181-195. behavior relational graph network for effective recom-
[37] 孙伟，陈平华.基于知识图谱上下文的图注意矩阵补全[J]. mendation[C]//Proceedings of the 43rd International ACM
计算机工程与应用，2022，58（11）：171-177. SIGIR Conference on Research and Development in Infor-
SUN W，CHEN P H.Graph attention matrix completion mation Retrieval，2020：2231-2240.
based on the context of knowledge graph[J].Computer [50] 梁顺攀，涂浩，王荣生，等.融合重要性采样和池化聚合的
Engineering and Applications，2022，58（11）：171-177. 知识图推荐算法[J].小型微型计算机系统，2021，42（5）：
[38] CHO K，VAN M B，GULCEHRE C，et al.Learning phrase 967-971.
representations using RNN encoder-decoder for statisti- LIANG S P，TU H，WANG R S，et al.Knowledge graph
cal machine translation[C]//Proceedings of the 2014 Con- recommendation algorithm combining importance sampling
ference on Empirical Methods in Natural Language Pro- and pooling aggregation[J].Journal of Chinese Computer
cessing，2014：1724-1734. Systems，2021，42（5）：967-971.
[39] WANG X，HE X，CAO Y，et al.KGAT：knowledge graph [51] CHANAA A，EL FADDOULI N E.Predicting learners need
attention network for recommendation[C]//Proceedings of for recommendation using dynamic graph-based knowledge
the 25th ACM SIGKDD International Conference on tracing[C]//International Conference on Artificial Intelli-
Knowledge Discovery and Data Mining，2019：950-958. gence in Education.Cham：Springer，2020：49-53.
[40] 荣沛，苏凡军.基于知识图注意网络的个性化推荐算法[J]. [52] HU L M，LI C，SHI C，et al.Graph neural news recom-
计算机应用研究，2021，38（2）：398-402. mendation with long-term and short-term interest mod-
RONG P，SU F J.Personalized recommendation algorithm eling[J].Information Processing & Management，2020，57
based on knowledge graph attention network[J].Applica- （2）：102-142.
tion Research of Computers，2021，38（2）：398-402. [53] 李凡长，刘洋，吴鹏翔，等.元学习研究综述[J].计算机学
[41] YANG Z，DONG S.HAGERec：hierarchical attention graph 报，2021，44（2）：422-446.
convolutional network incorporating knowledge graph for LI F C，LIU Y，WU P X，et al.A survey on recent advances
explainable recommendation[J].Knowledge-Based Systems， in meta-learning[J].Chinese Journal of Computers，2021，
2020，204：106194. 44（2）：422-446.
[42] QU Y，BAI T，ZHANG W，et al.An end-to-end neigh- [54] CHEN M，ZHANG W，ZHANG W，et al.Meta relational
borhood-based interaction model for knowledge-enhanced learningforfew-shotlinkpredictioninknowledgegraphs[C]//
recommendation[C]//Proceedings of the 1st International Proceedings of the 2019 Conference on Empirical Methods
Workshop on Deep Learning Practice for High-Dimensional in Natural Language Processing and the 9th International
Sparse Data，2019：1-9. Joint Conference on Natural Language Processing，2019：
[43] WANG X，HUANG T，WANG D，et al.Learning intents 4217-4226.
behind interactions with knowledge graph for recommen- [55] 孙睿.基于多模态知识图谱的推荐系统[D].成都：电子科
dation[C]//Proceedings of the Web Conference 2021，2021： 技大学，2021.
878-887. SUN R.Resommender system based on multi-modal knowl-
[44] SHA X，SUN Z，ZHANG J.Attentive knowledge graph edge graphs[D].Chengdu：University of Electronic Science
embedding for personalized recommendation[J].arXiv： and technology of China，2021. --------------------------------------------------------------------------------- 第 卷 第 期 ComputerEngineering 计算机工程 年 月
48 3 2022 3
·热点与综述· 文章编号：1000-3428（2022）03-0023-15 文献标志码：A 中图分类号：TP391.1
知识图谱构建技术综述
张吉祥，张祥森，武长旭，赵增顺
（山东科技大学电子信息工程学院，山东青岛 ）
266590
摘 要：知识图谱在医疗、金融、农业等领域得到快速发展与广泛应用，其可以高效整合海量数据的有效信息，为实
现语义智能化搜索以及知识互联打下基础。随着深度学习的发展，传统基于规则和模板的知识图谱构建技术已经
逐渐被深度学习所替代。梳理知识抽取、知识融合、知识推理 类知识图谱构建技术的发展历程，重点分析基于卷
3
积神经网络、循环神经网络等深度学习的知识图谱构建方法，并归纳现有方法的优劣性与发展思路。此外，深度学
习虽然在自然语言处理、计算机视觉等领域取得了较大成果，但自身存在依赖大规模样本、缺乏推理性与可解释性
等缺陷，限制了其进一步发展。为此，对知识图谱应用于深度学习以改善深度学习自身缺陷的相关方法进行整理，
分析深度学习的可解释性、指导性以及因果推理性，归纳知识图谱的优势以及发展的必要性。在此基础上，对知识
图谱构建技术以及知识图谱应用于深度学习所面临的困难和挑战进行梳理和分析，并对该领域的发展前景加以
展望。
关键词：知识图谱；信息抽取；语义网；深度学习；自然语言处理
开放科学（资源服务）标志码（OSID）：
中文引用格式：张吉祥，张祥森，武长旭，等.知识图谱构建技术综述［J］.计算机工程， ，（）： - .
2022 48 3 23 37
英文引用格式：ZHANG J X，ZHANG X S，WU C X，et al.Survey of knowledge graph construction techniques［J］.
ComputerEngineering， ，（）： - .
2022 48 3 23 37
Survey of Knowledge Graph Construction Techniques
ZHANG Jixiang，ZHANG Xiangsen，WU Changxu，ZHAO Zengshun
（CollegeofElectronicandInformationEngineering，ShandongUniversityofScienceandTechnology，Qingdao，Shandong ，China）
266590
【Abstract】Knowledge graph has been rapidly developed and widely used in the medical，financial，agricultural，and
other fields.It can efficiently integrate the effective information of massive data and lay the foundation for semantic
intelligent search and knowledge interconnection.With the development of deep learning，the traditional knowledge
graph construction technology based on rules and templates has been gradually replaced by deep learning.This paper
studies the development process of three types of knowledge graph construction technologies：knowledge extraction，
knowledge fusion，and knowledge reasoning；focuses on knowledge graph construction methods based on deep learning
such as Convolutional Neural Network（CNN）and Recurrent Neural Network（RNN）；and summarizes the advantages
and disadvantages of existing methods and development ideas.In addition，although deep learning has made great
achievements in Natural Language Processing（NLP），computer vision，and other fields，its own defects such as reliance
on large-scalesamples，lack ofreasoning，and interpretability limititsfurtherdevelopment.Therefore，thispapersortsout
the relevant methods for applying knowledge graph to deep learning to address the defects of the latter；analyzes the
interpretability，guidance，and causal reasoning of deep learning；and summarizes the advantages of knowledge graph
and the necessity of development. On this basis，this paper studies and analyzes the construction technology of
knowledge graph and the difficulties and challenges faced by the application of knowledge graph in deep learning and
looksforwardtothedevelopmentprospectofthisfield.
【Keywords】knowledgegraph；informationextraction；semanticWeb；deeplearning；NaturalLanguageProcessing（NLP）
DOI：10.19678/j.issn.1000-3428.0061803
容获取与查询功能的Web . ，步入到可参与互联网
0 概述 1 0
并进行内容制造的Web . ，以及以知识互联为支柱
2 0
随着互联网的不断发展，人类从简单的具备内 的Web . ［ 1］，万物互联的时代使人们的生活更便
3 0
基金项目：中国博士后科学基金特别项目（2015T80717）；山东省自然科学基金（ZR2020MF086）。
作者简介：张吉祥（1997—），男，硕士研究生，主研方向为知识图谱、自然语言处理；张祥森、武长旭，硕士研究生；赵增顺（通信作者），副教授、
博士。
收稿日期： - - 修回日期： - - E⁃mail：zhaozengshun@163.com
2021 05 31 2021 08 10 ComputerEngineering 计算机工程 年 月 日
24 2022 3 15
利，信息获取更快速。但是，由于互联网的内容多 应用。
源、数据多样，大量的信息不能得到有效地利用，知 本文阐述知识图谱构建技术的发展历程，对相
识互联面临着极大挑战。知识组织的原则中表明知 关模型进行讨论，归纳知识抽取、知识融合、知识推
识的充分性、有序性和标准化原则［ 2］，这就需要人们 理等相关研究成果，分析知识图谱用于深度学习时
以一种新的视角去整合互联网的异源和异构知识信 的可解释性、指导性以及因果推理性，在此基础上，
息，从而适应用户的认知需求，而知识图谱的诞生为 对知识图谱未来的发展方向加以展望。
实现语义智能化检索以及知识互联打下了坚实的
1 知识图谱的定义与架构
基础。
互联网信息量的快速增长给深度学习带来了巨 1.1 知识图谱的定义
大的数据资源，通过对大规模数据的标注和使用，深 知识图谱的概念由Google于 年提出，用于
2012
度学习在自然语言处理（NaturalLanguageProcessing， 完善搜索引擎，是一种典型的多边关系图，由节点
NLP）、计算机视觉（ComputerVersion，CV）等领域取 （实体）和边（实体之间的关系）组成。知识图谱本质
得了较好的成绩。但是，深度学习自身存在着很大 上是一种语义网络，用于揭示万物之间的关系。如
的局限性，数据红利的消耗殆尽也限制了其进一步 图 所示，知识图谱旨在从多种类型的复杂数据中
1
发展，具体体现在 个方面：深度学习的效果在很大 抽取概念、实体和关系，是事物关系的可计算模型。
3
程度上依赖大规模的样本，缺乏先验知识，导致某些 按照知识的覆盖范围和领域的不同，知识图谱整体
结果可能背离人类知识或专家知识；深度学习本质 可以划分为通用性知识图谱和领域性知识图谱。随
上是一种映射，是输入和输出之间的特征关系，不具 着科技的不断发展，知识图谱在NLP领域应用广泛，
备因果推理性；深度学习缺乏可解释性，只是一种端 如语义搜索［ 9］、智能问答［ 10］、辅助决策［ 11］等方面，其
到端模型，包含了众多的神经元和参数，人们无法清 已经成为人工智能发展的重要动力。
楚地解释每一个参数的意义，这也是深度学习最大
的缺陷之一。基于以上原因，人们开始尝试将知识
图谱与深度学习相结合，旨在打破人工智能发展中
所出现的瓶颈。
徐增林等［ 3］对知识图谱的定义、当前的大规模
知识图谱、知识图谱构建技术以及知识图谱典型应
用进行了分析与讨论，将知识图谱的构建分为知识
抽取、知识表示、知识融合、知识推理 个方面。李
4 图1 事物关系的可计算模型
涓子等［ 4］总结归纳知识表示及构建技术。文献［ 3- 4］
Fig.1 Computablemodelofrelationshipbetweenthings
涉及深度学习技术的部分内容，均从深度学习相关
知识图谱的一种通用表示形式是三元组形式，
技术应用于知识图谱这一角度出发，而本文从深度
即 G=(Entity ,Relation,Entity )，Entity 为三元
学习用于构建知识图谱、知识图谱用于深度学习推 head tail head
组G中的头实体，Entity 为尾实体，Relation为 个
理、知识图谱指导深度学习、知识图谱提高深度学 tail 2
实体之间的关系，其中，Entity=[Entity ,Entity ,…,
习可解释性等多个角度，对最近几年知识图谱与深 1 2
Entity ]表示实体的集合，其包含了n种实体的概念，
度学习相结合的最新研究进展进行整理分析。除 n
此之外，还有一些综述是针对知识图谱构建的子任 Relation=[Relation 1,Relation 2,…,Relation n] 表 述 实
务，如命名实体识别（Named Entity Recognition， 体之间的关系集合，其包含了n种不同的关系。
NER）［ 5］、关系抽取（Relation Extraction，RE）［ 6- 8］等。 1.2 知识图谱的体系架构
其中：文献［ ］对 年— 年的命名实体识别、 知识图谱的体系架构分为 个部分，如图 所
5 2014 2019 3 2
命名实体消歧和命名实体链接技术进展进行了详 示：第一部分是源数据的获取，即在各个类型的数据
细的分析，以文本预处理、命名实体识别、命名实体 中获取有用的资源信息；第二部分是知识融合，用于
消歧、命名实体链接为主要脉络进行综述；文献［ ］ 关联多数据源的知识，扩大知识范围；第三部分是知
6
主要针对关系抽取中的远程监督方法进行归纳，该 识计算与知识应用，知识计算是知识图谱能力输出
方法适用于结构化或半结构化的数据；文献［ - ］针 的主要方式［ 12］，而知识应用是将知识图谱与特定领
7 8
对深度学习用于关系抽取进行分析综述，文献［］分 域或业务相结合，从而提高业务效率。由于构建知
7
析了卷积神经网络在关系抽取中的应用，文献［］分 识图谱的技术和深度学习紧密相关，因此本文重点
8
析了卷积神经网络、循环神经网络以及混合网络的 分析知识图谱构建技术。 第 卷 第 期 张吉祥，张祥森，武长旭，等：知识图谱构建技术综述
48 3 25
图2 知识图谱的体系架构
Fig.2 Architectureofknowledgegraph
其为知识精细化工作以及辅助决策的实现方式。本
2 知识图谱构建技术
节根据知识图谱的体系架构详细介绍知识抽取、知识
知识图谱的构建需要应用到多方面信息处理技
融合、知识推理的相关研究。
术。知识抽取从多种数据源中提取知识并存入知识
2.1 知识抽取
图谱，是构建大规模知识图谱的基础。知识融合可以
知识抽取主要分为命名实体识别和关系抽取 个
2
解决不同知识图谱的异构问题，通过知识融合，能够 方面。按照其发展历程，主要可分为 类方法，分别
3
使得不同数据源的异构知识图谱相互联通、相互操作， 是基于传统规则和模板、基于统计机器学习、基于深
从而提高知识图谱的质量。知识计算是知识图谱的 度学习的知识抽取，本文主要对第 类方法展开分析。
3
主要输出能力，其中，知识推理是最重要的能力之一， 实体关系抽取的发展历程如图 所示。
3
图3 实体关系抽取的发展历程
Fig.3 Thedevelopmentofentityrelationshipextraction ComputerEngineering 计算机工程 年 月 日
26 2022 3 15
. . 命名实体识别 数据集中，RD-CNN-CRF的性能高于BI-LSTM-CRF，
2 1 1
在命名实体识别方面， 类知识抽取方法具体 并且学习速率更快。随着注意力机制的兴起和广泛
3
如下： 运用， 年，JUN等［ 26］针对传统CNN无法捕捉句
2021
）基于传统规则和模板的方法 子中长期信息的问题，将注意力机制和CNN相融合，
1
在早期技术发展不成熟时，命名实体识别和关 提出新的卷积神经网络模型ALL CNN（ACNN），其
系抽取主要采用人工编写规则和模板的方法来实 利用融合不同卷积核以及残差结构的CNN来捕捉
现［ 13- 14］。对于命名实体识别任务，首先由特定领域 不同尺度的上下文信息，引入注意力机制增强模型
的专家构建大量的实体识别规则，如“人名：（姓氏+ 捕捉上下文信息的能力。
名字），地址名：（省+市+县+…）”，然后将规则和文本 除 CNN 模型外，RNN 模型及其变体同样在
字符相匹配从而抽取实体。 年，RAU［ 13］首次利
NER 任务中被广泛应用。HUANG 等［ 27］提出了
1991
LSTM、BI-LSTM、BI-LSTM-CRF等模型，BI-LSTM
用启发式算法和人工构造规则，从财经新闻中自动
可以综合考虑过去和未来的特征，因此，在CoNLL-
提取公司名称，准确率超过了 %，远高于人工抽取
95
和CoNLL- 数据集中，BI-LSTM-CRF相对
的准确率。但是，通过构造规则的方法会耗费大量 2000 2003
其他模型准确率更高。受到上述研究的启发，文
的人力物力，并且一套规则只能适用于一种领域，其
献［ ］提出端到端的命名实体识别模型，其通过
迁移性和泛化性很低。 20
CNN网络将单词级和字符级的嵌入向量整合在一
）基于传统机器学习的方法
2 起并同时送入BI-LSTM-CRF模型中，取得了较好的
基于机器学习的方法主要利用标注的数据进行
效果。 年，GREGORIC等［ 28］采用多个独立的
模型训练，采用的模型有最大熵马尔科夫模型 2018
BI-LSTM单元，通过模型间的正则化提高了各个
（Maximum Entropy Markov Model，MEMM）、条件随
LSTM单元之间的多样性，大幅减少了参数量，在
机场（Conditional Random Field，CRF）等。 年，
2004 CoNLL- 数据集中比文献［ ］方法的 F 值高
ZHOU等［ 17］通过HMM和基于HMM的实体识别器， 2003 20 1
. %。 年，RONRAN等［ 29］改进HUANG等所
对词的形态模式、词性等进行集成，通过KNN算法 0 27 2020
提的模型，研究词嵌入、字符特征和词特征对实体识
解决了数据稀疏问题，在GENIAV . 中总体F 值
3 0 1 别的有效性，并利用CNN-BI-LSTM-CRF模型进行
为 . %。除此之外， 年，LIU等［ 18］在半监督学
66 6 2011 实体识别，其准确率得到有效提升。
习框架下结合KNN分类器和CRF模型进行实体识
除CNN与RNN之外，近年来，将Transformer系
别，该方法缓解了训练数据匮乏的问题，并且将
列模型应用于命名实体识别也成为研究重点。
KNN与半监督学习策略相结合，提升了模型的效
Transformer完全依赖于注意力机制，准确率更高并
果。基于机器学习的方法需要构造特征，其误差传
且训练时间更少，典型代表有文献［ ］提出的针对
30
播也是一个问题，因此，研究人员开始将命名实体识
命名实体识别的 Transformer（Transformer Encoder
别技术转向深度学习领域。
forNER，TENER）、Google［ 31］提出的BERT（Bidirectional
）基于深度学习的方法
3
Encoder Representations from Transformers）以及 BERT-
基于深度学习的方法对人工构造特征的依赖性
BIGRU-CRF［ 21］等衍生模型。 年，曾青霞等［ 32］
2021
大幅降低，解决了特征提取误差传播的问题，对于命
提 出 一 种 结 合 自 注 意 力 机 制 的 BI-LSTM-CRF
名实体识别而言，主要的方法有卷积神经网络 （SelfAtt-BI-LSTM-CRF），其在 BI-LSTM-CRF 的基
（Convolutional Neural Network，CNN）和循环神经网
础上引入自注意力机制，可以获取句子的全局依赖
络（RecurrentNeuralNetwork，RNN）两大类。 2011年， 性并捕捉其结构特征。罗熹等［ 33］同样将自注意力
COLLOBERT等［ 24］将单层的CNN模型用于命名实 机制与BI-LSTM-CRF相结合，使用一种新的融合领
体识别，但是其丢失了长距离单词的有效信息。针 域字典的字符表示方法，有效提升了模型的实体识
对传统CNN模型学习速率低的问题， 年，QIU 别能力。注意力机制的引入为命名实体识别等
2019
等［ 25］提出结合 CRF 的残差膨胀卷积神经网络 NLP技术注入了新的活力，拓展出了新的研究方
（RD-CNN-CRF），其利用RD-CNN捕获上下文特征， 向。近年来所出现的命名实体识别方法对比如表
1
最后通过CRF捕获相邻标签的相关性，在CCKS- 所示。
2017 第 卷 第 期 张吉祥，张祥森，武长旭，等：知识图谱构建技术综述
48 3 27
表1 命名实体识别方法对比
Table1 Comparisonofnamedentityrecognitionmethods
方法类别 年份 方法 数据集 模型 方法特点 适用场景 评测指标 评测值/%
较准确地自动提取实体，
基于传统规则 启发式 但构造规则的方法会耗
[ 13] 财经新闻 启发式算法+规则 财经新闻 Acc .
的方法 1991 方法 费大量的人力，可移植性 9750
很差
集成了构词模式、形态模
式、词性、中心名词、特殊
基于传统机器
[ 17] HMM GENIAV . HMM+实体识别器 动词、别称这 个特征，生物医学领域 F .
学习的方法 2004 30 6 1 6660
特征丰富，但需要人工构
造特征
在半监督框架下进行实
基于传统机器 体识别，有效缓解了训练 推特博文等
[ 18] CRF Tweets KNN分类器+CRF F .
学习的方法 2011 数据匮乏的问题，但需要 通用领域 1 8020
人工构造特征
首次引入CNN进行实体
基于深度学习
[ 24] CNN CoNLL- Conv-CRF 识别，但丢失了长距离单 通用领域 F .
的方法 2011 2003 1 8867
词的有效信息
将实体识别视为序列标
基于深度学习 注任务，利用残差膨胀卷
[ 25] CNN CCKS- RD-CNN-CRF 医学临床领域 F .
的方法 2019 2017 积捕获上下文，有效提高 1 8851
了训练效率
构建多级CNN+注意力机
基于深度学习
[ 26] CNN CCKS- ALLCNN 制捕获不同尺度的上下文 医学临床领域 F .
的方法 2021 2017 1 9049
信息，提高了模型效率
首次应用BI-LSTM捕获
基于深度学习
[ 27] RNN CoNLL- BI-LSTM-CRF 过去和未来的特征，但需 通用领域 F .
的方法 2015 2003 1 8883
要大量的特征工程
不需要人工构造特征，将
基于深度学习
[ 20] RNN CoNLL- LSTM-CNNs-CRF BI-LSTM 与 CNN 相结 通用领域 F .
的方法 2016 2003 1 9121
合，是完全端到端的模型
采用多个独立的BI-LSTM，
基于深度学习
[ 28] RNN CoNLL- 并行RNN模型 大幅减少了参数量，提高了 通用领域 F .
的方法 2018 2003 1 9148
训练效率
研究单词和字符特征对
实体识别的有效性，采用
基于深度学习
[ 29] RNN CoNLL- CNN-BI-LSTM-CRF 两层BI-LSTM减少输入 通用领域 F .
的方法 2020 2003 1 9110
序列，以克服长输入序列
难以预测的问题
基于深度学习 Trans‐ 引入相对位置编码，可以分
的方法
2019[ 30]
former
CoNLL-
2003
TENER
别在词级与字符级表示
通用领域 F
1
91.
52
采用Transformer-Encoder
基于深度学习 Trans‐ 结构，可以深度挖掘上下文
的方法
2019[ 31]
former
CoNLL-
2003
BERT
相关信息，但模型参数量
通用领域 F
1
92.
80
大，训练速率较慢
引入自注意力机制,更好
基于深度学习 Trans‐ SelfAtt-BI-
的方法
2021[ 32]
former
CoNLL-
2003 LSTM-CRF
地处理实体之间的长距 通用领域 Acc 90.
47
离依赖关系
将中文字符特征与临床
基于深度学习 Trans‐
的方法
2021[ 33]
former
CCKS-
2017
MHA-BiLSTM-CRF 知识特征相结合，对医学 医学临床领域 F
1
91.
97
临床文本更具针对性
. . 关系抽取 编写模板来匹配关系，这种基于规则和模板的方法
2 1 2
在关系抽取方面，类知识抽取方法具体如下： 会耗费领域专家大量的时间和精力，且可移植性较
3
）基于传统规则和模板的方法 差，无法适应数据的变化。
1
传统的关系抽取主要采用人工编写规则和模板 ）基于传统机器学习的方法
2
的方法来实现［ 24- 25］，一般是由特定领域的专家手动 对于关系抽取而言，传统的机器学习方法可以 ComputerEngineering 计算机工程 年 月 日
28 2022 3 15
分为有监督、半监督和无监督 类。有监督的关系 Bi-LSTM可以获取当前单词之前和之后的信息，在
3
抽取算法受到标注数据集的制约，其准确率受到标 关系抽取任务中具有有效性。 年，GAN等［ 22］提
2019
注数据质量和数量的影响，并且不能拓展新关系［ 34］。 出子序列级实体注意力LSTM网络（EA-LSTM），其
因此，学术界开始转向研究半监督和无监督的学习 可以集中地关注 个实体间的重要信息，在特征融
2
方法，这 种方法对标注数据的依赖性较弱，适合缺 合阶段引入注意力机制来提高模型的上下文信息处
2
少语料数据的关系抽取任务。无监督学习具有领域 理能力。文献［ ］对句子本身进行句法分析，构建
43
无关性，非常适合大规模开放领域的关系抽取，如文 双向树结构的BI-LSTM分析句法，提高了关系抽取
献［ ］通过多层级聚类方法抽取关系，在基础模板 性能。针对关系抽取中过度依赖句子树本身信息的
19
上不断衍射生成新的子类模板，在美国的 家报纸 问题，文献［ ］将注意力机制与句子树结构相结合，
12 44
文章中进行关系抽取，获得了较好的效果。基于传 生成权重矩阵，构造注意力图长短时记忆神经网络
统机器学习的方法缺点同样明显，该类方法存在特 （Attention Graph Long Short Term Memory Neural
征提取误差传播问题，因此，研究人员开始将深度学 Network，AGLSTM），同时利用句子的时序结构和自
习和实体关系抽取相结合。 身结构进行关系抽取，在SemEval- 数据集中，其
2010
）基于深度学习的方法 F 值为 . %。
3 1 85 3
基于深度学习的关系抽取方法改善了特征提取 （）实体关系联合抽取方法
2
误差传播的问题，是近些年的研究热点。本文将基 传统的流水线方法先抽取实体再抽取关系，其存
于深度学习的关系抽取方法分为流水线方法和实体 在错误传播的问题，实体识别模块的效果直接影响关
关系联合抽取方法两类。 系抽取模块的抽取效果。另外，实体识别模块中抽取
（）流水线方法 的实体对不一定完全存在关系，没有关系的实体对会
1
流水线方法分 步抽取信息，先抽取实体再抽 带来冗余信息，影响分类效果。联合抽取方法将实体
2
取关系，最后整合三元组输出。流水线方法一般采 识别和关系抽取模型相融合，直接在文本中抽取实体
用CNN、RNN及其改进模型进行关系抽取，由于它 关系三元组。联合抽取方法可分为 种，分别是基于
2
们不需要手动构造特征并且预测精度很高，因此得 参数共享和基于序列标注的联合抽取方法。
到广泛关注和应用。 基于参数共享的实体关系联合抽取
①
文献［ ］首次利用CNN提取词汇特征和句子 年，MIWA等［ 45］首次提取单词序列和依赖
35 2016
特征并进行关系抽取，大幅提升了模型的分类准确 树结构上实体之间的关系以用于模型训练，在模型
率，但其提出的模型在长句序列中会受到不相关子 结构中，实体识别和关系抽取共享BI-LSTM编码层
序列的影响和干扰。 年，XU等［ 36］利用CNN从 信息，但是，这种方法只是简单地共享底层参数和编
2015
最短依赖路径中学习关系表示，并在模型中加入了 码表示，个任务之间没有关联，并非真正意义上的
2
负采样策略，其比文献［ ］模型的 F 值提高了 联合抽取。 年，KATIYAR等［ 46］首次将注意力机
35 1 2017
. %，大幅提升了关系抽取性能。CNN模型存在 制和BI-LSTM用于实体关系联合抽取，实体识别任
1 3
个问题：一方面，CNN模型卷积核的大小固定不 务采用BI-LSTM来完成，关系分类任务利用实体识
2
变，因此，其对句子语义的提取不充分，为解决该问 别任务输出的实体序列和共享的编码表示作为输
题，GUO等［ 37］提出一种新的Att-RCNN模型以提取 入，引入了注意力模型，有效改善了文献［ ］方法依
45
文本特征与关系分类，利用注意力机制来强化关键 赖于词性标签等复杂特征的缺点。
词与特征，提高了分类性能， 年，闫雄等［ 38］将 基于序列标注的实体关系联合抽取
2020 ②
CNN与自注意力机制相结合进行关系抽取，并取得 基于参数共享的实体关系联合抽取任务弥补了
了较好的效果；另一方面，单一CNN对非连续性词 传统流水线模型中的错误传播、信息丢失等缺点，但
的特征抽取效果较差，因此，龚乐君等［ 39］将CNN与 是，基于参数共享的模型本质上还是先抽取实体再
BI-GRU相结合，改善了单一模型特征提取不足的问 抽取关系，会产生不存在关系的冗余实体信息。为
题，文献［ ］将BI-LSTM与CNN相结合，并引入注 了弥补这一缺陷，ZHANG等［ 47］提出了基于序列标注
40
意力机制来捕捉句子的内部语义信息，在SemEval- 的实体关系联合抽取方法，其可以将实体关系联合
数据集中，该融合模型的F 值为 . %，优于 抽取任务转换为序列标注任务，如图 所示，序列标
2010 1 79 38 4
单一模型。 注输出包含 种信息：实体词的位置信息，采用｛BIE
3
除了采用CNN进行关系抽取外，RNN同样被用 S O｝进行标注；关系类型信息，如｛CP：Country-
于关系抽取。 年，SOCHER等［ 41］利用RNN获取 President，CF：Company-Founder｝；实体对角色信息｛ ，
2012 1
句子的向量表示，提高了关系抽取的性能。由于 ｝，分别表示｛实体 ，实体 ｝。通过这种新的标注
2 1 2
RNN存在梯度消失和梯度爆炸的问题，因此研究人 策略可以同时识别标注出实体和关系，避免构建复
员开始将LSTM等RNN网络的变体引入关系抽取 杂特征，有效减少了基于参数共享方法中的实体识
任务。ZHANG等［ 42］采用Bi-LSTM进行关系分类， 别冗余信息。 第 卷 第 期 张吉祥，张祥森，武长旭，等：知识图谱构建技术综述
48 3 29
图4 实体关系联合抽取标注策略
Fig.4 Annotationstrategyofentityrelationshipjointextraction
但是，文献［ ］方法同样存在缺陷，即无 组，有效解决了关系重叠问题。文献［ ］同样将三
47 50
法 解 决 实 体 关 系 重 叠 问 题（EntityPairOverlap， 元组抽取分为头实体抽取和尾实体抽取 个部分，
2
SingleEntity Overlap，EPO SEO）。针对关系重叠问 解决了SEO问题，在进行尾实体抽取时，采用 种
3
题，文献［ ］提出一种基于多标签分类的联合分类 策略（EPO_None/Two/Three_Tagging）对尾实体进行
48
模型，其编码器由BI-LSTM+DCNN组成，解码器由 标记，在NYT数据集中取得了较好的效果。 年，
2020
实体预测、关系预测以及实体关系联合预测组成， XIAO 等［ 23］设 计 一 种 章 节 级 联 合 学 习 的 模 型
将关系抽取任务转换为多标签分类任务，有效解决 Ch-MEL，该模型利用BI-LSTM与自注意力机制增
了实体关系重叠问题。 年，WEI等［ 49］提出了级 强章节学习表示能力，将参数共享与联合解码相结
2019
联二进制标记框架（CasRel），其将关系看作主语映 合，在SemEval- 数据集中，其F 值比文献［ ］
2010 1 45
射 到 宾 语 的 函 数 f(·)，通 过 Subject Tagger 与 模型高 . %。近年来所出现的关系抽取方法对比
0 4
Relation-Specific Object Taggers获取实体关系三元 如表 所示。
2
表2 关系抽取方法对比
Table2 Comparisonofrelationshipextractionmethods
方法类别 方法细分 年份 方法 数据集 模型 方法特点 适用场景 评测指标 评测值/%
利用本体层次结构与概
基于传统规则和 本体
— [ 16] footballdomain RelExt 念之间的关系进行关系 足球领域 Precision .
模板的方法 2005 扩展 2020
抽取，但可移植性较差
无监督关系抽取，在基础
基于传统机器 多层级 UnrestrictedRela‐ 新闻报纸
学习的方法
— 2006[ 19]
聚类
news
tionDiscovery
模板上不断衍射生成新
领域
Acc 75.
00
的子类模板
采用CDNN自动提取词
基于深度学习 流水线 SemEval- 汇与句子级别的特征，但
[ 35] CNN CDNN 通用领域 F .
的方法 方法 2014 容易受到不相关子序列 1 8270
2010
的干扰
引入最短依赖路径与负
基于深度学习 流水线 SemEval- 采样策略来避免无关序
[ 36] CNN depLCNN+NS 通用领域 F .
的方法 方法 2015 列的干扰，并解决了关系 1 8400
2010
的方向性问题
结合CNN与BI-GRU提
基于深度学习 流水线 SemEval- 取更丰富的上下文表示，
[ 37] CNN Att-RCNN 通用领域 F .
的方法 方法 2019 利用词级注意力与句子 1 8660
2010
级注意力强化特征
通过引入自注意力机制得
基于深度学习 流水线 SemEval-
[ 38] CNN Self-Att-CNN 到词序列之间的关系，使得 通用领域 F .
的方法 方法 2020 1 8446
2010 词向量信息更加丰富
BI-GRU与CNN相对于
基于深度学习 流水线 DDIExtraction 单一模型可以更充分地 生物医学
[ 39] CNN BI-GRU+CNN F .
的方法 方法 2020 提取句子蕴含的语义信 领域 1 7500
2013
息与特征
利用RNN获取句子的向
基于深度学习 流水线 SemEval-
[ 41] RNN MV-RNN 量表示，但无法处理长期 通用领域 F .
的方法 方法 2012 1 8240
2010 依赖问题
基于深度学习 流水线 SemEval- 采用BI-LSTM获取单词
[ 42] RNN BI-LSTM 通用领域 F .
的方法 方法 2015 的双向信息 1 8430
2010
重点关注实体之间的文
基于深度学习 流水线 SemEval- 本，在特征融合阶段引入
[ 22] RNN EA-LSTM 通用领域 F .
的方法 方法 2019 注意力机制获取最终的 1 8470
2010
特征表示 ComputerEngineering 计算机工程 年 月 日
30 2022 3 15
续表
方法类别 方法细分 年份 方法 数据集 模型 方法特点 适用场景 评测指标 评测值/%
基于深度学习 流水线 SemEval- 通过软修剪策略与注意力
[ 44] RNN AGLSTM 通用领域 F .
的方法 方法 2021 机制学习句子的结构信息 1 8530
2010
实体识别与关系抽取共享
基于深度学习 联合抽取 参数 SemEval-
[ 45] SPTree BI-LSTM编码层，但 个任 通用领域 F .
的方法 方法 2016 共享 2 1 8550
2010 务之间不存在关联
提出一种新的标注策略
基于深度学习 联合抽取 序列 同时抽取实体与关系，但
[ 47] NYT LSTM-LSTM-Bias 通用领域 F .
的方法 方法 2017 标注 无法解决实体关系重叠 1 4950
问题
将关系抽取任务转化为多
基于深度学习 联合抽取 序列
[ 48] NYT BI-LSTM+DCNN 标签分类任务，有效解决了 通用领域 F .
的方法 方法 2019 标注 1 5310
实体关系重叠问题
将关系看作头实体到尾
基于深度学习 联合抽取 序列
[ 49] NYT CasRel 实体的映射，有效解决了 通用领域 F .
的方法 方法 2020 标注 1 8960
实体关系重叠问题
在进行尾实体抽取时采
基于深度学习 联合抽取 序列
[ 50] NYT Bert+BI-LSTM 用 种策略，解决了关系 通用领域 F .
的方法 方法 2020 标注 3 1 8600
重叠问题
从章节级粗粒度角度进
基于深度学习 联合抽取 序列 SemEval-
[ 23] Ch-MEL 行跨句或跨段的实体关 通用领域 F .
的方法 方法 2020 标注 1 8590
2010 系抽取
2.2 知识融合 物力，缺乏自动方法的支持，因此本体映射方法应运而
知识图谱的构建数据来源十分广泛，不同数据 出，研究人员从不同的角度采用不同的方法建立本体
源之间的知识缺乏深入的关联，知识重复问题很严 之间的映射，主要分为以下 种映射方法：
4
重［ 51］。知识融合将来自不同数据源的异构化、多样 ）基于NLP的方法，其比较映射对象的相似度，
1
化的知识在同一个框架下进行消歧、加工、整合等， 如PORTER［ 54］提出的Stemming算法，用于寻找词形
达到数据、信息等多个角度的融合。知识融合的核 的变化。
心在于映射的生成［ 12］，目前，知识融合技术可以分为 2）基于结构的方法，如 Stanford 大学开发的
本体融合和数据融合 个方面。
AnchorPROMPT本体工具集［ 55］。
2
. . 本体融合 ）基于实例的方法，大多采用机器学习方法，让
2 2 1 3
算法学习到正确的映射。该类方法可以较好地解决
在知识融合技术中，本体层占据着重要部分。
异构本体之间的映射问题，但不适用于本体关系间
到目前为止，研究人员已经提出了多种解决本体异
的映射。
构的方法，主要分为本体集成和本体映射［ 52］两大类，
）综合方法，即综合使用多种映射方法，如
如图 所示。本体集成是将多个不同数据源的异构 4
5 QOM，其通过合理利用各种分配算法，可以提高映
本体集成为一个统一的本体，本体映射则是在多个
射效率，有效处理大规模本体映射问题。
本体之间建立映射规则，使信息在不同本体之间进
. . 数据融合
行传递。 2 2 2
数据方面的知识融合包括实体合并、实体对齐、
实体属性融合等方面。其中，实体对齐是多源知识
融合的重要部分，用于消除实体指向不一致性与冲
突问题。知识图谱的对齐算法可分为 类，分别是
3
成对实体对齐、局部实体对齐和全局实体对齐。
）成对实体对齐
图5 本体映射和本体集成 1
成对实体对齐方法包括基于传统概率模型和基
Fig.5 Ontologymappingandontologyintegration
于机器学习的实体对齐方法。文献［ ］利用属性相
56
对于本体集成，文献［ ］将本体集成划分为一系 似度将实体匹配问题转换为分类问题，为后来的研
53
列的子活动，包括决定本体集成的方式、确定识别模块、 究奠定了基础。 年，张伟莉等［ 57］将实体对齐建
2017
确定每个模块中需要表示的知识、识别和获取候选本 模为带约束的二分类问题，将特征空间划分为 个
2
体、候选本体研究和分析、选择源本体，最后执行集成 视图，引入半监督协同算法分别在 个视图上训练
2
过程。由于本体集成步骤比较复杂，耗费大量的人力 分类器，提升了实体对齐的效果。 第 卷 第 期 张吉祥，张祥森，武长旭，等：知识图谱构建技术综述
48 3 31
）局部实体对齐 义匹配模型的知识推理。
2
局部实体对齐方法引入实体属性并为其分配不 ）基于翻译模型的知识推理
1
同的权重，再进行加权求和计算实体的相似度。文 在基于翻译模型的知识推理中，经典模型有
献［ ］提出一种大规模实体匹配方法，其主要采用 TransE、TransR等，但是，TransE、TransR等模型认为
58
TF-IDF为向量中的每个分量分配权重并建立索引， 三元组之间是独立的。 年，WANG等［ 66］提出
2018
实体相似度通过余弦相似性进行判别。这种算法具 TransN模型以整合三元组周围的邻域信息，其采用
有较快的计算速度和较高的召回率，但准确性较低， 对象嵌入和上下文嵌入表示实体与关系，提升了知
因为其只是将实体关系看作实体的一类属性，并未 识推理的性能。由于TransE、TransR等模型都无法
实现真正的对齐。 完全满足所有关系的建模，因此 SUN 等［ 67］提出
）全局实体对齐 Rotate模型，如图 所示，其将关系看作头实体向量
3
6
全局实体对齐综合考虑多种匹配策略来判别实
向尾实体向量的旋转角度，可以建模和推断各种关
体相似度，包括基于相似性传播和概率模型的实体
系的模式，并提出一种较为新颖的自对抗负采样技
对齐方法。 年，BHATTACHARYA等［ 59］提出一
术，使得模型效果大幅提升。
2007
种关系聚类算法用于实体对齐，LACOSTE-JOURNAL
等［ 60］基于该算法进一步提出SiGMa算法，将实体对
齐问题转换为全局匹配评分目标优化问题，引入实
体关系与属性并不断迭代发现所有的实体匹配对。
基于概率模型的实体对齐方法通常利用统计关系进
行计算，如 CRF、马尔科夫逻辑网（Markov Logic
Networks，MLNs）模型等。 2012年，WICK 等［ 61］将
图6 Rotate模型中的关系建模
CRF引入判别式层次模型中，其中将实体作为树结
Fig.6 RelationshipmodelinginRotatemodel
构、观察值作为叶子节点，以进行推理，其适用于大
文献［ ］在TransE的基础上引入三元组邻域信
规模的知识图谱实体对齐。针对大规模数据集对齐
68
效率问题，文献［ ］基于MLNs提出一种通用的实
息，提出聚合邻域信息的表示模型TransE-NA，为实体
62
选择最相关的属性作为邻域信息，有效缓解了数据稀
体匹配算法，其在实体的有限子集运行匹配器，在实
例之间传递所构建的消息集以控制匹配器的交互， 疏问题。 年，宋浩楠等［ 69］针对知识推理可解释性
2021
从而显著提高实体匹配的召回率。 差的问题，将知识表示与强化学习相结合，提出
2.3 知识推理 RLPTransE模型，其将知识推理问题转化为马尔科夫
知识推理根据已有的实体关系信息来推断新的 序列决策问题，增强了知识推理的可解释性。
事实结论，从而进一步丰富知识图谱，满足上游任务 ）基于张量分解的知识推理
2
的需求。本文将知识推理方法主要分为 种类型， 在基于张量分解的知识推理中，一般将知识图
3
分别为基于逻辑规则的推理、基于分布式特征表示 谱中的实体关系三元组通过张量分解方法进行表示
的推理和基于深度学习的推理。 学习，将分解得到的向量重构为张量，元素值高于一
. . 基于逻辑规则的推理 定阈值的作为候选推理结果。 年，NICKEL
2 3 1 2011
基于逻辑规则的推理包括谓词逻辑推理、本体 等［ 70］提出RESCAL，如图 所示，其将高维关系数据
7
推理和随机推理。 年，SCHOENMACKERS 分解为三阶张量，在降低数据维度的同时又保持了
2010
等［ 63］提出的一阶归纳学习就是一种典型的谓词逻辑 数据原有特征，在知识推理中取得了较好的效果。
推理，其可以自动提取高质量的事实并去除噪声，但
是，谓词逻辑推理效率很低。 年，CHEN等［ 64］提
2016
出一种本体寻路（Ontological Pathfinding，OP）算法，
该算法通过一系列的并行优化技术实现大规模的知
识图谱，在Freebase数据库中挖掘了第一个规则集，
取得了较好的效果。文献［ ］为解决实体关系推理
65 图7 高维关系数据的分解
中准确率和召回率低的问题，提出双层随机游走
Fig.7 Decompositionofhighdimensionalrelationaldata
（Two-tier Random Walk，TRWA）算法，TRWA利用无
向图来表述知识图谱，除此之外，TRWA在全局模式 由于RESCAL计算复杂，所占内存很大，因此文
和局部模式 种角度下对路径特征进行评估，提高 献［ ］提出新的知识推理模型TRESCAL，其引入实
2 71
了算法的准确率和召回率。 体类型信息来约束并排除不满足关系的三元组，显
. . 基于分布式特征表示的推理 著降低了训练时间并提高了预测性能。 年，
2 3 2 2017
基于分布式特征表示的推理包括基于翻译模型 吴运兵等［ 72］通过对知识图谱进行路径张量分解，旨
的知识推理、基于张量分解的知识推理以及基于语 在解决知识图谱推理中忽略实体间关系路径的问 ComputerEngineering 计算机工程 年 月 日
32 2022 3 15
题，该方法可以高效地挖掘实体间的关系与新事实， DAS等［ 77］提出一种具有单一性和高容量性的
有助于完善知识图谱。 RNN模型，该模型的所有目标关系共享RNN的关系
）基于语义匹配模型的知识推理 类型表示和组合矩阵，减小了训练参数量，在大规模
3
文献［ ］提出DistMult模型，其将RESCAL中的 知识图谱推理中具有更高的准确性和实用性。 年，
73 2018
每一个关系向量转换为对角矩阵，从而对RESCAL进 GUO等［ 78］设计了知识图谱的深度序列模型（Deep
行简化，减少参数，在对现有知识库的推理中表现出了 Sequential model for KG，DSKG），分别用独立的
较好的效果。但是，无论是RESCAL还是DistMult，都 RNN单元处理实体层和关系层，取得了较好的效
忽略了实体和关系的语义多样性。 年，刘峤等［ 74］ 果。 年，CHEN等［ 79］针对实体句中的词序特征，
2017 2020
认为每个关系都反映了相应实体的某些语义关系，可 提出基于 LSTM 的知识图谱嵌入方法（Learning
以通过选择性的加权来对这些关系进行表示和区分， Knowledge Graph Embedding with Entity Descriptions
因此，其提出统一加权模型（UnifiedWeightedModel， based on LSTM Networks，KGDL），其采用LSTM实
UWM）和独立加权模型（IndependentWeightedModel， 体描述的句子进行编码，然后联合TransE与LSTM
IWM）关系推理算法，计算效率较高。 年，ZHANG 模型将实体描述的句子嵌入与三元组编码为实体描
2019
等［ 75］引入超复数来建模实体和关系，同样将关系看作 述，从而实现知识推理。除RNN之外，CNN也被引
超平面内头实体到尾实体的旋转，相对于Rotate只有 入知识推理任务。 年，DETTMERS等［ 80］提出一
2018
一个旋转平面，QuatE有 个旋转平面，其自由度及泛 种用于知识推理的卷积神经网络模型ConvE，该模
2
化能力更好。 型采用二维卷积的嵌入来对知识图谱中的新链接进
. . 基于深度学习的推理 行推理，在现有的知识图谱数据集中获得了较好的
2 3 3
目前，深度神经网络已被广泛应用于NLP领域， 结 果 。 由 于 ConvE 的 交 互 数 量 有 限 ，因 此
并取得了显著的成效。神经网络可以自动捕捉特 VASHISHTH等［ 81］提出InteractE，InteractE通过特征
征，通过非线性变换将输入数据从原始空间映射到 置换、特征重塑以及圆形卷积来捕捉额外的异构特
另一个特征空间并自动学习特征表示，适用于知识 征，增加实体关系间的交互次数。李少杰等［ 82］认为
推理这种抽象任务。 ConvE丢失了三元组的整体结构信息，因此，提出基
年，SOCHER等［ 76］提出一种新的神经张量 于CNN的知识表示模型（Convolutional Knowledge
2013
网络模型（NeuralTensor Network，NTN）以建模关系 Embeddings，ConvKE），该模型将三元组的各个元素
信息，如图 所示，该模型采用双线性张量层直接将 整合到一起提取整体的结构信息，通过维度变换策
8
个实体向量跨多个维度联系起来，刻画实体之间复 略增加卷积滑动窗口步数，增强了知识之间的信息
2
杂的语义关系，大幅提高了推理性能。 交互。
3 知识图谱在深度学习中的应用
3.1 深度学习的可解释性
深度学习在CV、NLP等领域获得了巨大的成
功，但是可解释性一直是深度学习的一个弱点，深度
学习复杂性高，参数多，人们一般无法解释这种“端
到端”模型做出决策的原理，也无法判断决策的可靠
性。大部分的深度学习模型都采用数据驱动的方
法，很少关注知识驱动，因此，将知识图谱与深度学
习相结合构建具有可解释性的深度学习模型是一个
新的研究课题。
年，CATHERINE等［ 83］将深度学习和知识
2016
图谱相结合，构建了一个具有可解释性的通用概率
逻辑系统（Programming with Personalized PageRank，
ProPPR），以完成推荐任务，其提出EntitySim，由于
EntitySim仅使用知识图谱链接来了解用户的喜好，
并没有利用实体的类型等额外信息，因此文中作者
将其扩展为TypeSim，并开发了基于图的潜在因子
模型GraphLF，其可以展现对象的隐藏维度以提高
推荐性能。 年，CAO等［ 84］考虑到知识图谱总是
2019
图8 NTN网络中的关系建模 不完整的，因此，他们在将知识图谱引入推荐系统时
Fig.8 RelationshipmodelinginNTNnetwork 还加入了知识图谱补全技术，利用知识图谱的先验 第 卷 第 期 张吉祥，张祥森，武长旭，等：知识图谱构建技术综述
48 3 33
知识来增强用户-系统的交互，通过用户-系统的交互 性能，尤其适用于数据集有限的情况。 年，
2019
来补全知识图谱，实现了相互增强的效果，提高了推 WANG等［ 89］在信息抽取任务中，考虑到实体之间的
荐的可解释性。文献［ ］提出一种图模型，用于揭 关系与实体类型紧密相关，这种依赖关系可以看作
85
示预训练模型CNN中的隐藏层知识层次，其通过自 约束并表示为逻辑规则，同样采用一阶逻辑的形式
动学习上万个节点的解释图来揭示CNN的层次和 将逻辑知识集成到深度学习网络中。该文提出的模
知识结构，解释图中的节点代表CNN中卷积层的部 型由深度学习模块和逻辑模块组成，深度学习模块
分模式，利用知识图谱来解释决策。 用于学习每个单词的特征表示，逻辑模块是通过一
3.2 深度学习的指导 阶逻辑（First-Order Logic，FOL）表示的一组逻辑规
知识图谱可以作为约束来优化目标，将知识图 则，其指明了输出标签的空间复杂关系。文中通过
谱中的知识表达作为优化目标的后验正则项，从而 映射函数将神经网络的输出映射到逻辑系统并最终
提升深度学习模型的性能。其中，比较典型的是文 产生逻辑输出，在意见目标抽取任务和关系抽取任
献［ ］将深度神经网络和结构化逻辑规则相结合， 务中效果较好。
86
如图 所示，将一阶逻辑规则用于增强各种类型的 3.3 深度学习推理
9
神经网络，该文所提框架teacher-student network可 深度学习本质上是一种映射，并不具有推理性，
以使神经网络在标记的数据和逻辑规则中同时进行 缺乏“归纳推广”的能力。贝叶斯网络之父JUDEA
学习，通过一个迭代的规则知识提取过程，将逻辑规 PEARL在文献［ ］中也明确提出，当前机器学习的
90
则中编码的结构化信息转换为网络参数。其中，利 突破口在于“因果革命”。基于此，在因果推理领域，
用teacher network建模逻辑规则，student network通 最典型的方法是BATTAGLIA等［ 91］面向关系推理而
过反向传播算法与teacher network的约束来学习规 提出的图网络，该网络将图与深度学习相结合，图网
则，该框架应用于CNN与RNN，在命名实体识别和 络具有较好的归纳推广和推理能力，同时也具备深
情感分析中获得了较高的性能。 度学习“端到端”的灵活性，其主要的计算单元为图
网络模块（graph-to-graph），输入为图的格式，对结构
进行计算并返回图作为输出，图网络相对于普通的
神经网络具有归纳推广和组合概括的能力，使得深
度学习也能进行因果推理。图神经网络除了具有较
好的归纳推广和因果推理能力之外，其最大的优点
在于可以处理非欧几里德结构数据。图神经网络可
以 分 为 不 同 的 类 别 ，如 图 卷 积 网 络（Graph
Convolution Networks，GCN）、图注意力网络（Graph
Attention Network，GAT）等。
在推荐模型方面，文献［ ］提出一种混合推荐
图9 逻辑规则与神经网络结合框架 92
模型，其包含 个模型，分别是由知识图谱和深度学
Fig.9 Combiningframeworkoflogicrulesand 2
习相结合的RCKD模型和知识图谱与协同过滤相结
neuralnetworks
合的RCKC模型。其中：RCKD模型首先利用已知
年，WANG等［ 87］提出深度概率逻辑系统 的三元组(h,r,t)构成图，再搜索知识图谱中的推理路
2018
（Deep Probabilistic Logic，DPL），DPL将概率逻辑和 径，利用TransE模型将推理路径嵌入成路径向量，最
深度学习相结合，使用概率逻辑表示间接监督的监 后利用深度学习获取路径向量中的语义预测评分；
督模块，使用深度神经网络作为最终的预测模块， RCKC模型则利用TransE模型获取知识图谱中的实
DPL模型将决策标记为潜在变量，先验知识采用加 体向量，再利用协同过滤思想对用户进行物品推荐，
权一阶逻辑公式表示，最后采用变分期望最大化交 其推荐准确率相对较高。
替学习深度神经网络和改善间接监督中不确定权
4 存在的困难与挑战
重，在生物医学机器阅读实验中表现出了优良的性
能。针对神经网络需要大量数据集进行训练的问 知识图谱的概念于 年由Google提出，其发
2012
题，LI等［ 88］利用逻辑规则将先验知识引入神经网络 展还不算成熟，属于建立在多个技术领域上的一门
中用于指导训练和预测。不同于文献［ ］使用结构 实用技术。本文对知识图谱的构建以及知识图谱在
86
化规则的teacher network，该文直接将结构化的知识 深度学习中的应用进行分析，总结出该领域目前面
整合到神经网络结构中，通过将规则转换为可微分 临的困难和挑战具体如下：
的计算图，使用其节点约束来系统地扩充现有的网 ）知识图谱构建技术方面
1
络结构。该文提出的框架在机器理解、自然语言推 （）对于知识抽取技术，现有的实体关系联合抽
1
理、文字分块等任务中都可以改进现有神经网络的 取技术并未解决关系重叠问题，算法准确率和召回 ComputerEngineering 计算机工程 年 月 日
34 2022 3 15
率都较低。除此之外，基于开放域的关系抽取还处 子科技大学学报， ，（ ）： - .
2016 45 4 589 606
于初级阶段，多语种、大范围的多元实体关系抽取是 XUZL，SHENGYP，HELR，etal.Reviewonknowledge
graph technique［s J］. Journal of University of Electronic
当前面临的主要困难之一，无监督关系抽取具有较
ScienceandTechnologyofChina， ，（ ）： - .
高的可移植性和泛化性，为开放域关系抽取任务提 2016 45 4 589 606
（inChinese）
供了新的思路。 ［ ］ 李涓子，侯磊. 知识图谱研究综述［J］. 山西大学学报（自
4
（）对于知识融合技术，实体对齐是最主要的手 然科学版）， ，（ ）： - .
2 2017 40 3 454 459
LIJZ，HOUL.Reviewsonknowledgegraphresearch［J］.
段，如何实现高质量的实体对齐、共指消解是一项巨
Journal of Shanxi University（Natural Science Edition），
大的挑战，开放领域下的实体对齐、共指消解以及多
，（ ）： - .（inChinese）
源数据库融合是当前主要的研究重点，如何在短文 2017 40 3 454 459
［ ］ Al-MOSLMIT，OCAA M G，OPDAHLA L，etal.Named
5
本情况下准确地将实体链接到知识库中亟需解决。 entityextractionforknowledgegraphs：aliteratureoverview［J］.
小样本学习是最具潜力的研究方法之一，在计算机 IEEEAccess， ，： - .
2020 8 32862 32881
［ ］ SMIRNOVAA，CUDRE-MAUROUXP.Relationextraction
视觉中取得了较好的效果，使得模型具有高效的学 6
using distantsupervision：a survey［J］.ACM Computing
习能力，将小样本学习应用于实体对齐具有重要的
Surveys， ，（ ）：- .
研究价值。 2019 51 5 1 35
［ ］ KUMARS.Asurveyofdeeplearningmethodsforrelation
7
（）对于知识推理技术，现有的知识推理技术大 extraction［EB/OL］.［ - - ］.https：//arxiv.org/pdf/
3 2021 04 05
多只关注静态数据，忽略了时间信息，知识图谱的信 . .pdf.
1705 03645
［ ］ 庄传志，靳小龙，朱伟建，等. 基于深度学习的关系抽取
息应该随着时间的推移而变化，因此，动态知识图谱 8
研究综述［J］. 中文信息学报， ，（ ）：- .
推理还需要进行研究探索，如EvolveGCN［ 93］，其使用
ZHUANG C Z，JIN X
L，ZHU2 W019 J，3 e3 ta1 l.2 De1 ep1 l8
earning
RNN来演化GCN的参数，捕捉图序列的动态信息。
basedrelationextraction：asurvey［J］.JournalofChinese
除此之外，如何利用文本、音频、图像等多源信息来 InformationProcessing， ，（ ）：- .（inChinese）
2019 33 12 1 18
进行知识推理以及跨语言的知识推理，也是一个新 ［ ］ DONGX，GABRILOVICHE，HEITZG，etal.Knowledge
9
vault：a Web-scale approach to probabilistic knowledge
的研究方向。
fusion［C］//Proceedings of the th ACM SIGKDD
）知识图谱应用于深度学习方面 20
2 International Conference on Knowledge Discovery and
目前，将知识图谱应用于深度学习还处于起步 DataMining.NewYork，USA：ACMPress， ： - .
2014 601610
阶段，存在一些问题亟需解决，例如，知识图谱由点 ［ ］ HAOY，ZHANGY，LIUK，etal.Anend-to-endmodelfor
10
和边组成，符号化的知识在向量化后不可避免地会 question answering over knowledge base with cross-
attentioncombiningglobalknowledge［C］//Proceedingsof
导致语义缺失问题，因此，如何对知识图谱进行高质
the th Annual Meeting of the Association for
量的表示仍是一个挑战。 55
ComputationalLinguistics.［S.l.］：ACL， ： - .
2017 221 231
5 结束语 ［ ］ GONG F，WANG M，WANG H，et al. SMR：medical
11
knowledge graph embedding for safe medicine
作为知识工程的一个重要分支，知识图谱已经 recommendatio［n J］.BigDataResearch， ， ： .
2021 23 100174
成为人工智能发展的核心动力和重要领域。本文对 ［ ］ 王昊奋，漆桂林，陈华钧. 知识图谱：方法，实践与应用［M］.
12
北京：电子工业出版社， .
比分析知识图谱构建技术，讨论知识图谱与深度学 2019
WANG H F，QI G L，CHEN H J. Knowledge graph：
习相结合的方法，并给出研究难点与潜在解决思路。
method，practiceandapplication［M］.Beijing：Publishing
从当前研究进展可以看出，将深度学习用于知识图 HouseofElectronicsIndustry， .（inChinese）
2019
谱构建已成为主流方法并取得了较好的效果，但无 ［ ］ RAU L F. Extracting company names from text［C］//
13
Proceedings of the th IEEE Conference on Artificial
论是知识图谱构建还是深度学习，目前都存在着一 7
IntelligenceApplications.WashingtonD.C.，USA：IEEE
些缺陷和挑战。在未来，基于深度学习的开放领域
Press， ： - .
知识抽取、多源知识融合、动态知识推理，以及利用 1991 12 23
［ ］ HUMPHREYS K，GAIZAUSKAS R，AZZAM S，et al.
14
知识图谱弥补深度学习的某些缺陷，将是知识图谱 Universityofsheffield：descriptionoftheLaSIE-IIsystem
领域的重要研究方向。 as used for MUC- ［M］.［S. l.］：Association for
7
ComputationalLinguistics， .
1998
参考文献 ［ ］ AITKEN J S. Learning information extraction rules：an
15
inductivelogicprogrammingapproach［C］//Proceedingsof
［ ］ MIN C，MAO S，LIU Y. Big data：a survey［J］. Mobile the thEuropeanConferenceonArtificialIntelligence.
1 15
Networks&Applications， ，（ ）： - . Berlin，Germany：Springer， ： - .
2014 19 2 171 209 2002 102 112
［ ］ 付小红. 论知识组织的原则［J］. 情报资料工作， （ ）： ［ ］ SCHUTZ A，BUITELAAR P.RelExt：a tool for relation
2 2001 5 16
- . extractionfromtextinontologyextension［C］//Proceedings
11 15
FU X H. Principles on knowledge organization［J］. ofthe thInternationalSemanticWebConference.Berlin，
4
InformationandDocumentationServices， （ ）： - . Germany：Springer， ： - .
2001 5 11 15 2005 593 606
（inChinese） ［ ］ ZHOUGD，ZHANGJ，SUJ，etal.Recognizingnamesin
17
［ ］ 徐增林，盛泳潘，贺丽荣，等. 知识图谱技术综述［J］. 电 biomedicaltexts：amachinelearningapproach［EB/OL］.
3 第 卷 第 期 张吉祥，张祥森，武长旭，等：知识图谱构建技术综述
48 3 35
［ - - ］.https：//academic.oup.com/bioinformatics/ org/N - .pdf.
2021 04 05 19 1423
article/ / / / . ［ ］ 曾青霞，熊旺平，杜建强，等. 结合自注意力的BiLSTM-
2071178245780 32
［ ］ LIU X，ZHANG S，WEI F，et al. Recognizing named CRF的电子病历命名实体识别［J］. 计算机应用与软件，
18
entities in tweets［C］//Proceedings of the th Annual ，（ ）： - ， .
49 2021 38 3 159 162 242
MeetingoftheAssociationforComputationalLinguistics. ZENGQX，XIONGWP，DUJQ，etal.Electronicmedical
［S.l.］：ACL， ： - . record named entity recognition combined with self-
2011 14 18
［ ］ SHINYAMA Y，SEKINE S. Preemptive information attention BiLSTM-CRF［J］. Computer Applications and
19
extraction using unrestricted relation discovery［C］// Software， ，（ ）： - ， .（inChinese）
2021 38 3 159 162 242
ProceedingsofHumanLanguageTechnologyConference ［ ］ 罗熹，夏先运，安莹，等. 结合多头自注意力机制与BiLSTM-
33
of the North American Chapter of the Association of CRF的中文临床实体识别［J］. 湖南大学学报（自然科学
ComputationalLinguistics.［S.l.］：ACL， ： - . 版）， ，（ ）： - .
2006 304 311 2021 48 4 45 55
［ ］ MA X，HOVY E. End-to-end sequence labeling via bi- LUOX，XIAXY，ANY，etal.ChineseCNERcombined
20
directional LSTM-CNNs-CRF［EB/OL］.［ - - ］. with multi-head self-attention and BiLSTM-CRF［J］.
2021 04 05
https：//www.aclweb.org/old_anthology/P/P /P - . Journal of Human University（Natural Sciences）， ，
16 16 1101 2021
pdf. （ ）： - .（inChinese）
48 4 45 55
［ ］ 杨飘，董文永.基于BERT嵌入的中文命名实体识别方法［J］. ［ ］ 于浏洋，郭志刚，陈刚，等. 面向知识图谱构建的知识抽
21 34
计算机工程， ，（ ）： - ， . 取技术综述［J］. 信息工程大学学报， ，（ ）： - .
2020 46 4 40 45 52 2020 21 2 227235
YANGP，DONGW Y.Chinesenamedentityrecognition YULY，GUOZG，CHENG，etal.Summaryofknowledge
methodbasedonBERTembeddin［g J］.ComputerEngineering， graph construction oriented knowledge extraction
，（ ）： - ， .（inChinese） technology［J］. Journal of Information Engineering
2020 46 4 40 45 52
［ ］ GANT，GANY，YANMINHE.Subsequence-levelentity University， ，（ ）： - .（inChinese）
22 2020 21 2 227 235
attentionLSTMforrelationextraction［C］//Proceedingsof ［ ］ ZENGD，LIUK，LAIS，etal.Relationclassificationvia
35
International Computer Conference on Wavelet convolutionaldeepneuralnetwor［k EB/OL］［. - - ］.
2019 20210405
Active Media Technology and Information Processing. http：//www.nlpr.labs.gov.cn/cip/liukang.files/camera_
WashingtonD.C.，USA：IEEEPress， ： - . coling _final.pdf.
2019 102 113 2014
［ ］ XIAO J，ZHOU Z. Chapter-level entity relationship ［ ］ XU K，FENG Y，HUANG S，et al. Semantic relation
23 36
extractionmethodbasedonjointlearning［C］//Proceedings classificationviaconvolutionalneuralnetworkswithsimple
of International Conference on Intelligent Human- negative sampling［J］. Computer Science， ， ：
2020 2015 71
Machine Systems and Cybernetics. Washington D. C.， - .
941 949
USA：IEEEPress， ： - . ［ ］ GUOXY，ZHANGHY，XUHJ，etal.Asingleattention-
2020 145 156 37
［ ］ RONANC，JASONW，LÉONB，etal.Naturallanguage based combination of CNN and RNN for relation
24
processing（almost）from scratch［J］.JournalofMachine classification［J］.IEEEAccess， ，： - .
2019 7 12467 12475
LearningResearch， ， ： - . ［ ］ 闫雄，段跃兴，张泽华. 采用自注意力机制和CNN融合
2011 12 2493 2537 38
［ ］ QIUJ，ZHOUY，WANGQ，etal.Chineseclinicalnamed 的实体关系抽取［J］. 计算机工程与科学， ，（ ）：
25 2020 42 11
entity recognition using residual dilated convolutional - .
2059 2066
neural network with conditional random field［J］. IEEE YAN X，DUAN Y X，ZHANG Z H. Entity relationship
TransactionsonNanoBioscience， ， ： - . extractionfusingself-attentionmechanismandCNN［J］.
2019 12 306 315
［ ］ KONGJ，ZHANGL，JIANGM，etal.Incorporatingmulti- Computer Engineering & Science， ，（ ）： -
26 2020 42 11 2059
level CNN and attention mechanism for Chinese clinical .（inChinese）
2066
named entity recognition［J］. Journal of Biomedical ［ ］ 龚乐君，刘晓林，高志宏，等. 基于双向GRU和CNN的药
39
Informatics， ， ： . 物相互作用关系抽取［J］．陕西师范大学学报（自然科学
2021 116 103737
［ ］ HUANG Z，WEI X，KAI Y. Bidirectional LSTM-CRF 版）， ，（ ）： - .
27 2020 48 6 108 113
models for sequence tagging［EB/OL］.［ - - ］. GONGLJ，LIUXL，GAOZH，etal.Extractionofdrug-
2021 04 05
https：//arxiv.org/pdf/ . .pdf. druginteractionbasedonbidirectionalGRUandCNN［J］.
1508 01991
［ ］ UKOV-GREGORIA，BACHRACHY，COOPES.Named Journal of Shaanxi Normal University（Natural Science
28
entityrecognitionwithparallelrecurrentneuralnetworks Edition）， ，（ ）： - .（inChinese）
2020 48 6 108 113
［C］//Proceedings of the th Annual Meeting of the ［ ］ YIN B，SUN Y，WANG Y. Entity relation extraction
56 40
AssociationforComputationalLinguistics.［S.l.］：ACL， method based on fusion of multiple information and
： - . attention mechanism［C］//Proceedings of IEEE
2018 69 74 2020
［ ］ RONRANC，LEES.Effectofcharacterandwordfeatures InternationalConferenceonComputerandCommunications.
29
inbidirectionalLSTM-CRFforNER［C］//Proceedingsof WashingtonD.C.，USA：IEEEPress， ： - .
2020 145 160
IEEEInternationalConferenceonBigDataandSmart ［ ］ SOCHERR，HUVALB，MANNINGCD，etal.Semantic
2020 41
Computing.WashingtonD.C.，USA：IEEEPress， ： compositionality through recursive matrix-vector spaces
2020
- . ［C］//Proceedings of Joint Conference on Empirical
14 25
［ ］ YAN H，DENG B，LI X，et al. TENER：adapting Methods in Natural Language Processing（EMNLP）&
30
transformerencoderfornameentityrecognition［EB/OL］. Computational Natural Language Learning（CoNLL）.
［ - - ］.https：//arxiv.org/pdf/ . .pdf. WashingtonD.C.，USA：IEEEPress， ： - .
2021 04 05 1911 04474 2012 1201 1211
［ ］ DEVLIN J，CHANG M W，LEE K，et al. BERT：pre- ［ ］ SHUZ，ZHENGD，HUX，etal.Bidirectionallongshort-
31 42
training of deep bidirectional transformers for language term memory networks for relation classification［C］//
understanding［EB/OL］.［ - - ］.https：//aclanthology. Proceedings of the th Pacific Asia Conference on
20210405 29 ComputerEngineering 计算机工程 年 月 日
36 2022 3 15
Language，InformationandComputation.WashingtonD.C.， （ ）： - .
3381 954 959
USA：IEEEPress， ： - . ［ ］ 张伟莉，黄廷磊，梁霄. 基于半监督协同训练的百科知识
2015 73 78 57
［ ］ GENG Z，CHEN G，HAN Y，et al. Semantic relation 库实体对齐［J］. 计算机与现代化， （ ）： - .
43 2017 12 88 93
extractionusingsequentialandtree-structuredLSTM with ZHANGWL，HUANGTL，LIANGX.Instancealignment
attention［J］.InformationSciences， ， ： - . algorithm betweenencyclopediabasedonsemi-supervised
2020 509 183 192
［ ］ 张勇，高大林，巩敦卫，等. 用于关系抽取的注意力图长 co-trainin［g J］.ComputerandModernization， （ ）： -
44 2017 12 88
短时记忆神经网络［J］. 智能系统学报， ，（ ）： .（inChinese）
2021 16 3 93
- . ［ ］ LI J，WANG Z，XIAO Z，et al. Large scale instance
518 527 58
ZHANGY，GAODL，GONGDW，etal.Attentiongraph matchingviamultipleindexesandcandidateselection［J］.
long short term memory neural network for relation Knowledge-BasedSystems， ， ： - .
2013 50 112 120
extraction［J］.CAAITransactionsonIntelligentSystems， ［ ］ BHATTACHARYAI，GETOORL.Collectiveentityresolution
59
，（ ）： - .（inChinese） in relational data［J］. ACM Transactions on Knowledge
2021 16 3 518 527
［ ］ MIWA M，BANSAL M. End-to-end relation extraction DiscoveryfromData， ，（ ）：- .
45 2007 1 1 5 10
using LSTMs on sequences and tree structures［C］// ［ ］ LACOSTE-JULIEN S，PALLA K，DAVIES A，et al.
60
Proceedingsofthe thAnnualMeetingoftheAssociation SiGMa：simple greedy matching for aligning large
54
forComputationalLinguistics.［S.l.］：ACL， ： - knowledge bases［C］//Proceedings of the th ACM
2016 1105 19
. SIGKDDInternationalConferenceonKnowledgeDiscovery
1116
［ ］ KATIYAR A，CARDIE C. Going out on a limb：joint and Data Mining. New York，USA：ACM Press， ：
46 2013
extraction of entity mentions and relations without - .
10 13
dependency trees［C］//Proceedings of the th Annual ［ ］ WICK M，SINGH S，MCCALLUM A. A discriminative
55 61
MeetingoftheAssociationforComputationalLinguistics. hierarchicalmodelforfastcoreferenceatlargescale［C］//
［S.l.］：ACL， ： - . Proceedingsofthe thAnnualMeetingoftheAssociation
2017 917 928 50
［ ］ ZHENG S，WANG F，BAO H，et al. Joint extraction of for Computational Linguistics.［S. l.］：ACL， ：
47 2012
entitiesandrelationsbasedonanoveltaggingschem［e EB/ - .
379 388
OL］.［ - - ］. https：//arxiv. org/pdf/ . . ［ ］ RASTOGIV，DALVIN，GAROFALAKISM.Large-scale
2021 04 05 1706 05075 62
pdf. collective entity matching［J］.Proceedings ofthe VLDB
［ ］ LIUY，LIA，HUANGJ，etal.Jointextractionofentities Endowment， ，（ ）： - .
48 2011 4 4 208 218
and relations based on multi-label classification［C］// ［ ］ SCHOENMACKERS S，DAVIS J，ETZIONI O，et al.
63
Proceedings of IEEE International Conference on Learning first-order horn clauses from Web text［C］//
2019
Data Science in Cyberspace. Washington D. C.，USA： Proceedings of Conference on Empirical Methods in
IEEEPress， ： - . Natural Language Processing. New York，USA：ACM
2019 102 113
［ ］ WEIZ，SUJ，WANGY，etal.Anovelhierarchicalbinary Press， ： - .
49 2010 1088 1098
taggingframeworkforrelationaltripleextraction［EB/OL］. ［ ］ CHENY，GOLDBERGS，WANGDZ，etal.Ontological
64
［ - - ］.https：//arxiv.org/pdf/ . v .pdf. pathfinding：mining first-order knowledge from large
2021 04 05 1909 03227 2
［ ］ WANG C，LIA，TU H，etal.An advanced BERT-based knowledgebase［s C］//Proceedingsof ACMSIGMOD
50 2016
decompositionmethodforjointextractionofentitiesand Conference on Management of Data. New York，USA：
relations［C］//Proceedings of IEEE International ACMPress， ： - .
2020 2016 835 846
ConferenceonDataScienceinCyberspace.WashingtonD.C.， ［ ］ 刘峤，韩明皓，江浏祎，等. 基于双层随机游走的关系推
65
USA：IEEEPress， ： - . 理算法［J］. 计算机学报， ，（ ）： - .
2020 145 163 2017 40 6 1275 1290
［ ］ 林海伦，王元卓，贾岩涛，等. 面向网络大数据的知识融 LIUQ，HANMH，JIANGLY，etal.Two-tierrandomwalk
51
合方法综述［J］. 计算机学报， ，（ ）：- . basedrelationalinferencealgorithm［J］.ChineseJournalof
2017 40 1 1 27
LIN H L，WANG Y Z，JIA Y T，etal.Network big data Computers， ，（ ）： - .（inChinese）
2017 40 6 1275 1290
orientedknowledgefusionmethods：asurvey［J］.Chinese ［ ］ WANG C，CHENG P. Translating representations of
66
JournalofComputers， ，（ ）：- .（inChinese） knowledgegraphswithneighbor［s C］//Proceedingsofthe
2017 40 1 1 27
［ ］ KALFOGLOUY，SCHORLEMMERM.Ontologymapping： stInternationalACMSIGIRConferenceonResearch&
52 41
thestateofthear［t J］.TheKnowledgeEngineeringReview， DevelopmentinInformationRetrieval.NewYork，USA：
，（ ）：- . ACMPress， ： - .
2003 18 1 1 31 2018 917 920
［ ］ PINTOHS，MARTINSJP.Amethodologyforontology ［ ］ SUNZQ，DENGZH，NIEJY，etal.Rotate：knowledge
53 67
integration［C］//Proceedings of the st International graphembeddingbyrelationalrotationincomplexspace
1
Conference on Knowledge Capture. Washington D. C.， ［EB/OL］［. - - ］.http：//arxiv.org/pdf/ . .
20210405 1902 10197
USA：IEEEPress， ： - . pdf.
2001 123 146
［ ］ PORTER M F. An algorithm for suffix stripping［J］. ［ ］ 彭敏，黄婷，田纲，等. 聚合邻域信息的联合知识表示模
54 68
ProgramElectronicLibraryandInformationSystems， ， 型［J］. 中文信息学报， ，（ ）： - .
1980 2021 35 5 46 54
（ ）： - . PENG M，HUANG T，TIAN G，et al. Neighborhood
14 3 130 137
［ ］ NOYNF，MUSENMA.ThePROMPTsuite：interactive aggregationforknowledgegraphrepresentation［J］.Journal
55
toolsforontologymergingandmapping［J］.International ofChineseInformationProcessing， ，（ ）： - .（in
2021 35 5 4654
Journal of Human-Computer Studies， ，（ ）： - Chinese）
2003 59 6 983
. ［ ］ 宋浩楠，赵刚，王兴芬. 融合知识表示和深度强化学习的
1024 69
［ ］ NEWCOMBEHB，KENNEDYJM，AXFORDSJ，etal. 知识推理方法［J］. 计算机工程与应用， ，（ ）：
56 2021 57 19
Automaticlinkageofvitalrecord［s J］.Science， ， - .
1959 130 189 197 第 卷 第 期 张吉祥，张祥森，武长旭，等：知识图谱构建技术综述
48 3 37
SONG H N，ZHAO G，WANG X F，et al. Knowledge Intelligence.［S.l.］：AAAIPress， ： - .
2017 1811 1818
reasoning method combining knowledge representation ［ ］ VASHISHTHS，SANYALS，NITINV，etal.InteractE：
81
with deep reinforcement learning ［J］. Computer improvingconvolution-basedknowledgegraphembeddings
EngineeringandApplications， ，（ ）： - .（in by increasing feature interactions［C］//Proceedings of
2021 57 19 189 197
Chinese） AAAIConferenceonArtificialIntelligence.［S.l.］：AAAI
［ ］ NICKELM，TRESPV，KRIEGELHP.Athree-waymodel Press， ： - .
70 2020 3009 3016
for collective learning on multi-relational data［C］// ［ ］ 李少杰，陈曙东，郝悦星，等. 基于卷积神经网络的高效
82
Proceedings of International Conference on Machine 知识表示模型［J］. 高技术通讯， ，（ ）： - .
2020 30 9 901 907
Learning. Washington D. C.，USA：IEEE Press， ： LIS J，CHEN S D，HAO Y X，etal.A novelknowledge
2011
- . representationmodelbasedonconvolutionalneuralnetwork
809 816
［ ］ CHANG K W，YIH W T，YANG B，et al. Typed tensor ［J］.ChineseHighTechnologyLetters， ，（ ）： -
71 2020 30 9 901
decompositionofknowledgebasesforrelationextraction .（inChinese）
907
［EB/OL］.［ - - ］. https：//mirror. aclweb. org/ ［ ］ CATHERINER，COHENW.Personalizedrecommendations
2021 04 05 83
emnlp /papers/pdf/EMNLP .pdf. usingknowledgegraphs：aprobabilisticlogicprogramming
2014 2014165
［ ］ 吴运兵，朱丹红，廖祥文，等. 路径张量分解的知识图谱 approach［C］//Proceedings of ACM Conference on
72
推理算法［J］. 模式识别与人工智能， ，（ ）： - . Recommender Systems. New York，USA：ACM Press，
2017 30 5 473480
WUYB，ZHUDH，LIAOXW，etal.Knowledgegraph ： - .
2016 11 22
reasoningbasedonpathsoftensorfactorization［J］.Pattern ［ ］ CAOY，XIANGW，HEX，etal.Unifyingknowledgegraph
84
RecognitionandArtificialIntelligence， ，（ ）： - learning and recommendation：towards a better
2017 30 5 473
.（inChinese） understanding of user preferences［EB/OL］.［ - -
480 2021 04
［ ］ YANGB，YIHWT，HEX，etal.Embeddingentitiesand ］.https：//arxiv.org/pdf/ . .pdf.
73 05 1902 06236
relationsforlearningandinferenceinknowledgebase［s EB/ ［ ］ ZHANG Q，CAO R，SHI F，et al. Interpreting CNN
OL］.［ - - ］. http：//scottyih. org/files/ICLR 85 knowledgeviaanexplanatorygraph［EB/OL］.［ - -
2021 04 05 201 2021 04
_updated.pdf. ］.https：//arxiv.org/pdf/ . .pdf.
5 05 1708 01785
［ ］ 刘峤，韩明皓，杨晓慧，等. 基于表示学习和语义要素感 ［ ］ HUZ，MAX，LIUZ，etal.Harnessingdeepneuralnetworks
74 86
知的关系推理算法［J］. 计算机研究与发展， ，（ ）： with logic rules［C］//Proceedings of the th Annual
- . 2017 54 8 MeetingoftheAssociationforComputational5 L4 inguistics.
1682 1692
LIU Q，HAN M H，YANG X H，et al. Representation ［S.l.］：ACL， ： - .
learning based relational inference algorithm with ［ ］ WANGH，PO2 O0 N16 H2 .4 D1 e0 ep24 p2 ro0 babilisticlogic：aunifying
semantical aspect awareness［J］. Journal of Computer 87 frameworkforindirectsupervisio［n EB/OL］［. - - ］.
ResearchandDevelopment， ，（ ）： - .（in 20210405
https：//arxiv.org/pdf/ . .pdf.
2017 54 8 1682 1692
Chinese） 1808 08485
［ ］ LIT，SRIKUMAR V.Augmenting neuralnetworkswith
［ 75］ ZHANGS，TAYY，YAOLN，etal.Quaternionknowledge 88 first-order logic［C］//Proceedings of the th Annual
graphembedding［s C］//Proceedingsofthe rdConference 57
33 MeetingoftheAssociationforComputationalLinguistics.
on Neural Information Processing Systems. New York， ［S.l.］：ACL， ： - .
USA：ACMPress， ： - . 2019 102 113
2019 2731 2741 ［ ］ WANGW，PANSJ.Integratingdeeplearningwithlogic
［ ］ SOCHERR，CHEND，MANNINGCD，etal.Reasoning 89
76 fusionforinformationextraction［EB/OL］.［ - - ］.
withneuraltensornetworksforknowledgebasecompletion 2021 04 05
https：//arxiv.org/pdf/ . v .pdf.
［C］//Proceedingsofthe thInternationalConferenceon 1912 03041 1
26 ［ ］ PEARL J. Theoretical impediments to machine learning
Neural Information Processing. New York，USA：ACM 90
with seven sparks from the causal revolution［C］//
Press， ： - .
2013 926 930 Proceedingsofthe thACMInternationalConferenceonWeb
［ ］ DASR，NEELAKANTANA，BELANGERD，etal.Chains 7
77 SearchandDataMining.NewYork，USA：ACMPress， ：
ofreasoningoverentities，relations，andtextusingrecurrent 2018
- .
neuralnetwork［s C］//Proceedingsofthe thConference 3 9
15 ［ ］ BATTAGLIA P W，HAMRICK J B，BAPST V，et al.
of the European Chapter of the Association for 91
Relational inductive biases，deep learning，and graph
ComputationalLinguistics.［S.l.］：ACL， ： - .
2017 105 110 network［s EB/OL］.［ - - ］.https：//arxiv.org/pdf/
［ ］ GUO L B，ZHANG Q H，GE W Y，etal.DSKG：a deep 2021 04 05
78 . .pdf.
sequential model for knowledge graph completion［C］// 1806 01261
［ ］ 康雁，李涛，李浩，等. 融合知识图谱与协同过滤的推荐
Proceedings of China Conference on Knowledge 92
2018 模型［J］. 计算机工程， ，（ ）： - ， .
Graph and Semantic Computing. Berlin，Germany： 2020 46 12 73 79 87
KANGY，LIT，LIH，etal.Recommendationmodelfusing
Springer， ： - .
2018 65 77 with knowledge graph and collaborative filtering［J］.
［ ］ CHENWR，HONGDP，ZHENGC.Learningknowledge
79 Computer Engineering， ， （ ）： - ， .（in
graphembeddingwithentitydescriptionsbasedonLSTM 2020 46 12 73 79 87
Chinese）
networks［C］//Proceedings of IEEE International
2020 ［ ］ PAREJAA，DOMENICONIG，CHENJ，etal.EvolveGCN：
Symposium on Product Compliance Engineering-Asia. 93
evolvinggraphconvolutionalnetworksfordynamicgraphs
WashingtonD.C.，USA：IEEEPress， ：- .
2020 1 7 ［EB/OL］.［ - - ］.https：//arxiv.org/pdf/ . .
［ ］ DETTMERS T，MINERVINI P，STENETORP P，et al. 20210405 1902 10191
80 pdf.
Convolutional D knowledge graph embeddings［C］//
2 编辑 吴云芳
Proceedings of the nd AAAI Conference on Artificial
32 --------------------------------------------------------------------------------- 情报科学
第第3344卷卷第第22期期22001166年年22月月
· ·
DOI:10.13833/j.cnki.is.2016.02.025
网上信息特征对于消费者延迟选择的影响研究
李 亮1，黄 赞2
（ 山西财经大学工商管理学院，山西太原 ； 上海财经大学国际工商管理学院，上海 ）
1. 030006 2. 200433
摘 要：互联网已经发展成为一个重要的外部信息来源，消费者在网上购物选择时不仅面临信息的不对称，而且也
会感受到信息的过载。然而，对于这两个不完全信息的构面如何影响消费者的选择却知之甚少。为此，根据先前
的相关研究，本文设计出网上信息特征对于消费者延迟选择影响的理论模型。实证结果表明，除了较高的信息不
对称感知并未导致相应程度的感知风险，其他路径均显著并符合各研究假定。同时，感知风险和感知价值在信息
过载对于延迟选择的影响中起到了部分中介的作用，涉入度在信息过载对于感知风险和感知价值的影响中起到了
较为显著的正向调节作用。最后依照研究结果为管理实务提出对策建议。
关键词：互联网；信息不对称；信息过载；延迟选择
中图分类号：F713.36 文献标识码： 文章编号： （ ）
A 1007-7634 2016 02-120-07
ResearchontheInfluenceofCharacteristicofOnlineInformationontheChoice
DeferralofConsumer
LILiang1,HUANGZan2
( SchoolofBusinessAdministration,ShanxiUniversityofFinance&Economics,Taiyuan ,China; Schoolof
1. 030006 2.
InternationalBusinessAdministration,ShanghaiUniversityofFinance&Economics,Shanghai ,China)
200433
Abstract：
The Internet has become an important external information source, when consumers go shopping online and
make choices, they not only face information asymmetry, but also could feel information overload. However, there is little
knownabouthowtwofacetsoftheincompleteinformationinfluencethechoiceofconsumer.Therefore,accordingtothepre⁃
viousrelevantstudy,thepaperdesignsthetheoreticalmodelabouttheinfluenceofcharacteristicofonlineinformationon
thechoicedeferralofconsumer.Theempiricalresultsshowthattheotherpathsareallsignificantandmeettheresearchhy⁃
’
potheses except the higher perception of information asymmetry can t result in the corresponding perceived risk. Mean⁃
while,perceivedriskandperceivedvalueplaythepartialintermediaryroleoftheinfluenceoftheinformationoverloadon
thechoicedeferral,andtheinvolvementplaysamoresignificantpositiveadjustmentoftheinfluenceofinformationover⁃
loadontheperceivedriskandperceivedvalue.Finally,severalimplicationsareputforward.
Keywords： ； ； ；
internet informationasymmetry informationoverload choicedeferral
对称性增加了，处于信息劣势地位的消费者因而面临了更多
1 引 言 的机会主义威胁和交易的不确定，并缺少对于交易的控制，
这些都使消费者在网络购物方式下感受到比传统购物方式
世纪 年代以来，网上购物的迅速发展引起企业界 更高的风险。并且，由于买卖双方之间的信息不对称而产生
20 90
和理论界的广泛关注。网络购物带来便捷的同时，与互联网 的在线消费者的不确定和风险的感知会减少他们的购买行
虚拟环境伴生的风险却阻碍着购物行为的发展。究其原因， 为【 1】。所以，对于如电子商务这种间接的交流方式，衡量由
由于电子商务交易的虚拟性、时空扩展性和电子化，许多传 于信息不对称而导致的风险，就显得尤为重要【 2】。
统商务方式中的交互活动无法展开，交易双方之间的信息不 同时，网上的商店数量众多，而且提供了无比丰富的产
收稿日期：2014-12-25
基金项目：2015年山西财经大学青年科研基金项目（QN-2015001）
作者简介：李 亮（1980—），男，山西阳泉人,管理学博士，教师，主要从事消费者行为、电子商务研究.
- 120 - 情报科学
第第3344卷卷第第22期期22001166年年22月月
· ·
品以及详细的产品信息，使顾客能够方便地进行比较和选 认为，选择过载能可靠的发生是依赖于一些特别的调节变
择。但根据美国 年在线购物的相关报告，几乎有 量，研究者们应该继续探索这些调节变量【 】。 检验了
11
2008 80% Vieira
的消费者认为，互联网能买到其他渠道难以买到的商品，同 过多选项效应的假设，分析了如果有太多选项去选择时，对
时也有 的消费者认为，当他们搜索产品信息时，他们会 于消费者决策过程实际上是好还是坏。他提到了未来研究
60%
感到挫折、困惑和被信息所淹没【】。因为，在电子商务环境 应该分析过多选择理论的调节变量【 】。 对于不同
3 12
Malhotra
下消费者的信息处理能力有限，在网络购物过程中又不得不 学者关于消费者决策制定中的信息过载研究作出回应。他
面对网络上的大量产品和信息。在网上购买产品时，消费者 提出一些未来研究方向，在个体差异方面例如涉入度的不
会主观的体会到信息过载的状态，即超出处理能力的大量信 同【 】。因此，本文需要确定相应的调节变量，而涉入度可以
13
息对消费者行为的影响，即信息丰富环境的不利一面是信息 进一步去检测。
过载的可能性【】。因此，在互联网时代，理解信息丰富的环 叶乃沂认为，虽然在消费者行为研究领域有一些关注购
4
境是怎样影响消费者决策是非常重要的。 物选择困难、拖延决策、放弃选择等，但在消费者上网购物行
将消费者购物决策视为信息处理的一个过程， 为方面，对消费者消极购物行为重视还不够，特别是对消费
Bettman
在不同购物情景下，消费者的决策依据是不同的，他会根据 者消极购物行为的影响机理关注不够【】。先前的研究显示，
10
需要而构建自己的决策依据【】。互联网已经发展成一个重 当消费者有较多选项去选择时，他们会感到压迫，太多选择
5
要的外部信息来源，消费者在进行网络购物前会在网上搜寻 或许会引起困惑，会降低他们对于自己选项的自信，他（或
产品和企业的相关信息已经成为他们一个主要的信息搜寻 她）可能认为最好去延迟选择或者根本不选择。
Scheibe⁃
活动。因此，当消费者同时面临上述信息不对称与信息过载 等认为，为了更好的了解过多选择效应和选择过载的
henne
两种不同的信息状态时，研究对其购物决策会产生怎样的影 发生，未来的研究需要更加明确不做选择作为因变量的定
响，一方面可以丰富消费者行为领域的相关研究，另一方面 义，以及把延迟和未来选择包括进来【】。因此，综合以上考
11
可为网上商家和网站经营者提供相应的建议和对策。 虑，本文把延迟选择作为落脚点，来考察网上信息特征对于
消费者行为意愿的影响。
2 文献回顾与假设提出 基于上述分析，本文把网上信息特征，即关于在线商家
生成内容方面分为信息不对称和信息过载，而感知风险和感
知价值作为中介变量影响消费者行为，同时涉入度在信息过
22..11 文文献献回回顾顾
载对感知风险和感知价值的影响中起调节作用。根据本文
以往从信息的角度对于消费者行为的研究大多基于信 的研究实际，把延迟选择作为消费者的行为愿意。基于上述
息搜索的方面。然而，人们已经很久的认识到，绝大多数的 思路，本文的理论模型如图 所示。
1
购买决策是基于不完全信息作出的，但是研究者们对于不完
全信息对于消费者选择的影响却知之甚少【】。本文则是以
6
信息系统中常引用关于不完全信息的两个构面——信息不
对称与信息过载为研究的出发点【】，从信息方面这一新的视
7
角来研究网上信息特征对于消费者行为意愿的影响。
先前的相关研究大多都是将信息不对称或信息过载与
消费者行为意愿直接建立联系，针对两者关系间中介变量 图1 网上信息特征对于消费者延迟选择影响理论模型
的研究却非常少见。 和 研究了服装购买情境
Stanton Paolo 22..22 假假设设提提出出
下信息过载的本质和影响，以及相关的应对策略。他们认
为，对信息的反应是行为决策的前因，更多研究需要了解消 等将信息不对称界定为消费者对于销售方拥有
Mishra
费者采用他们应对策略时的路径【 8】。 等研究了在线产 更多数量或者质量关于其商品、人格和销售行为信息的感
Park
品陈列对于消费者情绪、感知风险和购买意愿的影响。研 知【】。相关研究也发现，市场上的信息不对称是导致消费者
14
究结果显示营销刺激可以唤起情绪，而感知风险在情绪与 产生不确定感与感知风险的主要因素之一。
Grabner-Kraeu⁃
购买意愿之间起到了中介作用【 9】。叶乃沂对消费者感知风 研究了在线购物中顾客信任的作用。他认为由于电子商
ter
险及上网购物行为进行研究。在今后的研究方向上，他提 务不同于传统的商务形式，因为买卖双方之间的信息不对
到在消费者上网购物行为理论框架方面，还可以增加一些 称，在线内容使得交易具有风险和不确定性【】。
15
研究变量，例如价值判断方面的变量，使模型能够提供更多 等发现，过量信息和缺乏信息都会影响个人对于
Afzal
的解释和预测信息【 10】。以上分析意味着需要发现一些相关 选项的价值判断。不对称的信息创造了一个内容环境，其
的中介变量，而感知价值和感知风险值得在本文中进一步去 中购买者会发现只有较少的线索能被用于评价一个产品，
探索。 结果是低估了该产品的价值。他们的研究结论是，对称信
等对选择过载进行了元分析研究。他们 息的条件下，对于一个产品的判断会接近其真实的产品价
Scheibehenne
- 121 - INFORMATION SCIENCE
ProfessionResearch
· ·
Vol.34,No.2 February,2016
值，而不对称的信息会低估这个产品的价值【】。 等指 品以及整个过程中，主观上认定发生各种损失风险的一种预
16
Lee
出，在线市场中的机会主义行为是能够被预测的。买卖双方 测和推断【】。 等实证研究发现，在一个零售的环境
26
Sweeney
之间的信息不对称创造了点燃一个柠檬市场的可能性。当 中，感知风险对于感知价值有一个直接、负向的影响作用，并
欺诈风险升高时，购买者会低估选项的价值来减少潜在的交 且中介于产品质量和感知价值的关系中【】。感知风险对于
27
易风险【】。基于上述分析，本文提出研究假设： 感知价值的反向作用已被众多学者的研究所证实。
17
：信息不对称的感知程度会正向影响在线购买消费 研究指出，在消费者的购买决策过程中，感知风
H1a Mitchell
者对于选购商品的感知风险。 险贯穿于各个阶段，影响着消费者的购买决策行为。当感知
：信息不对称的感知程度会负向影响在线购买消费 风险超出消费者个体所能承受的风险范围时，消费者就会推
H1b
者对于选购商品的感知价值。 迟或者放弃消费行为，反之，则实施购买行为【】。 等认
28
Cho
目前，信息过载还没有一个被广泛接受的单独定义。本 为，有 类因素引起购物犹豫或者拖延：感知不确定、新的购
4
文将信息过载界定为：消费者在选购商品时，不仅感受到有 物渠道、因特网和顾客的个人因素。其中，最主要的原因就
过多的商品选项，而且还有其他关于商品方面的信息，这些 是感知不确定或感知风险 。基于上述分析，本文提出研究
[29]
综合使得消费者难以去处理的感知。 等在研究在线消 假设：
Park
费者评论中信息过载和其产生的结果时认为，消费者是经常 ：消费者的感知风险会负向影响其的感知价值。
H4a
面临大量信息的。如果他们试图去处理“太多的”信息时，他 ：消费者的感知风险会正向影响延迟选择的发生。
H4b
们有限的处理能力会变的认知过载【】。 和 发 范秀成和罗海成将感知价值界定为消费者对于企业提
18
Garbarino Edell
现，一项任务需要更多的认知努力去评价的话，会导致更多 供的产品或者服务所具有价值的主观认知【】。 提
30
Anderson
的负面情绪【】。相关研究也证实了，负面情绪反应通常会使 出了决策回避行为前因后果的理性 情绪模型，总结了影响
19
-
人们高估负向结果的可能性。 等指出，不断增加的信 延迟选择行为的认知因素和情绪因素。其中，认知因素方面
Walsh
息量或许最终会增加消费者的感知风险，同时延迟购买的决 包括了选项的相对吸引力水平会对延迟选择产生影响【】。
31
策【】。 杨宜苗在研究中证实，消费者感知价值的损失对于负向购买
20
和 研究证实，选项数量与消费者怎样估价 意愿有着显著的正向影响【】。基于上述分析，本文提出研究
32
Keller Staelin
每个选项之间存在一个负向关系，并且随着选项数量的增 假设：
加，最终会导致较低的决策效力【】。 等发现，不断增 ：消费者的感知价值会负向影响延迟选择的发生。
21
Beattie H5
加产品的数量将会减少产品的吸引力，消费者甚至希望其他 本文参考曾志宏的定义及结合研究目的，将延迟选择
人来帮助他们做出决策【】。 等指出，当个人面对众多 界定为当消费者在作购买决策时，因为不仅面临到有过多
22
Reed
的选项需要做出决策时，搜索成本的精力耗费通常会使选择 的商品选项，而且还有其他关于商品方面的信息，这些综合
结果面临贬值【】。基于上述分析，本文提出研究假设： 使得消费者难以去处理，进而促使消费者采取延迟购买的
23
：信息过载的感知程度会正向影响在线购买消费者 可能【 】。过去的研究指出，过载会导致延迟制定决策。
33
H2a
对于选购商品的感知风险。 研究发现，消费者决策时的备选集的构成会引起不做
Dhar
：信息过载的感知程度会负向影响在线购买消费者 选择的行为；消费者偏好的不确定对其不做选择的行为有
H2b
对于选购商品的感知价值。 中间影响作用；购买活动中可供选择的对象太多也会引起
将涉入度界定为消费者认知该产品与其内 决策拖延【】。基于上述分析，本文提出研究假设：
34
Zaichkowsky
在需要、兴趣和价值观的攸关程度【 】。 等研究发现，在 ：信息过载的感知程度会正向影响延迟选择的发生。
24
Park H6
高涉入度的情况下，消费者通常具有处理所有可得信息的 综合以上相关分析和假设，进一步提出假设：
倾向。结果是，大量的评论对于高度涉入的消费者造成了 ：感知风险和感知价值在信息过载对延迟选择的影
H7
一个沉重负担，所以他们或许采用浏览／扫描策略来获取 响中起到中介作用。
信息集中的大概观点。经过这样的信息处理，他们会担心
所忽略的一些细节信息，这增加了他们的不确定感和降低 3 研究设计
了他们的信心【 】。 和 研究指出，消费者的涉入度
18
Celsi Olson
水平影响了理解过程的内容和聚焦，而凭此过程消费者处
33..11 数数据据收收集集
理关于产品属性和结果的信息，从而形成产品的评价以及
做出品牌的选择【 25】。基于上述分析，本文提出研究假设： 本文的调研对象选择为在淘宝网有过购买服装经历的
：涉入度对于消费者的信息过载感知与感知风险的 消费者，将问卷设立于专门的问卷调查网站（问卷星），受访
H3a
关系具有调节作用。 者直接打开网页就可以进行填答，最终共有 个被试作
313
：涉入度对于消费者的信息过载感知与感知价值的 答。根据调查问卷中隐含的逻辑关系对问卷的有效性进行
H3b
关系具有调节作用。 辨识，对其中明显不认真填写的视为无效问卷，共清理出
13
和 将感知风险界定为消费者在网上购买产 份。
Forsythe Shi
- 122 - 情报科学
第第3344卷卷第第22期期22001166年年22月月
· ·
有效样本中，男性占 ，女性占 ； 岁的 拟合指标数值良好。所有测项标准化因子载荷均大于 ，
32.3% 67.7% 20-29 0.5
占 ， 岁的占 ；本科及以上学历者占 ； 且 值达到了显著水平。因子的组合信度（ ）分别为
47.0% 30-39 46.7% 88.7% t CR
事业单位／公务员占 ，国企职员占 ，民营企业职 和 ，均高于 的标准。感知价值和感知风险
20.0% 25.0% 0.7447 0.8384 0.6
员占 ；月均收入 元的占 ， 的平均方差抽取量（ ）分别为 和 ，均接近于
47.3% 3000-5000 41.7% 5000-10000 AVE 0.4946 0.4642
元的占 。在购买行为方面，过去一年中网购服装花费 的标准，此测量模型的收敛效度尚可。二者 的平方
40.7% 0.5 AVE
元的占 ， 元的占 ， 元以上 根均大于其的相关系数，该测量模型具有区分效度。
100-500 15.7% 500-1000 23.3% 1000
的占 ；购买 件服装的占 ，购买 件的占 表2 感知价值与感知风险验证性因子分析拟合度指标表
60.3% 2-5 24.3% 5-10
，购买 件以上的占 。
44.7% 10 30.0% 模型名称 χ2 χ2/df
df GFI AGFI NFI CFI RMRRMSEA
33..22 问问卷卷与与测测量量 评价标准越小越好
- <3 >0.9 >0.8 >0.9 >0.9 <0.05 <0.08
实际值
为确保测量工具的信度及效度，本文尽量引用他人文献 70.697 26 2.719 0.9500.9140.9180.9460.052 0.076
修正值
中已经发展成熟的量表，并根据本文研究内容进行适当修 57.628 25 2.305 0.9600.9290.9330.9610.048 0.066
改。信息不对称量表借鉴 等的研究【】；信息过载量表 （）涉入度与延迟选择的测量模型。从表 看出，各拟
Pavlou 35 3 3
借鉴 和 的研究【】；感知风险量表借鉴 合指标数值良好。所有测项标准化因子载荷均大于 ，且
Diehl Poynor 36 Jarvenpaa 0.5 t
和 的研究【】；感知价值量表借鉴 和 的研 值达到了显著水平。因子的组合信度（ ）分别为 和
Todd 37 Sweeney Soutar CR 0.7506
究【】；涉入度的量表借鉴 的研究 ；延迟选择量 ，均高于 的标准。涉入度的平均方差抽取量
38 Zaichkowsky [24] 0.8042 0.6
表借鉴 等的研究【 】。对各测量题项进行回译、征求 （ ）为 其均接近于 的标准，而延迟选择的平均
Walsh 20,39 AVE 0.4346 0.5
专家意见和小规模访谈，确定了初步的测量题项，进行问卷 方差抽取量为 ，此测量模型的收敛效度尚可。二者
0.5104
的前测（前测样本为 个被试），根据前测结果对问卷进行 的平方根均大于其的相关系数，该测量模型具有区分
77 AVE
修正，最终形成本研究的正式问卷。 效度。
对测量指标数据通过探索性因子分析提取出 个因子， 表3 涉入度与延迟选择验证性因子分析拟合度指标表
6
所有指标都在对应的因子上，且载荷较大，均大于 ，并且
0.5 模型名称 χ2 χ2/df
df GFI AGFI NFI CFI RMRRMSEA
交叉变量的因子载荷都没有超过 ，表明测量问项具有较
0.5 评价标准越小越好—
好的收敛效度和区分效度。然后，对 个因子进行信度分 <3 >0.9 >0.8 >0.9 >0.9 <0.05 <0.08
6 实际值
析，计算 ’ 系数。其中，信息不对称和信息过 23.139 19 1.218 0.9810.9630.9650.9930.037 0.027
Cronbach salpha
载的 ’ 系数在 以上，其他变量的
Cronbach s alpha 0.6 Cron⁃ 44..22 假假设设检检验验
系数均大于 。
bach'salpha 0.7
本部分将分别进行理论模型分析（未考虑涉入度）、感知
4 数据分析与假设检验 风险和感知价值的中介作用分析以及涉入度的调节作用分
析。
（）理论模型分析。本模型包括 个变量，分别是信息
44..11 验验证证性性因因子子分分析析 1 5
不对称、信息过载、感知风险、感知价值和延迟选择，涉及测
测量模型的评估可以逐个部分进行匹配验证。因此，本 量项目总共有 个。运用 软件，对整个模型进行
19 AMOS7.0
部分将模型中的变量分为 个部分进行分析，分别是信息不 结构方程估计，参照修正指标进行修正后，结果如图 所示。
3 2
对称与信息过载、感知价值与感知风险、涉入度与延迟选择。
（）信息不对称与信息过载的测量模型。从表 看出，
1 1
各拟合指标数值良好。所有测项标准化因子载荷均大于
，且 值达到显著水平。因子的组合信度（ ）都在 以
0.5 t CR 0.7
上，高于 的标准【】。信息不对称的平均方差抽取量
40
0.6
（ ）为 ，接近于 的标准【】，而信息过载的平均方
41
AVE 0.4474 0.5
差抽取量为 ，此测量模型的收敛效度尚可。二者
0.4083 AVE
的平方根均大于其的相关系数，该测量模型具有区分效度。 图2 修正的结构方程模型图
表1 信息不对称与信息过载验证性因子分析拟合度指标表 结构方程模型的各路径系数及其显著性检验，结果如表
模型名称 χ2
df
χ2/df
GFI AGFI NFI CFI RMRRMSEA
4所示。可以看出，大部分假设得到验证，只有 H1a（信息不
对称的感知程度会显著影响在线购买消费者对于选购商品
评价标准越小越好
- <3 >0.9 >0.8 >0.9 >0.9 <0.05 <0.08 的感知风险）没有被支持。
实际值
10.968 8 1.371 0.9880.9690.9640.9900.048 0.035 （）中介作用分析。对于中介作用的检验，本研究采用
2
（）感知价值与感知风险的测量模型。从表 看出，各 嵌套模型的比较方法。比较的两个模型是原模型和对比模
2 2
- 123 - INFORMATION SCIENCE
ProfessionResearch
· ·
Vol.34,No.2 February,2016
型（在原模型的基础上去掉信息过载到延迟选择的连线），结 径在高、低涉入度样本下呈现较大差异。
果如表 所示。可以看出，比较模型比初始模型更为精简 再次，对不同涉入度的模型进行恒定性检验，以此进一
5
（自由度多出 ），但拟合度却显著恶化（△χ2 步分析在高、低涉入度样本间是否具有显著性差异【 40】。由于
1 =13.866|
△df=1lp<0.05）。根据精简原则接受初始模型，即信息过 本研究只需检验涉入度对原假设路径的影响，故只对模型进
载对延迟选择有直接影响，感知风险和感知价值在信息过载 行形态相同检验和因子负荷等同检验，结果如表 所示。可
7
对延迟选择的影响中起到了部分中介的作用，即假设 成 以看出，各项指标均得到了较好拟合，说明本研究所采用的
H7
立。 模型在高、低涉入度的样本中具有普适性；其次，进行因子负
表4 模型各路径回归系数检验表
荷等同检验，由于 χ2在 ＜ 的水平上具有统计显著性，
p 0.001
这表明因子负荷等同检验不能通过，即在不同涉入度下，模
路径系数 显著性
S.E. C.R. P 型路径系数出现了显著变化。故进一步探究是哪些路径发
感知风险 信息不对称 不显著
¬ .087 .067 1.298 .193 生了显著变化，先检验信息过载到感知风险的路径系数，设
感知风险 信息过载 显著
¬ .629 .103 6.107 *** 定该系数在恒定性检验中保持不变，其他路径系数暂定为自
感知价值 信息不对称 － － 显著
¬ .234 .079 2.962 .005 由估计，由于 χ2 ，在 ＜ 的水平上具有统计显
感知价值 信息过载 － － 显著 =443.354 p 0.05
¬ .082 .037 2.216 .034
著性，表明模型没能通过恒定性检验，从而说明涉入度对该
感知价值 感知风险 － － 显著
¬ .394 .116 3.397 ***
延迟选择 感知风险 显著 路径的调节作用通过了检验。同理，涉入度对于信息过载到
¬ .249 .110 2.264 .024
延迟选择 感知价值 － － 显著 感知价值的调节作用也通过了检验（χ2 ），即
¬ .174 .077 2.259 .023 =444.255|P|0.05
延迟选择 信息过载 显著 假设 和 成立。
¬ .397 .118 3.364 *** H3a H3b
表5 模型的对比分析结果表
5 结论与启示
模型名称 χ2 χ2 Δχ2 Δdf 值
df p( ) GFI CFI RMSEA P
初始模型
250.580143 0.000 0.9160.937 0.050
比较模型 55..11 研研究究结结论论
264.446144 0.000 0.9120.929 0.053 13.866 1 <0.05
（）调节作用分析。为了探求涉入度对信息过载与感知 在理论模型分析中，大部分假设得到验证，只有 没
3 H1a
风险和感知价值关系的调节作用，本研究采用多组分析法来 有通过。究其原因，在测量指标的描述性统计中可以看到，
进行检验【 42-44】。 本研究中消费者的信息不对称感知程度是普遍较高的，但感
首先，通过 的两步聚类法将整个样本数据依 知风险却普遍不高。在与消费者的小规模访谈中了解到，一
SPSS15.0
照涉入度进行归类，样本自动归为两类，高涉入度样本数为 是消费者对网上购买已较为熟悉，二是对于淘宝网存在的风
，低涉入度样本数为 。其次，对两个样本分别作结构 险也有充分的认识。因此，较高的信息不对称感知并未导致
100 200
方程分析，比较拟合优度指标，结果如表 所示。可以看出， 相应程度的感知风险。
6
在高涉入度和低涉入度的样本中，信息过载到感知风险和信 本研究通过中介作用的分析，发现信息过载不但对延迟
息过载到感知价值的路径均显著，这和总体样本情况保持一 选择有着显著的直接影响，而且也通过感知风险和感知价值
致，但信息过载到感知风险和信息过载到感知价值这两条路 对延迟选择有着显著的间接影响，这充分说明感知风险和感
表6 涉入度对路径关系的调节作用表
总样本模型 高涉入度样本模型 低涉入度样本模型
路径关系
标准化路径系数 标准化路径系数 标准化路径系数
t t t
感知风险 信息过载
¬ .629 6.627*** .715 6.220*** .433 2.648**
感知价值 信息过载 － － － － － －
¬ .082 2.206* .198 2.266* .079 2.261*
χ2=250.580 χ2=282.04 χ2=270.778
,df=143 ,df=143 ,df=143
模型拟合优度 GFI=0.916,AGFI=0.888 GFI=0.900,AGFI=0.868 GFI=0.915,AGFI=0.854
NFI=0.915,CFI=0.937 NFI=0.901,CFI=0.936 NFI=0.911,CFI=0.925
RMR=0.042,RMSEA=0.050 RMR=0.047,RMSEA=0.059 RMR=0.048,RMSEA=0.070
表7 模型的恒定性检验表
模型拟合优度
原假设
χ2 χ2
NFI CFI GFI RMSEA df
模型形态检验 V
438.236 0.925 0.910 0.932 0.042 286
因子负荷等同检验 ***
475.900 0.933 0.901 0.917 0.044 300 37.664
感知风险 信息过载 *
¬ 443.354 0.924 0.909 0.931 0.042 287 5.118
感知价值 信息过载 *
¬ 444.255 0.922 0.907 0.929 0.043 287 6.019
- 124 - 情报科学
第第3344卷卷第第22期期22001166年年22月月
· ·
知价值在信息过载对延迟选择的影响中起到了部分中介的 vironments[A].InWindJ&MahajanV(eds),DigitalMarket⁃
作用。因此，这个结果探索并验证了相关研究。 ing[C].NewYork:JohnWiley&Sons，2001：163-200.
本研究通过调节作用的分析，发现涉入度对研究模型起 5 BettmanJR,LuceMF,PayneJW.ConstructiveConsumer
到了较为显著的正向调节作用，这说明涉入度高的消费者在 Choice Processes[J]. Journal of consumer research, 1998, 25
感受到信息过载时，相比涉入度低的消费者，会有更高的感 (3):187-217.
知风险和更大的感知价值损失。因此，这个结果探索并验证 6 Kivetz R, Simonson I. The Effects of Incomplete Informa⁃
了相关研究。 tion on Consumer Choice[J]. Journal of Marketing Re⁃
search,2000,37(4):427-448.
55..22 管管理理启启示示
7 GroverV,LimJ,AyyagariR.TheDarkSideofInformation
and Market Efficiency in E‐Markets*[J].Decision Sciences,
本研究证实，虽然较高的信息不对称感知并未导致相应
2006,37(3):297-324.
程度的感知风险，但是其仍会通过负向影响网购消费者的感
8 Stanton J V, Paolo D M. Information Overload in the Con⁃
知价值，最终导致延迟选择的发生。然而，一方面随着技术
text of Apparel: Effects on Confidence, Shopper Orientation
的不断进步，消费者可以更加直观了解所购商品与交易商家
andLeadership[J].JournalofFashionMarketingandManage⁃
的各种具体信息；另一方面，商家也应明白，主动让消费者了
ment,2012,16(4):454-476.
解自身的各种信息，有利于商家长远发展；再者，网站经营者
9 ParkJ,LennonSJ,StoelL.On‐LineProductPresentation:
要采取各种手段来减少买卖双方之间信息不对称现象，这也
Effects on Mood, Perceived Risk, and Purchase Intention[J].
有助于网站自身的健康发展。例如，淘宝网于 年 月
2010 3 Psychology&Marketing,2005,22(9):695-719.
日正式宣布，将面向全球首度开放淘宝数据。这就意味
31 10 叶乃沂.消费者感知风险及上网购物行为研究[D].成都：
着商家、企业以及消费者将可获得到来自淘宝全网的海量原
西南交通大学，2008.
始数据。因此，对于普通消费者而言，淘宝开放数据将会有
11 ScheibehenneB,GreifenederR,ToddPM.CanThereEv⁃
效解决目前我国网络购物中其与卖家就产品质量方面的信
er Be Too Many Options? A Meta‐Analytic Review of
息不对称问题【】。
45
Choice Overload[J].Journal of Consumer Research, 2010,
本研究显示，信息过载不但对延迟选择有着显著的直接
37(3):409-425.
影响，而且也会通过感知风险和感知价值对延迟选择有着显
12 Vieira V A. When More is Less and Less is More: The
著的间接影响，其带来的负面影响，最终导致消费者延迟做
Over Choice Hypothesis[J]. Available at SSRN 1864632,
出购买选择。因此，既要减轻信息过载的影响，又要最大化
2011.
利益，网站经营者在设计面向消费者的网络购物环境时，需
13 Malhotra N K. Reflections on the Information Overload
要把握一个更好的平衡【 】。例如，网站设计者可以根据每
46-47
Paradigm in Consumer Decision Making[J].The Journal of
一个访问者的需要和偏好来设计网站内容，而这种个性化的
ConsumerResearch,1984,10(4):436-440.
服务可以去掉不需要的产品和信息，减少剔除无关信息耗费
14 Mishra D P, Heide J B, Cort S G. Information Asymmetry
的精力，提高搜寻的准确性、交易的便利性和速度【】。又如，
48 and Levels of Agency Relationships[J].Journal of marketing
基于消费者的个人偏好，通过提供产品推荐系统，当消费者
Research,1998,(35):277-295.
在网上搜索和挑选产品时，这个系统可以支持和提高消费者
15 Grabner-Kraeuter S. The Role of Consumers' Trust in
制定的决策质量。同时，也可减轻消费者面临的信息过载和
Online-Shopping[J].Journal of Business Ethics, 2002, 39
在线搜索的复杂性【】。
49 (1-2):43-50.
16 AfzalW,RolandD,Al-SquriMN.InformationAsymme⁃
参考文献
try and Product Valuation: An Exploratory Study[J].Journal
1 Yang S J, Park J K, Park J. Consumers’Channel Choice for ofInformationScience,2009,35(2):192-203.
University-Licensed Products: Exploring Factors of Con⁃ 17 LeeB,ChoH,ChaeM,etal.EmpiricalAnalysisofOnline
sumer Acceptance with Social Identification[J]. Journal of Auction Fraud: Credit Card Phantom Transactions[J].Ex⁃
RetailingandConsumerServices,2007,14(3):165-174. pertSystemswithApplications,2010,37(4):2991-2999.
2 Christozov, D., Chukova, S., Mateev, P. A Measure of Risk 18 ParkDH,LeeJ,HanI.InformationOverloadanditsCon⁃
Caused by Information Asymmetry in E-Commerce[J].Is⁃ sequencesintheContextofOnlineConsumerReviews[C].
suesinInformingScienceandInformationTechnology,2006, PACIS,2006:28.
(3):147-158. 19 Garbarino E C, Edell J A. Cognitive Effort, Affect, and
3 Horrigan, J.B. Online Shopping[R].Washington, DC: Pew Choice[J].Journal of Consumer Research, 1997, 24(2):
InternetLife&AmericanProjectReport,2008. 147-158.
4 Dholakia U, Bagozzi R. Consumer Behavior in Digital En⁃ 20 Walsh G, Hennig-Thurau T, Mitchell V W. Consumer
- 125 - INFORMATION SCIENCE
ProfessionResearch
· ·
Vol.34,No.2 February,2016
Confusion Proneness: Scale Development, Validation, and 36 Diehl K, Poynor C. Great Expectations?! Assortment Size,
Application[J].Journal of Marketing Management, 2007, 23 Expectations, and Satisfaction[J].Journal of Marketing Re⁃
(7-8):697-721. search,2010,47(2):312-322.
21 KellerKL,StaelinR.EffectsofQualityandQuantityofIn⁃ 37 JarvenpaaSL,ToddPA.ConsumerReactionstoElectron⁃
formation on Decision Effectiveness[J].Journal of Consumer icShoppingontheWorldWideWeb[J].InternationalJour⁃
Research,1987,(14):200-213. nalofElectronicCommerce,1996,1(2):59-88.
22 Beattie J, Baron J, Hershey J C, et al. Psychological Deter⁃ 38 SweeneyJC,SoutarGN.ConsumerPerceivedValue:The
minants of Decision Attitude[J].Journal of Behavioral Deci⁃ DevelopmentofaMultipleItemScale[J].Journalofretailing,
sionMaking,1994,7(2):129-144. 2001,77(2):203-220.
23 ReedDD,DiGennaroReedFD,ChokJ,etal.The“Tyr⁃ 39 Nagpal A, Khare A, Chowdhury T, et al. The Impact of
annyofChoice”:ChoiceOverloadasaPossibleInstanceof the Amount of Available Information on Decision Delay:
EffortDiscounting[J].ThePsychologicalRecord,2011,61(4): The Role of Common Features[J].Marketing Letters, 2011,
3. 22(4):405-421.
24 Zaichkowsky J L. Measuring the Involvement Construct[J]. 40 黄芳铭.结构方程模型—理论与应用[M].北京：中国税务
Journalofconsumerresearch,1985,12(3):341-352. 出版社，2005：270.
25 Celsi R L, Olson J C. The Role of Involvement in Atten⁃ 41 Bagozzi R P, Yi Y. On the Evaluation of Structural Equa⁃
tion and Comprehension Processes[J].Journal of consumer tionModels[J].Journaloftheacademyofmarketingscience,
research,1988,15(2):210-224. 1988,16(1):74-94.
26 Forsythe S M, Shi B. Consumer Patronage and Risk Per⁃ 42 Keil M, Tan B C Y, Wei K K, et al. A Cross-Cultural
ceptions in Internet Shopping[J].Journal of Business Re⁃ Study on Escalation of Commitment Behavior in Software
search,2003,56(11):867-875. Projects[J].MisQuarterly,2000,24(2):299-325.
27 SweeneyJC,SoutarGN,JohnsonLW.TheRoleofPer⁃ 43 PalmatierRW,ScheerLK,SteenkampJBEM.Custom⁃
ceivedRiskin the Quality-ValueRelationship:AStudyin er Loyalty to Whom? Managing the Benefits and Risks of
a Retail Environment[J].Journal of retailing, 1999, 75(1): Salesperson-Owned Loyalty[J].Journal of marketing re⁃
77-105. search,2007,44(2):185-199.
28 Mitchell V W, Papavassiliou V. Marketing Causes and Im⁃ 44 San Martín S, Camarero C. How Perceived Risk Affects
plications of Consumer Confusion[J].Journal of Product & Online Buying[J].Online Information Review, 2009, 33(4):
BrandManagement,1999,8(4):319-342. 629-654.
29 ChoCH,KangJ,CheonHJ.OnlineShoppingHesitation 45 张 樊.淘宝开放数据解决生产企业信息不对称困惑
[J].CyberPsychology&Behavior,2006,9(3):261-274. [EB/OL].http://www.bianews.com/news/84/n-189684.
30 范秀成，罗海成.基于顾客感知价值的服务企业竞争力探 htm,2015-09-01.
讨[J].南开管理评论，2003，（6）：41-45. 46 LeeBK,LeeWN.TheEffectofInformationOverloadon
31 Anderson C J. The Psychology of Doing Nothing: Forms ConsumerChoiceQualityinanOn‐LineEnvironment[J].
ofDecisionAvoidanceResultfromReasonandEmotion[J]. Psychology&Marketing,2004,21(3):159-183.
Psychologicalbulletin,2003,129(1):139. 47 Ghose A. The Economic Impact of User-Generated and
32 杨宜苗.错过价格促销情境下消费者感知价值损失及其 Firm-Published Online Content: Directions for Advancing
对负向购买意愿的影响[J].商业经济与管理，2010，（2）： theFrontiersinElectronicCommerceResearch[A].InJank
52-60. W & Shmueli G (eds), Statistical Methods in ECommerce
33 曾志宏.时间压力、商店气氛和知觉差异对消费者延迟购 Research[C].NewYork:JohnWiley&Sons,2008.
买行为之研究[D].台湾：台湾私立中原大学，2007. 48 Chakraborty G, Lala V, Warren D. What Do Customers
34 DharR.ConsumerPreferenceforaNo-ChoiceOption[J]. Consider Important in B2B Websites?[J].Journal of Adver⁃
JournalofConsumerResearch,1997,24(2):215-231. tisingResearch,2003,43(1):50-61.
35 Pavlou P A, Liang H, Xue Y. Understanding and Mitigat⁃ 49 Xiao B, Benbasat I. E-commerce Product Recommenda⁃
ingUncertaintyinOnlineExchangeRelationships:APrin⁃ tion Agents: Use, Characteristics, and Impact[J].Mis Quar⁃
cipal-Agent Perspective[J].MIS quarterly,2007, 31(1): terly,2007,31(1):137-209.
105-136. （责任编辑：徐 波）
- 126 - --------------------------------------------------------------------------------- 情报科学
第第3344卷卷第第22期期22001166年年22月月
· ·
DOI:10.13833/j.cnki.is.2016.02.025
网上信息特征对于消费者延迟选择的影响研究
李 亮1，黄 赞2
（ 山西财经大学工商管理学院，山西太原 ； 上海财经大学国际工商管理学院，上海 ）
1. 030006 2. 200433
摘 要：互联网已经发展成为一个重要的外部信息来源，消费者在网上购物选择时不仅面临信息的不对称，而且也
会感受到信息的过载。然而，对于这两个不完全信息的构面如何影响消费者的选择却知之甚少。为此，根据先前
的相关研究，本文设计出网上信息特征对于消费者延迟选择影响的理论模型。实证结果表明，除了较高的信息不
对称感知并未导致相应程度的感知风险，其他路径均显著并符合各研究假定。同时，感知风险和感知价值在信息
过载对于延迟选择的影响中起到了部分中介的作用，涉入度在信息过载对于感知风险和感知价值的影响中起到了
较为显著的正向调节作用。最后依照研究结果为管理实务提出对策建议。
关键词：互联网；信息不对称；信息过载；延迟选择
中图分类号：F713.36 文献标识码： 文章编号： （ ）
A 1007-7634 2016 02-120-07
ResearchontheInfluenceofCharacteristicofOnlineInformationontheChoice
DeferralofConsumer
LILiang1,HUANGZan2
( SchoolofBusinessAdministration,ShanxiUniversityofFinance&Economics,Taiyuan ,China; Schoolof
1. 030006 2.
InternationalBusinessAdministration,ShanghaiUniversityofFinance&Economics,Shanghai ,China)
200433
Abstract：
The Internet has become an important external information source, when consumers go shopping online and
make choices, they not only face information asymmetry, but also could feel information overload. However, there is little
knownabouthowtwofacetsoftheincompleteinformationinfluencethechoiceofconsumer.Therefore,accordingtothepre⁃
viousrelevantstudy,thepaperdesignsthetheoreticalmodelabouttheinfluenceofcharacteristicofonlineinformationon
thechoicedeferralofconsumer.Theempiricalresultsshowthattheotherpathsareallsignificantandmeettheresearchhy⁃
’
potheses except the higher perception of information asymmetry can t result in the corresponding perceived risk. Mean⁃
while,perceivedriskandperceivedvalueplaythepartialintermediaryroleoftheinfluenceoftheinformationoverloadon
thechoicedeferral,andtheinvolvementplaysamoresignificantpositiveadjustmentoftheinfluenceofinformationover⁃
loadontheperceivedriskandperceivedvalue.Finally,severalimplicationsareputforward.
Keywords： ； ； ；
internet informationasymmetry informationoverload choicedeferral
对称性增加了，处于信息劣势地位的消费者因而面临了更多
1 引 言 的机会主义威胁和交易的不确定，并缺少对于交易的控制，
这些都使消费者在网络购物方式下感受到比传统购物方式
世纪 年代以来，网上购物的迅速发展引起企业界 更高的风险。并且，由于买卖双方之间的信息不对称而产生
20 90
和理论界的广泛关注。网络购物带来便捷的同时，与互联网 的在线消费者的不确定和风险的感知会减少他们的购买行
虚拟环境伴生的风险却阻碍着购物行为的发展。究其原因， 为【 1】。所以，对于如电子商务这种间接的交流方式，衡量由
由于电子商务交易的虚拟性、时空扩展性和电子化，许多传 于信息不对称而导致的风险，就显得尤为重要【 2】。
统商务方式中的交互活动无法展开，交易双方之间的信息不 同时，网上的商店数量众多，而且提供了无比丰富的产
收稿日期：2014-12-25
基金项目：2015年山西财经大学青年科研基金项目（QN-2015001）
作者简介：李 亮（1980—），男，山西阳泉人,管理学博士，教师，主要从事消费者行为、电子商务研究.
- 120 - 情报科学
第第3344卷卷第第22期期22001166年年22月月
· ·
品以及详细的产品信息，使顾客能够方便地进行比较和选 认为，选择过载能可靠的发生是依赖于一些特别的调节变
择。但根据美国 年在线购物的相关报告，几乎有 量，研究者们应该继续探索这些调节变量【 】。 检验了
11
2008 80% Vieira
的消费者认为，互联网能买到其他渠道难以买到的商品，同 过多选项效应的假设，分析了如果有太多选项去选择时，对
时也有 的消费者认为，当他们搜索产品信息时，他们会 于消费者决策过程实际上是好还是坏。他提到了未来研究
60%
感到挫折、困惑和被信息所淹没【】。因为，在电子商务环境 应该分析过多选择理论的调节变量【 】。 对于不同
3 12
Malhotra
下消费者的信息处理能力有限，在网络购物过程中又不得不 学者关于消费者决策制定中的信息过载研究作出回应。他
面对网络上的大量产品和信息。在网上购买产品时，消费者 提出一些未来研究方向，在个体差异方面例如涉入度的不
会主观的体会到信息过载的状态，即超出处理能力的大量信 同【 】。因此，本文需要确定相应的调节变量，而涉入度可以
13
息对消费者行为的影响，即信息丰富环境的不利一面是信息 进一步去检测。
过载的可能性【】。因此，在互联网时代，理解信息丰富的环 叶乃沂认为，虽然在消费者行为研究领域有一些关注购
4
境是怎样影响消费者决策是非常重要的。 物选择困难、拖延决策、放弃选择等，但在消费者上网购物行
将消费者购物决策视为信息处理的一个过程， 为方面，对消费者消极购物行为重视还不够，特别是对消费
Bettman
在不同购物情景下，消费者的决策依据是不同的，他会根据 者消极购物行为的影响机理关注不够【】。先前的研究显示，
10
需要而构建自己的决策依据【】。互联网已经发展成一个重 当消费者有较多选项去选择时，他们会感到压迫，太多选择
5
要的外部信息来源，消费者在进行网络购物前会在网上搜寻 或许会引起困惑，会降低他们对于自己选项的自信，他（或
产品和企业的相关信息已经成为他们一个主要的信息搜寻 她）可能认为最好去延迟选择或者根本不选择。
Scheibe⁃
活动。因此，当消费者同时面临上述信息不对称与信息过载 等认为，为了更好的了解过多选择效应和选择过载的
henne
两种不同的信息状态时，研究对其购物决策会产生怎样的影 发生，未来的研究需要更加明确不做选择作为因变量的定
响，一方面可以丰富消费者行为领域的相关研究，另一方面 义，以及把延迟和未来选择包括进来【】。因此，综合以上考
11
可为网上商家和网站经营者提供相应的建议和对策。 虑，本文把延迟选择作为落脚点，来考察网上信息特征对于
消费者行为意愿的影响。
2 文献回顾与假设提出 基于上述分析，本文把网上信息特征，即关于在线商家
生成内容方面分为信息不对称和信息过载，而感知风险和感
知价值作为中介变量影响消费者行为，同时涉入度在信息过
22..11 文文献献回回顾顾
载对感知风险和感知价值的影响中起调节作用。根据本文
以往从信息的角度对于消费者行为的研究大多基于信 的研究实际，把延迟选择作为消费者的行为愿意。基于上述
息搜索的方面。然而，人们已经很久的认识到，绝大多数的 思路，本文的理论模型如图 所示。
1
购买决策是基于不完全信息作出的，但是研究者们对于不完
全信息对于消费者选择的影响却知之甚少【】。本文则是以
6
信息系统中常引用关于不完全信息的两个构面——信息不
对称与信息过载为研究的出发点【】，从信息方面这一新的视
7
角来研究网上信息特征对于消费者行为意愿的影响。
先前的相关研究大多都是将信息不对称或信息过载与
消费者行为意愿直接建立联系，针对两者关系间中介变量 图1 网上信息特征对于消费者延迟选择影响理论模型
的研究却非常少见。 和 研究了服装购买情境
Stanton Paolo 22..22 假假设设提提出出
下信息过载的本质和影响，以及相关的应对策略。他们认
为，对信息的反应是行为决策的前因，更多研究需要了解消 等将信息不对称界定为消费者对于销售方拥有
Mishra
费者采用他们应对策略时的路径【 8】。 等研究了在线产 更多数量或者质量关于其商品、人格和销售行为信息的感
Park
品陈列对于消费者情绪、感知风险和购买意愿的影响。研 知【】。相关研究也发现，市场上的信息不对称是导致消费者
14
究结果显示营销刺激可以唤起情绪，而感知风险在情绪与 产生不确定感与感知风险的主要因素之一。
Grabner-Kraeu⁃
购买意愿之间起到了中介作用【 9】。叶乃沂对消费者感知风 研究了在线购物中顾客信任的作用。他认为由于电子商
ter
险及上网购物行为进行研究。在今后的研究方向上，他提 务不同于传统的商务形式，因为买卖双方之间的信息不对
到在消费者上网购物行为理论框架方面，还可以增加一些 称，在线内容使得交易具有风险和不确定性【】。
15
研究变量，例如价值判断方面的变量，使模型能够提供更多 等发现，过量信息和缺乏信息都会影响个人对于
Afzal
的解释和预测信息【 10】。以上分析意味着需要发现一些相关 选项的价值判断。不对称的信息创造了一个内容环境，其
的中介变量，而感知价值和感知风险值得在本文中进一步去 中购买者会发现只有较少的线索能被用于评价一个产品，
探索。 结果是低估了该产品的价值。他们的研究结论是，对称信
等对选择过载进行了元分析研究。他们 息的条件下，对于一个产品的判断会接近其真实的产品价
Scheibehenne
- 121 - INFORMATION SCIENCE
ProfessionResearch
· ·
Vol.34,No.2 February,2016
值，而不对称的信息会低估这个产品的价值【】。 等指 品以及整个过程中，主观上认定发生各种损失风险的一种预
16
Lee
出，在线市场中的机会主义行为是能够被预测的。买卖双方 测和推断【】。 等实证研究发现，在一个零售的环境
26
Sweeney
之间的信息不对称创造了点燃一个柠檬市场的可能性。当 中，感知风险对于感知价值有一个直接、负向的影响作用，并
欺诈风险升高时，购买者会低估选项的价值来减少潜在的交 且中介于产品质量和感知价值的关系中【】。感知风险对于
27
易风险【】。基于上述分析，本文提出研究假设： 感知价值的反向作用已被众多学者的研究所证实。
17
：信息不对称的感知程度会正向影响在线购买消费 研究指出，在消费者的购买决策过程中，感知风
H1a Mitchell
者对于选购商品的感知风险。 险贯穿于各个阶段，影响着消费者的购买决策行为。当感知
：信息不对称的感知程度会负向影响在线购买消费 风险超出消费者个体所能承受的风险范围时，消费者就会推
H1b
者对于选购商品的感知价值。 迟或者放弃消费行为，反之，则实施购买行为【】。 等认
28
Cho
目前，信息过载还没有一个被广泛接受的单独定义。本 为，有 类因素引起购物犹豫或者拖延：感知不确定、新的购
4
文将信息过载界定为：消费者在选购商品时，不仅感受到有 物渠道、因特网和顾客的个人因素。其中，最主要的原因就
过多的商品选项，而且还有其他关于商品方面的信息，这些 是感知不确定或感知风险 。基于上述分析，本文提出研究
[29]
综合使得消费者难以去处理的感知。 等在研究在线消 假设：
Park
费者评论中信息过载和其产生的结果时认为，消费者是经常 ：消费者的感知风险会负向影响其的感知价值。
H4a
面临大量信息的。如果他们试图去处理“太多的”信息时，他 ：消费者的感知风险会正向影响延迟选择的发生。
H4b
们有限的处理能力会变的认知过载【】。 和 发 范秀成和罗海成将感知价值界定为消费者对于企业提
18
Garbarino Edell
现，一项任务需要更多的认知努力去评价的话，会导致更多 供的产品或者服务所具有价值的主观认知【】。 提
30
Anderson
的负面情绪【】。相关研究也证实了，负面情绪反应通常会使 出了决策回避行为前因后果的理性 情绪模型，总结了影响
19
-
人们高估负向结果的可能性。 等指出，不断增加的信 延迟选择行为的认知因素和情绪因素。其中，认知因素方面
Walsh
息量或许最终会增加消费者的感知风险，同时延迟购买的决 包括了选项的相对吸引力水平会对延迟选择产生影响【】。
31
策【】。 杨宜苗在研究中证实，消费者感知价值的损失对于负向购买
20
和 研究证实，选项数量与消费者怎样估价 意愿有着显著的正向影响【】。基于上述分析，本文提出研究
32
Keller Staelin
每个选项之间存在一个负向关系，并且随着选项数量的增 假设：
加，最终会导致较低的决策效力【】。 等发现，不断增 ：消费者的感知价值会负向影响延迟选择的发生。
21
Beattie H5
加产品的数量将会减少产品的吸引力，消费者甚至希望其他 本文参考曾志宏的定义及结合研究目的，将延迟选择
人来帮助他们做出决策【】。 等指出，当个人面对众多 界定为当消费者在作购买决策时，因为不仅面临到有过多
22
Reed
的选项需要做出决策时，搜索成本的精力耗费通常会使选择 的商品选项，而且还有其他关于商品方面的信息，这些综合
结果面临贬值【】。基于上述分析，本文提出研究假设： 使得消费者难以去处理，进而促使消费者采取延迟购买的
23
：信息过载的感知程度会正向影响在线购买消费者 可能【 】。过去的研究指出，过载会导致延迟制定决策。
33
H2a
对于选购商品的感知风险。 研究发现，消费者决策时的备选集的构成会引起不做
Dhar
：信息过载的感知程度会负向影响在线购买消费者 选择的行为；消费者偏好的不确定对其不做选择的行为有
H2b
对于选购商品的感知价值。 中间影响作用；购买活动中可供选择的对象太多也会引起
将涉入度界定为消费者认知该产品与其内 决策拖延【】。基于上述分析，本文提出研究假设：
34
Zaichkowsky
在需要、兴趣和价值观的攸关程度【 】。 等研究发现，在 ：信息过载的感知程度会正向影响延迟选择的发生。
24
Park H6
高涉入度的情况下，消费者通常具有处理所有可得信息的 综合以上相关分析和假设，进一步提出假设：
倾向。结果是，大量的评论对于高度涉入的消费者造成了 ：感知风险和感知价值在信息过载对延迟选择的影
H7
一个沉重负担，所以他们或许采用浏览／扫描策略来获取 响中起到中介作用。
信息集中的大概观点。经过这样的信息处理，他们会担心
所忽略的一些细节信息，这增加了他们的不确定感和降低 3 研究设计
了他们的信心【 】。 和 研究指出，消费者的涉入度
18
Celsi Olson
水平影响了理解过程的内容和聚焦，而凭此过程消费者处
33..11 数数据据收收集集
理关于产品属性和结果的信息，从而形成产品的评价以及
做出品牌的选择【 25】。基于上述分析，本文提出研究假设： 本文的调研对象选择为在淘宝网有过购买服装经历的
：涉入度对于消费者的信息过载感知与感知风险的 消费者，将问卷设立于专门的问卷调查网站（问卷星），受访
H3a
关系具有调节作用。 者直接打开网页就可以进行填答，最终共有 个被试作
313
：涉入度对于消费者的信息过载感知与感知价值的 答。根据调查问卷中隐含的逻辑关系对问卷的有效性进行
H3b
关系具有调节作用。 辨识，对其中明显不认真填写的视为无效问卷，共清理出
13
和 将感知风险界定为消费者在网上购买产 份。
Forsythe Shi
- 122 - 情报科学
第第3344卷卷第第22期期22001166年年22月月
· ·
有效样本中，男性占 ，女性占 ； 岁的 拟合指标数值良好。所有测项标准化因子载荷均大于 ，
32.3% 67.7% 20-29 0.5
占 ， 岁的占 ；本科及以上学历者占 ； 且 值达到了显著水平。因子的组合信度（ ）分别为
47.0% 30-39 46.7% 88.7% t CR
事业单位／公务员占 ，国企职员占 ，民营企业职 和 ，均高于 的标准。感知价值和感知风险
20.0% 25.0% 0.7447 0.8384 0.6
员占 ；月均收入 元的占 ， 的平均方差抽取量（ ）分别为 和 ，均接近于
47.3% 3000-5000 41.7% 5000-10000 AVE 0.4946 0.4642
元的占 。在购买行为方面，过去一年中网购服装花费 的标准，此测量模型的收敛效度尚可。二者 的平方
40.7% 0.5 AVE
元的占 ， 元的占 ， 元以上 根均大于其的相关系数，该测量模型具有区分效度。
100-500 15.7% 500-1000 23.3% 1000
的占 ；购买 件服装的占 ，购买 件的占 表2 感知价值与感知风险验证性因子分析拟合度指标表
60.3% 2-5 24.3% 5-10
，购买 件以上的占 。
44.7% 10 30.0% 模型名称 χ2 χ2/df
df GFI AGFI NFI CFI RMRRMSEA
33..22 问问卷卷与与测测量量 评价标准越小越好
- <3 >0.9 >0.8 >0.9 >0.9 <0.05 <0.08
实际值
为确保测量工具的信度及效度，本文尽量引用他人文献 70.697 26 2.719 0.9500.9140.9180.9460.052 0.076
修正值
中已经发展成熟的量表，并根据本文研究内容进行适当修 57.628 25 2.305 0.9600.9290.9330.9610.048 0.066
改。信息不对称量表借鉴 等的研究【】；信息过载量表 （）涉入度与延迟选择的测量模型。从表 看出，各拟
Pavlou 35 3 3
借鉴 和 的研究【】；感知风险量表借鉴 合指标数值良好。所有测项标准化因子载荷均大于 ，且
Diehl Poynor 36 Jarvenpaa 0.5 t
和 的研究【】；感知价值量表借鉴 和 的研 值达到了显著水平。因子的组合信度（ ）分别为 和
Todd 37 Sweeney Soutar CR 0.7506
究【】；涉入度的量表借鉴 的研究 ；延迟选择量 ，均高于 的标准。涉入度的平均方差抽取量
38 Zaichkowsky [24] 0.8042 0.6
表借鉴 等的研究【 】。对各测量题项进行回译、征求 （ ）为 其均接近于 的标准，而延迟选择的平均
Walsh 20,39 AVE 0.4346 0.5
专家意见和小规模访谈，确定了初步的测量题项，进行问卷 方差抽取量为 ，此测量模型的收敛效度尚可。二者
0.5104
的前测（前测样本为 个被试），根据前测结果对问卷进行 的平方根均大于其的相关系数，该测量模型具有区分
77 AVE
修正，最终形成本研究的正式问卷。 效度。
对测量指标数据通过探索性因子分析提取出 个因子， 表3 涉入度与延迟选择验证性因子分析拟合度指标表
6
所有指标都在对应的因子上，且载荷较大，均大于 ，并且
0.5 模型名称 χ2 χ2/df
df GFI AGFI NFI CFI RMRRMSEA
交叉变量的因子载荷都没有超过 ，表明测量问项具有较
0.5 评价标准越小越好—
好的收敛效度和区分效度。然后，对 个因子进行信度分 <3 >0.9 >0.8 >0.9 >0.9 <0.05 <0.08
6 实际值
析，计算 ’ 系数。其中，信息不对称和信息过 23.139 19 1.218 0.9810.9630.9650.9930.037 0.027
Cronbach salpha
载的 ’ 系数在 以上，其他变量的
Cronbach s alpha 0.6 Cron⁃ 44..22 假假设设检检验验
系数均大于 。
bach'salpha 0.7
本部分将分别进行理论模型分析（未考虑涉入度）、感知
4 数据分析与假设检验 风险和感知价值的中介作用分析以及涉入度的调节作用分
析。
（）理论模型分析。本模型包括 个变量，分别是信息
44..11 验验证证性性因因子子分分析析 1 5
不对称、信息过载、感知风险、感知价值和延迟选择，涉及测
测量模型的评估可以逐个部分进行匹配验证。因此，本 量项目总共有 个。运用 软件，对整个模型进行
19 AMOS7.0
部分将模型中的变量分为 个部分进行分析，分别是信息不 结构方程估计，参照修正指标进行修正后，结果如图 所示。
3 2
对称与信息过载、感知价值与感知风险、涉入度与延迟选择。
（）信息不对称与信息过载的测量模型。从表 看出，
1 1
各拟合指标数值良好。所有测项标准化因子载荷均大于
，且 值达到显著水平。因子的组合信度（ ）都在 以
0.5 t CR 0.7
上，高于 的标准【】。信息不对称的平均方差抽取量
40
0.6
（ ）为 ，接近于 的标准【】，而信息过载的平均方
41
AVE 0.4474 0.5
差抽取量为 ，此测量模型的收敛效度尚可。二者
0.4083 AVE
的平方根均大于其的相关系数，该测量模型具有区分效度。 图2 修正的结构方程模型图
表1 信息不对称与信息过载验证性因子分析拟合度指标表 结构方程模型的各路径系数及其显著性检验，结果如表
模型名称 χ2
df
χ2/df
GFI AGFI NFI CFI RMRRMSEA
4所示。可以看出，大部分假设得到验证，只有 H1a（信息不
对称的感知程度会显著影响在线购买消费者对于选购商品
评价标准越小越好
- <3 >0.9 >0.8 >0.9 >0.9 <0.05 <0.08 的感知风险）没有被支持。
实际值
10.968 8 1.371 0.9880.9690.9640.9900.048 0.035 （）中介作用分析。对于中介作用的检验，本研究采用
2
（）感知价值与感知风险的测量模型。从表 看出，各 嵌套模型的比较方法。比较的两个模型是原模型和对比模
2 2
- 123 - INFORMATION SCIENCE
ProfessionResearch
· ·
Vol.34,No.2 February,2016
型（在原模型的基础上去掉信息过载到延迟选择的连线），结 径在高、低涉入度样本下呈现较大差异。
果如表 所示。可以看出，比较模型比初始模型更为精简 再次，对不同涉入度的模型进行恒定性检验，以此进一
5
（自由度多出 ），但拟合度却显著恶化（△χ2 步分析在高、低涉入度样本间是否具有显著性差异【 40】。由于
1 =13.866|
△df=1lp<0.05）。根据精简原则接受初始模型，即信息过 本研究只需检验涉入度对原假设路径的影响，故只对模型进
载对延迟选择有直接影响，感知风险和感知价值在信息过载 行形态相同检验和因子负荷等同检验，结果如表 所示。可
7
对延迟选择的影响中起到了部分中介的作用，即假设 成 以看出，各项指标均得到了较好拟合，说明本研究所采用的
H7
立。 模型在高、低涉入度的样本中具有普适性；其次，进行因子负
表4 模型各路径回归系数检验表
荷等同检验，由于 χ2在 ＜ 的水平上具有统计显著性，
p 0.001
这表明因子负荷等同检验不能通过，即在不同涉入度下，模
路径系数 显著性
S.E. C.R. P 型路径系数出现了显著变化。故进一步探究是哪些路径发
感知风险 信息不对称 不显著
¬ .087 .067 1.298 .193 生了显著变化，先检验信息过载到感知风险的路径系数，设
感知风险 信息过载 显著
¬ .629 .103 6.107 *** 定该系数在恒定性检验中保持不变，其他路径系数暂定为自
感知价值 信息不对称 － － 显著
¬ .234 .079 2.962 .005 由估计，由于 χ2 ，在 ＜ 的水平上具有统计显
感知价值 信息过载 － － 显著 =443.354 p 0.05
¬ .082 .037 2.216 .034
著性，表明模型没能通过恒定性检验，从而说明涉入度对该
感知价值 感知风险 － － 显著
¬ .394 .116 3.397 ***
延迟选择 感知风险 显著 路径的调节作用通过了检验。同理，涉入度对于信息过载到
¬ .249 .110 2.264 .024
延迟选择 感知价值 － － 显著 感知价值的调节作用也通过了检验（χ2 ），即
¬ .174 .077 2.259 .023 =444.255|P|0.05
延迟选择 信息过载 显著 假设 和 成立。
¬ .397 .118 3.364 *** H3a H3b
表5 模型的对比分析结果表
5 结论与启示
模型名称 χ2 χ2 Δχ2 Δdf 值
df p( ) GFI CFI RMSEA P
初始模型
250.580143 0.000 0.9160.937 0.050
比较模型 55..11 研研究究结结论论
264.446144 0.000 0.9120.929 0.053 13.866 1 <0.05
（）调节作用分析。为了探求涉入度对信息过载与感知 在理论模型分析中，大部分假设得到验证，只有 没
3 H1a
风险和感知价值关系的调节作用，本研究采用多组分析法来 有通过。究其原因，在测量指标的描述性统计中可以看到，
进行检验【 42-44】。 本研究中消费者的信息不对称感知程度是普遍较高的，但感
首先，通过 的两步聚类法将整个样本数据依 知风险却普遍不高。在与消费者的小规模访谈中了解到，一
SPSS15.0
照涉入度进行归类，样本自动归为两类，高涉入度样本数为 是消费者对网上购买已较为熟悉，二是对于淘宝网存在的风
，低涉入度样本数为 。其次，对两个样本分别作结构 险也有充分的认识。因此，较高的信息不对称感知并未导致
100 200
方程分析，比较拟合优度指标，结果如表 所示。可以看出， 相应程度的感知风险。
6
在高涉入度和低涉入度的样本中，信息过载到感知风险和信 本研究通过中介作用的分析，发现信息过载不但对延迟
息过载到感知价值的路径均显著，这和总体样本情况保持一 选择有着显著的直接影响，而且也通过感知风险和感知价值
致，但信息过载到感知风险和信息过载到感知价值这两条路 对延迟选择有着显著的间接影响，这充分说明感知风险和感
表6 涉入度对路径关系的调节作用表
总样本模型 高涉入度样本模型 低涉入度样本模型
路径关系
标准化路径系数 标准化路径系数 标准化路径系数
t t t
感知风险 信息过载
¬ .629 6.627*** .715 6.220*** .433 2.648**
感知价值 信息过载 － － － － － －
¬ .082 2.206* .198 2.266* .079 2.261*
χ2=250.580 χ2=282.04 χ2=270.778
,df=143 ,df=143 ,df=143
模型拟合优度 GFI=0.916,AGFI=0.888 GFI=0.900,AGFI=0.868 GFI=0.915,AGFI=0.854
NFI=0.915,CFI=0.937 NFI=0.901,CFI=0.936 NFI=0.911,CFI=0.925
RMR=0.042,RMSEA=0.050 RMR=0.047,RMSEA=0.059 RMR=0.048,RMSEA=0.070
表7 模型的恒定性检验表
模型拟合优度
原假设
χ2 χ2
NFI CFI GFI RMSEA df
模型形态检验 V
438.236 0.925 0.910 0.932 0.042 286
因子负荷等同检验 ***
475.900 0.933 0.901 0.917 0.044 300 37.664
感知风险 信息过载 *
¬ 443.354 0.924 0.909 0.931 0.042 287 5.118
感知价值 信息过载 *
¬ 444.255 0.922 0.907 0.929 0.043 287 6.019
- 124 - 情报科学
第第3344卷卷第第22期期22001166年年22月月
· ·
知价值在信息过载对延迟选择的影响中起到了部分中介的 vironments[A].InWindJ&MahajanV(eds),DigitalMarket⁃
作用。因此，这个结果探索并验证了相关研究。 ing[C].NewYork:JohnWiley&Sons，2001：163-200.
本研究通过调节作用的分析，发现涉入度对研究模型起 5 BettmanJR,LuceMF,PayneJW.ConstructiveConsumer
到了较为显著的正向调节作用，这说明涉入度高的消费者在 Choice Processes[J]. Journal of consumer research, 1998, 25
感受到信息过载时，相比涉入度低的消费者，会有更高的感 (3):187-217.
知风险和更大的感知价值损失。因此，这个结果探索并验证 6 Kivetz R, Simonson I. The Effects of Incomplete Informa⁃
了相关研究。 tion on Consumer Choice[J]. Journal of Marketing Re⁃
search,2000,37(4):427-448.
55..22 管管理理启启示示
7 GroverV,LimJ,AyyagariR.TheDarkSideofInformation
and Market Efficiency in E‐Markets*[J].Decision Sciences,
本研究证实，虽然较高的信息不对称感知并未导致相应
2006,37(3):297-324.
程度的感知风险，但是其仍会通过负向影响网购消费者的感
8 Stanton J V, Paolo D M. Information Overload in the Con⁃
知价值，最终导致延迟选择的发生。然而，一方面随着技术
text of Apparel: Effects on Confidence, Shopper Orientation
的不断进步，消费者可以更加直观了解所购商品与交易商家
andLeadership[J].JournalofFashionMarketingandManage⁃
的各种具体信息；另一方面，商家也应明白，主动让消费者了
ment,2012,16(4):454-476.
解自身的各种信息，有利于商家长远发展；再者，网站经营者
9 ParkJ,LennonSJ,StoelL.On‐LineProductPresentation:
要采取各种手段来减少买卖双方之间信息不对称现象，这也
Effects on Mood, Perceived Risk, and Purchase Intention[J].
有助于网站自身的健康发展。例如，淘宝网于 年 月
2010 3 Psychology&Marketing,2005,22(9):695-719.
日正式宣布，将面向全球首度开放淘宝数据。这就意味
31 10 叶乃沂.消费者感知风险及上网购物行为研究[D].成都：
着商家、企业以及消费者将可获得到来自淘宝全网的海量原
西南交通大学，2008.
始数据。因此，对于普通消费者而言，淘宝开放数据将会有
11 ScheibehenneB,GreifenederR,ToddPM.CanThereEv⁃
效解决目前我国网络购物中其与卖家就产品质量方面的信
er Be Too Many Options? A Meta‐Analytic Review of
息不对称问题【】。
45
Choice Overload[J].Journal of Consumer Research, 2010,
本研究显示，信息过载不但对延迟选择有着显著的直接
37(3):409-425.
影响，而且也会通过感知风险和感知价值对延迟选择有着显
12 Vieira V A. When More is Less and Less is More: The
著的间接影响，其带来的负面影响，最终导致消费者延迟做
Over Choice Hypothesis[J]. Available at SSRN 1864632,
出购买选择。因此，既要减轻信息过载的影响，又要最大化
2011.
利益，网站经营者在设计面向消费者的网络购物环境时，需
13 Malhotra N K. Reflections on the Information Overload
要把握一个更好的平衡【 】。例如，网站设计者可以根据每
46-47
Paradigm in Consumer Decision Making[J].The Journal of
一个访问者的需要和偏好来设计网站内容，而这种个性化的
ConsumerResearch,1984,10(4):436-440.
服务可以去掉不需要的产品和信息，减少剔除无关信息耗费
14 Mishra D P, Heide J B, Cort S G. Information Asymmetry
的精力，提高搜寻的准确性、交易的便利性和速度【】。又如，
48 and Levels of Agency Relationships[J].Journal of marketing
基于消费者的个人偏好，通过提供产品推荐系统，当消费者
Research,1998,(35):277-295.
在网上搜索和挑选产品时，这个系统可以支持和提高消费者
15 Grabner-Kraeuter S. The Role of Consumers' Trust in
制定的决策质量。同时，也可减轻消费者面临的信息过载和
Online-Shopping[J].Journal of Business Ethics, 2002, 39
在线搜索的复杂性【】。
49 (1-2):43-50.
16 AfzalW,RolandD,Al-SquriMN.InformationAsymme⁃
参考文献
try and Product Valuation: An Exploratory Study[J].Journal
1 Yang S J, Park J K, Park J. Consumers’Channel Choice for ofInformationScience,2009,35(2):192-203.
University-Licensed Products: Exploring Factors of Con⁃ 17 LeeB,ChoH,ChaeM,etal.EmpiricalAnalysisofOnline
sumer Acceptance with Social Identification[J]. Journal of Auction Fraud: Credit Card Phantom Transactions[J].Ex⁃
RetailingandConsumerServices,2007,14(3):165-174. pertSystemswithApplications,2010,37(4):2991-2999.
2 Christozov, D., Chukova, S., Mateev, P. A Measure of Risk 18 ParkDH,LeeJ,HanI.InformationOverloadanditsCon⁃
Caused by Information Asymmetry in E-Commerce[J].Is⁃ sequencesintheContextofOnlineConsumerReviews[C].
suesinInformingScienceandInformationTechnology,2006, PACIS,2006:28.
(3):147-158. 19 Garbarino E C, Edell J A. Cognitive Effort, Affect, and
3 Horrigan, J.B. Online Shopping[R].Washington, DC: Pew Choice[J].Journal of Consumer Research, 1997, 24(2):
InternetLife&AmericanProjectReport,2008. 147-158.
4 Dholakia U, Bagozzi R. Consumer Behavior in Digital En⁃ 20 Walsh G, Hennig-Thurau T, Mitchell V W. Consumer
- 125 - INFORMATION SCIENCE
ProfessionResearch
· ·
Vol.34,No.2 February,2016
Confusion Proneness: Scale Development, Validation, and 36 Diehl K, Poynor C. Great Expectations?! Assortment Size,
Application[J].Journal of Marketing Management, 2007, 23 Expectations, and Satisfaction[J].Journal of Marketing Re⁃
(7-8):697-721. search,2010,47(2):312-322.
21 KellerKL,StaelinR.EffectsofQualityandQuantityofIn⁃ 37 JarvenpaaSL,ToddPA.ConsumerReactionstoElectron⁃
formation on Decision Effectiveness[J].Journal of Consumer icShoppingontheWorldWideWeb[J].InternationalJour⁃
Research,1987,(14):200-213. nalofElectronicCommerce,1996,1(2):59-88.
22 Beattie J, Baron J, Hershey J C, et al. Psychological Deter⁃ 38 SweeneyJC,SoutarGN.ConsumerPerceivedValue:The
minants of Decision Attitude[J].Journal of Behavioral Deci⁃ DevelopmentofaMultipleItemScale[J].Journalofretailing,
sionMaking,1994,7(2):129-144. 2001,77(2):203-220.
23 ReedDD,DiGennaroReedFD,ChokJ,etal.The“Tyr⁃ 39 Nagpal A, Khare A, Chowdhury T, et al. The Impact of
annyofChoice”:ChoiceOverloadasaPossibleInstanceof the Amount of Available Information on Decision Delay:
EffortDiscounting[J].ThePsychologicalRecord,2011,61(4): The Role of Common Features[J].Marketing Letters, 2011,
3. 22(4):405-421.
24 Zaichkowsky J L. Measuring the Involvement Construct[J]. 40 黄芳铭.结构方程模型—理论与应用[M].北京：中国税务
Journalofconsumerresearch,1985,12(3):341-352. 出版社，2005：270.
25 Celsi R L, Olson J C. The Role of Involvement in Atten⁃ 41 Bagozzi R P, Yi Y. On the Evaluation of Structural Equa⁃
tion and Comprehension Processes[J].Journal of consumer tionModels[J].Journaloftheacademyofmarketingscience,
research,1988,15(2):210-224. 1988,16(1):74-94.
26 Forsythe S M, Shi B. Consumer Patronage and Risk Per⁃ 42 Keil M, Tan B C Y, Wei K K, et al. A Cross-Cultural
ceptions in Internet Shopping[J].Journal of Business Re⁃ Study on Escalation of Commitment Behavior in Software
search,2003,56(11):867-875. Projects[J].MisQuarterly,2000,24(2):299-325.
27 SweeneyJC,SoutarGN,JohnsonLW.TheRoleofPer⁃ 43 PalmatierRW,ScheerLK,SteenkampJBEM.Custom⁃
ceivedRiskin the Quality-ValueRelationship:AStudyin er Loyalty to Whom? Managing the Benefits and Risks of
a Retail Environment[J].Journal of retailing, 1999, 75(1): Salesperson-Owned Loyalty[J].Journal of marketing re⁃
77-105. search,2007,44(2):185-199.
28 Mitchell V W, Papavassiliou V. Marketing Causes and Im⁃ 44 San Martín S, Camarero C. How Perceived Risk Affects
plications of Consumer Confusion[J].Journal of Product & Online Buying[J].Online Information Review, 2009, 33(4):
BrandManagement,1999,8(4):319-342. 629-654.
29 ChoCH,KangJ,CheonHJ.OnlineShoppingHesitation 45 张 樊.淘宝开放数据解决生产企业信息不对称困惑
[J].CyberPsychology&Behavior,2006,9(3):261-274. [EB/OL].http://www.bianews.com/news/84/n-189684.
30 范秀成，罗海成.基于顾客感知价值的服务企业竞争力探 htm,2015-09-01.
讨[J].南开管理评论，2003，（6）：41-45. 46 LeeBK,LeeWN.TheEffectofInformationOverloadon
31 Anderson C J. The Psychology of Doing Nothing: Forms ConsumerChoiceQualityinanOn‐LineEnvironment[J].
ofDecisionAvoidanceResultfromReasonandEmotion[J]. Psychology&Marketing,2004,21(3):159-183.
Psychologicalbulletin,2003,129(1):139. 47 Ghose A. The Economic Impact of User-Generated and
32 杨宜苗.错过价格促销情境下消费者感知价值损失及其 Firm-Published Online Content: Directions for Advancing
对负向购买意愿的影响[J].商业经济与管理，2010，（2）： theFrontiersinElectronicCommerceResearch[A].InJank
52-60. W & Shmueli G (eds), Statistical Methods in ECommerce
33 曾志宏.时间压力、商店气氛和知觉差异对消费者延迟购 Research[C].NewYork:JohnWiley&Sons,2008.
买行为之研究[D].台湾：台湾私立中原大学，2007. 48 Chakraborty G, Lala V, Warren D. What Do Customers
34 DharR.ConsumerPreferenceforaNo-ChoiceOption[J]. Consider Important in B2B Websites?[J].Journal of Adver⁃
JournalofConsumerResearch,1997,24(2):215-231. tisingResearch,2003,43(1):50-61.
35 Pavlou P A, Liang H, Xue Y. Understanding and Mitigat⁃ 49 Xiao B, Benbasat I. E-commerce Product Recommenda⁃
ingUncertaintyinOnlineExchangeRelationships:APrin⁃ tion Agents: Use, Characteristics, and Impact[J].Mis Quar⁃
cipal-Agent Perspective[J].MIS quarterly,2007, 31(1): terly,2007,31(1):137-209.
105-136. （责任编辑：徐 波）
- 126 - --------------------------------------------------------------------------------- 情报资料工作 年第 期
2007 3
理
论
探
索
网络化信息环境中信息过载
＊
问题研究综述
蔺丰奇 刘 益 西安交通大学管理学院 西安
（ 710049）
摘要 在网络化信息环境中 随着新信息 知识和技术不断增长 信息过载正日益
 、 
成为一个备受关注的社会问题 文章在文献研究的基础上 系统分析了信息过载产生
。 
的背景及起因 探讨了其原因及影响 同时还总结了应对信息过载的策略和建议 并指
 ； 
出了研究的局限和未来趋势
。
关键词 信息过载 信息污染 信息管理 信息粹取 信息素养
随着新的知识和技术不断增长 信息技术的快速 11 信息过载的定义
、 ．
发展和广泛应用 信息资源正以指数级速度迅猛增 信息过载 又称作 信息超载 资讯过载 超
 “ ” “ ”、“ ／
长 由此带来丰富的信息来源和信息快速的扩散效 载 目前仍没有一个公认的定义
。 ” （David Bawdenet al 
果 但同时也引发了如信息过载 从传者 渠道和受众这一传播流程来看 大量
 （informationoverload）、 1999）。 、  、
搜寻负荷加重 资料品质降低等问题 信息过载现象 复杂 不断增加的信息在传播渠道上流动必然导致
、 。 、
日益凸显 并成为一个备受关注的社会问题 而如何 超载 从信息接受者的视角看 受众将信息 资料转
  “ ”；  、
减轻甚至避免信息过载现象及其负面影响 将是相当 化为自身知识的过程中也存在 瓶颈 障碍而无法有
 “ ”
值得研究的课题 效吸纳 导致 过载 等 认为 信
。  “ ”。David Bawden （1999） 
对信息过载问题的研究始于 世纪初 至 年 息过载通常是个人在工作中无法有效处理相关及有
20  60
代以来逐渐增多 信息过载真正成为一个问题导因于 用信息的一种状态 而这些信息必须具备某种程度的
。 
世纪 年代出版品的快速成长 特别是科技文献 价值且能够获取得到[2] 则认为
20 50  。Orrin E．Klapp（1986） 
的增长 学者 首先注意该现象的研究 这是一种信息的恶化现象 而其发生是由于信息变得
 GeorgSimmel 。 
年 在 未来的冲击 一书中 就曾经 不相关 与原信息产生干扰或过剩 老旧及不能够引
1970 Alvin Toffler 《 》   、
指出需要深入研究信息重荷对人类行为的影响[1] 随 起任何兴趣等[3] 信息过载是指信息超过个人接受和
。 。
着信息网络化及其带来的信息爆炸 信息过载问题已 处理的能力 从而导致厌烦和心理焦虑的现象[4]
  。Ju-
成为信息社会的普遍现象 相关研究表明 对信息资 认为 信息过载是现代媒体科技生
。  lian Dibbell（2003） 
源特性的误解及不当的信息处理态度 将会导致信息 产太多文化所能够吸收的文字及图像 而该趋势已锐
 
污染 信息过载现象发生 且会对人们的工作 生活以 不可当 则从个人角度出发认为
、  、 。Michael Marien（2003） 
及生理 心理及人际关系等产生严重的影响 如何有 信息过载是人们急于想赶上信息的步伐 但却发现已
、 。 
效解决信息过载问题成为一个重要议题 本文通过对 落后越来越多 和 认为 信息过载
。 。Hiltz Turdoff（2001） 
有关信息过载文献研究 具体分析了信息过载的原因 是一种因太多资料而超出个人认知能力所能处理的

及影响 总结了相应的对策和措施 并指出了研究的 情境 认为 信息过载是人们因某种
  。Mark Nelson（2001） 
局限和未来研究方向 因素而无法从众多信息中萃取出想要的信息
。 。
综上 所谓信息过载即是人们接受了太多信息
 
1 关于信息过载的原因分析 但却无法有效整合 组织及内化成自己需要的信息
、 
＊本文系国家自然科学基金项目 创新研究群体项目 和新世纪优秀人才支持计划项目 的研究成果之一
（70272023、70572037）、 （70121001） （NCET－04－0933） 。
36 情报资料工作 年第 期
2007 3
理
以至影响到人们的工作 生活以及人际关系等 传播方式的重复信息及确认电话 不仅增加信息接收
、 。  论
12 信息过载产生的原因 数量 亦影响工作品质及效率
探
．  。
许多人认为 信息过载导因于电脑及网络的发 新信息科技的发展 由于信息技术的飞速发 索
 （3） 。
展 但 则认为 早在 世纪因印 展及广泛应用 使得信息生产 传播 加工 处理 储存
 Kathryn Hensiak（2003）  19  、 、 、 、
刷技术的革新 该问题就已经产生 由于印刷技术的 的方式方法产生了根本性变化 由此造成了信息密集
 。 
进步 使得印刷资料可以大量生产并传布给众多使用 化 多样化 高速化传播 使得人们所处的信息环境日
 、 、 
者阅读 而人们第一次接受到比以前更多的信息[5]信 趋稠密 一般大众所认为的新信息科技 包含电子邮
 。 。 
息过载真正成为一个问题导因于 世纪 年代出版 件 网际网络 推播技术 等 其提供读
20 50 、 、 （pushtechnology） 
品的快速增长 特别是科技文献的增长 而首先注意 者快速及便利的信息管道 然亦造成了信息过载之效
  
到该现象的社会科学家为 此外 电脑和 应 如 认为 纸本资料 网页及电子邮件等信息
GeorgSimmel 。  。 Infield  、
网络技术的广泛运用亦为其肇因 之后 信息过载 数量的增加 是造成信息过载的主因 亦指
。 “ ”  Mary Biggs
问题就广泛为学者所探讨 如 年 就倡 出 易得性资料 出版品扩散及信息设备的广泛使用
 1973 Torkelson  、
议利用专题选粹服务 是造成信息过载之重要因素
（selective disseminationofinforma- 。
简称 帮助使用者解决信息过载问题[6] 对于新信息科技的崇拜 指出 信息
tion SDI） 。 （4） 。Hensiak 
许多学者认为信息过载产生之因相当复杂 如 过载产生之因除了新信息科技的发展外 另一因素为
 
及 两位学者 即将 人们对于新信息科技的崇拜 使得人们相信信息越多
MartinJ．Eppler Jeanne Mengis（2003）  
组织 信息过载产生之因区分为个人因素 信息特 越好 遑论该信息品质为何 学者 将该现象称
（ ） 、  。 Postman
质 任务及过程因素 组织设计及信息科技等五大类 为 科技垄断 因此 人们应该改变对于
、 、 “ ”（technopoly）。 
别[7] 信息的态度 以品质为重而非以量取胜[10]
。  。
综合文献研究 关于信息过载产生的原因大致可 工作性质 许多学者的研究指出 信息过载与
 （5） 。 
归纳为以下几个方面 工作性质或工作环境息息相关 从过程的观点来看
： 。 
信息资源的充分开发和总量扩张 表现为信 信息过载可能同工作过程中诸多变量相关 的
（1） 。 。Casey
息资源的开发范围扩大 物质信息采集从宏观 天体 研究认为信息过载决定于工作任务的特性 其中最重
 （ 、 
宇宙 向微观 粒子 基因 纵深发展 经济 社会信息 要的是任务的复杂性[11] 指出信息交流的
） （ 、 ）  、 。Schneider
随着经济活动加剧得到空前的开发 信息资源总量呈 数量和交流过程的中断都可能导致信息过载 其中信
 
爆炸式增长 世纪 年代信息总量约 亿字符 息交流的中断可能影响信息处理过程的效率[12]
。20 60 72  。
年代信息总量约 万亿字符 年的知识总量 则相信决策方式是信息过载的决定性因素 决
80 500 1995 Glazer 
是 年的 倍 人类科学知识在 世纪是每 策类型的理性化和多样化比起单一化的决策更容易
1985 2400 。 19 50
年增加一倍 世纪中期约每 年增加一倍 目前是 引起信息过载[13] 则指出工作团队中人员的知
20 10  。Kiley
每 年增加一倍 据估计 目前全世界每年发表的科 识结构和技能特征影响信息过载的发生 因为与工作
3 。  
技论文约四五百万篇 出版科技期刊约为 万种 报 相关的知识和技能的增加会提高人们接受和处理信
 5 
纸 万种 世界上每天的出版量业已达到 本之 息的能力 而相关知识和技能的不足则会导致处理信
6 。 1000 
多 由电话 电脑 电视等组成的各种类型的新信息系 息时发生困难[14]
。 、 、 。
统也向社会源源不断地提供着意义更为广泛的多媒 不了解本身的信息需求 认为 现代
（6） 。Wurman 
体信息 及 亦发现 英国剑桥 人在搜集信息时 很少深思应该阅读及不需阅读哪些
。Rudolf Hanka Karel Fuka  
大学图书馆的馆藏量每 年扩增一倍 而该结果与 信息 并耗费许多记忆空间于无用信息的吸收[15] 因
33   。
的研究相符 其认为医学信息量每 年增加 此 减少信息过载的首要之务便是了解自己本身之信
J．Wyatt  19 
一倍[8] 此外 及 在 年 息需求 确实掌握哪些信息为必须 并做好其优先顺
。 Peter Lyman Hal Varian 2000 10  
月的报告指出 世界上一年的印刷资料 影片 光碟资 序排列
 、 、 。
料及磁带内容之生产量 大约需要 亿 的储 缺乏处理信息的能力 每个人都拥有处理信
 15 gigabytes （7） 。
存空间 而这相当于每个人需要 的信息 息的能力 惟信息量若超过个人所能承受的范围 则
 250megabytes  
量[9]学者指出 今日信息量爆增已到了人类无法臆测 其信息处理能力降低 使得信息过载情形依旧存在
。   。
的地步 使得信息过载情形相当严重 因此 如何加强个人信息处理能力 为未来信息过载
 。  
信息的多变性 纸本资源需凭借不定期的修 研究的重要课题
（2） 。 。
订发行 以维持信息新颖性及正确性 但内容往往与 信息传播中存在缺陷或障碍 在信息的交流
  （8） 。 、
旧版重复性高 而电子资源因具备容易编辑 复制及 处理 使用过程中 人们常常有意或无意地歪曲信息
 、 、  、
传播等特性 使得一般人常获取到重复的信息或电子 制造或传播垃圾信息 使信息传播中出现人为的或技
 
邮件 因此 同一份信息可能一天内收到许多种不同 术上的噪音 从而加剧了信息泛滥 一般而言 信息传
。  。 。 
37 情报资料工作 年第 期
2007 3
理
播的缺陷大致有以下几个方面 传递工具方面的缺 不理解信息时 感到被淹没在大量要理解的信息里
论 ：① 
探 陷 人与人之间的信息沟通大多是借助语言 文字 而 时 不知某种信息是否存在时 不知到哪里查找信息
。 、   
索 语言 文字在表达方面很可能存在语义不清 措辞不 时 或者知道到哪里查找信息却不能对其进行访问
、 、 
当等方面的信息交流的障碍 还存在着信息传递工具 时 都会产生信息焦虑情绪 亦指出 信息过载
。  。”Shenk 
在加工 传播信息过程中因技术不稳定 不完善问题 可能引发心血管压力的升高 视力减弱 困惑 挫折
、 、 、 、 、 、
而造成的信息混乱无序 组织结构上的缺陷 如果 判断力减弱 同情心降低及过度的自负等症状[20] 此
。② 。 、 。
组织层次过多 机构过于庞大 信息经过层层传递必 外 在 上述清单中又另外加上了
  Michael Gorman Shenk
然要遇到障碍 甚至造成曲解 衰竭 变异和紊乱 放弃 及绝望 等症状[21] 前述
 、 、 。③ （resignation） （repair） 。
信息传播过程中人们的心理状态的缺陷 在信息交流 机构所做的研究指出 有 的经理人由于信
。 Reuters  2／3
过程中 因个人见解 立场 态度的差异 人们在传递 息过载感受到持续性的紧张状态 并有 的经理人
 、 、   1／3
信息时会出现各种不同 噪音 因此产生身体不适之状况 心理学家 分析
“ ”。 。 David Lewis
了先前学者所做的研究 而首先提出 信息疲劳症候
 “
2 信息过载现象的影响 群 简称 一词来描述
”（Information Fatigue Syndrome IFS）
信息作为一种现象 并非无条件地等于 资源 上述症状 包含焦虑 拙劣的决策 记忆不佳及工作满
 “ ”、  、 、
财富 信息交流使用过程中的信息过剩 信息失真 意度降低等 对于某些人而言 上述持续的失控状况
“ ”。 、 、 。 
信息干扰 信息传递混乱状态被称为信息污染 正如 可能进一步导致无助 沮丧及耗尽感等症状[22] 信息
、 。 、 。
约翰 奈斯比特所说 没有经过加工整理的信息不 焦虑是数据和知识之间的黑洞 是由人们所理解的信
· “ 
是我们的朋友 甚至是我们的敌人 当然更不是财 息与他们认为应该理解的信息之间日益扩大的鸿沟
 －－－
富资源 大量但无序的信息 不但不是资源 而是灾 造成的 当信息没能把人们想要或者需要了解的内容
”；“   ；
难 据国内外相关研究 对资源特性的误解及不当的 告诉他们时 人们就会产生信息焦虑[23] 不确定性和
”。   。
信息处理态度 将会导致信息污染 信息过载现象发 不明确性是造成信息焦虑的根本原因[24] 信息时代的
 、 。
生 且会对人们的工作和生活 生理 心理及人际关系 人们对信息的吸收是呈平方数增长的 然而人类的思
 、 、 
等产生严重的影响 维模式尚未较好地调整到可以接受如此大量信息的
。
大量文献讨论了信息过载的负面作用 ＆ 阶段[25]因而导致 信息焦虑症
（Klapp  “ ”。
＆ 对人们的生活和人际关系的影响等
Miller1986；Wurman1989；Meglio Kleiner1990； （3） 。David
特别是 世纪 年代以后 由于 等 在 信息过载 数字世界的绿色主张
Wheelwright1995）。 20 90  Shenk （1999） 《 ： 》
新信息科技的发展 特别是 网际网络及 一书中指出 信息过载或过度饱和不但不能提升生活
 E－mail  
等 学者们开始意识到信息过载已成为一大问 品质 反而会造成焦虑 迷惑 无知等情形的发生 此
WWW   、 、 。
题 而许多相关研究亦指出 信息过载对于个人或组 外 信息处理的负荷更威胁到自我教育之能力 造成
   
织而言 皆为相当严重的问题 并已严重影响到人们 社会中组成成员的疏离感 英国的科学家戴维 谢恩
  。 ·
的工作效率甚至是健康 关于信息过载现象的影响的 克新近对信息污染造成的病症进行了详细的描述 在
。 ：
研究 主要集中于以下几个方面 信息时代 人类正在经受信息过剩的威胁 人们每天
 ：  
对工作效率的影响 至于信息过载在工作中 要听到 看到许多新闻 观点 故事 调查 传言和报
（1） 。 、 、 、 、 、
产生的影响 研究者都注重强调它的负面作用[16] 道 其中有许多是与自己无关或者互相矛盾的 由此
 。  。
等人认为 信息过载会影响交换和 造成的结果是 我们确实收到了不少的信息 但从中
Wheelwright（1995）   
处理信息的速度和个人工作的专心程度 因此可能会 得到的东西却少得可怜 他认为 过去 年里计算机
 。  10
对个人完成任务的效率和质量产生负面影响[17] 信息 的发展是造成这一间题的主要症结所在 因为国际互
。 。
过载影响完成任务的效率以及完成任务的质量 联网的全球化趋势使得任何只要拥有计算机 调制解
、
[18]根据 机构针对 位企业 调器和电话的人都可以将自己的信息发往世界上任
（Wurman1989） 。 Reuters 1300
经理人所做的调查结果显示 的经理人相信信息 何地方 同时也可以接收大量信息 由于信息资源的
：2／3  。
过载使得工作满意度降低 的经理人相信信息过 审查管理还不完善 也不乏有些钻空子的人在大堆的
；2／3 
载影响其人际关系 的经理人相信信息过载影响 报纸 杂志中剪剪贴贴 拼凑成 信息报 这类的东西
；1／3 、  “ ” 
其健康 几近一半的经理人相信一些重要的决策因信 只图赚钱 不计后果 还有些人以信息咨询为名 专事
；  。 
息过载而延迟[19] 倒买倒卖二手 三手信息 索取中介费 这些也是信息
。 、  
对生理和心理健康的影响 污染产生的主要原因 通过各种载体或渠道获得的超
（2） 。Francis Heylighen 。
认为 信息过载对于个人最大的影响就是渐增之压 乎寻常的信息只会带来一种后果 即人们在解决一个
 
力 且伴随该压力而来的是产生心理 生理及社会之 问题或者做出一个决定之前会不由自主地求助于它
 、 
问题 提出 信息焦虑 的概念 当人们 而这也使许多人疲于应付 其实绝大多数的信息对他
。Wurman（1989） “ ” “ 
38 情报资料工作 年第 期
2007 3
理
们是没有用的 信息过载让美国未来学家丹尼尔 贝 席 首次提出信息素养的观念
。 · Paul Zurkowski （ShirleyJ． 论
尔也不得不发出这样的感叹 到哪儿去寻找广阔的空 其主要的定义是指个人具有找出 评
探
： Behrens1994） 、
间呢 在哪儿才能摆脱天空飞来的一个接一个的 信 估与利用各种不同来源信息的能力 年美国国家 索
？ “ 。1977
息 所产生的紧张状态呢 科学基金会科学信息部 主任 提
” ？ （NSF） Lee G．Burchinal
研究表明 信息过载若处理不当 所引发的后果 出信息素养的新涵义 拥有一些新技能的人
  ： （newset of
不仅影响个人生理层面 更甚者是导致心理层面的挫 包括有效地找到所需的信息 使用信息以解决
 skills） 、
败 使得人们开始逃避或拒绝信息 当前信息污染的 相关的问题
 。 （Charles R．McClure1994）。Breivik（1985）
危害已相当严重 它给人类社会造成物质上和精神上 认为具备信息素养的人是 有能力获取和判断信息
 “ 
的巨大损失 极大地增加了人们获得信息的成本 因 以满足信息需求的人 信息素养是发现自己的信息
 。 ”
此 信息污染问题需要人们像对待环境污染问题一 需要 寻找信息 判断和呈现信息 以及使用信息的能
 、 、 
样 在理论上和实践中认真加以对待 因此 如何协助 力 年美国图书馆学会
 。  。1989 （American Library Associa-
人们管理或减低信息过载情形 即成为信息社会的重 简称 将信息素养定义为 个体具有能力知
 tion ALA） ：
要课题 道何时需要信息 且能有效寻获 评估与使用所需要
。  、
的信息 即知道何时需要信息 确认解决特定问题的
 
3 信息过载之纾解对策 信息 找到所需信息 评估信息 组织信息及将信息有
 、 、
信息过载从 世纪 年代成为问题以来 许多 效地应用在特定问题上 澳洲大学图书馆员委员会
20 50  。
学者即致力于研究该现象对于个人的影响 并寻求其 简称
 （Council of Australian University Librarians’ CAUL）
解决之道 及 认为 先驱研究之一系美 更明白指出 一个有信息素养的人应具有以下十方面
。Eppler Mengis  
国心理学家 在 年代针对都市人所 的能力[30] 知道所需信息 决定所需信息的程度
Stanley Milgram 70 ：① ；② ；
感受到的信息过载问题进行探讨 在其研究中 他们 有效率地获取所需信息 评估信息及其来源
。  ③ ；④ ；⑤
最后发展出人们持续接触到大量信息过载的六种因 将所选择信息融入其知识库中 有效率地使用信息
；⑥
应对策 分别为 分配较少的时间给每一项信息输入 以实现其目的 了解信息使用的经济 法规 社会及
 ：  ；⑦ 、 、
漠视重要性较低的信息输入 重新划定社会关系 将 文化等议题 能够有道德及合理地获取与使用信
  ；⑧
过度负荷的重担转移至其他人身上 利用一些方式来 息 将所搜集的信息加以分类 储存及运用 认知
 ；⑨ 、 ；〇10
阻绝新信息的进入 利用过滤装置减低信息输入的强 信息素养是终身学习的先决条件
 。
度及设立特殊的组织 专门来吸收对个人而言过多的 掌握应对信息过载的方法 目前许多使用者
 （2） 。
信息 面临信息过载时 已非仅是被动地回应超载情形 而
（MartinJ．EpplerandJeanne Mengis2003）。  
和 等人 研究[26]指出了信息过 是积极地采取各种策略来避免信息过载之现象 以下
Klapp Miller （1986） 
载的负面作用 并主张预防和消除信息过载现象 仅列举数项使用者最常用来避免信息过载问题的方
 。
年 出版了 信息焦虑 一书 信息使用者 式[31] 经验法则 许多经验法则依循
1989 Wurman 《 》  。① （rules of thumb）。
的视角论述了 信息爆炸 和 信息焦虑 的本质 并探 的满足理论 即使用者不以大量信息为
“ ” “ ”  Hebert Simon 
讨了向用户提供更加清晰 明了 易懂信息的方式和 取得目标 而仅取得现存信息中令人满意的一部分
、 、  。
手段 等 提出了 信息过载 数字世 略读法 这是人们处理过多高
。David Shenk （1999） “ ： ② （skimmingoff thetop）。
界的绿色主张 目前虽然已经有管理部门正着手开 品质信息而使用略读或扫描方式来代替仔细与周全
”。
发相应的软件 力图克服信息过载的负面影响[27] 的阅读方式 如不看文章仅看评论或摘要等 分块
 。  。③
认为 信息过载解决之道是多层面的问 法 即阅读过文献后 将其中的信息分类或
Bawden  （chunking）。 
题 且没有单一工具或技巧可以克服该问题 因此 他 整理成一些片段放置于记忆中的一种认知过程 去
 。  。④
们将解决之道区分为两大类 管理层面及技术层面 枝法 即在信息不断增加的情况下 除去多
：  （twigging）。 
并就其实际内涵进行探讨[28] 余枝节或仅在某一范围内选取信息的方法 是一种适
。 
通过对文献的归纳 可以发现 使用者信息过载 合专业人士之选择性撷取信息法 分派法
  。⑤
解决之道主要有以下几种类型 个人处理方式 信息 即将部分或全部信息搜集与分析的工作
： 、 （delegation）。
系统辅助以及信息服务组织协助方式 兹将其分述如 交给其他人执行 删除及逃离法
。 。⑥ （omissionandes-
下 所谓删除法系立刻停止处理信息 而逃离法系
： cape）。 
31 个人处理方式 逃避处理信息的责任 延迟处理法 即在
． 。⑦ （quening）。
信息素养培育 信息素养 接受过量信息之尖峰时间中延迟回覆的时间 并借此
（1） 。 （Information Literacy） 
是解决信息问题不可缺少的技能 也 短暂休息以提升信息处理的效率 过滤法
（McMlure1994） 。⑧ （filter）。
是对抗信息过载的最有效方法 指专心处理某类信息而忽略其它相关信息 以避免信
（Anne Goulding2001） 
[29] 年美国国家图书信息科学委员会 主 息过载的情形
。1974 （NCLIS） 。
39 情报资料工作 年第 期
2007 3
理
32 信息系统辅助方式 息量而仅需最高品质 最接近问题的信息 但有时却
论 ．  
探 信息科技日益发展 许多人认为信息系统如能运 需要广泛搜集与问题相关的信息 而这也说明信息过
 
索 作良好 在某种程度上可适度解决使用者之信息过载 载并非信息使用者遭遇的唯一问题 信息品质过滤问
 
情形[32] 题亦是
。 。
个人信息管理系统 总之 如 所言 信息过载仍是未来设计系
（personal information manage-  Taylor 
被视为一种纾解信息过载的有效方式 认 统过程中最主要及困难的问题之一 未来应开发新的
ment） 。Etzel 
为 结合电脑媒体与信息过滤软体功能的个人信息管 软件或系统 致力降低不相关之信息与提升信息的品
 
理系统 将可有效解决信息过载之问题 智能型代 质 促使信息过载问题能够获得改善
 。（1）  。
理软件 具备搜寻引擎与人工智慧 33 信息组织的服务 如信息服务机构 图书馆 电
（intelligent agents）。 ． （ 、 、
判断的能力 其依据使用者资料档 快速搜寻所有相 子数据库等
  ）
关信息 然后由电脑进行主题相关判断之工作 并将 在信息膨胀的网络时代 信息使用者将持续面临
  
信息按相关性高低进行排序 自动化过滤软件 爆炸性增长的信息量 使用者身陷信息大海中 客观
。（2）  
所谓自动化过滤软件亦可 上需要信息组织提供面对复杂信息环境的应对方法
（automaticfilteringagents）。 
称为信息粹取系统 系从 以满足其信息需求 许多学
（informationextractionsystem） （Richard L．Hopkins1995）。
信息流中粹取最相关的信息 以解决使用者之信息超 者认为 在未来信息过载日益严重的情况下 信息组
  
载情形 推播技术 推播技术允许 织的角色将凸显出来 以协助解决使用者之信息过载
。（3） （pushtechnology）。 
在非同步的情况下 将符合需求的信息主动送达使用 问题 这有赖于信息组织自我能力提升和改进客户服
 。
者 使用者亦需事先建立正确的检索或使用者资料 务两个方面功能的发展 认为 步入知识
（ 。Seonghee Kim 
档 甚至还可以让使用者即时取得最新信息 随着许 管理时代 信息组织应视自己为知识专家 协助使用
） 。  
多使用者承受信息过载的情形日益严重 许多人便希 者组织及使用信息 以解决其信息过载 而其重点工
  
望推播技术能够有助于解决该问题 因而使得其研究 作将包括不同形式组织信息的呈现 发展组织和获取
 
越来越热门[33] 知识的方法与系统 知识散布及传递 加强知识的有
。  
目前针对网络信息浏览 取得与管理等议题 学 用性及价值 知识储存与检索等 即关注焦点应在加强
、   。
术界皆尝试提出相关的改善方法 例如许多学者们以 知识的获取与品质 设计和发展知识产品与服务以促进
。 
过滤及分类观念为基础 协助使用者管理 上的信 学习与察觉 使读者对于知识的价值有所认
 Web （awareness）
息 [34] [35] 知而加以利用 此外 要更积极扮演知识的训练者及顾
（Borchers et al ．1998 ；Chen1998 ；Lincke and 。 
此外 应用 问 以协助使用者进行知识管理[38] 信息组织不能仅仅
Schmidt1998；Rumpradit1999）。  meta－  。
来支援网络上的信息管理亦是另一个重要趋势 局限于进行浅层次的二次文献资料处理 而要能够进行
data 
[36] 学科导航 同时 还应该成为信息过滤者 信息组织要
（Balasubramanianand Bashian1998 ；Hindasand   。
突破传统功能 并通过各项管理技术协助整个社会来
Raivshankar1998；Lambrix．and Shahmehri 1998； 
组织 管理和使用信息资源 纾解信息过载现象
Lassila1998；Lawrence and Giles1998；Noah1998； 、  。
常用 为此 信息组织还必须改进信息服务功能 以降
Rajaramanand Norvig1998；Lai and Yang2000）  
的方法如通过智能代理人 以知识库 低使用者之信息过载问题 学者 和
（intelligent agents） 。 K．Nageswara Rao
或即时的线上学习方式来协助使用者管理 上的 指出 虽然近年来已开始训练使用者自行进
Web KHBabu 
资料 行检索以降低其信息过载 但由于检索的复杂性 部
。  、
许多学者认为 未来信息系统设计若能从使用者 分资源及检索过程的限制性 所以 代为检索的需求
  
角度出发 则可有效降低信息过载之情形 并未相对降低 认为 由专业人员代使用者进
 。Robert 。Griffiths 
虽未针对信息过载提出解决之道 不过 他认为 行检索 可节省读者三倍 四倍甚至五倍的时间 亦即
Taylor    、 
未来信息系统设计应有以下三大重点[37] 未来信 其检索效率是使用者的三倍 四倍甚至五倍[39] 因此
：（1）  。 
息系统设计应依据使用者的真正信息需求 而非仅依 学者们认为 网络时代比起纸本时代而言 信息数量
  
赖于传统技术或主题领域的内容 亦即信息系统设计 不仅暴增 连信息性质也变得复杂 使用者时间及精
  。
应朝向使用者角度发展而非科技角度或内容角度 力有限难以应对信息过载问题 客观上需要提供信息
。 
信息系统设计应由使用者加入其对系统的条件 咨询服务与导航服务 以便快速 准确地获取信息资
（2） 、  、
标准与期望 包含易于使用 降低噪音 品质 适应性 源 信息组织应对信息资源进行深度加工 为需求者
 、 、 、 、 。 
节省时间及费用等 而上述条件皆与应付信息过载的 提供高效服务 以降低使用者之信息过载现象
 
问题有关 认为 信息过载问题并不在于潜在相 ＆ 总之 信息组织自
。Taylor  （Nageswara Rao KHBabu2001）。 
关信息的指数增长 而是在于系统未能有效过滤 传 我能力提升是未来角色和功能发挥的基础 通过角色
 、 
输与散布信息所致 信息使用者有时需要减少信 的转型及功能的加强 在协助使用者解决信息过载问
。（3） 
40 情报资料工作 年第 期
2007 3
理
题上可以发挥重要作用 我国的具体实际 开展相应的理论研究将是今后的一
。  论
个重要现实议题
探
。
4 研究的局限及未来趋势 参考文献 索
目前 信息过载现象及其纾解对策 已成为信息
  1 Toffler A．Future Shock ．NewYork:BantamBooks1970
社会中相当热门的议题 但现有的研究仍然存在一定
。
2 DavidBawdenClive HolthamNigel Courtney．Perspectives
的局限 需要做进一步深入的研究 oninformationoverload．AslibProceedings199951（8）:249
 。
信息过载现象的影响问题 目前文献研究主 3 OrrinE．Klapp．Overloadandboredom:Essays onthequalityof
（1） 。
要强调其负面作用 但是缺乏充分的实证研究 也有 lifeintheinformationsociety．West－portConn．:Greenwoord
 。
人 ＆ 认为 人对信息量的适 Press1986:2
（Daft Lengel 1996；et al） 
4 Schick AGGordon LAHaka S．Informationoverload:a
度性有很大的弹性 人对信息的处理能力会因学习
 、 temporal approach ．Accounting OrganizationsandSociety1990
工作团队和任务的类型等因素发生改变 适度的信
。 15（3）:199－220
息过载对工作绩效可能并没有负面影响 甚至可能
 5 Kathryn Hensiak．Too Muchof a Good Thing:Information
会提高工作效率[40] 。因此 对待工作过程中信息过载
OverloadandLawLibrarians．Legal ReferenceServices Quarterly
的作用 不应简单地持否定态度 不应当凭想像过分
200322（2／3）:86
 
渲染信息过载的负面效应 而应该更深入细致和全 6 DavidBawdenClive HolthamNigel Courtney．Perspectives

面地分析研究 oninformationoverload．AslibProceedings199951（8）:249
。
如何有效处理信息过载问题需要做多方面 7 MartinJ．EpplerJeanne Mengis．AFrameworkforInforma－
（2）
的研究 目前学界和业界主要关注于个人处理方式
tionOverloadResearchinOrganization．ICAWorkPaper2003（1）
。 、 8 Rudolf HankaKarel Fuka．Informationoverloadand＂Just－in－
信息系统辅助方式及信息组织协助方式等方面 这
。 time＂knowledge．The Electronic Library200018（4）:280
些方面固然重要 但显然还远远不够 信息过载解决
 。 9 Paul Pedley．Informationoverloadandinformationliteracy ．
是多层面的问题 择其要者而论 信息资源的有
 ：① ManagingInformation2001（July／August）:8
序化管理 这需要信息生产 加工 储存 传播等部门
10 Kathryn Hensiak．Too Muchof a Good Thing:Information Over
 、 、 、
广泛合作 合理规划 综合应用经济学 法学 社会 loadand LawLibrarians ．Legal Reference Services Quarterly
  、 、
学 心理学 管理学 信息科学 情报学等学科的理论 200322（2／3）:89－90
、 、 、 、
方法 从经济 人文 技术三个不同角度去研究如何 11 Casey CJ．Coping withinformationoverload:the needfor
 、 、
实现信息资源有序化 并加以有效地落实 制订相 empirical research．Cost and Management199266（4）:31－38
 。②
应的政策法规 完善管理和监督机制 信息市场也应
12 Schneider SC．Informationoverload:Causesandconsequences ．
 。 HumanSystems Management19877（2）:143－154
建立统一的管理和监督机制 制定相应的政策法规
 13 Glazer R．Locallyrational decision making:the distractingeffect
条例来作为衡量信息商品 信息交易 信息服务的标
、 、 ofinformationon managerial performance ．Management Science
准 加强对信息源的检查 管理 杜绝信息市场中的
 、  199238（2）:212－227
有害 虚假信息滋生蔓延 加拿大信息政策与法规中
、 。 14 Kiley K．Thecyberspace databaseinformationoverload ．
有 文牍削减法 此法规定的目的就是对文件过多
Catalog Age199512（9）:56－59
《 》 理查 伍尔曼 资讯焦虑 张美惠译 台北市 时报文化
加以限制 因为过多的信息会干扰 污染必要的信 15 ． ． ．  : 
 、
息 设立相应的组织机构 目前 世界上越来越多 1996:202
。③ 。 
的公司开始意识到信息污染造成的负面效应 并采 16 Meglio CEKleiner BH．Managinginformationoverload．

取有效的措施控制过多的信息 例如 伦敦的怀特斯 Industrial Management and Data System19901（1）:23－26
。 
17 Wheelwright G．Informationoverload．Communications
公司就设立了一个 信息识别中心 以筛选那些无
“ ”  International199522（1）:55－58
关紧要的信息 提高公民的科学文化道德素质和信
。④ 18 Wurman RS．Information Anxiety ．NewYork:Bantam
息素质及能力 增强抵抗信息污染的能力 把泛滥的
 。“ Doubleday Dell Publishing GroupInc．1989
知识变成智慧是当今人类所面临的挑战 未来仍有
” 19 Pual Waddington．Dyingforinformation:Areportontheeffectsof
相当长的路要走
informationoverloadinthe UKand worldwide．1998
。 大卫 申克 林宜敬 陈美岑 译 资讯超载 数位世界的绿
信息过载问题的本土研究 信息过载问题最 20 · ．   ． :
（3） 。 色主张 台北 商周
早出现于西方发达国家 在理论和实践方面进行了大 ． : 1998:27－28

量卓有成效的工作 并积累了有益的成果和经验 随 21 Michael Gorman．The EnduringLibrary:Technologytradition
 。
着网络经济的发展 信息过载问题也开始在我国显现 andthequestfor balance．Chicago:American Library

Association2003:25
出来 并对人们的工作和生活产生各种不同的影响
 。 22 Francis Heylighen．ComplexityandInformation Overloadin
因此 逐渐成为人们关注的问题 国外的相关研究为
 。 Society:whyincreasingefficiencyleadstodecreasingcontrol ．
我们开展本土的研究提供了有益的借鉴和启示 结合 下转第 页
 ECCO WorkPaper2002（12） （ 48 ）
41 情报资料工作 年第 期
2007 3
理
索平台以及 等的运用表明图书馆已经在联 数据 数据库使用数据等 数据分析 开展基于用户使
论 Firstsearch 、 ） 
探 合发布资源方面取得很大成绩 但是在建立联合目录 用数据之上的推荐服务 将用户注意力引向更多的相
 
索 的规模 标准 服务对象以及如何降低检索和发现成 关资料 从而使图书馆的长尾资源得以更好地开发利
、 、 
本等诸方面还有待进一步研究 用
。 。
34 建立大型资源导航系统 引导用户发现感兴趣 有关 长尾理论 的讨论刚开始不久 但这一理论
．  “ ” 。
资源 确实为互联网环境下的图书馆服务提供了新的理念
条件下 信息阻塞的鸿沟被慢慢填平 用 和思路 那就是图书馆应该与用户共同建设资源 主
Web 2．0    
户的注意力从需求曲线的 头部 被引导向 长尾 豆 动地推介资源 引导用户发现资源 并降低发现和获
“ ” “ ”。  
瓣网 是发掘 长尾市场 的成功范例 该 取资源的成本 唯其如此 图书馆才能赢回用户的注
（douban．com） “ ” 。 。 
网对用户想看 在看 看过的书 电影和音乐进行标 意力 为长远发展注入新的活力
、  、  。
注 分类和评价 根据用户的口味 从浩瀚的书海和影 参考文献
、 ； 
音资料中找到用户感兴趣的 并找到和用户同样口味 方 军 林嘉澎 长尾 无处不在
 1  ． : ．[2006－12－10]．
的人 通过这种方式 用户的视野逐渐从大众领域转
 
http:／／www．mindmeters．com／pdf／MKW001-longtail．pdf
卜华白 长尾理论 及其对互联网商业运营模式的构筑启
向小众 个性 领域 从而完成用户个人充满趣味的 2 ．“ ”
（ ）  示 商场现代化
发现 之旅 这一引导用户拓展视野 发现兴趣资源 ． 2005（23）:66－67
“ ” 。 、
的模式应该被图书馆所借鉴 图书馆可以通过建立相 3 Librariesandthe LongTail LorcanDempsey．D－Lib Magazine
。
应的机制让用户参与建设 评价 推荐资源 并通过对 2006（4）
、 、 
4 Chris Anderson．＂Thelongtail＂．Wired MagazineIssue 12．
这些评论 推荐资源 读者选择列表等数据的分析 挖
、 、  10－October 2004
掘其内在联系 为用户提供丰富的导航结构 引导用
 
户一步步找到原本可能被忽略的 感兴趣的资源 另 作者简介 苏海燕 女 年生 石家庄学院图书馆助理讲师
、 。 [ ]  1977  。
外 图书馆还可以进行流通 包括馆藏数据 馆际互借 收稿日期
：2007－01－30
 （ 、
上接第 页
（ 41 ） 35 Chen HHouston AL．Internet BrowsingandSearching:
23 http:／／www．onepine．demon．co．uk／pwurman．html User Evaluationsof Category MapandConcept Space Techniques．
24 http:／／www．smu．edu／％ErmaSOn／Info’Anx／AnxDef．html Journal ofthe AmericanSocietyforInformationScience199849
陈雨彤 信息焦虑症 新世纪的时髦病 医药世界
25 ． : ． 2001（1）:40 （7）:582－603
26 KlappOrrinE．OverloadandBoredom:Essaysonthelifeinthe 36 Balasubramanian VBashian A．Document Management
InformationSociety．NewYork:Greenwood1986 and Web Technologies:Alice Marriesthe Mad Hatter．
27 FoleyJ．Managinginformationinfoglut newtoolscanhelptamean Communicationofthe ACM199831（7）:107－114
oceanof data．Information Week199530（10）:30－33 37 Richard L．Hopkins．CounteringInformation Overload:The Role
28 DavidBawdenClive HolthamNigel Courtney．Perspectives ofthe Librarian．Reference Librarian1995（49／50）:322－327
oninformationoverload．AslibProceedings199951（8）：249－255 38 Seonghee Kim．The Roles of Knowledge Professionalsfor
29 Anne Goulding．InformationPovertyor Overload．Journal of Knowledge Management．http:／／www．ifla．org／IV／ifla65／
LibrarianshipandInformationScience200133（3）:11 papers／042－115e．htm1999
30 Carmel O’Sullivan．Isinformationliteracyrelevantinthereal 39 K．Nageswara RaoKHBabu．Roleof LibrarianinInternet
world．Reference Services Review200230（1）:9－10 and World Wide Web Environment．InformationScience20014
31 Joel Ruddand MaryJo Rudd．Coping withInformation Load: （1）:31－33
＆
User StrategiesanImplicationsfor Librarians．College 40 Daft RLLengel Rh．Organizationalinformationrequirements
Research Libraries1986（7）:317－320 mediarichnessandstructural design．Management Science1996
32 Universityof California（Berkerly）．School ofInformation 42（5）:554－571
＆
Management SsytemsInformationSystems1997（Fall）:206
作者简介 蔺丰奇 男 年生 西安交通大学管理学院博士生
33 Angela EdmundsAnne Morris．The problemofinformation [ ]  1965  
河北经贸大学教授
overloadinbusiness organizations:areviewoftheliterature． 。
刘 益 女 年生 西安交通大学管理学院教授 博士研究
InternationalJournalofInformationManagement2000（20）:17－28  1961  、
生导师
34 Borchers AHerlockerJKonstanJRiedl J．Ganging Upon 。
收稿日期
Information Overload．Computer199831（4）:106－108 ：2007－01－04
48 --------------------------------------------------------------------------------- ComputerEngineeringandApplications计算机工程与应用 2021，57（19） 189
融合知识表示和深度强化学习的知识推理方法
宋浩楠，赵 刚，王兴芬
北京信息科技大学 信息管理学院，北京 100192
摘 要：知识推理是解决知识图谱中知识缺失问题的重要方法，针对大规模知识图谱中知识推理方法仍存在可解释
性差、推理准确率和效率偏低的问题，提出了一种将知识表示和深度强化学习相结合的方法RLPTransE。利用知识
表示学习方法，将知识图谱映射到含有三元组语义信息的向量空间中，并在该空间中建立强化学习环境。通过单步
择优策略网络和多步推理策略网络的训练，使强化学习智能体在与环境交互过程中，高效挖掘推理规则进而完成推
理。在公开数据集上的实验结果表明，相比于其他先进方法，该方法在大规模数据集推理任务中取得更好的表现。
关键词：知识推理；深度强化学习；知识表示；路径控制；规则挖掘
文献标志码：A 中图分类号：TP391 doi：10.3778/j.issn.1002-8331.2104-0430
Knowledge Reasoning Method Combining Knowledge Representation with Deep Reinforce-
ment Learning
SONGHaonan,ZHAOGang,WANGXingfen
SchoolofInformationManagement,BeijingInformationScience＆TechnologyUniversity,Beijing100192,China
Abstract：Knowledge reasoning is an important method to solve the problem of lack of knowledge in the knowledge
graph.Theknowledgereasoningmethodinthelarge-scaleknowledgegraphstillhastheproblemsofpoorinterpretability,
lowreasoningaccuracyandefficiency.ThispaperproposesamethodRLPTransEthatcombinesknowledgerepresentation
with deep reinforcement learning. Firstly, it uses the knowledge representation learning method to map the knowledge
graph to the vector space containing the semantic information of the triples, and establishes a reinforcement learning
environmentinthespace.Then,ittrainsthroughthesingle-stepoptimizationstrategynetworkandthemulti-stepreasoning
strategynetworktoenablethereinforcementlearningagenttoefficientlyminethereasoningrulesandcompletethereasoning
intheprocessinteractingwiththeenvironment.Accordingtoexperimentalresultsonpublicdatasets,comparedwithstate-
of-the-artmethods,theproposedmethodachievesbetterperformanceinreasoningtasksforlarge-scaledatasets.
Keywords：knowledgereasoning;deepreinforcementlearning;knowledgerepresentation;pathcontrol;rulemining
随着知识图谱相关技术的快速发展，各种大规模的 性能，所以被广泛应用于知识推理相关任务中，该类模
知识图谱被构建出来并广泛服务于各个领域。例如 型将知识图谱中的实体和关系映射到低维向量空间，并
Freebase[1]、DBpedia[2]、NELL[3]等知识图谱都为研究和应 在此空间中进行计算完成推理；关系路径推理方法作为
用提供了巨大数据支撑。但是，无论是自动化构建或人 一种适用于大规模知识图谱的推理方法引起关注和研
工构建的通用知识图谱，还是自动化构建或人工构建的 究，其主要思想是：在知识图谱中充分挖掘和利用实体
领域知识图谱，绝大多数都存在一定程度的不完备问 间多步关系，组成路径信息从而完成知识推理。而知识
题[4]，知识图谱中存在大量的实体和关系缺失。知识图 表示学习和关系路径相融合的方法因其同时具备以上
谱补全技术便是为了应对实体和关系缺失而出现，该技 两种优势，因此得到广泛的研究和利用。
术的最主要方法就是知识推理[5]。 尽管如此，现阶段知识图谱补全研究中仍存在可解
近年来，基于知识表示学习推理和基于关系路径推 释性差、大规模知识推理效率和准确率较低的问题，特
理等研究方法，已成为知识推理研究的热点。知识表示 别是推理的可解释性[8]逐渐受到领域研究者的关注。针
学习方法（TransE[6]、TransH[7]等）因其具有较好的效率和 对这类问题，本文提出了一种将知识表示和深度强化学
基金项目：国家重点研发计划课题（2019YFB1405003）。
作者简介：宋浩楠（1993—），男，硕士研究生，研究方向为知识推理、强化学习，E-mail：shnbistu@sina.com；赵刚（1965—），男，博士，
教授，CCF会员，研究方向为强化学习、风险评估；王兴芬（1968—），女，博士，教授，研究方向为大数据分析与智能决策。
收稿日期：2021-04-30 修回日期：2021-06-15 文章编号：1002-8331（2021）19-0189-09 190 2021，57（19） ComputerEngineeringandApplications计算机工程与应用
习（Reinforcement Learning，RL）相结合的方法RLP- 习从实数空间到复数空间的扩展。将关系看作是从头
TransE。将知识图谱中的所有的三元组信息通过知识 实体到尾实体的旋转。Zhang等人[13]引入超复数的概
表示方法映射成低维向量空间中的稠密向量，充分保留 念，提出了QuatE，与RotatE类似，该模型将关系看作超
其语义信息，同时引入强化学习方法，将知识图谱中知 复数平面内头实体到尾实体的旋转。相比于其他先进
识推理问题转化为马尔可夫序列决策问题，通过知识表 方法，上述方法存在以下问题：（1）将知识推理转化为单
示和强化学习相融合的方法充分挖掘知识图谱中的有 一的向量计算，带来了可解释性差的问题；（2）未能充分
效推理规则，并且对智能体选择的路径质量进行了控 利用关系路径等重要信息，推理能力受限，推理准确率
制，从而高效完成大规模知识图谱的补全任务，该融合 尚有较大提升空间。
方法也为知识推理的混合推理研究提供了新的思路。 1.2 基于关系路径的推理方法
与其他方法相比，本文方法在大规模数据集上的表 该类方法主要是基于知识库中图的结构特性进行
现均优于知识表示学习推理和关系路径推理等方法。 研究推理[14]。Lao等人[15]提出了路径排序算法（Path
本文的主要贡献： Ranking Algorithm，PRA），将知识库中连接实体的不同
（1）提出了一种融合知识表示和深度强化学习的知 的关系路径作为特征，通过在知识库中统计路径来构建
识推理方法RLPTransE，将知识推理问题转化为序列决 分类的特征向量，建立针对关系的分类器来预测两个实
策问题，增强了推理的可解释性。 体之间的关系。Lao等人[16]基于PRA算法，通过调整和
（2）提出了一种单步择优策略网络和多步推理策略 组合图中不同随机游走相关权重来学习推断关系，提升
网络的双网络结构。其目的是准确并高效地挖掘高质 路径推理质量的同时使其更适用于大规模知识图谱推
量推理规则。 理。Gardner等人[17]提出的子图特征提取模型，将图中
（3）该融合推理方法充分发挥了两者的优势，在公 的节点对生成特征矩阵，通过修改PRA路径搜索的过
开标准数据集上的对比实验结果显示，本方法取得了较 程，提取路径之外更丰富的特征，提高推理的效率。
好的性能，为知识推理的混合推理研究提供了新的思路。 Gardner等人[18]通过结合文本内容对PRA算法进行修
改，引入了向量空间相似性，缓解了PRA中的特征稀疏
1 相关工作 性问题。Das等人[19]使用RNN模型，通过递归方式组合
知识图谱的中知识缺失问题普遍存在，而知识推理 知识图谱中多跳路径的分布式语义从而构成关系路径，
是解决知识图谱补全任务的重要方法。大规模知识图 并且在推理过程中引入了注意力机制。Chen等人[20]设
谱中知识推理方法大致分为三类：基于知识表示学习的 计了概率图模型下的推理问题，在知识推理中引入变分
方法、基于关系路径的方法和基于知识表示学习和关系 推理框架，将路径搜索和路径推理紧密结合从而进行联
路径融合的方法。本章将按照此类别对国内外知识推 合推理，大幅提升了推理效果。相比于其他先进方法，
理方法研究进行介绍。 上述方法存在如下问题：（1）由于存在数据稀疏问题，知
1.1 基于知识表示学习的推理方法 识图谱中的信息未被充分利用；（2）未考虑路径的可靠
自词嵌入表示模型提出后，许多自然语言任务都证 性[5]计算问题，难以适用于大规模知识图谱。
明了其重要作用。受此启发，对知识三元组的表示学习 1.3 基于知识表示学习和路径融合方法
也取得了许多突破性成果。Border等人[6]提出了TransE， 上面的两类模型仅考虑了图谱中实体间的直接关
将知识库中实体之间的关系当作实体间的某种平移，实 系或者只考虑了实体间简单的路径关系，但事实上，知
现了对多元关系数据高效建模的知识补全，但该模型在 识图谱中实体之间的关系路径隐含着丰富的语义信息，
处理一对多等复杂关系表示问题存在不足。针对这个 研究知识表示和关系路径的融合方法具有重要意义。
问题，后续研究提出了许多衍生版本。Wang等人[7]提出 Lin等人[21]设计了PTransE，使用语义连接算法表示路径
TransH，引入超平面法向量，实现了不同实体在不同关 关系，同时引入路径约束资源分配算法来衡量关系路径
系下拥有不同的表示，但三元组知识仍处于相同的语义 的可靠性，将实体和关系映射到低维空间中表示计算，
空间，限制了自身的表达能力；Lin等人[9]提出了TransR， 从而显著提高推理能力。陈海旭等人[22]提出了PSTransE，
为每一种关系定义单独的语义空间，并使用不相同的映 该模型对PTransE进行了改进，用关系和路径的向量相
射矩阵实现从实体空间到不同关系空间的映射；Ji等 似度来表示路径推理关系的概率，通过互补方法计算推
人[10]提出TransD，不仅考虑关系的多样性，而且考虑实 理概率，在综合考虑相关路径信息的同时，更注重关键
体的多样性，提出了不同实体具有不同的映射矩阵，减 路径对推理所起的决定性作用。文献[23-24]都是在
少模型参数的同时使模型更加灵活。Ebisu等人[11]提出 PTransE的基础上的改进模型，它们的基本结构一致，仅
TorusE，将TransE的思想应用在李群（Lie group）理论的 在知识的表示方式上存在不同。
环面空间中。Sun等人[12]提出RotatE，实现知识表示学 近年来，机器学习的可解释性越来越得到大家的关 2021，57（19）
注，强化学习在可解释性和性能等方面的优势，使得强 结合这两类方法的优势来提高模型推理的可解释性、准
化学习应用于知识推理领域成为研究热点。Xiong等 确性和推理效率，于是本文提出了一种融合知识表示和
人[25]设计了DeepPath，将知识库中知识推理过程转化为 深度强化学习的推理方法RLPTransE。如图1所示，使
马尔可夫序列决策过程（Marcov Decision Process， 用知识表示学习方法，将知识图谱映射到含有三元组语
MDP），以实体集合为状态空间，关系集合为动作空间， 义信息的向量空间中，然后在该空间中建立深度强化学
智能体通过选择最优动作以拓展其路径来实现知识库 习的环境。通过基于有监督的单步择优策略网络的训
中的推理。但由于DeepPath模型简单，并且需要提供大 练，降低RL智能体单步错误动作的选择率，再通过基于
量已知路径进行预训练，训练过程复杂，因此其推理性 奖励函数的多步推理策略网络的训练，提升RL智能体
能存在很大提升空间。Das等人[26]提出了MINERVA，将 搜索正确路径的成功率。最终，实现RL智能体在与知
起始实体到目的实体之间的路径选择问题转化为序列 识图谱环境交互过程中，成功挖掘推理规则进而完成推
决策问题，通过建模以查询问题为条件引导模型在知识 理任务。
库中找出预测路径，解决了在已知一个实体和关系情况 2.1 知识表示学习模块
下的问答问题。Lin等人[27]提出了Multi-Hop，针对路径 为了解决大规模知识推理面临的复杂数据高效利
择优和路径多样性探索的问题分别提出了软奖励机制 用的问题，在词嵌入表示模型的启发下，研究人员基于分
和随机Action-Drop方法。Li等人[28]提出了DIVINE，一 布式思想提出知识表示学习（Knowledge Representation
种基于生成式对抗模仿学习的框架，并通过模仿从知识 Learning，KRL）的方法[6]，将实体和关系的语义信息映
库中自动采样来自适应地学习推理策略和奖励函数。 射到低维向量空间，使得语义相近对象的向量表示距离
Wang等人[29]提出了AttnPath，将LSTM和图注意力机制 也相近。
作为记忆组件，并提出一种新的避免智能体停滞不前的 在TransE模型中，知识库中的关系当作实体间的某
强化学习机制来提高推理成功率。相比于其他先进方 种平移。对于知识库中三元组，用l h、l r和l t依次表示头
法，上述方法侧重于提高推理准确率，但由于引入许多 向量、关系向量和尾向量。该模型的核心思想如公式所
新技术，模型的复杂度更高，推理效率较低。 示：
l h+l r≈l
t
（1）
2 融合知识表示和深度强化学习的知识推理方法 得分函数定义如下：
上述推理方法，各有其优点和不足。因此本文考虑 d
r(h,t)=|
l h+l r-l
t|
（2）
L1/L2
图1 融合知识表示和深度强化学习的知识推理模型框架图
Fig.1 Overall framework of integrating knowledge representation and deep reinforcement
learning model for knowledge reasoning
The KG Environment
Reason Task：PlayinLeague
Start Entity：Ionel Messi The DRL System
Single-step Accurate Strategy Network
Bernab
HomeStadium
Next State State π(a|s)
Softmax
InputLawyer HiddenLawyer OutputLawyer
Model Transfer
Multi-step Reasoning Strategy Network
State π(a|s)
Softmax
InputLawyer HiddenLawyer OutputLawyer
noitatneserpeR
egdelwonK
宋浩楠，等：融合知识表示和深度强化学习的知识推理方法 191
None
Pla
Tea
minlea g u e MR ae da rl id Playsport−1yf or
LaLiga Football Reward
League
Tea
minleague
PlayinLeague tro
p sy
alP
Workfor Playsforteam Ionel
None Barcelona
Graduatedfrom
ationin
None
H
ashusba Born nid
n
m partofessi Next State
c b
o u
L s
None
Argentina
Spain None 192 2021，57（19） ComputerEngineeringandApplications计算机工程与应用
使用基于边界的方法，定义了如下优化目标函数： （3）状态转移P
L= ∑ ∑ [ γ+d r(h,t)-d r′(h ′,t ′)]
+ （3）
RL智能体通过选择当前状态下的最优动作实现状
(h,r,t)∈S(h′,r′,t′)∈S′ 态转移，具体而言，智能体以知识图谱中的某个实体为
其中，S是正样本三元组集合；S 是负样本三元组集合，
′ 当前位置，选择一个与当前实体相连的某个具体关系作
该集合是通过随机替换正样本三元组的头实体或者尾
为下一步执行的动作，然后执行该动作，实现智能体状
实体得到；[ x]
表 +
示max( 0,x；)γ表示一个边界参数，是一
态转移。状态转移P表示如下：
个需要设置为大于零的超参。 P={s ′|(s,a) ;s∈S,a∈A} （7）
当前知识表示学习模型多样。本文选用了TransE （4）奖励函数γ
模型，因其参数数量较少，在大规模稀疏数据集上效果 RL智能体完成一次完整的任务过程后，环境都会
明显，在与深度强化学习融合过程中，解决了知识稀疏
给予智能体一定的奖励，包括正向奖励和负向奖励，智
性问题，提高了模型整体效果，实验结果证明该模型对
能体根据这些反馈的奖励值来更新自己的策略，以实现
本文方法具有支撑作用。
最大化的奖励。本文采取了多样化的奖励方式，下面将
2.2 深度强化学习模块
对奖励函数进行详细介绍。
本文将知识图谱中推理问题转化为马尔可夫序列 全局奖励 在同环境交互过程中，智能体会有大量
决策问题，RL智能体的动作选择和状态转移都是在该
的可选动作，这就意味着智能体很有可能选择错误的动
框架中进行的，故本部分将介绍对知识图谱的强化学习 作，从而导致无法到达目标状态。为了解决该问题，强
建模过程。
化学习方法添加了一个全局奖励函数。若智能体在与
该过程主要由<S,A,P,γ>四部分组成，下面将其进
环境的交互过程中，从起始状态e 成功达到目标状态
cur
行详细介绍。 e ，则给予智能体一个正向奖励，否则无奖励。其定义
tar
（1）状态空间S
如下：
本模型的状态空间S是由知识图谱中的有效实体
γ (e )=ì í1 if e cur=e tar
集合E组成的。针对本文的双策略网络结构，设计了两 Golbal cur î0 if e ≠e （8）
cur tar
种状态。在单步择优策略网络中，将每个实体作为RL
单步负向奖励 在同环境交互过程中，智能体可能
智能体的具体状态s；在多步推理策略网络中，将当前实
选择大量错误动作，为了降低智能体的错误动作选择
体和目标实体作为RL智能体的具体状态s，其中状态
率，定义了单步负向奖励函数，当智能体选择的动作不
s∈S。状态的两种表示如下：
能推理出目标实体时，给予负向奖励。
s s1 2t t= =T Tr ra an ns sE E( (e ec c,) e t) （ （54） ） γ Step_wrong(e cur)={ -
0
i0 f.1 oti hf ee rwcur i≠ sepath tar （9）
其中，e c表示知识图谱中的当前实体，e t表示知识图谱中 路径长度奖励 对于知识图谱中的推理任务，大量
的目的实体，s1t、s2t是当前实体在状态空间中的向量化 的研究表明：短关系路径p比长关系路径p更能提供有
表示。为了规范化表达，如无特殊说明，本文状态均用s 价值的推理关系。为了限制推理路径的长度，提高推理
表示。 效率。本文定义了如下的路径长度奖励函数：
（2）动作空间A
1
γ =
RL智能体在当前状态下，经过动作选择后，基于环 path_length length( p) （10）
境的交互反馈实现状态转移。本模型的动作空间A是 路径多样性奖励 为了使智能体推理出不同的关系
由智能体可能选择的动作集合A s组成的，它是由状态s 路径，本文定义了如下的路径多样性奖励函数：
的当前位置实体在知识图谱G中所有可能的输出边组 |F|
1 ( )
成的，动作集合表示如下： γ DIVERSITY=- |F|∑ p,p i （11）
i=1
A s={(e c,a,e n) ∈E:S={s t} ;a∈R;e c,e n∈E} （6） 其中|F|表示已发现的路径的数量，p和p i表示关系路
其中，e、e 分别表示当前位置实体和下一个可能的位置 径组成的表示向量。
c n
实体，a表示采取的动作，S表示状态空间，R表示关系集 单步择优策略网络仅使用全局奖励进行训练，多步
合，E表示实体集合。 推理策略网络则综合使用4种奖励函数进行训练，训练
特别地，关系集合R由知识图谱中已存在的关系r 过程中保证正向奖励总和大于负向奖励总和。
和新添加关系r-1两部分组成，r-1是关系r的逆关系。 （5）策略神经网络
大量实验研究表明，将r-1关系添加到动作空间中，不仅 由于大规模知识图谱的关系数量众多，建模出来
可以使智能体自动撤销错误的决策，而且还可能发现一 的强化学习方法的动作空间规模庞大，因此本文直接
些隐含的推理信息。 选择基于策略梯度的深度强化学习来完成该任务。本 宋浩楠，等：融合知识表示和深度强化学习的知识推理方法 2021，57（19） 193
文使用三层全连接神经网络设计策略函数，其中在每个 7. 更新策略网络
隐藏层之后添加非线性层（ReLU），并使用softmax函数 8. ∇θlogπ(a=r cur,s t;θ)γ(e t,r cur)
对输出层进行归一化处理。该策略网络实现了将状态 9. end for
向量s映射到所有选择动作的概率分布中，本方法采用 2.3.2 基于奖励函数的多步推理策略网络训练
REINFORCE[30]策略进行参数优化，如下面公式所示： 经过单步择优策略网络训练后，RL智能体对单步
∇θJ(θ)=∇θ∑lrt|s t;θ)γ
（12）
动作选择具有很高的成功率，但它在知识图谱环境交互
t 过程中多步动作选择的成功率却很低。而对于知识推
其中θ是策略网络的参数，π(a=r t|s t;θ是)基于状态s t时
理任务而言，实现多步推理才是任务目标。本部分的主
策略网络输出动作为r 的概率，γ是选择该动作获得的
t
要目的是通过基于奖励函数的再训练，提高智能体在推
奖励值。
理任务中的多步路径选择能力。
本文方法中单步择优策略网络和多步推理策略网
（1）训练集
络使用了相同的神经网络结构。
为了提高本模型的整体性能，对于知识图谱中的三
2.3 训练过程
{ }
元组集合F= e ,r,e，将r作为推理任务。针对特定的
训练过程由单步择优策略网络训练和多步推理策 h t
略网络训练两部分组成。如图1所示，首先使用有监督
推理任务r ′(r ′∈r，)将三元组集合F中含有关系r ′的三元
{ }
组分离出来，组成推理任务三元组集合T= e ,r,e，按照
策略学习方法对单步择优策略网络进行训练，提高RL h ′ t
比例7∶3分为训练集Trainset和测试集Testset。
智能体在推理过程中单步择优能力。将训练后的参数
（2）训练流程及算法
作为多步推理策略网络的初始化参数，基于奖励函数对
与单步择优策略网络训练任务不同，多步推理策略
多步推理策略网络进行再训练，提高智能体在推理任务
网络训练的目的是使RL智能体高效的完成多步关系路
中的多步路径择优能力。
{ }
2.3.1 基于有监督的单步择优策略网络训练 径推理任务。对于推理任务三元组集合T= e h,r ′,e t中
本文首先对RL智能体进行有监督策略学习的单步 的三元组(e h,r ′,e t)，RL智能体从起始状态e h出发，通过
择优策略网络训练任务，目的是让智能体尽可能地在第 与知识图谱环境不断地交互中发现有效路径，寻找除了
一步就选择正确动作。单步择优策略网络在知识图谱 关系r ′外到达目的状态e t的路径。在与知识图谱环境
推理任务中只需训练一次，极大提高了推理效率。 不断地交互过程中，使用多种奖励函数对深度强化学习
（1）训练集 进行多步推理策略网络训练。训练的算法2如下所示。
知识图谱中的三元组集合F={ e ,r,e 是} RL智能 算法2 多步推理策略网络训练算法
h t
体知识推理的环境。首先，为三元组集合F中元素添加 输入：训练集Trainset
{( ) 输出：强化学习智能体的策略网络参数
一个反向关系，生成一个新的三元组集合F ′= e h,r,e t ,
1.初始化RL环境env，加载单步择优策略网络参数
( )}
e t,r ′,e h 。取出F ′中三元组的前两部分并将相同部分 2.for训练集Trainset中的三元组(e h,r ′,e t) ：
合并组成二元组训练集合D train={( e h,r) ,(e t,r ′。)} 3. cur_s t,tar_s t=getEntity embeding(e h,e t)
（2）训练流程及算法 4. succ=0，train_step=0，
RL智能体依次将训练集合D train中的实体作为的起 5. while train_step<max_stepandsucc==：1
始状态e ，并输入到深度强化学习的策略网络中，根据 6. a =policy_NN(cur_s )
cur next t
策略网络的输出结果，选择一个关系r作为下一步的执 7. Reward,new_s t,done=env.interact( (cur_s t,tar_s t) ,
行动作，此时判断起始状态e cur和单步动作选择的关系r a next)
组成的新二元组是否属于D ，若是，给予+1奖励并更 8. train_step+=1
train
新策略网络。预训练算法如算法1所示。 9. if new_s t==：e t
算法1 单步择优策略网络训练算法 10. succ=1
输入：D 11. new_s t=cur_s t
train
输出：强化学习智能体的策略网络参数 12. end while
1.Entity embeding,Action embeding=TransE(D train) 13. 更新策略网络
2. for D train中的二元组(e cur,r) ： 14. ∇θlogπ(a=r cur,s t;θ) γ
3. s =getEntity (e ) 15. end for
t embeding cur
4. r =policy_NN(s )
cur t
5. If <s,r > in D ： 3 实验与分析
t cur train
6. γ(e t,r cur)=1 通过公开数据验证方法有效性，并通过对比和消融 194 2021，57（19） ComputerEngineeringandApplications计算机工程与应用
实验来进一步分析说明。代码使用Python编写，基于 表2 链接预测结果
TensorFlow框架实现。运行环境为Ubuntu 18.04.5操作 Table 2 Link prediction results
系统，Intel® Xeon Silver4210 2.20GHz CPU和NVIDIA 算法 模型 FB15K-237 NELL-995
Tesla V100S GPU。 基于知识表示 TransE 0.532 0.737
3.1 数据集及参数介绍 学习算法 TransR 0.540 0.789
基于关系路径 PRA 0.541 0.675
本文实验中，采用知识推理领域通用的两个基准数
算法 DIVA 0.598 0.886
据集FB15K-237[31]和NELL-995[25]作为对比实验的实验
DeepPath 0.572 0.796
数据集，两者都是较大数据集的子集，其中FB15K-237 MINERVA[26] 0.553 0.885
基于融合算法
中的三元组是从FB15K中去除了冗余关系后得到的数 DININE（MINERVA） 0.568 0.893
据集。NELL-995是基于NELL系统的第995次迭代产 AttnPath 0.585 0.834
本文算法 RLPTransE 0.616 0.801
生的数据集整理后的数据集。数据的统计信息如表1
所示。 表3 事实预测结果
Table 3 Fact prediction results
表1 数据集统计信息
Table 1 Statistics of the datasets 算法 模型 FB15K-237 NELL-995
TransE 0.277 0.383
数据集 实体量 关系量 事实量 任务数
基于知识表示 TransH 0.309 0.389
FB15K-237 14505 237 310116 20
学习算法 TransR 0.302 0.406
NELL-995 75492 200 154213 12
TransD 0.303 0.413
本文方法知识表示模型TransE用Fast-TransX（https：
DeepPath 0.311 0.493
//github.com/thunlp/Fast-TransX）中的方法训练，嵌入维度 基于融合算法 DeepPath TransD 0.313 0.535
设置为100维；策略网络的隐藏层是由两个全连接网络 AttnPath 0.315 0.598
和ReLU激活函数构成，神经元分别设置为512和1024， 本文算法 RLPTransE 0.347 0.589
输出层节点数等于RL环境中所有关系数量：FB15K-237 3.3.1 链接预测
是474，NELL-995是400。单步择优策略网络训练任务 链接预测是指三元组在给定头实体和关系二元组
上batchsize设置为1000，训练1000个epochs。 (e h,r条) 件下预测三元组的尾实体e t。本文采用DeepPath
3.2 评价方式和评价指标 中测试方法，通过对候选尾实体打分来进行排名。实验
对于知识推理任务的评价方式，通常是链接预测 结果由表2所示。
（Link Precdiction，LP）和事实预测（Fact Precdiction， 由表2所示的实验结果可知，本文方法在FB15K-237
FP）。链接预测是预测三元组中缺失的部分。事实预测 数据集上取得了最优的链接预测结果，性能比AttnPath
是在判断三元组的正确与否。数据集按7∶3的比例分为 高出0.031，而在NELL-995数据集上取得了优于知识表
训练集和初始测试集，而测试集是由初始测试集和其生 示学习方法、关系路径方法中PRA和融合方法中Deep-
成的负样本组合而成，正负样本比例约为1∶10，其中负 Path的性能，但略逊色于MINERVA等其他模型的性能。
样本是由正样本被替换尾实体生成。此次实验使用平 本文方法在规模较大的FB15K-237数据集上性能提升
均精度均值（Mean Average Precision，MAP），定义如下： 更明显，主要原因是：相比于关系稀疏的NELL-995数据
1
m
1
|{ rank( y ′) ≤rank( y) ;y ′∈t i}| 集，FB15K-237数据集中实体之间平均路径长度较长，
MAP= ∑ ∑
m i=1|t i|
y∈ti
rank( y) （13） 动作选择的错误率更高，导致大量正确路径难以被挖
掘，模型性能降低。而本文的优势在于降低错误动作的
( ) ( )
其中rank y 和rank y ′ 分别为正样本和负样本的排名，
选择率，提高正确路径的挖掘成功率，因此在FB15K-
t i为测试集，m为样本总数。
237数据集上效果提升更明显。
∑M
3.3.2 事实预测
T
本文实验结果使用所有任务MAP的平均值 |T|
事实预测旨在判断未知事实是否为真，对于给定的
作为评价指标，其中T为任务集合。 三元组(e h,r,e t)，模型通过判断符合路径的个数作为分
3.3 实验结果及分析 数，从而判断其正确与否。本文延用DeepPath中的评价
为了验证RLPTransE方法的有效性，将本文方法 方法，对测试集所有输出采取全排名方式计算结果，由
RLPTransE与基于知识表示学习算法（TransE[6]、TransH[7]、 于PRA未提供所有三元组全排名结果，因此这里不考
TransR[9]、TransD[10）] 、基于关系路径算法（PRA[16]、DIVA[20）] 虑PRA作为基线。表3显示了所有方法的结果。
和基于融合算法（DeepPath[25]、AttnPath[29]等）在两个公开 如表3所示，本文方法同样在FB15K-237数据集上
数据集上进行对比实验，实验结果如表2和表3所示。 的事实预测结果达到了最优性能，性能比AttnPath高出 宋浩楠，等：融合知识表示和深度强化学习的知识推理方法 2021，57（19） 195
0.032，而在NELL-995上取得优于其他模型，但略逊色 因此，实验结果表明，引入单步择优策略网络对推理任
于AttnPath的结果。对于FB15K-237数据集，本文方法 务的完成具有明显的提升效果。
比知识表示学习方法中性能最好的TransH高出0.038。 为了进一步分析单步择优策略网络在本方法中的
对于NELL-995数据集，本文方法比知识表示学习方法 重要性。本文对该网络的单步择优能力作了对比实验，
中性能最好的TransD高出0.176。相比于融合模型中的 使用不同训练集对单步择优策略网络进行训练，然后对
DeepPath及其衍生模型，本文方法性能均有较大提升。 网络的单步选择成功率进行统计。定义如下三种模型：
3.4 消融实验 All-train，使用D
train
的样本集合{ (e h,r),(e t,r训′)} 练；Pos-
为了进一步分析单步择优策略网络训练对本文模 train，使用D
train
中正向样本集合{ (e h,r)训} 练；No-train，
型推理效果的影响，本节对RLPTransE做了消融实验分 不使用样本集合训练，即使用初始化参数。不同epoch
析。将RL智能体直接从多步推理策略网络开始推理任 次数下的实验结果如表5所示。
务，即在原方法的基础上去掉单步择优策略网络训练任
表5 对比实验结果
务，得到模型RLPTransE-part，使用和RLPTransE相同的
Table 5 Comparative experimental results
训练集和测试集对该模型进行训练和测试。消融实验
模型 10 20 30 40 50 平均值
的结果如表4所示。两个模型的测试次数统一设为1。
All-train 0.9408 0.9406 0.9406 0.9401 0.9412 0.9407
表4 预训练消融实验结果 Pos-train 0.7860 0.7867 0.7862 0.7864 0.7861 0.7863
Table 4 Pre-training ablation experimental results No-train 0.0093 0.0095 0.0092 0.0095 0.0093 0.0093
单步择优策 多步推理策 如表5所示，使用D train 训练的All-train在单步选择
模型 MAP（LP/FP）
略网络 略网络 成功率上的均值达到了94.07%，Pos-train结果达到了
RLPTransE-part × 0.727/0.471 78.65%，而No-train的选择成功率几乎为0。该实验充
√
RLPTransE 0.801/0.589 分验证单步择优策略网络对本方法具有重要支撑作用。
√ √
如表4所示，RLPTransE-part模型在链接预测和事 3.5 推理规则的分析
实预测的实验结果都不及RLPTransE模型，主要原因是 为了分析本文方法对知识推理可解释性的增强作
缺乏单步择优策略网络训练的方法，单步选择有效路径 用，从RL智能体在NELL-995数据集上挖掘出的推理
能力不足，路径的搜索能力弱，直接影响多步推理效果。 规则中选择部分任务结果，如表6所示。
表6 RL智能体发现的推理规则
Table 6 Inference formulas found by RL Agent
关系 推理规则
playsforteam−>teamhomestadium
athletehomestadium belongstoorganization−>leaguestadiums
ledsportsteam−>teamplayssport−>sportusesstadium
athletehomestadium−>teamhomestadium_inv
athleteplaysforteam athleteplayssport−>teamplayssport_inv
athleteplaysinleague−>belongstoleague_inv−>belongstoorganization
playsforteam−>teamplaysinleague
athletehomestadium−>leaguestadiums_inv
athleteplaysinleague
playssport−>teamplayssport_inv−>teamplaysinleague
playsforteam−>teamplaysagainstteam−>teamplaysinleague
playsforteam−>teamplayssport
athleteplayssport homestadium−>sportusesstadium_inv
playsinleague−>teamplaysinleague_inv−>teamplayssport
haswife−>personbornincity
hashusband−>personbornincity
personborninlocation
personbornincity−>mutualproxyfor_inv
graduatedfromuniversity−>graduatedfromuniversity_inv−>personbornincity
teamhomestadium−>leaguestadiums_inv
teamplaysinleague subpartoforganization−>agentactsinlocation−>leaguestadiums_inv
teamplaysincity−>proxyfor−>leaguestadiums_inv
teamhomestadium−>sportusesstadium_inv
teamplayssport teamplaysincity−>stadiumlocatedincity_inv−>sportusesstadium_inv
teamplaysinleague−>athleteplaysinleague_inv−>athleteplayssport 196 2021，57（19） ComputerEngineeringandApplications计算机工程与应用
如表6所示，对于任务关系“athleteplaysinleague”， [6] BORDES A，USUNIER N，GARCIA-DURAN A，et al.
对应的推理规则为“playsforteam−>teamplaysinleague” Translating embeddings for modeling multi-relational
和“athletehomestadium−>leaguestadiums_inv”，即运动 data[C]//Advances in Neural Information Processing Sys-
tems，2013：2787-2795.
员效力的球队所属的联赛就是运动员效力的联赛和运
[7] WANG Z，ZHANG J，FENG J，et al.Knowledge graph
动员主场所注册的联赛就是运动员效力的联赛。其他
embedding by translating on hyperplanes[C]//Proceedings
任务的说明类似，不再逐一展开分析。因此，分析结果
of the 28th Conference on Artificial Intelligence（AAAI），
表明，本文方法对于增强知识推理的可解释性具有重要
2014：1112-1119.
支撑。
[8] 阮小芸，廖健斌，李祥，等.基于人才知识图谱推理的强
化学习可解释推荐研究[J].数据分析与知识发现，2020，
4 结束语 5（6）：36-50.
本文提出了一种融合知识表示和深度强化学习方 RUAN X Y，LIAO J B，LI X，et al.Interpretable recom-
法RLPTransE。该模型通过知识表示方法，将知识图谱 mendation of reinforcement learning based on talent
knowledge graph reasoning[J].Data Analysis and Knowl-
映射到含有三元组语义信息的向量空间中，然后在该空
edge Discovery，2020，5（6）：36-50.
间建立强化学习环境，将知识推理成功转化为马尔可夫
[9] LIN Y，LIU Z，SUN M，et al.Learning entity and relation
序列决策过程。基于有监督的单步择优策略网络的训
embeddings for knowledge graph completion[C]//Proceedings
练和基于奖励函数的多步推理策略网络的训练，使得
of the 29th Conference on Artificial Intelligence，2015：
RL智能体在推理过程中挖掘出高质量推理规则，从而
2181-2187.
完成大规模知识图谱推理任务。在公开数据集上的对
[10] JI G，HE S，XU L，et al.Knowledge graph embedding via
比实验表明，本文方法提升了推理性能，特别是大规模
dynamic mapping matrix[C]//Proceedings of the 53rd
知识图谱推理任务。本文还通过消融实验对单步择优 Annual Meeting of the Association for Computational
策略网络对本文方法的影响做了进一步分析。通过对 Linguistics and the 7th International Joint Conference on
挖掘出来的推理规则分析，验证了本文方法对知识推理 Natural Language Processing，2015：687-696.
可解释性具有增强作用。 [11] EBISU T，ICHISE R.Toruse：Knowledge graph embed-
ding on a lie group[C]//Proceedings of the 32nd AAAI
Conference on Artificial Intelligence，2018：1819.
参考文献：
[12] SUN Z Q，DENG Z H，NIE J Y，et al.Rotate：Knowledge
[1] BOLLACKER K，EVANS C，PARITOSH P，et al.Freebase：
graph embedding by relational rotation in complex
A collaboratively created graph database for structuring
space[J].arXiv：1902.10197，2019.
human knowledge[C]//Proceedings of 2008 ACM SIGMOD
[13] ZHANG S，TAY Y，YAO L N，et al.Quaternion knowl-
International Conference on Management of Data，2008：
edge graph embeddings[C]//Proceedings of the 33rd Con-
1247-1250.
ference on Neural Information Processing Systems，
[2] AUER S，BIZER C，KOBILAROV G，et al.DBpedia：A
2019：2735.
nucleus for a Web of open data[C]//Proceedings of the
[14] 刘峤，李杨，段宏，等.知识图谱构建技术综述[J].计算机
6th Int’l Semantic Web Conference，2007：722-735.
研究与发展，2016，53（3）：582-600.
[3] CARLSON A，BETTERIDGE J，KISIEL B，et al.Toward
LIU Q，LI Y，DUAN H，et al.Knowledge graph con-
an architecture for never-ending language learning[C]//
struction techniques[J].Journal of Computer Research and
Proceedings of the 24th AAAI Conference on Artificial
Development，2016，53（3）：582-600.
Intelligence，2010：1306-1313.
[15] LAO N，COHEN W W.Relational retrieval using a
[4] 张仲伟，曹雷，陈希亮，等.基于神经网络的知识推理研究
combination of path-constrained random walks[J].Machine
综述[J].计算机工程与应用，2019，55（12）：8-19.
Learning，2010，81（1）：53-67.
ZHANG Z W，CAO L，CHEN X L，et al.Survey of
[16] LAO N，MITCHELL T，COHEN W W.Random walk
knowledge reasoning based on neural networks[J].Com-
inference and learning in a large scale knowledge base[C]//
puter Engineering and Applications，2019，55（12）：8-19.
Proceedings of the Conference on Empirical Methods
[5] 官赛萍，靳小龙，贾岩涛，等.面向知识图谱的知识推理研
in Natural Language Processing，Association for Com-
究进展[J].软件学报，2018，29（10）：2966-2994.
putational Linguistics，2011：529-539．
GUAN S P，JIN X L，JIA Y T，et al.Knowledge reasoning
[17] GARDNER M，MITCHELL T.Efficient and expressive
over knowledge graph：A survey[J].Journal of Software，
knowledge base completion using subgraph feature
2018，29（10）：2966-2994. extraction[C]//Proceedings of the Conference on Empirical 宋浩楠，等：融合知识表示和深度强化学习的知识推理方法 2021，57（19） 197
Methods in Natural Language Processing，2015：1488-1498. forcement learning method for knowledge graph rea-
[18] GARDNER M，TALUKDAR P，KRISHNAMURTHY J， soning[J].arXiv：1707.06690，2017.
et al.Incorporating vector space similarity in random [26] DAS R，DHULIAWALA S，ZAHEER M，et al.Go for a
walk inference over knowledge bases[C]//Proceedings of walk and arrive at the answer：Reasoning over paths in
the 2014 Conference on Empirical Methods in Natural knowledge bases using reinforcement learning[J].arXiv：
Language Processing（EMNLP），2014：397-406. 1711.05851，2017.
[19] DAS R，NEELAKANTAN A，BELANGER D，et al.Chains [27] LIN X V，SOCHER R，XIONG C.Multi-hop knowledge
of reasoning over entities，relations，and text using
graph reasoning with reward shaping[C]//Proceedings of
recurrent neural networks[J].arXiv：1607.01426，2016.
the 2018 Conference on Empirical Methods in Natural
[20] CHEN W，XIONG W，YAN X，et al.Variational knowl-
Language Processing，2018.
edge graph reasoning[J].arXiv：1803.06581，2018.
[28] LI R，CHENG X.DIVINE：A generative adversarial
[21] LIN Y，LIU Z，LUAN H，et al.Modeling relation paths
imitation learning framework for knowledge graph
for representation learning of knowledge bases[C]//Pro-
reasoning[C]//Proceedings of the 2019 Conference on
ceedings of the 2015 Conference on Empirical Methods
Empirical Methods in Natural Language Processing and
in Natural Language Processing，2015：705-714.
the 9th International Joint Conference on Natural Lan-
[22] 陈海旭，周强，刘学军.一种结合路径信息和嵌入模型
guage Processing（EMNLP-IJCNLP），2019.
的知识推理方法[J].小型微型计算机系统，2020，41（6）：
[29] WANG H，LI S，PAN R，et al.Incorporating graph attention
1147-1151.
mechanism into knowledge graph reasoning based on
CHEN H X，ZHOU Q，LIU X J.Knowledge graph rea-
deep reinforcement learning[C]//Proceedings of the 2019
soning combining path information and embedding
Conference on Empirical Methods in Natural Language
model[J].Journal of Chinese Computer Systems，2020，
Processing and the 9th International Joint Conference on
41（6）：1147-1151.
Natural Language Processing（EMNLP-IJCNLP），2019.
[23] JIA Y，WANG Y，JIN X，et al.Path-specific knowledge
[30] WILLIAMS R J.Simple statistical gradient-following
graph embedding[J].Knowledge-Based Systems，2018，
algorithms for connectionist reinforcement learning[J].
151：37-44．
[24] WU Y B，ZHU D H，LIAO X W，et al.Knowledge Machine Learning，1992，8（3/4）：229-256.
graph reasoning based on paths of tensor factorization[J]. [31] TOUTANOVA K，CHEN D，PANTEL P，et al.Representing
Pattern Recognition and Artificial Intelligence，2017， text for joint embedding of text and knowledge bases[C]//
30（5）：473-480． Proceedings of the 2015 Conference on Empirical Methods
[25] XIONG W，HOANG T，WANG W Y.Deeppath：A rein- in Natural Language Processing，2015：1499-1509. --------------------------------------------------------------------------------- ComputerEngineeringandApplications计算机工程与应用 2021，57（15） 133
融合社交关系和局部地理因素的兴趣点推荐
夏 英，张金凤
重庆邮电大学 计算机科学与技术学院，重庆 400065
摘 要：兴趣点（Point-Of-Interest，POI）推荐是基于位置社交网络（Location-Based Social Network，LBSN）中一项重
要的个性化服务，可以帮助用户发现其感兴趣的POI，提高信息服务质量。针对POI推荐中存在的数据稀疏性问
题，提出一种融合社交关系和局部地理因素的POI推荐算法。根据社交关系中用户间的共同签到和距离关系度量
用户相似性，并基于用户的协同过滤方法构建社交影响模型。为每个用户划分一个局部活动区域，通过对区域内
POIs间的签到相关性分析，建立局部地理因素影响模型。基于加权矩阵分解挖掘用户自身偏好，并融合社交关系
和局部地理因素进行POI推荐。实验表明，所提出的POI推荐算法相比其他方法具有更高的准确率和召回率，能
够有效缓解数据稀疏性问题，提高推荐质量。
关键词：位置社交网络；兴趣点推荐；社交关系；局部地理因素；加权矩阵分解
文献标志码：A 中图分类号：TP311 doi：10.3778/j.issn.1002-8331.2007-0172
POI Recommendation Fusing Social Relations and Local Geographic Factors
XIAYing,ZHANGJinfeng
School of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing
400065,China
Abstract：POI recommendation is an important personalized service in Location-Based Social Network（LBSN）, which
can help users discover POIs and improve the quality of information services.Aiming at the problem of data sparsity in
POI recommendation, this paper proposes a POI recommendation algorithm combining social relationship and local
geographic factors. This algorithm measures user similarity based on the common check-in and distance relationships
among users in the social relationship, and builds a social model through user collaborative filtering.Alocal activity area
for each user is divided, and the sign-in correlation is analyzed to establish a local geographic factor model. Based on
weighted matrix decomposition, users’own preferences are mined, and social relationships and local geographic factors for
POI recommendation are integrated. Experiments on the Gowalla dataset show that the proposed POI recommendation
algorithm has higher accuracy and recall rate than other methods, which can effectively alleviate the problem of data
sparsityandimproverecommendationperformance.
Keywords：Location-BasedSocialNetworks（LBSN）;Point-Of-Interes（t POI）recommendation;socialrelationship;local
geographicfactors;weightedmatrixfactorization
目前，随着智能手机、移动互联网等技术的发展， 律，有利于提高个性化POI推荐服务质量。
LBSN得到广泛应用，如国外的Gowalla、Foursquare，国 在LBSN平台，POI的规模庞大且分布广泛，而每个
内的大众点评、美团等。在LBSN平台，用户可对当前 用户访问并签到过的POI往往很少，这使得用户签到数
访问的POI（如餐厅、书店、旅游景点等）进行签到、评论 据十分稀疏，给POI推荐带来挑战。
等操作，并能与社交好友分享自己的签到信息。在 针对用户签到数据的稀疏性问题，本文提出基于社
LBSN除了用户签到信息，还包含社交关系、兴趣点、用 交关系和局部地理因素的POI推荐算法，通过融合社交
户评论等海量数据，充分挖掘这些数据，可以更好地分 关系、地理位置信息来丰富有效数据，提高推荐质量。
析用户的签到行为，把握用户群体兴趣特征和访问规 本文的主要贡献有以下三点：
基金项目：国家自然科学基金（41971365）；重庆市基础与前沿研究计划（cstc2019jcyjmsxm0131）；重庆市研究生科研创新项目（CYS20277）。
作者简介：夏英（1972—），女，博士，教授，CCF会员，研究领域为数据库、数据挖掘、云计算；张金凤（1995—），通信作者，女，硕士，
研究领域为社交网络分析、推荐系统、数据挖掘，E-mail：381877677@qq.com。
收稿日期：2020-07-10 修回日期：2021-05-28 文章编号：1002-8331（2021）15-0133-07 134 2021，57（15） ComputerEngineeringandApplications计算机工程与应用
（1）在构建社交关系影响模型时，综合考虑用户间 签到信息的用户难以构建社交影响模型；在分析地理因
的共同签到和距离关系，提出一种用户相似性度量方 素影响时，现有计算全局POIs间地理相关性的方法不
法，减少相似性计算误差。 能充分剖析每个用户的地理偏好。因此，本文提出融合
（2）在构建地理因素影响模型时，通过为每个用户 社交关系和局部地理因素的POI推荐算法，可以有效地
划分一个局部活动区域，分析用户所属区域内尚未访问 提高推荐的准确率和召回率。
POIs间的签到相关性，更加充分地剖析出每个用户签
到的地理偏好。 2 兴趣点推荐模型
（3）在进行兴趣点推荐时，将上述考虑的社交关系 POI推荐的任务是给用户推荐一个其感兴趣但尚
和局部地理因素融合到加权矩阵分解模型中，构建一个 未访问过的POIs列表。本章通过深入分析社交关系和
更加符合用户偏好的POI推荐模型，在一定程度上缓解 地理因素对用户签到行为的影响，构建更加符合用户偏
了数据稀疏性问题。实验表明，本文所提出的算法具有 好的POI推荐模型。
更高的准确率和召回率。 2.1 相关符号及定义
为方便后续讨论，表1给出了相关符号及其含义。
1 相关工作
同时，对签到矩阵和签到热点进行了定义。
POI推荐是LBSN中重要的个性化服务，旨在为用
表1 相关符号描述
户推荐符合他们兴趣但尚未访问过的POI列表。目前， Table 1 Relevant Symbols description
针对位置社交网络的POI推荐已展开大量的研究工作，
符号 相关描述
一些特定场景的应用也开始大量涌现，如餐厅推荐[1]、旅 U,I 所有用户集合，所有POI集合
游路线推荐[2]等。 u,i 用户u∈U，POIi∈I
R 用户签到矩阵
目前，大多数的POI推荐都是通过用户签到数据结
C 签到矩阵R对应的0，1矩阵
合丰富的上下文信息来缓解数据稀疏性，挖掘用户对尚
S 用户对POI的社交偏好矩阵
未访问POIs的偏好程度。如Cheng等人[3]采用多中心
G 用户对POI的地理偏好矩阵
高斯分布来建模POIs间距离分布，并结合社交关系进 E 用户对POI的最终偏好矩阵
行POI推荐。Zhang等人[4]为避免所有用户采用统一分 P 用户隐藏特征矩阵
Q POI隐藏特征矩阵
布造成的误差，采用核密度估计模拟任意两个POIs间
K 隐藏特征矩阵维度
的距离分布，构建地理因素影响模型。Zhang等人[5]从
W 签到矩阵R对应的权重矩阵
位置序列中挖掘顺序模式，并将序列影响、社交影响和
定义1（签到矩阵）根据用户历史签到记录，构建签
地理因素影响融合在统一的推荐框架中。Yali等人[6]在
到矩阵R ，矩阵中每个元素r 表示用户u对POIi
基于朋友协同过滤基础上，综合考虑社交关系和地理位 |U|×|I| ui
的签到次数。
置特征，提出个性化的兴趣点推荐模型。Zhang等人[7]
定义2（签到热点）用户u签到次数最高的POI。
对标签、社交和地理因素分别进行建模，并将它们融合
2.2 社交关系影响模型的构建
到一种矩阵分解方法中。Zhang等人[8]利用BPR模型对
在LBSN中，用户的签到行为在一定程度上受到其
矩阵分解进行优化，并结合用户社交关系和地理位置信
息进行POI推荐。 社交关系的影响，进而促使用户访问一些未去过的
POIs。例如，在日常生活中去过一个体验很好的餐厅或
除此之外，也有很多研究利用其他上下文信息进行
POI推荐，如Gao等人[9]将一天划分为多个时间段，分别 书店后，很可能会邀请或推荐自己的朋友前去，这些都
构建不同时间段下的User-POI签到矩阵，然后使用矩阵 可能使得用户在相同的POI产生共同签到，社交用户间
分解法获取不同时间段的用户偏好。Zhang等人[10]对用 存在一定的行为相似性。因此，考虑用户的社交关系对
户评论进行语义分析和情感计算，根据用户的情感倾向
用户签到行为的影响有利于提高POI推荐质量。
预测用户偏好。Wu等人[11]将POI流行度特征融入基于 对于用户尚未访问过的POIs，本文使用基于用户的
用户协同过滤方法中，并结合社交关系和地理因素进行
协同过滤方法[12]计算社交关系信息对用户签到行为的
POI推荐。 影响程度，其计算公式如下：
尽管通过融合丰富的上下文信息可以有效缓解数 ∑ sim uv×c vi
据稀疏性问题，但现有融合上下文信息的POI推荐算法 s ui= v∈F ∑u
sim
（1）
uv
中仍存在以下一些问题：在研究社交关系影响时，用户 v∈Fu
相似性影响因素选取往往比较单一，对于那些拥有较少 其中，c 的定义如下：
vi 夏 英，等：融合社交关系和局部地理因素的兴趣点推荐 2021，57（15） 135
ì1, r >0 sim =(1-α)sim +αsim （8）
c =í vi （2） uv c d
vi î0, r vi=0 其中，α为调节用户签到相似度和距离相似度影响权重
其中，s 表示用户u对POIi的偏好程度。 F 表示用 的参数。
ui u
户u在社交网络上的所有朋友集合，用户v是用户u的 将式（8）代入式（1）即可得到在社交关系影响下用
社交好友，c 表示好友v对POIi的签到情况，sim 表 户对兴趣点的社交偏好矩阵S。
vi uv
示用户u和v的相似度。 2.3 局部地理因素影响模型的构建
对于式（1）中的用户相似度sim uv，不同的研究采用 在位置社交网络中，地理位置信息是其特有的语境
的方法不同[3-6]。大多数研究中，只考虑了基于共同签到 信息，是提升POI推荐质量的重要因素。目前，考虑地
的用户相似度，这对那些拥有较少签到信息的用户无法 理因素影响的模型主要是通过分析用户所有签到POIs
有效计算其社交偏好。因此，本文考虑在以往基于共同 的分布情况，通过POIs间距离关系计算用户对POIs的
签到的相似性研究基础上，同时通过用户间距离关系来 签到概率，如常用的高斯分布[3]及核密度估计[4]等。为
度量用户间的兴趣差异，减小用户相似度的计算误差。 了进一步研究地理因素的影响，这里发现用户签到呈现
一方面，通常认为用户间的共同签到越多，他们的 出空间聚类现象[15]，表明用户喜欢访问邻近POIs，如用
偏好就越相似。在基于行为相关性的相似性度量方法 户去某个城市旅行，往往会对相邻区域集中的POIs都
中，Jaccard方法[13]在计算效率和推荐准确率上效果更
进行访问，邻近POIs间的签到情况具有一定的关联
好，基于Jaccard方法计算用户签到相似度公式如下： 性[16]。因此，本文考虑为每个用户划分一个局部活动区
sim
=|R u⋂R v|
（3）
域，充分剖析区域内尚未访问POIs间的签到相关性，构
c |R ⋃R |
u v 建更加符合用户偏好的局部地理因素影响模型。
其中，R u和R v分别表示用户u和v签到的POIs集合。 步骤1 划分用户活动区域
另一方面，考虑到相距较近的用户拥有更多的共 首先，找到用户u的签到热点，然后为用户u划分
享兴趣点，会产生较多的共同签到。因此，对于距离越 一个距离签到热点半径为 β的局部活动区域。
近的用户，其签到行为的相似度越高。本文通过改进
步骤2 寻找区域内用户尚未访问的POIs
Sigmod函数计算用户距离相似度。
在步骤1所划分用户活动区域内，寻找用户u尚未
Sigmod函数是常见的S型函数，公式定义如下：
访问的POIs集合，分析与集合中POIi相距小于γ的邻
1
S(x)= （4） 居POIs的签到情况。
1+e-x
步骤3 计算地理偏好程度
该函数连续、光滑、严格单调，关于点（0，0.5）中心
对称，在区间[-∞,+∞]上呈非线性增长。基于上述假 研究发现，用户往往会对邻近POIs进行集中访问，
针对邻近POIs的签到影响已展开相关研究[16]。其中，
设中距离相似度随着用户间距离应呈递减状态，因此考
Hossein等人[17]认为用户对邻近POIs的签到数量会对用
虑改进Sigmod函数来衡量基于用户距离的相似度，改
户u签到POIi产生一定影响，并构建出一个更加符合
进后的用户距离相似度计算公式如下：
用户偏好的地理偏好模型。因此，本文根据邻居POIs
2
sim = （5）
d 1+edis(u,v) 的签到情况，采用文献[17]中的地理偏好定义，计算用
其中，dis(u,v)表示用户u与v间的距离，其根据用户签 户u对POIi的签到概率，公式如下：
到热点的经纬度信息，利用Haversin e 方法[14]计算得 Nu
g =1- i （9）
出。计算公式如下：
ui |L u|
dis(u,v) 其中，Nu表示用户u对POIi所有邻居POIs的签到数
hav( )=hav(φ -φ )+cosφ ⋅ i
R 2 1 1
量，L 表示用户u曾访问过的所有POIs集合。
u
cosφ ⋅hav(σ -σ ) （6）
2 2 1 2.4 融合社交关系和局部地理因素的兴趣点推
1-cosθ
hav(θ)= （7） 荐模型
2
其中，R为地球半径，φ 和φ 分别表示用户u和v签 2.4.1 基础模型
1 2
到热点的纬度，σ 和σ 分别表示用u和v签到热点的 在LBSN中，用户社交关系、地理位置等上下文信
1 2
经度。 息都会影响用户的签到行为，但最主要的是从用户历史
综合以上设计，本文对用户签到相似度和距离相似 签到数据中反映出来的用户自身偏好。在POI推荐中，
度行线性加权，得到用户u和v的最终相似度，计算公 矩阵分解技术[18]常用于挖掘用户的自身偏好。但由于
式如下： User-POI签到矩阵中只能观察到用户访问过的POIs，对 136 2021，57（15） ComputerEngineeringandApplications计算机工程与应用
于那些用户尚未访问过的POIs会产生大量的缺失项， 1. for eachu∈Udo
因此无法使用一般的矩阵分解技术来构建用户自身偏 2. for eachi∈Ido
好模型。Hu等人[19]首次在大规模隐式数据上提出加权 3. 由式（1）计算社交偏好程度s ui
矩阵分解（Weighted Matrix Factorization，WMF）模型， 4. 由式（9）计算地理偏好程度g ui
该模型通过对用户已访问的POIs分配较大权重，对尚 5.由式（12）计算权重系数w ui
6. End for
未访问的POIs分配一个较小权重来解决User-POI签到
7. End for
矩阵中存在的缺失项问题。
8. for each u∈U do
在POI推荐中，WMF方法将User-POI签到矩阵分
9. 更新矩阵P
解为两个低维隐藏特征矩阵 P 和Q ，用户对POI
m×k n×k
10. End
的自身偏好矩阵即为两个隐藏特征矩阵的内积。本文
11. for eachi∈Ido
基于WMF模型构建用户自身偏好模型，其目标函数定
12. 更新矩阵Q
义如下：
13.End
|U| |I|
f=∑∑w (c -p Tq)2+λ(p 2 +q 2 ) （10） 14.由式（14）计算用户对POI的最终偏好矩阵E
ui ui u i u i
u=1i=1 15.根据矩阵元素e ui排序，为用户推荐 POIs列表
ì1, r >0
c =í ui （11）
ui î0, r ui=0 3 实验评估
其中，p 和q 分别表示用户 u与POIi对应的隐特征
u i 3.1 数据集
向量，λ表示正则化系数。w 表示每个用户签到次数
ui 实验选取数据集Gowalla[21]，Gowalla收集了2009年
r 对应的权重，本文采用文献[20]中权重设置方法，加
ui 2月至10月期间的所有签到数据、用户社交关系和POI
权矩阵w的权重系数设置如下：
信息。为使实验数据更加有效，将数据集中用户和POI
w =1+lb(1+r /ε) （12）
ui ui 签到数量少于15条的低价值数据去除。处理后的标准
其中，ε是用来控制权重系数随用户访问POI次数增长
数据集共有5628个用户，31803个POIs和620683条签
的速率。
到记录，以及46001条社交关系。
2.4.2 模型融合
3.2 评价指标
在2.4.1节中，WMF模型根据用户的签到频次信息
实验选取常用的准确率(Precision)和召回率(Recall)
提取用户对POI的自身偏好，但没有考虑社交关系和地
作为评价指标来衡量推荐算法的性能，其定义分别
理位置等影响因素。本文在WMF模型上进行改进，将
如下：
上述考虑的社交关系和局部地理信息融合到WMF模
型中，构建一个更加符合用户偏好的POI推荐模型 Precision= |U1 |∑|U||R |u R⋂T
|
u| （15）
u=1 u
SLGMF。该模型的目标函数如式（13）所示：
|U| |I| Recall=
1 ∑|U||R u⋂T u|
（16）
f=∑∑w (c -e )2+λ(p 2 +q 2 ) （13） |U| |T |
ui ui ui u i u=1 u
u=1i=1 其中，|U|表示用户数量，R 表示为用户u推荐的POIs
e =p Tq +s +g （14） u
ui u i ui ui 列表，T 表示用户u曾访问过的POIs列表。
其中，e 表示用户 u 对POI i 的最终偏好，p 2 和 u
ui u 3.3 对比方法与参数设置
q 2 分别表示用户u和POIi的正则化项，加入目的是 为了验证所提SLGMF算法的性能，实验选取两种
i
为了防止过拟合。 均融合社交关系和地理因素的POI推荐算法：MGMPFM[3]
本文目标函数采用交替最小二乘法进行优化，其主 和LORE[5]。另外，为了考察不同因素对POI推荐的影
要思想是先依次固定矩阵 P ，优化矩阵Q，然后再固定 响，本文将SLGMF算法拆分为仅融合社交关系的推荐
矩阵Q，优化矩阵 P ，反复交替，不断修正 p和q分量， 算法S-MF和仅融合局部地理因素的推荐算法LG-MF，
获得最优矩阵 P 和矩阵Q。 并进行自身对比。
SLGMF模型的构建如算法2所示。 MGMPFM：利用多中心高斯模型建模地理因素影
算法2 SLGMF模型构建 响，在概率矩阵分解基础上融合社交和地理位置信息进
输入：用户集U ，用户签到集R，用户社交信息，地理位 行POI推荐。
置信息 LORE：从用户签到的位置序列中挖掘出序列模式，
输出：为用户推荐的Top-N POIs列表 并融合社交和地理因素进行POI推荐。 2021，57（15）
S-MF：本文提出的模型，仅融合社交关系信息的推 取何值，SLGMF算法在准确率和召回率上均有所提升，
荐算法。 表明了本文所提出SLGMF算法的有效性。
LG-MF：本文提出的模型，仅融合地理位置信息的 另外，本文将SLGMF模型拆分为仅融合社交信息
推荐算法。 的POI推荐模型和仅融合地理位置信息的POI推荐模
SLGMF：本文提出的模型，基于加权矩阵分解，综 型，通过实验分析融合单一上下文信息的推荐效果，结
合考虑社交关系和局部地理因素的推荐算法。 果如图1和图2所示。当为用户进行Top-5推荐时，在准
在参数设置上，所选用对比模型应尽量与原文献保 确率上，SLGMF算法相对S-MF算法提升了14.6%，相
持一致，使各个算法性能达到最优。对于本文提出的 对LG-MF算法提升了11.2%。在召回率上，SLGMF算
SLGMF模型，分别设置隐藏特征矩阵维度 K=25，用 法相对于S-MF算法提升了24.3%，相对于LG-MF算法
户相似性影响因子α=0.6，地理因素影响因子 β=30， 提升了22.8%。这说明本文在加权矩阵分解基础上融
γ=12，上述参数的取值使得推荐效果达到最优。另 合多种上下文信息，确实可以有效地缓解数据稀疏性问
外，地球半径R取平均值为6371。 题，提高推荐性能，并且融入有效的上下文信息越多，推
3.4 实验结果与分析 荐效果越好。除此之外，对比S-MF和LG-MF算法可以
本文在相同数据集上对各个 POI 推荐算法进行 发现，仅融合地理因素的LG-MF推荐性能要优于仅融
Top-N（N=5，10，15，20，25，30）推荐，图1和图2展示了 合社交因素的S-MF，这表明地理因素对用户签到行为
Top-N推荐的准确率和召回率。可以观察到准确率随 的影响要高于社交因素。
着 N 的增大而减小，召回率随着 N 的增大而增大。这 3.5 模型参数的影响
是由于返回的POIs越多，越有可能发现更多用户愿意 在2.4.1节中构建用户自身偏好模型时，通过WMF
访问的POIs。 将用户签到矩阵分解为两个维度为 K 的隐藏特征矩阵
P和Q，参数K的值决定用户对POI的自身偏好程度。
MGMPFM
LORE 本节选取不同的 K 值，对用户进行Top-5推荐，推荐结
0.05 S-MF
果如图3所示。可以看出，当维度 K=25时，SLGMF推
LG-MF
0.04 SLGMF 荐性能最好，且随着 K 的不断增加，推荐效果开始呈下
降状态，这是由于模型已经出现过拟合的原因。
0.03
0.02
0.01
在式（8）中计算用户最终相似度时，参数α决定着
距离相似度和签到相似度的影响程度。为了探究用户
间距离和共同签到对用户签到行为的影响，实验选取不
同的 α值对用户 u 进行Top-5推荐，结果如图4所示。
可以看出，当α=0.6时，推荐效果最佳，同时也表明用
户签到行为相似度受用户间距离的影响更大。
在2.3节构建局部地理因素影响模型时，为每个用
图1和图2可以看出，对比MGMPFM和LORE这两 户划分一个局部活动区域，参数 β是用来控制用户活动
种均融合社交关系和地理因素的POI推荐算法，无论 N 范围，参数 γ 用来判别区域内尚未访问POI i 的邻居
N@noisicerP
5 10 15 20 25 30
N
图1 推荐的准确率
Fig.1 Recommendation precision
0.10
MGMPFM
0.09 LORE
0.08 S-MF
LG-MF
0.07
SLGMF
0.06
0.05
0.04
0.03
0.02
0.01
N@llaceR
0.060
0.055
0.050
0.045
Precision@5
0.040 Recall@5
0.035
0.030
0.025
0.020
0 10 20 30 40 50
K
图3 参数K对准确率和召回率的影响
Fig.3 Effect of parameters k on precision and recall
5 10 15 20 25 30
N
图2 推荐的召回率
Fig.2 Recommendation recall
llaceR
&
noisicerP
夏 英，等：融合社交关系和局部地理因素的兴趣点推荐 137 2021，57（15） ComputerEngineeringandApplications计算机工程与应用
0.060 和距离关系提出一种用户相似性度量方法，并基于用户
0.055 的协同过滤得出社交关系对用户签到行为的影响程度；
0.050 然后，为每个用户划分一个局部活动区域，充分剖析区
0.045 Precision@5 域内尚未访问POIs间的签到相关性，计算局部地理因
Recall@5
0.040 素对用户签到行为的影响程度；最后，基于加权矩阵分
0.035 解构建用户自身偏好模型，并结合上述考虑的社交关系
0.030 和局部地理因素，构建更加符合用户偏好的POI推荐模
0.025 型，有效地缓解数据稀疏性问题；在Gowalla数据集上进
0.020 行实验，结果表明所提的SLGMF算法具有良好的推荐
0 0.2 0.4 0.6 0.8 1.0
α 性能。
现实生活中，影响用户签到行为的因素除了本文所
考虑的社交关系和地理因素外，还有诸如时间、评论文
POIs。因此，为探究用户局部签到规律，实验选取不同
本、图像等丰富的上下文信息。在未来的研究工作中，
的 β和γ进行Top-5推荐，分析局部地理因素对用户签
将重点考虑如何利用更多的上下文信息来提高POI推
到行为的影响，推荐结果分别如图5和图6所示。可以
荐性能。
看出，当 β=30，γ=12时，推荐效果达到最佳，也可以
看出用户比较倾向访问离自己较近的POIs。
参考文献：
[1] ZHANG C B，ZHANG H Y，WANG J Q.Personalized
restaurant recommendation method combining group cor-
relations and customer preferences[J].Information Sciences，
2018：128-143.
[2] GUY I，MEJER A，NUS A.Extracting and ranking travel
tips fromuser-generated reviews[C]//Proceedings of the
26th International Conference on World Wide Web，
2017：987-996.
[3] CHENG C，YANG H，KING I.Fused matrix factorization
with geographical and social influence in location-based
social networks[C]//Proceedings of the 26th AAAI Con-
ference on Artificial Intelligence，Toronto，Canada，2012，
12：1.
[4] ZHANG J D，CHOWC Y，LI Y H.iGSLR：personalizedgeo-
social location recommendation：a kernel density estimation
approach[C]//Proceedings of the 21st ACM SIGSPATIAL
International Conference on Advances in Geographical
Information Systems.New York：ACM，2013：334-343.
[5] ZHANG J D，CHOWC Y，LI Y H.Lore：exploiting sequential
influence for location recommendations[C]//Proceedings of
the 22nd ACM SIGSPATIAL International Conference on
Advances in Geographical Information Systems，Dallas，
USA，2014：103-112.
[6] YALI S，FU Z Z，WEN Y L.An adaptive point-of-interest
recommendation method for location-based social net-
works based on user activity and spatial features[J].
4 结束语
Knowledge-Based Systems，2019，163（1）：267-282.
为了解决POI推荐中存在的数据稀疏性问题，本文 [7] ZHANG Z，LIU Y，ZHANG Z.Fused matrix factorization
提出一种融合社交关系和局部地理因素的POI推荐模 with multi-tag，social and geographical influences for
型SLGMF。首先，根据社交关系中用户间的共同签到 POI recommendation[J].World Wide Web，2019，22（3）：
llaceR
&
noisicerP
图4 参数α对准确率和召回率的影响
Fig.4 Effect of parameter α on precision and recall
0.060
0.055
0.050
0.045
Precision@5
0.040
Recall@5
0.035
0.030
0.025
0.020
0 10 20 30 40 50 60
β
llaceR
&
noisicerP
图5 参数β对准确率和召回率的影响
Fig.5 Effect of parameters β on precision and recall
0.060
0.055
0.050
0.045
Precision@5
0.040 Recall@5
0.035
0.030
0.025
0.020
0 2 4 6 8 10 12 14 16
γ
llaceR
&
noisicerP
138
图6 参数γ对准确率和召回率的影响
Fig.6 Effect of parameters γ on precision and recall 夏 英，等：融合社交关系和局部地理因素的兴趣点推荐 2021，57（15） 139
1135-1150. Quantifying geocode location error using GIS methods[J].
[8] 张进，孙福振，王绍卿，等.融合社交关系和地理信息的兴 Environmental Health，2007，6（10）.
趣点推荐模型[J].计算机工程与应用，2020，56（5）：173-178. [15] YE M，YIN P，LEE W，et al.Exploiting geographical
ZHANG J，SUN F Z，WANG S Q，et al.POI recommen- influence for collaborative point-of-interest recommen-
dation algorithm with fusing social relationand geograph- dation[C]//Proceedings of the 34th International ACM
ical information[J].Computer Engineering and Applications， SIGIR Conference on Research and Development in
2020，56（5）：173-178. Information Retrieval，Beijing，China，2011：325-334.
[9] GAO H，TANG J，HU X，et al.Exploring temporal effects [16] LIU Y，WEI W，SUN A.Exploiting geographical neigh-
for location recommendation on location-based social borhood characteristics for location recommendation[C]//
networks[C]//Proceedings of the 7th ACM Conference on Proceedings of the 23rd ACM International Conference
Recommender Systems.New York：ACM，2013：93-100. on Information and Knowledge Management，Shanghai，
[10] 张宜浩，朱小飞，徐传运.基于用户评论的深度情感分析 China，2014：739-748.
和多视图协同融合的混合推荐方法[J].计算机学报， [17] HOSSEIN A R，MOHAMMAD A，SAJAD A.LGLMF：
2019，42（6）：1316-1333. local geographical based logistic matrix factorization
ZHANG Y H，ZHU X F，XU C C.Hybird recommen- model for POI recommendation[C]//The 15th Asia Infor-
dation approach based on deep sentiment analysis of mation Retrieval Societies Conference，Hong Kong，
user reviews and multi-view collaborative fusion[J]. China，2019.
Chinese Journal of Computers，2019，42（6）：1316-1333. [18] BOKDE D，GIRASE S，MUKHOPADHYAY D.Matrix
[11] 吴燕，章韵，陈双双.混合时空和流行度特征的兴趣点推 factorization model in collaborative filtering algorithms：
荐算法[J].计算机工程，2018，44（9）：59-63. a survey[C]//Proceedings of the 4th International Con-
WU Y，ZHANG Y，CHEN S S.Point of interest recom- ference on Advances in Computing，Communication and
mendation algorithm fusing with spatiotemporal and Control，Mumbai，India，2015：136-146.
popularity features[J].Computer Engineering，2018，44（9）： [19] HU Y，KOREN Y，VOLINSKY C.Collaborative filtering
59-63. for implicit feedback datasets[C]//Proceedings of the 8th
[12] MA H，KING I，LYU M R.Learning to recommend with IEEE International Conference on Data Mining，Pisa，Italy，
social ensemble[C]//Proceedings of the 32nd Interna- 2008：263-272.
tional ACM SIGIR Conference on Research and Devel- [20] ZHAO P，XU X，LIU Y，et al.Exploiting hierarchical
opment in Information Retrieval，Boston，USA，2009： structures for POI recommendation[J].IEEE International
203-210. Conference on Data Mining，2017：655-664.
[13] ZHANG X L，FU Y Z，CHU P X.Application of jaccard [21] LIU Y，PHAM T A N，CONG G.An experiment evaluation
similarity coefficient in recommender system[J].Computer of point-of-interest recommendation in location-based
Technology and Development，2015，25（4）：158-161. social networks[J].Proceedings of the VLDB Endowment，
[14] STRICKLAND M J，SIFFEL C，GARDNER B R，et al. 2017，10（10）：1010-1021. --------------------------------------------------------------------------------- 第29 卷 第3期 模式识别与人工智能 Vol．29 No．3
2016年3月 PＲ ＆ AI Mar． 2016
*
融合社交网络信息的协同过滤推荐算法
郭兰杰 梁吉业 赵兴旺
1(山西大学 计算机与信息技术学院 太原030006)
2(山西大学 计算智能与中文信息处理教育部重点实验室 太原030006)
摘 要 在推荐系统中，协同过滤推荐算法往往面临数据集的高度稀疏性和推荐精度有限的问题．为了解决上述
问题，在基于物品的协同过滤推荐框架下，分别在物品相似度的计算和用户对物品的评分预测阶段，利用社交网络
中朋友关系信息选择性地填充评分矩阵中的缺失值，最大化利用评分矩阵中的已有信息，提出融合社交网络信息
的协同过滤推荐算法．最后，在Epinions数据集上的实验表明，文中算法在一定程度上缓解数据稀疏性问题，同时
在评分误差和分类准确率两个指标上优于其它协同过滤算法．
关键词 协同过滤，社交网络，缺失值填充，数据稀疏性
中图法分类号 TP391 DOI 10．16451/j．cnki．issn1003-6059．201603010
引用格式 郭兰杰，梁吉业，赵兴旺．融合社交网络信息的协同过滤推荐算法．模式识别与人工智能，2016，29(3):
281－288．
Collaborative Filtering Ｒecommendation Algorithm
Incorporating Social Network Information
GUO Lanjie，LIANG Jiye，ZHAO Xingwang
( School of Computer and Information Technology，Shanxi University，Taiyuan 030006)
( Key Laboratory of Computational Intelligence and Chinese Information Processing of Ministry of Education，
Shanxi University，Taiyuan 030006)
ABSTＲACT
To solve the problems of high data sparsity and limited recommendation precision of collaborative
filtering recommendation algorithms，a collaborative filtering algorithm incorporating social network
information is proposed under the framework of item-based collaborative filtering recommendation． In item
similarity calculation period and user rating prediction period，social network information is utilized to fill
missing values in rating matrix selectively and thus the existing rating information is utilized as much as
possible． Finally，experiment is conducted on Epinions dataset． Ｒesults show that the proposed algorithm
alleviates the data sparsity problem and outperforms other collaborative filtering algorithms on rating error
and precision．
* 国家自然科学基金项目(No．61573229，61432011，U1435212)、山西省科技基础条件平台建设项目(No．2012091002－0101)、
山西省科技攻关计划项目(No．20110321027－01) 资助
Supported by National Natural Science FoundationofChina(No．61573229，61432011，U1435212)，ConstructionProjectofScience
and Technology Basic Condition Platform of Shanxi Province ( No．2012091002 －0101)，Key Technology Ｒ＆D Program of Shanxi
Province (No．20110321027－01)
收稿日期:2015－05－19;修回日期:2015－10－13;录用日期:2015－10－26
Manuscript received May19，2015; revised October13，2015; accepted October26，2015 282 模式识别与人工智能 29卷
Key Words Collaborative Filtering，Social Network，Missing Value Filling，Data Sparsity
Citation GUO L J，LIANG J Y，ZHAO X W． Collaborative Filtering Ｒecommendation Algorithm Incor-
porating Social Network Information． Pattern Ｒecognition and Artificial Intelligence，2016，
29(3) : 281 －288．
随着信息技术和互联网的飞速发展，人们开始 基于上述考虑，为了克服由于评分信息稀疏性
面临严重的信息过载问题，这使推荐系统在信息获 导致推荐精度较低的问题，在基于物品的协同过滤
取中成为一种重要技术［1］． 推荐系统利用知识发现 推荐框架下，本文提出融合社交网络信息的协同过
技术帮助用户从海量物品中发现自己感兴趣的物 滤推荐算法．该算法分别在物品相似度的计算和用
品，进而进行个性化推荐． 户对物品的评分预测阶段，利用社交网络中朋友关
在已有的推荐技术中，协同过滤［2］是发展较快 系信息填充评分矩阵中的部分缺失值，使评分矩阵
也较为流行的一种方法．然而在实际应用领域中，评 中的已有信息利用达到最大化． 本文算法可有效缓
分信息数据集中用户和物品的维度规模逐渐增大， 解传统协同过滤算法在相似度计算和预测评分阶段
数据的稀疏程度不断增加，导致传统的协同过滤推 由于数据稀疏性引起的邻居数量和可靠性不足而导
荐算法的准确性随着数据集稀疏程度的增加而降 致推荐能力有限的问题． 最后，在真实数据集 Epin-
低［3］．为了解决这一问题，一些学者已从不同角度 ions上与已有的 4 种推荐算法进行的实验分析表
开展一些探索性的研究［4－7］． 冷亚军等［4］针对稀疏 明，本文算法在评分误差和分类准确率两个指标上
评分导致的最近邻搜寻不准确的问题，提出两阶段 优于其它算法．
最近邻选择算法，首先找到用户近邻倾向性高的集
合，然后计算它们之间的等价关系相似性，得到最终 1 相关知识
的最近邻集合，有效提高近邻搜寻的准确性． Wang
等［5］融合基于用户的协同过滤和基于物品的协同
协同过滤推荐算法由 Goldberg 等［2］提出，现已
过滤的思想，并利用相似用户对相似物品的评分进
成为推荐系统中发展最快、应用最广的推荐算法之
行预测，在一定程度上缓解单一协同过滤方法面临
一． 该算法主要利用用户对物品的评分矩阵信息
的数据稀疏问题． Liang 等［6］利用联合聚类方法，聚
Ｒ ，如表1 所示，其中行代表用户，列代表物品，矩
类原始评分矩阵，并融合类别相似性和传统评分相 m×n
阵中元素r 表示用户u对物品i的评分，通常采用
似性，有效缓解数据稀疏性带来的相似性计算不准 u，i
1 ～ 5 分表示，空值代表无评分． 在大部分应用系统
确的问题． Koren 等［7］将原始稀疏评分矩阵分解为
中评分数据稀疏度都在99% 以上，这成为限制传统
低维稠密的潜因子矩阵，解决协同过滤算法对数据
协同过滤算法性能的重要原因之一．
稀疏性敏感的问题． 上述方法虽在一定程度上缓解
评分矩阵的稀疏性问题，但这些研究仅依赖极度稀
表1 原始用户－物品评分矩阵
疏的用户评分信息进行处理，算法性能缺乏一定的
Table1 Original user-item rating matrix
可靠性．
i i i i i … i
1 2 3 4 5 n
在传统的协同过滤推荐算法中，用户是否喜欢
u r r
1 1，1 1，4
目标物品只受个人偏好的影响，并假设用户之间相
u r r r r
2 2，2 2，3 2，5 2，n
互独立．然而在现实生活中，用户的决定是由多方面 u r r r
3 3，1 3，2 3，4
因素共同作用而产生，除了自身原因之外，还会受到 
u r r
身边朋友的影响．近年随着 Web 2．0 技术的快速发 m m，3 m，4
展和日趋成熟，已产生许多诸如用户社交关系、用户
评论转发等社交网络． 社交网络的出现为推荐技术 传统协同过滤算法通常分为两类: 基于模型的
的研究提供新的途径［8］． 已有研究表明，在推荐系 协同过滤算法和基于内存的协同过滤算法． 基于模
统评分预测过程中，如果能合理填充评分矩阵中的 型的协同过滤算法采用机器学习、数据挖掘中的方
缺失值，可提升预测精度［9］． 同时，Tang 等［10］也指 法进行建模，如聚类模型［11］、回归模型［12］、潜在语
出，用户的社交网络信息对于提升推荐系统的性能 义模型［13］、贝叶斯模型［14］ 等，具有良好的可扩展
有着重要的作用． 性．基于内存的协同过滤算法利用整个用户－物品 3期 郭兰杰 等:融合社交网络信息的协同过滤推荐算法 283
评分矩阵进行推荐． 一般分为基于用户的协同过滤 的协同过滤推荐算法．
算法和基于物品的协同过滤算法［1］． 从基于物品协
同过滤的角度来说，算法过程主要分为两个阶段． 2 融合社交网络信息的协同过滤
1) 邻居物品的形成． 首先基于评分信息，计算
推荐算法
物品i与其它物品的相似度，然后从大到小排序，选
择前k个物品作为物品i的邻居．常用的相似度度量
方法为皮尔逊相似度［8］，定义如下: 通过上述分析，在基于物品的协同过滤推荐算
sim( i，j) = 法的框架下，将社交网络信息融入推荐过程中，通过
对评分矩阵中的缺失值进行有选择地填充，缓解数
∑ (r －r)·(r －r)
u，i i u，j j
u∈U(i)∩U(j) ， 据稀疏性的问题，达到提高协同过滤算法推荐准确
槡∑ (r
u，i
－r i)2· 槡∑ (r
u，j
－r j)2 度的目的．下面将研究如下两个问题:1)选择哪些缺
u∈U(i)∩U(j) u∈U(i)∩U(j)
失值进行预测填充;2) 如何利用社交网络信息对评
(1)
分矩阵中的缺失值进行填充．
其中，U( i)、U( j) 分别表示对物品 i 和物品 j 评分过
2．1 两阶段缺失值填充策略
的用户集合，U( i) ∩U( j) 表示同时对物品i和物品
本节主要研究第一个问题，即选择哪些缺失值
j评分过的用户集合，r 表示用户 u 对物品 i 的评
u，i
位置进行预测填充．为此，本文提出两阶段缺失值填
分，r 和r 分别表示物品i和物品j所有评分的均值．
i j 充策略．
2) 预测评分． 在找到的物品 i 的邻居集合的基
1) 第一阶段． 从式(1)可看到，物品间相似度的
础上，通过目标用户u对物品i邻居的评分值进行加
计算依赖于共同评价过它们的用户． 如果用户量较
权求和，得到最终的预测结果．预测公式如下［15］:
大，计算结果较准确; 如果用户量太小，计算结果就
∑sim( i，j) ·( r － r)
u，j j 缺乏可信度．而由于数据稀疏性，满足要求的用户很
P = r + j∈S(i) ， (2)
u，i i ∑sim( i，j) 少，导致相似度计算不准确，同时物品获得的评分未
j∈S(i)
得到充分利用．因此，针对物品单方面缺失的情况，
其中，S( i) 表示物品i的k近邻集合，Sim( i，j) 表示
如果能给予恰当的填充值，就可最大限度利用物品
式(1) 定义的物品与物品之间的皮尔逊相似度，r
i
已有的评分数据，同时避免引入过多的噪声数据，提
和r 分别表示物品i和物品j所有评分的均值，r 表
j u，j
高相似度计算的可靠性．
示用户u对物品j的实际评分．
例如，表1为推荐系统原始的用户－物品评分矩
近年出现一些融合社交网络信息进行协同过滤
阵，假如要计算物品 i 和 i 的相似度，在传统协同
推荐的方法，弥补传统协同过滤推荐算法在评分数 1 2
过滤中，只能利用u 对它们评分的差异性． 虽然 u
据稀疏性方面存在的缺陷． 例如，Qian 等［16］将用户 3 1
对i 进行评分，但因为未对i 进行评分，因此无法利
个人兴趣、朋友之间的影响力等3 种因素融合到概 1 2
用这部分信息．同理，u 对i 的评分信息面临同样的
率矩阵分解模型中，提高协同算法的推荐精度．Liu 2 2
等［17］利用用户社交关系信息改进传统协同过滤算 问题．在这种情形下，本文利用用户的社交关系信
息，填充u 对i 的评分及u 对i 的评分，达到对已
法寻找最近邻的过程，将评分相似用户和朋友共同 1 2 2 1
作为用户邻居，缓解数据稀疏引起的邻居数量不足 有评分信息的充分利用． 需注意的是，用户 u m 对物
的问题．Yang等［18］利用社交网络数据，将用户圈与 品i 1、i
2
的评分不进行填充，因为该用户对两个物品
物品类别对应，针对特定类别的物品，根据对应用户 都未有评分，对这部分填充会加入更多的噪声，在可
圈的评分信息进行预测，避免对不相关社交关系的 靠性上存在较大不足．
误用． 2)第二阶段．从式(2)可知，在评分预测过程中，
上述研究在一定程度上缓解数据稀疏性对推荐 传统基于物品的协同过滤依赖于用户对相似物品的
准确性的影响，但对社交网络信息仅在计算用户邻 评分．但在实际应用中，由于评分数据的稀疏性，极
居的过程中得到应用，未能与评分信息进行深度融 有可能用户对相似物品无评分，而评分的不是相似
合，进而使其在整个推荐过程中充分发挥作用，同时 物品．因此，针对该情况，如果能对相似物品进行恰
对已有评分信息的利用还很不充分． 为了解决这一 当的缺失值填充，就能充分利用相似度计算的结果，
问题，本文提出社交网络信息与评分矩阵深度融合 给予更准确的预测． 284 模式识别与人工智能 29卷
例如，在表1中，假如要预测用户u 对物品i 的 合，f 表示用户u和用户v的熟悉程度，本文使用流
3 5 u，v
评分，而已计算出与物品i 最相似的是物品i ，但由 行的Salton方法进行计算，r 表示用户v对物品i的
5 3 v，i
于u 未对i 进行评分，在传统方法中将会利用相似 评分值．
3 3
度较小的物品计算．针对这种情况，本文利用用户的 需要注意的是，有时候用户的朋友也未对目标
社交关系信息，填充 u 对 i 的评分值，以期提高算 物品进行过评分．在这种情况下，使用物品均值和用
3 3
法的预测精度． 户均值进行填充，以保证已有的评分数据得到充分
2．2 基于用户社交关系的缺失值预测算法 利用，此时计算公式如下:
r + r
在确定填充位置后，现主要解决如何利用社交 P = i u，
u，i 2
网络信息进行填充的问题．给定用户社交关系网络，
其中r 表示目标物品i的评分均值．
记为G = ( U，E) ，其中 i
综上所述，缺失值填充的计算公式如下:
U = {u ，u ，…，u }
1 2 m
 ∑ f (r －r )
表示用户节点集合，E表示用户之间的关系集合，如  u，v v，i v
r +v∈F(u) ， F(u) 不为空
果( u，v) ∈E，表示用户u与用户v之间有好友关系，  u ∑ f
P =  u，v (4)
相反，表示不存在好友关系．用户u的直接好友集合 u，i

v∈F(u)
可表示为N( u) ，即如果v∈N( u) ，则( u，v) ∈E．
r
i
+r
u， 其它
2
不同于协同过滤中相似度的计算方法，本文使
2．3 基于缺失值填充的协同过滤推荐算法
用熟悉度度量好友之间的亲近程度，基于如下假设:
基于2．2 节提出的用户社交关系的缺失值填充
共同好友越多，用户间越熟悉，而越熟悉的用户越有
算法，通过缓解评分数据的稀疏性，改善传统协同过
可能有相似的兴趣爱好．
滤推荐算法推荐精度较低的问题．算法步骤如下．
2．2．1 熟悉度
算法 基于缺失值填充的协同过滤推荐算法
使用常用的 Salton 指标和大度节点不利指标
输入 用户－物品评分矩阵Ｒ ，用户社交关系信
( Hub Depressed Index，HDI)［19］度量用户间的社交 m×n
息G = ( U，E)
关系强度，以此评价不同熟悉度定义下对最终推荐
输出 目标用户u生成长度为L的推荐列表L( u)
性能的影响．
step1 在评分矩阵Ｒ 找到用户u的未评分
m×n
Salton指标定义如下:
物品集合I'，即评分矩阵中第u行空值对应的物品．
N( u) ∩N( v)
ST = ， (3) step 2 计算物品i与所有物品集合I( iI) 中
u，v
槡k( u) k( v)
物品之间的皮尔逊相似度． 首先利用式(4) 针对评
其中，ST 表示用户 u 和用户 v 的熟悉程度;N( u)
u，v 分向量单方面存在缺失值的情况进行填充，然后利
和N( v) 分别表示用户u和用户v的好友集合;k( u)
用式(1) 进行相似度的计算．
和k( v) 分别表示用户u和用户v的度，即好友数量．
step 3 选择相似度最大的 k 个物品作为目标
HDI定义如下:
物品i的邻居，并根据式(4) 对目标用户未对齐评分
HDI =
N( u) ∩N( v)
， 的物品进行缺失值填充，然后采用式(2) 计算用户u
u，v max( k( u) ，k( v) )
对物品i的预测评分．
其中，HDI 表示用户u和用户 v 的熟悉程度，其余
u，v step 4 循环step 2 ～ step 3，计算用户u对未
符号表示含义与式(3)相同．
评分物品集合I' 中每个物品的预测评分，然后按照
2．2．2 填充缺失值
评分值大小降序排列，选择前L个物品加入到用户u
使用类似基于用户协同过滤的思想，通过融合
的推荐列表L( u) 中．
朋友偏好，代表用户偏好．计算公式如下:
本文算法步骤的关键是在传统的基于物品协同
∑ f ( r － r ) 过滤推荐算法的两个阶段( 物品间相似度计算和预
u，v v，i v
P u，i = r u + v∈F(u) ∑ f ， 测评分) 中，通过引入用户社交网络信息，缓解评分
u，v
v∈F(u) 数据稀疏性带来的问题．在step 2 中，传统协同过滤
其中，P 表示用户u对物品i的填充评分，r 和r 分 算法仅利用稀疏的评分数据计算物品间相似度，往
u，i u v
别表示用户 u 和用户 v 对物品所有评分的平均值， 往会导致相似度计算的不可靠． 本文算法在物品相
F( u) 表示用户u的好友中对物品i评分过的用户集 似度计算之前，对单方面评分缺失的情况利用2．2 3期 郭兰杰 等:融合社交网络信息的协同过滤推荐算法 285
节中提出的方法进行选择性填充，提高物品相似度 户i对物品j的预测评分，N表示测试集中包含的评
计算的可靠性． 同时，在 step 3 中，传统协同过滤算 分数量．
法在找到最近邻后，只能利用用户对其有评分的部 ＲMSE定义为
分，而数据稀疏性导致这部分可用评分极少，导致预 1
ＲMSE = ∑ ( r － r' ) 2，
测结果精度有限．而本文算法在计算之前，采用2．2 槡N i，j i，j
i，j
节中提出的填充方法，针对目标用户对应的缺失评 其中各符号的意义与MAE的相同．MAE和ＲMSE的
分，利用用户好友的评分信息表示，使可利用评分增 值越小，表示预测误差越小，预测精度越高．
加，提高预测精度． 第二类指标度量最终推荐列表的分类准确性．
由于本文实验数据集的评分范围为1 ～5分，因此本
3 实验及结果分析 文认为在测试集中大于3 的评分，表示用户喜欢相
应物品，如果能将这部分物品排到推荐列表前端，则
用户可能对推荐列表更满意． 使用平均准确率
首先从推荐结果的有效性方面对比本文算法与
( Mean Average Precision，MAP) 进行度量，值越大
已有推荐算法，其次通过实验分析本文算法一些参
表示生成的推荐列表质量越高，具体定义如下:
数的设置对性能的影响．
实验环境如下:4 GB内存，Intel (Ｒ) Core (TM) MAP = 1 ∑U 1 ∑mj Precision( r ) ，
U m j，k
i7 －2600 处理器，3．4 GHz，Windows 7 操作系统． j=1 j k=1
其中，U 表示总共推荐的用户数量，m 表示用户在
3．1 实验数据集 j
测试集中喜欢的物品数量，Precision( r ) 表示用户
实验应用通过用户评价网站 Epinions．com 采 j，k
j喜欢的物品k在推荐列表中位置的倒数，即用户真
集的Epinions数据集．该数据集的信息表示用户给
正喜欢的物品排序越靠前，准确率越高．整个系统的
汽车、图书、电影等物品的评分，通常用数值1 ～5表
平均准确率为所有用户准确率的平均值．
示．同时，用户可表达是否信任系统中其他用户，如
考虑到用户未评分物品无法验证准确性，因此
果信任，在数据集中标记为1，否则标记为0．
最终推荐列表中只对测试集中存在的物品进行排
该数据集包含40 163 位用户对139 738 种物品
序，以此判断算法是否将用户喜欢的物品排到列表
的664 824个评分数据，其中每个用户至少评价过一
前面．
个物品．该评分数据的稀疏度为99．99%，其它统计
3．3 5 种算法实验结果对比分析
信息见表2．此外，该数据集还包含442 979 条用户
为了验证用户的社交关系在推荐过程中的作用
之间的信任关系，信任数据的稀疏度为99．97%．
和对推荐性能的影响，在MAE、ＲMSE和MAP这3个
指标上将本文算法与如下4 种算法对比分析．
表2 Epinions评分数据统计
Table2 Statistics of user-item rating matrix of Epinions
1) 传统的基于用户的协同过滤算法( User-
Based Collaborative Filtering，UCF)［8］．只利用评分
统计项 最小评分数量 最大评分数量 平均评分数量
用户 1 1022 16．55 信息，通过度量用户间皮尔逊相似度，进而基于用户
物品 1 2018 4．76 最近邻进行预测推荐．
2) 传统的基于物品的协同过滤算法( Item-
3．2 评价指标 Based Collaborative Filtering，ICF)［20］．只利用评分
采用如下两类指标评价推荐结果的优劣． 信息，通过度量物品间皮尔逊相似度，进而基于物品
第一类指标度量评分预测误差率，通过对比真 最近邻进行预测推荐．
实评分和预测评分之间的差距评价推荐算法预测评 3) Liu等［17］提出的融合用户朋友和相似用户的
分的准确度．本文使用平均绝对误差( Mean Absolute 协同过滤算法( Combine Neighbors and Friends
Error，MAE) 和均方根误差( Ｒoot Mean Squared Er- Based Collaborative Filtering，CNCF) ． 利用评分信
ror，ＲMSE)［9］，值越小表示推荐效果越好． 息和社交关系信息，由社交关系强度最大的用户和
MAE定义为 评分相似度最大的用户共同构成传统最近邻，然后
1 采用与UCF相同的策略进行预测推荐．
MAE = ∑ r － r' ，
N
i，j
i，j i，j 4) 基于用户朋友的协同过滤算法( Friend-
其中，r 表示用户i对物品j的实际评分，r ' 表示用 Based Collaborative Filtering，FCF)［17］． 由社交关
i，j i，j 286 模式识别与人工智能 29卷
系强度最大的用户构成最近邻，然后采用与 UCF 相 错误诱导．另外，相比其余4种算法，本文算法在3个
同的策略进行预测推荐． 指标上都有更好结果，再次验证本文算法推荐结果
本文算法选择使用Salton指标度量用户间社交 的有效性．
关系强度，选择使用皮尔逊相似度度量计算用户间
或物品间的评分相似度． 实验采用五折交叉验证方
法，最终结果为5 次实验结果的平均值．
已有研究表明，协同过滤推荐算法在用户或物
品邻居数为30 时推荐效果较优［19］． 因此，5 种算法
都将用户或物品邻居数设置为30 进行对比分析，实
验结果如表3 所示，表中，↓ 表示该指标值越小越
好，↑表示该指标值越大越好．
表3 在30近邻时5种推荐算法的实验结果
Table3 Ｒesults of the5 recommendation algorithms
with30 neighborhoods (a)MAE
指标 UCF ICF CNCF FCF 本文算法
MAE↓ 1．0646 1．0917 1．0633 1．3257 0．8865
ＲMSE↓ 1．3286 1．3500 1．3262 1．5170 1．1604
MAP↑ 0．9209 0．9205 0．9216 0．8983 0．9406
另外，5 种算法在协同过滤过程中度量用户间、
物品间的相似度时均采用皮尔逊相关系数．特别地，
本文算法在基于社交网络对缺失值进行选择性填充
时，朋友数量设置为30，并选择Salton指标度量用户
间社交关系强度．
由表3可知，CNCF 在3个指标上都优于传统的
(b)ＲMSE
协同过滤算法，说明用户社交网络关系信息在推荐
过程中发挥重要作用，弥补传统协同过滤算法可能
存在的邻居不足问题．FCF性能表现最差，原因可能
在于并不是用户与其所有朋友都有相同的兴趣偏
好，不能简单地将其视为传统意义上的邻居．同时可
看出，本文算法在3 个指标上都取得最好效果，验证
本文算法基于用户社交关系信息进行评分缺失值填
充的有效性，较大幅度提高传统协同过滤算法的推
荐准确度．
在传统的协同过滤算法中，用户或物品的邻居
数量会对推荐结果产生一定影响． 图1 给出用户或
物品邻居数量的变化对5 种推荐算法的推荐精度的
(c)MAP
影响．
从图1 可看出，随着邻居数量的增加，5 种算法
图1 目标物品邻居数量对5种算法推荐性能的影响
的MAE和ＲMSE都呈现出先减后增的趋势，而MAP
Fig． 1 Influence of neighborhood number of target item on
呈现出先增后减的趋势． 这是由于当邻居数量太少 the recommendation performance of5 algorithms
时，因为只参考少数人的意见，导致预测评分受个人
因素影响较大．而当邻居数量过多时，又有可能加入 为了更进一步研究本文算法，以下部分将对影
质量较低用户的意见，对正确用户做出的预测产生 响本文算法性能的因素进行更深入的实验分析，主 3期 郭兰杰 等:融合社交网络信息的协同过滤推荐算法 287
要包括缺失值填充过程中朋友数量及朋友之间社交 数量的继续增加，各个指标逐渐变差，而当利用用户
关系强度的度量指标的选择． 所有的朋友关系时，推荐性能变得很差． 可见，恰当
3．4 缺失值填充时社交关系强度计算方法对比 选择朋友数量，可提高本文算法性能．由实验分析可
在本文算法中，基于用户社交关系缺失值填充 得，本文选择30 个朋友对用户缺失值进行预测性能
是极其重要的一步． 而用户之间社交关系的强度决 最佳．
定用户朋友对于填充值的贡献程度，因此如何准确
度量用户间社交关系强度至关重要． 实验中，对比
Salton方法与HDI对推荐结果的影响． 为了验证基
于网络结构刻画用户间关系强度的优势，还对比传
统的基于用户评分向量的皮尔逊相似度．最后，为了
说明不同社交关系强度方法的有效性，对比所有社
交关系强度都为1 的情形．
表4给出3个指标对推荐性能的影响情况．相比
HDI，Salton 可在3 个评价指标上都取得更优结果．
同时发现，相比传统的皮尔逊方法，基于网络结构的
(a)MAE
HDI和Salton在3个指标上都更优．这主要是因为基
于网络结果的方法在考虑共同评分部分外，还考虑
用户节点度的影响，因此对用户的相似度刻画更精
细准确．而上述任何一种度量方法都要比社交关系
强度区分的常量为1 的方法更好．可见，使用何种方
法计算用户间的社交关系强度对于推荐性能影响非
常重要．
表4 3个指标对推荐性能的影响
Table4 Influence of3 evaluation indexes on recommendation
(b)ＲMSE
performance
指标 HDI Salton Pearson Const = 1
MAE ↓ 0．8898 0．8865 0．8910 0．9175
ＲMSE↓ 1．1652 1．1604 1．1660 1．2037
MAP ↑ 0．9404 0．9406 0．9387 0．9387
3．5 缺失值填充时朋友数量对推荐结果的影响
在本文算法中，基于用户社交关系进行缺失值
填充是极其重要的一步，而参与填充的朋友数量对
推荐精度有一定影响．如果朋友数量过少，可能缺失
值的预测集中在某几个人的意见，从而产生较大偏 (c)MAP
差．而朋友数量过多，可能会带入一些噪音，反而降
低预测精度． 图2 缺失值填充时朋友数量对本文算法推荐性能的影响
图2 给出在预测评分时目标物品邻居数量为 Fig． 2 Influence of friend number on recommendation
30，好友熟悉度度量采用Salton指标的情况下，缺失 performance of the proposed algorithm after filling
missing values
值填充时好友数量对最终推荐精度的影响，图中，
All表示目标用户的所有朋友．
4 结 束 语
从图2 可见，不同的朋友数量对于实验结果产
生一定程度的影响．当朋友数量由少变多时，各个指
标都趋于更优．而当朋友数量超过30 时，随着朋友 本文提出基于社交网络对评分矩阵进行缺失值 288 模式识别与人工智能 29卷
填充的协同推荐算法，在传统的基于物品的协同过 ［10］TANG J L，HU X，LIU H． Social Ｒecommendation: A Ｒeview．
滤推荐算法中，通过利用丰富的用户社交网络信息，
SocialNetworkAnalysisandMining，2013，3(4): 1113－1133．
［11］吴湖，王永吉，王 哲，等．两阶段联合聚类协同过滤算法．软件
对稀疏的原始评分数据进行两阶段缺失值的填充，
学报，2010，21(5): 1042－1054．
缓解制约传统协同过滤算法推荐性能的数据稀疏问
(WUH，WANG Y J，WANG Z，et al． Two-Phase Collaborative
题．实验表明，本文算法有效提升传统推荐算法的推
Filtering Algorithm Based on Co-clustering． Journal of Software，
荐准确度，且比已有的利用社交关系信息的推荐算 2010，21(5): 1042－1054．)
法更有效． ［12］VUCETICS，OBＲADOVICZ． CollaborativeFilteringUsingaＲe-
gression-Based Approach． Knowledge and Information Systems，
本文只利用用户社交关系信息，忽略用户及物
2004，7(1): 1－22．
品的一些内容属性信息、评分时间信息等．在未来研
［13］CAID，WANGXH，HEXF． ProbabilisticDyadicDataAnalysis
究中，将在推荐过程中融入更多的社交上下文信息，
withLocalandGlobalConsistency // Procofthe26thAnnualIn-
以便进一步改善传统协同过滤算法的推荐性能． ternational Conference on Machine Learning． Montreal，Canada，
2009: 105－112．
参 考 文 献
［14］HAＲVEYM，CAＲMAN M J，ＲUTHVEN I，et al． Bayesian La-
tent Variable Models for Collaborative Item Ｒating Prediction //
Procofthe20thACMInternationalConferenceon Information and
［1］冷亚军，陆 青，梁昌勇．协同过滤推荐技术综述．模式识别与人
KnowledgeManagement． Glasgow，UK，2011: 699－708．
工智能，2014，27(8): 720－734．
［15］CHENG G H，GONG S J． An Efficient Collaborative Filtering
(LENGYJ，LUQ，LIANGCY． SurveyofＲecommendationBased
Algorithm with Item Hierarchy // Proc of the 2nd International
onCollaborativeFiltering． PatternＲecognitionandArtificialIntelli-
Symposium on Intelligent Information Technology Application．
gence，2014，27(8): 720－734．)
Shanghai，China，2008，III: 28－31．
［2］GOLDBEＲGD，NICHOLSD，OKIBM，etal． UsingCollaborative
［16］QIANXM，FENGH，ZHAOCS，etal． PersonalizedＲecommen-
FilteringtoWeave an Information Tapestry． Communications of the
dationCombiningUser Interest and Social Circle． IEEE Trans on
ACM，1992，35(12): 61－70．
KnowledgeandDataEngineering，2013，26(7): 1763－1777．
［3］ADOMAVICIUS G，TUZHILIN A． Toward the Next Generation of
［17］LIUFK，LEEHJ． UseofSocialNetworkInformationtoEnhance
Ｒecommender Systems: A Survey of the State-of-the-Art and Po-
CollaborativeFilteringPerformance． Expert Systems with Applica-
ssibleExtensions． IEEETransonKnowledgeandDataEngineering，
tions，2010，37(7): 4772－4778．
2005，17(6): 734－749．
［18］YANGXW，STECHH，LIUY． Circle-BasedＲecommendationin
［4］冷亚军，梁昌勇，丁 勇，等．协同过滤中一种有效的最近邻选择
OnlineSocialNetworks［C/OL］． ［2015 －04 －25］． http: //ee-
方法．模式识别与人工智能，2013，26(10): 968－974．
web．poly．edu/faculty/yongliu/docs/CircleＲec．pdf．
(LENGYJ，LIANGCY，DINGY，etal． MethodofNeighborhood
［19］LLY，ZHOUT． LinkPredictioninComplexNetworks: ASur-
FormationinCollaborativeFiltering． PatternＲecognitionandArtifi-
vey． PhysicaA: StatisticalMechanicsandItsApplications，2011，
cialIntelligence，2013，26(10): 968－974．)
390(6): 1150－1170．
［5］WANGJ，DEVＲIESAP，ＲEINDEＲSMJT． UnifyingUser-Based
［20］DESHPANDEM，KAＲYPIS G． Item-Based Top-N Ｒecommenda-
andItem-BasedCollaborativeFilteringApproachesbySimilarityFu-
tionAlgorithms． ACMTransaction on Information Systems，2004，
sion // Proc of the 29th Annual International ACM SIGIＲ Con-
22(1): 143－177．
ferenceonＲesearchandDevelopmentinInformationＲetrieval． Se-
attle，USA，2006: 501－508．
作者简介
［6］LIANGCY，LENGYJ． CollaborativeFilteringBased on Informa-
tion-Theoretic Co-clustering． International Journal of Systems Sci- 郭兰杰，男，1991年生，硕士研究生，主要研究方向为推荐系
ence，2014，45(3): 589－597． 统．E-mail:1178315430@qq．com．
［7］KOＲEN Y，BELL Ｒ，VOLINSKY C． Matrix Factorization Tech- (GUO Lanjie，born in1991，master student． His research in-
niquesforＲecommenderSystems． Computer，2009，42(8): 30－ terests include recommendation system．)
37．
梁吉业(通讯作者)，男，1962年生，博士，教授，主要研究方
［8］孟祥武，刘树栋，张玉洁，等．社会化推荐系统研究．软件学报，
向为粒计算、数据挖掘、机器学习．E-mail: ljy@sxu．edu．cn．
2015，26(6): 1356－1372．
(LIANG Jiye( Corresponding author)，born in1962，Ph．D．，
(MENGX W，LIU S D，ZHANG Y J，et al． Ｒesearch on Social
professor． His research interests include granular computing，
Ｒe-commenderSystems． Journal of Software，2015，26(6): 1356
data mining and machine learning．)
－1372．)
赵兴旺，男，1984年生，博士研究生，主要研究方向为数据挖
［9］BＲEESEJS，HECKEＲMAN D，KADIE C． Empirical Analysis of
PredictiveAlgorithmsforCollaborativeFiltering // Procofthe14th
掘、机器学习．E-mail: zhaoxw84@163．com．
Conference on Uncertainty in Artificial Intelligence． Minneapolis， (ZHAO Xingwang，born in 1984，Ph． D． candidate． His re-
USA，1998: 43－52． search interests include data mining and machine learning．) --------------------------------------------------------------------------------- ISSN1673-9418 CODENJKYTA8
E-mail:fcst@vip.163.com
JournalofFrontiersofComputerScienceandTechnology
http://www.ceaj.org
1673-9418/2018/12(02)-0208-10
Tel:+86-10-89056056
doi:10.3778/j.issn.1673-9418.1702012
融合社交网络特征的协同过滤推荐算法*
郭宁宁1，王宝亮1+，侯永宏1，常 鹏2
1.天津大学 电子信息工程学院，天津 300072
2.天津大学 信息与网络中心，天津 300072
Collaborative Filtering Recommendation Algorithm Based on Characteristics of
Social Network
􀆽
GUO Ningning1,WANG Baoliang1+,HOUYonghong1,CHANG Peng2
1.SchoolofElectronicInformationEngineering,TianjinUniversity,Tianjin300072,China
2.InformationandNetworkCenter,TianjinUniversity,Tianjin300072,China
+ Correspondingauthor:E-mail:wangbl@tju.edu.cn
GUO Ningning, WANG Baoliang, HOU Yonghong, et al. Collaborative filtering recommendation algorithm
basedoncharacteristicsofsocialnetwork.JournalofFrontiersofComputerScienceandTechnology,2018,12
(2)：208-217.
Abstract: To solve the severe sparseness problem of traditional collaborative filtering recommendation algorithm,
this paper proposes a novel collaborative filtering recommendation algorithm based on the characteristics of social
network. On the basis of traditional matrix decomposition model, the algorithm obtains the trust and trusted charac-
teristicmatrixbyintegratingthecharacteristicsofsocialnetworkanduserspreferencedegree,andthen,predictsthe
􀆳
ratingofthecommoditybythesocialidentitymatrix,thecommoditycharacteristicmatrixandtheuserratingprefer-
ence similarity in common. In order to verify the reliability of the proposed algorithm, this paper uses the Epinions
open dataset to compare the algorithm performance.The experimental results show that compared with the existing
social recommendation algorithms, the proposed algorithm has smaller average absolute error and root mean square
error.Meanwhile,thereisalinearrelationshipbetweenthetimecomplexityoftheproposedalgorithmandthenum-
ber of the dataset.Therefore,the proposed algorithmcan effectivelyreducethe impactof datasparseness on recom-
mendationresultsandimprovetherecommendationaccuracyrate.Inpractice,theproposedalgorithmcanbeconsid-
*TheNationalNaturalScienceFoundationofChinaunderGrantNo.61571325(国家自然科学基金).
Received2017-02,Accepted2017-04.
CNKI网络优先出版:2017-04-19,http://kns.cnki.net/kcms/detail/11.5602.TP.20170419.1308.002.html 郭宁宁 等：融合社交网络特征的协同过滤推荐算法 209
eredasanalternativeanddevelopmentofthelarge-scaledatasetrecommendation.
Keywords:recommendersystem;socialnetwork;collaborativefiltering;userratingpreference;ratingprediction
摘 要：为了解决传统协同过滤算法中存在的严峻的数据稀疏性问题，提出了一种融合社交网络特征的协同
过滤推荐算法。该算法在传统矩阵分解模型基础上，通过融合社交网络特征与用户评分偏好程度得到信任和
被信任特征矩阵，然后利用社交特征矩阵、商品特征矩阵和用户评分偏好相似性共同预测用户对商品的评分
值。为了验证该算法的可靠性，使用Epinions公开数据集对算法性能进行对比分析。实验结果显示，相比现有
的社交推荐算法，所提算法有更小的平均绝对误差和均方根误差，同时算法的时间复杂度与数据集的数量之
间为线性关系。因此，该算法可以有效缓解数据稀疏性对推荐结果的影响，并提高推荐准确率。在现实推荐
中，该算法可以考虑作为大规模数据集进行商品推荐的一个选择方式。
关键词：推荐系统；社交网络；协同过滤；用户评分偏好；评分预测
文献标志码：A 中图分类号：TP301
1 引言 多依赖网络社交工具，比如Facebook、微信等。社交
大数据时代的快速发展造成日益严重的信息过 关系为推荐系统提供了一个独立的信息源，在社交
载现象，信息检索已经无法满足用户日益增长的个 推荐算法中起着越来越重要的作用[9]。基于社交关
性化信息获取的需求。个性化推荐系统因为其可靠 系的推荐方法[10-14]，在一定程度上缓解了用户稀疏性
性高，推荐结果准确，迅速成为解决信息过载的方式 和冷启动问题，同时提高了推荐准确率，但是依然存
之一。其基本思想是依据用户的历史行为推荐用户 在一些问题。首先现有的网络数据集中，只有少部
感兴趣的用户或商品集，并且为获得更好的用户体 分数据集有用户社交关系矩阵，且矩阵数值都是二
验提供个性化服务[1]。目前，个性化推荐技术主要分 值数据，因此很难区别用户间的信任程度；其次对用
为协同过滤推荐[2]、基于内容的推荐[3]、基于图的推 户社交数据建模时，大部分模型建立仅仅依靠用户
荐[4]、混合推荐技术[5]。其中协同过滤推荐又包括基 显性信任关系，从而忽视了用户的隐性社交关系，如
于模型的协同过滤[6]和基于记忆的协同过滤[7]，该技 相似性等。
术在分析用户资源的基础上，充分挖掘用户潜在兴 为解决上述存在的问题，本文提出了一种融合
趣，并以此作为预测和推荐依据，现已成为推荐系统 社交网络关系的协同过滤推荐方法，即融合用户间
中发展最成熟、应用最广泛的推荐技术，也是本文主 社交网络信息和用户评分信息，对传统基于分解模
要的研究对象。 型的协同过滤算法进行优化。本文方法包含以下几
协同过滤推荐技术取得广泛应用，在信息海洋 个步骤：（1）将用户评分矩阵和用户信任矩阵分别映
时代节省了用户获取信息的时间代价，但该技术也 射到低维空间，即用户空间、商品空间、信任空间和
存在一些固有缺陷。首先，协同过滤技术依靠用户- 被信任空间；（2）用社交特征、商品特征矢量和用户
商品评分矩阵进行推荐，但是在现实生活中评分矩 相似性近似估计稀疏用户评分矩阵；（3）依据密集用
阵存在严重的数据稀疏性问题；其次，部分用户只对 户评分矩阵选择评分最高的N个商品，形成推荐列
很少部分商品进行评分，因此该技术存在冷启动问 表。最后在Epinions公开数据集上验证本文算法，证
题；最后，传统的协同过滤技术仅仅依靠用户-商品评 明了该算法有效缓解了数据稀疏性对推荐结果的影
分矩阵为用户推荐，由于数据源单一，造成推荐结果 响，并有效降低了平均绝对误差，提高了推荐准确率。
失真[8]。 本文组织结构如下：第2章简要介绍传统分解模
随着社交网络技术的发展，用户之间的联系更 型的协同过滤算法和本文提出的基于社交网络关系 210 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2018, 12(2)
的协同过滤方法；第3章对本文推荐算法进行仿真验 户集，I {i i i}代表全部的商品集。如何有效
= 1, 2,⋯, n
证与实验结果分析；第4章对全文进行总结。 得到未评分商品的预测值R ，是个性化推荐至关重
ui
,
要的一步。最后计算真实评分和预测评分之间的差
2 基于社交关系的协同过滤推荐算法 异最小值来评估推荐系统的推荐准确性，则上述问
2.1 问题分析 题变成求最优解问题，目标函数如式（1）：
传统协同过滤推荐算法往往只分析用户的评分 m n R R 2 （1）
矩阵数据，容易忽视用户之间存在的社交信息。但 min∑ u ∑ i u ,i- u ,i
=1 =1
通常情况若只分析用户评分矩阵来预测缺失评
在实际推荐应用中，社交网络信息在推荐系统中的
分，易导致评分预测不准确。通过增加额外的社交
重要性越来越明显，越来越多的研究者将社交网络
网络数据源辅助用户评分数据，来提高预测值的准
中的信任关系引入推荐系统中。Massa等人在2004
确性[12]。这种方法的评分预测依据是：两个用户之间
年首次提出将社交中的信任关系融入推荐算法中，
的偏好具有相似性或存在信任的社交关系，如果其
用用户间的信任度替代传统相似度对用户空缺值进
中一个用户对某商品的评分较高，则可以认为另一
行预测评分[11]，该方法对比传统协同过滤推荐算法准
用户对该商品的评分也较高。社交网络中用户间的
确性有很大提升。Ma等人在推荐系统中引入社交规
信任关系可以用矩阵T 表示，T [T ] ，其中T
则的概念，阐述了所提出的两种社交规则对推荐系 = u ,v m ×m u ,v∈
[ ]表示用户间信任程度，如图1（b），用户u 信任用
统的贡献，实验证明基于社交规则的推荐可以有效
0,1 1
提高推荐的准确性[12]。文献[7]融合用户社交信任度 户u、u、u ；用户之间的不信任关系用矩阵 D 表
3 4 5
和评分相似性，提出了一个新矩阵填充的推荐方法， 示，D [D ] ，D ( ,1]表示用户间的不信任程
= u ,v m ×m u ,v∈ 0
使预测评分准确度明显提升，改善了推荐过程中存 度，如图1（c），用户u 不信任u 。本文研究的内容主
1 2
在的稀疏性问题。文献[9,14]将高维用户评分矩阵映 要是引入社交网络数据源对用户评分数据中的空缺
射到低维特征矩阵，融合用户的社交信息以及各自 值进行填充，从而完成相关推荐。
的隐性数据源进行推荐，实验结果证明该方法可以 2.2 传统矩阵分解模型
提高推荐准确度，但会造成部分信息丢失。 矩阵分解（matrix factorization，MF）模型被广泛
假设研究的推荐系统含有 m 个用户和 n 个商 应用在协同过滤推荐算法中，适用于对用户-商品评
品，用户对商品的评分矩阵为 R [R ] ，如图1 分矩阵数据进行分析，近似预测缺失数据[15]。其思想
= u ,i m ×n
（a）。 R [ , ]表示用户u对商品i的评分值，5表 是将高维用户评分矩阵分解成为低维用户特征矩阵
u ,i∈1 5
示最喜欢，1表示最讨厌，评分值为空表示用户未对 U l ×m和商品特征矩阵I l ×n，其中l (m n)，
∈ℝ ∈ℝ ≤min ,
该商品评分。其中，U {u u u }表示全部的用 分解后的用户特征只由几个少量的重要特征决定[16]，
= 1, 2,⋯, m
Fig.1 Asampleofuser-itemmatrixandusers relationship
􀆳
图1 用户评分矩阵与用户关系举例 郭宁宁 等：融合社交网络特征的协同过滤推荐算法 211
评分矩阵R可以用UTI 近似替代，UT为矩阵U 的转 向越一致，则用户之间的信任程度越高，反之越低，
置。为了方便研究，通常用函数 f(x) xR 将用户 如UPS（user position similarity）方法[17]、用户间接可
= / max
评分数据映射到 之间[1]，R 是用户评分的最大 信度[11]等方法构建用户之间的信任度。本文主要基于
[0,1] max
值。传统的基于矩阵分解模型的协同过滤方法利用 已知社交信任数据下的协同过滤推荐算法进行研究。
简单的线性模型R UTI 近似拟合评分矩阵，容易造 社交网络关系一般存在以下几个特点：（1）用户
=
成预测评分过分偏离真实评分，使预测失真。本文 信任关系具有传递机制，如果用户u、v之间，v、w
引入非线性logistic函数 g(x) ( -x)，将预测评分 之间分别存在信任关系，则 v、w 之间被认为也存
=1/1+e
值映射在 内。 在信任关系，但是三者间的信任程度不同，T
[0,1] uw≤
为了避免过拟合现象，添加正则化约束项，求解 T T ；（2）用户间社交网络信任关系不存在对
min( uv, vw)
最小代价函数L如式（1）时的用户特征矩阵U 和商 称性，即使用户u信任用户 v，不一定用户 v信任用
品特征矩阵I ，则上述问题的目标函数如式（2）： 户u；（3）社交网络中的不信任关系不存在传递机制。
L (R g(UTI)) 2 λ U2 λI2 （2） 依据2.2节中的矩阵分解模型的分解方法，可以
= (∑
u ,i) ∈R
u ,i- u i + u F+ i
F 将用户间的信任关系矩阵T m ×m映射成两个低维
m n ∈ℝ
其中， ∙2 表示二阶范数；A2
=
∑∑|A ij|2 ；λ u、λ
i
特征矩阵，即信任特征矩阵P ∈ℝk ×m和被信任特征矩
F F i j
=1 =1 阵Q k ×m ，则信任矩阵T 的信任值可通过T PTQ
代表特征矩阵U、I 的正则化系数；λ U2 、λI2 ∈ℝ =
u i 线性组合近似估计，其中m表示用户数量，k m表
F F ≤
为正则化项。用户-商品预测评分的预测值则可以用
示特征数量。假如某个用户u是否信任用户 v由 k
式（3）计算：
个特征因素决定，那么可以用一个 k 维向量 P
u=
R
u
,i=g(U uTV i) ∙R
max
（3）
[p 1,p 2,…,p k] T表示用户u的信任标准。用Q v=[q 1,q
2,…,
2.3 基于社交网络的协同过滤方法
q] T 表示被信任用户 v本身的特征，用户u对用户 v
k
传统基于矩阵分解模型的协同过滤推荐算法依
的信任值T 可以用PTQ 近似表示，但由于噪声的存
uv u v
据用户对商品的评分来预测空缺评分数据，忽视了
在，这种分解并不准确，从而用代价函数L评估真实
用户、商品属性以及用户之间的社交关系，推荐预测
值与预测值之间的差异，代价函数L最小时对应求得
并不一定准确[10]。目前社交关系被广泛应用于社交
的特征矩阵P、Q即为最优解。代价函数为式（4）：
推荐系统中，社交推荐系统基于如下基本假设：如果
L
(T g(PTQ))2 λP2 λQ2 （4）
用户u与v之间存在正相关社交信任关系，则认为用 = (∑
uv) T
u ,v- u v + p F+ q
F
, ∈
户u、v之间的兴趣偏好程度高于不相关的陌生人[1]， 其中，λ 、λ 为正则化系数；λP2、λQ2是正则
p q p q
F F
近几年的很多研究已经证明在社交网络中具有正相
化项。预测到的社交信任数据通过非线性logistic函
关社交关系的用户之间可以很好地传播这种正相关
数g(x) ( -x)映射到[0,1]之间。
=1/1+e
特性，通过利用这种正相关性能够有效地提高推荐
通常用户之间不是完全相互独立的，而是具有
准确率[7，17]。基于以上依据可以认为在实际社交推荐
一定相关性的。相关性度量方法通常有余弦相似性
过程中，用户更容易接受与其具有正相关社交关系
和Pearson相关性，本文采用Pearson相关性方法计算
的用户的推荐。此处用户之间的信任关系可以由信
用户之间的相关程度，计算方法如式（5）：
任评分矩阵显性表示，如果数据集中用户之间的信
(r r )(r r)
任程度由显性的信任数据表示，信任数据范围是[0, sim(u v) ∑I ui-ˉu∙ vi-ˉv （5）
1 , =
(r r )2 (r r)2
1]，无评分则为空，如Epinions数据集；若没有显性信 ∑I ui-ˉu ∑I vi-ˉv
任数据时，信任度可以依据用户共同评分项等隐性 其中，I 表示用户u、v 的共同评分商品集，i I；r
∈ ui
信任数据构建，即用户之间的共同评分项的评分趋 和r 分别表示用户u和 v对项目i的评分值；r 、r
vi ˉu ˉv 212 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2018, 12(2)
分别表示用户u和用户 v的评分均值。通常用户间 λ 、λ 和 λ 是矩阵 P、Q和V 正则化系数，以防止
p q v
的共同评分项的评分倾向越一致，则认为二者对项 过拟合现象。
目的关注程度越一致，二者的相似性值也越高。定 根据上述模型描述，使损失函数最小时P、Q和
义用户评分偏好程度如式（6）：
V 的值即为最优解。为了求代价函数的最优解，算法
æ|I I|( ≥t) |I I|( <t)ö 采用随机梯度下降法求代价函数关于P、Q 和V 的
P(u v) çç u⋂ v u⋂ v ÷÷ u u i
, = è |I u|( ≥t) + |I u|( <t) ø× 偏导数，如式（12）、（13）、（14）即为梯度方向。
æ èç ç|I u |⋂
I
v|(I ≥v t| )( ≥t) +|I u |⋂
I
v|(I <tv )|( <t) ö ø÷ ÷ （6） ∂∂ PL
u
=2é ëê
∑
i
∈R(u)( βV ig ′(βP uTV i+( 1-β)Q uTV i))
×
其中，t是区分评价好坏的阈值，超过阈值记为积极 ( g(βPTV ( β)QTV) R )
u i+ 1- u i - u ,i +
评分，否则为消极评分；I u、I v分别表示用户u、v的 Q sim(u v)g(PTQ)(g(PTQ) T )
∑ v , ′ u v u v - u ,v +
评分商品集合。将用户偏好程度融入相似度计算中， v T(u)
∈
ù
即基于偏好程度的相似性度量方法，计算如式（7）： (λ P λ|P P|)ú （12）
sim(u v) P(u v) sim(u v) （7） v∑ ∈D(u) p - 1 u- v û
, = , × 1 , é
其 用户中 间，P P( eu a, rv s) o表 n相示 关用 系户 数间 。评 社分 交偏 信好 任程 关度 系； 的sim 代1( 价u , 函v)为
数
∂∂ QL
u
=2 ëêê i∑ ∈R(u)( ( 1-β)V ig ′(βP uTV i+( 1-β)Q uTV i)) ×
为式（8）：
( g(βP uTV i+( 1-β)Q uTV i) -R
u
,i)
+
L = (∑
u ,v)
∈Ts(u ,v)(T u ,v-g(P uTQ v)) 2 +λ pP2 F+λ qQ2 F（8） v∑ ∈T(u)P uTsim(u ,v)g ′(P uTQ v)(g(P uTQ v) -T u ,v) +
通过对基于社交网络的研究，用户对商品预测 ù
(λ Q λ|Q Q|)úú （13）
评分可用社交特征和商品特征修正，如式（9）： v∑ D(u) q - 2 u- v û
∈
R
u
,i=g(βP uTV i+γQ uTV i+θsim(u ,v)) （9）
∂L
é
êê (βPT ( β)QT)
其中，β γ θ ( )，且 β γ θ ，是调控信任特征 ∂V i =2 ëu∑ R(i) u + 1- u ×
, , ∈ 0,1 + + =1 ∈
向量、被信任特征向量和相似性的贡献率参数。 ( g(βPTV ( β)QTV) R )
u i+ 1- u i - u ,i ×
在社交网络关系中，如果两个用户u、v之间不
ù
g (βPTV ( β)QTV) λVúú （14）
存在信任关系，而是怀疑关系，那么认为两个用户的 ′ u i+ 1- u i + v û
兴趣偏好存在较大偏差，对同一商品的评分差别可
其中，R(u)表示用户u评分过的商品集；T(u)表示用户
能较大。在本算法中，可以计算用户特征空间的欧
u信任的用户集；D(u)表示用户u怀疑的用户集；R(i)
氏距离描述用户之间兴趣偏好的差异。
表示给商品i评分过的用户集。沿梯度的负方向不断
m m
P P 2 Q Q 2 （10） 迭代更新P、Q和V直至收敛，即可认为得到最优解。
∑∑ u- w +∑∑ u- w
u w D(u) u w D(u)
基=1 于∈ 以上描述，最小= 代1 ∈ 价函数修正成式（11）： ì ï ïïP t +1=P t+α ∂∂ PL
u
L = (∑ u ,i) ∈R( g(βP uTV i+( 1-β)Q uTV i) -R u ,i) 2 + íï ïQ t +1=Q t+α ∂∂ QL
u
（15）
(∑ u ,v) ∈Ts(u ,v)(g(P uTQ v) -T u ,v)2 +λ pP2 F+ îïïï V t +1=V t+α ∂∂ VL
i
m
λQ2 λV2 λ P P 2 其中，α表示学习速率；P 、Q 和V 用随机数进行初
q F+ v
F
- 1∑
u
w∑
D(u)
u- v - t t t
=1 ∈ 始化，t 表示迭代次数，t [ )。通过不断迭代更
m
λ Q Q 2 ∈1,∞
2∑∑ u- v （11） 新，P、Q和V 的值会趋于稳定，稳定后的值即为最
u u D(u)
=1 ∈
其中，λ 、λ 是社交网络差异特征矩阵正则化系数； 优解。高维评分矩阵、社交信任矩阵通过分解变成
1 2 郭宁宁 等：融合社交网络特征的协同过滤推荐算法 213
低维用户信任特征矩阵、被信任特征矩阵、商品特征 的社交数据，其中487181条记录表示用户间的关系
矩阵，利用式（9）对用户评分矩阵进行预测评估，稀 是积极的，认为是信任数据，信任值为1，其余不存在
疏矩阵变为密集矩阵，选择目标用户中评分最高的N 信任关系即为0。经对数据统计分析可得每类评分
个商品推荐给用户，即完成Top-N 推荐。 的贡献情况，评分数据中评分为5的记录数占总数的
2.4 复杂度分析 45%，评分为4的占29%，评分为3的占11%，评分为2
评价一个算法性能，主要计算算法的时间复杂 的占8%，评分为1的占7%，所有评分的平均值约为
度，即语句总的执行次数[18]。在本研究中，用户之间 3.9，接近一半的用户给商品的评分为最高值5。如果
的相似性以及评分矩阵、社交矩阵分解等计算过程 用户的评论数量低于5，则被认为是“冷启动”用户，
都是离线条件下完成的，因此本文基于社交网络的 该类用户数量为26037，那么数据集中有超过一半的
协同过滤推荐算法的计算复杂度主要受代价函数和 用户属于冷启动用户。
梯度下降特征矩阵维数变量的影响。其中代价函数 3.2 实验设置
的计算复杂度是O(k(|R| |T| |D|))，k表示隐性特征
3.2.1 实验方法
+ +
维数，|R|、|T|和|D|表示存在的非空用户评分数量、 K 折交叉验证：为验证本文算法的有效性和真实
用户信任连接数量和用户不信任连接数量。梯度 性，本实验采用5折交叉验证的方法[7]将所研究的数
L P、 L Q 和 L V 的复杂度分别为O(k(|R| |T| 据集平分成5份，每次实验随机选取数据集中的1组
∂ /∂ ∂ /∂ ∂ /∂ + +
|D|))、O(k(|R| |T| |D|))和O(k|R|)，因此本算法的复杂 作为测试数据，剩下的4组数据集作为训练数据，每
+ +
度为O(k(|R| |T| |D|))，即时间复杂度与观察到的用 个实验进行5次，实验结果为5次实验的平均值，并
+ +
户评分数、信任连接数与不信任连接数的和成线性 进行比较分析。
关系，因此适合用于大规模数据集的推荐。 3.2.2 实验评估指标
（1）为了验证推荐算法的准确性，常用的推荐性
3 实验及结果分析 能评估指标主要包括平均绝对误差MAE和均方根误
为了验证本文算法的可靠性和有效性，利用 差RMSE[20]，用来评估推荐结果的误差分布。MAE
Epinions真实数据集，采用五折交叉验证方法，对本 计算的是所有测试用户对测试项目的预测评分和实
文算法与其他现有的社交推荐算法进行实验对比， 际评分的平均误差大小，RMSE计算真实评分与预测
统计分析不同方法在推荐准确性方面的平均绝对 评分值的均方根误差，如式（16）、（17）：
误差（mean absolute error，MAE）和均方根误差（root 1
MAE |R R | （16）
= N∑ u ,i- u ,i
mean square error，RMSE）指标。同时对推荐系统在 u ,i ∈Tu
1
Top-N 推荐时每个算法在不同的推荐数量N 的情况 RMSE (R R ) 2 （17）
= N∑ u ,i- u ,i
下的查准率、查全率和F1-Measure值进行统计并分 u ,i ∈Tu
其中，T 表示测试集中的用户数据集合；N 表示测
析，以此验证本文算法的可靠性。 u
试集中商品数量；R 表示用户u对商品i的预测评
3.1 数据集描述 ui
,
分；R 表示真实评分。
本文选择Epinions公开数据集作为研究的真实 ui
,
数据集，它由Massa在http://www.epinions.com网站 （2）另一种预测推荐系统质量的方法是计算推
收集整理所得[19]。该数据集是一极度稀疏的数据集， 荐的正确率（Precision）、召回率（Recall）和F1-Measure
稀疏度用空评分数据数量（/ 用户数量×商品数量）表 值[16]。准确率和召回率是评估推荐系统常用的两个
示，为99.99135%，包含49290个用户对139738个不 度量指标。其中准确度可以衡量推荐系统的查准
同商品的评分数据，用户评分数据为1~5内的整数，1 率，即推荐结果满足用户喜好的概率；召回率衡量的
表示最差，5表示最好；同时也包含664824条用户间 是推荐系统的查全率，即所有推荐结果与用户喜好 214 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2018, 12(2)
相关的概率。两者取值在0和1之间，数值越接近1， Table1 Parametersettings
查准率或查全率就越高。F1-Measure是结合Preci- 表1 参数设置
sion和Recall两者给出的综合评价指标。定义如下： 方法 参数选择
Precision
∑
u
∈Tu|L u⋂B u|
（18）
So Tc Dia MlM FF λ λu u= =λ λv v= =0 0. .0 00 01 1, ,λ λT S== 11
0
= |L | λ λ λ λ ,
∑ u TDRec p= w= v= c=0.001
u ∈Tu λ =λ t=0.5, β =0.4,α
=0.001
|L B | λ λ λ ,λ λ ,
∑ u⋂ u TDSRec p= q= v=0.001 1= 2=0.0001
Recall u ∈Tu （19） β =0.3,γ =0.5, θ =0.2,α
=0.001
= |B |
∑ u
u ∈Tu
Table2 MAEandRMSEresultsof
Precision Recall
F1 = 2× Precision × Recall （20） differentalgorithmsonallusers
+
其中，L 表示用户u由训练数据集得到的推荐商品 表2 所有用户在不同算法得到的MAE、RMSE值
u
集合；B 表示在测试数据集给出正反馈评分的商品 维数k 评估方法 MAE Improve/% RMSE Improve/%
u
集合；T 表示测试集中的用户数据集合。 SocialMF 0.4222 6.04 0.6232 3.05
u
TDMF 0.4135 4.07 0.6198 2.52
3.2.3 方法比较 5
TDRec 0.3969 0.06 0.6153 1.81
为了评估本文算法的性能，采用以下几种方法
TDSRec 0.3967 — 0.6042 —
进行对比验证。 SocialMF 0.4245 8.72 0.6412 7.30
（1）SocialMF（matrix factorization in social net- TDMF 0.4053 4.38 0.6100 2.56
10
TDRec 0.3969 2.36 0.5799 0.54
works）：该算法是一种基于信任传递机制的社交推荐
TDSRec 0.3875 — 0.5944 —
算法[21]。
（2）TDMF（matrix factorization with trust and dis- Table3 MAEandRMSEresultsofdifferent
trust information）：该算法利用社交信任和不信任信 algorithmsoncold-startusers
息进行推荐[22]。 表3 冷启动用户在不同算法得到的MAE、RMSE值
（3）TDRec（matrix factorization with explicit trust
维数k 评估方法 MAE Improve/% RMSE Improve/%
and distrust side information for improved social recom- SocialMF 0.9546 15.23 1.2123 23.73
mendation）：该算法通过显式信任和非信任数据进行 TDMF 0.9084 10.92 1.1910 22.37
5
TDRec 0.8488 4.67 1.0097 8.43
社交推荐[23]。
TDSRec 0.8092 — 0.9246 —
（4）TDSRec（similarity social recommendation with
SocialMF 1.0354 24.05 1.2054 28.00
trust and distrust information）：该算法是本文算法模 TDMF 0.9073 13.32 1.1868 26.87
10
型，在考虑社交网络的同时，融合基于用户评分偏好 TDRec 0.8066 2.51 0.9217 5.84
TDSRec 0.7864 — 0.8679 —
的相似性，共同对用户评分矩阵中的数据值进行评
分预测。 和10时，本文算法与现有算法的平均绝对误差（MAE）
为了便于比较，将各个算法的参数设置为表1， 和均方根误差（RMSE），并计算得到本文算法比现有
参数的设置来自于参考文献或者本研究模型。在矩 算法的提升率，观察到本文算法的MAE和RMAE小
阵分解过程中，特征矩阵的维数设置为5和10，分别 于已有算法，实验证明了本文算法提升了推荐准确度。
统计特征维数的误差值。 由图2、图3可以得出，在特征矩阵维数 k
=10
3.3 实验结果及分析 时，随着迭代次数的增加，MAE和RMSE逐渐趋于稳
在表2、表3中，分别统计了所有用户和冷启动用 定。结果显示，本文算法的MAE和RMSE低于被比
户（用户对商品评分个数少于5）在矩阵特征数k为5 较对象，性能优于被比较算法。 郭宁宁 等：融合社交网络特征的协同过滤推荐算法 215
Fig.4 Precision
Fig.2 MAEatdifferentiterationsonallusers
图4 查准率
图2 所有用户不同迭代次数时的MAE
Fig.5 Recall
图5 查全率
Fig.3 RMSEatdifferentiterationsonallusers
图3 所有用户不同迭代次数时的RMAE
通过实验对比分析本文算法与已有算法，证明
本文提出的协同过滤推荐算法在不同的推荐数量N
下的查准率、查全率和综合指标F1-Measure都优于
被比较算法。同时由图4、图5可知算法的查全率和
查准率呈相反趋势增长，由图6可知综合两者特性的
F1-Measure参数也有增长趋势。
Fig.6 F1-Measure
4 结束语 图6 F1-Measure
协同过滤推荐技术是推荐系统中应用最广和最 个低维的用户特征矩阵和商品特征矩阵的同时，分
多的推荐技术，在过去的十几年内，已有很多基于社 解社交网络矩阵数据为信任特征矩阵和被信任特征
交网络特征的协同过滤推荐方法，数据稀疏性、推荐 矩阵；在求解分解矩阵过程中通过融合用户评分偏
准确性方面在一定程度上都得到提升[9]，但是推荐系 好程度计算用户相似性使代价函数最小，如式（11），
统的固有缺陷仍然存在，导致推荐质量较差，很难满 使用梯度下降法不断迭代更新得到对应分解后的特
足用户个性化需求。本文针对推荐系统中存在的固 征矩阵，如式（12）、（13）、（14）；利用信任特征矩阵、
有的数据稀疏和冷启动问题，创新性地提出一种融 被信任特征矩阵、商品特征矩阵预测用户对商品的
合社交网络特征的协同过滤推荐算法。本文算法主 评分值，如式（9）。以此缓解矩阵稀疏性，提高推荐
要基于传统矩阵分解模型，分解用户评分矩阵为两 结果的准确性和有效性。 216 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2018, 12(2)
为了验证本文算法的可靠性，基于Epinions公开 ligence,Austin,Jan25-30,2015.MenloPark:AAAI,2015:
217-223.
数据集进行实验分析，采用五折交叉验证方法，分
[6]GuoLanjie,LiangJiye,ZhaoXingwang.Collaborativefil-
析对比了本文算法较现有的社交网络推荐算法如
tering recommendation algorithm incorporating social net-
TDMF、SocialMF、TDRec等算法的先进性和优越 workinformation[J].PatternRecognitionandArtificialIntel-
性。实验结果表明，本文算法在使用相同数据集的 ligence,2016,29(3):281-288.
[7]WangMeiling,MaJun.Anovelrecommendationapproach
情况下与其他算法相比，平均绝对误差、均方根误差
basedonusers weightedtrustrelationsandtheratingsimi-
都有所下降，有效地提高了推荐算法的性能。在现 􀆳
larities[J].SoftComputing,2015,20(10):3981-3990.
实推荐中，本文算法可以有效用于大规模用户商品 [8] Wang Shengsheng, Zhao Haiyan, Chen Qingkui, et al. La-
集的推荐，有效缓解数据稀疏性，提高预测准确度和 tentfactormodelforpersonalizedrecommendation[J].Jour-
nalofChineseComputerSystem,2016,37(5):881-889.
推荐准确度，改善推荐质量。
[9]FelfernigA,NinausG,GrabnerH,etal.Anoverviewofrecom-
本文提出的融合社交网络的协同过滤推荐算
mendersystemsinrequirementsengineering[M]//Ma-alejW,
法，虽然在一定程度上缓解了评分数据稀疏性对推 ThurimellaAK.ManagingRequirementsKnowledge.Ber-
荐结果的影响，并对于大量数据的推荐运算具有一 lin,Heidelberg:Springer,2013:315-332.
[10]PanJunchi,ZhangXingming,WangXin.Improvedsingular
定效果，但是不足以支撑超大规模数据推荐，此时可
valuedecompositionrecommenderalgorithmbasedonuser
以在本文基础上考虑超大规模推荐的并行算法来克
reliability[J]. Journal of Chinese Computer System, 2016,
服此局限性。同时本文算法未考虑时间差异对推荐 37(10):2171-2176.
产生的影响，由于用户对商品的兴趣爱好时间长短 [11]MassaP,BhattacharjeeB.Usingtrustinrecommendersys-
tems:anexperimentalanalysis[C]//LNCS2995:Proceedings
不一，同一用户对同一商品的评分在不同时间点存
of the 2nd International Conference onTrust Management,
在差异，由此可以发现可疑用户，以此提高推荐准确
Oxford, Mar 29-Apr 1, 2004. Berlin, Heidelberg: Springer,
率。以上两点可以作为下一步的研究方向。 2004:221-235.
[12] Ma Hao, Zhou Dengyong, Liu Chao, et al. Recommender
systems with social regularization[C]//Proceedings of the
References:
4thInternationalConferenceonWebSearchandWebData
[1]BaiTiansheng,YangBo,LiFei.TDRec:enhancingsocial
Mining, Hong Kong, China, Feb 9-12, 2011. New York:
recommendation using both trust and distrust information
ACM,2011:287-296.
[C]//Proceedingsofthe2ndEuropeanNetworkIntelligence
[13]ChenWei.Multi-collaborativefilteringtrustnetworkforon-
Conference,Karlskrona,Sep21-22,2015.Washington:IEEE linerecommendation[J].InformationSystemsFrontiers,2015,
ComputerSociety,2015:60-66. 15(4):533-551.
[2] Breese J S, Heckerman D, Kadie C. Empirical analysis of [14] Ma Hao, Lyu M R, King I. Learning to recommend with
predictive algorithms for collaborative filtering[C]//Proceed- trust and distrust relationships[C]//Proceedings of the 2009
ingsofthe14thConferenceonUncertaintyinArtificialIntel- Conference on Recommender Systems, NewYork, Oct 23-
ligence, Madison, Jul 24-26, 1998. San Francisco: Morgan 25,2009.NewYork:ACM,2009:189-196.
KaufmannPublishersInc,1998:43-52. [15]KorenY,BellR,VolinskyC.Matrixfactorizationtechniques
[3]WangLicai,MengXiangwu,ZhangYujie.Context-aware forrecommendersystems[J].Computer,2009,42(8):30-37.
recommendersystems[J].JournalofSoftware,2012,23(1): [16]Wang Peiying. Community discovery and collaborative fil-
1-20. teringrecommendationinsocialnetworks[D].Beijing:Bei-
[4]ZhangYanmei,WangLu,CaoHuaihu,etal.Recommenda- jingJiaotongUniversity,2016.
tion algorithm based on user-interest-item tripartite graph [17]DuYongping,DuXiaoyan,HuangLiang.Improvethecol-
[J].PatternRecognitionandArtificialIntelligence,2015,28 laborative filtering recommender system performance by
(10):913-921. trust network construction[J]. Chinese Journal of Electron-
[5] Lu Zhongqi, Dou Zhicheng, Lian Jianxun, et al. Content- ics,2016,25(3):418-423.
basedcollaborativefilteringfornewstopicrecommendation [18]FoussF,SaerensM.Evaluatingperformanceofrecommender
[C]//Proceedingsofthe29thConferenceonArtificialIntel- systems:anexperimentalcomparison[C]//Proceedingsofthe 郭宁宁 等：融合社交网络特征的协同过滤推荐算法 217
2008InternationalConferenceonWebIntelligenceandIntel- dationwithtrusterandtrusteerelationshipinusertrustnet-
ligent Agent Technology, Los Alamitos, Dec 9-12, 2008. work[J].InformationSciences,2016,374(C):100-114.
Washington:IEEEComputerSociety,2008:735-738.
[19]RennieJDM,SrebroN.Fastmaximummarginmatrixfac- 附中文参考文献：
torizationforcollaborativeprediction[C]//Proceedingsofthe
[3]王立才,孟祥武,张玉洁.上下文感知推荐系统[J].软件学
22nd International Conference on Machine Learning, Bonn,
报,2012,23(1):1-20.
Aug7-11,2005.NewYork:ACM,2005:713-719.
[4]张艳梅,王璐,曹怀虎,等.基于用户-兴趣-项目三部图的
[20] MaoYiyu, Liu Jianxun, Hu Rong, et al. Sigmoid function-
推荐算法[J].模式识别与人工智能,2015,28(10):913-921.
based Web service collaborative filtering recommendation
[6]郭兰杰,梁吉业,赵兴旺.融合社交网络信息的协同过滤
algorithm[J].JournalofFrontiersofComputerScienceand
推荐算法[J].模式识别与人工智能,2016,29(3):281-288.
Technology,2017,11(2):314-322.
[8]王升升,赵海燕,陈庆奎,等.个性化推荐中的隐语义模型
[21] Jamali M, Ester M. A matrix factorization technique with
[J].小型微型计算机系统,2016,37(5):881-889.
trust propagation for recommendation in social networks
[10]潘骏驰,张兴明,汪欣.融合用户可信度的改进奇异值分
[C]//Proceedings of the 4th ACM Conference on Recom-
解推荐算法[J].小型微型计算机系统,2016,37(10):2171-
mender Systems, Barcelona, Sep 26-30, 2010. New York:
2176.
ACM,2010:135-142.
[22]ForsatiR,MahdaviM,ShamsfardM,etal.Matrixfactoriza- [16]王培英.社会网络中的社区发现及协同过滤推荐技术研
tionwithexplicittrustanddistrustsideinformationforim- 究[D].北京:北京交通大学,2016.
proved social recommendation[J]. ACM Transactions on [20]毛宜钰,刘建勋,胡蓉,等.采用Sigmoid函数的Web服务
InformationSystems,2014,32(4):17. 协同过滤推荐算法[J].计算机科学与探索,2017,11(2):
[23]ParkC,KimD,OhJ,etal.Improving top-K recommen- 314-322.
GUONingningwasbornin1992.SheisanM.S.candidateatTianjinUniversity.Herresearchinterestsincluderecom-
mendationsystemanddatamining,etc.
郭宁宁（1992—），女，山东聊城人，天津大学电子信息工程学院宽带无线通信与3D成像研究所硕士研究生，主
要研究领域为推荐系统，数据挖掘等。
WANGBaoliangwasbornin1971.HereceivedthePh.D.degreefromTianjinUniversityin2010.Nowheisasenior
engineerandM.S.supervisoratTianjinUniversity.Hisresearchinterestsincludedatamining,mobileinternetand
imageprocessing,etc.
王宝亮（1971—），男，山东潍坊人，2010年于天津大学获得博士学位，现为天津大学高级工程师、硕士生导师，
主要研究领域为数据挖掘，移动互联，图像处理等。
HOUYonghong was born in 1968. He received the Ph.D. degree in communication and information system from
TianjinUniversityin2009.NowheisanassociateprofessorandPh.D.supervisoratTianjinUniversity.Hisresearch
interestsincludecomputervision,artificialintelligenceandmultimediasignalprocessing,etc.
侯永宏（1968—），男，山西太原人，2009年于天津大学获得博士学位，现为天津大学电子信息工程学院副教
授、博士生导师，主要研究领域为计算机视觉，人工智能，多媒体信号处理等。
CHANGPengwasbornin1980.HereceivedthePh.D.degreefromTianjinUniversityin2010.Nowheisaresearch
assistantatTianjinUniversity.Hisresearchinterestsincludedatamining,textminingandinformationretrieval,etc.
常鹏（1980—），男，山西太原人，2010年于天津大学获得博士学位，现为天津大学助理研究员，主要研究领域
为数据挖掘，文本挖掘，信息检索等。 --------------------------------------------------------------------------------- 44 Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57
Frontiers of Information Technology & Electronic Engineering
www.zju.edu.cn/jzus; engineering.cae.cn; www.springerlink.com
ISSN 2095-9184 (print); ISSN 2095-9230 (online)
E-mail: jzus@zju.edu.cn
Review:
*
Cross-media analysis and reasoning: advances and directions
Yu-xin PENG†1, Wen-wu ZHU†‡2, Yao ZHAO3, Chang-sheng XU4, Qing-ming HUANG5,
Han-qing LU4, Qing-hua ZHENG6, Tie-jun HUANG7, Wen GAO7
(1Institute of Computer Science and Technology, Peking University, Beijing 100871, China)
(2Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China)
(3Institute of Information Science, Beijing Jiaotong University, Beijing 100044, China)
(4National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China)
(5Key Laboratory of Intelligent Information Processing, Institute of Computing Technology,
Chinese Academy of Sciences, Beijing 100190, China)
(6Department of Computer Science and Technology, Xi’an Jiaotong University, Xi’an 710049, China)
(7School of Electronics Engineering and Computer Science, Peking University, Beijing 100871, China)
†E-mail: pengyuxin@pku.edu.cn; wwzhu@tsinghua.edu.cn
Received Dec. 7, 2016; Revision accepted Dec. 30, 2016; Crosschecked Jan. 1, 2017
Abstract: Cross-media analysis and reasoning is an active research area in computer science, and a promising direction for
artificial intelligence. However, to the best of our knowledge, no existing work has summarized the state-of-the-art methods for
cross-media analysis and reasoning or presented advances, challenges, and future directions for the field. To address these issues,
we provide an overview as follows: (1) theory and model for cross-media uniform representation; (2) cross-media correlation
understanding and deep mining; (3) cross-media knowledge graph construction and learning methodologies; (4) cross-media
knowledge evolution and reasoning; (5) cross-media description and generation; (6) cross-media intelligent engines; and (7)
cross-media intelligent applications. By presenting approaches, advances, and future directions in cross-media analysis and rea-
soning, our goal is not only to draw more attention to the state-of-the-art advances in the field, but also to provide technical insights
by discussing the challenges and research directions in these areas.
Key words: Cross-media analysis; Cross-media reasoning; Cross-media applications
http://dx.doi.org/10.1631/FITEE.1601787 CLC number: TP391
1 Introduction demonstrate rich natural and social properties. As a
whole they represent comprehensive knowledge and
Along with the progress of human civilization reflect the behavior of individuals and groups. Con-
and the development of science and technology, in- sequently, a new form of information is recognized,
formation acquisition, transmission, processing, and known as cross-media information.
analysis have gradually changed from one form of Over the past several decades, as the require-
media to multiple types of media such as text, image, ments for data management and utilization have in-
video, audio, and stereo picture. Different media creased significantly, multimedia information pro-
types on various platforms and modalities from social, cessing and analysis has been a research hotspot (Lew
cyber, and physical spaces are now mixed together to et al., 2006). However, previous studies were devoted
mainly to scenarios involving a single media. Re-
‡ Corresponding author search in cognitive science indicates that in the human
* Project supported by the National Natural Science Foundation of brain, cognition of the environment is through the
China (Nos. 61371128, U1611461, 61425025, and 61532005)
fusion of multiple sensory organs (McGurk and
ORCID: Yu-xin PENG, http://orcid.org/0000-0001-7658-3845
MacDonald, 1976). Although the representations of
© Zhejiang University and Springer-Verlag Berlin Heidelberg 2017 Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57 45
different media types are heterogeneous, they may ternal environment. Although considerable im-
share the same semantics, and have rich latent corre- provement has been made in the research of cross-
lations. Consider the topic of ‘bird’ as an example. All media analysis and reasoning (Rasiwasia et al., 2010;
of the texts, images, videos, audio clips, and stereo Yang et al., 2012; Peng et al., 2016a; 2016b), there
pictures about this topic describe the same semantic remain some important challenges and unclear points
concept ‘bird’ from complementary aspects. As a in future research directions. In this paper, we give a
result, due to limitations in information diversity, comprehensive overview of not only the advances
traditional single-media analysis methods have dif- achieved by existing studies, but also future directions
ficulty in achieving the goal of semantic extraction for cross-media analysis and reasoning. The aim is to
from multiple modalities, and cannot deal with the attract more researchers to the research field in
analysis of cross-media data. Meanwhile, traditional cross-media analysis and reasoning, and thus we
reasoning methods are mainly text-based and perform provide insights by discussing challenges and re-
reasoning under fully defined premises. They cannot search directions, to facilitate new studies and appli-
deal with cross-media scenarios with sophisticated cations on this new and exciting research topic.
compositions, different representations, and complex
correlations. Therefore, a key problem in research and
2 Cross-media analysis and reasoning
application has been how to simulate the human
brain’s process of transforming environmental in-
The advances and directions in cross-media
formation to analytical models through vision, audi-
analysis and reasoning can be summarized as seven
tion, language, and other sensory channels, and fur-
parts: (1) theory and model for cross-media uniform
ther to realize cross-media analysis and reasoning.
representation; (2) cross-media correlation under-
The topic of cross-media analysis and reasoning
standing and deep mining; (3) cross-media
has attracted considerable research interest. With
knowledge graph construction and learning method-
respect to cross-media analysis, existing studies focus
ologies; (4) cross-media knowledge evolution and
mainly on modeling correlations and generating a
reasoning; (5) cross-media description and generation;
uniform representation of two media types as in the
(6) cross-media intelligent engines; (7) cross-media
popular correlation analysis method, called canonical
intelligent applications. In this section, we will pro-
correlation analysis (CCA) (Hotelling, 1936). Though
vide descriptions of these seven parts, so as to present
there are limited studies on cross-media reasoning so
a comprehensive overview of cross-media analysis
far, it is an important future direction to extend tradi-
and reasoning.
tional text-based reasoning methods to cross-media
2.1 Theory and model for cross-media uniform
scenarios. There are also wide prospects for applica-
representation
tions in cross-media analysis and reasoning. Effective
yet efficient cross-media methods can provide more Cross-media data naturally carries different
flexible and convenient ways to retrieve and manage kinds of information, which needs to be integrated to
multimedia big data. Users would like to adopt the obtain comprehensive results in real-world applica-
cross-media intelligent engine for applications such tions. A fundamental research problem is how to learn
as cross-media retrieval, and cross-media technology uniform representation for cross-media data. Gener-
is also useful for important application scenarios, ally, this approach tries to build a commonly shared
such as web content monitoring, web information space where similarities between heterogeneous data
trend analysis, and healthcare data fusion and rea- objects can be computed directly using common dis-
soning. However, there still exist important chal- tance metrics like Euclidean and cosine distances
lenges for cross-media intelligent applications. after mapping data into this space (Fig. 1). In this way,
Cross-media analysis and reasoning has been an the heterogeneous gap among data from different
active research area in computer science, and an im- modalities is reduced. To this end, two issues should
portant future direction in artificial intelligence. As be addressed: (1) how to build the shared space; (2)
discussed in Pan (2016), cross-media intelligence how to project data into it. To deal with these issues,
plays the role of a cornerstone in artificial intelligence, learning schemes based on different models have
through which the machines can recognize the ex- been proposed recently. 46 Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57
Image space
Commonly shared space
Text space
Fig. 1 An example of uniform representation methods for multimodal data (considering the images and texts as
examples)
To the best of our knowledge, the first well- to represent data, where each MMD is a set of media
known cross-media model is based on CCA (Rasi- objects of different modalities but carrying the same
wasia et al., 2010). It learns a commonly shared space semantics. The distances between MMDs are related
by maximizing the correlation between pairwise to each modality, and in this way we can perform
co-occurring heterogeneous data and performs pro- cross-media retrieval. Daras et al. (2012) employed a
jection by linear functions. Although the scheme is radial basis function (RBF) network to address the
simple, it has inspired subsequent studies. CCA has problem of missing modalities. However, the main
many variants (Andrew et al., 2013; Gong et al., 2014; problem with the MMD is that it only handles data
Rasiwasia et al., 2014). For example, Andrew et al. from different modalities together, which is not flex-
(2013) extended this method using a deep learning ible in many applications. Most cross-media repre-
technique to learn the correlations more comprehen- sentation learning models still belong to subspace
sively than those using CCA and kernel CCA. These learning techniques.
methods can, for the most part, model only the cor- The topic model is another frequently used
relations of two media types. To overcome this limi- technique in cross-media uniform representation
tation, researchers have also attempted to develop learning tasks, assuming that heterogeneous data
datasets and methods for scenarios with more media containing the same semantics shares some latent
types. For example, the newly constructed XMedia topics. For example, Roller and Schulte im Walde
dataset (http://www.icst.pku.edu.cn/mipl/XMedia) is (2013) integrated visual features into latent Dirichlet
the first dataset containing five media types (text, allocation (LDA) and proposed a multimodal LDA
image, video, audio, and 3D model), and methods model to learn representations for textual and visual
such as those proposed by Zhai et al. (2014) and Peng data. Wang Y et al. (2014) proposed a scheme called
et al. (2016b) can jointly model the correlations and the multimodal mutual topic reinforce model (M3R),
semantic information in a unified framework with which seeks to discover mutually consistent semantic
graph regularization for the five media types on the topics via appropriate interactions between model
XMedia dataset. Yang et al. (2008) introduced an- factors. These schemes represent data as topic dis-
other model called the multimedia document (MMD) tributions, and similarities are measured by the Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57 47
likelihood of observed data in terms of latent topics. images described by those sentences. Feng et al.
Metric learning is usually performed if we know (2014) and Wang W et al. (2014) applied auto-
which data pairs are similar and which are dissimilar encoders to perform cross-modality retrieval. More
from heterogeneous modalities. An appropriate dis- recently, Wang et al. (2015) proposed a multimodal
tance metric is designed to measure heterogeneous deep learning scheme to learn accurate and compact
similarity, and learned using the given labeled data multimodal representations for multimodal data
pairs to achieve the best performance. When the (Fig. 2). This method facilitates efficient similarity
learned metric is decomposed into modality-specific search and other related applications on multimodal
projection functions (Wu et al., 2010), data can be data. Zhang et al. (2014a) presented an attribute dis-
explicitly projected into a uniform representation as covery approach, named the independent component
CCA does. Apart from the above-mentioned models, multimodal autoencoder (ICMAE), which can learn
Mao et al. (2013) proposed a manifold-based model shared high-level representation to identify attributes
called parallel field alignment retrieval (PFAR), from a set of image and text pairs. Zhang et al. (2016)
which considers cross-media retrieval as a manifold further proposed to learn image-text uniform repre-
alignment problem using parallel fields. sentation from web social multimedia content, which
In recent years, since deep learning has shown is noisy, sparse, and diverse under weak supervision.
superiority in image classification (Krizhevsky et al., Wei et al. (2017) proposed a deep semantic matching
2012) and image content representation (Babenko et (deep-SM) method that uses the convolutional neural
al., 2014), it has also been widely used in cross-media network and fully connected network to map images
research to learn uniform representations. Ngiam et al. and texts into their label vectors, achieving state-of-
(2011) proposed an autoencoder model to learn uni- the-art accuracy. The cross-media multiple deep
form representations for speech audios coupled with network (CMDN) (Peng et al., 2016a) is a hierar-
videos of the lip movements. Srivastava and Sala- chical structure with multiple deep networks, and can
khutdinov (2012) introduced a deep restricted simultaneously preserve intra-media and inter-media
Boltzmann machine to learn joint representations for information to further improve the retrieval accuracy.
multimodal data. Andrew et al. (2013) proposed a Although there are significant research efforts on
deep CCA method which is a deep extension of the uniform representation learning for cross-media
traditional CCA method. Socher et al. (2014) intro- analysis tasks, a large gap still exists between these
duced dependency tree recursive neural networks methods and user expectations. This is caused by the
(DT-RNNs), employing dependency trees to embed fact that existing schemes still have not achieved a
sentences into a vector space in order to retrieve satisfactory performance; i.e., their accuracies are far
xˆ 1 ... xˆ P xˆ 1i ... xˆ Pi
... ... ... ...
Joint RBM ... ... ... ...
h ...
... ... ... ...
h 1 (m1) ... ... h P(mP) h ... Code layer h ...
... ...
h 1(m1) ... ... h P(mP) ... h i(mi)
h (1) ... ... h(1)
1 P ... ...
x 1 ... x P
Modality 1 Modality P h 1(1) ... ... h P(1) ... h i(1)
x 1 ... x P x i
Modality 1 Modality P Modality i
(a) (b)
Fig. 2 The framework for compact multimodal representation learning, where (a) represents the pretraining stage and
(b) represents the fine-tuning stage 48 Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57
from acceptable. Therefore, we still need to investi- structured, and structured data. However, most of
gate better uniform representation methods for cross- these studies are based on low-level features and
media research. formats. Few studies are focusing on multimodal
content and high-level correlations, e.g., generating a
2.2 Cross-media correlation understanding and
description for the entities by fusing semi-structured
deep mining
Wiki data and unstructured web data. Moreover,
Cross-media correlations describe specific types cross-media data is not only from different modalities
of statistical dependencies among homogeneous and and structures, but also from different sources. The
heterogeneous data objects. For example, if two im- study of associating and fusing cross-media data from
ages are taken from the same location, they may be different sources remains in its infancy, e.g., objective
intrinsically correlated from content, attribute, and data and subjective user-generated content (UGC),
topic perspectives, and thus they may share certain user data from different online social networks
levels of intrinsic semantic consistency. The content (OSNs), and cross-space data from cyber and physical
in the paragraphs and social comments on a video spaces.
webpage is semantically related to the content of the
Image Text Image Text
video itself. The aim of cross-media correlation reconstruction reconstruction reconstruction reconstruction
... ... ... ...
learning is to construct metrics on heterogeneous data
representation to measure how they are semantically
Code layer
... ...
relevant.
Existing cross-media correlation mining meth-
ods focus mainly on finding the common subspace ... ...
Image raw feature Text raw feature
where different modalities of data have semantic
Fig. 3 Correspondence full-modal autoencoder (Feng
correlations. Researchers from the multimedia com-
et al., 2014)
munity have conducted extensive studies along this
line. For example, in Feng et al. (2014), the corre- In cross-media deep mining, the knowledge base
spondence autoencoder deep network was proposed to is manually and professionally edited by experts in
be trained on the raw features of different modalities, traditional expert systems. Currently, many studies
and then the combined multimodal deep feature was are focusing on extracting and learning knowledge
extracted for cross-media relevance measurement from data automatically, e.g., Google Knowledge
(Fig. 3). Zhang et al. (2014b) measured the correla- Vault (Dong et al., 2014). However, similar to data,
tions between visual and acoustic modalities by ex- knowledge is essentially cross-media. Recently we
amining the visual-acoustic statistical relevance. have seen a rapid development of different types of
However, cross-media correlation mining goes far intelligent perceptions, e.g., vision-based environ-
beyond subspace learning. In many scenarios, the mental perception in Visual SLAM (Fuentes-Pacheco
representation of cross-media data objects cannot be et al., 2015) and multimodal based human-computer
directly obtained. For example, there is no given interaction in gesture and action recognition (Rau-
feature representation for a structured cross-media taray and Agrawal, 2015). Moreover, ubiquitous
object such as a set of hyperlinked multimedia doc- perception has received increasing attention these
uments or points-of-interest (POI). In such cases, the days (Adib et al., 2015). Development in the above
correlations can be inferred directly from the areas provides opportunities to research the problem
cross-media data objects by constructing appropriate of cross-media knowledge mining. While critical
information averaging mechanisms in a matrix com- challenges exist in constructing the cross-media
pletion framework to predict or complete the missing knowledge base, it is of great theoretical and technical
values in the object correlation description (Zhang et significance to combine perceptions from different
al., 2015). modalities to supplement and improve the current
Following another line of research, researchers text-based knowledge base.
from the database community have investigated the Despite the achievements in cross-media corre-
correlations and fusion among unstructured, semi- lation understanding, there is still a long way to go in Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57 49
this research direction. Basically, existing studies knowledge bases to describe relations between visual
construct correlation learning on cross-media data objects, scenes, and attributes (Deng et al., 2009;
with representation learning, metric learning, and Chen X et al., 2013; Prabhu and Babu, 2015). For
matrix factorization, which are usually performed in a example, NEIL (Chen X et al., 2013) presents a
batch learning fashion and can capture only the never-ending learning system for visual ontology
first-order correlations among data objects. How to construction from image search engines, which iter-
develop more effective learning mechanisms to cap- ates between concept relationship extraction, image
ture the high-order correlations and adapt to the instance recognition, and concept classifier/detector
evolution that naturally exists among heterogeneous learning. Fang et al. (2016) proposed a multimodal
entities and heterogeneous relations, is the key re- ontology construction solution by considering both
search issue for future studies in cross-media corre- textual and visual information in extracting entity
lation understanding. relationships. Zhu et al. (2015) proposed a scalable
multimodal knowledge base construction system, and
2.3 Cross-media knowledge graph construction
defined three types of relations: image-label, intra-
and learning methodologies
correlations, and inter-correlations. Sadeghi et al.
The aim of cross-media knowledge graph con- (2015) developed the visual knowledge extraction
struction is to represent framed rules, values, expe- system (VisKE), which can extract some general
riences, contexts, instincts, and insights with entities relationships like ‘eat’ and ‘ride’ from the context of
and relations from general to specific domains image and text. Hua et al. (2014) went beyond on-
(Davenport and Prusak, 1998). In cross-media re- tology co-occurrences (Cilibrasi and Vitanyi, 2007) in
search, the entities and relations are defined and ex- most of the existing visual knowledge bases, and
tracted from not only the textual data corpus, but also proposed to measure the ontology similarity by com-
numerous loosely correlated data modalities includ- bining visual, textual, and semantics cues. By design-
ing texts, images, videos, and other related infor- ing human-expert-powered, semi-automatic, and fully
mation sources. Cross-media knowledge graphs pro- automatic procedures, diverse types of knowledge
vide essential computable knowledge representation graphs have been constructed and released for real
structures for semantic correlation analysis and cog- applications, containing more than 60 billion ontolo-
nition-level reasoning in cross-media context, facili- gies and trillions of facts/relations, and covering a
tating theoretical and technical development in wide range of domains from geography to life science
cross-media intelligence and a diversified range of (Fig. 4). Unfortunately, none of them are specifically
applications. designed to represent knowledge in cross-media data.
In recent decades, research efforts on knowledge The second area of focus on knowledge graphs is
graphs have been devoted to two aspects. First, how to deploy knowledge graphs to enhance the
knowledge graphs are used to represent general or performance and user experience in information re-
domain-specific knowledge. Two primary elements in trieval and web applications, especially in the era of
knowledge graphs are entities (a.k.a. ontologies) and big data. As a pioneering work, Garfield (2004)
relations. The set of entities for knowledge graph developed the HistCite software to generate
construction is defined by either domain expertise or knowledge graphs in academic literature, which led to
existing entity sets, e.g., WordNet (Fellbaum and the birth of the academic search engine CiteSeer. The
Miller, 1998), Wikipedia, and FreeBase. The relations, Knowledge Graph released by Google in 2012
represented as edges with real values between the (Singhal, 2012) provided a next-generation infor-
entities, are employed to reflect structural or statisti- mation retrieval service with ontology-based intelli-
cal entity dependency in certain domain contexts. gent search based on free-style user queries. Similar
Most existing knowledge graphs are constructed on a techniques, e.g., Safari, were developed based on
textual data corpus using natural language processing achievements in entity-centric search (Lin et al.,
(Carlson et al., 2010) and co-occurrence statistics 2012). However, existing entity-based search engines
(Cilibrasi and Vitanyi, 2007). In visual modalities, cannot perform fully automatic content parsing on
significant efforts have been devoted to constructing heterogeneous modalities, and thus they cannot 50 Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57
S TG SL p r ci e io nac n oel dh fv d g tn f lfW i ad ciILD Sd CSs ed a
(
cE t Ol P x Foa rae S a&u UREtdn mpt Dg l Ca Dx Bsa id si nl O (s p
I
)s . Rgl lRa oKo Dt rBA vE i eIo . SK rn u( n )E Te kn ir ng - g dry oe an) GLvf tc . oe aa uer n. zke g edP Gto o t os n eU ct vsc kK ToN A E rdH K A am enT KS C T( Ti( iOn EE s i Wnn2g dsn ig-) i n- ) a Co tt LeM i a uAt Oy rK .o kg( g vT Gr E )t in aoC (naA D r-r Sl lE dK v Ui g s Em n T f) S.
C
a- i e n bS( r d Ooe ua nrvcs rt d c.he va u en ea . k ag yr e tb Cd i Eto aod
(
euu a Ov . on u ns ru gs t . gons t. kai u oc d ryn
st
. aa O ok tvag Le
a
lt l. )op y ce t d a rn d as all t a tn Ea a ut s ut a tu . kp pd i ag ro .s ka g o ta oov tt t os si. vre a cu F tv .n .u ska g .t Obn zH p Se
(e
Kn nL nE sia IL onB s oRra p .sE keTt rr es t Uni c ua e u ast lh .Da Br. tt sdn tk oF (- )s
a
i. Fe -PM s( INL tnD ) )Dr O atA c o m oB a uI S rUg tB bA )aer SC a (sam L DiGW F n aiB e kniRS tB el C o edd au a C Te dolr d i r afg ni oxoe c F foL e i rTa n sr p id h es ett f e x si. aM szF eBe sM u g) B TP rT s( CJ e ae iuo sc l p Ue B enh hl - N Me(n iD L) G a Bme L EDo iGe n Oa Cs e k ptI yo e a enD C cA d( nci hD ms u r rc a nb ) o eo t ga C n rTag a Tlt iu il as N Yco ( c in s D ma ol es e i FB r WI i w e)n c k a Y B sM oc c o A( u t kr D Lr b Gau b l ea d oai Os F xt n Utai vrc oz e b o(r eD e) BM b rBr bM aTau E lu si vs in e ceni ec z de n) iat liP nBo g jue Uk vx re oR nd I( eJ Da r(BM z m Br i Pt EPTau g e e no duis i L Mnn ds k ibi int pc d i nz e d) la pDe i eGo k D te) B dee dr B de DDD ii aP a ie ae BBBkFG D PPPaw Po gm B eeeio o un PL id l dddr e yo et s iiiu dt Le aaai - i ic w a nCOgo krf an D Mplo a elo i aR aech p ds eiinD ksi lsp d Co yrF e Th r RD e BDut vai as C i rk d SL ylt
u
nwl r i saua b eiu a gu knn e Gcp n e Trb a Gr P Dtn mk vp l gb C es ri uc e ee cc Io- .e nMl ta To rh jed ee gn- O P cN bton e rt w to ass Ul M sDF O nE D oS S Bm o iR iax S sWe om m PoT o sp eDem g row od h ad dy ee an oF pk u car ata e tci -t ep tn E se ua a nt t c d k-i S -Loc C Do is nou ay kdr s te Sc ate ud See Id m B DDy oo N EDcov RBBC EDis e( Rt B F PrT AS u lU DLh iS r nPe BuWRh g )M s see aL R Pa ga s i est d l un Lye t ai tc imsnr sdh t Si Io sn d u bdR Bd n Pa Lie o ff s Ubt O a. Df ec a f B N mCr Ea / OD (LB 3LO LL di Sb Pi )Lp n N tr C hke a sCe e .n r fy s r Ce Ea S E Im ou
V
no Pl E mra p ndIu r eC Vitm ait nS ao c Oh t nna se EsT xuh D ( pr W P Re u B l2 oKs s La 0. rBP eP CrS )R IA M tHA eU eM a SS PU n em EH rE sxnB e( iE R np rrh C K l t)oSe B r i eUlm AL CS mC o MES puCH ttn S ohd na di on R ta AD g Are EBa Cs 2ipto Oc h 0-h i Ae 0e I 1Wiki IG RIN TD S IET EW EcNI aB e sM w tle-R DE OES P YE LX
(L O CEi enDn ntGk o trA le o aRd g l)y S AP de X ci am e ctB nd oiota m mR nn o osLtic TVG old
a
ue Eo o
j
rNu el iW t se r) moto r
D
COU o( rJSr o
c i
daS Md lu el
l i
sf r
i
caC Ca n
n
ene b
g
sn os uu ts ) Cli n Am g Eb Mi EE TUN
M
WIS
e et
aG
o
tfL hfe
i
ei cn o rek De aT dw taarql EARAA Tul hSp ski tW nlrW ie a(o V (o Wr Ud rdA 3N N C)e )et t GEMETW EC xo o ( pr Rrn lod Ke rN Bt et e ro )t
TO -D uhp a ree ut san
saAto Get Otl L R. Cn O OD VE
OL Cpi
oS
n
eT I lkSo ona eVm rx
ed
sUo dyn Aff Cy him x Ee Mtr
BL
(BU P Oin o Mu Mi 2 bP R IMr Do eFt ) d
Int re
orPPS OGRI oT neO gE tn- yoe l MGIPROMDO SGD GeneIDHGNC CP hu Peb am
K tE hG wG
aS yTITCH K DE r KG Eu mE nG g G
z
eyGCV oI rV lnO el LA V UA IVS FO GeK oIS gT
M
rI
ae pd hi ia
c
Forecasts
SWtaetaitohnesr Air tp sor
P cr to Dd Bu
OP nTro y topd leu osc gt y I Mt ua muli sa sen G wo A ro arg pt l pe
S Lm ina krt
UniParc UniRef Un SiST
M Cae rd ei User-generaP tu edb l cic oa nt tio en ns
t
er Government
Cross-domain
Life sciences
Fig. 4 An illustration of existing knowledge graphs
provide entity-based information retrieval for cross- 2.4 Cross-media knowledge evolution and rea-
media content. soning
To transform the web of data into a web of know-
Early artificial intelligence systems mostly de-
ledge (Suchanek and Weikum, 2014), several issues
pend on texts to perform reasoning using predicates,
should be considered in research on cross-media
propositions, and rules, under fully defined premises.
knowledge graphs. First of all, effective and efficient
Judea Pearl, as a National Academy of Engineering
techniques for entity extraction and relation con-
(NAE) member and Turing Award winner, was one of
struction from heterogeneous cross-media infor-
the pioneers in probabilistic and causal reasoning in
mation sources should be studied. Second, infor-
artificial intelligence (Pearl, 2000). Radinsky et al.
mation search and retrieval based on cross-media
(2012) proposed a methodology for modeling and
knowledge graphs should be investigated to provide
predicting future events by generalizing examples of
more effective knowledge harvesting and information
causality pairs to infer a causality predictor. Some
seeking mechanisms for more diverse application
research institutions, such as Illinois State University
contexts. Third, mining and reasoning in cross-media
knowledge graphs should be developed to facilitate and Michigan State University, attempted to estimate
knowledge acquisition and high-level reasoning for county health statistics (Culotta, 2014) and the un-
real applications. Finally, knowledge-driven cross- employment rate (Antenucci et al., 2013) by analyz-
media learning models will be required in the near ing social media content. Google Flu Trends (Gins-
future to achieve more generalization and learning berg et al., 2009) analyzes search patterns on the web
capabilities, resulting in more advanced cross-media search engine to help predict the spread of influenza
intelligence. (Fig. 5). Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57 51
big data. Therefore, the problem of performing cross-
2008-2009 Past years
Minimal media reasoning based on multiple media types rather
Low than on only text information, has become important
Moderate
F lu Trends High in both research and application areas. Note that there
Intense is little research on cross-media knowledge evolution
and reasoning, and many key problems need to be
solved, which include, for instance, the acquisition,
Jun Jul Aug Sep Oct Nov Dec Jan Feb Mar Apr May
representation, mining, learning, and reasoning of
Fig. 5 Google Flu Trends
cross-media knowledge, and the construction of
large-scale cross-media knowledge bases. We still
In addition, it has been shown that some learning need to confront the significant challenges that are
mechanisms, such as reinforcement learning and involved in constructing cross-media reasoning sys-
transfer learning, can be helpful for constructing more tems for real applications.
complex intelligent reasoning systems (Lazaric, To address the problems noted above, several
2012). Furthermore, lifelong learning (Lazer et al., issues should be studied further. First, it is important
2014) is the key capability of advanced intelligence to study data-driven and knowledge-guided cross-
media knowledge learning methods. Second, cross-
systems. For example, Google DeepMind has con-
media reasoning frameworks based on semantic un-
structed a machine intelligence system based on a
derstanding should be constructed with technologies
reinforcement learning algorithm (Gibney, 2015),
such as cross-media deep learning and multi-instance
which beat humans at classic video games. Recently,
learning. Third, never-ending knowledge acquisition,
AlphaGo, developed by Google DeepMind, has been
mining, and evolution processes should be compre-
the first computer Go program that can beat a top
hensively investigated in future work.
professional human Go player. It even beat the world
champion Lee Sedol in a five-game match. We have 2.5 Cross-media description and generation
witnessed increasing numbers of intelligence systems Cross-media description and generation aims to
winning human-machine competitions. realize cross-translation among text, image, video,
However, the knowledge and reasoning process and audio information, and link the multimodal un-
in the real world usually involves collaboration derstanding with natural language descriptions, where
among language, vision, and other types of media visual content description is the most challenging task.
data. Most existing intelligent systems exploit only Therefore, we will stress this challenge in the fol-
the information from a single media type, such as text, lowing discussion. Visual content description is a new
to perform reasoning processes. There have been research direction integrating natural language pro-
some recent works involving reasoning on cross- cessing and computer vision. It requires not only the
media data. Visual question answering (VQA) can be recognition of visual objects and their semantic in-
regarded as a good example of cross-media reasoning teractions, but also the ability to capture visual-
(Antol et al., 2015). VQA aims to provide natural language interactions and learn how to translate the
language answers for questions given in the form of visual understanding into sensible sentence descrip-
combination of the image and natural language. tions. Fig. 6 shows some examples of visual content
Johnson et al. (2015) attempted to improve the ac- descriptions.
curacy of image retrieval with the assistance of the Existing studies on visual content description
scene graph, which also shows the idea of cross- can be divided into three groups. The first group,
media reasoning. A scene graph presents objects and based on language generation, first understands
their attributes and relationships, which can be used to images in terms of objects, attributes, scene types, and
guide image retrieval at the semantic level. However, their correlations, and then connects these semantic
it is still hard for these systems to make full use of the understanding outputs to generate a sentence de-
rich semantic information contained in complemen- scription using natural language generation tech-
tary media types, and they cannot perform complex niques, e.g., templates (Yang et al., 2011), n-grams
cross-media analysis and reasoning on multimedia (Kulkarni et al., 2011), and grammar rules 52 Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57
(Kuznetsova et al., 2014). These methods are direct temporal information with RNN, and thus they re-
and intuitive, but the sentences generated are limited ceive more attention. However, it is still a preliminary
by their syntactic dependency and thus are inflexible. exploration and there exist many problems regarding
further research: (1) As the parameter size of deep
neural network is huge, it demands large amounts of
annotated data for training and is easy to overfit,
which makes sentence generation depend heavily on
the training set; (2) The global features from CNN
(a) A dog is wearing (b) Several cars and a motorcycle (c) Some people in chairs and a child
(a) a red sombrero (b) are on a snow covered street (c) watch someone playing a trumpet have difficulty in representing local objects accurately,
which results in incorrect or missing descriptions of
local objects, especially their correlation in images.
In conclusion, the current research is centered
(d) A girl is putting her finger into a plastic cup containing an egg mainly on natural language descriptions of single-
Fig. 6 Examples of visual content descriptions, where media content, and improvements are needed in the
(a)–(c ) represent image descriptions and (d) represents a areas of training set collection and application, model
video description
building, and efficient learning and optimization
modeling with human cognition. Furthermore, the
The second group covers retrieval-based meth- cross-media descriptions of text, image, video, and
ods, retrieving content that is similar to a query and audio are rarely involved, such as image generation
transferring the descriptions of the similar set to the from text and video generation from audio. Consid-
query. According to the differences in the retrieval ering that human cognition is an integrated under-
feature space, studies in this group include two types, standing procedure of different types of sensory in-
i.e., retrieval in a uni-modal space (Ordonez et al., formation, it becomes a very challenging but valuable
2011) and in a multimodal space (Hodosh et al., 2013). task to implement a comprehensive and accurate
The former aims to search for similar images or vid- description of multimodal information with natural
eos in the visual feature space, and the latter projects language processing. The connections with complex
images or videos and sentence features into a com- cognition, human emotion, and logical reasoning are
mon multimodal space, and searches for similar also attractive areas for in-depth exploration.
content in the projected space. Sentences obtained
2.6 Cross-media intelligent engines
with these methods are more natural and grammati-
cally correct, but they usually suffer with regard to The intelligent engine is a kind of intelligent
generating variable-length and novel sentences. analysis and reasoning system having specific pur-
The third group is based on deep neural networks, poses and common knowledge. With the rapid de-
employing the CNN-RNN codec framework, where velopments in artificial intelligence, some interna-
the convolutional neural network (CNN) is used to tional companies and research institutions have im-
extract features from images, and the recursive neural plemented text-based artificial intelligent systems
network (RNN) (Socher et al., 2011) or its variant, the with specific capabilities. Technology companies
long short-term memory network (LSTM) (Hochreiter such as Google, Baidu, and Microsoft have proposed
and Schmidhuber, 1997), is used to encode and de- the concept of intelligent search and the framework
code language models. These methods typically use for search techniques (Uyar and Aliyu, 2015). Based
neural networks for both image-text embedding and on the highly effective indexing of big data, intelli-
sentence generation (Karpathy and Li, 2015; Vinyals gent search attempts to realize intelligent and hu-
et al., 2015), and visual attention (Xu et al., 2015) or manized information services, allowing users to re-
semantic guidance (Jia et al., 2015) is also integrated trieve whatever they want with input in natural lan-
in the model learning to further improve the perfor- guage forms. It can provide more convenient and
mance. Compared with the other methods, the deep accurate search results than traditional search engines.
models benefit from a stronger feature expression In the field of medical treatment, researchers have
ability from CNN and capture dynamic spatio- also proposed the technological concept of the Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57 53
intelligent medical search engine (Luo and Tang, ties in autonomic learning and evolution. The effi-
2008). cient intelligent engine would act as a bridge between
In the late 1990s, Deep Blue and Deeper Blue, technologies and applications, which could integrate
developed by IBM, were the first computer chess- cross-media uniform representation, correlation
playing systems that won a chess match against a learning, knowledge evolution, reasoning, and so on.
reigning world champion (Hsu, 2002). Siri, an intel- Such an engine would provide cross-media analysis
ligent personal assistant developed by Apple Inc. in and reasoning services, and be a computing platform
2010, is powered by natural language understanding for cross-media intelligent applications.
and driven by entity or ontology based technologies.
2.7 Cross-media intelligent applications
Later in 2011, IBM’s DeepQA project developed a
question answering computer system, named Watson The advent of the artificial intelligence era and
as shown in Fig. 7 (Ferrucci et al., 2013), which was the availability of huge amounts of cross-media data
specifically designed to play on the quiz show Jeop- have been revolutionizing the landscape in all indus-
ardy, and it won the first-place prize. It has been fur- try sectors. Among these, cross-media web content
ther improved for the Q&A service in medical diag- monitoring, web information trend analysis, and
nosis. The chatbots Xiaobing and Tay on Twitter de- healthcare data fusion and reasoning are three key
veloped by Microsoft, can improve their own intel- applications, which if well addressed would present
ligence level through communication with human important models and demonstration significance to
users. DeepMind has proposed an artificial intelli- all other areas. We will briefly review the preliminary
gence system based on Q-learning and the convolu- background, previous studies, as well as the existing
tional neural network (Mnih et al., 2015), which can challenges to be confronted.
adapt to different application requirements. iMonitor: The Internet is recognized as one of
the most influential factors for the stability of human
society. Many countries have built intelligent systems
Answer E sv oi ud re cn ec se hL ee lpa r cn oe md bm ino ed ae nls d
sources weigh the evidence to monitor the content propagating or streaming over
Question P sr eim ara cr hy gC eaa nnn esd rwi ad e ta iorte
n
A scn os rw ine gr E revi td rie en vc ae l e svD cid oe e re in np c ge MMM ooo ddd eee lll sss MMM ooo ddd eee lll sss the Internet, such as the PRISM system in the US, the
Tempora system in the UK, and the SORM system in
Q a& nu ae to ls ypt si io c isn decQ ou me ps otio sin tion H geyp no et rh ae tiosi ns eH vy idp eo nth cee s sis c oa rn ind g Synthesis Fin mal r e ac r no g kn in if ni gd g e &nce R wu ebss i ca o. n A tet nth t e m s oa nm ite o rti im nge , s C ysh ti en ma s i ,s sd ue cv he l ao sp ti hn eg Ga ose ldt eo nf
Shield Project for the Ministry of Public Security of
Hypothesis Hypothesis and
generation evidence scoring Answer &
confidence China. However, existing monitoring systems work
...
mainly in the form of passive sampling-post hoc
analysis, which limits the usefulness of existing sys-
Fig. 7 The high-level architecture of IBM’s DeepQA used
in Wa tson tems, and raises three challenges in the intelligent
systems community, namely (1) time lag, (2) insuffi-
However, cross-media big data is naturally cient coverage, and (3) high cost, especially consid-
multimodal and cross-domain, employing sophisti- ering the diversity of cross-media data.
cated compositions, different representations, and iTrend: Trend analysis of cross-media web in-
complex correlations. Existing intelligent systems formation is the key to improve the stability of human
and frameworks depend heavily on the structured society, by alleviating unnecessary social panic and
input and knowledge of specific domains. They understanding the evolution of public opinion. There
cannot adapt to the characteristics of cross-media data, are numerous existing studies on social media analy-
and cannot cope with the increasingly complex needs sis, sentiment analysis, and news verification. For
of general tasks (such as information retrieval) and example, the Xinhua News Agency explores verifi-
specific tasks (such as content monitoring) in cross- cation techniques on UGC data, and there is also the
media scenarios, which makes it very hard for them to PHEME project in the EU, the Tian-Ji system de-
realize cross-media intelligent analysis and reasoning. veloped by the Institute of Computing Technology,
To address these problems, it is essential to develop Chinese Academy of Sciences (ICT, CAS), and the
an efficient cross-media intelligent engine with abili- TRS analysis system. However, existing systems for 54 Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57
cross-media trend analysis suffer from the following Chen Y et al., 2013; Yuan et al., 2014) is limited due
three main limitations: (1) They are unable to effi- to (1) inability to perform cross-media fusion and
ciently collect cross-media data; (2) They have the analysis (Chen et al., 2007), (2) lack of supervision
disadvantage of under-utilization of cross-media data; from domain experts (Chen Y et al., 2013), and (3)
(3) The sequential characteristics of public opinion poor adaptability toward different medical paradigms.
are usually ignored in the analysis. To address these
challenges, trend analysis systems must be carefully iTrend framework
designed with three additional components, namely Information fusion
fusion, reasoning, and decision making. An advanced
framework is shown in Fig. 8.
Time and
iCare: Data-driven healthcare analytics (MIT space Data driven
modeling
Technology Review, 2014), based on the fusion of Time and Inversion
space fusion Aggregation reconstruction Inversion
massive cross-media data, is reforming the experi- situation and mining casual modeling
awareness reasoning
ence diagnostics and evidence-based medicine Situation Situation
forecasting reconstruction
(Brownson et al., 1999) toward the next stage, namely
personalized and precision medicine (Aamodt and
Plaza, 1994). Healthcare analytics is a key technique
eF ao rlr ye c wa as rt nin ing
g
M ta rain
c
ec ba au cs kes
for a wide range of real-world applications (Fig. 9). Early warning and
inversion theory
Many IT giants have joined the healthcare ana-
lytics community; e.g., IBM released Watson Health-
care (http://spectrum.ieee.org/computing/software/ibms- Decision-making control indicator system
Collaborative
watson-goes-to-med-school), Google announced decision-making
control
DeepMind (https://deepmind.com/health), and Baidu Collaborative decision-making optimization
just released Baidu Medical Brain. In spite of their
Collaborative
usefulness in certain areas, the applicability of exist- decision-making theory
ing models and algorithms (Kumar et al., 2012; Fig. 8 iTrend framework
Forecasting
Trend
inM foe rmdi aca til o Din
sease
manaP gre ed mic et niv te modeling
Data
min Ci fn
r
ug
o ss is o- nm ae nd dia C ir no ts es l- lm
ig
eA
e
nn da til aysis
reporting
StA as ts ie ss ts icm ae ln t
analysis
Public health
M e md aic
n
aS aE lO
g
r ee mso eu nr tce
Resource managem
Stae tin stt
ics
Vis
u al
a n
al
ytics
reaso cn oin mg
C pr uo
tD
s is
na
-
gt ma
pe
Plada
eti
rn
a
f
soa orly
m
n
s ali is
zed
analysis
TPe ar rf gor em
t
anc Fe
i
na ann
cal iay
l
s ri es
porting
H hoo ss pp ii tt aa ll aa ln lid
a nce
Effectiveness analysis Trend
Pharma Marketing and sales
Fig. 9 Existing applications in healthcare analytics Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57 55
3 Conclusions Chen, X., Shrivastava, A., Gupta, A., 2013. NEIL: extracting
visual knowledge from web data. IEEE Int. Conf. on
Computer Vision, p.1409-1416.
In this paper, we have presented an overview of
http://dx.doi.org/10.1109/ICCV.2013.178
cross-media analysis and reasoning. The advances Chen, Y., Carroll, R.J., Hinz, E.R.M., et al., 2013. Applying
achieved by existing studies, as well as the major active learning to high-throughput phenotyping algo-
challenges and open issues, have been shown in the rithms for electronic health records data. J. Am. Med.
Inform. Assoc., 20(e2):253-259.
overview. From the seven parts of this paper, it can be
http://dx.doi.org/10.1136/amiajnl-2013-001945
seen that cross-media analysis and reasoning has been
Cilibrasi, R.L., Vitanyi, P.M.B., 2007. The Google similarity
a key problem of research, and has wide prospects for
distance. IEEE Trans. Knowl. Data Eng., 19(3):370-383.
application. The introduction and discussion in this http://dx.doi.org/10.1109/TKDE.2007.48
paper are expected to attract more research interest to Culotta, A., 2014. Estimating county health statistics with
this area, and provide insights for researchers on the twitter. ACM Conf. on Human Factors in Computing
Systems, p.1335-1344.
relevant topics, so as to inspire future research in
http://dx.doi.org/10.1145/2556288.2557139
cross-media analysis and reasoning.
Daras, P., Manolopoulou, S., Axenopoulos, A., 2012. Search
and retrieval of rich media objects supporting multiple
Acknowledgements multimodal queries. IEEE Trans. Multim., 14(3):734-746.
http://dx.doi.org/10.1109/TMM.2011.2181343
The authors would like to thank Peng CUI, Shi-kui WEI,
Davenport, T.H., Prusak, L., 1998. Working Knowledge: How
Ji-tao SANG, Shu-hui WANG, Jing LIU, and Bu-yue QIAN for
Organizations Manage What They Know. Harvard Busi-
their valuable discussions and assistance.
ness School Press, Boston, p.5.
Deng, J., Dong, W., Socher, R., et al., 2009. ImageNet: a large-
References scale hierarchical image database. IEEE Conf. on Com-
Aamodt, A., Plaza, E., 1994. Case-based reasoning: founda- puter Vision and Pattern Recognition, p.248-255.
tional issues, methodological variations, and system ap- http://dx.doi.org/10.1109/CVPR.2009.5206848
proaches. AI Commun., 7(1):39-59. Dong, X., Gabrilovich, E., Heitz, G., et al., 2014. Knowledge
http://dx.doi.org/10.3233/AIC-1994-7104 vault: a Web-scale approach to probabilistic knowledge
Adib, F., Hsu, C.Y., Mao, H., et al., 2015. Capturing the human fusion. ACM SIGKDD Int. Conf. on Knowledge Dis-
figure through a wall. ACM Trans. Graph., 34(6):219. covery and Data Mining, p.601-610.
http://dx.doi.org/10.1145/2816795.2818072 http://dx.doi.org/10.1145/2623330.2623623
Andrew, G., Arora, R., Bilmes, J., et al., 2013. Deep canonical Fang, Q., Xu, C., Sang, J., et al., 2016. Folksonomy-based
correlation analysis. Int. Conf. on Machine Learning, visual ontology construction and its applications. IEEE
p.1247-1255. Trans. Multim., 18(4):702-713.
Antenucci, D., Li, E., Liu, S., et al., 2013. Ringtail: a gener- http://dx.doi.org/10.1109/TMM.2016.2527602
alized nowcasting system. Proc. VLDB Endow., 6(12): Fellbaum, C., Miller, G., 1998. WordNet: an Electronic Lexical
1358-1361. http://dx.doi.org/10.14778/2536274.2536315 Database. MIT Press, Cambridge, MA.
Antol, S., Agrawal, A., Lu, J., et al., 2015. VQA: visual ques- Feng, F., Wang, X., Li, R., 2014. Cross-modal retrieval with
tion answering. IEEE Int. Conf. on Computer Vision, correspondence autoencoder. ACM Int. Conf. on Multi-
p.2425-2433. http://dx.doi.org/10.1109/ICCV.2015.279 media, p.7-16.
Babenko, A., Slesarev, A., Chigorin, A., et al., 2014. Neural http://dx.doi.org/10.1145/2647868.2654902
codes for image retrieval. European Conf. on Computer Ferrucci, D., Levas, A., Bagchi, S., et al., 2013. Watson: be-
Vision, p.584-599. yond jeopardy! Artif. Intell., 199-200:93-105.
http://dx.doi.org/10.1007/978-3-319-10590-1_38 http://dx.doi.org/10.1016/j.artint.2012.06.009
Brownson, R.C., Gurney, J.G., Land, G.H., 1999. Evidence- Fuentes-Pacheco, J., Ruiz-Ascencio, J., Rendón-Mancha, J.M.,
based decision making in public health. J. Publ. Health 2015. Visual simultaneous localization and mapping: a
Manag. Pract., 5(5):86-97. survey. Artif. Intell. Rev., 43(1):55-81.
http://dx.doi.org/10.1097/00124784-199909000-00012 http://dx.doi.org/10.1007/s10462-012-9365-8
Carlson, C., Betteridge, J., Kisiel, B., et al., 2010. Towards an Garfield, E., 2004. Historiographic mapping of knowledge
architecture for never-ending language learning. AAAI domains literature. J. Inform. Sci., 30(2):119-145.
Conf. on Artificial Intelligence, p.1306-1313. http://dx.doi.org/10.1177/0165551504042802
Chen, D.P., Weber, S.C., Constantinou, P.S., et al., 2007. Gibney, E., 2015. DeepMind algorithm beats people at classic
Clinical arrays of laboratory measures, or “clinarrays”, video games. Nature, 518(7540):465-466.
built from an electronic health record enable disease Ginsberg, J., Mohebbi, M., Patel, R.S., et al., 2009. Detecting
subtyping by severity. AMIA Annual Symp. Proc., influenza epidemics using search engine query data. Na-
p.115-119. ture, 457(7232):1012-1014. 56 Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57
Gong, Y., Ke, Q., Isard, M., et al., 2014. A multi-view em- Lew, M.S., Sebe, N., Djeraba, C., et al., 2006. Content-based
bedding space for modeling internet images, tags, and multimedia information retrieval: state of the art and
their semantics. Int. J. Comput. Vis., 106(2):210-233. challenges. ACM Trans. Multim. Comput. Commun. Appl.,
http://dx.doi.org/10.1007/s11263-013-0658-4 2(1):1-19. http://dx.doi.org/10.1145/1126004.1126005
Hochreiter, S., Schmidhuber, J., 1997. Long short-term Lin, T., Pantel, P., Gamon, M., et al., 2012. Active objects:
memory. Neur. Comput., 9(8):1735-1780. actions for entity-centric search. ACM Int. Conf. on
http://dx.doi.org/10.1162/neco.1997.9.8.1735 World Wide Web, p.589-598.
Hodosh, M., Young, P., Hockenmaier, J., 2013. Framing image http://dx.doi.org/10.1145/2187836.2187916
description as a ranking task: data, models and evaluation Luo, G., Tang, C., 2008. On iterative intelligent medical search.
metrics. J. Artif. Intell. Res., 47(1):853-899. ACM SIGIR Conf. on Research and Development in In-
Hotelling, H., 1936. Relations between two sets of variates. formation Retrieval, p.3-10.
Biometrika, 28(3-4):321-377. http://dx.doi.org/10.1145/1390334.1390338
https://doi.org/10.1093/biomet/28.3-4.321 Mao, X., Lin, B., Cai, D., et al., 2013. Parallel field alignment
Hsu, F., 2002. Behind Deep Blue: Building the Computer that for cross media retrieval. ACM Int. Conf. on Multimedia,
Defeated the World Chess Champion. Princeton Univer- p.897-906. http://dx.doi.org/10.1145/2502081.2502087
McGurk, H., MacDonald, J., 1976. Hearing lips and seeing
sity Press, Princeton, USA.
voices. Nature, 264(5588):746-748.
Hua, Y., Wang, S., Liu, S., et al., 2014. TINA: cross-modal
http://dx.doi.org/10.1038/264746a0
correlation learning by adaptive hierarchical semantic
MIT Technology Review, 2014. Data driven healthcare.
aggregation. IEEE Int. Conf. on Data Mining, p.190-199.
https://www.technologyreview.com/business-report/data-
http://dx.doi.org/10.1109/ICDM.2014.65
driven-health-care/free [Dec. 06, 2016].
Jia, X., Gavves, E., Fernando, B., et al., 2015. Guiding
Mnih, V., Kavukcuoglu, K., Silver, D., 2015. Human-level
long-short term memory for image caption generation.
control through deep reinforcement learning. Nature,
arXiv:1509.04942.
518(7540):529-333.
Johnson, J., Krishna, R., Stark, M., et al., 2015. Image retrieval
http://dx.doi.org/10.1038/nature14236
using scene graphs. IEEE Conf. on Computer Vision and
Ngiam, J., Khosla, A., Kim, M., et al., 2011. Multimodal deep
Pattern Recognition, p.3668-3678.
learning. Int. Conf. on Machine Learning, p.689-696.
http://dx.doi.org/10.1109/CVPR.2015.7298990
Ordonez, V., Kulkarni, G., Berg, T.L., 2011. Im2text: describ-
Karpathy, A., Li, F.F., 2015. Deep visual-semantic alignments
ing images using 1 million captioned photographs. Ad-
for generating image descriptions. IEEE Conf. on Com-
vances in Neural Information Processing Systems,
puter Vision and Pattern Recognition, p.3128-3137.
p.1143-1151.
http://dx.doi.org/10.1109/CVPR.2015.7298932
Pan, Y.H., 2016. Heading toward artificial intelligence 2.0.
Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. ImageNet:
Engineering, 2(4):409-413.
classification with deep convolutional neural networks.
http://dx.doi.org/10.1016/J.ENG.2016.04.018
Advances in Neural Information Processing Systems,
Pearl, J., 2000. Causality: Models, Reasoning and Inference.
p.1097-1105.
Cambridge University Press, Cambridge, UK.
Kulkarni, G., Premraj, V., Dhar, S., et al., 2011. Baby talk:
Peng, Y., Huang, X., Qi, J., 2016a. Cross-media shared repre-
understanding and generating simple image descriptions.
sentation by hierarchical learning with multiple deep
IEEE Conf. on Computer Vision and Pattern Recognition,
networks. Int. Joint Conf. on Artificial Intelligence,
p.1601-1608.
p.3846-3853.
http://dx.doi.org/10.1109/CVPR.2011.5995466 Peng, Y., Zhai, X., Zhao, Y., et al., 2016b. Semi-supervised
Kumar, S., Sanderford, M., Gray, V.E., et al., 2012. Evolu- cross-media feature learning with unified patch graph
tionary diagnosis method for variants in personal exomes. regularization. IEEE Trans. Circ. Syst. Video Technol.,
Nat. Meth., 9(9):855-856. 26(3):583-596.
http://dx.doi.org/10.1038/nmeth.2147 http://dx.doi.org/10.1109/TCSVT.2015.2400779
Kuznetsova, P., Ordonezz, V., Berg, T.L., et al., 2014. Prabhu, N., Babu, R.V., 2015. Attribute-Graph: a graph based
TREETALK: composition and compression of trees for approach to image ranking. IEEE Int. Conf. on Computer
image descriptions. Trans. Assoc. Comput. Ling., 2:351- Vision, p.1071-1079.
362. http://dx.doi.org/10.1109/ICCV.2015.128
Lazaric, A., 2012. Transfer in reinforcement learning: a frame- Radinsky, K., Davidovich, S., Markovitch, S., 2012. Learning
work and a survey. In: Wiering, M., van Otterlo, M. (Eds.), causality for news events prediction. Int. Conf. on World
Reinforcement Learning: State-of-the-Art. Springer Ber- Wide Web, p.909-918.
lin Heidelberg, Berlin, p.143-173. http://dx.doi.org/10.1145/2187836.2187958
http://dx.doi.org/10.1007/978-3-642-27645-3_5 Rasiwasia, N., Costa Pereira, J., Coviello, E., et al., 2010. A
Lazer, D., Kennedy, R., King, G., et al., 2014. The parable of new approach to cross-modal multimedia retrieval. ACM
Google flu: traps in big data analysis. Science, 343(6176): Int. Conf. on Multimedia, p.251-260.
1203-1205. http://dx.doi.org/10.1126/science.1248506 http://dx.doi.org/10.1145/1873951.1873987 Peng et al. / Front Inform Technol Electron Eng 2017 18(1):44-57 57
Rasiwasia, N., Mahajan, D., Mahadevan, V., et al., 2014. Wei, Y., Zhao, Y., Lu, C., et al., 2017. Cross-modal retrieval
Cluster canonical correlation analysis. Int. Conf. on Arti- with CNN visual features: a new baseline. IEEE Trans.
ficial Intelligence and Statistics, p.823-831. Cybern., 47(2):449-460.
Rautaray, S.S., Agrawal, A., 2015. Vision based hand gesture http://dx.doi.org/10.1109/TCYB.2016.2519449
recognition for human computer interaction: a survey. Wu, W., Xu, J., Li, H., 2010. Learning similarity function
Artif. Intell. Rev., 43(1):1-54. between objects in heterogeneous spaces. Technique
http://dx.doi.org/10.1007/s10462-012-9356-9 Report MSR-TR-2010-86, Microsoft.
Roller, S., Schulte im Walde, S., 2013. A multimodal LDA Xu, K., Ba, J., Kiros, R., et al., 2015. Show, attend and tell:
model integrating textual, cognitive and visual modalities. neural image caption generation with visual attention. Int.
Conf. on Empirical Methods in Natural Language Pro- Conf. on Machine Learning, p.2048-2057.
cessing, p.1146-1157. Yang, Y., Zhuang, Y., Wu, F., et al., 2008. Harmonizing hier-
Sadeghi, F., Divvala, S.K., Farhadi, A., 2015. VisKE: visual archical manifolds for multimedia document semantics
knowledge extraction and question answering by visual understanding and cross-media retrieval. IEEE Trans.
verification of relation phrases. IEEE Conf. on Computer Multim., 10(3):437-446.
Vision and Pattern Recognition, p.1456-1464. http://dx.doi.org/10.1109/TMM.2008.917359
http://dx.doi.org/10.1109/CVPR.2015.7298752 Yang, Y., Teo, C.L., Daume, H., et al., 2011. Corpus-guided
Singhal, A., 2012. Introducing the knowledge graph: things, sentence generation of natural images. Conf. on Empiri-
not strings. Official Blog of Google. cal Methods in Natural Language Processing, p.444-454.
Socher, R., Lin, C., Ng, A.Y., et al., 2011. Parsing natural Yang, Y., Nie, F., Xu, D., et al., 2012. A multimedia retrieval
scenes and natural language with recursive neural net- framework based on semi-supervised ranking and rele-
works. Int. Conf. on Machine Learning, p.129-136. vance feedback. IEEE Trans. Patt. Anal. Mach. Intell.,
Socher, R., Karpathy, A., Le, Q., et al., 2014. Grounded 34(4):723-742.
compositional semantics for finding and describing im- http://dx.doi.org/10.1109/TPAMI.2011.170
ages with sentences. Trans. Assoc. Comput. Ling., 2:207- Yuan, L., Pan, C., Ji, S., et al., 2014. Automated annotation of
218. developmental stages of Drosophila embryos in images
Srivastava, N., Salakhutdinov, R., 2012. Multimodal learning containing spatial patterns of expression. Bioinformatics,
with deep Boltzmann machines. Advances in Neural In- 30(2):266-273.
formation Processing Systems, p.2222-2230. http://dx.doi.org/10.1093/bioinformatics/btt648
Suchanek, F., Weikum, G., 2014. Knowledge bases in the age Zhai, X., Peng, Y., Xiao, J., 2014. Learning cross-media joint
of big data analytics. Proc. VLDB Endow., 7(13):1713- representation with sparse and semi-supervised regulari-
1714. http://dx.doi.org/10.14778/2733004.2733069 zation. IEEE Trans. Circ. Syst. Video Technol., 24(6):965-
Uyar, A., Aliyu, F.M., 2015. Evaluating search features of 978. http://dx.doi.org/10.1109/TCSVT.2013.2276704
Google Knowledge Graph and Bing Satori: entity types, Zhang, H., Yang, Y., Luan, H., et al., 2014a. Start from scratch:
list searches and query interfaces. Onl. Inform. Rev., towards automatically identifying, modeling, and naming
39(2):197-213. visual attributes. ACM Int. Conf. on Multimedia, p.187-
http://dx.doi.org/10.1108/OIR-10-2014-0257 196. http://dx.doi.org/10.1145/2647868.2654915
Vinyals, O., Toshev, A., Bengio, S., et al., 2015. Show and tell: Zhang, H., Yuan, J., Gao, X., et al., 2014b. Boosting cross-
a neural image caption generator. IEEE Conf. on Com- media retrieval via visual-auditory feature analysis and
puter Vision and Pattern Recognition, p.3156-3164. relevance feedback. ACM Int. Conf. on Multimedia,
http://dx.doi.org/10.1109/CVPR.2015.7298935 p.953-956. http://dx.doi.org/10.1145/2647868.2654975
Wang, D., Cui, P., Ou, M., et al., 2015. Learning compact hash Zhang, H., Shang, X., Luan, H., et al., 2016. Learning from
codes for multimodal representations using orthogonal collective intelligence: feature learning using social im-
deep structure. IEEE Trans. Multim., 17(9): 1404-1416. ages and tags. ACM Trans. Multim. Comput. Commun.
http://dx.doi.org/10.1109/TMM.2015.2455415 Appl., 13(1):1. http://dx.doi.org/10.1145/2978656
Wang, W., Ooi, B.C., Yang, X., et al., 2014. Effective multi- Zhang, J., Wang, S., Huang, Q., 2015. Location-based parallel
modal retrieval based on stacked auto-encoders. Proc. tag completion for geo-tagged social image retrieval.
VLDB Endow., 7(8):649-660. ACM Int. Conf. on Multimedia Retrieval, p.355-362.
http://dx.doi.org/10.14778/2732296.2732301 Zhu, Y., Zhang, C., Ré, C., et al., 2015. Building a large-scale
Wang, Y., Wu, F., Song, J., et al., 2014. Multi-modal mutual multimodal knowledge base system for answering visual
topic reinforce modeling for cross-media retrieval. ACM queries. arXiv:1507.05670.
Int. Conf. on Multimedia, p.307-316.
http://dx.doi.org/10.1145/2647868.2654901 doi:10.1631/FITEE.1601787
题目：跨媒体分析与推理：研究进展与发展方向
概要：跨媒体分析与推理是计算机科学的热点问题，也是人工智能中一个具有广阔前景的研究方向。目前，
尚未有文献对跨媒体分析与推理的现有方法进行归纳总结并给出它的研究进展、挑战及发展方向。
为解决这些问题，本文从七个方面进行综述：（1）跨媒体统一表征理论与模型；（2）跨媒体关联
理解与深度挖掘；（3）跨媒体知识图谱构建与学习方法；（4）跨媒体知识演化与推理；（5）跨媒
体描述与生成；（6）跨媒体智能引擎；（7）跨媒体智能应用。本文的目标是给出跨媒体分析与推
理的方法、进展以及发展方向，吸引更多人关注该领域的最新进展，通过探讨面临的挑战和研究方
向，为研究者提供重要参考。
关键词：跨媒体分析；跨媒体推理；跨媒体应用 --------------------------------------------------------------------------------- 计算机科学与探索 1673-9418/2023/17(08)-1793-21
JournalofFrontiersofComputerScienceandTechnology doi:10.3778/j.issn.1673-9418.2212063
面向图神经网络的知识图谱嵌入研究进展
延照耀，丁苍峰，马乐荣+，曹 璐，游 浩
延安大学 数学与计算机科学学院，陕西 延安 716000
+通信作者 E-mail:mlr@yau.edu.cn
摘 要：随着图神经网络的发展，基于图神经网络的知识图谱嵌入方法日益受到研究人员的关注。相比传统
的方法，它可以更好地处理实体的多样性和复杂性，并捕捉实体的多重特征和复杂关系，从而提高知识图谱的
表示能力和应用价值。首先概述知识图谱的发展历程，梳理知识图谱和图神经网络的基本概念；其次着重讨
论基于图卷积、图神经、图注意力以及图自编码器的知识图谱嵌入的设计思路和算法框架；然后描述图神经网
络的知识图谱嵌入在链接预测、实体对齐、知识推理以及知识图谱补全等任务中的性能，同时补充图神经网络
在常识性知识图谱中的一些研究；最后进行全面性的总结，并针对知识图谱嵌入存在的一些问题和挑战，勾画
未来研究方向。
关键词：知识图谱；知识图谱嵌入；图神经网络；表示学习
文献标志码：A 中图分类号：TP39
Advances in Knowledge Graph Embedding Based on Graph Neural Networks
YAN Zhaoyao, DING Cangfeng, MALerong+, CAO Lu,YOU Hao
CollegeofMathematicsandComputerScience,Yan’anUniversity,Yanan,Shaanxi716000,China
'
Abstract: As graph neural networks continue to develop, knowledge graph embedding methods based on graph
neural networks are receiving increasing attention from researchers. Compared with traditional methods, they can
better handle the diversity and complexity of entities, and capture the multiple features and complex relationships of
entities, thereby improving the representation ability and application value of knowledge graphs. This paper firstly
outlines the development history of knowledge graphs and the basic concepts of knowledge graphs and graph neural
networks. Secondly, it focuses on discussing the design ideas and algorithm frameworks of knowledge graph
embedding based on graph convolution, graph neural networks, graph attention, and graph autoencoders. Then, it
describes the performance of graph neural network knowledge graph embedding in tasks such as link prediction,
entity alignment, knowledge graph reasoning, and knowledge graph completion, while supplementing some research
on commonsense knowledge graphs with graph neural networks. Finally, this paper makes a comprehensive
summary, and future research directions are outlined with respect to some challenges and issues in knowledge graph
embedding.
Keywords:knowledgegraph;knowledgegraphembedding;graphneuralnetwork;representationlearning
基金项目：国家自然科学基金（62262067，61866038）；陕西省级人才项目（YAU202213065，CXY202107）；陕西省教育厅自然科学
专项（22JK0622）；延安大学十四五重大科研项目（2021ZCQ012）。
This work was supported by the National Natural Science Foundation of China (62262067, 61866038), the Talent Project of Shaanxi
Province (YAU202213065, CXY202107), the Natural Science Special Project of Shaanxi Provincial Education Department (22JK0622),
andtheMajorScientificResearchProjectsofYananUniversityatthe14thFiveYearPlan(2021ZCQ012).
'
收稿日期：2022-12-22 修回日期：2023-03-29 1794 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(8)
“知识”二字早在甲骨文中就已经出现，其中 总结，主要研究框架如图1所示。本文首先阐述了知
“知”本义为“谈论和传授狩猎作战的经验”，“识”本 识图谱和图神经网络的基本概念；然后按照图神经
义为“识辨指认武器”。进入20世纪，“知识”被释义 网络的主流算法将不同的知识图谱嵌入方法分为基
为“人们在社会实践中所获得的认识和经验的综 于图卷积、基于图神经、基于图注意力以及基于图自
合”。知识对人工智能而言同等重要，谷歌在2012年 编码器四种类别的知识图谱嵌入方法，并分析链接
发布知识搜索产品 Google knowledge graph，提出 预测、实体对齐、知识推理以及知识图谱补全等下游
“Things, Not Strings”的理念，知识图谱（knowledge 任务中的性能；随后介绍常识性知识图谱的基本概
graph，KG）才被正式提出，将知识图谱定义为一种用 念、开源数据集以及在图神经网络方面的研究；最后
图模型来描述知识和构建世界万物之间的关联关系 讨论了基于图神经网络的知识图谱嵌入方法在分布
的技术方法[1]。自此，以知识表示、挖掘和推理等知 外泛化、动态知识图谱、多模态知识融入、网络深度
识图谱技术成为人工智能的研究热点。 与邻居节点数量的矛盾、图神经网络的可解释性以
知识图谱表示（knowledge representation learning， 及图谱深层次信息的主要挑战和未来方向。
KRL）[2]旨在对知识图谱进行建模，从而可以方便知
识计算。传统的知识图谱表示使用的是基于离散符
号的表示方式，以三元组的格式对知识进行组织，虽
然这些符号化的表达能力可以非常有效地将数据结
构化，但是在计算机中的表达相关的语义信息和进
行语义计算等方面面临着巨大的挑战。为了解决计
算效率低下和数据稀疏性强这两个挑战，在词嵌入
（word embedding）[3]的启发下，研究者将注意力集中
在将知识图谱中的实体和关系映射到低维稠密实值
图1 研究内容框架
的向量空间中，并包含一些语义层面的信息。这种
Fig.1 Researchcontentframework
将知识图谱中实体和关系的信息映射到低维稠密实
值的向量空间的研究方法称为知识图谱嵌入（KG
1 基本概念
embedding，KGE）。
本章介绍知识图谱嵌入和图神经网络的基本概念。
类似于词向量，知识图谱嵌入也是通过机器学
1.1 知识图谱嵌入
习的方法对模型进行学习的，多数知识图谱嵌入方
知识图谱（KG），又被定义为语义网络的知识库，
法依靠知识图谱中的实体、关系的属性信息和图谱
是一种用图模型来描述客观事物和建模事物之间的
的结构信息进行训练。根据有关知识图谱嵌入的综
关联关系的技术方法。一般地，知识图谱定义为
述[4]，将知识图谱嵌入的方法分为基于转移思想、
KG E R F ，其中，E 表示知识图谱包含的实体集
基于语义匹配、考虑附加信息、基于传统深度学习以 ={ , , }
合 e e e ，R表示不同实体之间的关系集合 r
及基于图神经网络。随着图神经网络（graph neural { , ,⋯, E} { ,
1 2 1
r r ，F 表示知识图谱中的三元组集合 f
network，GNN）[5]的兴起，一种利用深度学习直接学 ,⋯, R} { ,
2 1
习图的结构化数据的框架，大量的基于图神经网络 f f ，每个三元组 f 被定义为 h r t ，其中 h、r、t
,⋯, T} ( , , )
2
的知识图谱嵌入方法被提出。由于GNN对图数据结 分别表示头实体、关系和尾实体。
构具有非线性实体拟合的能力，在不同领域的问题 为了解决基于离散符号的知识图谱表示不能在
上具有更高的精确度和更好的鲁棒性。此外，基于 计算机中表达相应的语义信息的挑战，在词向量的
GNN的知识图谱嵌入方法可将知识图谱中基于领域 启发下，将知识图谱中的实体和关系的特征映射到
的数据和业务有效地结合起来，展示出越来越丰富 低维的向量空间中，把这种研究领域称为知识图谱
的实用价值，典型的下游应用包括问答系统[6]、信息 嵌入、知识图谱的表示学习。类似于词向量，知识图
抽取[7-8]以及推荐系统[9]。 谱嵌入通过机器学习的方法对模型进行学习，与词
为此，本文梳理了基于图神经网络的知识图谱 袋模型、独热编码不同的是，知识图谱嵌入方法依赖
嵌入方法的不同设计思想，并对相应的方法进行了 于监督学习进行训练，在训练过程中学习语义信息。 延照耀 等：面向图神经网络的知识图谱嵌入研究进展 1795
知识图谱嵌入算法的发展经历了多个阶段，从 络模型使用如下迭代方式更新节点的状态：
传统的基于矩阵分解的方法到最近的基于深度学习 Ht +1 F Ht X （2）
= ( , )
的方法。其中，利用矩阵分解进行知识表示学习中 其中，Ht表示 H 的第t轮迭代。
的一个典型模型是RESCAL[10]，其算法思想是将实体 图神经网络模型也可以用消息传递网络模型进
和关系都表示为三维张量，然后对实体和关系张量 行描述[19]，该模型在前向传播过程中可以分为消息传
进行分解，学习低维嵌入表示。近年来，许多基于 递和消息读取两个阶段。其中消息传递阶段又分为
RESCAL的改进算法被提出，为了解决RESCAL参 目标节点传递语义信息至邻居节点、聚合自身信息
数问题，DistMult[11]模型使用矩阵W 来表示所有实体 与邻居节点信息两个过程，这也是GNN的前向传播
之间的关系，矩阵W 的每一列对应一个实体，每一行 思想。为此，GNN的前向传播思想可以统一建模为：
对应实体之间的关系，最后实体嵌入向量与关系矩 hk +1 Merge hk aggr hk （3）
i = ({ i}⋃ ({ j}j ∈N(i )))
阵W 相乘得到预测分数。为了解决DistMult无法处
其中，Merge 表示特征融合函数，aggr 表示邻居
(·) (·)
理非对称关系的问题，ComplEx[12]在矩阵乘法中引入
特征聚合函数，Ni 表示节点 i的邻居集合，hk +1表
()
复数运算，而HolE（holographic embedding）[13]将知识
示节点在第k层网络中输入的特征向量。
图谱中的关系抽象为高阶张量的双线性关系，以此
来捕获关系数据中的丰富交互。奠基性的基于转移
2 模型框架
的知识图谱嵌入方法TransE（translatingembedding）[14]
本章将具体介绍不同类型的基于GNN的知识图
的设计思想就是将三元组中的头实体 h经过关系 r
谱嵌入算法的基本思想和模型。按照GNN衍生的许
的转移后接近尾实体t，使其满足关系h r t，例如：
+ ≈ 多变体，将知识图谱嵌入方法大致分类为：基于图卷
vec罗纳尔多 vec国籍 vec巴西
( )+ ( )≈ ( ) 积、基于图神经、基于图注意力以及基于图自编码器
其中，vec表示实体和关系嵌入向量。然而TransE在
的方法。其中，图卷积是将卷积神经网络中的卷积
处理对称关系时失去了语义辨识的能力，为了解决
运算推广到图数据结构，对实体和关系进行表示学
该问题，RotatE（rotating embedding）[15]通过将关系向
习，进行卷积操作的主要方法为基于谱分解和节点
量表示为旋转矩阵来有效地捕捉关系的方向性信
空间变化；与图卷积网络注重于利用邻域信息不同
息。在传统深度学习的知识图谱嵌入中，ConvE[16]将
的是，图神经网络采用消息传递机制来学习嵌入表
知识图谱中的实体和关系嵌入到低维空间中，并通
示，更好地捕捉实体和关系之间的交互信息；图注意
过卷积网络学习实体和关系之间的语义关联。
力是在基础GNN的消息传递过程中引入注意力机
1.2 图神经网络
制，为每个相邻节点分配不同的注意力分数，使神经
图神经网络将现有的神经网络方法拓展到了图
网络关注较为重要的相邻实体和关系；图自编码器
结构数据处理领域，来学习、提取和挖掘图结构数据
是将输入的实体和关系信息作为学习目标，对实体
中的特征和模式[17]。节点采用其特征和图中与其相
和关系信息进行表示学习[20-21]，被广泛应用于无监督
关的节点进行描述，根据输入的节点邻居更新节点
学习的图节点嵌入方法中。
状态，它可以编码该节点的邻居节点信息和图的拓
变体GNN的知识图谱嵌入方法都是建立在传统
扑结构；因此，图神经网络的目标是为每个节点学习
知识图谱嵌入方法之上，利用变体GNN的图嵌入方
一个状态表示 h RS ，利用这个状态表示可以生成
v∈ 法作为编码器学习图结构信息，然后采用TransE、
模型的输出 o ，将所有的状态、输出、特征和节点特 ComplEx和ConvE等传统的知识图谱嵌入方法作为
v
征堆叠起来，即可得到基础图神经网络模型的公式 模型的解码器，将学习到的实体和关系的嵌入进行
表达： 解码并在链接预测等下游任务中验证模型的性能。
■H F H X 下文将按照上述分类的顺序依次介绍各类方法的思
■ = ( , ) （1）
■O =G (H ,X
N)
想以及相应的算法实现。
其中，F 是全局转移函数，G 是全局输出函数，X 和 2.1 基于图卷积的知识图谱嵌入
N
X 分别表示通过堆叠所有节点特征和所有特征构建 本节从基础GCN（graph convolutional network）
的矩阵，H 和O分别表示所有节点的状态和所有节 的思想入手介绍奠基性方法R-GCN（relational graph
点的输出。根据巴拿赫不动点定理[18]，基础图神经网 convolutional network），然后从该方法的问题角度介 1796 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(8)
绍该方法的改进版本，理清基于图卷积的知识图谱 构关系的方法。除此之外，CompGCN（compositional
嵌入模型的发展脉络。 graph convolutional network）[25]利用基于语义匹配的
虽然GCN在节点分类等下游任务中取得了不错 知识图谱嵌入算法DistMult和HolE思想，提出新的
的成绩，但基础GCN模型只是针对同构图，为了处理 聚合函数，将实体和关系联合嵌入到关系图中，并且
知识图谱这种特殊的异构图，Schlichtkrull等人[22]提 还根据关系的数量进行扩展，以解决模型的过度参
出关系图卷积网络R-GCN，与GCN不同的是，R-GCN 数化问题。但大多数GCN模型关注实体嵌入过程中
中边表示为不同的关系，为每个关系r引入相关联的 加入关系信息，而缺乏关系嵌入过程中加入实体信
权重矩阵W ，在聚合邻居信息的过程中使用相应的 息。为了解决这一局限性，Yu等人[26]提出一种基于
r
关系权重矩阵更新邻居特征，其特征更新过程表示为： 知识嵌入的图卷积网络（knowledge-enhanced graph
■ ■ convolutional network，KE-GCN），结合GCN的消息
h ik +1 =σ ■| | ∑
r
∈R∑
j ∈N
irc1
i
,rW r(k )h( jk ) +W 0(k )h( ik ) ■| | （4） 传递和知识图谱嵌入方法的优势，将CompGCN、R-
GCN和WGCN（weightedgraphconvolutionalnetwork）[27]
可以看出，R-GCN将基础GCN模型扩展到了关
方法进行统一，如图3所示，与之前基于图卷积的方
系图中，但是每种关系关联相应的权重矩阵，造成参
法相比，KE-GCN实现简单，性能更好。各模型的实
数量过大的问题，尤其是在处理关系类别极大的数
体更新和关系更新函数见表1，其中 El、El、El表示
据时。针对该问题，R-GCN使用参数共享和稀疏化 h r t
矩阵策略减少模型参数并防止过拟合。R-GCN还提
头实体h、关系r和尾实体t在l层的嵌入，ml t+1表示
出一种Encoder-Decoder的框架，将基础图神经网络 邻居实体的聚合表示，σ 表示实体更新和关系更新
模型应用于链接预测任务中。如图2所示，R-GCN作 的激活函数，W 表示权重矩阵。
为Encoder学习实体特征，传统知识图谱嵌入算法
DistMult作为Decoder计算三元组得分，后续大多数
基于图神经网络的知识图谱模型将Encoder-Decoder
框架作为模型的基础框架。
图3 VR-GCN、CompGCN、TransGCN和
图2 R-GCN用于链接预测任务框架
KE-GCN模型框架
Fig.2 R-GCNforlinkingpredictiontaskframework
Fig.3 ModelframeworksofVR-GCN,CompGCN,
R-GCN虽然在聚合邻居信息时考虑了不同关系 TransGCNandKE-GCN
信息，但是忽略了关系的方向和异构图中不同实体
在研究动态知识图谱对齐工作中，Yan等人[28]使
类型可能具有不同的特征空间的问题。为了应对上
用图卷积模型提出DINGAL，并在DINGAL的基础
述问题，Ye等人[23]提出一种向量化的关系图卷积网
上引出一系列知识图谱嵌入方法。主要思想是将
络（variational relational graph convolutional networks，
GCN的参数矩阵看作特征转换算子，并将转换过程
VR-GCN），将TransE的思想引入R-GCN模型中，同
与聚合过程进行解耦，在此基础上提出DINGAL-B，
时考虑关系的类别信息和方向信息，以同时学习实
用于静态知识图谱对齐。随之提出两种有效的动态
体和关系的嵌入，VR-GCN的特征更新函数如下：
知识图谱对齐方法DINGAL-O（利用之前的参数矩
■■ ■ ■ ■ ■
h il +1 =σ| || |d1| | ∑∑(hl t-hl r)+∑∑(hl t+hl r)| | +h il| |Wl| |（5） 阵更新实体嵌入）与DINGAL-U（利用新的关系微调
■■ ■r ∈Nrr ∈Ntr r ∈Nrr ∈Ntr ■ ■ ■ 参数矩阵），DINGAL系列算法细节如图4所示，从而
TransGCN[24]在VR-GCN的基础上，利用RotatE 有效解决动态知识图谱的实体嵌入问题，这项工作也
思想对聚合函数进行了扩展，提出一种新的处理异 被认为是第一个研究动态知识图谱对齐问题的工作。 延照耀 等：面向图神经网络的知识图谱嵌入研究进展 1797
表1 R-GCN、WGCN、CompGCN与KE-GCN更新函数描述
Table1 DescriptionofR-GCN,WGCN,CompGCNandKE-GCNupdatefunctions
模型 实体更新 关系更新
R-GCN ml t+1 = (h,∑
r)∈N
in(t)W rlE hl + (h,∑
r)∈N
out(t)W rlE hl , E tl+1 =σ (ml t+1 +W 0lE tl ) No
WGCN ml t+1 = ∑ W rl (αl rE hl )+ ∑ W rl (αl rE hl ), E tl+1 =σ (ml t+1 +WlE tl ) No
(h,r)∈N in(t) (h,r)∈N out(t)
CompGCN ml t+1 = (h,∑
r)∈N
in(t)W rlϕ in(E hl ,E rl )+ (h,∑
r)∈N
out(t)W rlϕ out(E hl ,E rl ), E tl+1 =σ (ml t+1 +W 0lE tl ) E rl+1 =W rlE rl
f El El El f El El El f El El El
KE-GCN ml t+1
= (h,∑
r)∈N
in(t)W rl∂in( ∂h E, tlr, t)
+ (h,∑
r)∈N
out(t)W rl∂out( ∂t E, tlr, h)
,
E tl+1 =σ (ml t+1 +W 0lE tl
)
ml r+1
= (u,∑
r)∈N
in(v)∂r( ∂u,
E
rlr, v)
,
E rl+1 =σ (W rl (ml r+1 +E rl
))
图4 DINGAL系列算法细节
Fig.4 AlgorithmdetailsofDINGALseries
基于图卷积的知识图谱嵌入方法由于运算操作 由于GNN在建模图数据方面所表现出优越的性能。
简单、参数量适中、学习效率高等优势，成为了知识 先前的R-GCN模型还存在着表示能力低、扁平
图谱嵌入领域非常活跃的研究方向之一。然而图卷 化堆叠和对噪音的鲁棒性差三个缺点，为此，Wang等
积网络本身也存在诸多缺点，比如邻居实体重要性 人[29]提出一种多级图神经网络（multi-levelgraphcon-
分配、动态图处理等，使得后续工作可以针对这些缺 volutional neural network，M-GNN）来解决上述缺
点对基于图卷积的知识图谱嵌入方法进一步改进。 点。R-GCN利用均值聚合器聚合邻居信息，与R-
2.2 基于图神经的知识图谱嵌入 GCN不同的是，M-GCN使用多层感知机设计GNN
上述基于图卷积的知识图谱嵌入方法使用卷积 层进行邻居聚合操作，以提高GNN层的表示能力。
操作来捕捉局部邻域信息，核心思想是利用实体和 M-GCN的更新过程如下：
其邻居实体之间的关系来表示实体的特征。而基于 h (k ) (k ) ε(k ) hk -1 hk -1 （6）
图神经网络的知识图谱嵌入方法则将图作为输入，
v =MLP ((1+ )· r 0,v + u∑
∈Nvr
r ,u )
通过对图中节点的消息传递和聚合来学习节点的嵌 其中，N vr表示关系r下节点i的邻居集合，h rk - u1表示
,
入向量。它可以充分利用图的全局结构信息，同时 关系r下每个邻居节点u传递的消息，h rk - v1表示自连
0,
也考虑了节点之间的复杂依赖关系。此外，基于图 接消息。在此基础上，将知识图谱粗化为一系列图，
神经网络的知识图谱嵌入方法还可以根据时间信息 并以多层方式堆叠GNN层建模知识图谱的层级结构。
对实体的嵌入向量进行动态更新，处理时序知识图 前期的一些工作是将知识图谱嵌入单曲率空
谱，从而更好地表达知识图谱的演化过程。本节将 间，比如欧几里德空间和双曲空间，但忽略了知识图
介绍基于图神经网络的知识图谱嵌入方法。近几 谱特有的异构特性，因此无法捕获其拓扑结构。为
年，GNN在知识图谱嵌入的研究发展较为迅速，主要 了解决这个问题，Wang等人[30]提出一种混合曲率关 1798 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(8)
系图神经网络模型（mixed-curvature multi-relational 分函数，因此GNN的归纳能力并没有充分利用。与
graphneuralnetwork，M2GNN），以解决单曲率空间忽 GraIL不同的是，INDIGO[34]将知识图谱以透明的方式
略知识图谱的异构特性的问题。具体而言，将多个 完全编码在GNN中，并且可以直接从GNN的最后一
单曲率空间（例如球面、双曲线和欧几里德空间）的 层读取预测的三元组，从而不需要额外的评分函数，
流形乘积来定义和构造混合曲率空间，以此来建模 以此来解决太过依赖启发式和评分函数的缺点。
知识图谱的各种异构结构。然而，混合曲率空间的 上述工作都是在链接预测任务中测试知识图谱
构造需要手动定义，需要额外的数据分析，定义不当 嵌入方法的性能，很少考虑实体对齐这一关键技术，
会无法准确地捕捉知识图谱的异构特性。为了解决 实体对齐通常也存在无法处理异构特性的问题。为
这个问题，M2GNN将混合曲率设置为可训练的参数， 了解决这一问题，研究者提出了一种多通道图神经网
利用GNN作为嵌入更新模块，用于聚合实体的邻居 络模型（multi-channelgraphneuralnetwork，MuGNN）[35]，
和关系特征，并更新每个实体和关系的嵌入表示，以 通过多通道对两个知识图谱进行编码来学习基于对
此来提高知识图谱嵌入的性能，基于图神经的更新 齐的知识图谱嵌入，每个通道使用不同的关系加权
函数定义如下： 策略对知识图谱进行编码，其第l 层与第i个通道
+1
e ′i=GNN(e j,r k|j ∈N i,k ∈R
ij)
（7） 的隐层状态表示为 H il +1 =GNN(A i,Hl ,W i)，其中 A表
其中，e 定义为目标实体 e 更新后的嵌入，r 表示 示图的邻接矩阵，H 是当前实体的嵌入表示，W 为
′i i k
可学习的参数。此外还进行推断和传递并一致性地
实体 e 和实体 e 之间的关系，N 表示实体 e 的邻居
i j i i
完成两个知识图谱的规则知识，以此协调两个知识
实体，R 是实体e 和实体e 的关系集合。
ij i j
图谱的结构差异性。但MuGNN在低维空间中嵌入
于此同时，马尔可夫逻辑网络（Markov logicnet-
实体，然后通过向量表示获得实体对齐，尽管之前的
works，MLNs）[31]将逻辑规则和概率图模型结合起来
工作取得了持续的改进，但其性能仍然令人不满
解决知识图谱的问题，但是MLNs中的推理规则计算
意。在知识图谱的实体对嵌入（entity-pair embed-
太过密集，无法应用在工业中。随着GNN的兴起，提
ding approach，EPEA）[36]方法中引入两个知识图谱的
出一种结合MLNs和GNN的变体模型ExpressGNN[32]，
成对联通图（pairwise connectivity graph，PCG），其节
使用图神经网络在马尔可夫逻辑网络中进行推理，
点是实体对，边对应关系，然后学习节点（实体对）嵌
充分利用GNN在图嵌入学习的优点和MLNs在逻辑
入，并利用GNN增强实体对的邻居实体之间的消息
推理的优势，ExpressGNN的聚合函数如下：
传递，基于GNN的特征提取公式为Hl
+1
Wl
+1
■αl hl r θ =ReLU( ⊗
■|| αlt += 1MLP 1( t, α;
l
1)
（8）
Hl +bl +1 )，Hl 为第 l层的输出， ⊗为卷积算子，以此
|| t =AGG({ t}t :r (h ,t )∈O) 学习理想的实体对嵌入。另一方面，当前的基于图
■hl +1 hl αl +1 θ
t =MLP 2( t, t ; 2) 神经网络的知识图谱嵌入方法要么忽略实体间的差
其中，αl 表示实体 t的邻居聚合信息，hl 表示实体 t
t t 异，要么通过实体或者三元组来表示关系，并没有对
在 l 层的嵌入表示，θ、θ 为GNN参数并在整个图 关系中的元语义信息进行建模。Mao等人[37]提出一
1 2
谱中共享， 和 表示消息传递和消息聚 种新的元关系感知实体对齐方法（metarelation-aware
MLP(·) AGG(·)
合函数。另一个知识图谱嵌入的路线是逻辑归纳问 entity alignment，MRAEA），通过关注实体的出度与
题，一种试图导出给定知识图谱的概率逻辑规则，其 入度邻居以及连接关系的元语义信息，直接对跨语
中代表性的框架为GraIL[33]，从包含两个目标实体的 言知识图谱进行建模。此外，MRAEA还采用双向迭
子图中预测两个实体的关系，最后利用多关系GNN 代策略处理基于对齐的不对称性。
对三元组进行评分，启发于多关系模型 R-GCN， 2.3 基于图注意力的知识图谱嵌入
GraIL的聚合函数如下： 本节介绍基于图注意力的知识图谱嵌入方法，
■ R 基于图注意力的方法是通过引入注意力机制，为每
||αl αl Wlhl
-1
■
||
t=∑ r =1s∑ ∈Nr(t
)
rr tst r s （9） 个相邻实体和关系分配不同的注意力分数，使图神
■hl t=ReLU(Wl hl
t-1
+αl
t) 经网络关注较为重要的邻居实体和关系，以此来学
self
其中，αl 表示实体 t的邻居聚合信息，hl 表示实体 t 习三元组的特征。
t t
在l层的嵌入表示。但是GraIL太过依赖启发式和评 基于图卷积的模型的缺点在于平等对待知识图 延照耀 等：面向图神经网络的知识图谱嵌入研究进展 1799
谱中的关系，而忽略了每个关系拥有不同的重要性， 谱的异构特性，引入特定于关系的网络参数θ ，为不
r
这可能会限制模型的扩展性。启发于基于GCN的知 同关系建模相应的消息函数，自适应地学习不同关
识图谱嵌入在聚合邻居信息过程中加入权重参数， 系下相邻实体的信息，RAGAT的消息函数定义如下：
以实现不同重要性的思想，如图5所示，SACN（structure- Cr ϕ e e e θ （11）
hrt = r( h, r, t, r)
( ,,)
awareconvolutionalnetworks）[27]使用加权图卷积网络
其中，ϕ 是聚合函数，e 和e 表示实体的嵌入，e 表
r h t r
WGCN，利用知识图谱实体结构、实体属性和关系类
示关系的嵌入。
型学习关系权重参数。然而SACN只考虑了关系类
不同关系类别下，并非中心实体的所有邻居实
别，没有考虑邻居实体的关系，为了同时考虑邻居实
体都具有相同的重要性，为此提出一种层级注意力
体和邻居关系拥有不同的重要性，Nathani等人[38]参
的图神经网络模型（relational graph neural network
考GAT（graph attention network）的思想聚合邻居信
with hierarchical attention，RGHAT）[42]。除了在关系
息，提出一种新的基于注意力的知识图谱嵌入方法，
层计算不同关系类别的权重之外，RGHAT还加入了
与之前规则不同的是，Nathani等人直接聚合邻居三
实体层的注意力机制，强调不同关系下的邻居实体
元组的信息，而不是聚合邻居实体的信息，聚合函数
具有不同的重要性。同时，异构关系注意力网络
如下：
（heterogeneous relation attention network，HRAN）[43]
■ M ■
h t=σ ■|| M1
∑
m
=1∑
j
∈Ntr∑
∈Rh,tαm hrtcm
hrt
■|| （10） 模 生成型 知也 识采 图用 谱一 嵌种 入包 。含 与实 R体 G级 HA和 T关 不系 同级 的的 是层 ，H次 A结 RN构 是，
其中，cm 为三元组的嵌入表示，αm 是三元组的注意 基于关系路径下为邻居实体和关系分配不同的重要
hrt hrt
力系数。不同的是，r-GAT（relational graph attention 性。在知识推理任务中，Zhao等人[44]也提出一种
network）[39]通过多通道学习实体的嵌入表示，不同的 分层的注意力机制模型（target relational attention-
通道对应不同的实体语义信息，并且利用关系特征 oriented reasoning，TRAR），实体级注意力使用经典
聚合邻居信息，很好地处理了复杂的关系图。在实 的GAT聚合邻居信息，子图级注意力根据推理任务
体对齐任务中，一种分散的知识图谱嵌入方法decent- 中的关系决定注意力分数，利用注意力机制使模型
RL[40]利用分散注意力网络（decentralized attention 更关注与目标实体相匹配的关系，从而获得更好的
network，DAN），依赖目标实体的邻居实体而忽略嵌 实体嵌入表示，模型从局部领域到层次结构细节如
入要求来计算注意力分数。上述方法虽然在知识图 图6所示。
谱嵌入中引入了注意力机制，并没有将知识图谱的 然而，前期的一些工作主要依赖于节点的一阶
异构特性加入模型之中。相比之下，Liu等人[41]提出 邻居信息，忽略了知识图谱丰富的局部结构，如图7
一种关系感知的图注意力网络模型（relation aware 所示的循环结构、三角结构和星型结构，因此没能更
graphattentionnetwork，RAGAT），该模型利用知识图 好地捕获这些结构下的各种语义信息。Ji等人为了
图5 WGCN模型框架
Fig.5 WGCNmodelframework 1800 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(8)
（association rules enhanced knowledge graph attention
network，AR-KGAT），AR-KAGT利用GAT框架，以端
到端的方式捕获目标实体的高阶邻居实体的语义信
息和关系信息，AR-KAGT最主要的部分是使用基于
关联规则和基于图注意力来估计关系级和邻居级的
权重系数，注意力嵌入的传播层函数为：
e αL 1 αN 1 C1 （12）
h= f 1(h ,∑ r ,t )∈NL 1(h )( (h ,r ,t )+ (h ,r ,t )) (h ,r ,t )
其中，αL 1 、αN 1 分别表示基于逻辑和基于图的注
hrt hrt
( ,,) ( ,,)
意力系数，C1 为三元组的表示形式。与AR-KGAT
hrt
( ,,)
不同的是，AR-KGAT的变体模型AR-KACN（associa-
tion rules enhanced knowledge graph convolutional
network）将GCN作为聚合器，而不是利用注意力机
制进行邻居聚合。在解决知识图谱补全问题中，另
一个挑战是知识图谱的多关系异构特性以及实体和
关系之间的多种复杂交互，Dai等人[48]在可以为邻居
分配不同权重的前提下设计了一种多关系图注意力
模型（multi-relationalgraphattentionnetwork，MRGAT），
图6 RGHAT、RAGAT、HRAN与TRAR分级细节
该模型可以适应异构特性，在不同实体权重的网络
Fig.6 GradingdetailsofRGHAT,RAGAT,HRAN&TRAR
中引入自注意力机制进行优化，然后通过自注意力
层计算邻居实体的重要性。
相比图卷积的知识图谱嵌入算法，基于图注意
力的思想就是考虑知识图谱的异构特性，对目标实
体的邻居实体和关系分配不同的重要性，以解决图
卷积不能处理动态图和不易对邻居节点分配不同权
图7 局部结构
重的瓶颈。与图卷积相同的是，二者都是将目标实
Fig.7 Localstructure
体的邻居实体特征聚合，学习目标实体的嵌入表示。
克服这一缺点，提出一种具有新的邻居聚合策略的 2.4 基于图自编码器的知识图谱嵌入
图注意力网络模型LSA-GAT（local structure-aware
本节简单介绍基于图自编码器的知识图谱嵌入
graph attention networks）[45]，该模型考虑了知识图谱 算法，自编码器（autoencoder，AE）[49-50]和变分自编码
丰富的局部结构并且捕获了复杂的结构信息。除知 器（variationalautoencoder，VAE）[51-52]被广泛应用于无
识图谱丰富的同构结构之外，其异构的邻居结构也
监督学习的图节点嵌入方法中，成功地利用AE和
不可避免，异构的邻居结构也很容易导致GAT产生
VAE解决知识图谱的链接预测问题。
不同的嵌入表示。为此，提出一种新的知识图谱嵌
图自编码器模型同图卷积模型一样侧重于无向
入方法AliNe（t alignment network）[46]，以端到端的方
图，忽略了图结构中的潜在方向。为此，Salha等人[53]
式减轻邻居结构的异构特性。AliNet捕获了多阶邻
启发于牛顿万有引力定律，扩展图自编码器和变分
居的语义信息，使用注意力机制放大邻居结构之间
编码器，提出一种新的解码器框架Gravity GraphVA
的重叠部分，并限制实体对在每个GAT层中具有相
和Gravity Graph VAE，从而有效地解决有向图中链
同的隐藏状态。
接预测问题。值得一提的是，Salha等人在节点嵌入
在大多数现有的知识图谱嵌入方法中，仅仅使
中应用牛顿万有引力定律（任何两个物体都存在通
用三元组的信息，尚未对知识图谱补全任务中的逻
过其连心线方向上的相互吸引的力，该引力 F 大小
辑规则进行研究。为了解决这个问题，Zhang等人[47]
Gm m
为 1 2 ，其中G 为万有引力常量，m、m 为物体
提出一种关联规则增强的知识图谱注意力方法 r2 1 2 延照耀 等：面向图神经网络的知识图谱嵌入研究进展 1801
的质量，r为两个物体之间的距离），得出有向图中节 总体来看，基于图自编码器的知识图谱嵌入方
点i与节点 j相关联的可能性： 法的研究工作并不算多。虽然图自编码器能够自动
a F Gm j （13） 提取目标特征，有效地解决了传统手动方法提取特
i →j= m
i
= r2 征不足的问题，同时避免过拟合的问题，也使得这一
然而，随着知识图谱规模的不断扩大，将知识图 类模型在开源数据集中取得了不错的性能。但是在
谱中的实体和关系表示为32 bit的浮点型向量，使得 处理知识图谱这种大规模的图数据中，其模型的训
知识图谱嵌入在内存消耗方面变得越来越大。为了 练时间变得更长，并且图自编码器属于无监督学习，
解决上述问题，Zhang等人[54]提出一种关系图自编码 不能很好地描述所学习到的特征表示，因此图自编
器模型R-GAE，R-GAE是图自编码器的扩展，对知识 码器的问题也随之遗留在知识图谱嵌入中。因此如
图谱的局部邻域进行操作。R-GAE过程说明如图8 何设计更好的基于图自编码器的知识图谱嵌入模
所示。首先利用R-GAT作为编码器改变实体和关系 型，有待进一步研究。
嵌入的维度，其中R-GAT使用多头注意力机制学习
实体和关系的特征表示Z，并通过GCN进行聚合。 3 任务分析
然后利用变分自编码器VAE和Gumbel-Softmax[55]将
本章介绍了知识图谱嵌入模型在链接预测、实
浮点型嵌入压缩为二进制嵌入B，以获得大规模的关
体对齐、知识图谱推理以及知识图谱补全下游任务
系型数据，大大减少了数据存储的空间，同时也保留
中的性能。需要说明的是，在不同下游任务中的模
了知识图谱的内在信息。最后解码器使用编码器的
型指标均来自现有论文，考虑到不同方法在嵌入维
输出重构知识图谱。
度、批采样大小、负采样大小、损失函数设计以及训
练轮数等都存在差异，因此任务分析中的数据不完
全适用于分析对比不同类别方法之间的性能优劣。
3.1 链接预测
链接预测（link prediction，LP）的任务是通过一
个已知的实体和关系去预测另一个实体，或者通过
已知的两个实体去预测关系（如头实体和关系已知，
图8 R-GAE过程说明
去预测正确的尾实体）。形式化定义为，给定查询
Fig.8 R-GAEprocessdescription
h r r t h t ，分别预测正确的头实体、关系和尾
( , ,?)(?, , )( ,?, )
大多数基于图自编码器模型的工作都有一个共
实体集合，其中 h、r、t 分别表示头实体、关系和尾
同的问题，这类模型可能无法捕获知识图谱更复杂
实体，“ ”表示三元组缺失的实体或关系，图9为链
?
的结构，比如一对多或多对多，也无法适应不同类型
接预测的示例。当知识图谱的嵌入被学习完成之
实体和关系的不确定性。为此，Yang提出了GCN-
后，就可以试图预测知识图谱中缺失的信息。例如
VAE[56]，一种新的用于学习大规模知识图谱中实体和
给定查询 h r ，将知识图谱中的每一个实体都放在
( , ,?)
关系嵌入的概率框架，利用变分自编码器将目标实
尾实体的位置上，通过知识图谱嵌入模型中的得分
体的邻域结构编码为潜在嵌入分布，输出潜在表示 z
函数计算不同实体作为该三元组的尾实体的得分，
的分布参数，并将其建模为高斯后验分布，生成 z 的
得分最高的实体会被作为链接预测的最终结果。
均值和方差 μ σ q ZR E ，同时为了将高斯后验分
, = ϕ( | , )
布建模为更灵活的非高斯分布，而不是简单的多元
高斯分布。Yang还研究了逆自回归流（inverse auto-
regressiveflow，IAF）作为VAE的解码器，改进实体嵌
入分布的密度估计。于此同时，Hu等人[57]提出了一
种新的卷积自编码器模型作为知识图谱嵌入的解码
图9 链接预测示例
器，其中利用双向关系编码器对实体嵌入进行编码，
Fig.9 ExampleofLP
以生成实体的双向关系特征，旨在获取相应的隐藏
关系表示。 链接预测通常被用于评估知识图谱嵌入算法的 1802 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(8)
有效性，将正确的三元组排名记录在有序列表中，查 标值。在链接预测任务中，RGHAT和AR-KGAT在
看正确三元组是否在错误三元组之前，因此链接预 数据集FB15K-237和WN18RR上均取得了不错的性
测任务也被定义为实体排序任务。其链接预测的评 能，这可能取决于模型的注意力机制，不仅利用了知
估指标通常采用平均排名（mean rank，MR）、平均倒 识图谱的异构特性，而且采用GAT的注意力机制，对
数排名（mean reciprocal rank，MRR）和正确三元组排 实体和关系分配不同的重要性。
序在前n个的比例Hits@n，评估指标定义如下：
■ |
|
||MR = 2| T1 test| x∑
i∈T
test(rank ih +rank it )
| ■ ■
||| | |MRR = 2| T1 test| x∑
i∈T
test■|| ra1 nk ih + ra1 nk it ■||
■Hits n 1 I rankh n I rankt n（14）
| || @ = 2| T test| x∑
i∈T
test
[ i ≤ ]+ [ i≤ ]
|| | || |r ra an nk ki th =1+ x∑
i∈T
test
II [[ SS (h ,r ,t )< SS (h ′,r ,t ) ]]
■| i=1+ x∑
i∈T
test
(h ,r ,t )< (h ,r ,t ′)
其中，T 是测试集评估样本的个数，rankh、rankt为
i i
test
第i个样本中正确三元组的排序值，I 为示性函数，
[·] 图10 FB15K-237数据集上的模型指标
I x 当且仅当 x为真，否则 I x 。由于评估指标
[ ]=1 [ ]=0 Fig.10 ModelmetricsonFB15K-237dataset
中MR是一种不被认可的指标，下面将在MRR和
Hits@n中描述模型的性能，不再阐述MR。
在链接预测实验中，主要在4个使用广泛的开源
数据集FB15K[14]、FB15K-237[58]、WN18[14]和WN18RR[16]
上评估知识图谱嵌入模型的性能。FB15K是知识图
谱库FreeBase的一个子集，其中包含大量的知识事
实；WN18是WordNet的一个子集，是一个描述词汇
关系的知识图谱。研究发现，FB15K和WN18包含了
实体之间的逆向关系。为了解决这种情况，将数据
集中的逆向关系删除，提出一种更具有挑战性的数
据集FB15K-237和WN18RR，数据集的详细概述见
表2。由于数据集FB15K和WN18存在的逆向关系
图11 WN18RR数据集上的模型指标
会影响模型的性能，将在FB15K-237和WN18RR数
Fig.11 ModelmetricsonWN18RRdataset
据集中阐明模型的性能指标。
3.2 实体对齐
表2 FB15K、WN18、FB15K-237和
在知识图谱嵌入应用中，实体对齐也是一项关
WN18RR数据集概述
Table2 OverviewofFB15K,WN18,FB15K-237 键的技术。实体对齐（entity alignment，EA），也称为
andWN18RRdatasets 实体解析，其任务是验证两个实体是否指代或者引
用的是同一个事物或对象，在处理知识图谱中冗余
数据集 实体 关系 训练集 验证集 测试集
FB15K 14951 1345 483142 50000 59071 的实体上很有帮助，也可以在知识图谱融合的时候
WN18 40943 18 141442 5000 5000 从异构的数据集中找相同的实体。实体对齐的定义
FB15K-237 14541 237 272115 17535 20466 为：两个不同的知识图谱 KG、KG ，其中的实体有一
WN18RR 40943 11 86835 3034 3134 1 2
定的对应关系，在已知一些实体对齐样本的前提下，
在图10和图11中，对每个基于图神经网络的知 预测知识图谱中其他实体的对齐关系，图12为实体
识图谱嵌入模型都阐述了在数据集中的各项评估指 对齐的示例。 延照耀 等：面向图神经网络的知识图谱嵌入研究进展 1803
表3 DBP15K数据集概述
Table3 OverviewofDBP15Kdataset
关系 属性
数据集 子集 图 实体 关系
三元组 三元组
DBP15K ZH 66469 2830 153929 379684
ZH-EN EN 98125 2317 237674 567755
图12 实体对齐示例 DBP15K FR 66858 1379 192191 528665
DBP15K
Fig.12 ExampleofEA FR-EN EN 105889 2209 278590 576543
DBP15K JA 65774 2043 164373 354619
传统的实体对齐方法主要从基于相似度和基于
JA-EN EN 95680 2096 233319 497230
关系推理来比较知识图谱中实体之间的关系。随着
知识图谱嵌入研究的发展，研究者也随之提出了基
于图神经网络的实体对齐方法，由于图神经网络具
有较强的鲁棒性和泛化能力，大多数实体对齐方法
使用图神经网络进行知识图谱表示学习。基于图神
经网络的知识图谱嵌入方法按照利用信息的不同，
分为只利用图谱的结构信息、利用图谱结构信息和
实体的额外信息（实体的描述信息、属性）、只利用实
体的额外信息三种类别。
除了链接预测的评估指标MR、MRR、Hits@n之
外，个别实体对齐任务还使用Precision、Recall、F1-
measure作为评估指标。精确率（Precision）被定义为
实体对齐的准确程度，定义为： 图13 DBP15K（FR-EN）数据集上的模型指标
N Fig.13 ModelmetricsonDBP15K(FR-EN)dataset
P success （15）
= N
total
其中，N 、N 分别表示知识图谱嵌入方法对齐
success total
的正确实体的数量和实体对总数。
召回率（Recall）表示被正确对齐的实体占全部
真实存在实体的比例，定义为：
N
R success （16）
= R
total
其中，R 表示所有的真实存在的实体对数量。
total
F1值（F1-measure）则反映实体对齐的综合效
果，定义为：
R P
F 2× × （17）
1= R P
+ 图14 DBP15K（JA-EN）数据集上的模型指标
在实体对齐实验中，大多数实体对齐数据集都
Fig.14 ModelmetricsonDBP15K(JA-EN)dataset
是基于Wikidata、DBpedia和YAGO等知识图谱构建
的，从DBpedia构建的实体对齐数据集DBP15K[59]使 表现效果最好。这表明成对连通图（PCG），利用
用最为广泛。DBP15K从DBpedia的不同语言版本 GCN捕获实体对的属性信息，再加上关系感知的图
构建出 3 个版本的子数据集 DBP15K（ZH-EN）、 注意力网络传播相似特征，这种嵌入方法聚合邻居
DBP15K（FR-EN）和DBP15K（JA-EN），以进行实体 实体的特征信息时，可以同时兼顾实体的属性信息
对齐任务，数据集的详细信息如表3所示。 和结构信息，最终得到实体的嵌入表示。因此在基
图13~图15描述了每个基于图神经网络的知识 于图神经网络的知识图谱嵌入方法中加入结构信息
图谱嵌入模型在数据集DBP15K的3个子数据集的 和额外的属性信息，可以更好地捕获实体的语义信
评估指标值。不难发现，EPEA模型在实体对齐方面 息，从而获得更好的区分度。 1804 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(8)
见表4。其验证指标同链接预测一样使用MR、MRR
和Hits@n，下面不再赘述。图17描述了部分知识推
理方法在FB15K-237和WN18RR数据集的性能指标。
表4 NELL-995、YAGO-10数据集概述
Table4 OverviewofNELL-995andYAGO-10datasets
数据集 实体 关系 训练集 验证集 测试集
NELL-995 74536 200 149678 543 2818
YAGO-10 123188 37 1079040 5000 5000
图15 DBP15K（ZH-EN）数据集上的模型指标
Fig.15 ModelmetricsonDBP15K(ZH-EN)dataset
3.3 知识图谱推理
知识图谱推理（knowledgegraphreasoning，KGR），
简称知识推理，从一个或者多个现有的知识出发，用
特定的方法推断新的或未知的结论，或者识别错误
的信息。例如，给出已知的三元组信息（X ，出生地，
Y），通过推理可以得到新的三元组信息（X ，国籍，
Y）。在某种程度上，知识推理类似于链接预测，其核
心都是对三元组中的实体和关系进行预测。图16给
出了知识推理的示例。
图17 FB15K-237和WN18RR数据集上的性能指标
Fig.17 PerformancemetricsonFB15K-237and
图16 知识图谱推理示例
WN18RRdatasets
Fig.16 ExampleofKGR
知识推理作为知识图谱嵌入的重要任务之一，
知识推理方法又可分为基于逻辑规则、基于分
是通过对三元组中的实体和关系进行预测，实现对
布式表示、基于深度学习和基于图神经网络四大
未知知识的推断。链接预测、实体对齐和三元组分
类。随着GNN在知识图谱嵌入的广泛应用，基于图
类等任务与知识推理密切相关，但它们是在已知实
神经网络的知识推理也成为当下主流的知识推理方
法。基于图神经的知识推理方法，可以将知识图谱 体和关系的基础上进行预测。虽然大部分知识推理
的异构特性和实体的语义信息有效结合起来，在信 方法将链接预测作为评估其有效性的任务，但对于
息聚合的时候不仅考虑目标实体的隐层信息，同时 知识推理任务需要根据不同的场景和需求选择合适
也考虑该实体的邻居实体信息和局部结构信息，大 的任务进行分析。
大提高了知识推理方法的推理能力。 比较新颖的是，知识图谱推理在军事、医疗和交
同链接预测任务一样，验证知识推理方法所使 通领域也被广泛应用。在军事领域，知识图谱推理
用的数据集除 FB15K-237和 WN18RR外，还使用 帮助指挥官理解复杂多变的战场形势，其中军事决
NELL-995[60]和YAGO-10[61]作为验证数据集，具体详情 策知识图谱中不仅包括战斗行为实体和关系，而且 延照耀 等：面向图神经网络的知识图谱嵌入研究进展 1805
也包括军队指定的军事规则。Nie等人[62]提出一种 补全[66]、关系补全[67]和属性补全[68]，它们是知识图谱
混合规则和图神经网络学习的知识图谱推理方法 补全的三个重要方面。实体补全是指识别并添加新
（context-surrounding graph neural networks with num- 实体到知识图谱中；关系补全是指将已知实体之间
bers，CS-GNN-N），其中规则学习、规则注入和图神经 的未知关系添加到知识图谱中；属性补全是指根据
网络学习在CS-GNN-N中迭代完成。在建模药物之 已知信息自动生成实体的属性信息。除了实体补
间的相互作用和多药副作用中，Zitnik等人[63]提出一 全、关系补全和属性补全这三方面外，还有一些其他
种Decagon的建模方法，Decagon使用GCN来学习药 的补全任务，例如事件补全[69]和时间补全[70]，它们也
物的低维向量表示，同时考虑药物之间的相互作用， 可以被视为知识图谱补全的子任务。在实际应用场
利用药物的嵌入向量计算之间的相似度来预测多药 景中，知识图谱补全可以帮助人们更好地理解和利
副作用。为了应对交通模式的时变性和道路网络的 用数据，提高信息的精度和效率。
复杂空间依赖性的挑战，Cui等人[64]提出一种新颖的 根据任务场景的不同，知识图谱补全可以分为
静态知识图谱补全与动态知识图谱补全。具体而
深度学习框架TGC-LSTM（traffic graph convolutional
言，如果补全过程中涉及的实体和关系属于原始知
long short-term memory neural network），TGC-LSTM
识图谱，则称为静态知识图谱补全，否则称为动态知
使用GCN从城市交通网络提取特征，然后使用循环
识图谱补全。目前大量的知识图谱补全模型都是基
神经网络对交通流量时间序列数据进行建模和预
于静态知识图谱[71]，在这种情况下假设所有的实体和
测，从而有效捕捉城市交通网中的复杂关系。
关系都属于同一知识图谱中，而图谱的补全只能挖
由于部分方法使用基于领域的数据集进行方法
掘现有实体之间的潜在关系来实现，而不是向现有
评估，且链接预测、实体对齐等任务的方法评价指标
的图谱中添加新的关系或对应实体，这也导致了静
前面已经介绍，图17只给出部分方法的评估指标。
态知识图谱补全主要适用于规模小的领域知识图
3.4 知识图谱补全
谱，也不能很好地扩展图谱结构。基于概率数据库
知识图谱补全（knowledgegraphcompletion，KGC）
理论中的动态假设[1]，为动态知识图谱补全提供了一
作为知识图谱构建中的一个热门话题，同链接预测
种预测新实体和关系的方法。由于替代新知识的范
一样，预测知识图谱中缺失的实体或关系。不同的
围很广，在动态知识图谱补全中难以建立本地和外
是，知识图谱补全通过挖掘未知事实来补全知识图
部之间的联系，但是当扩大知识图谱的规模时，动态
谱的结构，图18给出了知识图谱补全的示例。知识
知识图谱补全具有更大的优势。
图谱补全的目标是解决知识图谱中缺失的事实或者
由于目前的大多数研究集中于静态知识图谱补
链接导致知识图谱的不完整性和稀疏性的问题，是
全，根据三元组中缺失的部分，知识图谱补全的任务
发现新知识的重要手段，同时也是提高知识图谱质
可分为头实体预测、关系预测、尾实体预测，且静态
量的必要手段。除知识推理等三种具体任务之外，
知识图谱补全任务所使用的数据集以及评估指标同
知识图谱补全也可以应用于特定任务，比如属性预
链接预测任务一样，因此本文的内容也限制在此范
测或其他子任务。
围内，不再针对知识图谱补全任务进行赘述。
4 常识知识图谱
上文所述模型大部分应用于百科全书知识图谱
（encyclopediaKG），百科全书知识图谱是指将百科全
书中的知识整理出来，形成一个具有结构化信息的
知识图谱，为读者提供详实全面的知识体系。与之
相比，常识知识图谱（common sense KG）主要涵盖日
常生活中的各种常识，为人们提供一种方便快捷的
图18 知识图谱补全示例
查询工具，帮助人们解决生活中的各种疑惑和问
Fig.18 ExampleofKGC
题。这两种知识图谱在信息的处理和展现方面都具
知识图谱补全是指通过自动化方法识别和填补 有较为清晰的信息结构和易于查询的特点，因为它
知识图谱中的空缺或错误[65]，知识图谱补全包括实体 们都采用了一种语义化的表示方式，使得它们之间 1806 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(8)
的关系可以被机器自动理解和处理。 该方法通过额外的关系利用图谱的层次结构，进一
针对常识性知识图谱，研究者会挖掘词之间的语 步使用加权方案对实体分配不同的重要性，以改进
言知识，比较注意的关系有isARelation、HasProperty、 图谱中的消息传递。根据图卷积消息传递规则
isUsedFor等，可以将此过程解释为问题理解，所需要 Hl +1 σ D-1AHlθl ，DGP的加权消息传递规则变为：
= ( )
的知识称之为常识性知识（commonsenseknowledge）。 ■ K ■ K ■ ■
H σ|| αaDa-1Aaσ| αdDd-1AdXθ |θ || （18）
对于百科全书知识图谱而言，研究者通常会注意实 = ■∑ k k k k ■∑ k k k k d ■ a ■
=0 =0
体与实体之间的事实连接，比如SpouseOf、DayOf- 其中，Aa和 Ad 表示为邻接矩阵部分，Da和 Dd 是 Aa
k k k k k
Birth、LocatedIn等，通常将此过程解释为问题回答。
和 Ad对应的度矩阵，θ为权重矩阵。但DGP的前提
k
根据常识知识图谱[72]已有介绍，表5总结了代表性的
假设是图谱为有向非循环图，比如WordNet，而常识
常识知识图谱，这些资源涵盖了丰富的知识范围，从
知识图谱并不是有向无环图结构。为了解决这一局
日常知识到以事件为中心的知识，再到视觉知识。
限性，Nayak等人[87]引入ZSL-KG（zero-shot learning
常识知识图谱已经在自然语言处理、计算机视觉和
with knowledge graph），这是一个利用机器翻译和语
知识图谱等领域被应用[81-83]。
言建模任务的非线性模块Transformers[88]，使用多层
常识知识图谱嵌入通常使用TransE图嵌入和
感知机和自注意力机制的特性学习非线性聚合器
BERT文本嵌入，而利用GCN传输不同类别的信息研
TrGCN（transformer graph convolutional network），用
究较少。随着零样本学习（zero-shot learning）[84]的兴
于学习嵌入表示。与之前GCNZ、DGP以及大多数图
起，Wang等人[85]提出利用常识图谱的结构化信息和
神经网络方法使用的聚合函数不同的是，ZSL-KG利
复杂关系，而不需要任何类标签来学习视觉分类器
用TrGCN学习基于转移的聚合器，计算邻居实体的
的方法GCNZ（graph convolutionalnetworkswith zero-
非线性组合，增强嵌入表示的表达能力，从而捕获常
shotlearning）。该方法是建立在图卷积网络之上，将
识知识图谱中的复杂关系。TrGCN将特征向量经过
具有回归损失的图卷积应用于零样本学习，该图卷
非线性层标准化后，利用自注意力机制计算每个查
积的作用是在不同类别之间传递消息。该方法在训
询实体的特征加权组合，表示如下：
练期间调整整个图结构，但常识知识图谱的规模庞
■hl Wl
+1
σWl
+1
hl hl
大，并且在整个图上训练图神经网络开销过于昂 | ′u=LN{ fh ·[ ( fh · u)]+ u}
|
贵 纳方。 法为 模了 型仍 D然 G可 P（以 de利 ns用 eg图 ra谱 ph的 pr图 opa结 ga构 tio特 n）性 [86]， 被一 提种 出归
，
■ ■| |{z ul +1 ∀u ∈N (v )}=softmax■ ■| | Q dK (pT )■ ■| |V （19）
表5 代表性常识知识图谱统计
Table5 RepresentativecommonsenseKGstatistics
知识库 描述 映射
WordNet、DBpedia、
ConceptNet[73] ConceptNet是一个开源的语义网络，旨在帮助计算机理解人们使用的单词的含义
OpenCyc、Wiktionary
ATOMIC2020，一个拥有133万个关于实体和事件的大规模的文本描述常识库，这些文本描述
ATOMIC2020[74] ConceptNet、Cyc
编码了人类日常经验的社会和物理方面，对当前语言模型中编码的常识性知识进行补充
WikiData是一个自由和开放的知识库，人类和计算机都可以阅读和编辑，其内容可在自由许可
WikiData[75] various
下使用，使用标准格式导出，并可与链接数据网上的其他开放数据集相互链接
WordNet是一个大型的英语词汇数据库。名词、动词、形容词和副词被分组为synsets（setsof
WordNet[76]
cognitivesynonyms），每个同义词都表达了一个独特的概念
VerbNe（t VN）是最大的英语动词在线网络，将其句法和语义模式联系起来，是一个分层的、与
VerbNet[77] FrameNet、WordNet
领域无关的、覆盖面很广的动词词典
FrameNet，一个英语词汇数据库，既是人类可读的，也是计算机可读的，其基础是对实际文本中
FrameNet[78]
的词汇使用方式进行注释
VisualGenome是一个有100000多张图片和上面所有物体的描述的数据集，该数据集旨在用
VisualGenome[79] WordNet
于物体搜索和识别任务，包含了对图像、物体、属性和关系的描述
ImageNet是一个根据WordNet层次结构（目前只有名词）组织的图像数据库，其中层次结构的
ImageNet[80] WordNet
每个节点都由成百上千的图像描绘 延照耀 等：面向图神经网络的知识图谱嵌入研究进展 1807
其中，Q Wl +1 hl 是所有邻居查询向量的集合， 数据集FB15K-237和WN18RR数据集上的链接预测
= q · ′u
W Wl +1 hl 是所有键向量，V Wl +1 hl 是所有值向 任务、DBP15K数据集上的实体对齐任务以及NELL-
= k · ′u = v · ′u
995和YAGO-10数据集上的知识推理任务的实验指
量。TrGCN通过聚合局部邻居特征来学习实体的嵌
标结果，实验指标采用MRR和Hits@n指标。
入表示，意味着学习的模型可以用于预测新的图形
结构，而不需要再次训练，这也使得ZSL-KG更适合 虽然基于图神经网络的知识图谱嵌入方法大部
零样本学习。 分应用于百科全书类知识图谱，但当前的常识知识
图谱数据源包含对下游任务整体有益的补充知识，
5 总结与展望 但不同的建模方法阻止了二者之间的交互。未来，
可以将图神经网络的图嵌入技术和预训练语言模型
5.1 总结
的信息嵌入技术结合，以捕获知识图谱的各种形式
知识图谱嵌入的思想是将实体和关系的语义信
的结构相关性和文本相似性。
息映射到低维稠密实值的向量空间中，因此，需要对
5.2 展望
知识图谱的结构信息以及实体和关系的语义信息进
行学习，进而将学习到的实体和关系嵌入应用于多 GNN经过近几年的不断发展，这种有效的方法
种下游任务。GNN将现有的神经网络方法拓展到了 和框架也在理论和实验上被证实，基于图神经网络
图结构数据处理领域，依靠图结构数据进行建模，来 的知识图谱嵌入方法也得到了迅速发展，但是仍然
学习、提取和挖掘图结构数据中的特征和模式。知 存在许多的挑战和待完善的问题，不少已有方向都
识图谱嵌入利用图神经网络强大的图编码能力，可 遇到了瓶颈。根据国内外的研究现状，下面探讨了
以很好地学习知识图谱中的实体信息、关系信息以 一些基于图神经网络的知识图谱嵌入方法的未来研
及结构信息，从而高效地解决了知识图谱中的图结 究方向和待完善的问题。
构数据问题。 （1）如何解决知识图普的分布外泛化问题。分
本文分别从基于图卷积、图神经、图注意力和图 布外泛化问题OOD泛化（out-of-distribution general-
自编码器等方面对知识图谱嵌入进行了综述，介绍 ization）是指当测试样本的分布与训练样本的分布不
了各类知识图谱嵌入的基础模型和核心算法，并就 同时，如何提高在新数据（例如未知实体或未知分
基于图神经网络的知识图谱嵌入在链接预测、实体 布）上的泛化性能。目前大部分关于分布外泛化问
对齐、知识推理以及知识图谱补全等下游任务中进 题的研究主要集中在欧式数据（比如图片），虽然有
行了任务分析及归纳。表6~表9总结了这四类知识 一定的文献[89-92]在研究图的分布外泛化问题，但对知
图谱嵌入方法的优缺点和基础特征。 识图谱的相关研究还是比较少，如何利用有限观测
为了更好地展示不同方法在下游任务中的性 的数据，学习一个稳健的模型，能够泛化到训练分布
能，本文在第3章任务分析中给出了部分方法在开源 有明显差异的测试数据上是分布外泛化问题要解决
表6 图卷积嵌入方法总结
Table6 Summaryofgraphconvolutionalembeddingmethods
类别 方法 优缺点 特征
优点：易扩展，参数共享
R-GCN
缺点：稀有或缺失关系的处理不够优秀，可解释性较差
优点：自适应学习实体的分布表示
VR-GCN
缺点：隐空间的节点表示比较抽象，难以直观地解释实体
分为空间图卷积
优点：引入可训练的转移矩阵建模实体和关系的语义关系 和谱分解图卷积，
TransGCN
缺点：运算复杂度比较高，导致计算效率较低 参数共享，但实体
基于图卷积
优点：考虑多关系类型的组合，更好地描述实体的复杂关系 数量越多，知识图
CompGCN
缺点：无监督的嵌入方法，无法直接应用于一些需要标注的任务 谱规模越大，训练
成本越高
优点：将语义匹配和拓扑匹配融合起来，实现更全面的知识表示
KE-GCN
缺点：算法采用随机梯度下降进行训练，容易陷入局部最优解
优点：使用基于交替优化的训练过程，提高对齐的稳定性和鲁棒性
DINGAL
缺点：对知识图谱的动态变化做出简单的假设，不能很好地处理复杂场景 1808 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(8)
表7 图注意力嵌入方法总结
Table7 Summaryofgraphattentionembeddingmethods
类别 方法 优缺点 特征
优点：很容易地与其他模型集成
SACN
缺点：需要大量的训练数据
优点：自适应地调整权重，提高模型的泛化能力
WGCN
缺点：对于边权重分布不均的情况，影响模型的表现
优点：提出新的损失函数，解决标准交叉熵损失函数中的类别不平衡问题
Nathani
缺点：只考虑了一阶邻居信息，未考虑高阶邻居信息
优点：采用多头注意力机制，可以并行计算不同的注意力权重，提高准确率
r-GAT
缺点：引入关系特征矩阵增加了模型的参数量，可能会导致过拟合的问题
优点：利用去中心化的结构并行处理大规模的图数据，降低了时间复杂度
decentRL
缺点：模型结构较为简单，可能会受到模型容量的限制 引入注意力机制，
为邻居实体和关
优点：引入关系感知机制，多层注意力机制，支持扩展性
RAGAT 系分配不同的注
缺点：计算量较大，对于长距离依赖的建模不足，需要合适的参数选择
意力分数，使其关
优点：采用较大的滑动窗口，考虑更多的关系三元组
基于图注意力 RAHAT 注较为重要的邻
缺点：可解释性相对较差，难以解释模型的决策过程
居实体和关系，鲁
优点：学习异构图上的关系特征，提高嵌入质量和知识图谱补全的准确性
HRAN 棒性和可解释性
缺点：模型需要对异构图谱的实体和关系类型进行预定义
更强，但额外增加
优点：采用基于目标关系的约束，更好地适应实际任务中的目标关系需求 了时间和内存消耗
TRAR
缺点：计算复杂度较高，需要更多的计算资源
优点：引入基于LSA的词向量嵌入方法，增强对文本信息的理解能力
LSA-GAT
缺点：采用词向量嵌入方法在处理长文本时可能存在信息损失的问题
优点：采用基于标签的负采样和动态交互机制，提高负样本的质量
AliNet
缺点：未考虑实体和关系的类型信息，无法充分挖掘实体和关系的语义关联
优点：利用自适应规划的参数更新方式提高模型的泛化能力和鲁棒性
AR-KGAT
缺点：模型计算量较大，需要在GPU等高性能设备上进行训练和预测
优点：采用子网络来捕获不同的信息，更好地利用知识图谱的结构信息
MRGAT
缺点：使用均匀分布初始化参数，可能存在梯度消失或梯度爆炸等问题
表8 图神经嵌入方法总结
Table8 Summaryofgraphneuralembeddingmethods
类别 方法 优缺点 特征
优点：引入元图的概念，动态地学习不同的子图结构，并且可以自适应调整
M-GNN
缺点：使用基于邻居聚合的消息传递方式，存在消息传递的误差累积问题
优点：自适应学习图层之间的重要性，提升了嵌入的效果
M2GNN
缺点：模型结构相对复杂，难以直观地理解内部的学习过程和机制
优点：支持不确定性推理，可以捕捉复杂的关系，可以进行自动参数学习
MLNs
缺点：计算代价高，数据要求高，难以调参
优点：有效处理大规模的概率逻辑规则和知识图谱，支持复杂的推理任务
ExpressGNN
缺点：适用于概率逻辑推理任务，对于其他类型的任务可能效果不佳
将现有的神经网
优点：采用互动网络来对关系进行编码，有效地利用了关系之间的交互信息
GraIL 络方法拓展到了
缺点：只考虑二元关系，对于多元关系的处理需要进行改进
基于图神经 图结构数据处理
优点：充分利用实体的语义信息，提高知识图谱补全的准确性
INDIGO 领域，学习到更深
缺点：计算复杂度上较高，对于稀疏知识图谱的处理效果不够理想
层次的语义信息
优点：采用多通道的方式来综合利用不同类型的图
MuGNN
缺点：需要预定义不同类型的图，对于一些新颖的类型无法适应
优点：将实体对齐任务转化为向量空间中的距离度量，提高计算效率
EPEA
缺点：未考虑关系类型的信息，无法处理更复杂的实体关系
优点：利用跨语言知识图谱中实体的语言信息进行实体嵌入学习和对齐
MRAEA
缺点：算法的训练和推理速度较慢
优点：使用上下文信息来丰富实体和关系的表示，解决数据稀疏和噪声问题
CS-GNN-N
缺点：数字特征对结果产生噪声影响，需要对数字特征的质量进行处理 延照耀 等：面向图神经网络的知识图谱嵌入研究进展 1809
表9 图自编码器嵌入方法总结
Table9 Summaryofgraphautoencoderembeddingmethods
类别 方法 优缺点 特征
优点：能够处理有向图的重构，在较小的训练集上进行有效的训练
GravityGraphVA
缺点：需要进行大量的超参数调整
编码器将图转为
优点：能够生成与输入图相似的图形，能够学习图数据的连续表示
GravityGraphVAE 低维稠密表示，
缺点：训练模型需要更多的时间和计算资源，比GravityGraphVA更耗时
解码器重构图的
优点：采用自编码器的思想将嵌入空间进行压缩，提高空间和时间的效率 结构和属性，缩
基于图自编码器 R-GAE
缺点：处理多种关系类型存在一定的限制，需要对关系类型进行预定义 减输入量，但需
要手动设置隐层
优点：能够处理不同大小和形状的图，并生成具有多样性的图
GCN-VAE 维度，多为无监
缺点：生成的图缺乏真实性，处理大规模图时，训练和生成时间较长
督学习，性能较差
优点：引入双向关系编码网络，更好地捕捉实体的关系和上下文信息
Hu等人
缺点：在编码网络中使用简单的结构，无法充分表达实体的复杂关系
的核心问题。 不同的场景和任务，需要根据具体的情况选择合适
（2）如何学习动态知识图谱的知识图谱嵌入。 的方法来解决这个问题。
现有的知识图谱结构是静态的图结构，但现实中知 （5）如何研究图神经网络中的可解释性以提高
识图谱的图结构往往会随着时间的推移而发生改 知识预测的可靠性。图神经网络在知识图谱中的应
变，例如部分实体被增加或者删除，而且传统基于静 用面临着可解释性不足的问题，这可能会导致模型
态图谱的嵌入技术不能很好将语义信息表示出来， 在预测时出现不确定性，降低预测的可靠性。此外，
如何将基于动态知识图谱的嵌入表示进行高效的学 可解释性技术可以进一步发现知识图谱中的规律和
习也是未来的研究方向之一。 模式，提高对知识的理解和分析能力。需要注意的
（3）如何将多模态的知识融入图谱嵌入技术。 是，在研究图神经网络中的可解释性时，需要综合考
通过将不同形式表达的知识（比如视频、文本或音 虑模型的预测性能和可解释性之间的平衡，以达到
频）融入知识图谱嵌入技术中，进一步丰富嵌入信 最优的预测效果。
息，进而从不同类型的数据中获得更符合客观世界 （6）如何挖掘和探索知识图谱中更深层次的信
规律的知识图谱嵌入方法，基于多模态的知识图谱 息。目前基于图神经网络的知识图谱嵌入研究中，
嵌入方法也将应运而生。将多模态数据的特征作为 诸多的研究者将精力放在了知识图谱的关系信息
节点或边的属性输入到图神经网络，利用多模态数 上。但知识图谱除了关系信息，还蕴含了实体和关
据的信息更好地学习知识之间的关系和图谱之间的 系的属性信息、知识图谱的层次信息以及实体信息，
复杂结构，以实现将多模态的知识融入基于图神经 如果可以充分挖掘和探索这些信息，必将会提升知
的图谱嵌入，这将会成为研究的又一热点。 识图谱嵌入的性能。
（4）如何解决网络深度与邻居节点特征聚合数 综上所述，基于图神经网络的知识图谱嵌入目
量之间的矛盾。在自然语言处理或者计算机视觉 前还面临着众多挑战，这也需要研究者投入更多的
精力去解决这些问题。
中，神经网络的层数可以进行多层叠加，而且在一定
范围内神经网络的增加会更有效地提取语义信息。
但是，在知识图谱中，实体的邻居节点数量往往会随 参考文献：
着网络深度的增加而呈指数级别增长，这就带来了 [1]SINGHALA.Introducingtheknowledgegraph:things,not
strings[J].OfficialGoogleBlog,2012,5:16.
网络深度与邻居节点特征聚合数量之间的矛盾。图
[2]刘知远,孙茂松,林衍凯,等.知识表示学习研究进展[J].
神经网络的核心是邻居节点的消息传递和消息读
计算机研究与发展,2016,53(2):247-261.
取，传递和读取过程中邻居节点的阶数会随着网络
LIUZY,SUNMS,LINYK,etal.Knowledgerepresenta-
层数的增加而扩张，进而导致邻居节点的特征聚合
tion learning: a review[J]. Journal of Computer Research
数量成指数增加。如果增加网络深度，就必须要限
andDevelopment,2016,53(2):247-261.
制每层的节点数量，但节点之间的消息传递和读取 [3]MIKOLOVT,SUTSKEVER I,CHEN K,etal.Distributed
也会随之受阻。需要注意的是，不同的方法适用于 representationsofwordsandphrasesandtheircomposition- 1810 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(8)
ality[C]//Advances in Neural Information Processing Sys- [C]//Advances in Neural Information Processing Systems
tems26,LakeTahoe,Dec5-8,2013:3111-3119. 26,LakeTahoe,Dec5-8,2013:2787-2795.
[4]杨东华,何涛,王宏志,等.面向知识图谱的图嵌入学习研 [15] SUN Z, DENG Z H, NIE J Y, et al. Rotate: knowledge
究进展[J].软件学报,2022,33(9):3370-3390. graph embedding by relational rotation in complex space
YANG D H, HE T, WANG H Z, et al. Survey on know- [J].arXiv:1902.10197,2019.
ledge graph embedding learning[J]. Journal of Software, [16]DETTMERST,MINERVINIP,STENETORPP,etal.Con-
2022,33(9):3370-3390. volutional 2D knowledge graph embeddings[C]//Proceed-
[5]SCARSELLIF,GORIM,TSOIAC,etal.Thegraphneural ings of the 32nd AAAI Conference on Artificial Intelli-
network model[J]. IEEE Transactions on Neural Networks, gence,the30thInnovativeApplicationsofArtificialIntelli-
2008,20(1):61-80. gence, and the 8th AAAI Symposium on Educational Ad-
[6]BORDESA,WESTON J,USUNIERN.Openquestionan- vancesinArtificialIntelligence,NewOrleans,Feb2-7,2018.
swering with weakly supervised embedding models[C]// MenloPark,AAAI,2018:1811-1818.
LNCS 8724: Proceedings of the 2014 European Conference [17]吴博,梁循,张树森,等.图神经网络前沿进展与应用[J].
on Machine Learning and Knowledge Discovery in Data- 计算机学报,2022,45(1):35-68.
base,Nancy,Sep15-19,2014.Cham:Springer,2014:165- WU B,LIANG X,ZHANG SS,etal.Advancesandappli-
180. cations in graph neural network[J]. Chinese Journal of
[7]DAIBERJ,JAKOBM,HOKAMPC,etal.Improvingeffi- Computers,2022,45(1):35-68.
ciency and accuracy in multilingual entity extraction[C]// [18] KHAMSI M A, KIRK W A. An introduction to metric
Proceedings of the 9th International Conference on Semantic spacesandfixedpointtheory[M].NewYork:JohnWiley&
Systems,Graz,Sep4-6,2013.NewYork:ACM,2013:121- Sons,2011.
124. [19]GILMER J,SCHOENHOLZ S S,RILEYPF,etal.Neural
[8] HOFFMANN R, ZHANG C, LING X, et al. Knowledge- message passing for quantum chemistry[C]//Proceedings of
based weak supervision for information extraction of over- the 34th International Conference on Machine Learning,
lapping relations[C]//Proceedings of the 49thAnnual Meeting Sydney,Aug6-11,2017:1263-1272.
of the Association for Computational Linguistics: Human [20] BENGIO Y, COURVILLEA, VINCENT P. Representation
Language Technologies, Portland, Jun 19-24, 2011. Strouds- learning: a review and new perspectives[J]. IEEE Transac-
burg:ACL,2011:541-550. tions on Pattern Analysis and Machine Intelligence, 2013,
[9] GUO Q, ZHUANG F, QIN C, et al.Asurvey on knowledge 35(8):1798-1828.
graph-based recommender systems[J]. IEEE Transactions on [21] LECUN Y, BENGIO Y, HINTON G. Deep learning[J].
KnowledgeandDataEngineering,2022,34(8):3549-3568. Nature,2015,521(7553):436-444.
[10]NICKELM,TRESPV,KRIEGELH P.Athree-way model [22]SCHLICHTKRULLM,KIPFTN,BLOEMP,etal.Model-
forcollectivelearningonmulti-relationaldata[C]//Proceedings ing relational data with graph convolutional networks[C]//
of the 28th International Conference on Machine Learning, LNCS10843:Proceedingsofthe15thInternationalConfer-
Bellevue, Jun 28-Jul 2, 2011. Madison: Omnipress, 2011: ence the Semantic Web, Heraklion, Jun 3-7, 2018. Cham:
809-816. Springer,2018:593-607.
[11]YANGB,YIHSW,HEX,etal.Embeddingentitiesandre- [23] YE R, LI X, FANG Y, et al.A vectorized relational graph
lations for learning and inference in knowledge bases[C]// convolutional network for multi-relational network align-
Proceedings of the 3rd International Conference on Learning ment[C]//Proceedings of the 28th International Joint Con-
Representations,SanDiego,May7-9,2015:1-12. ference on Artificial Intelligence, Macao, China, Aug 10-
[12]TROUILLONT,WELBLJ,RIEDELS,etal.Complexem- 16,2019:4135-4141.
beddings for simple link prediction[C]//Proceedings of the [24]CAIL,YANB,MAIG,etal.TransGCN:couplingtransfor-
33rd International Conference on Machine Learning, New mation assumptions with graph convolutional networks for
York,Jun19-24,2016:2071-2080. link prediction[C]//Proceedings of the 10th International
[13] NICKEL M, ROSASCO L, POGGIO T. Holographic em- Conference on Knowledge Capture, Marina Del Rey, Nov
beddings of knowledge graphs[C]//Proceedings of the 30th 19-21,2019.NewYork:ACM,2019:131-138.
AAAIConferenceonArtificialIntelligence,PhoenixArizo- [25]VASHISHTH S,SANYALS,NITINV,etal.Composition-
nam,Feb12-17,2016:1955-1961. basedmulti-relationalgraphconvolutionalnetworks[J].arXiv:
[14] BORDES A, USUNIER N, GARCIA-DURAN A, et al. 1911.03082,2019.
Translating embeddings for modeling multi-relational data [26]YU D,YANG Y, ZHANG R, et al. Knowledge embedding 延照耀 等：面向图神经网络的知识图谱嵌入研究进展 1811
based graph convolutional network[C]//Proceedings of the edge graph[C]//Proceedings of the 13th International Con-
Web Conference 2021, Ljubljana, Apr 19-23, 2021. New ferenceonWebSearchandDataMining,Houston,Feb3-7,
York:ACM,2021:1619-1628. 2020.NewYork:ACM,2020:420-428.
[27]SHANGC,TANGY,HUANGJ,etal.End-to-endstructure- [38] NATHANI D, CHAUHAN J, SHARMAC, et al. Learning
aware convolutional networks for knowledge base comple- attention-based embeddings for relation prediction in know-
tion[C]//Proceedingsofthe33rdAAAIConferenceonArti- ledge graphs[C]//Proceedings of the 57th Annual Meeting
ficial Intelligence, the 31st InnovativeApplications ofArti- of theAssociation for Computational Linguistics, Florence,
ficial Intelligence Conference, the 9th AAAI Symposium Jul28-Aug2,2019.Stroudsburg:ACL,2019:4710-4723.
on Educational Advances in Artificial Intelligence, Honolulu, [39]CHENM,ZHANGY,KOUX,etal.r-GAT:relationalgraph
Jan27-Feb1,2019.MenloPark:AAAI,2019:3060-3067. attention network for multi-relational graphs[J]. arXiv:2109.
[28] YAN Y, LIU L, BAN Y, et al. Dynamic knowledge graph 05922,2021.
alignment[C]//Proceedings of the 35th AAAI Conference [40]GUOL,WANGW,SUNZ,etal.Decentralizedknowledge
on Artificial Intelligence, the 33rd Conference on Innova- graphrepresentationlearning[J].arXiv:2010.08114,2020.
tiveApplicationsofArtificialIntelligence,the11thSympo- [41] LIU X, TAN H, CHEN Q, et al. RAGAT: relation aware
sium on Educational Advances in Artificial Intelligence, graph attention network for knowledge graph completion
Feb2-9,2021.MenloPark:AAAI,2021:4564-4572. [J].IEEEAccess,2021,9:20840-20849.
[29] WANG Z, REN Z, HE C, et al. Robust embedding with [42] ZHANG Z, ZHUANG F, ZHU H, et al. Relational graph
multi-levelstructuresforlinkprediction[C]//Proceedingsof neural network with hierarchical attention for knowledge
the 28th InternationalJointConference onArtificialIntelli- graph completion[C]//Proceedings of the 2020AAAI Con-
gence,Macao,China,Aug10-16,2019:5240-5246. ferenceonArtificialIntelligence,NewYork,Feb7-12,2020:
[30] WANG S, WEI X, DOS SANTOS C N, et al. Mixed- 9612-9619.
curvaturemulti-relationalgraphneuralnetworkforknowledge [43] LI Z, LIU H, ZHANG Z, et al. Learning knowledge graph
graph completion[C]//Proceedings of the Web Conference embedding with heterogeneous relation attention networks
2021,Ljubljana,Apr19-23,2021:1761-1771. [J]. IEEE Transactions on Neural Networks and Learning
[31]RICHARDSONM,DOMINGOSP.Markovlogicnetworks Systems,2022,33(8):3961-3973.
[J].MachineLearning,2006,62(1):107-136. [44] ZHAO X, JIA Y, LI A, et al. Target relational attention-
[32]ZHANGY,CHENX,YANGY,etal.Efficientprobabilistic oriented knowledge graph reasoning[J]. Neurocomputing,
logic reasoning with graph neural networks[C]//Proceed- 2021,461:577-586.
ingsofthe8thInternationalConferenceonLearningRepre- [45] JI K, HUI B, LUO G. Graph attention networks with local
sentations,AddisAbaba,Apr26-30,2020:1-20. structure awareness for knowledge graph completion[J].
[33] TERU K K, DENIS E G, HAMILTON W L. Inductive IEEEAccess,2020,8:224860-224870.
relation prediction by subgraph reasoning[C]//Proceedings [46] SUN Z, WANG C, HU W, et al. Knowledge graph align-
of the 37th International Conference on Machine Learning, ment network with gated multi-hop neighborhood aggrega-
Jul13-18,2020:9448-9457. tion[C]//Proceedingsofthe34thAAAIConferenceonArti-
[34] LIU S, GRAU B, HORROCKS I, et al. INDIGO: GNN- ficialIntelligence,the32ndInnovativeApplicationsofArti-
based inductive knowledge graph completion using pair- ficial Intelligence Conference, the 10th AAAI Symposium
wise encoding[C]//Advances in Neural Information Pro- on Educational Advances in Artificial Intelligence, New
cessingSystems34,Dec6-14,2021:2034-2045. York,Feb7-12,2020.MenloPark:AAAI,2020:222-229.
[35]CAOY,LIUZ,LIC,etal.Multi-channelgraphneuralnet- [47] ZHANG Z, HUANG J,TAN Q.Association rules enhanced
work for entity alignment[C]//Proceedings of the 57th An- knowledge graph attention network[J]. Knowledge-Based
nualMeetingoftheAssociationforComputationalLinguis- Systems,2022,239:108038.
tics,Florence,Jul28-Aug2,2019.Stroudsburg:ACL,2019: [48]DAIG,WANG X,ZOU X,etal.MRGAT:multi-relational
1452-1461. graph attention network for knowledge graph completion
[36] WANG Z,YANG J,YE X. Knowledge graph alignment with [J].NeuralNetworks,2022,154:234-245.
entity-pair embedding[C]//Proceedings of the 2020 Confer- [49] BALDI P. Autoencoders, unsupervised learning, and deep
ence on Empirical Methods in Natural Language Process- architectures[C]//Proceedings of the 2011 ICMLWorkshop
ing,Nov16-20,2020.Stroudsburg:ACL,2020:1672-1680. on Unsupervised and Transfer Learning, Bellevue, Jul 2,
[37]MAOX,WANGW,XUH,etal.MRAEA:anefficientand 2011:37-50.
robust entity alignment approach for cross-lingual knowl- [50] RUMELHART D E, HINTON G E, WILLIAMS R J. 1812 JournalofFrontiersofComputerScienceandTechnology 计算机科学与探索 2023, 17(8)
Learning internal representations by error propagation[M]. [63]ZITNIKM,AGRAWALM,LESKOVECJ.Modelingpoly-
Cambridge:MITPress,1985. pharmacy side effects with graph convolutional networks
[51] KINGMA D P, WELLING M. Auto-encoding variational [J].Bioinformatics,2018,34(13):i457-i466.
Bayes[J].arXiv:1312.6114,2013. [64]CUIZ,HENRICKSONK,KER,etal.Trafficgraphconvo-
[52]TSCHANNENM,BACHEMO,LUCICM.Recentadvances lutional recurrent neural network: a deep learning frame-
in autoencoder-based representation learning[J]. arXiv:1812. work for network-scale traffic learning and forecasting[J].
05069,2018. IEEE Transactions on Intelligent Transportation Systems,
[53] SALHA G, LIMNIOS S, HENNEQUIN R, et al. Gravity- 2019,21(11):4883-4894.
inspiredgraphautoencodersfordirectedlinkprediction[C]// [65] CHEN Z, WANG Y, ZHAO B, et al. Knowledge graph
Proceedings of the 28thACM International Conference on completion: a review[J]. IEEE Access, 2020, 8: 192435-
Information and Knowledge Management, Beijing, Nov 3- 192456.
7,2019.NewYork:ACM,2019:589-598. [66] LIN Y, LIU Z, SUN M, et al. Learning entity and relation
[54] ZHANG S, ZHANG Z, ZHUANG F, et al. Compressing embeddings for knowledge graph completion[C]//BONET
knowledge graph embedding with relational graph auto- B, KOENIG S. Proceedings of the 29thAAAI Conference
encoder[C]//Proceedings of the 2020 IEEE 10th International on Artificial Intelligence, Austin, Jan 25-30, 2015. Menlo
Conference on Electronics Information and Emergency Park:AAAI,2015:2181-2187.
Communication, Beijing, Jul 17-19, 2020. Piscataway: IEEE, [67] SHEN Y, DING N, ZHENG H T, et al. Modeling relation
2020:366-370. paths for knowledge graph completion[J]. IEEE Transac-
[55] JANG E, GU S, POOLE B. Categorical reparameterization tions on Knowledge and Data Engineering, 2020, 33(11):
withgumbel-softmax[J].arXiv:1611.01144,2016. 3607-3617.
[56]YANG K.GCN-VAE forknowledgegraph completion[EB/ [68] ZHANGY, ZHENG W,WANG H, et al. Joint entity struc-
OL].[2022-09-14].http://snap.stanford.edu/class/cs224w-2019/ turalandattributeinformationforknowledgegraphcomple-
project/26425038.pdf. tion[C]//Proceedings of the 2021 International Conference
[57]HUKR,LIUH,ZHANCJ,etal.Learningknowledgegraph onHighPerformanceComputingandCommunication,Xia-
embedding with a bi-directional relation encoding network men,Dec3-5,2021:264-269.
and a convolutional autoencoder decoding network[J]. [69] JUNG J, JUNG J, KANG U. Learning to walk across time
Neural Computing and Applications, 2021, 33(17): 11157- forinterpretabletemporalknowledgegraphcompletion[C]//
11173. Proceedings of the 27th ACM SIGKDD Conference on
[58] TOUTANOVA K, CHEN D. Observed versus latent fea- Knowledge Discovery and Data Mining, New York, Aug
tures for knowledge base and text inference[C]//Proceed- 14-18,2021.NewYork:ACM,2021:786-795.
ingsofthe3rdWorkshoponContinuousVectorSpaceModels [70]GARCÍA-DURÁNA,DUMANČIĆS,NIEPERTM.Learn-
andTheirCompositionality,Beijing,Jul26-31,2015.Strouds- ing sequence encoders for temporal knowledge graph com-
burg:ACL,2015:57-66. pletion[J].arXiv:1809.03202,2018.
[59] SUN Z, HU W, LI C. Cross-lingual entity alignment via [71] REITER R. On closed world data bases[M]. San Mateo:
jointattribute-preservingembedding[C]//LNCS10587:Pro- MorganKaufmann,1981.
ceedings of the 16th International SemanticWeb Conference, [72] ILIEVSKI F, SZEKELY P, ZHANG B. CSKG: the com-
Vienna,Oct21-25,2017.Cham:Springer,2017:628-644. monsense knowledge graph[C]//LNCS 12731: Proceedings
[60]XIONGW,HOANGT,WANGWY.Deeppath:areinforce- ofthe18thInternationalConferencetheSemanticWeb,Jun
ment learning method for knowledge graph reasoning[J]. 6-10,2021.Cham:Springer,2021:680-696.
arXiv:1707.06690,2017. [73] SPEER R, CHIN J, HAVASI C. ConceptNet 5.5: an open
[61] SUCHANEK F M, KASNECI G, WEIKUM G. YAGO: a multilingual graph of general knowledge[C]//Proceedings
core of semantic knowledge[C]//Proceedings of the 16th ofthe31stAAAIConferenceonArtificialIntelligence,San
International Conference on World Wide Web, Banff, May Francisco, Feb 4-9, 2017. Menlo Park:AAAI, 2017: 4444-
8-12,2007.NewYork:ACM,2007:697-706. 4451.
[62]NIE K,ZENG K,MENG Q.Knowledge reasoning method [74] SAP M, LEBRAS R, ALLAWAY E, et al. ATOMIC: an
for military decision support knowledge graph mixing rule atlas of machine commonsense for if-then reasoning[J].
and graph neural networks learning together[C]//Proceed- arXiv:1811.00146,2018.
ings of the 2020 Chinese Automation Congress, Shanghai, [75] VRANDEČIĆ D, KRÖTZSCH M.Wikidata: a free collab-
Nov6-8,2020.Piscataway:IEEE,2020:4013-4018. orative knowledgebase[J]. Communications of the ACM, 延照耀 等：面向图神经网络的知识图谱嵌入研究进展 1813
2014,57(10):78-85. Invariantmodelsforcausaltransferlearning[J].TheJournal
[76] MILLER GA. WordNet: a lexical database for English[J]. ofMachineLearningResearch,2018,19(1):1309-1342.
CommunicationsoftheACM,1995,38(11):39-41. [90] WU Q, ZHANG H, YAN J, et al. Handling distribution
[77] SCHULER K K. VerbNet: a broad-coverage, comprehen- shifts on graphs: an invariance perspective[J]. arXiv:2202.
sive verb lexicon[D]. Philadelphia: University of Pennsyl- 02466,2022.
vania,2005. [91]ARJOVSKYM,BOTTOU L,GULRAJANII,etal.Invari-
[78] BAKER C F, FILLMORE C J, LOWE J B. The Berkeley antriskminimization[J].arXiv:1907.02893,2019.
FrameNetproject[C]//Proceedingsofthe36thAnnualMeet- [92] LI H, WANG X, ZHANG Z, et al. OOD-GNN: out-of-
ing of the Association for Computational Linguistics and distribution generalized graph neural network[J]. IEEE
17th International Conference on Computational Linguis- TransactionsonKnowledgeandDataEngineering,2023,35
tics,Montreal,1998:86-90. (7):7328-7340.
[79] KRISHNA R, ZHU Y, GROTH O, et al. Visual genome:
connecting language and vision using crowdsourced dense 延照耀（1999—），男，陕西榆林人，硕士研究
image annotations[J]. International Journal of Computer 生，主要研究方向为知识图谱、图神经网络、自
Vision,2017,123(1):32-73. 然语言处理。
[80] DENG J, DONG W, SOCHER R, et al. ImageNet: a large- YAN Zhaoyao, born in 1999, M.S. candidate.
scale hierarchical image database[C]//Proceedings of the His research interests include knowledge graphs,
2009 IEEE Conference on Computer Vision and Pattern graphneuralnetworksandnaturallanguagepro-
Recognition, Miami, Jun 20-25, 2009. Washington: IEEE cessing.
ComputerSociety,2009:248-255.
[81]YASUNAGAM, REN H, BOSSELUTA, et al. QA-GNN:
丁苍峰（1978—），男，河南唐河人，博士，副教
reasoning with language models and knowledge graphs for
授，硕士生导师，主要研究方向为多层复杂网
questionanswering[J].arXiv:2104.06378,2021.
络、图神经网络、自然语言处理。
[82] SHWARTZ V, WEST P, BRAS R L, et al. Unsupervised
DING Cangfeng, born in 1978, Ph.D., associ-
commonsense question answering with self-talk[J]. arXiv:
ate professor, M.S. supervisor. His research in-
2004.05483,2020.
terests include multilayer complex networks,
[83]BOSSELUTA,RASHKINH,SAPM,etal.COMET:com-
graphneuralnetworksandnaturallanguagepro-
monsensetransformersforautomaticknowledgegraphcon-
cessing.
struction[J].arXiv:1906.05317,2019.
[84] PALATUCCI M, POMERLEAU D, HINTON G E, et al.
马乐荣（1974—），男，陕西神木人，博士，教授，
Zero-shot learning with semantic output codes[C]//Advances
硕士生导师，主要研究方向为人工智能、大数
in Neural Information Processing Systems 22, Vancouver,
据知识工程、自然语言处理。
Dec7-10,2009:1410-1418.
MALerong,bornin1974,Ph.D.,professor,M.S.
[85] WANG X,YE Y, GUPTAA. Zero-shot recognition via se-
supervisor. His research interests include artifi-
mantic embeddings and knowledge graphs[C]//Proceedings
cial intelligence, big data knowledge engineer-
of the 2018 IEEE/CVF Conference on Computer Vision
ingandnaturallanguageprocessing.
and Pattern Recognition, Salt Lake City, Jun 18-22, 2018.
Washington:IEEEComputerSociety,2018:6857-6866.
曹璐（2001—），女，陕西咸阳人，硕士研究生，
[86] KAMPFFMEYER M, CHEN Y, LIANG X, et al. Rethink-
主要研究方向为图神经网络、自然语言处理。
ingknowledgegraphpropagationforzero-shotlearning[C]//
CAOLu,bornin2001,M.S.candidate.Herre-
Proceedings of the 2019 IEEE/CVF Conference on Com-
search interests include graph neural networks
puterVision and Pattern Recognition, Long Beach, Jun 16-
andnaturallanguageprocessing.
20,2019.Piscataway:IEEE,2019:11479-11488.
[87]NAYAKNV,BACHSH.Zero-shotlearningwithcommon
游浩（2000—），男，陕西安康人，硕士研究生，
senseknowledgegraphs[J].arXiv:2006.10713,2020.
主要研究方向为大数据知识工程。
[88] VASWANIA, SHAZEER N, PARMAR N, et al.Attention
YOUHao,bornin2000,M.S.candidate.Hisre-
isallyouneed[C]//AdvancesinNeuralInformationProcess-
searchinterestisbigdataknowledgeengineering.
ingSystems30,LongBeach,Dec4-9,2017:5998-6008.
[89]ROJAS-CARULLAM,SCHÖLKOPFB,TURNERR,etal. --------------------------------------------------------------------------------- 计算机研究与发展 ＤＯＩ：１０．７５４４?ｉｓｓｎ１０００－１２３９．２０１６．２０１５０６８９
Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｒｅｓｅａｒｃｈ ａｎｄ Ｄｅｖｅｌｏｐｍｅｎｔ ５３（１）：１１３－１２２，２０１６
面向智能交互的图像识别技术综述与展望
蒋树强 闵巍庆 王树徽
（中国科学院智能信息处理重点实验室（中国科学院计算技术研究所） 北京 １００１９０）
（ｓｑｊｉａｎｇ＠ｉｃｔ．ａｃ．ｃｎ）
Ｓｕｒｖｅｙ ａｎｄ Ｐｒｏｓｐｅｃｔ ｏｆ Ｉｎｔｅｌｌｉｇｅｎｔ Ｉｎｔｅｒａｃｔｉｏｎ－Ｏｒｉｅｎｔｅｄ Ｉｍａｇｅ Ｒｅｃｏｇｎｉｔｉｏｎ Ｔｅｃｈｎｉｑｕｅｓ
Ｊｉａｎｇ Ｓｈｕｑｉａｎｇ，Ｍｉｎ Ｗｅｉｑｉｎｇ，ａｎｄ Ｗａｎｇ Ｓｈｕｈｕｉ
（Ｋｅｙ Ｌａｂｏｒａｔｏｒｙ ｏｆ Ｉｎｔｅｌｌｉｇｅｎｔ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ （Ｉｎｓｔｉｔｕｔｅ ｏｆ Ｃｏｍｐｕｔｉｎｇ Ｔｅｃｈｎｏｌｏｇｙ，Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ ｏｆ
Ｓｃｉｅｎｃｅｓ），Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ，Ｂｅｉｊｉｎｇ１００１９０）
Ａｂｓｔｒａｃｔ Ｖｉｓｉｏｎ ｐｌａｙｓ ａｎ ｉｍｐｏｒｔａｎｔ ｒｏｌｅ ｉｎ ｂｏｔｈ ｔｈｅ ｈｕｍａｎ ｉｎｔｅｒａｃｔｉｏｎ ａｎｄ ｈｕｍａｎ－ｎａｔｕｒｅ ｉｎｔｅｒａｃｔｉｏｎ．
Ｆｕｒｔｈｅｒｍｏｒｅ，ｅｑｕｉｐｐｉｎｇ ｔｈｅ ｔｅｒｍｉｎａｌｓ ｗｉｔｈ ｔｈｅ ｉｎｔｅｌｌｉｇｅｎｔ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｉｎｔｅｒａｃｔｉｏｎ ｉｓ ｏｎｅ ｏｆ
ｔｈｅ ｃｏｒｅ ｃｈａｌｌｅｎｇｅｓ ｉｎ ａｒｔｉｆｉｃｉａｌ ｉｎｔｅｌｌｉｇｅｎｃｅ ａｎｄ ｃｏｍｐｕｔｅｒ ｔｅｃｈｎｏｌｏｇｙ，ａｎｄ ａｌｓｏ ｏｎｅ ｏｆ ｌｏｆｔｙ ｇｏａｌｓ．Ｗｉｔｈ
ｔｈｅ ｒａｐｉｄ ｄｅｖｅｌｏｐｍｅｎｔ ｏｆ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ ｔｅｃｈｎｉｑｕｅｓ，ｉｎ ｒｅｃｅｎｔ ｙｅａｒｓ ｔｈｅ ｅｍｅｒｇｉｎｇ ｎｅｗ ｔｅｃｈｎｉｑｕｅｓ
ａｎｄ ｐｒｏｂｌｅｍｓ ｈａｖｅ ｂｅｅｎ ｐｒｏｄｕｃｅｄ．Ｃｏｒｒｅｓｐｏｎｄｉｎｇｌｙ，ｔｈｅ ａｐｐｌｉｃａｔｉｏｎｓ ｗｉｔｈ ｔｈｅ ｉｎｔｅｌｌｉｇｅｎｔ ｉｎｔｅｒａｃｔｉｏｎ
ａｌｓｏ ｐｒｅｓｅｎｔ ａ ｆｅｗ ｎｅｗ ｃｈａｒａｃｔｅｒｉｓｔｉｃｓ，ｗｈｉｃｈ ａｒｅ ｃｈａｎｇｉｎｇ ｏｕｒ ｏｒｉｇｉｎａｌ ｕｎｄｅｒｓｔａｎｄｉｎｇ ｏｆ ｔｈｅ ｖｉｓｕａｌ
ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｉｎｔｅｒａｃｔｉｏｎ．Ｗｅ ｇｉｖｅ ａ ｓｕｒｖｅｙ ｏｎ ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ ｔｅｃｈｎｉｑｕｅｓ，ｃｏｖｅｒｉｎｇ ｒｅｃｅｎｔ
ａｄｖａｎｃｅｓ ｉｎ ｒｅｇａｒｄｉｎｇ ｔｏ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ，ｖｉｓｕａｌ ｄｅｓｃｒｉｐｔｉｏｎ，ｖｉｓｕａｌ ｑｕｅｓｔｉｏｎ ａｎｄ ａｎｓｗｅｒｉｎｇ（ＶＱＡ）．
Ｓｐｅｃｉｆｉｃａｌｌｙ，ｗｅ ｆｉｒｓｔ ｆｏｃｕｓ ｏｎ ｔｈｅ ｄｅｅｐ ｌｅａｒｎｉｎｇ ａｐｐｒｏａｃｈｅｓ ｆｏｒ ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｓｃｅｎｅ
ｃｌａｓｓｉｆｉｃａｔｉｏｎ．Ｎｅｘｔ，ｔｈｅ ｌａｔｅｓｔ ｔｅｃｈｎｉｑｕｅｓ ｉｎ ｖｉｓｕａｌ ｄｅｓｃｒｉｐｔｉｏｎ ａｎｄ ＶＱＡ ａｒｅ ａｎａｌｙｚｅｄ ａｎｄ ｄｉｓｃｕｓｓｅｄ．
Ｔｈｅｎ ｗｅ ｉｎｔｒｏｄｕｃｅ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｉｎｔｅｒａｃｔｉｏｎ ａｐｐｌｉｃａｔｉｏｎｓ ｉｎ ｍｏｂｉｌｅ ｄｅｖｉｃｅｓ ａｎｄ ｒｏｂｏｔｓ．
Ｆｉｎａｌｌｙ，ｗｅ ｄｉｓｃｕｓｓ ｆｕｔｕｒｅ ｒｅｓｅａｒｃｈ ｄｉｒｅｃｔｉｏｎｓ ｉｎ ｔｈｉｓ ｆｉｅｌｄ．
Ｋｅｙ ｗｏｒｄｓ ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ；ｉｎｔｅｌｌｉｇｅｎｔ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ；ｉｎｔｅｌｌｉｇｅｎｔ ｉｎｔｅｒａｃｔｉｏｎ；ｖｉｓｕａｌ ｄｅｓｃｒｉｐｔｉｏｎ；
ｖｉｓｕａｌ ｑｕｅｓｔｉｏｎ ａｎｄ ａｎｓｗｅｒｉｎｇ（ＶＱＡ）；ｄｅｅｐ ｌｅａｒｎｉｎｇ
摘 要 视觉在人与人交互以及人与自然界的交互过程中起到非常重要的作用，让终端设备具有智能的
视觉识别和交互能力是人工智能和计算机技术的核心挑战和远大目标之一．可以看到，近年来视觉识别
技术发展飞速，新的创新技术不断涌现，新的研究问题不断被提出，面向智能交互的应用呈现出一些新
的动态，正在不断刷新人们对此领域的原有认识．从视觉识别、视觉描述和视觉问答３个角度对图像识
别技术进行综述，对基于深度学习的图像识别以及场景分类技术进行了具体介绍，对视觉描述和问答技
术的最新技术进行了分析和讨论，同时对面向移动终端和机器人的视觉识别和交互应用进行了介绍，最
后对该领域的未来研究趋势进行了分析．
收稿日期：２０１５－０７－２６；修回日期：２０１５－１０－２０
基金项目：国家自然科学基金重点项目（６１５３２０１８）；国家自然科学基金优秀青年科学基金项目（６１３２２２１２）；国家自然科学基金青年科学基金
项目（６１３０３１６０）；国家“九七三”重点基础研究发展计划基金项目（２０１２ＣＢ３１６４００）
Ｔｈｉｓ ｗｏｒｋ ｗａｓ ｓｕｐｐｏｒｔｅｄ ｂｙ ｔｈｅ Ｎａｔｉｏｎａｌ Ｋｅｙ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｃｈｉｎａ（６１５３２０１８），ｔｈｅ Ｎａｔｉｏｎａｌ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ
Ｆｏｕｎｄａｔｉｏｎ ｆｏｒ Ｅｘｃｅｌｌｅｎｔ Ｙｏｕｎｇ Ｓｃｈｏｌａｒｓ ｏｆ Ｃｈｉｎａ（６１３２２２１２），ｔｈｅ Ｎａｔｉｏｎａｌ Ｎａｔｕｒａｌ Ｓｃｉｅｎｃｅ Ｆｏｕｎｄａｔｉｏｎ ｏｆ Ｃｈｉｎａ Ｙｏｕｎｇ Ｓｃｉｅｎｔｉｓｔｓ
Ｆｕｎｄ（６１３０３１６０），ａｎｄ ｔｈｅ Ｎａｔｉｏｎａｌ Ｂａｓｉｃ Ｒｅｓｅａｒｃｈ Ｐｒｏｇｒａｍ ｏｆ Ｃｈｉｎａ（９７３Ｐｒｏｇｒａｍ）（２０１２ＣＢ３１６４００）．
书书书 １１４ 计算机研究与发展 ２０１６，５３（１）
关键词 图像识别；智能的视觉识别；智能交互；视觉描述；视觉问答；深度学习
中图法分类号 ＴＰ３９１
人类得以在自然界中长期生存，一个重要的原 场景．随着技术发展，一些面向智能交互与服务的应
因就是拥有迅速认识并理解其所处环境的能力，而 用模式也逐渐引起了研究者的关注，这也进一步促
这其中的关键环节是利用人类视觉系统完成对目标 进了图像识别技术的发展．
的定位与识别，同时实现视觉场景的理解与描述．如 本文将对图像识别与应用技术的最新进展进行
果计算机能够实现自动的图像识别，必将进一步丰 介绍．在方法上，将首先对基于深度学习的图像识别
富与方便人类生活，这促使图像识别技术成为当前 技术进展进行讨论，主要从物体识别和场景识别２
人工智能领域内重要的研究方向之一．图像识别是 个角度探讨相关技术的特点．ＩｍａｇｅＮｅｔ是最新的常
指利用计算机视觉、模式识别、机器学习等技术方 用数据集，主要是物体概念的图像，也包括少量场景
法，自动识别图像中存在的一个或多个语义概念，广 概念的图像，该数据集是当前不同深度学习模型的
义的图像识别还包括对识别的概念进行图像区域定 训练数据来源，也是算法性能的主要测试场地；而随
位等．图像识别技术可以满足用户在不同场景下的 着ＳＵＮ３９７，Ｐｌａｃｅｓ等大规模场景数据集的出现和
视觉应用需求，主要包括面向互联网的图像检索与 普及，场景分类技术成为当前图像识别的重要研究
挖掘、面向移动设备和机器人等智能终端的人机对 问题，在分类方法和模型训练上都有新的推进，本文
话与信息服务等． 也将进行介绍．此外，我们对近一两年来研究颇多的
最早的图像识别技术可以追溯到２０世纪６０年 图像描述与问答技术也进行介绍，这是最新研究方
代［１］，自２０世纪９０年代以来，随着计算机的处理能 向．在面向视觉交互的图像识别应用上，将主要对面
力越来越强，图像识别技术得到了很大的进步与发 向移动终端与面向机器人的视觉识别技术进行讨
展．从最早的数字识别、手写文字识别逐渐发展到人 论，同时对基于图像理解的智能交互的不同应用模
脸识别、物体识别、场景识别、属性识别、精细目标识 式进行分析．在本文的最后，将对未来的研究趋势进
别等，所采用的技术也从最早的模板匹配、线性分类 行展望和讨论．
到现在所广泛使用的深层神经网络与支持向量机分
类的方法．特别是进入２１世纪１０年代以来，随着计 １ 基于深度学习的图像识别技术
算能力的大幅度提升、新的计算方法的不断提出、可
利用的数据资源的大规模增长、新型应用模式不断 自从Ｋｒｉｚｈｅｖｓｋｙ等人［５］在ＩｍａｇｅＮｅｔ上训练一
涌现，图像识别及其应用技术无论在研究的广度和 个８层的深度模型并在ＩｍａｇｅＮｅｔ竞赛上取得非常
深度上、在识别效果的性能上、在技术及应用的扩展 好的效果后，卷积神经网络（ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ
上，都呈现出新的趋势．其中有４个特点比较突出： ｎｅｔｗｏｒｋ，ＣＮＮ）在图像分类与识别领域受到了广泛
１）图像的特征表示已经从传统的手工设定演变为如 关注，取得了巨大成功．之后，在很多图像识别的应
今的自动学习方法，这主要得益于深度神经网络技 用场景中，卷积神经网络也都取得了很大的性能改
术的广泛应用；２）图像识别的概念已由早期个别概 进．卷积神经网络能够逐层学习图像的特征，其中低
念（如特定概念、十几个概念的识别）转变为成百上 层是具有普遍性的（ｇｅｎｅｒａｌ）特征，如图像的边缘、
千的概念，这主要是由于大规模图像数据集的发展 角点、纹理等；高层特征是低层特征的组合，是针对
所推动的，如ＩｍａｇｅＮｅｔ［２］，Ｐｌａｃｅｓ［３］，ＳＵＮ３９７［４］等； 特定任务的有针对性的（ｓｐｅｃｉｆｉｃ）特征［６－７］．逐层特
３）图像识别技术正在和自然语言理解技术进行融 征学习模拟了人脑分层处理信息机制，能够直接从
合，形成了图像描述技术，有别于图像识别只是对图 原始像素得到图像特征．将卷积神经网络用于图像
像进行个别概念的标注，图像描述可以自动对一副 识别与分类，可以归纳为３种途径：
图像进行一句话或一小段话的描述，从而可以更全 １）直接在待分类的数据集上训练一个深层的网
面地描述图像内容；４）在应用模式上，传统的图像识 络．随着ＣＮＮ深度和宽度的增加，ＣＮＮ的分类性能
别技术或者是为了服务于监控、检索等特定的应用 有着明显的提升．Ｓｉｍｏｎｙａｎ等人［８］提出了一个１９层
场景，或只是为了突破计算机视觉的挑战性问题，在 的ＣＮＮ模型（ＶＧＧ－１９），该模型在原来Ｋｒｉｚｈｅｖｓｋｙ［５］
技术研究时并未过多考虑全面图像识别技术的应用 提出的模型的基础上通过增加卷积层来增加该模型 蒋树强等：面向智能交互的图像识别技术综述与展望 １１５
的深度，由于在所有的层上采用比较小的卷积滤波 如表２所示，ＧｏｏｇＬｅＮｅｔ由于采用最多的２２层网
核（３×３），因而可在实践中实现．相比之下，Ｓｚｅｇｅｄｙ 络而达到最好的测试性能；ＶＧＧ采用１９层网络紧
等人［９］基于 Ｈｅｂｂｉａｎ原理和多尺度处理的启发提 随其后；相比于增加深度学习模型的层数，ＳＰＰＮｅｔ［１８］
出了一个２２层的深度学习模型 ＧｏｏｇＬｅＮｅｔ［９］，它 网络通过将空间金字塔模型引入到深度学习模型
是由多个Ｉｎｃｅｐｔｉｏｎ Ｍｏｄｅｌ堆叠而成．该模块中，利 中，消除了输入图像尺寸的限制，在网络层数最多只
用不同带宽的卷积核对前一层的输出做卷积，最后 有７层的条件下组合多个深度学习模型，达到了第
合并形成后一层的输入．不同尺寸大小的卷积核能 ３名的测试结果．从表２我们可以看出，这些深度学
够捕获多尺度的视觉特征，这些特征的融合能够使 习模型的架构基本没有什么变化，可以通过１）增加
整个网络更好地适应图像物体的表观多尺度特性． 网络层数学习更为抽象的表示；２）消除深度学习中
另外针对不同的分类任务，如场景分类和物体分类 的某些限制或者瓶颈，比如输入图像尺寸的限制等
等，不同数据集上训练的模型也有不同的特性，例如 途径继续通过深度学习模型提高识别性能．
Ｚｈｏｕ等人在Ｐｌａｃｅｓ［３］上训练的深度模型，对于场景
Ｔａｂｌｅ １ Ｏｂｊｅｃｔ Ｃｌａｓｓｉｆｉｃａｔｉｏｎ Ａｃｃｕｒａｃｙ ｏｎ Ｄｉｆｆｅｒｅｎｔ Ｄａｔａｓｅｔｓ
的分类有非常好的效果．
表１ 不同数据集的物体分类准确率
２）在训练好的网络上直接提取特征．训练好的
Ｔｏｔａｌ Ｂｅｓｔ Ａｃｃｕｒａｃｙ
Ｄａｔａｓｅｔｓ Ｃｌａｓｓｅｓ
ＣＮＮ模型可以直接用来当特征提取器，提取的特征 Ｓａｍｐｌｅｓ Ｍｅｔｈｏｄｓ ?％
可以用做其它的后续操作．Ｄｏｎａｈｕｅ等人［１０］利用 Ｃａｌｔｅｃｈ１０１ １０１ ９ １４４ ＳＰＰＮｅｔ ９３．４２
Ｋｒｉｚｈｅｖｓｋｙ提出的模型将ＣＮＮ的全连接层的特征 Ｃａｌｔｅｃｈ２５６ ２５６ ３０ ６０７ ＣＮＮ－Ｓ ７７．６１
与ＳＶＭ分类器结合，在多个数据集上取得了很好 ＶＯＣ２００７ ２０ ９ ９６３ ＨＣＰ［１９］ ８５．２０
的分类效果，这表明ＣＮＮ的高层全连接层的特征 ＩｍａｇｅＮｅｔ １０ ０００ １ ２８１ １６７ ＧｏｏｇＬｅＮｅｔ ９３．３３
可以作为通用的视觉特征．相比之下，Ｌｉｕ等人［１１］采
Ｔａｂｌｅ ２ Ｒｅｓｕｌｔｓ ｏｆ ＩＬＳＶＲＣ ２０１４Ｃｌａｓｓｉｆｉｃａｔｉｏｎ［１８］
用跨卷积层池化技术将卷积层的特征作为通用特征
表２ 不同深度学习模型在ＩＬＳＶＲＣ ２０１４的物体分类结果［１８］
在ＭＩＴ－６７等数据库上取得了更好的分类效果．Ｇｏｎｇ
Ｒａｎｋ Ｍｅｔｈｏｄｓ Ｔｏｐ－５Ｔｅｓｔ
等人［１２］在多个尺度下基于图像块提取ＣＮＮ特征，
１ ＧｏｏｇＬｅＮｅｔ ６．６６
然后通过主成分分析（ｐｒｉｎｃｉｐａｌ ｃｏｍｐｏｎｅｎｔ ａｎａｌｙｓｉｓ，
２ ＶＧＧ ７．３２
ＰＣＡ）降维以及局部聚合的描述子向量（ｖｅｃｔｏｒ ｏｆ
３ ＳＰＰＮｅｔ ８．０６
ｌｏｃａｌｌｙ ａｇｇｒｅｇａｔｅｄ ｄｅｓｃｒｉｐｔｏｒｓ，ＶＬＡＤ）［１３］编码等
４ Ｈｏｗａｒｄ ８．１１
形成图像的特征．相比于直接从整幅图片上提取
５ ＤｅｅｐｅｒＶｉｓｉｏｎ ９．５０
ＣＮＮ特征，该方法提取的特征具有几何不变性．Ｌｉ
６ ＮＵＳ－ＢＳＴ ９．７９
等人［１４］更进一步在提取图像的多个块级特征的基
７ ＴＴＩＣ ＥＣＰ １０．２２
础上，通过关联规则来发现隐藏在这些特征之间的
模式，从而实现图像的分类和识别．
３）在目标数据集上对现有深度模型进行“精细 ２ 场景分类技术
化”调整（ｆｉｎｅ－ｔｕｎｉｎｇ）．在特定数据集上训练好的模
型有很强的泛化性能，但是ｆｉｎｅ－ｔｕｎｉｎｇ能够进一步 场景分类技术一般分为２步：１）提取图像的中
提升分类性能［１５］．ｆｉｎｅ－ｔｕｎｉｎｇ是在目标数据集上重 层特征描述；２）基于中层特征描述训练分类器，并进
新调整网络参数，从而使深度模型能够捕获针对目 行场景分类．近１０年来，场景分类技术的发展主要
标任务更具有区分性的特征［１６－１７］． 体现在中层特征描述能力的不断增强．典型的中层
表１给出了基于ＣＮＮ的分类方法在不同的数 描述特征为词袋（ｂａｇ－ｏｆ－ｗｏｒｄ）［２０］，该方法利用聚类
据集上最好的分类准确率．从Ｋｒｉｚｈｅｖｓｋｙ等人的８层 得到视觉特征码书，根据码书进行编码，得到词袋特
的ＣＮＮ－Ｓ［５］网络到 Ｓｉｍｏｎｙａｎ等人的２２层网络 征，进而用ＳＶＭ 进行分类．Ｌｉ等人［２１］提出了一种
ＧｏｏｇＬｅＮｅｔ［９］，随着网络层次的增加，ＣＮＮ的性能 基于物体描述的中层特征，预先学习物体检测器，检
有很大提升．表２给出了２０１４年ＩｍａｇｅＮｅｔ大规模 测器的响应即为其物体描述特征．Ｒａｓｉｗａｓｉａ等人［２２］
视觉识别挑战（ＩＬＳＶＲＣ ２０１４）［２，１８］的排名前７的结 利用场景类别概率分布作为中层描述，对每一场景
果，这些团队均是采用深度学习模型得到测试结果． 类别学习狄利克雷混合模型，以预测未知图像属于 １１６ 计算机研究与发展 ２０１６，５３（１）
该场景类别的概率，所有场景类别概率的分布即为 注竞赛中，来自微软［２６－２７］、谷歌［２８］、蒙特利尔大学、
该图像的中层特征描述．具体来说，对于每一个在语 多伦多大学［２９］和加州大学伯克利分校［３０－３１］等研究
义空间中的每个场景类别通过如下狄利克雷混合分 机构的最新工作在人工测评和图灵测试方面都取得
布表示： 了令人惊叹的成绩．谷歌（基于ＣＮＮ视觉特征和
Ｐ Π｜Ｙ（π｜ｙ；Λｙ）＝ ∑βｋｙＤｉｒ（π；α ｋｙ）． （１） ＲＮＮ（ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ）语言模型）和微软
ｋ （基于区域的单词检测和最大熵语言模型）目前在技
这里模型参数为Λｙ＝｛ βｋｙ，α ｋｙ｝，Ｄｉｒ（π；α）参数
术和性能方面处于领先地位．
为α＝｛α，α，…，α｝．该工作仅仅考虑全局的共生
１ ２ Ｌ 目前，在目标描述这一方面的解决方案主要都
模式，为了改进图像的特征表示能力，Ｓｏｎｇ等人［２３］
是根据通过编码－解码（ｅｎｃｏｄｅｒ－ｄｅｃｏｄｅｒ）的想法而
利用局部空间和多特征上下文信息优化了文献［２２］
来，最有代表性的方法有２种：
的中层描述，增强了特征描述能力．相比于以上方
１）类似于Ｆａｎｇ等人［２６］使用的流程化方法：
法，当前最有效的场景分类方法是深度学习方法，即
根据图片得到单词，再将单词组合为句子，最后对
训练ＣＮＮ，利用末层决策层分类．ＣＮＮ虽不同于传
句子进行打分．Ｆａｎｇ等人［２６］首先利用多示例学习
统２步分类框架，并没有明显的中层特征描述，但网
（ＭＩＬ）方法，根据图片的各个部分产生相对应的名
络的中间层结果也可被认为是一种中层特征描述，
词、动词和形容词；接下来，使用最大熵语言模型
且也可结合ＳＶＭ分类器用以分类．近两年ＣＮＮ的
（ＭＥＬＭ）产生包含提取词的句子；最后，使用最小
发展主要体现在２方面：１）更深层的网络，如ＶＧＧ－
错误率训练（ＭＥＲＴ）对所产生的所有句子进行打分
ＮＥＴ［８］和ＧｏｏｇＬｅＮｅｔ；２）更丰富的训练图像数据，
并排序．
如Ｐｌａｃｅｓ．随着网络深度的增加，识别正确率也大幅
２）类似于Ｖｉｎｙａｌｓ等人［２８］和Ｋａｒｐａｔｈｙ等人［３０］
度提升；同时由于数据集的丰富，训练集能涵盖更多
使用的端到端（ｅｎｄ－ｔｏ－ｅｎｄ）方法：受机器翻译技术的
场景类别，场景分类技术已能看到实际应用的曙光．
启发，将图片整体转化为特征，再将特征转化为一个
例如，麻省理工学院目前发布的关于场景识别的演
完整的句子．Ｋａｒｐａｔｈｙ等人［３０］利用ＣＮＮ模型将图
示［２４］已能达到正确识别大部分室内外和自然场景
片整体转化为一个特征，再利用ＲＮＮ模型根据已
的效果．表３给出了当前最好的不同场景数据集下
产生的单词预测句子中的下一个单词，最终生成一
的分类性能．
个完整的描述．
Ｔａｂｌｅ ３ Ｓｃｅｎｅ Ｃｌａｓｓｉｆｉｃａｔｉｏｎ Ａｃｃｕｒａｃｙ ｏｎ Ｄｉｆｆｅｒｅｎｔ Ｄａｔａｓｅｔｓ 对于整体流程中各个步骤的研究也有许多进
表３ 不同数据集的场景分类性能 展，比如对于流程化方法：Ｋｉｒｏｓ等人［３４］提出的ＳＣ－
Ｄａｔａｓｅｔｓ Ｃｌａｓｓｅｓ Ｔｏｔａｌ Ｂｅｓｔ Ａｃｃｕｒａｃｙ ＮＬＭ（ｓｔｒｕｃｔｕｒｅ－ｃｏｎｔｅｎｔ ｎｅｕｒａｌ ｌａｎｇｕａｇｅ ｍｏｄｅｌ），
Ｓａｍｐｌｅｓ Ｍｅｔｈｏｄｓ ?％
它与其他模型的不同之处在于它根据已生成的单
Ｓｃｅｎｅ１５ １５ ４ ４８５ ＣＮＮ－Ｐｌａｃｅｓ［３］ ９０．２
词预测的并不是下一个单词而是接下来的句子结
ＭＩＴ６７ ６７ １ ５２０ ＣＮＮ＋Ｆｉｓｈｅｒ［２５］ ７９．２
构．对于端到端方法，Ｍａｏ等人［３５］提出的 ｍ－ＲＮＮ
ＳＵＮ３９７ ３９７ １０８ ７６２ ＣＮＮ＋Ｆｉｓｈｅｒ［２５］ ６１．７
（ｍｕｌｔｉｍｏｄａｌ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ）模型，它
Ｐｌａｃｅｓ ２０５ ２ ４４８ ８７３ ＣＮＮ－Ｐｌａｃｅｓ［３］ ６６．２
通过一个 ｍｕｌｔｉｍｏｄａｌ的部分将ＣＮＮ 和ＬＭ 联系
起来．Ｄｏｎａｈｕｅ等人［３１］提出的 ＬＲＣＮｓ（ｌｏｎｇ－ｔｅｒｍ
３ 图像描述技术 ｒｅｃｕｒｒｅｎｔ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ）模型可以在可变
长度的输入和可变长度的输出之间直接建立映射
通过目标检测和分类技术，可以将图片中用户 关系．这与Ｃｈｅｎ等人［３６］在图片和描述映射关系方
感兴趣的部分从复杂的背景中分离出来并对其进行 面提出的方法有类似之处，该方法并未将图片和描
分类．在此基础上，通过目标描述技术，我们可以使 述映射到同一空间，而是在图片和描述之间直接建
用更加丰富的信息来产生更进一步的结果：自动产 立双向映射关系．最近，Ｊｉａ等人［３７］则是采用ｇＬＳＴＭ
生自然语言来对视觉目标进行描述． （ｇｕｉｄｉｎｇ ｌｏｎｇ－ｓｈｏｒｔ ｔｅｒｍ ｍｅｍｏｒｙ）模型，如图１所
随着计算机视觉和自然语言理解领域相关技术 示，在ＬＳＴＭ 模型［２８］的基础上引入外部的语义信
的突破，图片描述［２６－３３］技术是在２０１４—２０１５年获得 息生成图像标题．具体来说，ｇＬＳＴＭ 块的内存细胞
了突飞猛进的发展．在２０１５年微软ＣＯＣＯ图片标 和门定义为 蒋树强等：面向智能交互的图像识别技术综述与展望 １１７
ｉ′＝σ（Ｗｘ ＋Ｗ ｍ ＋Ｗｇ）， （２） 景是视觉问答，这也是近期受研究者关注的一个新
ｌ ｉｘ ｌ ｉｍ ｌ－１ ｉｑ
ｆ′＝σ（Ｗ ｘ ＋Ｗ ｍ ＋Ｗ ｇ）， （３） 方向．该技术将自然语言理解与视觉内容描述相结
ｌ ｆｘ ｌ ｆｍ ｌ－１ ｆｑ
ｏ′＝σ（Ｗ ｘ ＋Ｗ ｍ ＋Ｗｇ）， （４） 合，可以根据当前图像内容与用户问题产生出相应
ｌ ｏｘ ｌ ｏｍ ｌ－１ ｏｑ
ｃ′＝ｆ′⊙ｃ′ ＋ｉ′⊙ 的回答．针对当前的视觉问答主要有推理和端到端
ｌ ｌ ｌ－１ ｌ
ｈ（Ｗ ｘ ＋Ｗ ｍ ＋Ｗｇ）， （５） 的深度学习２种方法．
ｃｘ ｌ ｃｍ ｌ－１ ｃｑ
ｍ ＝ｏ′ｃ′， （６） 推理方法比较有代表性的是 Ｍａｌｉｎｏｗｓｋｉ等
ｌ ｌｌ
其中，⊙表示逐项相乘；σ（·）表示Ｓ形函数；ｈ（·）表
人［３９］提出的使用基于不确定输入的多世界（ｍｕｌｔｉ－
示双曲正切函数；ｉ′，ｆ′，ｏ′，ｃ′和ｍ′分别表示输入
ｗｏｒｌｄ）方法实现对于真实世界的场景问答：该方法
ｌ ｌ ｌ ｌ ｌ
门、遗忘门、ＬＳＴＭ细胞的输出门、内存单元细胞的 使用带有深度信息的数据集ＮＶＵ－Ｄｅｐｔｈ Ｖ２ｄａｔａｓｅｔ，
对于场景使用语义分割算法［４０］构建世界并且收集
状态门和隐状态；ｘ 表示在时间ｌ的序列元素；
ｌ
关于物体的识别信息，例如物体类别、３Ｄ位置和颜
Ｗ ［·］［·］代表模型参数；ｇ为引入的语义信息．相比于
色；然后利用对于一个场景的多种ｗｏｒｌｄ解释，这里
标准的ＬＳＴＭ架构，ｇＬＳＴＭ引入了新的语义项，该
的ｗｏｒｌｄ解释是由语义分割产生；最后通过概率模
项成为连接视觉和文本域的桥梁．
型来得到最大后验概率的答案．
端到端的深度学习方法主要输入为自由形式的
问题文本．答案的输出主要分为：１）Ｍａｌｉｎｏｗｓｋｉ等
人［４１］和Ｇａｏ等人［４２］基于ＲＮＮ框架，可以产生自由
形式答案；２）Ｇｅｍａｎ等人［４３］和 Ｍａ等人［４４］提出的基
于分类方式产生答案框架．Ｇａｏ等人［４２］采用ｌｏｎｇ－
ｓｈｏｒｔ ｔｅｒｍ ｍｅｍｏｒｙ（ＬＳＴＭ）抽取输入问题的表示，
同时利用 ＣＮＮ 抽取视觉图像表示，再利用一个
ＬＳＴＭ存储答案中的语言环境信息，最后利用一个
融合组件将３种成分进行融合产生答案．Ｍａ等
Ｆｉｇ．１ Ｉｍａｇｅ ｃａｐｔｉｏｎ ｇｅｎｅｒａｔｉｏｎ ｕｓｉｎｇ ＬＳＴＭ ａｎｄ ｔｈｅ 人［４４］对输入问题使用ＣＮＮ生成输入问题表示，同
ｐｒｏｐｏｓｅｄ ｇＬＳＴＭ［３７］． 时利用ＣＮＮ生成图像的视觉表示并使用映射矩阵
图１ 用ＬＳＴＭ和ｇＬＳＴＭ生成图像标题［３７］ 将其映射到与问题表示相同的向量长度，最后将２
表４给出了不同方法在生成图像标题性能的结
个表示向量进行混合后再次使用卷积与ｓｏｆｔｍａｘ进
果，评价指标采用了ＢＬＥＵ量度［３８］．从表４中我们 行分类输出对应的答案，如图２所示：
看到最新的方法Ｈａｒｄ－Ａｔｔｅｎｔｉｏｎ和ｇＬＳＴＭ达到最
好的性能．
Ｔａｂｌｅ ４ Ｃｏｍｐａｒｉｓｏｎ ｏｆ Ｄｉｆｆｅｒｅｎｔ Ｍｅｔｈｏｄｓ ｏｎ ＭＳ ＣＯＣＯ
表４ 不同图像标题生成模型在ＭＳ ＣＯＣＯ的性能比较
Ｍｅｔｈｏｄｓ Ｂ＠１ Ｂ＠２ Ｂ＠３ Ｂ＠４
Ｍｕｌｔｉｍｏｄａｌ ＲＮＮ［３０］ ６２．５ ４５．０ ３２．１ ２３．０
Ｇｏｏｇｌｅ ＮＩＣ［２８］ ６６．６ ４６．１ ３２．９ ２４．６
ＬＲＣＮ－ＣａｆｆｅＮｅｔ［３１］ ６２．８ ４４．２ ３０．４
ｍ＿ＲＮＮ［３８］ ６７．０ ４９．０ ３５．０ ２５．０
Ｓｏｆｔ－Ａｔｔｅｎｔｉｏｎ［２９］ ７０．７ ４９．２ ３４．４ ２４．３
Ｈａｒｄ－Ａｔｔｅｎｔｉｏｎ［２９］ ７１．８ ５０．４ ３５．７ ２５．０
Ｆｉｇ．２ Ｔｈｅ ｐｒｏｐｏｓｅｄ ＣＮＮ ｍｏｄｅｌ ｆｏｒ ｉｍａｇｅ ＱＡ［４４］．
ｇＬＳＴＭ ６７．０ ４９．１ ３５．８ ２６．４
图２ 提出的图像问答的ＣＮＮ模型［４４］
目前针对视觉问答的工作还不多，但是已经可
４ 视觉问答技术 以看到深度学习在这个领域中已经有了比较好的表
现．这主要得益于目前深度学习在视觉表示和自然
基于图像内容识别与分类的另一个新的应用场 语言理解等领域都有了长足的发展． １１８ 计算机研究与发展 ２０１６，５３（１）
ＤＮＮ［５］等应用到基于移动端的人脸识别、鞋识别和
５ 面向移动终端的视觉识别技术 检索等视觉任务中．
近些年来移动设备（如手机、平板）越来越普及， ６ 面向机器人的视觉识别技术
这些设备大多装配有摄像头和图形芯片，此外还有
ＧＰＳ和无线联网等功能．这些都促使移动端的视 视觉识别技术在机器人的领域也扮演着举足轻
觉识别应用越来越多，常见的包括地标建筑物识 重的角色．作为机器人感知外界环境信息的一个重
别［４５－４６］、商品识别［４７－４８］、食品识别［４９－５０］、艺术品识 要输入渠道，其对于机器人理解周围场景和辅助完
别［５１］等，上线的ＡＰＰ如Ｇｏｇｇｌｅｓ［５２］等． 成特定任务具有至关重要的作用．目前视觉识别技
由于面向移动端，一些方法关注移动设备资源 术在机器人领域的应用主要有环境理解［５９－６２］、自学
的合理利用，如提高传输速度、减小内存开销等． 习物体识别［６３－６４］和智能交互［６３］、导航与避障［６５］等．
Ｔｓａｉ等人［４７］提取低码率的ＣＨｏＧ特征［５３］，并利用 面向机器人的视觉识别技术不同于其他单纯的
了位置直方图编码对特征描述子的位置进行压缩， 视觉识别方法，其具有一定的交互能力（语言、动作
最后用几何验证的方法对检索结果进行重排序．Ｈｅ 等）和多感知能力（深度信息感器、定位装置等），对
等人［４８］将图像的局部特征编码到位数较少的哈希 于机器人的视觉能力可以具有一定的辅助作用．从
码，而非对视觉单词（ＶＷ）进行量化，从而将图像表 机器人视觉感知方式上可以分为２种：基于２Ｄ图
示成词袋型哈希码，然后采用边界特征对检索结果 像的识别和基于３Ｄ视觉信息的识别．
进行重排序． １）２Ｄ图像识别中主要是对获取到的图像进行
移动设备带有丰富的传感器，可以为图像提供 物体检测和整体场景识别．基于２Ｄ图像的识别可以
拍照时的上下文信息，如 ＧＰＳ获取的地理位置信 直接对图像进行特征提取或者对图像进行区域特征
息、拍摄时间、相机参数等，所以有些工作利用这些 提取然后使用模型进行标签预测．Ｒｏｕａｎｅｔ等人［６３］
信息对图像中的目标进行识别．Ｒｕｎｇｅ等人［５４］将图 的方法在交互过程中利用用户指定区域，从而缩小
像的地理标签、时间、图像主颜色、天气等各种信息 图像区域，然后对该区域提取特征并进行物体识别，
与图像的视觉特征组合成一个特征向量，然后利用 这里为了进行增量式学习，采用了产生式模型进行
分类器预测图像的概念标签．Ｃｈｅｎ等人［４５］基于 物体识别．Ｗａｎｇ等人［６１］给出了一种实例级物体识
ＳＩＦＴ描述子训练得到的词汇树，计算数据库中的图 别方法，利用图像检索方式匹配输入图像与数据库
像与查询图像的相似度，排除地理相距非常远的地 中的图像，再经过空间一致性验证和投票机制实现
标建筑，然后在特征空间使用近似近邻（ＡＮＮ）的方 物体的识别，这种方法识别精度比较高，但是缺点是
法对查询图像进行识别．Ｄｈｉｒａｊ和Ｌｕｏ［５５］对视觉和 对于识别的物体不具有很好的泛化能力．
地理检测器分别训练并使用相同的权重在预测阶段 ２）３Ｄ图像识别主要是借助可以获取深度信息
进行融合．进一步地，Ｌｉ等人［５６］对不同概念分别学 的传感器例如 Ｋｉｎｅｃｔ或者激光测距实现对于环境
习了不同检测器的权重．Ｘｕ等人［４９］研究了利用地 内的物体深度感知．额外的深度信息可以帮助机器
理信息辅助视觉识别菜品类别的问题．为了对分类 人感知物体位置及大小．Ｌｖ等人［６２］利用 Ｋｉｎｅｃｔ采
模型进行地理约束，该文提出地理局部化模型，将地 集的深度信息和人体骨骼信息进行手持物体分割，
理上下文信息用于分类模型的训练过程，使得模型 同时提取多种模态特征训练分类模型，从而实现对
从根本上对地理信息更有针对性，最后再根据查询 人手上物体的理解．Ｆｉｌｌｉａｔ等人［５９］主要针对室内的
图像的地理坐标对这些分类模型进行自适应组合， 物体进行识别．采用ＰＣＬ库［６６］将获取到的３Ｄ数据
从而实现菜品类别的预测．该方法用到的图像特征 映射到点云空间中，通过检测去除地板和墙壁等噪
就是训练好的深度特征． 音同时进行物体分割，然后使用多种特征结合作为
近年来，由于深度学习很强的特征学习能力已 前馈神经网络输入学习到综合特征表示．
应用到各种移动视觉识别任务中．例如，Ｔｅｒａｄｅｅｐ［５７］ 视觉识别技术是机器人感知外界信息的重要渠
公司已经针对移动和嵌入式设备开发了一套基于深 道，因此未来在交互过程中利用视觉识别技术以增
度学习的算法实现移动端的场景理解、物体检测和 强机器人理解能力和提升与用户交互体验也具有很
识别等．百度等搜索公司［５８］也将深度学习技术比如 重要的研究价值，是一个具有挑战性的方向．例如利 蒋树强等：面向智能交互的图像识别技术综述与展望 １１９
用图像识别技术同时识别人脸和物体，可以帮助关 理解简单的场景，设计理解复杂场景的视觉技术也
联理解用户意图和兴趣爱好．目前受到大家广泛研 是未来视觉技术发展的一个难点问题．３）现有的视
究关注的图像描述和问答技术也会很快和机器人的 觉识别技术依然以视觉信息为主，但是随着各种传
视觉交互应用相结合，产生新的研究内容和应用场 感器的迅速发展，我们可以得到各种各样的上下文
景，从而进一步促进视觉识别技术的发展和进步． 信息，如果将视觉信息和这些上下文信息高效有机
结合将对提高视觉识别的性能有很大的改进，尤其
７ 总结和展望 是在面向基于机器人的视觉识别应用中．如果未来
能够比较好地解决这些技术问题，视觉识别和智能
由于相关理论和技术的长足发展，在过去２０年
交互技术有望在未来越来越多的领域中造福人类社
中，视觉识别和智能交互技术发生了日新月异的变
会，更加深入地为人类的生产、生活、消费和娱乐等
化．从小数据到大数据，从手工设计特征到以深度学
方面提供智能化、个性化和全面化的服务．
习为代表的视觉特征学习，从简单内容到自然场景，
从简单模型到复杂模型，从单一输出到复杂输出，从
参 考 文 献
视觉识别到视觉理解、进一步到视觉描述和问答，视
觉识别和智能交互技术已经逐渐从实验室走向现实
［１］ Ａｎｄｒｅｏｐｏｕｌｏｓ Ａ， Ｔｓｏｔｓｏｓ Ｊ Ｋ．５０ ｙｅａｒｓ ｏｆ ｏｂｊｅｃｔ
的应用场景，相关方法尤其在深度学习方法、视觉和
ｒｅｃｏｇｎｉｔｉｏｎ：Ｄｉｒｅｃｔｉｏｎｓ ｆｏｒｗａｒｄ［Ｊ］．Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ
自然语言处理等技术深度结合的方面发展速度快， Ｉｍａｇｅ Ｕｎｄｅｒｓｔａｎｄｉｎｇ，２０１３，１１７（８）：８２７－８９１
技术更新多．视觉交互的主要形式从普通设备逐渐 ［２］ Ｒｕｓｓａｋｏｖｓｋｙ Ｏ，Ｄｅｎｇ Ｊｉａ，Ｓｕ Ｈａｏ，ｅｔ ａｌ．ＩｍａｇｅＮｅｔ：Ｌａｒｇｅ
迁移到智能终端和机器人，视觉信息处理能力越来 ｓｃａｌｅ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ ｃｈａｌｌｅｎｇｅ［Ｊ］．Ｉｎｔｅｒｎａｔｉｏｎａｌ Ｊｏｕｒｎａｌ
越强，人机交互的体验也越来越真实． ｏｆ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ，２０１５，１１５（３）：２１１－２５２
［３］ Ｚｈｏｕ Ｂｏｌｅｉ，Ｌａｐｅｄｒｉｚａ Ａ，Ｘｉａｏ Ｊｉａｎｘｉｏｎｇ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ
通过以上分析和讨论，视觉识别和智能交互技
ｄｅｅｐ ｆｅａｔｕｒｅｓ ｆｏｒ ｓｃｅｎｅ ｒｅｃｏｇｎｉｔｉｏｎ ｕｓｉｎｇ Ｐｌａｃｅｓ ｄａｔａｂａｓｅ［Ｃ］
术呈现４个发展趋势：１）深度学习方法由于其突出
??Ｐｒｏｃ ｏｆ ｔｈｅ ２８ｔｈ Ａｎｎｕａｌ Ｃｏｎｆ ｏｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ
的泛化能力和视觉特征捕捉能力，将被应用在更深
Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｃａｍｂｒｉｄｇｅ，ＭＡ：ＭＩＴ Ｐｒｅｓｓ，２０１４：
层次、多角度的视觉识别和理解的各项技术当中；２） ４８７－４９５
视觉识别和理解将与语言和认知技术进行更深入全 ［４］ Ｘｉａｏ Ｊｉａｎｘｉｏｎｇ，Ｈａｙｓ Ｊ，Ｅｈｉｎｇｅｒ Ｋ，ｅｔ ａｌ．Ｓｕｎ ｄａｔａｂａｓｅ：
面的结合，使得更加高级的视觉理解和描述性语义 Ｌａｒｇｅ－ｓｃａｌｅ ｓｃｅｎｅ ｒｅｃｏｇｎｉｔｉｏｎ ｆｒｏｍ ａｂｂｅｙ ｔｏ ｚｏｏ［Ｃ］??Ｐｒｏｃ ｏｆ
输出取代简单的物体、场景识别而成为下一个１０年
ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１５：３４８５－３４９２
的研究热点；３）视觉识别和理解将会在具体的应用
［５］ Ｋｒｉｚｈｅｖｓｋｙ Ａ，Ｓｕｔｓｋｅｖｅｒ Ｉ， Ｈｉｎｔｏｎ Ｇ Ｅ．ＩｍａｇｅＮｅｔ
中进行更深层次的融合和适配，如特定内容的图像
ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｗｉｔｈ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ［Ｃ］??
和视频识别等；４）随着视觉描述和视觉问答的兴起，
Ｐｒｏｃ ｏｆ ｔｈｅ ２６ｔｈ Ａｎｎｕａｌ Ｃｏｎｆ ｏｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ
智能终端和机器人的视觉能力将在人机智能交互中 Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｃａｍｂｒｉｄｇｅ，ＭＡ：ＭＩＴ Ｐｒｅｓｓ，２０１２：
起到越来越重要的作用，并将逐渐从较为局限的人 １０９７－１１０５
机对话模式，进化为基于多通道智能信息处理的自 ［６］ Ｙｏｓｉｎｓｋｉ Ｊ，Ｃｌｕｎｅ Ｊ，Ｂｅｎｇｉｏ Ｙ，ｅｔ ａｌ．Ｈｏｗ ｔｒａｎｓｆｅｒａｂｌｅ
ｆｅａｔｕｒｅｓ ｉｎ ｄｅｅｐ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ２８ｔｈ
然交互．
Ａｎｎｕａｌ Ｃｏｎｆ ｏｎ Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．
与此同时，在视觉识别和智能交互技术发展的
Ｃａｍｂｒｉｄｇｅ，ＭＡ：ＭＩＴ Ｐｒｅｓｓ，２０１４：３３２０－３３２８
过程中也面临着许多挑战．主要包括３个方面：１）通
［７］ Ｚｅｉｌｅｒ Ｍ Ｄ，Ｆｅｒｇｕｓ Ｒ．Ｖｉｓｕａｌｉｚｉｎｇ ａｎｄ ｕｎｄｅｒｓｔａｎｄｉｎｇ
过深度学习技术提高性能的一种主流方法是通过增 ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ １６ｔｈ Ｅｕｒｏｐｅａｎ Ｃｏｎｆ
加网络层数来增加识别的准确度．但是更深的网络 ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｂｅｒｌｉｎ：Ｓｐｒｉｎｇｅｒ，２０１４：２９７－３１２
需要更多训练的参数，这就意味着需要更多的训练 ［８］ Ｓｉｍｏｎｙａｎ Ｋ，Ｚｉｓｓｅｒｍａｎ Ａ． Ｖｅｒｙ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ
样本和训练时间．因此，怎样设计网络模型如网络深 ｎｅｔｗｏｒｋｓ ｆｏｒ ｌａｒｇｅ－ｓｃａｌｅ ｉｍａｇｅ ｒｅｃｏｇｎｉｔｉｏｎ［Ｊ］．ＣｏＲＲ ａｂｓ?
１４０９．１５５６，２０１４
度、卷积核的个数、卷积核的大小等以及如何快速地
［９］ Ｓｚｅｇｅｄｙ Ｃ，Ｌｉｕ Ｗｅｉ，Ｊｉａ Ｙａｎｇｑｉｎｇ，ｅｔ ａｌ．Ｇｏｉｎｇ ｄｅｅｐｅｒ ｗｉｔｈ
训练得到高性能模型将是深度学习技术面临的一个
ｃｏｎｖｏｌｕｔｉｏｎｓ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ
重要挑战．２）尽管现有的视觉识别和理解技术取得
Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，
了巨大的进展，但是现有的视觉识别技术仍然只能 ２０１５：１－９ １２０ 计算机研究与发展 ２０１６，５３（１）
［１０］ Ｄｏｎａｈｕｅ Ｊ，Ｊｉａ Ｙａｎｇｑｉｎｇ，Ｖｉｎｙａｌｓ Ｏ，ｅｔ ａｌ．ＤｅＣＡＦ：Ａ ｄｅｅｐ ［２３］ Ｒａｓｉｗａｓｉａ Ｎ，Ｖａｓｃｏｎｃｅｌｏｓ Ｎ．Ｈｏｌｉｓｔｉｃ ｃｏｎｔｅｘｔ ｍｏｄｅｌｓ ｆｏｒ
ｃｏｎｖｏｌｕｔｉｏｎａｌ ａｃｔｉｖａｔｉｏｎ ｆｅａｔｕｒｅ ｆｏｒ ｇｅｎｅｒｉｃ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ［Ｊ］．ＩＥＥＥ Ｔｒａｎｓ ｏｎ Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ ａｎｄ
［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ３１ｓｔ Ｉｎｔ Ｃｏｎｆ ｏｎ Ｍａｃｈｉｎｅ Ｌｅａｒｎｉｎｇ．Ｎｅｗ Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０１２，３４（５）：９０２－９１７
Ｙｏｒｋ：ＡＣＭ，２０１４：６４７－６５５ ［２４］ Ｓｏｎｇ Ｘｉｎｈａｎｇ，Ｊｉａｎｇ Ｓｈｕｑｉａｎｇ，Ｈｅｒｒａｎｚ Ｌ．Ｊｏｉｎｔ ｍｕｌｔｉ－
［１１］ Ｌｉｕ Ｌｉｎｇｑｉａｏ，Ｓｈｅｎ Ｃｈｕｎｈｕａ，Ｈｅｎｇｅｌ Ａ．Ｔｈｅ ｔｒｅａｓｕｒｅ ｆｅａｔｕｒｅ ｓｐａｔｉａｌ ｃｏｎｔｅｘｔ ｆｏｒ ｓｃｅｎｅ ｒｅｃｏｇｎｉｔｉｏｎ ｉｎ ｔｈｅ ｓｅｍａｎｔｉｃ
ｂｅｎｅａｔｈ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｌａｙｅｒｓ： Ｃｒｏｓｓ－ｃｏｎｖｏｌｕｔｉｏｎａｌ－ｌａｙｅｒ ｍａｎｉｆｏｌｄ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ
ｐｏｏｌｉｎｇ ｆｏｒ ｉｍａｇｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１５：
ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ， １３１２－１３２０
ＮＪ：ＩＥＥＥ，２０１５：４７４９－４７５７ ［２５］ ＭＩＴ．Ｐｌａｃｅｓ［ＥＢ?ＯＬ］．［２０１５－０７－１０］．ｈｔｔｐ：??ｐｌａｃｅｓ．ｃｓａｉｌ．
［１２］ Ｇｏｎｇ Ｙｕｎｃｈａｏ，Ｗａｎｇ Ｌｉｗｅｉ，Ｇｕｏ Ｒｕｉｑｉ，ｅｔ ａｌ．Ｍｕｌｔｉ－ｓｃａｌｅ ｍｉｔ．ｅｄｕ?ｄｅｍｏ．ｈｔｍｌ
ｏｒｄｅｒｌｅｓｓ ｐｏｏｌｉｎｇ ｏｆ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ａｃｔｉｖａｔｉｏｎ ｆｅａｔｕｒｅ［Ｃ］ ［２６］ Ｆａｎｇ Ｈａｏ，Ｇｕｐｔａ Ｓ，Ｉａｎｄｏｌａ Ｆ，ｅｔ ａｌ．Ｆｒｏｍ ｃａｐｔｉｏｎｓ ｔｏ
??Ｐｒｏｃ ｏｆ ｔｈｅ １６ｔｈ Ｅｕｒｏｐｅａｎ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ． ｖｉｓｕａｌ ｃｏｎｃｅｐｔｓ ａｎｄ ｂａｃｋ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ
Ｂｅｒｌｉｎ：Ｓｐｒｉｎｇｅｒ，２０１４：３９２－４０７ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，ＮＪ：
［１３］Ｊｅｇｏｕ Ｈ，Ｄｏｕｚｅ Ｍ，Ｓｃｈｍｉｄ Ｃ，ｅｔ ａｌ．Ａｇｇｒｅｇａｔｉｎｇ ｌｏｃａｌ ＩＥＥＥ，２０１５：１４７３－１４８２
ｄｅｓｃｒｉｐｔｏｒｓ ｉｎｔｏ ａ ｃｏｍｐａｃｔ ｉｍａｇｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ［Ｃ］??Ｐｒｏｃ ｏｆ ［２７］ Ｄｅｖｌｉｎ Ｊ，Ｃｈｅｎｇ Ｈａｏ，Ｆａｎｇ Ｈａｏ，ｅｔ ａｌ．Ｌａｎｇｕａｇｅ ｍｏｄｅｌｓ ｆｏｒ
ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ． ｉｍａｇｅ ｃａｐｔｉｏｎｉｎｇ：Ｔｈｅ ｑｕｉｒｋｓ ａｎｄ ｗｈａｔ ｗｏｒｋｓ［Ｃ］??Ｐｒｏｃ ｏｆ
Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１０：３３０４－３３１１ ｔｈｅ ２０１５ Ｃｏｎｆ ｏｆ ｔｈｅ Ａｓｓｏｃｉａｔｉｏｎ ｆｏｒ Ｃｏｍｐｕｔａｔｉｏｎａｌ
［１４］ Ｌｉ Ｙａｏ，Ｌｉｕ Ｌｉｎｇｑｉａｏ，Ｓｈｅｎ Ｃｈｕｎｈｕａ．Ｍｉｄ－ｌｅｖｅｌ ｄｅｅｐ ｐａｔｔｅｒｎ Ｌｉｎｇｕｉｓｔｉｃｓ．Ｓｔｒｏｕｄｓｂｕｒｇ，ＰＡ：ＡＣＬ，２０１５：１００－１０５
ｍｉｎｉｎｇ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ ［２８］ Ｖｉｎｙａｌｓ Ｏ，Ｔｏｓｈｅｖ Ａ，Ｂｅｎｇｉｏ Ｓ，ｅｔ ａｌ．Ｓｈｏｗ ａｎｄ ｔｅｌｌ：Ａ
Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１５：９７１－９８０ ｎｅｕｒａｌ ｉｍａｇｅ ｃａｐｔｉｏｎ ｇｅｎｅｒａｔｏｒ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ
［１５］ Ｃｈａｔｆｉｅｌｄ Ｋ，Ｓｉｍｏｎｙａｎ Ｋ，Ｖｅｄａｌｄｉ Ａ，ｅｔ ａｌ．Ｒｅｔｕｒｎ ｏｆ ｔｈｅ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，
ｄｅｖｉｌ ｉｎ ｔｈｅ ｄｅｔａｉｌｓ：Ｄｅｌｖｉｎｇ ｄｅｅｐ ｉｎｔｏ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｓ［Ｃ］ ＮＪ：ＩＥＥＥ，２０１５：３１５６－３１６４
??Ｐｒｏｃ ｏｆ ｔｈｅ Ｂｒｉｔｉｓｈ Ｍａｃｈｉｎｅ Ｖｉｓｉｏｎ Ｃｏｎｆ．Ｎｏｔｔｉｎｇｈａｍ，ＵＫ： ［２９］ Ｘｕ Ｋ，Ｂａ Ｊ，Ｋｉｒｏｓ Ｒ，ｅｔ ａｌ．Ｓｈｏｗ，ａｔｔｅｎｄ ａｎｄ ｔｅｌｌ：Ｎｅｕｒａｌ
Ｂｒｉｔｉｓｈ Ｍａｃｈｉｎｅ Ｖｉｓｉｏｎ Ａｓｓｏｃｉａｔｉｏｎ，２０１４ ｉｍａｇｅ ｃａｐｔｉｏｎ ｇｅｎｅｒａｔｉｏｎ ｗｉｔｈ ｖｉｓｕａｌ ａｔｔｅｎｔｉｏｎ［Ｊ］．ＣｏＲＲ
［１６］ Ａｇｒａｗａｌ Ｐ，Ｇｉｒｓｈｉｃｋ Ｒ，Ｍａｌｉｋ Ｊ．Ａｎａｌｙｚｉｎｇ ｔｈｅ ｐｅｒｆｏｒｍａｎｃｅ ａｂｓ?１５０２．０３０４４，２０１５
ｏｆ ｍｕｌｔｉｌａｙｅｒ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｏｂｊｅｃｔ ｒｅｃｏｇｎｉｔｉｏｎ［Ｃ］?? ［３０］ Ｋａｒｐａｔｈｙ Ａ，Ｌｉ Ｆ．Ｄｅｅｐ ｖｉｓｕａｌ－ｓｅｍａｎｔｉｃ ａｌｉｇｎｍｅｎｔｓ ｆｏｒ
Ｐｒｏｃ ｏｆ ｔｈｅ １６ｔｈ Ｅｕｒｏｐｅａｎ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ．Ｂｅｒｌｉｎ： ｇｅｎｅｒａｔｉｎｇ ｉｍａｇｅ ｄｅｓｃｒｉｐｔｉｏｎｓ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ
Ｓｐｒｉｎｇｅｒ，２０１４：３２９－３４４ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，ＮＪ：
［１７］ Ａｚｉｚｐｏｕｒ Ｈ，Ｒａｚａｖｉａｎ Ａ Ｓ，Ｓｕｌｌｉｖａｎ Ｊ，ｅｔ ａｌ．Ｆｒｏｍ Ｇｅｎｅｒｉｃ ＩＥＥＥ，２０１５：３１２８－３１３７
ｔｏ ｓｐｅｃｉｆｉｃ ｄｅｅｐ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｆｏｒ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ［Ｃ］?? ［３１］ Ｄｏｎａｈｕｅ Ｊ，Ｈｅｎｄｒｉｃｋｓ Ｌ，Ｇｕａｄａｒｒａｍａ Ｓ，ｅｔ ａｌ．Ｌｏｎｇ－ｔｅｒｍ
Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ ｒｅｃｕｒｒｅｎｔ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１５：３６－４５ ｄｅｓｃｒｉｐｔｉｏｎ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ
［１８］ Ｈｅ Ｋａｉｍｉｎｇ，Ｚｈａｎｇ Ｘｉａｎｇｙｕ，Ｒｅｎ Ｓｈａｏｑｉｎｇ，ｅｔ ａｌ．Ｓｐａｔｉａｌ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１５：
ｐｙｒａｍｉｄ ｐｏｏｌｉｎｇ ｉｎ ｄｅｅｐ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｔｗｏｒｋｓ ｆｏｒ ｖｉｓｕａｌ ２６２５－２６３４
ｒｅｃｏｇｎｉｔｉｏｎ ［Ｊ］．ＩＥＥＥ Ｔｒａｎｓ ｏｎ Ｐａｔｔｅｒｎ Ａｎａｌｙｓｉｓ ａｎｄ ［３２］ Ｖｅｄａｎｔａｍ Ｒ，Ｚｉｔｎｉｃｋ Ｃ Ｌ，Ｐａｒｉｋｈ Ｄ．ＣＩＤＥｒ：Ｃｏｎｓｅｎｓｕｓ－
Ｍａｃｈｉｎｅ Ｉｎｔｅｌｌｉｇｅｎｃｅ，２０１５，３７（９）：１９０４－１９１６ ｂａｓｅｄ ｉｍａｇｅ ｄｅｓｃｒｉｐｔｉｏｎ ｅｖａｌｕａｔｉｏｎ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ
［１９］ Ｗｅｉ Ｙｕｎｃｈａｏ，Ｘｉａ Ｗｅｉ，Ｈｕａｎｇ Ｊｕｎｓｈｉ，ｅｔ ａｌ．ＣＮＮ：Ｓｉｎｇｌｅ－ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
ｌａｂｅｌ ｔｏ ｍｕｌｔｉ－ｌａｂｅｌ［Ｊ］．ＣｏＲＲ ａｂｓ?１４０６．５７２６，２０１４ Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１５：４５６６－４５７５
［２０］ Ｄｉｘｉｔ Ｍ，Ｃｈｅｎ Ｓｉ，Ｇａｏ Ｄａｓｈａｎ ｅｔ ａｌ．Ｓｃｅｎｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｗｉｔｈ ［３３］ Ｃｈｅｎ Ｘｉｎｌｅｉ，Ｚｉｔｎｉｃｋ Ｃ Ｌ．Ｍｉｎｄ＇ｓ ｅｙｅ：Ａ ｒｅｃｕｒｒｅｎｔ ｖｉｓｕａｌ
ｓｅｍａｎｔｉｃ Ｆｉｓｈｅｒ Ｖｅｃｔｏｒｓ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｆｏｒ ｉｍａｇｅ ｃａｐｔｉｏｎ ｇｅｎｅｒａｔｉｏｎ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ
Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，ＮＪ： ＩＥＥＥ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
ＩＥＥＥ，２０１５：３４８５－３４９２ Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１５：２４２２－２４３１
［２１］ Ｌａｚｅｂｎｉｋ Ｓ，Ｓｃｈｍｉｄ Ｃ，Ｐｏｎｃｅ Ｊ．Ｂｅｙｏｎｄ ｂａｇｓ ｏｆ ｆｅａｔｕｒｅｓ： ［３４］ Ｋｉｒｏｓ Ｒ，Ｓａｌａｋｈｕｔｄｉｎｏｖ Ｒ，Ｚｅｍｅｌ Ｒ．Ｕｎｉｆｙｉｎｇ ｖｉｓｕａｌ－
Ｓｐａｔｉａｌ ｐｙｒａｍｉｄ ｍａｔｃｈｉｎｇ ｆｏｒ ｒｅｃｏｇｎｉｚｉｎｇ ｎａｔｕｒａｌ ｓｃｅｎｅ ｓｅｍａｎｔｉｃ ｅｍｂｅｄｄｉｎｇｓ ｗｉｔｈ ｍｕｌｔｉｍｏｄａｌ ｎｅｕｒａｌ ｌａｎｇｕａｇｅ ｍｏｄｅｌｓ
ｃａｔｅｇｏｒｉｅｓ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ［Ｊ］．ＣｏＲＲ ａｂｓ?１４１１．２５３９，２０１４
ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２００６： ［３５］ Ｍａｏ Ｊｕｎｈｕａ，Ｘｕ Ｗｅｉ，Ｙａｎｇ Ｙｉ，ｅｔ ａｌ．Ｅｘｐｌａｉｎ ｉｍａｇｅｓ ｗｉｔｈ
２１６９－２１７８ ｍｕｌｔｉｍｏｄａｌ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ［Ｊ］．ＣｏＲＲ ａｂｓ?１４１０．
［２２］ Ｌｉ Ｌｉｊｉａ，Ｓｕ Ｈａｏ，Ｘｉｎｇ Ｅ，ｅｔ ａｌ．Ｏｂｊｅｃｔ ｂａｎｋ：Ａ ｈｉｇｈ－ｌｅｖｅｌ １０９０，２０１４
ｉｍａｇｅ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｆｏｒ ｓｃｅｎｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ａｎｄ ｓｅｍａｎｔｉｃ ［３６］ Ｃｈｅｎ Ｘｉｎｌｅｉ，Ｚｉｔｎｉｃｋ Ｃ Ｌ．Ｍｉｎｄ＇ｓ ｅｙｅ：Ａ ｒｅｃｕｒｒｅｎｔ ｖｉｓｕａｌ
ｆｅａｔｕｒｅ ｓｐａｒｓｉｆｉｃａｔｉｏｎ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ２４ｔｈ Ａｎｎｕａｌ Ｃｏｎｆ ｏｎ ｒｅｐｒｅｓｅｎｔａｔｉｏｎ ｆｏｒ ｉｍａｇｅ ｃａｐｔｉｏｎ ｇｅｎｅｒａｔｉｏｎ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ
Ｎｅｕｒａｌ Ｉｎｆｏｒｍａｔｉｏｎ Ｐｒｏｃｅｓｓｉｎｇ Ｓｙｓｔｅｍｓ．Ｃａｍｂｒｉｄｇｅ，ＭＡ： ＩＥＥＥ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
ＭＩＴ Ｐｒｅｓｓ，２０１０：１３７８－１３８６ Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１５：２４２２－２４３１ 蒋树强等：面向智能交互的图像识别技术综述与展望 １２１
［３７］Ｊｉａ Ｘｕ，Ｇａｖｖｅｓ Ｅ，Ｆｅｒｎａｎｄｏ Ｂ，ｅｔ ａｌ．Ｇｕｉｄｉｎｇ ｌｏｎｇ－ｓｈｏｒｔ ［５１］ Ｋｕｒｚ Ｄ，Ｈｉｍａｎｅ Ｓ Ｂ．Ｉｎｅｒｔｉａｌ ｓｅｎｓｏｒ－ａｌｉｇｎｅｄ ｖｉｓｕａｌ ｆｅａｔｕｒｅ
ｔｅｒｍ ｍｅｍｏｒｙ ｆｏｒ ｉｍａｇｅ ｃａｐｔｉｏｎ ｇｅｎｅｒａｔｉｏｎ［Ｊ］．ＣｏＲＲ，ａｂｓ? ｄｅｓｃｒｉｐｔｏｒｓ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ
１５０９．０４９４２，２０１５ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１１：
［３８］ Ｍａｏ Ｊｕｎｈｕａ，Ｘｕ Ｗｅｉ，Ｙａｎｇ Ｙｉ，ｅｔ ａｌ．Ｄｅｅｐ ｃａｐｔｉｏｎｉｎｇ ｗｉｔｈ １６１－１６６
ｍｕｌｔｉｍｏｄａｌ ｒｅｃｕｒｒｅｎｔ ｎｅｕｒａｌ ｎｅｔｗｏｒｋｓ（ｍ－ＲＮＮ）［Ｊ］．ＣｏＲＲ，
［５２］ Ｇｏｏｇｌｅ．Ｇｏｏｇｌｅ Ｇｏｇｇｌｅｓ［ＥＢ?ＯＬ］．［２０１５－０７－０５］．ｈｔｔｐ：??
ｗｗｗ．ｇｏｏｇｌｅ．ｃｏｍ?ｍｏｂｉｌｅ?ｇｏｇｇｌｅｓ
ａｂｓ?１４１２．６６３２，２０１４
［５３］ Ｃｈａｎｄｒａｓｅｋｈａｒ Ｖ，Ｔａｋａｃｓ Ｇ，Ｃｈｅｎ Ｄ，ｅｔ ａｌ．ＣＨｏＧ：
［３９］ Ｍａｌｉｎｏｗｓｋｉ Ｍ，Ｆｒｉｔｚ Ｍ．Ａ ｍｕｌｔｉ－ｗｏｒｌｄ ａｐｐｒｏａｃｈ ｔｏ ｑｕｅｓｔｉｏｎ
Ｃｏｍｐｒｅｓｓｅｄ ｈｉｓｔｏｇｒａｍ ｏｆ ｇｒａｄｉｅｎｔｓ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ
ａｎｓｗｅｒｉｎｇ ａｂｏｕｔ ｒｅａｌ－ｗｏｒｌｄ ｓｃｅｎｅｓ ｂａｓｅｄ ｏｎ ｕｎｃｅｒｔａｉｎ ｉｎｐｕｔ
Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．
［Ｊ］．ＣｏＲＲ，ａｂｓ?１４１０．０２１０，２０１４
Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２００９：２５０４－２５１１
［４０］ Ｇｕｐｔａ Ｓ，Ａｒｂｅｌａｅｚ Ｐ，Ｍａｌｉｋ Ｊ．Ｐｅｒｃｅｐｔｕａｌ ｏｒｇａｎｉｚａｔｉｏｎ ａｎｄ ［５４］ Ｒｕｎｇｅ Ｎ，Ｗｅｎｉｇ Ｄ，Ｍａｌａｋａ Ｒ．Ｋｅｅｐ ａｎ ｅｙｅ ｏｎ ｙｏｕｒ ｐｈｏｔｏｓ：
ｒｅｃｏｇｎｉｔｉｏｎ ｏｆ ｉｎｄｏｏｒ ｓｃｅｎｅｓ ｆｒｏｍ ＲＧＢ－Ｄ ｉｍａｇｅｓ［Ｃ］??Ｐｒｏｃ Ａｕｔｏｍａｔｉｃ ｉｍａｇｅ ｔａｇｇｉｎｇ ｏｎ ｍｏｂｉｌｅ ｄｅｖｉｃｅｓ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ
ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｉｎｔ Ｃｏｎｆ ｏｎ Ｈｕｍａｎ－Ｃｏｍｐｕｔｅｒ Ｉｎｔｅｒａｃｔｉｏｎ ｗｉｔｈ Ｍｏｂｉｌｅ
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１３：５６４－５７１ Ｄｅｖｉｃｅｓ ＆Ｓｅｒｖｉｃｅｓ．Ｎｅｗ Ｙｏｒｋ：ＡＣＭ，２０１４：５１３－５１８
［４１］ Ｍａｌｉｎｏｗｓｋｉ Ｍ，Ｒｏｈｒｂａｃｈ Ｍ，Ｆｒｉｔｚ Ｍ．Ａｓｋ ｙｏｕｒ ｎｅｕｒｏｎｓ：Ａ ［５５］ Ｄｈｉｒａｊ Ｊ，Ｌｕｏ Ｊｉｅｂｏ．Ｉｎｆｅｒｒｉｎｇ ｇｅｎｅｒｉｃ ａｃｔｉｖｉｔｉｅｓ ａｎｄ ｅｖｅｎｔｓ
ｎｅｕｒａｌ－ｂａｓｅｄ ａｐｐｒｏａｃｈ ｔｏ ａｎｓｗｅｒｉｎｇ ｑｕｅｓｔｉｏｎｓ ａｂｏｕｔ ｉｍａｇｅｓ ｆｒｏｍ ｉｍａｇｅ ｃｏｎｔｅｎｔ ａｎｄ ｂａｇｓ ｏｆ ｇｅｏ－ｔａｇｓ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ Ｉｎｔ
［Ｊ］．ＣｏＲＲ，ａｂｓ?１５０５．０１１２１，２０１５ Ｃｏｎｆ ｏｎ Ｃｏｎｔｅｎｔ－Ｂａｓｅｄ Ｉｍａｇｅ ａｎｄ Ｖｉｄｅｏ Ｒｅｔｒｉｅｖａｌ．Ｎｅｗ
Ｙｏｒｋ：ＡＣＭ，２００８：３７－４６
［４２］ Ｇａｏ Ｈａｏｙｕａｎ，Ｍａｏ Ｊｕｎｈｕａ，Ｚｈｏｕ Ｊｉｅ，ｅｔ ａｌ．Ａｒｅ ｙｏｕ ｔａｌｋｉｎｇ
［５６］ Ｌｉ Ｘｉｒｏｎｇ，Ｓｎｏｅｋ Ｃ Ｇ Ｍ，Ｗｏｒｒｉｎｇ Ｍ，ｅｔ ａｌ．Ｆｕｓｉｎｇ ｃｏｎｃｅｐｔ
ｔｏ ａ ｍａｃｈｉｎｅ？Ｄａｔａｓｅｔ ａｎｄ ｍｅｔｈｏｄｓ ｆｏｒ ｍｕｌｔｉｌｉｎｇｕａｌ ｉｍａｇｅ
ｄｅｔｅｃｔｉｏｎ ａｎｄ ｇｅｏ ｃｏｎｔｅｘｔ ｆｏｒ ｖｉｓｕａｌ ｓｅａｒｃｈ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ
ｑｕｅｓｔｉｏｎ ａｎｓｗｅｒｉｎｇ［Ｊ］．ＣｏＲＲ，ａｂｓ?１５０５．０５６１２，２０１５
Ｉｎｔ Ｃｏｎｆ ｏｎ Ｍｕｌｔｉｍｅｄｉａ Ｒｅｔｒｉｅｖａｌ．Ｎｅｗ Ｙｏｒｋ：ＡＣＭ，２０１２：
［４３］ Ｇｅｍａｎ Ｄ，Ｇｅｍａｎ Ｓ，Ｈａｌｌｏｎｑｕｉｓｔ Ｎ，ｅｔ ａｌ．Ｖｉｓｕａｌ ｔｕｒｉｎｇ ｔｅｓｔ
１－８
ｆｏｒ ｃｏｍｐｕｔｅｒ ｖｉｓｉｏｎ ｓｙｓｔｅｍｓ［Ｊ］．Ｐｒｏｃｅｅｄｉｎｇｓ ｏｆ ｔｈｅ Ｎａｔｉｏｎａｌ ［５７］ ＴｅｒａＤｅｅｐ Ｉｎｃ．Ｔｅｒａｄｅｅｐ［ＥＢ?ＯＬ］．［２０１５－０７－０５］．ｈｔｔｐ：??
Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ ｏｆ ｔｈｅ Ｕｎｉｔｅｄ Ｓｔａｔｅｓ ｏｆ Ａｍｅｒｉｃａ，２０１５， ｗｗｗ．ｔｅｒａｄｅｅｐ．ｃｏｍ
１１２（１２）：３６１８－３６２３ ［５８］ ＬＬＲＸｃｏｍ．Ｃｈｉｐｓ［ＥＢ?ＯＬ］．［２０１５－０６－０６］．ｈｔｔｐ：??ｗｗｗ．
［４４］ Ｍａ Ｌｉｎ，Ｌｕ Ｚｈｅｎｇｄｏｎｇ，Ｌｉ Ｈａｎｇ．Ｌｅａｒｎｉｎｇ ｔｏ ａｎｓｗｅｒ ｌｌｒｘ．ｃｏｍ?ｆｅａｔｕｒｅｓ?ｎｅｗ－ｃｈｉｐｓ－ａｒｅ－ｕｓｉｎｇ－ｄｅｅｐ－ｌｅａｒｎｉｎｇ－ｔｏ－ｅｎｈａｎｃｅ－
ｑｕｅｓｔｉｏｎｓ ｆｒｏｍ ｉｍａｇｅ ｕｓｉｎｇ ｃｏｎｖｏｌｕｔｉｏｎａｌ ｎｅｕｒａｌ ｎｅｔｗｏｒｋ ｍｏｂｉｌｅ－ｃａｍｅｒａ－ａｎｄ－ａｕｔｏ－ｉｍａｇｅ－ｐｒｏｃｅｓｓｉｎｇ－ｃａｐａｂｉｌｉｔｉｅｓ．ｈｔｍ
［Ｊ］．ＣｏＲＲ，ａｂｓ?１５０６．００３３３，２０１５ ［５９］ Ｆｉｌｌｉａｔ Ｄ，Ｂａｔｔｅｓｔｉ Ｅ，Ｂａｚｅｉｌｌｅ Ｓ，ｅｔ ａｌ．Ｒｇｂｄ ｏｂｊｅｃｔ
［４５］ Ｃｈｅｎ Ｄ，Ｂａａｔｚ Ｇ，Ｋｏｓｅｒ Ｋ，ｅｔ ａｌ．Ｃｉｔｙ－ｓｃａｌｅ ｌａｎｄｍａｒｋ ｒｅｃｏｇｎｉｔｉｏｎ ａｎｄ ｖｉｓｕａｌ ｔｅｘｔｕｒｅ ｃｌａｓｓｉｆｉｃａｔｉｏｎ ｆｏｒ ｉｎｄｏｏｒ
ｓｅｍａｎｔｉｃ ｍａｐｐｉｎｇ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔ Ｃｏｎｆ ｏｎ
ｉｄｅｎｔｉｆｉｃａｔｉｏｎ ｏｎ ｍｏｂｉｌｅ ｄｅｖｉｃｅｓ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｃｏｎｆ
Ｔｅｃｈｎｏｌｏｇｉｅｓ ｆｏｒ Ｐｒａｃｔｉｃａｌ Ｒｏｂｏｔ Ａｐｐｌｉｃａｔｉｏｎｓ（ＴｅＰＲＡ）．
ｏｎ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，
Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１２：１２７－１３２
ＮＪ：ＩＥＥＥ，２０１１：７３７－７４４
［６０］ Ｌａｉ Ｋ，Ｂｏ Ｌｉｅｆｅｎｇ，Ｒｅｎ Ｘｉａｏｆｅｎｇ，ｅｔ ａｌ．ＲＧＢ－Ｄ Ｏｂｊｅｃｔ
［４６］ Ｌｉｍ Ｊ Ｈ，Ｌｉ Ｙｉｑｕｎ，Ｙｏｕ Ｙｉｌｕｎ，ｅｔ ａｌ．Ｓｃｅｎｅ ｒｅｃｏｇｎｉｔｉｏｎ ｗｉｔｈ
Ｒｅｃｏｇｎｉｔｉｏｎ：Ｆｅａｔｕｒｅｓ，Ａｌｇｏｒｉｔｈｍｓ，ａｎｄ ａ Ｌａｒｇｅ Ｓｃａｌｅ
ｃａｍｅｒａ ｐｈｏｎｅｓ ｆｏｒ ｔｏｕｒｉｓｔ ｉｎｆｏｒｍａｔｉｏｎ ａｃｃｅｓｓ［Ｃ］??Ｐｒｏｃ ｏｆ
Ｂｅｎｃｈｍａｒｋ ｉｎ Ｃｏｎｓｕｍｅｒ Ｄｅｐｔｈ Ｃａｍｅｒａｓ ｆｏｒ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ
ｔｈｅ ＩＥＥＥ Ｉｎｔ Ｃｏｎｆ ｏｎ Ｍｕｌｔｉｍｅｄｉａ ＆Ｅｘｐｏ．Ｐｉｓｃａｔａｗａｙ，ＮＪ： ［Ｍ］．Ｂｅｒｌｉｎ：Ｓｐｒｉｎｇｅｒ，２０１３：１６７－１９２
ＩＥＥＥ，２００７：１００－１０３ ［６１］ Ｗａｎｇ Ｓｈｕａｎｇ，Ｊｉａｎｇ Ｓｈｕｑｉａｎｇ．ＩＮＳＴＲＥ：Ａ ｎｅｗ ｂｅｎｃｈｍａｒｋ
［４７］ Ｔｓａｉ Ｓ Ｓ，Ｃｈｅｎ Ｄ，Ｃｈａｎｄｒａｓｅｋｈａｒ Ｖ，ｅｔ ａｌ．Ｍｏｂｉｌｅ ｐｒｏｄｕｃｔ ｆｏｒ ｉｎｓｔａｎｃｅ－ｌｅｖｅｌ ｏｂｊｅｃｔ ｒｅｔｒｉｅｖａｌ ａｎｄ ｒｅｃｏｇｎｉｔｉｏｎ［Ｊ］．ＡＣＭ
ｒｅｃｏｇｎｉｔｉｏｎ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ Ｉｎｔ Ｃｏｎｆ ｏｎ Ｍｕｌｔｉｍｅｄｉａ．Ｎｅｗ Ｔｒａｎｓ ｏｎ Ｍｕｌｔｉｍｅｄｉａ Ｃｏｍｐｕｔｉｎｇ，Ｃｏｍｍｕｎｉｃａｔｉｏｎｓ，ａｎｄ
Ｙｏｒｋ：ＡＣＭ，２０１０：１５８７－１５９０ Ａｐｐｌｉｃａｔｉｏｎｓ，２０１５，１１（３）：３７：１－３７：２０
［４８］ Ｈｅ Ｊｕｎｆｅｎｇ，Ｆｅｎｇ Ｊｉｎｙｕａｎ，Ｌｉｕ Ｘｉａｎｇｌｏｎｇ，ｅｔ ａｌ．Ｍｏｂｉｌｅ ［６２］ Ｌｖ Ｘｉｏｎｇ，Ｊｉａｎｇ Ｓｈｕｑｉａｎｇ，Ｈｅｒｒａｎｚ Ｌ，ｅｔ ａｌ．ＲＧＢ－Ｄ ｈａｎｄ－
ｈｅｌｄ ｏｂｊｅｃｔ ｒｅｃｏｇｎｉｔｉｏｎ ｂａｓｅｄ ｏｎ ｈｅｔｅｒｏｇｅｎｅｏｕｓ ｆｅａｔｕｒｅ ｆｕｓｉｏｎ
ｐｒｏｄｕｃｔ ｓｅａｒｃｈ ｗｉｔｈ Ｂａｇ ｏｆ Ｈａｓｈ Ｂｉｔｓ ａｎｄ ｂｏｕｎｄａｒｙ ｒｅｒａｎｋｉｎｇ
［Ｊ］．Ｊｏｕｒｎａｌ ｏｆ Ｃｏｍｐｕｔｅｒ Ｓｃｉｅｎｃｅ ａｎｄ Ｔｅｃｈｎｏｌｏｇｙ，２０１５，３０
［Ｃ］??Ｐｒｏｃ ｔｈｅ ＩＥＥＥ Ｃｏｍｐｕｔｅｒ Ｖｉｓｉｏｎ ａｎｄ Ｐａｔｔｅｒｎ
（２）：３４０－３５２
Ｒｅｃｏｇｎｉｔｉｏｎ．Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１２：１６－２１
［６３］ Ｒｏｕａｎｅｔ Ｐ，Ｏｕｄｅｙｅｒ Ｐ，Ｄａｎｉｅａｕ Ｙ，ｅｔ ａｌ．Ｔｈｅ ｉｍｐａｃｔ ｏｆ
［４９］ Ｘｕ Ｒｕｉｈａｎ，Ｈｅｒｒａｎｚ Ｌ，Ｊｉａｎｇ Ｓｈｕｑｉａｎｇ，ｅｔ ａｌ．Ｇｅｏｌｏｃａｌｉｚｅｄ
ｈｕｍａｎ－ｒｏｂｏｔ ｉｎｔｅｒｆａｃｅｓ ｏｎ ｔｈｅ ｌｅａｒｎｉｎｇ ｏｆ ｖｉｓｕａｌ ｏｂｊｅｃｔｓ［Ｊ］．
ｍｏｄｅｌｉｎｇ ｆｏｒ ｄｉｓｈ ｒｅｃｏｇｎｉｔｉｏｎ ［Ｊ］．ＩＥＥＥ Ｔｒａｎｓ ｏｎ
ＩＥＥＥ Ｔｒａｎｓ ｏｎ Ｒｏｂｏｔｉｃｓ，２０１３，２９（２）：５２５－５４１
Ｍｕｌｔｉｍｅｄｉａ，２０１５，１７（８）：１１８７－１１９９
［６４］ Ｍａｔｕｓｚｅｋ Ｃ，Ｂｏ Ｌｉｅｆｅｎｇ，Ｚｅｔｔｌｅｍｏｙｅｒ Ｌ，ｅｔ ａｌ．Ｌｅａｒｎｉｎｇ
［５０］ Ｋａｗａｎｏ Ｙ，Ｙａｎａｉ Ｋ．Ｆｏｏｄｃａｍ：Ａ ｒｅａｌ－ｔｉｍｅ ｆｏｏｄ ｒｅｃｏｇｎｉｔｉｏｎ ｆｒｏｍ ｕｎｓｃｒｉｐｔｅｄ ｄｅｉｃｔｉｃ ｇｅｓｔｕｒｅ ａｎｄ ｌａｎｇｕａｇｅ ｆｏｒ ｈｕｍａｎ－ｒｏｂｏｔ
ｓｙｓｔｅｍ ｏｎ ａ ｓｍａｒｔｐｈｏｎｅ ［Ｊ］． Ｍｕｌｔｉｍｅｄｉａ Ｔｏｏｌｓ ａｎｄ ｉｎｔｅｒａｃｔｉｏｎｓ ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ２８ｔｈ Ｃｏｎｆ ｏｎ Ａｒｔｉｆｉｃｉａｌ
Ａｐｐｌｉｃａｔｉｏｎｓ，２０１５，７４（１４）：５２６３－５２８７ Ｉｎｔｅｌｌｉｇｅｎｃｅ．Ｍｅｎｌｏ Ｐａｒｋ，ＣＡ：ＡＡＡＩ，２０１４：２５５６－２５６３ １２２ 计算机研究与发展 ２０１６，５３（１）
［６５］ Ｍｏｕｂａｒａｋ Ｐ Ｍ，Ｂｅｎ－Ｔｚｖｉ Ｐ．Ａｄａｐｔｉｖｅ ｍａｎｉｐｕｌａｔｉｏｎ ｏｆ ａ Ｍｉｎ Ｗｅｉｑｉｎｇ， ｂｏｒｎ ｉｎ １９８５． ＰｈＤ．
ｈｙｂｒｉｄ ｍｅｃｈａｎｉｓｍ ｍｏｂｉｌｅ ｒｏｂｏｔ［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔ Ｐｏｓｔｄｏｃｔｏｒ ｉｎ ｔｈｅ Ｉｎｓｔｉｔｕｔｅ ｏｆ Ｃｏｍｐｕｔｉｎｇ
Ｓｙｍｐ ｏｎ Ｒｏｂｏｔｉｃ ａｎｄ Ｓｅｎｓｏｒｓ Ｅｎｖｉｒｏｎｍｅｎｔｓ．Ｐｉｓｃａｔａｗａｙ， Ｔｅｃｈｎｏｌｏｇｙ，Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ．
ＮＪ：ＩＥＥＥ，２０１１：１１３－１１８ Ｍｅｍｂｅｒ ｏｆ Ｃｈｉｎａ Ｃｏｍｐｕｔｅｒ Ｆｅｄｅｒａｔｉｏｎ．
［６６］ Ｒｕｓｕ Ｒ Ｂ，Ｃｏｕｓｉｎｓ Ｓ．３Ｄｉｓ ｈｅｒｅ：Ｐｏｉｎｔ ｃｌｏｕｄ ｌｉｂｒａｒｙ（ＰＣＬ） Ｈｉｓ ｃｕｒｒｅｎｔ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ
［Ｃ］??Ｐｒｏｃ ｏｆ ｔｈｅ ＩＥＥＥ Ｉｎｔ Ｃｏｎｆ ｏｎ Ｒｏｂｏｔｉｃｓ ａｎｄ Ａｕｔｏｍａｔｉｏｎ ｍｕｌｔｉｍｅｄｉａ ａｎａｌｙｓｉｓ ａｎｄ ｃｏｎｔｅｘｔ ｂａｓｅｄ ｖｉｓｕａｌ ｒｅｃｏｇｎｉｔｉｏｎ
（ＩＣＲＡ）．Ｐｉｓｃａｔａｗａｙ，ＮＪ：ＩＥＥＥ，２０１１：９－１３ （ｍｉｎｗｅｉｑｉｎｇ＠ｉｃｔ．ａｃ．ｃｎ）．
Ｗａｎｇ Ｓｈｕｈｕｉ， ｂｏｒｎ ｉｎ １９８３． ＰｈＤ．
Ｊｉａｎｇ Ｓｈｕｑｉａｎｇ，ｂｏｒｎ ｉｎ １９７７．ＰｈＤ．
Ａｓｓｏｃｉａｔｅ ｐｒｏｆｅｓｓｏｒ ｉｎ ｔｈｅ Ｉｎｓｔｉｔｕｔｅ ｏｆ
Ｐｒｏｆｅｓｓｏｒ ｉｎ ｔｈｅ Ｉｎｓｔｉｔｕｔｅ ｏｆ Ｃｏｍｐｕｔｉｎｇ
Ｃｏｍｐｕｔｉｎｇ Ｔｅｃｈｎｏｌｏｇｙ，Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ
Ｔｅｃｈｎｏｌｏｇｙ，Ｃｈｉｎｅｓｅ Ａｃａｄｅｍｙ ｏｆ Ｓｃｉｅｎｃｅｓ．
ｏｆ Ｓｃｉｅｎｃｅｓ．Ｍｅｍｂｅｒ ｏｆ Ｃｈｉｎａ Ｃｏｍｐｕｔｅｒ
Ｍｅｍｂｅｒ ｏｆ Ｃｈｉｎａ Ｃｏｍｐｕｔｅｒ Ｆｅｄｅｒａｔｉｏｎ． Ｆｅｄｅｒａｔｉｏｎ．Ｈｉｓ ｃｕｒｒｅｎｔ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ
Ｈｉｓ ｃｕｒｒｅｎｔ ｒｅｓｅａｒｃｈ ｉｎｔｅｒｅｓｔｓ ｉｎｃｌｕｄｅ ｉｎｃｌｕｄｅ ｓｏｃｉａｌ ｍｅｄｉａ ｍｉｎｉｎｇ， ｍｕｌｔｉｍｅｄｉａ ａｎａｌｙｓｉｓ ａｎｄ
ｍｕｌｔｉｍｅｄｉａ ａｎａｌｙｓｉｓ ａｎｄ ｍｕｌｔｉ－ｍｏｄａｌ ｉｎｔｅｌｌｉｇｅｎｔ ｔｅｃｈｎｏｌｏｇｙ． ｍａｃｈｉｎｅ ｌｅａｒｎｉｎｇ（ｗａｎｇｓｈｕｈｕｉ＠ｉｃｔ．ａｃ．ｃｎ）． --------------------------------------------------------------------------------- 软件学报 ISSN 1000-9825, CODEN RUXUEW E-mail: jos@iscas.ac.cn
Journal of Software,2022,33(9):3370−3390 [doi: 10.13328/j.cnki.jos.006426] http://www.jos.org.cn
©中国科学院软件研究所版权所有. Tel: +86-10-62562563
*
面向知识图谱的图嵌入学习研究进展
杨东华1,2, 何 涛1, 王宏志1, 王金宝1
1(哈尔滨工业大学 计算学部, 黑龙江 哈尔滨 150001)
2(哈尔滨工业大学 分析测试与计算中心, 黑龙江 哈尔滨 150001)
通信作者: 王金宝, E-mail: wangjinbao@hit.edu.cn
摘 要: 知识图谱是一种用网络结构存储知识的知识库, 在知识图谱中, 单条知识被表示成三元组的形式, 即(头实
体, 关系, 尾实体). 得力于知识图谱在各个领域的广泛应用, 面向知识图谱的图嵌入学习也得到越来越多研究人员
的关注. 面向知识图谱的图嵌入学习任务旨在为图谱中的实体与关系学习低维且稠密的向量, 通过图嵌入向量表
达实体与关系的语义信息以及度量实体之间、关系之间、实体与关系之间的语义联系, 已有许多研究证明图嵌入
模型在下游任务中的有效性. 近年来, 越来越多研究人员开始关注知识图谱的图嵌入学习, 并取得大量的研究成果,
尝试将图嵌入算法分成了基于转移思想、基于张量分解、基于传统深度学习模型、基于图神经网络以及融入额
外信息的图嵌入学习共5大类, 梳理、介绍各类图嵌入算法的设计思路、算法特征以及优缺点, 以帮助指导初步
接触该领域的研究人员快速学习了解该研究领域的相关模型和算法.
关键词: 知识图谱; 图嵌入学习; 表示学习; 链接预测
中图法分类号: TP181
中文引用格式: 杨东华, 何涛, 王宏志, 王金宝. 面向知识图谱的图嵌入学习研究进展. 软件学报, 2022, 33(9): 3370–3390. http://
www.jos.org.cn/1000-9825/6426.htm
英文引用格式: Yang DH, He T, Wang HZ, Wang JB. Survey on Knowledge Graph Embedding Learning. Ruan Jian Xue Bao/Journal
of Software, 2022, 33(9): 3370–3390 (in Chinese). http://www.jos.org.cn/1000-9825/6426.htm
Survey on Knowledge Graph Embedding Learning
YANG Dong-Hua1,2, HE Tao1, WANG Hong-Zhi1, WANG Jin-Bao1
1(Faculty of Computing, Harbin Institute of Technology, Harbin 150001, China)
2(Center of Analysis, Measurement and Computing, Harbin Institute of Technology, Harbin 150001, China)
Abstract: Knowledge graphs (KGs) serve as a kind of knowledge base by storing facts with network structure, representing each piece of
fact as a triple, i.e. (head, relation, tail). Thanks to the general applications of KGs in various of fields, the embedding learning of
knowledge graph has also quickly gained massive attention. This study tries to classify the existing embedding algorithms as five types:
translation-based models, tensor factorization-based models, traditional deep learning-based models, graph neural network-based models,
and models by fusing extra information. Then, the key ideas, algorithm features, advantages and disadvantages of different embedding
models are introduced and analyzed to give the first-time researchers a guideline that can be referenced to help researchers quickly get
started.
Key words: knowledge graph (KG); graph embedding learning; representation learning; link prediction
1 引 言
近年来, 随着互联网、物联网等技术的不断发展, 以及其他研究领域的需求发展, 各类应用应运而生, 也相应
* 基金项目: 国家自然科学基金(61772157, 61832003, U1866602)
收稿时间: 2021-05-13; 修改时间: 2021-06-29; 采用时间: 2021-07-29; jos在线出版时间: 2021-10-20 杨东华 等: 面向知识图谱的图嵌入学习研究进展 3371
地产生了海量的数据资源. 其中, 图数据作为一种能够广泛建模诸多场景的数据类型, 吸引了大量且深入的相关研
究, 如社交网络、蛋白质网络、知识图谱等领域. 其中, 知识图谱作为一种异质图网络, 将知识表示成三元组的形
式(头实体, 关系, 尾实体), 知识中的实体(即头实体与尾实体)表示成图的节点, 知识中的关系表示成图的连边, 利
用网络化结构更加直观地表征与存储知识.
面向知识图谱的学习任务主要包含知识图谱的构建与维护, 以及基于知识图谱的下游任务, 如基于知识图谱
的问答系统[1]、基于知识图谱的信息抽取[2]任务等. 其中, 无论是属于面向知识图谱的知识补全、实体对齐、关
系抽取任务还是其他基于知识图谱的下游任务, 都能够基于知识图谱的图嵌入表示解决问题. 因此, 伴随着知识图
谱研究热度的上升, 面向知识图谱的表示学习也得到越来越多的关注.
面向知识图谱的表示学习, 又称为知识图谱的图嵌入学习, 旨在将知识图谱的实体与关系映射到低维且稠密
的向量或矩阵, 相比于one-hot向量, 图嵌入对存储要求更低, 且更加能够反映实体、关系的语义信息, 以及实体之
间、关系之间、实体与关系之间的语义联系. 除此以外, 相较于传统的图学习算法, 如基于规则学习的知识推理算
法[3,4]、基于本体推理的知识推理算法[5,6], 图嵌入学习具有较低的计算复杂性, 并且得利于并行运算能力与框架的
发展, 图嵌入学习的计算效率得以不断提升.
相比于其他领域的图嵌入学习, 例如面向无向图的图嵌入学习, 面向社交网络、蛋白质结构等异质图的图嵌
入学习任务, 知识图谱因为自身的数据特点使得在图嵌入学习方面与其他类型的异质图有所差异. 首先, 常见的异
质图包含的关系类别很少, 如DBLP网络只包含论文-作者、论文-会议和论文-题目用词3种关系类别, IMDB网
络只包含电影-演员、电影-导演两种关系, 极少的关系类别使得这类异质图学习更长、更丰富的上下文模式更加
方便. 基于元路径(meta-path)和元图(meta-graph)的图嵌入学习方法是两种异质图表示学习的常见路线[7], 元路
径和元图可以视为需要专家人工制定的子图模式. 而极少的关系类别也使得人工构建元路径和元图在效率上成为
可能, 这也使得异质图基于元路径和元图的图嵌入学习方法能够得到有效发展. 而知识图谱往往具有很多关系类
别, 例如FB15k-237数据集[8]包含237种关系, 想要人工设计元路径和元图模式则不可避免地需要面临组合爆炸
的问题; 其次, 对于常见的异质图, 因为结构简单、实体类别较少, 每个节点往往能够分配一个特定的类别, 这种节
点类别信息在异质图的图嵌入学习过程中能够起到不可忽略的作用, 例如HAN模型[9]在聚合信息前会首先将邻
居信息通过类别相关的线性变换映射到节点类别空间中. 而知识图谱实体标签过于复杂, 没有显示为每个实体分
配特定的类别, 同时因为结构过于复杂, 知识图谱的实体类别往往具有层次性, 可能实体与实体的类别本身都存在
图谱内, 所以想要现实表达实体的类别信息并不容易. 所以, 实体类别信息往往作为一种隐式知识被利用在图嵌入
学习任务中; 除此以外, 相比于常见的异质图, 知识图谱的节点(即实体)往往具有较为丰富的文本信息, 如实体名
称、实体描述, 这些文本信息能够配合知识图谱本身的图结构信息一起更好地学习实体的语义信息. 综上所述, 知
识图谱虽然作为一种异质图, 但因为自身的一系列特点, 使得面向知识图谱的图嵌入学习在学习思路、可利用的
信息等方面与其他类型的异质图有较大差异, 丰富的文本信息和复杂多变的网络结构使得面向知识图谱的图嵌入
学习增加了更多的挑战和研究空间.
为此, 本文梳理了面向知识图谱的图嵌入学习算法的不同设计思想, 并对相应方法进行了总结. 具体来说, 本
文首先给出图嵌入学习的任务描述以及相关符号定义, 然后按照设计思路、信息利用程度的不同将图嵌入学习方
法分成如下5种类别: 基于转移思想的图嵌入算法、基于矩阵/张量分解的图嵌入算法、基于传统深度学习的图
嵌入算法、基于图神经网络的图嵌入算法以及融入额外信息的图嵌入算法; 最后, 本文总结了以上不同类别图嵌
入的特征与优缺点, 以及部分有待深入研究的问题.
相较于现有的研究进展报告[10,11], 本文主要通过分析之前模型的不足来梳理和介绍当前的研究进展, 这样
有利于从问题出发有的放矢地介绍不同领域方法的发展脉络和不同研究成果的出发点和优缺点, 方便读者的
理解; 而且相较于文献[10,11]的工作, 本文将基于GNN的图嵌入模型从基于深度学习模型的图嵌入算法中抽
取出来单独列为一类, 一方面是为了结合了近阶段图神经网络模型的快速发展趋势, 另一方面是考虑到基于
GNN的图嵌入模型从编码思想上与其他几类方法有较大的差异, 其主要利用GNN模型较为强大的图结构编
码能力, 因此有必要单独列为一类, 所以本文在基于GNN模型的图嵌入方法上介绍也会较多; 除此以外, 本文 3372 软件学报 2022年第33卷第9期
还介绍了使用额外信息的一系列图嵌入算法, 如基于文本信息、路径信息等, 为面向知识图谱的图嵌入算法的
后续研究介绍更多可思考和研究的方向; 最后, 本文列举了面向知识图谱的图嵌入学习的部分难点和有待解决
的问题.
2 面向知识图谱的图嵌入学习任务描述与符号定义
2.1 面向知识图谱的图嵌入学习任务定义
本节我们给出面向知识图谱的图嵌入学习的任务描述以及相关符号定义. 给定一个知识图谱 KG=(E;
R;T), 其中E表示 KG包含的实体集合, R表示 KG涉及的关系集合, T表示 KG中包含的三元组集合, 面向知识
图谱的图嵌入学习, 简称为图嵌入学习任务, 旨在为每个实体 e2E学习相应的低维表示向量v∈Rde, 其中d
e e
表示实体嵌入的维度, 以及为每个关系r∈R学习相应的低维表示向量v∈Rdr或者表示矩阵M∈Rdr×dr, 其中d
r r r
表示关系表示的维度, 通常来说d=d=d. 旨在通过学习实体和关系的表示向量或矩阵, 有效建模实体和关系
e r
的语义信息, 以及实体与实体之间、关系与关系之间的语义联系, 同时有利于下游任务对知识图谱的发掘和
应用.
需要注意的是, 图嵌入只是学习结果, 而为了学习图嵌入, 通常需要经过特定的学习任务, 如链接预测任务(即
知识补全任务)、实体对齐任务等. 以链接预测任务为例, 该任务要求给定三元组中的两个元素, 去预测第3个元
素(如知道头实体和关系, 去预测正确的尾实体), 形式化定义就是给定查询(h, r, ?)或者(?, r, t), 分别预测正确的
尾实体和头实体集合, 其中h、r、t分别代表头实体、关系和尾实体. 通常通过学习图嵌入来计算三元组的得分
函数, 通过梯度反向传播算法在最大化正确三元组的得分函数的同时也学习了图嵌入表示. 相对于其他任务, 链接
预测任务需要的条件较少且研究意义深远, 因此研究人员通常使用链接预测任务来判断图嵌入学习算法的有效
性, 下文中除特殊说明外, 默认图嵌入学习的目标任务为面向知识图谱的链接预测任务.
链接预测的评估指标通常采用MRR、MR和Hits@k这3种排序指标, 之所以采用排序指标, 是因为链接预测
任务通常将学习任务视为排序任务, 在预测前, 需要为每个候选实体进行打分, 并按照打分情况对候选实体进行排
序. 对于评估样本(h, r, t), 假设其正确的标签集合为S={e|(h, r, e)}成立. 为了计算上述指标, 需要统计当前评估样
本(h, r, t)的正确标签t在候选实体中的排序值rank. 在统计排序值时, 有原始排序值和过滤排序值两种统计方式.
原始排序值即直接统计t在候选实体中的排序值作为最终rank, 但是考虑到正确的标签集合S不仅包含标签t, 还
包括其他实体, 如果模型只统计t在候选实体中的排序值, 而忽略了排在t之前的正确标签, 则计算出的排序值偏
大, 因此过滤排序值将所有排在t的正确标签过滤掉, 再计算t的排序值作为最终的rank. 通常来说给出的指标默
认是指过滤后的实验指标. 基于以上统计量, MR的计算方式为:
1
∑N
MR= rank;
N i
i=1
其中, N是评估样本的个数, rank表示第i个样本中正确标签的排序值. 相应的MRR的计算方式为:
i
1
∑N
1
MRR= :
N rank
i=1 i
Hits@k指标统计了所有评估样本中正确标签排序在前k个的比例, 计算方式为:
1
∑N
Hits@k= I(rank ⩽k);
N i
i=1
其中, I(x)为示性函数, 当参数x为真时该函数取值为1, 否则为0.
2.2 本文使用的部分符号定义与说明
为了方便后文介绍, 表1定义一些本文常用的符号, 并给出了相应的解释说明. 杨东华 等: 面向知识图谱的图嵌入学习研究进展 3373
表 1 本文使用的符号
符号定义 解释
G 表示知识图谱
h;r;t 分别表示头实体、关系与尾实体
ve;vr;Mr 分别表示实体e、关系r的表示向量, 以及关系r的表示矩阵
de;dr;d 分别指代实体表示与关系表示的维度, 如果两者维度相同, 则用d统一表示
V表示全体实体的表示向量组成的表示矩阵, V表示第i个实体的嵌入表示; M表示全体关系的表示向量(矩阵)组成的嵌
V;M 入矩阵(张i
量), M表示第k个实体的嵌入表示
k
E;R;Rinv 分别表示知识图谱G的实体集合、关系集合与逆关系集合, 因而|E|, |R|分别表示实体集合E与关系集合R的大小
ei;rj 分别表示实体集合E的第i个实体与关系集合R的第j个关系
ϕ r( (h h; ;r t; )t)
表示三元组(h, r, t)的得分函数三元组(h, r, t)另一种表达方式: 该值为1表示三元组成立; 为0则说明该三元组不存在
3 面向知识图谱的图嵌入学习模型研究框架
下面我们将具体介绍不同类型图嵌入学习算法的基本思想与代表模型. 我们按照图嵌入学习核心思想、基础
模型使用以及信息利用程度的不同, 本文将面向知识图谱的图嵌入算法分成了: 基于转移思路、基于张量分解、
基于传统深度学习、基于图神经网络以及融入额外信息的图嵌入学习算法. 其中前3种算法从距离度量、语义相
似度和特征抽取3个角度分别考察三元组的评估策略. 前3类方法的学习对象都是单个三元组, 而基于GNN的
模型建立在前3类方法的基础之上, 首先利用GNN模型对图谱的全局结构进行编码, 然后采用前3类方法作为
解码器做链接预测任务. 因此基于GNN的图嵌入学习方法学习到的图结构信息理论上更加全面有效, 这是从图
结构信息的挖掘深度角度进行分类. 最后, 前4类算法都只是涉及到知识图谱的结构信息, 而知识图谱作为一种特
别的异质图, 其实体与关系都可能关联了名称、描述、类别等信息, 如何在学习图嵌入的同时考虑这些信息是第
5类算法的关键思想. 下文将按照上述分类的顺序依次介绍各类算法的思想以及相应的算法实现.
3.1 基于转移思想的图嵌入学习
首先介绍基于转移思想(translation-based)的图嵌入学习方法, 我们将从基本思想入手开始介绍奠基性工作,
然后从该工作的问题角度分别介绍后续对该工作的改进与优化, 依次理清该类模型的发展脉络.
基于转移思想的图嵌入算法最早由Bordes等人[12]提出, 该工作提出了第一个基于转移的表示学习模型
TransE. TransE算法认为如果三元组(头实体, 关系, 尾实体)正确, 则头实体h、关系r与尾实体t的表示向量v 、
h
v和v需满足关系v +v≈v, 即头实体在经过关系的转移后需要接近尾实体. TransE的核心思想如图1(a)所示, 头、
r t h r t
尾实体均被建模成表示空间中的一个点, 而关系建模成表示空间中的向量位移, v +v≈v, 表示头实体h经过关系
h r t
r的位移后在表示空间中接近尾实体t, 例如v +v ≈v , v +v ≈v . 因此, 对于三元组(h, r, t),
哈尔滨 方言 东北话 广东 方言 粤语
TransE设计的优化目标函数为f(h, r, t)=||v +v-v|| , 当三元组正确时最小化该目标函数, 反之则最大化该函数.
h r t p
t
h r t h
t
r
h
(a) TransE 设计思想图例解释 (b) TransH 设计思想图例解释
图 1 TransE与TransH的核心思想示意图
需要提及的是, 虽然于TransE模型提出之前Bordes等人也提出了unstructed model (UM)[13]和structured
embedding (SE)[14]两个模型, 其中UM模型的目标函数设计为||v - v|| (因此UM模型可以视为TransE约束关系为
h t 2 3374 软件学报 2022年第33卷第9期
零向量时的特例), 而SE模型的目标函数设计为||M v – M v|| , 从目标函数的设计不难看出关系的重要性并不
h, r h t, r t 2
明显, 没有起到对头实体表示向量进行转移操作的作用, 因此本文还是认为最早提出转移思想的图嵌入算法的工
作由TransE最早提出. TransE建模简单但效果颇佳, 并且相较于传统的知识推理方法, 学习效率高, 能够很快部署
在大型知识图谱上, 因此很快引发了Trans系列模型的研究热潮. 尽管TransE算法表现不错, 学习效率高, 但依然
存在一些不足有待优化.
• 首先, 在处理多对一、一对多以及多对多关系(统称为多映射关系)时, 由于简单约束v +v≈v的作用, 会使
h r t
得不同实体的分布式表示在表示空间中聚集在一起, 即使这些实体具有不同的语义, 进而造成实体语义的混乱. 例
如通过简单约束v +v ≈v 与v +v ≈v , 使得哈尔滨与北京的语义发生混淆. 为了解决该问题,
哈尔滨 位于 中国 北京 位于 中国
TransH[15]引入了关系超平面的概念, 在转移头实体之前, 先将头尾实体分别投影到关系所在的超平面上:
v h;r=v h(cid:0)wT rv hw r,v t;r=v t(cid:0)wT rv tw r;
其中, w r 表示关系 r 相关的超平面的法向量. 在超平面上计算头实体经过关系转移后与尾实体的距离: ||v h, r+v r-v t, r|| p.
这使得相同的实体在不同的关系下具有不同的表示, 在一定程度上缓减了TransE在多映射关系上的弱表现问题,
该算法的设计思想参考图1(b)所示. 不同于TransH的超平面假设, TransR[16]假设每个关系都关联了一个表示空
间, 在转移操作前, TransR通过线性变换将实体表示映射到相应的关系空间中, 然后执行转移操作, 具体来说,
TransR定义了关系关联的映射矩阵 M , 在执行转移操作之前, 分别通过v =Mv 和v =Mv获得关系空间内的
r h, r r h t, r r t
头实体与尾实体表示, 最后通过计算||v +v-v || 得到优化目标. TransD[17]继承了TransR的思路, 但该算法观察
h, r r t, r p
到TransR为不同的关系类别 r 关联不同的映射矩阵M r, 容易造成参数量过大的问题, 因此对M r进行了分解表示.
TransD认为实体空间到关系空间的映射矩阵不应只受限于关系, 还与实体相关. 为了便于构造同时由实体与关系
决定的映射矩阵, TransD为每个实体(关系)引入了两个向量, 其中一个是实体(关系)的真实语义表示v(v), 另一
e r
个向量v (v )用于构建映射矩阵, 对于三元组(h, r, t), 通过 M =v vT +I与M =v vT +I分别构建头实体与尾
ep rp rh rp hp rt rp tp
实体的映射矩阵. TransR与TransD算法的设计思想可以参见图2所示. TranSparse[18]同样继承了TransR的思想,
为了缓解TransR参数量过大的问题, TranSparse算法考虑使用稀疏矩阵建模 M . 同时该算法注意到语义越复杂
r
的关系, 往往需要用更多的参数量来学习, 因此该算法为每个关系类别自适应地学习稀疏度:
1
(cid:18)l =1(cid:0) (1(cid:0)(cid:18) )Nl (l=h;t);
r Nl min r
r(cid:3)
其中, Nl表示关系r连接的实体对数目, Nl 表示所有关系中连接实体对数目的最大值. 这里TranSparse算法假设
r r(cid:3)
连接的实体对数目越多则该关系的语义越复杂. 计算完每个关系的稀疏度(cid:18)l 后, 基于该稀疏度生成稀疏矩阵
r
Ml((cid:18)l), 对于头实体和尾实体分别生成映射矩阵Mh((cid:18)h)和Mt((cid:18)t), 最后仿照TransR模型计算距离函数:
r r r r r r
jjMh((cid:18)t)v +v (cid:0)Mt((cid:18)t)vjj :
r r h r r r t p
M
rt 1
h 2
h 1
t
2
MMM rrr h 1
h r2
r
r
t t1
2
rt 1 h
3
t 2h 1 t h3
2
MM rr (th i ii == =vv 1rr p ,p v v 2tTh iT p ,i p + 3+ I )I hh 21
h 3
r r
r
t t1 3t
2
r
Entity space Relation space Entity space Relation space
(a) TransR 核心思想图例解释 (b) TransD 核心思想图例解释
图 2 TransR与TransD的核心思想图例解释
STransE[19]为每个关系 r 关联了两个独立的矩阵 W rh 、 W rt , 在转移操作前, 使用 W rh 将头实体映射到关系空间,
同时用Wt将尾实体映射到关系空间. 除此以外, CrossE[20]采用类似TransE的思想, 首先计算头实体与关系的合并,
r
之后希望合并后的向量与尾实体尽可能相似, 为了交互头实体与关系的信息, 引入了交互矩阵C , 使得实体以及
r
关系的表示能够根据不同的三元组自主选择有用的信息, 进而实现图嵌入的动态变化. 以上工作都是从表示空间
角度来考虑解决多映射关系的问题, TransM[21]从三元组的重要性角度提出新的思路, 该算法考虑了不同属性关系 杨东华 等: 面向知识图谱的图嵌入学习研究进展 3375
映射对三元组的贡献程度不同, 认为包含一对一映射属性关系的三元组更重要, 因而赋予相应三元组的损失函数
以更高的权重. TransF[22]则将方向作为度量三元组正确性的标准, 具体来说, 该算法不要求v +v≈v, 而是只要求v
h r t t
与v +v在方向上保持一致, 同理, 也要求v 与v+v保持方向一致, 为此该算法最终的得分函数为:
h r h t r
(v +v)T+(v (cid:0)v)Tv :
h r t r h
ManifoldE算法[23]观察到对于1-N和N-N类型的关系, 之所以会造成语义混乱的现象, 主要由于将尾实体集
合建模成空间中的一个点, 使得所有正确尾实体在表示空间都簇拥在一起. 因此该算法从流形角度出发, 认为在学
习链接预测任务(h, r, ?)的过程中, 正确的尾实体集合不应该由单个点表示, 而是用流形来建模. 例如分布在中心
为v +v, 半径为D的球面, 这样对于相同的头实体与关系, 球面上的所有点都可以代表正确尾实体的嵌入表示.
h r r
• TransE在处理对称关系时也具有天然的劣势, 对于对称类关系, 由于三元组(头实体, 关系, 尾实体)与(尾实
体, 关系, 头实体)同时成立, 使得这类关系的分布式表示均接近于零向量, 因此失去了语义辨识的能力. 为了解决
该问题, Sun等人[24]提出RotatE, 利用复数空间中的旋转操作代替欧式空间的加和操作, 考虑到两次旋转kπ弧度
总能回到原来的位置, 因此RotatE能够较好地学习并区分对称关系的性质. MDE[25]则针对对称类型关系将优化的
损失函数修改为||v +v-v||, 同时, 该模型还面向非对称、自反、组合关系针对性地提出了四类损失函数, 旨在利用
h t r
不同的损失函数学习不同的关系类型. 除此以外, ATTH[26]也利用反射操作一定程度上缓减了对称关系的学习问
题, 不过另一方面, 反射操作可以视为旋转操作在旋转角度为(cid:25)时的特殊情况. 类似于RotatE, QuatE[27]同样采用旋
转的思想, 但是QuatE没有使用复数空间, 而是采用了四元数向量来表示实体与关系, 利用四元数的内在属性,
QuatE能够自然建模对称与非对称关系.
• 除此以外, TransE在建模关系的组合模式能力上还略显不足. 所谓关系的组合模式, 是指对于一组关系r ,
1
r ,…, r 和r, 使得对于任意实体序列e , e ,…, e , 如果满足r (e , e )∧r (e , e )∧…∧r (e , e ), 则r(e , e )一
2 n 1 2 n+1 1 1 2 2 2 3 n n n+1 1 n+1
定会成立, 那么称关系r能够由关系序列r , r ,…, r 组合而成, 而r (e , e )∧r (e , e )∧…∧r (e , e )⇒ r(e ,
1 2 n 1 1 2 2 2 3 n n n+1 1
e )则被称为关系的组合模式. TransE 能够捕获简单的组合模式, 假设对于 8x, y, z, 存在组合模式r (x, y)∧r (y,
n+1 1 2
z)⇒ r(x, z), 那么在图嵌入的学习过程中, 根据约束v+v ≈v 、v+v ≈v和v+v≈v, 自然能够学习到等式关系v +
x r1 y y r2 z x r z r1
v ≈ v. 但TransE在学习关系的组合模式时一方面没有考虑关系序列的有序性, 另一方面也没有考虑实体在组合
r2 r
模式中扮演的角色, 虽然RotatE将TransE的加和操作修改为旋转操作, 但依然没有解决这两个问题. 为此,
DensE[28]提出基于非阿贝尔群的图嵌入学习方法, 该工作将每个关系分解为基于非阿贝尔群的旋转操作和3维空
间中的缩放操作, 有效解决了TransE和RotatE模型存在的问题, 并在WN18RR[29]公开数据集上取得了不错的提升.
• 其次, TransE没有显式建模实体的语义层级信息, 已有工作[30]证明实体层次信息有助于处理长尾实体的问
题. 为此, Hu等人[31]提出了实体的层级表示, 将实体作为叶节点, 上层概念作为内部节点, 构成有向无环图. Zhang
等人[30]则提出了HAKE, 从模长和弧度两个角度表示图嵌入, 模长用于建模不同层级实体之间的联系, 而弧度用
于度量相同语义层级实体之间的转移关系. 上述工作都是在欧式空间内学习分布式表示, 而MuRP[32]与ATTH[26]
直接从表示空间的类别选择入手, 借助双曲空间本身内在的层次性, 在双曲空间中学习图嵌入, 有效建模了知识图
谱的层次性质.
• TransE模型将每个实体建模成低维空间中的一个确定的点, 将每个关系建模成一个确定的矢量, 这意味着
模型被希望能够学习到实体和关系的确定语义, 然而语义的学习还受数据分布、实体与关系本身的含义影响. 例
如对于出现频率很低的实体与关系(又称为长尾实体与长尾关系), 由于能够刻画其语义信息的三元组较少, 想要
充分学习其语义信息较为困难; 除此以外, 很多实体与关系在不同上下文中(即不同三元组中)也往往具有不同但
近似的含义, 仅仅使用表示空间中的点来表示实体和关系显然是欠合理的. 为此, He 等人提出了KG2E模型[33], 用
相互独立的高斯分布表示每个实体和关系类别. 该工作将实体(关系)建模成高斯分布 N((cid:22);(cid:6))的形式, 其中(cid:22)用来
建模实体(关系)的中心位置, 而方差 (cid:6)度量了该实体(关系)的语义不确定程度, 直观上来看, 如果方差越大, 则表
明该实体(关系)的语义越不明确. 为了学习高斯嵌入, 给定三元组(h, r, t), 该工作基于TransE假设, 建模出t – h
的高斯分布形式, 然后计算 t(cid:0)h 与关系 r 代表的高斯分布之间的距离(论文中使用了KL散度), 对于正确的三元
组, 最小化分布之间的距离, 反之则最大化分布之间的距离. 3376 软件学报 2022年第33卷第9期
• 除此以外, Xiao等人[34]观察到TransE及其后续工作(如TransH、TransD、TransR等)都考虑计算h + r与
尾实体表示t的欧氏距离. 以TransE为代表, 其目标函数为||v +v-v|| , 在为相同的查询预测时, 模型根据所有实体
h r t p
与v +v的欧式距离对候选实体进行排序, 因此其等势面为超球面, 如图3(a)所示, 图中以二维空间为例, 红色圆
h r
圈表示正确尾实体, 蓝色三角形代表错误尾实体, TransE通过v +v或者预测尾实体的空间位置, 然后根据欧氏距
h r
离找出距离v +v最近的一系列实体作为尾实体的预测, 而所有距离v +v相同大小的实体都位于半径相等的圆
h r h r
环上. Xiao等人发现在计算向量距离时, 不同维度的重要性并不相同, 而TransE计算的欧氏距离将所有维度视为
同等重要, 为此他们提出了TransA模型[34], 该模型基于马氏距离的距离度量方法: (v +v-v)TW(v +v-v), 其中W
h r t r h r t r
是关系r对应的对称半正定矩阵. 基于马氏距离, TransA的等势面不再是超球面, 而是超椭球面, 对应于图3(a)的
例子, 在图3(b)展示了相同情况下TransA模型可能学习到的等势面, 不难看出, 通过调整等势面, TransA可以更
好地避开错误实体.
y y
v v v v
h r h r
v+v v+v
h r h r
O x O x
(a) TransE 模型 (b) TransA 模型
图 3 TransE模型的超球面图例解释与TransA模型的超椭球面图例解释
基于转移思想的图嵌入算法由于运算操作简单, 参数量适中, 学习效率高等优势, 成为了图嵌入领域非常活跃
的研究方向之一. 然而由于TransE本身存在的诸多问题, 使得后续研究需要从表示空间、运算类型等方面对
TransE进一步改进. 表2总结了部分Trans系列算法设计的得分函数.
表 2 部分Trans系列模型的得分函数设计
模型 得分函数
TransE[12] (cid:0)jjvh+vr(cid:0)vtjj
p
TransH[15] (cid:0)jj(vh(cid:0)wT rvhwr)+vr(cid:0)(vt(cid:0)wT rvtwr)jj
2
TransR[16] (cid:0)jjMrvh+vr(cid:0)Mrvtjj
2
TransD[17] (cid:0)jj(vrpvT hp+I)vh+vr(cid:0)(vrpvT tp+I)vtjj
2
STransE[19] (cid:0)jjMrhvh+vr(cid:0)Mrtvtjj
2
CrossE[20] (cid:27)(tanh(cr◦vh+cr◦vh◦vr+b)vT t)
TransF[22] (vh+vr)Tvt+(vt(cid:0)vr)Tvh
RotatE[24] (cid:0)jjvh◦vr(cid:0)vtjj
2
vh;vr;vt2Cdandjjvrjj=1
HAKE[31]
(cid:0)jjvhm◦vrm(cid:0)vtmjj
2(cid:0)(cid:21)jjsin(vhp+v 2rp(cid:0)vtp
)jj vh;vr;vt2[0;2(cid:25))d
MuRP[32] (cid:0)dB(expc 0(Mrlogc 0(vh));vt(cid:8) cvr)2+bh+bt;02Bd c;Bd
c
为切空间
QuatE[27] Qh(cid:10) jW Wr rj(cid:1)Qt e:t:Qh;Wr;Qt2Hd
{ }
KG2E[33] (cid:0)1
2
tr((cid:6)(cid:0) r1((cid:6) h+(cid:6) t))+(cid:22)T(cid:6)(cid:0) r1(cid:22)(cid:0)logde dt( e(cid:6) th ((cid:6)+ r)(cid:6) t) (cid:22)=(cid:22) h(cid:0)(cid:22) t(cid:0)(cid:22)
r
TransA[34] (cid:0)(jvh+vr(cid:0)vtj)TWr(jvh+vr(cid:0)vtj);Wr是半正定矩阵
3.2 基于张量分解的图嵌入学习
本节我们介绍基于张量分解的图嵌入算法, 同样在介绍完代表性算法后, 从分析以及解决代表性算法的缺陷 杨东华 等: 面向知识图谱的图嵌入学习研究进展 3377
入手介绍后续的相关工作.
基于张量分解的图嵌入方法, 又称为基于语义匹配的图嵌入学习方法. 其基本思想认为知识图谱能够被三维
张量T∈{0, 1}|E|·|R|·|E|建模, 其中元素T = 1表明三元组(e, r, e)正确, 相反T = 0则表明三元组(e, r, e)不正
ijk i j k ijk i j k
确, 通过张量分解方法将 T 分解为实体矩阵V∈R|E|·d、关系张量M∈Rd·|E|·d以及实体矩阵的转置VT的矩阵乘积形
式: T=V·M·VT, 其中V表示第i个实体的表示向量, M表示第j个关系的表示矩阵.
i j
基于张量分解的方法最早由RESCAL[35]提出, 对于正确的三元组(h, r, t), 该工作通过优化头实体向量v 、关
h
系矩阵M与尾实体向量v的乘积 vTMv 应满足:vTMv =T , 因此该算法的损失函数定义为:
r t h r t ∑ h r t hrt
1
(T (cid:0)vTMv)2:
2 ijk h r t
ijk
由于矩阵T由图谱知识本身决定, 因此最小化上式在优化效果上与直接最大化 vTMv 类似, 而vTMv 可以视
h r t h r t
为计算头实体、关系与尾实体的语义相似度, 因此基于张量分解思想与基于语义匹配的学习思路其实是同一种学
习思想的不同看待角度. 理论上可以证明RESCAL算法能够完全建模知识图谱蕴含的事实, 但是RESCAL算法
的缺陷在于其为每个关系都设置了相关矩阵, 造成参数量过大, 不论是防止过拟合还是为减少对硬件的要求都存
在待优化的余地.
为了解决参数问题, 如图4(b)所示, DistMult[36]约束关系矩阵为对角矩阵M=diag(v), 使得关系矩阵的参数量
r r
由O(d(cid:1)jRj(cid:1)d)减少为O(d(cid:1)jRj), 学习效率大幅提升. 同时, DistMult直接优化 vTMv , 使得正确的三元组该乘积更大,
h r t
错误的三元组乘积值更小. 但DistMult的缺陷也很明显, 对角矩阵的引入使得所有关系都被建模成对称关系, 因为
如果三元组(h;r;t)成立, 考虑到ϕ(h;r;t)=vTMv =vTMv =ϕ(t;r;h), 三元组(t;r;h)同样成立, 这后者往往并不成
h r t t r h
立. 尽管如此, 已有工作[37]表明经过改进后DistMult仍然能够取得不错的效果.
vT M v |R| vT M v |R|
h r t h r t
× × |E|h r × × |E|h r
t t
|E| |E|
知识图谱表示张量 知识图谱表示张量
(a) RESCAL 算法的核心思想图例解释 (b) DistMult 算法的核心思想图例解释
图 4 RESCAL算法与DistMult算法的核心思想解释说明
为了解决DistMult无法处理非对称关系的问题, ComplEx算法[38]尝试在矩阵乘法中引入复数运算. 具体来说,
ComplEx继承了DistMult约束关系矩阵为对角矩阵的思想, 同时设置矩阵元素类型为复数, 即V∈C|E|·d、
M2Cd(cid:1)jRj(cid:1)d, 且关系r的表示M=diag(v), 最终该算法选择的得分函数为 ϕ(h;r;t)=Re(<v;v ;v >). HolE[39]从向量
r r r h t
运算的角度出发, 对于三元组(h, r, t), 首先计算头实体与尾实体的循环相关值v ⋆v, 然后计算v ⋆v与关系表示
h t h t
v的乘积得到最终的得分函数: ϕ(i;j;k)=vT(v ⋆v). 作者在其工作中指出循环相关操作可以视为矩阵乘积的压缩
r r h t
形式, 使得HolE算法在学习效率和空间利用上更有优势. SimplE算法[40]通过为实体、关系引入两个分离的分布
式表示来解决DistMult无法建模非对称关系的问题: (1)为每个实体e关联两个不相关的嵌入表示v 、v , 分别
i i, h i, t
表示实体e充当头实体与尾实体时的向量表示; (2)同时为每个关系r关联两个嵌入表示M和M , 分别表示关
i i i –i
系r的正向以及其反方向关系r 的嵌入表示. 因为约束关系矩阵为对角矩阵, SimplE相比于RESCAL算法拥有
i –i
更少的参数量, 同时SimplE也具有充分表达图谱知识的能力.
基于RESCAL的张量分解思想, Liu等人[41]希望在图嵌入学习的过程中引入类比推理, 提出了Analogy算法.
通过对平行四边形范式的研究以及针对维持关系矩阵族的要求, 该工作在RESCAL算法的基础上引入了另外两
个约束: (1)任意关系对应的关系矩阵需符合正规矩阵; (2)任意两个关系r、r对应的关系矩阵均满足等式M·M =
i j i j
M·M. 同时, 该工作还通过关系矩阵的不同设计统一了DistMult、ComplEx与HolE算法, 具有较强的理论意义.
j i
与RESCAL算法不同, TuckER[42]并没有将知识图谱张量T分解为实体矩阵与关系张量的乘积形式, 而是采 3378 软件学报 2022年第33卷第9期
用Tucker分解算法, 将张量T分解为实体矩阵、关系矩阵、实体矩阵转置以及核张量W的乘积形式, 对于正确
的三元组(h, r, t)最大化得分函数ϕ(h, r, t)=W (cid:2) v (cid:2) v (cid:2) v, 其中核张量W是共享参数, 如图5所示. 与之前工作
1 h 2 r 3 t
不同, 由于Tucker分解的性质, TuckER算法中实体嵌入与关系嵌入的维度可以是不同的. 最后的实验结果表明该
算法也能够取得了相当不错的效果.
之前的工作, 如ComplEx、DistMult算法等, 在计算得分函数时使用向量内积方式, 该乘积方式使得实体嵌入
表示与关系嵌入表示在相同维度上进行作用, 以DistMult算法为例, 其得分函数为 vT(cid:1)M (cid:1)v , 考虑到关系矩阵M
h r t r
是对角阵, 所以DistMult算法的得分函数等价于向量v 、v、v对位相乘后求和, 其中v满足M=diag(v). 而
h r t r r r
SEEK[43]提出除了让嵌入的相同维度元素作用, 不同维度元素之间的相互作用有利于增强信息的交互融合. 为此,
该工作将实体表示与关系表示分成相同数量的片段, 表示向量之间不同位置的片段同样可以相互作用, 并设计了
能够同时建模对称与反对称的向量乘积函数f . 除此以外, 该工作还证明了通过设计不同的乘积函数f , SEEK能
够统一DistMult和ComplEx等算法.
相比于Trans系列的图嵌入算法, 基于张量分解的思路因为自设计之初就是从建模整张图谱的表示张量T的
角度来考虑, 所以该类型的许多算法拥有充分表达知识图谱的能力[35,40,42], 然而这类模型的设计往往需要较高的
数学基础, 因此相关研究工作少于Trans系列模型的研究. 表3列出了部分基于张量分解算法的得分函数设计.
w 表 3 部分基于张量分解的图嵌入算法的得分函数设计
模型 得分函数
RESCAL[35] vT hMrvt
e
s
d
e
DistMult[36] vT hdiag(vr)vt
d w ComplEx[38] Re(<vr;vh;vt>);vr;vh;vt2Cd
r r
d
HolE[39] vT r(vh⋆vt)
e
Analogy[41]SimplE[40] vT sWrvo;WrW rT=W rTWr v h◦v rv t + v t◦v -rv h
e
o TuckER[42] ϕ(h, r, t)=W×v×v×v
1 h 2 r 3 t
图 5 TuckER 算法示意图
3.3 基于传统深度学习模型的图嵌入学习
下面我们将简单介绍基于传统深度学习的图嵌入学习方法. 基于传统深度学习的方法通过使用或改进现有的
一些深度学习模型来学习三元组的特征, 按照使用的深度学习模型类别, 大致可以分为基于卷积神经网络[44]、基
于循环神经网络以及基于胶囊网络[45]的3类模型.
基于卷积神经网络(CNN)的图嵌入模型利用卷积神经网络对三元组或三元组部分元素进行编码, 从而实现
对三元组进行打分的目的. 如图6所示, ConvE[29]对三元组(h, r, t)中的头实体h与关系r进行拼接, 得到矩阵
[v ;v]∈Rd×2后对该矩阵的形状重新编辑; 然后使用卷积神经网络对其进行编码, 得到的编码结果经过全连接层输
h r
出最终的编码表示v , 计算v 与尾实体表示v的相似度, 实现对三元组进行打分. 图7是ConvKB[46]和RSN[47]的
hr hr t
算法流程. 与ConvE不同的是, ConvKB直接利用卷积神经网络对三元组进行编码: 以图7为例, 对于三元组(h, r,
t), ConvKB首先将其拼接为[v ;v;v]∈R4×3的形式, 其中4表示初试图嵌入表示的维度; 然后利用卷积神经网络对
h r t
其编码, 使用3个 1(cid:2)3 的卷积核对其进行卷积操作, 每个卷积核能够得到 4(cid:2)1 的卷积结果, 最终将3个不同卷积
核的卷积结果拼接; 编码结果最后经过全连接层直接进行打分(该全连接层的输出维度为1). ConvR[48]考虑使用卷
积对头实体进行编码, ConvE与ConvR模型的区别可以从图8中得到解释: ConvE首先拼接头实体和关系表示,
然后使用卷积操作对拼接结果进行卷积编码; 而ConvR直接将关系建模成卷积核, 直接针对头实体嵌入进行卷积
操作. 与ConvE相同, ConvR使用卷积编码结果与尾实体嵌入求内积计算三元组的得分. InteractE[49]观察到在学习
图嵌入的过程中, 实体表示与关系表示之间的交互计算越多, 图嵌入中蕴含的语义信息能够更深层次被利用, 也因
此更有利于目标任务的学习(如链接预测任务). 为此, InteractE提出通过特征排列(feature permutation)、特征重
塑 (checkered feature reshaping)和循环卷积(circular convolution)这3步操作增强图嵌入的表达能力. 杨东华 等: 面向知识图谱的图嵌入学习研究进展 3379
Projection to
Embeddings “Image” Feature maps embedding Logits Predictions
dimension
0.9
0.2
0.1
Fully connected Matrix Logistic 0.6
e1 Concat Convolve projection multiplication sigmoid 0 0. .2 3
rel With 0.0
0.7
entity matrix 0.1
0.4
0.4
Embedding Feature map Hidden layer 0.4
dropout (0.2) dropout (0.2) dropout (0.3)
图 6 ConvE算法流程[29]
ReLU 3 feature maps
are concatenated
Convolution
Dot
Matrix 4×3 3 filters 1×3 Product Score
Recurrent
skipping Combine Combine
network
h r t RNN unit
k=4
United Kingdom Country Tim berners-lee Employer W3C
(a) ConvKB 算法流程示例 (b) RSN 算法流程示例
图 7 ConvKB[46]和RSN[47]算法流程
Embeddings “Image” Feature maps Embeddings “Image” Feature maps
Reshape Convolve
s Reshape Convolve s
r
r Stack
Split & reshape
Relation-specfic
Global filters filters
(a) ConvE 卷积操作流程 (b) ConvR 卷积操作流程
图 8 ConvE与ConvR的卷积操作对比[48]
类似ConvKB, CapsE[50]采用胶囊网络(CapsNet)对三元组进行编码, 以图9展示为例, 算法具体流程如下: 首
先将三元组(h, r, t)拼接成输入矩阵[v ;v;v]∈Rd×3; 然后利用5个 1(cid:2)3大小的卷积核对输入矩阵进行编码, 得到
h r t
大小为d (cid:2)5的特征图; 该特征图被输入进第1层CapsNet层, 经过5个capsule处理, 每个capsule提取某一方面
事实; 最后将路由结果输入到第2层CapsNet, 用于计算该三元组的得分.
相比于CNN和CapsNet, 循环神经网络(RNN)在建模序列数据上的能力更加突出. 前面介绍的ConvE、
ConvKB以及CapsE等工作都只建模单独的三元组, 而知识图谱除了组成元素外, 三元组之间的连接信息也是构
成图网络的重要知识, 其中, 对应于其他类型异质图中的元路径(meta-path), 首尾相连的三元组路径是建模这种深
层次图结构知识的可用信息之一. 为了更好地挖掘知识图谱的长距离结构信息, Guo等人基于三元组路径的图嵌
入学习模型RSN[47]. Guo等人试图通过RNN对长距离结构信息进行编码, 然而三元组路径中包含实体和关系两
种元素, 在编码实体和关系时需要区别对待. 为此, Guo等人对RNN进行改进, 提出了Skipping机制: 3380 软件学报 2022年第33卷第9期
{
h; x 2E
h′= t t :
t S 1h t+S 2x t(cid:0)1; x t2R
即如果当前输入为实体, 则按照RNN的逻辑进行运行; 如果当前输入为关系, 则输出单元在RNN的基础上
还要加上前一次模型实体输入x . 如图8(b)所示, 对于三元组路径United Kingdom !country!Tim Berners-Lee
t–1
!employer!W3C, 当学习实体United Kingdom的表示时, 计算逻辑与原始的RNN模型相同, 而在编码关系
country时, 则同时使用country和United Kingdom的信息. 通过编码三元组序列, RSN将深层次的结构知识融入
到为实体与关系学习的图嵌入表示中. 作者后续又论证了RSN与残差网络的联系, 并在实体对齐任务中取得了相
当不错的成绩.
总体来看, 基于传统深度学习的图嵌入学习方法的研究内容并不算多. 虽然传统神经网络较为强大的学习能
力使得这类模型在一些数据集上也拥有不错的表现, 但是传统深度学习的可解释性问题也随之遗留在图嵌入学习
研究中. 因此如何基于传统深度学习设计更优良的模型, 以及关于神经网络可解释性问题有待进一步研究开展.
ReLU
5 feature maps
Convolution
Matrix 4×3 5 filters 1×3 4 capsules, each with 5 neurons
1 capsule, with 2 neurons
Squash
s r o
u
1
Squash
u
2 Routing
s e ||e||
process
u
3 Second capsule layer
u
4
k=4 First capsule layer
CNN layer
图 9 CapsE算法流程[50]
3.4 基于图神经网络模型的图嵌入学习
本小节我们介绍基于图神经网络的图嵌入学习算法, 从代表性工作的设计思想、短板分析以及后续改进的思
路梳理发展脉络.
图神经网络(GNN)[51,52]是近期研究较为广泛的领域之一, 很多研究表明GNN在建模图数据方面表现出非常
突出的性能, 目前图神经网络模型已被成功应用到诸多研究领域, 如社交网络[53]、医药研究、晶体性能预测[54]、
知识图谱[55]等.
图神经网络模型可以用message passing neural networks (MPNN)[56]框架来描述, 该框架在前向传播过程可分
为两个阶段: 信息传递和信息读取阶段. 其中信息传递阶段又分为传递信息至邻居节点、聚合自身信息与邻居传
递的信息两个过程, 这也正是GNN的前向传播逻辑. 为此, GNN每一层的前向传播过程可以用统一建模成:
hk i+1=Merge(fhk ig[aggr(fhk jg j2N(i)));
其中, Merge表示特征融合函数, aggr表示邻居特征聚合函数, N(i)表示节点i的邻居集合, 而hk就是节点i在第k
i
层网络中输入的特征向量.
图卷积神经网络(GCN)[51,52,57]是图神经网络模型研究中得到的一项主要成果, 成功将卷积操作应用到无向图
这类非欧空间数据. GCN的特征学习逻辑可以用下式表示:
Hk+1= f(AˆHkWk);
其中, Aˆ=D (cid:0)1 2(A+I)D (cid:0)1 2 , A是无向图的邻接矩阵, I是单位矩阵, 为D是无向图的度矩阵. 这里的 Hk 表示第 k 层网
络层学习到的节点特征矩阵, f是可选择的激活函数. 杨东华 等: 面向知识图谱的图嵌入学习研究进展 3381
虽然GCN在如节点分类、图分类等诸多任务上均取得了不错的成绩, 但是原始GCN模型只针对无向无权
图, 为了将其应用于知识图谱, 需要在GCN模型的基础上施以一定的调整. Schlichtkrull等人[55]提出R-GCN, 为每
个关系r引入关联的权重矩阵W, 在GCN在聚集邻居信息前先用相应关系权重矩阵特化邻居特征, 之后参与聚
r
合过程, 其特征更新过程可以用下式表示:
■ ■
h(
ik+1)=(cid:27)|||||||■∑ r2R∑
j2Nrc1
i;rW r(k)h( jk)+W 0kh(
ik)|||||||■;
i
其中, W(k)表示第k层关系r的权重矩阵.
r
可以看出, R-GCN虽然将GCN模型扩展到了关系图中, 但是仍然存在3方面问题.
(1) R-GCN只考虑了关系的类别, 却忽略了关系的方向;
(2) 由于需要为每个关系都关联一个权重矩阵, 对于关系类别较多的知识图谱, 存在参数量过大的问题;
(3) R-GCN只是引入了关系权重矩阵, 为每条边赋予了相应的权重, 但没有显示学习关系表示.
针对第2个问题, R-GCN考虑对关系矩阵进行约束, 提出了两种策略: (1)共享参数; (2)稀疏化矩阵. 共享参
数方法通过设置特定数目的基矩阵 fV b(k)g 1⩽b⩽B , 其中B是基矩阵的数目, 然后通过线性组合的方式得到不同关系关
∑B
联的权重矩阵W(k)= a(k)V(k). 稀疏化矩阵方案约束W(k)为对角块状矩阵, 即W(k)=diag(Q(l);:::;Q(l)), 其中
r rb b r r 1r Br
b=1
Q(l)2R(d(k+1)=B)(cid:1)(d(k)=B), 这里的d(k)与d(k+1)分别表示第k层网络以及第k+1层网络的输出维度.
br
除了将GCN扩展到关系图领域, R-GCN还提出了将GNN系列模型用于链接预测任务的框架范式, 即
Encoder-Decoder框架, 如图10所示. 其中R-GCN充当编码器, 用于学习节点特征, 最后一层输出节点特征后作为
解码器的输入, 解码器可以选择前面介绍过的传统的图嵌入学习算法, 如图1中使用的DistMult算法, 对于三元
组(e r, e), 基于R-GCN学习到实体表示h、h, 同时在编码器部分为每个关系引入关系矩阵R, 基于DistMult算
i, j i j r
法计算三元组得分ϕ(e;r;e )=hTRh , 根据得分高低判断三元组的正确性.
i j i r j
输入 R-GCN DistMult 损失
编码器 解码器
图 10 R-GCN用于链接预测任务框架
R-GCN 虽然在收集邻居信息时考虑了不同关系信息, 但是忽略了关系的方向, 除此以外, R-GCN直接聚合了
邻居的特征信息, 而忽略了异质图中不同节点因为实体类型不同可能拥有不同特征域的问题. 为此, VR-GCN[58]通
过将TransE引入R-GCN框架, 在聚合邻居信息前, 首先基于TransE的假设: h + r ≈ t, 将邻居转移到中心实体(也
就是待更新特征表示的实体)所在的特征域中, 从而解决了头、尾实体表示从属不同特征域的问题. 例如对于中心
实体e, 具体做法如下: (1)对于与实体e通过关系r相邻且充当尾实体的实体e, 通过组合函数为 c(hl;hl)=
i i j j r
hl(cid:0)hl将实体e转移到实体e的特征域中; (2)对于与实体e通过关系r相邻且充当头实体的实体e, 则利用组合
j r j i i j
函数为cˆ(hl;hl)=hl+hl. VR-GCN的层特征更新函数如下:
j r j r ■■ ■ ■ ■ ■
hl
i+1=(cid:27)|||||||■|||||||■
d1
|||||||■∑∑
(hl t(cid:0)hl
r)+∑∑
(hl t+hl
r)|||||||■+hl i|||||||■Wl|||||||■:
i r2Nrt2Ntr r2Nrt2Ntr
通过引入TransE的思想, VR-GCN成功在聚集邻居信息的同时既考虑了关系的类别信息, 又考虑了关系的方
向信息. 在VR-GCN的基础上, Trans-GCN[59]与CompGCN[60]对其使用的组合函数进行了扩展, 分别另外提出了使
用RotatE、DistMult和HolE思想的组合函数, 均取得了不错的效果. 除此以外, CompGCN还显示考虑了关系的
方向信息, 具体的特征更新函数如下式所示:
■ ■
h v=
f||||||■ ∑
W(cid:21)(r)ϕ(h u;h
r)||||||■;
(u;r)2N(v) 3382 软件学报 2022年第33卷第9期
其中, λ(r)表示关系r的方向, 该工作按照关系的方向类别将关系分成3大类: 出节点关系、入节点关系以及自循
环关系, 权重矩阵W 根据关系r方向的不同使用不同的参数矩阵.
λ(r)
图注意力网络(GAT)[61]是图神经网络模型研究得到的另一项重要成果, 该模型成功将注意力机制引入到图神
经网络的聚合过程中, 使得聚合邻居信息时不同邻居拥有不同的重要性, 这也启发了基于GNN的知识图谱表示
学习工作在聚集邻居信息的过程中加入权重参数进行重要性选择. SCAN[62]通过直接设置与关系类别相关的权重
参数, 实现了邻居信息的聚集过程中不同关系对于中心实体具有不同重要性的思想. 然而这种重要性的计算只与
关系类别有关, 与邻居实体没有关系, 为了同时考虑邻居实体与邻居关系在计算权重过程中的影响, Nathani 等
人[63]在聚合邻居信息的过程中参考了GAT的思想, 然而不过与之前工作不同, Nathani 等人并没有聚合邻居实体
信息, 而是直接聚合邻居三元组的信息, 以实体v为例, 其聚合邻居信息的工作原理如下: (1)首先考虑将所有实
i
体v参与的三元组编码成向量形式, 如三元组(v, r, v)编码成向量形式c =W [h||h||g], 其中h与h分别代表实
i i k j ijk 1 i j k i j
体v与v的嵌入表示, 而g代表关系r的嵌入表示; (2)计算三元组(v, r, v)的权重: α =Softmax(LeakyReLU
i j k k ■ t ■k j ijk
(W 2c ijk)); (3)为实体 v
i
聚合所有邻居信息, 得到 h′
i=(cid:27)|||||||■ ∑ ∑
(cid:11) ijkc
ijk|||||||■
, 这里用R ij表示连接实体v i与v j的关系集合.
j2N(vi)k2Rij
虽然文献[63]引入了attention机制, 但没有满足同一特征域内融合特征的思想, 相比之下, RAGAT[64]既采用
了GAT的注意力机制, 又继承了文献[58−60]等工作利用组合函数将邻居转移到中心实体特征域的做法. 需要说
明的是, RAGAT认为相同实体与不同关系关联时应具有不同表示, 在文献[58−60]等工作的基础上提出了与关系
相关的组合函数. 以基于TransE的组合函数为例, 实体v为中心实体, 实体u通过关系r与实体v组成三元组(v,
r, u), Trans-GCN定义的组合函数为e – e, 而RAGAT定义的组合函数为We – e, 如果仔细观察, 不难发现
u r r u r
RAGAT选择的组合函数更像是基于TransR算法的思想.
以上工作都只考虑每次聚合节点的一阶邻居信息, 虽然经过L次聚合操作, 每个节点都能获取其L-阶邻居的
信息, 但是Sun等人[65]指出这种方式容易加剧噪声传播的影响, 除此以外, Sun等人还证明了仅使用一阶邻居信息
在特殊情况下可能无法分辨不同节点邻居结构的异质性. 为此, 考虑多跳邻居信息是能够更好聚合邻居信息的一
种手段, Sun等人提出AliNet, 该模型直接聚合多跳邻居实体的特征信息, 并通过门机制控制不同阶邻居信息对组
成中心实体最终特征表示的重要性. Nathani 等人[63]通过直接加入新“边”来聚合多跳邻居的信息, 以二阶邻居为
例, 对于实体v , 实体v 通过路径(v, r , v)˄(v, r , v)与实体v相连, 该工作通过引入新关系 r′=r +r 来加入新
i j i 1 k k 2 j i 1 2
的三元组知识 (v i;t′;v j) , 如此, v j通过“关系” r′ 成为实体v i的一阶邻居, 进而实现聚合多跳邻居信息的目的. 目前关
于如何在聚合邻居信息的过程中引入多跳邻居信息的工作还可以进一步挖掘.
总而言之, 图神经网络凭借其强大的建模图结构数据的能力, 能够更加深入地挖掘学习图谱的结构信息, 对图
谱的结构信息进行深度编码. 结合图神经网络的发展趋势, 面向知识图谱的基于图神经网络的图嵌入研究有待进
一步的发展. 表4总结了部分基于GNN的图嵌入算法的特征更新公式.
3.5 引入额外信息的图嵌入学习方法
本小节我们从信息利用的角度考虑图嵌入学习问题, 介绍引入额外信息的图嵌入学习方法. 之前介绍的工作
理论上均专注于学习图谱的结构特征, 无论是TransE以及DistMult等工作每次的学习单元为单个三元组, 还是
RAGAT等工作利用图神经网络通过聚合实体的邻居信息来学习特征, 都只是通过学习结构信号来完成下游任务.
然而除了结构信号, 知识图谱作为一种特殊的异质图, 每个实体与关系均能够关联具体的文本概念或类别信息, 这
些信号都能够进一步补充结构信息, 使得图嵌入能够学习到更丰富的语义信息.
通过在图嵌入学习的过程中融入实体与关系的名称、实体描述等信息, 有利于丰富图嵌入表示学习到的语义
信息. 给定实体名称序列, NTN[66]直接使用实体名称所有字符的词向量表示的均值作为图嵌入的初始值. Zhang等
人[67]通过多任务学习联合学习图谱结构与图谱的文本信息, 该工作学习实体的文本表示时依然采用NTN的思路,
用实体名称包含的所有字符的词向量的均值作为实体的文本表示. 与上述工作不同, DKRL[68]通过CNN或
CBOW模型对头、尾实体的描述信息进行编码, 得到实体的文本表示 v 和v , 同时基于TransE思想, 在优化
hd td
E =||v + v – v||学习实体的结构表示的同时, 又通过将其中v 和v分别替换成基于实体描述信息编码出的实体表
S h r t h t 杨东华 等: 面向知识图谱的图嵌入学习研究进展 3383
示向量v 、v , 得到新的损失E =||v + v – v ||、E =||v + v – v||和E =||v + v – v ||, 通过混合训练结构表示
hd td DD hd r td DS hd r t SD h r td
和文本表示实现文本信息与结构信息的融合. Xu等人[69]通过结构表示与文本表示相加的方式向结构信息中添加
图谱的文本信号, 同时考虑到信号融合过程中不同信号拥有不同的权重, 该工作采取门机制自动平衡两类信号的
重要性. Wang等人[70]同样分别学习结构表示和文本表示, 在联合学习的过程中通过互注意力机制交互结构信息
与文本信息, 使两类信号能够互相学习, 互相弥补. 由于近年来预训练语言模型的发展, 文本信息的抽取和编码能
力得到长足提升, 同时考虑到预训练语言模型经过海量文本的自监督学习, 预训练语言模型本身的内部参数存储
了语法和常识知识, 于是开始出现使用预训练语言模型编码图嵌入的工作. Daza等人提出BLP框架[71], 该框架使
用Bert模型[72]编码实体描述信息, 作为传统图嵌入学习算法(如TransE)的图嵌入向量初始化值, 利用Bert模型
学习实体描述的文本知识, 同时利用基于结构信息的图嵌入学习算法学习知识图谱中蕴含的结构信息.
表 4 部分基于图神经网络的图嵌入算法的特征更新公式
模型 特征更新公式
∑∑
R-GCN[55] hl i+1=(cid:27)( r2Rj2Nrc1 i;rW rlhl j+W 0lhl i)
i
∑∑ ∑∑
VR-GCN[58] hl i+1=(cid:27)(Wl( (hl j(cid:0)r kl)+ (hl j+r kl)))
r2Rj2Nr r2Rj2Nr
it ih
■
∑
||||||■ W Ol; r2R
CompGCN[60] hl i+1=(cid:27)( (rk;ej)2N(ei)W(cid:21)l (rk)ϕ(hl j;r kl)) W (cid:21)l (r)=||||||■ W
W
SIl l;
;
r r2 =R si env
lf
∑ ∑
Trans-GCN[59] hl i+1=(cid:27)( c1 iWl( (ej;rk;ei)2Tin(ei)(hl j◦ r kl)+ (ei;rk;ej)2Tout(ei)(hl j(cid:3)r kl))+hl i)
RAGAT[64]
hl i+1=f( H1 ∑ hH =1(rk;e∑ j)2N(ei)(cid:11)h k;jmh (ei;rk;ej)) mh (ei;rk;ej)=Wdir(rk)ϕr(ei;ej)
(cid:11)h k;j=Softmax(LeakyReLU(Wattmh(ei;rk;ej)))
除却实体名称、实体描述等文本信息, 类别层级信息同样有利于丰富图嵌入的语义信息. TKRL[73]通过实体
类别信息构造类别的层次树形结构, 树的根节点为设置的最一般的实体类型, 通过层层细化, 叶子节点表示图谱中
划分最细致的实体类别, 每个叶子节点到树的根节点对应了唯一一条路径, 而这条路径可以用来全面描述该叶子
实体类型的层次信息, 层次树中的每个节点都对应了特定的映射矩阵, 其中叶子节点的映射矩阵可以通过RHE
与WHE两种方式获取. 同时该工作认为每个实体可能拥有多种类别, 而相同实体在不同关系下自然应当考虑不
同的类型信息. 基于TransE, TKRL提出了新的度量函数||M v + v –M v||, 其中M 是与头实体h以及关系r的
rh h r rt t rh
类别相关的投影矩阵, 同理M 是与尾实体t以及关系r的类别相关的投影矩阵. TKRL是第一篇将类别信息用于
rt
知识图谱表示学习的工作, 在一定程度上缓减了TransE无法处理多映射关系的问题. MKRL[74]则统一使用了上述
介绍的各种信息, 同时考虑了实体描述信息、实体类别层次类别信息以及关系的文本信息. Zhang等人[74]从关系
的层次信息出发, 将关系按照语义分成3个层次: 聚类关系层、关系层和次关系层. 聚类关系层通过对所有关系进
行聚类, 这是考虑了同一聚类关系具有一定的语义相似度; 关系层建模关系的直接语义信息; 而次关系层考虑了相
同关系在不同语境下可能具有不同的含义, 为此按照关系所参与的三元组进行聚类: 对于每个包含关系r的三元
组(h, r, t), 计算得到在该语境下关系的表示 v =v (cid:0)v , 如此操作后, 对于关系r会得到一系列不同语境下的向量
rˆ t h
表示frˆg, 对该集合进行聚类, 每个聚类对应了该关系在特定语境下的次关系表示.
相比于挖掘结构信息的图嵌入算法, 引入额外信息的图表示学习算法通过知识图谱自身蕴含的文本知识和层 3384 软件学报 2022年第33卷第9期
次信息来补充欠缺的结构信息, 进而学习到更有效、建模知识图谱更佳的图嵌入. 至于如何同时充分学习知识图
谱结构信息和其他类型的信息, 还有待进一步的研究和挖掘.
4 总 结
4.1 5类图嵌入学习算法的简单总结
本文从算法核心、基础模型使用以及信息利用等角度梳理了五类图嵌入算法的原理和设计特点, 并针对某些
奠基性的工作给予了着重介绍. 我们在表5中总结了这5类图嵌入算法的基础特征性质以供参考.
表 5 不同类型图嵌入算法的基础特征总结
类型 特征
建模思想直观, 可设计改进的空间较大, 参数量少, 计算效率高; 但是表达能力有限, 需要
基于转移思想的图嵌入算法
进一步的设计
理论表达能力强, 但现有算法的实验效果仍有待提高; 通常参数较多, 不利于应用与大规
基于张量分解的图嵌入算法
模图谱
基于传统深度学习的图嵌入算法 特征学习能力强; 然而可解释性不强, 部分算法的稳定性不强
利用图神经网络较强的图编码能力, 建模能力强; 然而计算效率低, 不利于大规模工业领
基于图神经网络的图嵌入算法
域应用
充分利用知识图谱的包含的其他类型信息, 对知识图谱的图结构特征进行补充; 目前研究
引入额外信息的图嵌入算法
工作不多, 有待进一步的研究探索
基于转移思想的图嵌入算法具有较为高效的计算效率, 适中的参数量, 也具有较为优秀的表达能力. 除此以外
也拥有灵活的设计空间, 可以从不同向量空间、不同转移操作等角度进行考虑设计. 然而由于其基本思想比较简
单, 奠基性算法TransE在处理对称、1-N、N-1以及N-N等关系类型上具有很大的劣势, 即这类算法在充分表达
知识图谱的能力上有可提升的空间, 因此后续基于转移思想的很多工作都需要着重考虑如何提升模型的建模能力上.
基于张量分解的图嵌入算法因为其基本思想旨在完整建模知识图谱蕴含的信息, 因此理论上具有很强的模型
表达能力, 例如其奠基性算法RESCAL 具有完全表达知识图谱的知识的能力, 但根据现有的模型的实验结果来看,
基于该思想的模型性能有待进一步挖掘. 除此以外RESCAL拥有过多的参数, 使得该算法在泛化能力以及应用在
大规模知识图谱上具有较大的劣势. 为此RESCAL的很多后续算法都旨在解决如何保留表达能力的同时减少参
数量, 提高模型的计算效率.
基于传统深度学习的图嵌入算法利用CNN、RNN以及CapsNet等传统深度学习算法在抽取特征上的优势
进行表示学习, 也取得了不错的成绩. 然而, 也正是因为深度学习模型的使用使得这类算法的可解释性不足. 除此
以外, 文献[75]的工作表明, ConvKB、CapsE算法在不同数据集实验效果浮动很大, 这也侧面反映了这类算法的
不稳定性.
基于图神经网络的图嵌入算法基于知识图谱的图结构特性对原本建模于无向图的图神经网络模型结构进行
了适当调整, 使得图嵌入学习过程中能够利用图神经网络强大的图编码能力. 然而考虑到这类算法在解码器端要
使用之前介绍的传统图嵌入算法作为解码器, 所以解码器拥有的缺陷也可能同样存在于基于图神经网络的图嵌入
模型中. 除此以外, 图神经网络的计算效率也是阻止其大规模工业化应用的原因之一, 如何在保证表达能力的同时
提高该类图嵌入模型的计算效率也是需要研究的问题. 同时, 如何更好地学习图谱蕴含的结构信息也是基于图神
经网络的图嵌入算法仍然有待完善的地方.
引入额外信息的图嵌入算法考虑图结构信息以外的信息来提升学习效果, 考虑了名称、描述、类别等额外信
息作为图结构信息的补充, 是从信息来源的角度考虑图嵌入学习问题, 在归纳假设上可能仍然采用之前提及的不
同图嵌入算法的基本思想, 例如TKRL虽然使用了实体的描述信息, 但该模型学习的基本假设还是采用了TransE
的基本思想. 至于如何更充分地利用以上信息, 也是有待进一步挖掘探索的工作.
为了更好地展示不同算法的性能, 本文在表6中给出了部分算法在标准数据集FB15k-237[8]和WN18RR[29]数 杨东华 等: 面向知识图谱的图嵌入学习研究进展 3385
据集上的链接预测任务的实验指标结果, 实验指标采取MRR和Hits@k指标. 考虑到FB15k-237和WN18RR两个
数据集提出时间较晚, 很多工作在论文中没有基于此二者进行实验, 为此本文从其他较新的工作中寻找他人复现
后的实验结果, 即使这样, 还是存在很多算法没有或者缺少实验结果数据, 为此对于没有实验结果的算法我们在
表6中不予展示, 对于缺少部分实验指标的算法我们用“－”代替. 表6中展示的所有结果都通过数据来源一列括
号内的索引给出了相应的结果出处, 其中DKRL算法的实验结果由我们自己复现得到.
需要说明的是, 列出的指标来自于现有的论文, 仅供参考, 考虑到不同算法在图嵌入维度、训练轮数、批采样
大小、负采样大小以及损失函数设计等都存在差异, 因此该数据不完全能够用于分析对比不同算法之间的性能优
劣. 除此以外, 根据Sun等人[76]的研究发现, 部分模型的指标计算存在问题, 部分算法如ConvKB、CapsE在为三
元组进行打分时常常会为不同的三元组赋予相同的分值. 因此这部分算法本文采取Sun等人重新评估后的实验
结果.
通过表6可以观察到, 通过引入复数空间、双曲空间、旋转操作和四元数等设计思想, Trans-系列方法的实验
性能得到大幅度提升, 在FB15k-237和WN18RR数据集上得到很好的实验效果; 基于张量分解方法的实验指标稍
微低一些, 这可能与该类方法的设计难度较高存在关联, 也可以参考Trans-系列方法的设计思路, 从表示空间、相
似度计算函数等方面进一步进行算法设计; 基于传统深度学习的方法表现不够突出, 而且除ConvE与ConvR的表
现相对稳定, ConvKB与CapsE在不同数据集上表现波动较大, 例如CapsE模型在WN18RR数据集上表现良好,
但是在FB15k-237数据集上效果却不如TransE, 波动的原因也值得进一步研究探索; 基于GNN的方法表现也相
当不错, 其中Rotat-GCN和RAGAT的解码器部分分别基于RotatE和CrossE模型, 因此不难猜想将解码器部分
换成表现更好的QuatE、ATTH等算法是否会进一步提升模型性能; 引入额外信息部分且存有可靠实验结果的相
关工作能够留下结果的并不多, 通过对比DKRL和TransE的实验结果, 引入实体描述信息确实有利于进一步提升
模型性能.
表 6 不同类型图嵌入算法在标准数据集上的实验结果对比
FB15k-237 WN18RR
类别 模型 数据来源
MRR Hits@10 MRR Hits@10
TransE[12] [77] 0.207 0.377 － －
TransH[15] [77] 0.211 0.386 － －
CrossE[20] [20] 0.299 0.474 － －
基于转移思想 MuRP[32] [32] 0.336 0.521 0.481 0.566
QuatE[27] [27] 0.366 0.556 0.488 0.582
RotatE[24] [24] 0.338 0.533 0.476 0.571
ATTH[26] [26] 0.348 0.540 0.486 0.573
DistMult[36] [32] 0.241 0.419 0.430 0.490
基于张量分解思想 ComplEx[38] [32] 0.247 0.428 0.440 0.510
TuckER[42] [42] 0.358 0.544 0.470 0.526
ConvE[29] [29] 0.316 0.491 0.460 0.480
ConvR[48] [48] 0.350 0.528 0.475 0.537
基于传统深度学习
ConvKB[46] [76] 0.243 0.421 0.249 0.524
CapsE[50] [76] 0.150 0.356 0.415 0.559
R-GCN[55] [55] 0.248 0.417 － －
CompGCN[60] [60] 0.355 0.535 0.479 0.546
基于图神经网络模型 Trans-GCN[59] [59] 0.315 0.477 0.233 0.508
Rotat-GCN[59] [59] 0.356 0.555 0.485 0.578
RAGAT[64] [64] 0.365 0.547 0.489 0.562
DKRL[68] 本文 0.225 0.385 0.204 0.550
引入额外信息
Zhang等人[77] [77] 0.315 0.496 － － 3386 软件学报 2022年第33卷第9期
4.2 面向知识图谱的图嵌入学习领域有待进一步解决的问题和挑战
近些年, 虽然面向知识图谱的图嵌入学习领域发展迅速, 但是仍然存在许多待解决的问题. 为了方便以后研究
人员的研究, 我们总结了一些面向知识图谱的图嵌入学习领域的研究热点和有待解决的问题:
• 如何更好地学习long-tail类型的实体? long-tail类型的实体和关系是指出现频率很少的实体与关系, 由于训
练样本不足, 往往学习出的图嵌入不足以建模该类实体的语义信息, 从而影响基于图嵌入的下游任务. 而文献[78]
分析了常见的知识图谱中long-tail类型的实体与关系占有相当的比例. 因此, 如何在long-tail的条件下充分学习
实体与关系的表示是一件很有价值的工作.
• 如何更好地将文本信息、类别信息融入图嵌入学习? 通过将知识图谱本身拥有的文本知识和类别知识, 进
一步丰富基于结构知识的图嵌入的信息. 除此以外, 考虑到实体关联的文本信息与类别信息与实体出现的频率无
关的特征, 因此结合文本和类别信息也是解决long-tail问题的方案之一.
• 如何更好地挖掘知识图谱本身蕴含的层次信息? 层次信息作为知识图谱本身蕴含的潜在结构信息, 如果能
够充分挖掘, 对于建模知识图谱的结构具有一定的研究意义. 除此以外, 利用层次树结构中同一父实体的子实体具
有相似的语义信息这一特点, 层次信息同样也有利于解决long-tail问题.
• 除了文本与类别信息, 图片、语音等多模态信息也是知识获取的途径. 在学习图嵌入的过程中, 考虑融入多
模态信息, 在面向知识图谱的下游任务中可能取到不错的效果.
• 研究图嵌入算法与其他推理算法的结合. 图嵌入算法在面向知识图谱的单步推理任务中具有不错的效果, 且
相对于其他种类的推理方法又具有学习效率高的优点, 但考虑到其主要依赖浅层结构约束来学习图表示, 在复杂
推理、多跳推理任务中表现不佳, 因此, 结合图嵌入算法的优点与其他推理算法的优势[79], 例如一阶逻辑推理方
法的可解释性, 在保证推理能力与可解释性的同时提高推理算法的计算效率.
• 如何在保证建模能力的同时提高图嵌入的学习效率? 现有的某些图嵌入算法虽然表达能力出众, 但是参数
量相对较多, 在学习大规模知识图谱表示的任务上具有低效率的缺点, 因此如何在充分保证模型学习能力的同时,
提高模型的学习效率, 这也是现有的图嵌入算法是否能够大规模应用于工业领域的关键问题之一.
• 如何结合上下文动态地学习图嵌入表示? 在知识图谱中, 实体的邻居相当于该实体的上下文, 在某些的任务,
例如基于知识图谱的链接预测任务中, 对于不同的query (h, r, ?), 实体 h的邻居可能起到不同的作用, 为此如何针
对不同的任务为实体h动态地学习相应的表示[80,81]也是很有意义的研究问题.
• 如何学习动态知识图谱(又称时序知识图谱)的图嵌入表示? 常见的知识图谱是静态的图结构, 但是现实使
用中, 知识图谱的图结构往往会伴随着时间而发生变化, 例如增加了部分实体或者删除了部分实体之间的关系, 虽
然短时间的局部结构变化对全局表示影响不大, 但伴随时间积累下的结构差异也会使得重新学习图嵌入非常重
要, 然而重新学习的成本通常较大. 为此, 如何高效学习动态知识图谱的图嵌入表示也是目前需要解决的研究问题
之一[82].
• 除此以外, 图嵌入算法的设计还需要考虑特定的下游任务, 如何在基于知识图谱的具体下游任务中设计并利
用好图嵌入也是需要考虑的问题.
综上所述, 面向知识图谱的图嵌入学习目前还存有很多需要解决的问题, 这也正需要更多研究人员的努力和投入.
References:
[1] Xu K, Reddy S, Feng YS, Huang SF, Zhao DY. Question answering on freebase via relation extraction and textual evidence. In: Proc. of
the 54th Annual Meeting of the Association for Computational Linguistics. Berlin: ACL, 2016. 2326–2336. [doi: 10.18653/v1/P16-1220]
[2] Hoffmann R, Zhang CL, Ling X, Zettlemoyer L, Weld DS. Knowledge-based weak supervision for information extraction of overlapping
relations. In: Proc. of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume
1. Portland: ACM, 2011. 541–550.
[3] Carlson A, Betteridge J, Kisiel B, Settles B, Hruschka ER, Mitchell TM. Toward an architecture for never-ending language learning. In:
Proc. of the 24th AAAI Conf. on Artificial Intelligence. Atlanta: AAAI, 2010. 1306–1313.
[4] Wang WY, Mazaitis K, Cohen WW. Programming with personalized pagerank: A locally groundable first-order probabilistic logic. In: 杨东华 等: 面向知识图谱的图嵌入学习研究进展 3387
Proc. of the 22nd ACM Int’l Conf. on Information & Knowledge Management. San Francisco: ACM Press, 2013. 2129–2138. [doi: 10.
1145/2505515.2505573]
[5] Jiang SP, Lowd D, Dou DJ. Learning to refine an automatically extracted knowledge base using markov logic. In: Proc. of the 12th IEEE
Int’l Conf. on Data Mining. Brussels: IEEE, 2012. 912–917. [doi: 10.1109/ICDM.2012.156]
[6] Bühmann L, Lehmann J. Pattern based knowledge base enrichment. In: Proc. of the 12th Int’l Semantic Web Conf. on the Semantic Web.
Sydney: Springer, 2013. 33–48. [doi: 10.1007/978-3-642-41335-3_3]
[7] Wang X, Bo DY, Shi C, Fan SH, Ye YF, Yu PS. A survey on heterogeneous graph embedding: Methods, techniques, applications and
sources. arXiv: 2011.14867, 2020.
[8] Toutanova K, Chen DQ, Pantel P, Poon H, Choudhury P, Gamon M. Representing text for joint embedding of text and knowledge bases.
In: Proc. of the 2015 Conf. on Empirical Methods in Natural Language Processing. Lisbon: ACL, 2015. 1499–1509. [doi: 10.18653/v1/
D15-1174]
[9] Wang X, Ji HY, Shi C, Wang B, Ye YF, Cui P, Yu PS. Heterogeneous graph attention network. In: Proc. of the 2019 World Wide Web
Conf. San Francisco: ACM, 2019. 2022–2032. [doi: 10.1145/3308558.3313562]
[10] Wang Q, Mao ZD, Wang B, Guo L. Knowledge Graph embedding: A survey of approaches and applications. IEEE Trans. on Knowledge
and Data Engineering, 2017, 29(12): 2724–2743. [doi: 10.1109/TKDE.2017.2754499]
[11] Dai YF, Wang SP, Xiong NN, Guo WZ. A survey on knowledge graph embedding: Approaches, applications and benchmarks.
Electronics, 2020, 9(5): 750. [doi: 10.3390/electronics9050750]
[12] Bordes A, Usunier N, Garcia-Durán A, Weston J, Yakhnenko O. Translating embeddings for modeling multi-relational data. In: Proc. of
the 26th Int’l Conf. on Neural Information Processing Systems. Lake Tahoe: Curran Associates Inc., 2013. 2787–2795.
[13] Bordes A, Glorot X, Weston J, Bengio Y. Joint learning of words and meaning representations for open-text semantic parsing. In: Proc. of
the 15th Int’l Conf. on Artificial Intelligence and Statistics. La Palma: JMLR, 2012. 127–135.
[14] Bordes A, Weston J, Collobert R, Bengio Y. Learning structured embeddings of knowledge bases. In: Proc. of the 25th AAAI Confe. on
Artificial Intelligence. San Francisco: AAAI, 2011. 301–306.
[15] Wang Z, Zhang JW, Feng JL, Chen Z. Knowledge graph embedding by translating on hyperplanes. In: Proc. of the 28th AAAI Conf. on
Artificial Intelligence. Québec City: AAAI, 2014. 1112–1119.
[16] Lin YK, Liu ZY, Sun MS, Liu Y, Zhu X. Learning entity and relation embeddings for knowledge graph completion. In: Proc. of the 29th
Conf. on Artificial Intelligence. Austin: AAAI, 2015. 2181–2187.
[17] Ji GL, He SZ, Xu LH, Liu K, Zhao J. Knowledge graph embedding via dynamic mapping matrix. In: Proc. of the 53rd Annual Meeting of
the Association for Computational Linguistics and the 7th Int’l Joint Conf. on Natural Language Processing. Beijing: ACL, 2015.
687–696. [doi: 10.3115/v1/P15-1067]
[18] Ji GL, Liu K, He SZ, Zhao J. Knowledge graph completion with adaptive sparse transfer matrix. In: Proc. of the 30th AAAI Conf. on
Artificial Intelligence. Phoenix: AAAI, 2016. 985–991.
[19] Nguyen DQ, Sirts K, Qu LZ, Johnson M. STransE: A novel embedding model of entities and relationships in knowledge bases. In: Proc.
of the 2016 Conf. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. San
Diego: ACL, 2016. 460–466. [doi: 10.18653/v1/N16-1054]
[20] Zhang W, Paudel B, Zhang W, Bernstein A, Chen HJ. Interaction embeddings for prediction and explanation in knowledge graphs. In:
Proc. of the 12th ACM Int’l Conf. on Web Search and Data Mining. Melbourne: ACM, 2019. 96–104. [doi: 10.1145/3289600.3291014]
[21] Fan M, Zhou Q, Chang E, Zheng TF. Transition-based knowledge graph embedding with relational mapping properties. In: Proc. of the
28th Pacific Asia Conf. on Language, Information and Computing. Phuket: Department of Linguistics, Chulalongkorn University, 2014.
328–337.
[22] Feng J, Zhou ML, Hao Y, Huang ML, Zhu XY. Knowledge graph embedding by flexible translation. arXiv: 1505.05253, 2015.
[23] Xiao H, Huang ML, Zhu XY. From one point to a manifold: Knowledge graph embedding for precise link prediction. In: Proc. of the 25th
Int’l Joint Conf. on Artificial Intelligence. New York: IJCAI/AAAI Press, 2016. 1315–1321.
[24] Sun ZQ, Deng ZH, Nie JY, Tang J. Rotate: Knowledge graph embedding by relational rotation in complex space. In: Proc. of the 7th Int’l
Conf. on Learning Representations. New Orleans: OpenReview, 2019.
[25] Sadeghi A, Graux D, Yazdi HS, Lehmann J. MDE: Multiple distance embeddings for link prediction in knowledge graphs. 2019. [doi: 10.
3233/FAIA200248]
[26] Chami I, Wolf A, Juan DC, Sala F, Ravi S, Ré C. Low-dimensional hyperbolic knowledge graph embeddings. In: Proc. of the 58th
Annual Meeting of the Association for Computational Linguistics. ACL, 2020. 6901–6914. [doi: 10.18653/v1/2020.acl-main.617]
[27] Zhang S, Tay Y, Yao LN, Liu Q. Quaternion knowledge graph embeddings. In: Proc. of the 33rd Int’l Conf. on Neural Information 3388 软件学报 2022年第33卷第9期
Processing Systems. Vancouver: Curran Associates Inc., 2019. 246.
[28] Lu H, Hu H. DensE : An enhanced non-commutative representation for knowledge graph embedding with adaptive semantic hierarchy.
arXiv: 2008.04548, 2020.
[29] Dettmers T, Minervini P, Stenetorp P, Riedel S. Convolutional 2D knowledge graph embeddings. In: Proc. of the 32nd AAAI Conf. on
Artificial Intelligence. New Orleans: AAAI, 2018. 1811–1818.
[30] Zhang ZQ, Cai JY, Zhang YD, Wang J. Learning hierarchy-aware knowledge graph embeddings for link prediction. In: Proc. of the 34th
AAAI Conf. on Artificial Intelligence. New York: AAAI, 2020. 3065–3072. [doi: 10.1609/aaai.v34i03.5701]
[31] Hu ZT, Huang PY, Deng YT, Gao YK, Xing E. Entity hierarchy embedding. In: Proc. of the 53rd Annual Meeting of the Association for
Computational Linguistics and the 7th Int’l Joint Conf. on Natural Language Proc. Beijing: ACL, 2015. 1292–1300. [doi: 10.3115/v1/P15-
1125]
[32] Balažević I, Allen C, Hospedales T. Multi-relational poincaré graph embeddings. In: Proc. of the 33rd Conf. on Neural Information
Processing Systems. Vancouver, 2019. 4465–4475.
[33] He SZ, Liu K, Ji GL, Zhao J. Learning to represent knowledge graphs with Gaussian embedding. In: Proc. of the 24th ACM Int’l Conf. on
Information and Knowledge Management. Melbourne: ACM, 2015. 623–632. [doi: 10.1145/2806416.2806502]
[34] Xiao H, Huang ML, Hao Y, Zhu XY. TransA: An adaptive approach for knowledge graph embedding. arXiv: 1509.05490, 2015.
[35] Nickel M, Tresp V, Kriegel HP. A three-way model for collective learning on multi-relational data. In: Proc. of the 28th Int’l Conf. on
Machine Learning. Bellevue, ICML, 2011. 809–816.
[36] Yang BS, Yih WT, He XD, Gao JF, Deng L. Embedding entities and relations for learning and inference in knowledge bases. In: Proc. of
the 3rd Int’l Conf. on Learning Representations. San Diego: ICLR, 2015.
[37] Kadlec R, Bajgar O, Kleindienst J. Knowledge base completion: Baselines strike back. In: Proc. of the 2nd Workshop on Representation
Learning for NLP. Vancouver: ACL, 2017. 69–74. [doi: 10.18653/v1/W17-2609]
[38] Trouillon T, Welbl J, Riedel S, Gaussier É, Bouchard G. Complex embeddings for simple link prediction. In: Proc. of the 33rd Int’l Conf.
on Machine Learning. New York: JMLR, 2016. 2071–2080.
[39] Nickel M, Rosasco L, Poggio TA. Holographic embeddings of knowledge graphs. In: Proc. of the 30th AAAI Conf. on Artificial
Intelligence. Phoenix: AAAI, 2016. 1955–1961.
[40] Kazemi SM, Poole D. SimplE embedding for link prediction in knowledge graphs. In: Proc. of the 32nd Int’l Conf. on Neural Information
Processing Systems. Montréal: Curran Associates Inc., 2018. 4289–4300.
[41] Liu HX, Wu YX, Yang YM. Analogical inference for multi-relational embeddings. In: Proc. of the 34th Int’l Conf. on Machine Learning.
Sydney: PMLR, 2017. 2168–2178.
[42] Balažević I, Allen C, Hospedales TM. Tucker: Tensor factorization for knowledge graph completion. In: Proc. of the 2019 Conf. on
Empirical Methods in Natural Language Processing and the 9th Int’l Joint Conf. on Natural Language Processing. Hong Kong: ACL,
2019. 5185–5194. [doi: 10.18653/v1/D19-1522]
[43] Xu WT, Zheng S, He L, Shao B, Yin J, Liu TY. SEEK: Segmented embedding of knowledge graphs. In: Proc. of the 58th Annual
Meeting of the Association for Computational Linguistics. ACL, 2020. 3888–3897. [doi: 10.18653/v1/2020.acl-main.358]
[44] Lecun Y, Bottou L, Bengio Y, Haffner P. Gradient-based learning applied to document recognition. Proc. of the IEEE, 1998, 86(11):
2278–2324. [doi: 10.1109/5.726791]
[45] Sabour S, Frosst N, Hinton GE. Dynamic routing between capsules. In: Proc. of the 31st Int’l Conf. on Neural Information Processing
Systems. Long Beach: Curran Associates Inc, 2017. 3859–3869.
[46] Nguyen DQ, Nguyen TD, Nguyen DQ, Phung D. A novel embedding model for knowledge base completion based on convolutional
neural network. In: Proc. of the 2018 Conf. of the North American Chapter of the Association for Computational Linguistics: Human
Language Technologies. New Orleans: ACL, 2018. 327–333. [doi: 10.18653/v1/N18-2053]
[47] Guo LB, Sun ZQ, Hu W. Learning to exploit long-term relational dependencies in knowledge graphs. In: Proc. of the 36th Int’l Conf. on
Machine Learning. Long Beach: PMLR, 2019. 2505–2514.
[48] Jiang XT, Wang Q, Wang B. Adaptive convolution for multi-relational learning. In: Proc. of the 2019 Conf. of the North American
Chapter of the Association for Computational Linguistics: Human Language Technologies. Minneapolis: ACL, 2018. 978–987. [doi: 10.
18653/v1/N19-1103]
[49] Vashishth S, Sanyal S, Nitin V, Agrawal N, Talukdar P. InteractE: Improving convolution-based knowledge graph embeddings by
increasing feature interactions. In: Proc. of the 34th AAAI Conf. on Artificial Intelligence. New York: AAAI, 2020. 3009–3016. [doi: 10.
1609/aaai.v34i03.5694]
[50] Nguyen DQ, Vu T, Nguyen TD, Nguyen DQ, Phung D. A capsule network-based embedding model for knowledge graph completion and 杨东华 等: 面向知识图谱的图嵌入学习研究进展 3389
search personalization. In: Proc. of the 2019 Conf. of the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies. Minneapolis: ACL, 2019. 2180–2189. [doi: 10.18653/v1/N19-1226]
[51] Bruna J, Zaremba W, Szlam A, LeCun Y. Spectral networks and locally connected networks on graphs. In: Proc. of the 2nd Int’l Conf. on
Learning Representations. Banff: ICLR, 2014.
[52] Defferrard M, Bresson X, Vandergheynst P. Convolutional neural networks on graphs with fast localized spectral filtering. In: Proc. of the
30th Int’l Conf. on Neural Information Processing Systems. Barcelona: Curran Associates Inc., 2016. 3844–3852.
[53] Hamilton WL, Ying R, Leskovec J. Inductive representation learning on large graphs. In: Proc. of the 31st Int’l Conf. on Neural
Information Processing Systems. Long Beach: Curran Associates Inc., 2017. 1025–1035.
[54] Sanyal S, Balachandran J, Yadati N, Kumar A, Rajagopalan P, Sanyal S, Talukdar P. MT-CGCNN: Integrating crystal graph
convolutional neural network with multitask learning for material property prediction. arXiv: 1811.05660, 2018.
[55] Schlichtkrull M, Kipf TN, Bloem P, van den Berg R, Titov I, Welling M. Modeling relational data with graph convolutional networks. In:
Proc. of the 15th Int’l Conf. on the Semantic Web. Heraklion: Springer, 2018. 593–607. [doi: 10.1007/978-3-319-93417-4_38]
[56] Gilmer J, Schoenholz SS, Riley PF, Vinyals O, Dahl GE. Neural message passing for quantum chemistry. In: Proc. of the 34th Int’l Conf.
on Machine Learning. Sydney: PMLR, 2017. 1263–1272.
[57] Kipf TN, Welling M. Semi-supervised classification with graph convolutional networks. In: Proc. of the 5th Int’l Conf. on Learning
Representations. Toulon: OpenReview.net, 2017. 1–14.
[58] Ye R, Li X, Fang YJ, Zang HY, Wang MZ. A vectorized relational graph convolutional network for multi-relational network alignment.
In: Proc. of the 28th Int’l Joint Conf. on Artificial Intelligence. Macao: IJCAI.org, 2019. 4135–4141. [doi: 10.24963/ijcai.2019/574]
[59] Cai L, Yan B, Mai GC, Janowicz K, Zhu R. TransGCN: Coupling transformation assumptions with graph convolutional networks for link
prediction. In: Proc. of the 10th Int’l Conf. on Knowledge Capture. Marina Del Rey: ACM, 2019. 131–138. [doi: 10.1145/3360901.
3364441]
[60] Vashishth S, Sanyal S, Nitin V, Talukdar PP. Composition-based multi-relational graph convolutional networks. In: Proc. of the 8th Int’l
Conf. on Learning Representations. Addis Ababa: OpenReview.net, 2020.
[61] Veličković P, Cucurull G, Casanova A, Romero A, Liò P, Bengio Y. Graph attention networks. In: Proc. of the 6th Int’l Conf. on
Learning Representations. Vancouver: OpenReview.net, 2018.
[62] Shang C, Tang Y, Huang J, Bi JB, He XD, Zhou BW. End-to-end structure-aware convolutional networks for knowledge base
completion. In: Proc. of the 33rd AAAI Conf. on Artificial Intelligence. Honolulu: AAAI, 2019. 3060–3067. [doi: 10.1609/aaai.v33i01.
33013060]
[63] Nathani D, Chauhan J, Sharma C, Kaul M. Learning attention-based embeddings for relation prediction in knowledge graphs. In: Proc. of
the 57th Annual Meeting of the Association for Computational Linguistics. Florence: ACL, 2019. 4710–4723. [doi: 10.18653/v1/P19-
1466]
[64] Liu XY, Tan HB, Chen QH, Lin GY. RAGAT: Relation aware graph attention network for knowledge graph completion. IEEE Access,
2021, 9: 20840–20849. [doi: 10.1109/ACCESS.2021.3055529]
[65] Sun ZQ, Wang CM, Hu W, Chen MH, Dai J, Zhang W, Qu YZ. Knowledge graph alignment network with gated multi-hop neighborhood
aggregation. In: Proc. of the 34th AAAI Conf. on Artificial Intelligence. New York: AAAI, 2020. 222–229. [doi: 10.1609/aaai.v34i01.
5354]
[66] Socher R, Chen DQ, Manning CD, Ng AY. Reasoning with neural tensor networks for knowledge base completion. In: Proc. of the 26th
Int’l Conf. on Neural Information Processing Systems. Lake Tahoe: Curran Associates Inc, 2013. 926–934.
[67] Zhang DX, Yuan B, Wang D, Liu R. Joint semantic relevance learning with text data and graph knowledge. In: Proc. of the 3rd Workshop
on Continuous Vector Space Models. Beijing: ACL, 2015. 32–40. [doi: 10.18653/v1/W15-4004]
[68] Xie RB, Liu ZY, Jia J, Luan HB, Sun MS. Representation learning of knowledge graphs with entity descriptions. In: Proc. of the 30th
AAAI Conf. on Artificial Intelligence. Phoenix: AAAI, 2016. 2659–2665.
[69] Xu JC, Qiu XP, Chen K, Huang XJ. Knowledge graph representation with jointly structural and textual encoding. In: Proc. of the 26th Int’l
Joint Conf. on Artificial Intelligence. Melbourne: IJCAI, 2017. 1318–1324. [doi: 10.24963/ijcai.2017/183]
[70] Wang YS, Zhang HH, Shi G, Liu ZR, Zhou Q. A model of text-enhanced knowledge graph representation learning with mutual attention.
IEEE Access, 2020, 8: 52895–52905. [doi: 10.1109/ACCESS.2020.2981212]
[71] Daza D, Cochez M, Groth P. Inductive entity representations from text via link prediction. In: Proc. of the Web Conf. 2021 (WWW2021).
Ljubljana: ACM, 2021. 798–808. [doi: 10.1145/3442381.3450141]
[72] Devlin J, Chang MW, Lee K, Toutanova K. BERT: Pre-training of deep bidirectional transformers for language understanding. In: Proc.
of the 2019 Conf. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 3390 软件学报 2022年第33卷第9期
Minneapolis: ACL, 2019. 4171–4186. [doi: 10.18653/v1/N19-1423]
[73] Xie RB, Liu ZY, Sun MS. Representation learning of knowledge graphs with hierarchical types. In: Proc. of the 25th Int’l Joint Conf. on
Artificial Intelligence. New York: IJCAI/AAAI Press, 2016. 2965–2971.
[74] Tang X, Chen L, Cui J, Wei BG. Knowledge representation learning with entity descriptions, hierarchical types, and textual relations.
Information Processing & Management, 2019, 56(3): 809–822. [doi: 10.1016/j.ipm.2019.01.005]
[75] Rossi A, Barbosa D, Firmani D, Matinata A, Merialdo P. Knowledge graph embedding for link prediction: A comparative analysis. ACM
Trans. on Knowledge Discovery from Data, 2021, 15(2): 14. [doi: 10.1145/3424672]
[76] Sun ZQ, Vashishth S, Sanyal S, Talukdar P, Yang YM. A re-evaluation of knowledge graph completion methods. In: Proc. of the 58th
Annual Meeting of the Association for Computational Linguistics. ACL, 2020. 5516–5522. [doi: 10.18653/v1/2020.acl-main.489]
[77] Zhang Z, Zhuang FZ, Qu M, Lin F, He Q. Knowledge graph embedding with hierarchical relation structure. In: Proc. of the 2018 Conf.
on Empirical Methods in Natural Language Processing. Brussels: ACL, 2018. 3198–3207. [doi: 10.18653/v1/D18-1358]
[78] Wang ZH, Lai KP, Li PJ, Bing LD, Lam W. Tackling long-tailed relations and uncommon entities in knowledge graph completion. In:
Proc. of the 2019 Conf. on Empirical Methods in Natural Language Processing and the 9th Int’l Joint Conf. on Natural Language
Processing. Hong Kong: ACL, 2020. 250–260. [doi: 10.18653/v1/D19-1024]
[79] Zhang W, Paudel B, Wang L, Chen JY, Zhu H, Zhang W, Bernstein A, Chen HJ. Iteratively learning embeddings and rules for knowledge
graph reasoning. In: Proc. of the 2019 World Wide Web Conf. San Francisco: ACM, 2366–2377. [doi: 10.1145/3308558.3313612]
[80] Sheng JW, Guo S, Chen ZY, Yue JW, Wang LH, Liu TW, Xu HB. Adaptive attentional network for few-shot knowledge graph
completion. In: Proc. of the 2020 Conf. on Empirical Methods in Natural Language Processing. ACL, 2020. 1681–1691. [doi: 10.18653/
v1/2020.emnlp-main.131]
[81] Zhang CX, Yao HX, Huang C, Jiang M, Li ZH, Chawla NV. Few-shot knowledge graph completion. In: Proc. of the 34th AAAI Conf. on
Artificial Intelligence. New York: AAAI, 2020. 3041–3048. [doi: 10.1609/aaai.v34i03.5698]
[82] Kazemi SM, Goel R, Jain K, Kobyzev I, Sethi A, Forsyth P, Poupart P. Representation learning for dynamic graphs: A survey. arXiv:
1905.11485, 2019.
杨东华(1976－), 男, 博士, 副教授, 博士生导师, 王宏志(1978－), 男, 博士, 教授, 博士生导师,
主要研究领域为数据库系统, 大数据管理与 CCF杰出会员, 主要研究领域为数据库系统, 大
分析. 数据管理与分析.
何涛(1997－), 男, 硕士, 主要研究领域为知识 王金宝(1985－), 男, 博士, 副教授, CCF专业会
图谱. 员, 主要研究领域为大数据分析. ---------------------------------------------------------------------------------